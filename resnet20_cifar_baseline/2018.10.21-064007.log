2018-10-21 06:40:07,526 - Log file for this run: /home/dllab/distiller/examples/classifier_compression/logs/baseline/2018.10.21-064007/2018.10.21-064007.log
2018-10-21 06:40:07,526 - Number of CPUs: 48
2018-10-21 06:40:07,606 - Number of GPUs: 1
2018-10-21 06:40:07,606 - CUDA version: 8.0.61
2018-10-21 06:40:07,606 - CUDNN version: 7102
2018-10-21 06:40:07,607 - Kernel: 4.15.0-29-generic
2018-10-21 06:40:07,607 - Python: 3.6.6 | packaged by conda-forge | (default, Oct 12 2018, 14:08:43) 
[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]
2018-10-21 06:40:07,607 - PyTorch: 0.4.0
2018-10-21 06:40:07,607 - Numpy: 1.14.3
2018-10-21 06:40:07,644 - Git is dirty
2018-10-21 06:40:07,644 - Active Git branch: master
2018-10-21 06:40:07,663 - Git commit: e0bfc7963cad2123ea9c2ea87c058ea0dba22b0b
2018-10-21 06:40:07,664 - App args: ['compress_classifier.py', '--arch', 'resnet20_cifar', '../../../data.cifar10', '-p=50', '--lr=0.3', '--epochs=300', '-b', '128', '--compress=resnet20_cifar_baseline.yaml', '-j=1', '--vs', '0', '--deterministic', '-o', 'logs/baseline/']
2018-10-21 06:40:07,666 - ==> using cifar10 dataset
2018-10-21 06:40:07,666 - => creating resnet20_cifar model for CIFAR10
2018-10-21 06:40:11,855 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2018-10-21 06:40:11,856 - Optimizer Args: {'lr': 0.3, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False}
2018-10-21 06:40:13,821 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2018-10-21 06:40:13,821 - Reading compression schedule from: resnet20_cifar_baseline.yaml
2018-10-21 06:40:13,828 - Schedule contents:
{
  "lr_schedulers": {
    "training_lr": {
      "class": "MultiStepMultiGammaLR",
      "milestones": [
        100,
        200,
        250
      ],
      "gammas": [
        0.1,
        0.1,
        0.5
      ]
    }
  },
  "policies": [
    {
      "lr_scheduler": {
        "instance_name": "training_lr"
      },
      "starting_epoch": 0,
      "ending_epoch": 301,
      "frequency": 1
    }
  ]
}
2018-10-21 06:40:13,830 - 

2018-10-21 06:40:13,830 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:40:15,563 - Epoch: [0][   50/  391]    Overall Loss 2.248264    Objective Loss 2.248264    Top1 19.203125    Top5 65.500000    LR 0.300000    Time 0.034599    
2018-10-21 06:40:17,167 - Epoch: [0][  100/  391]    Overall Loss 2.229725    Objective Loss 2.229725    Top1 21.398438    Top5 70.039062    LR 0.300000    Time 0.033312    
2018-10-21 06:40:18,776 - Epoch: [0][  150/  391]    Overall Loss 2.215522    Objective Loss 2.215522    Top1 23.114583    Top5 71.921875    LR 0.300000    Time 0.032919    
2018-10-21 06:40:20,374 - Epoch: [0][  200/  391]    Overall Loss 2.207381    Objective Loss 2.207381    Top1 24.144531    Top5 72.480469    LR 0.300000    Time 0.032663    
2018-10-21 06:40:21,977 - Epoch: [0][  250/  391]    Overall Loss 2.197844    Objective Loss 2.197844    Top1 25.193750    Top5 72.846875    LR 0.300000    Time 0.032537    
2018-10-21 06:40:23,590 - Epoch: [0][  300/  391]    Overall Loss 2.191201    Objective Loss 2.191201    Top1 25.979167    Top5 73.411458    LR 0.300000    Time 0.032483    
2018-10-21 06:40:25,193 - Epoch: [0][  350/  391]    Overall Loss 2.184692    Objective Loss 2.184692    Top1 26.680804    Top5 73.988839    LR 0.300000    Time 0.032416    
2018-10-21 06:40:26,645 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24591 | -0.00611 |    0.18294 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12414 | -0.00703 |    0.09806 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12131 |  0.00327 |    0.09675 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11815 |  0.00249 |    0.09483 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11413 |  0.00018 |    0.09079 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11511 |  0.00029 |    0.09127 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11293 | -0.00298 |    0.09043 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08250 |  0.00002 |    0.06610 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07949 | -0.00256 |    0.06342 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23497 |  0.00164 |    0.18615 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07946 | -0.00133 |    0.06294 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07910 | -0.00604 |    0.06342 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07878 | -0.00245 |    0.06271 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07787 | -0.00676 |    0.06272 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05692 | -0.00144 |    0.04552 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05488 | -0.00098 |    0.04378 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15986 | -0.00290 |    0.12751 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05446 | -0.00129 |    0.04336 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05390 |  0.00145 |    0.04307 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05350 |  0.00011 |    0.04269 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05303 |  0.00107 |    0.04229 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20366 | -0.00382 |    0.16281 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:40:26,646 - Total sparsity: 0.00

2018-10-21 06:40:26,646 - --- validate (epoch=0)-----------
2018-10-21 06:40:26,646 - 10000 samples (128 per mini-batch)
2018-10-21 06:40:27,875 - Epoch: [0][   50/   78]    Loss 2.132521    Top1 32.078125    Top5 79.921875    
2018-10-21 06:40:28,526 - ==> Top1: 31.920    Top5: 79.780    Loss: 2.132

2018-10-21 06:40:28,528 - ==> Best Top1: 31.920   On Epoch: 0

2018-10-21 06:40:28,528 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:40:28,671 - 

2018-10-21 06:40:28,671 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:40:30,390 - Epoch: [1][   50/  391]    Overall Loss 2.136056    Objective Loss 2.136056    Top1 31.656250    Top5 77.343750    LR 0.300000    Time 0.034313    
2018-10-21 06:40:32,030 - Epoch: [1][  100/  391]    Overall Loss 2.132744    Objective Loss 2.132744    Top1 32.039063    Top5 77.671875    LR 0.300000    Time 0.033514    
2018-10-21 06:40:33,637 - Epoch: [1][  150/  391]    Overall Loss 2.131026    Objective Loss 2.131026    Top1 32.302083    Top5 77.734375    LR 0.300000    Time 0.033038    
2018-10-21 06:40:35,220 - Epoch: [1][  200/  391]    Overall Loss 2.128001    Objective Loss 2.128001    Top1 32.585937    Top5 78.019531    LR 0.300000    Time 0.032682    
2018-10-21 06:40:36,840 - Epoch: [1][  250/  391]    Overall Loss 2.123260    Objective Loss 2.123260    Top1 33.081250    Top5 78.443750    LR 0.300000    Time 0.032611    
2018-10-21 06:40:38,429 - Epoch: [1][  300/  391]    Overall Loss 2.118527    Objective Loss 2.118527    Top1 33.541667    Top5 78.768229    LR 0.300000    Time 0.032463    
2018-10-21 06:40:40,111 - Epoch: [1][  350/  391]    Overall Loss 2.113054    Objective Loss 2.113054    Top1 34.073661    Top5 78.986607    LR 0.300000    Time 0.032623    
2018-10-21 06:40:41,539 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28654 |  0.00067 |    0.21541 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12345 | -0.00927 |    0.09776 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12072 | -0.00312 |    0.09671 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11209 | -0.00298 |    0.08957 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10988 | -0.00468 |    0.08741 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10872 | -0.00111 |    0.08626 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10723 | -0.00217 |    0.08603 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08213 | -0.00006 |    0.06564 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07718 | -0.00470 |    0.06154 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23138 |  0.00014 |    0.18411 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07702 | -0.00022 |    0.06091 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07636 | -0.00778 |    0.06127 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07650 | -0.00344 |    0.06078 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07464 | -0.00878 |    0.06003 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05698 | -0.00280 |    0.04550 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05271 | -0.00143 |    0.04203 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14928 | -0.00510 |    0.11953 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05147 | -0.00173 |    0.04099 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04988 |  0.00166 |    0.03989 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04895 | -0.00019 |    0.03904 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04837 |  0.00156 |    0.03855 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25833 | -0.00339 |    0.20406 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:40:41,539 - Total sparsity: 0.00

2018-10-21 06:40:41,539 - --- validate (epoch=1)-----------
2018-10-21 06:40:41,539 - 10000 samples (128 per mini-batch)
2018-10-21 06:40:42,701 - Epoch: [1][   50/   78]    Loss 2.132258    Top1 32.078125    Top5 79.937500    
2018-10-21 06:40:43,327 - ==> Top1: 32.140    Top5: 80.210    Loss: 2.132

2018-10-21 06:40:43,329 - ==> Best Top1: 32.140   On Epoch: 1

2018-10-21 06:40:43,329 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:40:43,345 - 

2018-10-21 06:40:43,346 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:40:44,999 - Epoch: [2][   50/  391]    Overall Loss 2.072188    Objective Loss 2.072188    Top1 38.390625    Top5 82.453125    LR 0.300000    Time 0.033003    
2018-10-21 06:40:46,536 - Epoch: [2][  100/  391]    Overall Loss 2.067299    Objective Loss 2.067299    Top1 38.937500    Top5 82.648438    LR 0.300000    Time 0.031837    
2018-10-21 06:40:48,072 - Epoch: [2][  150/  391]    Overall Loss 2.063233    Objective Loss 2.063233    Top1 39.296875    Top5 83.046875    LR 0.300000    Time 0.031452    
2018-10-21 06:40:49,576 - Epoch: [2][  200/  391]    Overall Loss 2.059051    Objective Loss 2.059051    Top1 39.699219    Top5 82.914062    LR 0.300000    Time 0.031094    
2018-10-21 06:40:51,130 - Epoch: [2][  250/  391]    Overall Loss 2.050348    Objective Loss 2.050348    Top1 40.578125    Top5 83.059375    LR 0.300000    Time 0.031083    
2018-10-21 06:40:52,685 - Epoch: [2][  300/  391]    Overall Loss 2.045186    Objective Loss 2.045186    Top1 41.093750    Top5 83.335938    LR 0.300000    Time 0.031072    
2018-10-21 06:40:54,246 - Epoch: [2][  350/  391]    Overall Loss 2.040920    Objective Loss 2.040920    Top1 41.555804    Top5 83.421875    LR 0.300000    Time 0.031087    
2018-10-21 06:40:55,635 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33487 | -0.00702 |    0.25513 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12715 | -0.00792 |    0.09929 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12479 | -0.00558 |    0.09826 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11173 | -0.00432 |    0.08787 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10973 | -0.00567 |    0.08685 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10781 | -0.00395 |    0.08418 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10613 | -0.00749 |    0.08573 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09090 | -0.00048 |    0.07123 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08164 | -0.00566 |    0.06484 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24262 | -0.00333 |    0.19147 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07789 | -0.00015 |    0.06133 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07623 | -0.00800 |    0.06120 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07800 | -0.00493 |    0.06191 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07485 | -0.01030 |    0.06041 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06047 | -0.00231 |    0.04799 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05242 | -0.00248 |    0.04169 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14546 | -0.00865 |    0.11667 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05023 | -0.00270 |    0.03995 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04728 |  0.00109 |    0.03772 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04566 | -0.00082 |    0.03641 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04478 |  0.00117 |    0.03564 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30828 | -0.00302 |    0.23668 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:40:55,635 - Total sparsity: 0.00

2018-10-21 06:40:55,636 - --- validate (epoch=2)-----------
2018-10-21 06:40:55,636 - 10000 samples (128 per mini-batch)
2018-10-21 06:40:56,860 - Epoch: [2][   50/   78]    Loss 2.007029    Top1 44.859375    Top5 86.750000    
2018-10-21 06:40:57,505 - ==> Top1: 44.540    Top5: 86.980    Loss: 2.012

2018-10-21 06:40:57,507 - ==> Best Top1: 44.540   On Epoch: 2

2018-10-21 06:40:57,507 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:40:57,524 - 

2018-10-21 06:40:57,524 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:40:59,274 - Epoch: [3][   50/  391]    Overall Loss 1.996045    Objective Loss 1.996045    Top1 46.125000    Top5 85.250000    LR 0.300000    Time 0.034920    
2018-10-21 06:41:00,858 - Epoch: [3][  100/  391]    Overall Loss 1.991686    Objective Loss 1.991686    Top1 46.476562    Top5 84.804688    LR 0.300000    Time 0.033282    
2018-10-21 06:41:02,470 - Epoch: [3][  150/  391]    Overall Loss 1.982641    Objective Loss 1.982641    Top1 47.432292    Top5 85.635417    LR 0.300000    Time 0.032911    
2018-10-21 06:41:04,086 - Epoch: [3][  200/  391]    Overall Loss 1.980014    Objective Loss 1.980014    Top1 47.652344    Top5 85.957031    LR 0.300000    Time 0.032753    
2018-10-21 06:41:05,686 - Epoch: [3][  250/  391]    Overall Loss 1.978296    Objective Loss 1.978296    Top1 47.881250    Top5 86.078125    LR 0.300000    Time 0.032593    
2018-10-21 06:41:07,264 - Epoch: [3][  300/  391]    Overall Loss 1.975923    Objective Loss 1.975923    Top1 48.132812    Top5 86.257812    LR 0.300000    Time 0.032412    
2018-10-21 06:41:08,822 - Epoch: [3][  350/  391]    Overall Loss 1.973876    Objective Loss 1.973876    Top1 48.332589    Top5 86.412946    LR 0.300000    Time 0.032225    
2018-10-21 06:41:10,255 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35134 | -0.00604 |    0.26515 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12659 | -0.00804 |    0.09810 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12334 | -0.00741 |    0.09565 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11031 | -0.00278 |    0.08490 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10818 | -0.00825 |    0.08521 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10569 | -0.00099 |    0.08111 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10364 | -0.00981 |    0.08343 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09649 | -0.00188 |    0.07389 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08526 | -0.00757 |    0.06711 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24430 | -0.01170 |    0.19309 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07997 | -0.00286 |    0.06265 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07598 | -0.00850 |    0.06118 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07813 | -0.00579 |    0.06171 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07408 | -0.01119 |    0.05977 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06276 | -0.00275 |    0.04947 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05228 | -0.00295 |    0.04128 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14134 | -0.01239 |    0.11346 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04979 | -0.00308 |    0.03945 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04523 |  0.00073 |    0.03600 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04273 | -0.00147 |    0.03402 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04146 |  0.00099 |    0.03292 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32848 | -0.00268 |    0.24650 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:41:10,255 - Total sparsity: 0.00

2018-10-21 06:41:10,256 - --- validate (epoch=3)-----------
2018-10-21 06:41:10,256 - 10000 samples (128 per mini-batch)
2018-10-21 06:41:11,492 - Epoch: [3][   50/   78]    Loss 1.973674    Top1 48.156250    Top5 86.203125    
2018-10-21 06:41:12,240 - ==> Top1: 48.400    Top5: 86.360    Loss: 1.970

2018-10-21 06:41:12,242 - ==> Best Top1: 48.400   On Epoch: 3

2018-10-21 06:41:12,242 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:41:12,258 - 

2018-10-21 06:41:12,258 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:41:14,050 - Epoch: [4][   50/  391]    Overall Loss 1.944652    Objective Loss 1.944652    Top1 51.171875    Top5 87.734375    LR 0.300000    Time 0.035779    
2018-10-21 06:41:15,645 - Epoch: [4][  100/  391]    Overall Loss 1.945642    Objective Loss 1.945642    Top1 51.234375    Top5 87.648438    LR 0.300000    Time 0.033814    
2018-10-21 06:41:17,238 - Epoch: [4][  150/  391]    Overall Loss 1.940885    Objective Loss 1.940885    Top1 51.708333    Top5 88.104167    LR 0.300000    Time 0.033150    
2018-10-21 06:41:18,862 - Epoch: [4][  200/  391]    Overall Loss 1.938840    Objective Loss 1.938840    Top1 51.957031    Top5 88.371094    LR 0.300000    Time 0.032969    
2018-10-21 06:41:20,461 - Epoch: [4][  250/  391]    Overall Loss 1.936458    Objective Loss 1.936458    Top1 52.284375    Top5 88.421875    LR 0.300000    Time 0.032764    
2018-10-21 06:41:22,013 - Epoch: [4][  300/  391]    Overall Loss 1.933140    Objective Loss 1.933140    Top1 52.679688    Top5 88.627604    LR 0.300000    Time 0.032467    
2018-10-21 06:41:23,573 - Epoch: [4][  350/  391]    Overall Loss 1.928623    Objective Loss 1.928623    Top1 53.107143    Top5 88.763393    LR 0.300000    Time 0.032281    
2018-10-21 06:41:25,006 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37005 | -0.00881 |    0.27725 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12542 | -0.00966 |    0.09553 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12160 | -0.01096 |    0.09265 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10973 | -0.00801 |    0.08278 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10703 | -0.00830 |    0.08304 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10394 | -0.00397 |    0.07882 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10238 | -0.00838 |    0.08190 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10300 | -0.00421 |    0.07763 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08966 | -0.01041 |    0.07010 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25057 | -0.01001 |    0.19544 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08262 | -0.00343 |    0.06448 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07583 | -0.00942 |    0.06074 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07897 | -0.00507 |    0.06181 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07357 | -0.01132 |    0.05928 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06598 | -0.00499 |    0.05200 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05388 | -0.00301 |    0.04234 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14009 | -0.01355 |    0.11257 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05116 | -0.00333 |    0.04034 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04424 |  0.00085 |    0.03507 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04076 | -0.00196 |    0.03243 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03871 |  0.00109 |    0.03063 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35724 | -0.00239 |    0.26761 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:41:25,007 - Total sparsity: 0.00

2018-10-21 06:41:25,007 - --- validate (epoch=4)-----------
2018-10-21 06:41:25,007 - 10000 samples (128 per mini-batch)
2018-10-21 06:41:26,308 - Epoch: [4][   50/   78]    Loss 1.959434    Top1 49.875000    Top5 92.359375    
2018-10-21 06:41:26,988 - ==> Top1: 50.020    Top5: 92.550    Loss: 1.960

2018-10-21 06:41:26,989 - ==> Best Top1: 50.020   On Epoch: 4

2018-10-21 06:41:26,990 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:41:27,005 - 

2018-10-21 06:41:27,006 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:41:28,799 - Epoch: [5][   50/  391]    Overall Loss 1.878044    Objective Loss 1.878044    Top1 58.343750    Top5 91.031250    LR 0.300000    Time 0.035805    
2018-10-21 06:41:30,422 - Epoch: [5][  100/  391]    Overall Loss 1.883600    Objective Loss 1.883600    Top1 57.773438    Top5 90.937500    LR 0.300000    Time 0.034113    
2018-10-21 06:41:32,005 - Epoch: [5][  150/  391]    Overall Loss 1.882701    Objective Loss 1.882701    Top1 57.776042    Top5 91.312500    LR 0.300000    Time 0.033279    
2018-10-21 06:41:33,602 - Epoch: [5][  200/  391]    Overall Loss 1.881055    Objective Loss 1.881055    Top1 57.929688    Top5 91.265625    LR 0.300000    Time 0.032933    
2018-10-21 06:41:35,171 - Epoch: [5][  250/  391]    Overall Loss 1.883354    Objective Loss 1.883354    Top1 57.684375    Top5 91.365625    LR 0.300000    Time 0.032610    
2018-10-21 06:41:36,754 - Epoch: [5][  300/  391]    Overall Loss 1.882736    Objective Loss 1.882736    Top1 57.721354    Top5 91.567708    LR 0.300000    Time 0.032444    
2018-10-21 06:41:38,335 - Epoch: [5][  350/  391]    Overall Loss 1.882224    Objective Loss 1.882224    Top1 57.754464    Top5 91.745536    LR 0.300000    Time 0.032321    
2018-10-21 06:41:39,761 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38534 | -0.00421 |    0.28191 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12467 | -0.00822 |    0.09262 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12050 | -0.01370 |    0.09092 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11010 | -0.00466 |    0.08095 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10774 | -0.00734 |    0.08193 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10414 | -0.00332 |    0.07720 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10292 | -0.00820 |    0.08118 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10948 | -0.00304 |    0.08116 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09526 | -0.00983 |    0.07389 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25661 | -0.01234 |    0.19800 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08633 | -0.00409 |    0.06693 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07687 | -0.01002 |    0.06144 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08154 | -0.00633 |    0.06359 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07420 | -0.01067 |    0.05943 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07057 | -0.00603 |    0.05527 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05678 | -0.00353 |    0.04436 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14054 | -0.01344 |    0.11353 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05378 | -0.00447 |    0.04217 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04392 |  0.00066 |    0.03449 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03952 | -0.00219 |    0.03132 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03666 |  0.00097 |    0.02880 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37294 | -0.00212 |    0.27584 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:41:39,761 - Total sparsity: 0.00

2018-10-21 06:41:39,762 - --- validate (epoch=5)-----------
2018-10-21 06:41:39,762 - 10000 samples (128 per mini-batch)
2018-10-21 06:41:40,957 - Epoch: [5][   50/   78]    Loss 1.934548    Top1 52.281250    Top5 90.578125    
2018-10-21 06:41:41,590 - ==> Top1: 52.920    Top5: 90.730    Loss: 1.929

2018-10-21 06:41:41,591 - ==> Best Top1: 52.920   On Epoch: 5

2018-10-21 06:41:41,591 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:41:41,607 - 

2018-10-21 06:41:41,608 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:41:43,351 - Epoch: [6][   50/  391]    Overall Loss 1.856080    Objective Loss 1.856080    Top1 60.031250    Top5 93.750000    LR 0.300000    Time 0.034796    
2018-10-21 06:41:44,927 - Epoch: [6][  100/  391]    Overall Loss 1.864105    Objective Loss 1.864105    Top1 59.414062    Top5 93.625000    LR 0.300000    Time 0.033140    
2018-10-21 06:41:46,477 - Epoch: [6][  150/  391]    Overall Loss 1.864133    Objective Loss 1.864133    Top1 59.380208    Top5 93.911458    LR 0.300000    Time 0.032404    
2018-10-21 06:41:48,054 - Epoch: [6][  200/  391]    Overall Loss 1.864350    Objective Loss 1.864350    Top1 59.390625    Top5 94.339844    LR 0.300000    Time 0.032179    
2018-10-21 06:41:49,693 - Epoch: [6][  250/  391]    Overall Loss 1.864469    Objective Loss 1.864469    Top1 59.387500    Top5 94.528125    LR 0.300000    Time 0.032290    
2018-10-21 06:41:51,271 - Epoch: [6][  300/  391]    Overall Loss 1.862023    Objective Loss 1.862023    Top1 59.604167    Top5 94.557292    LR 0.300000    Time 0.032160    
2018-10-21 06:41:52,841 - Epoch: [6][  350/  391]    Overall Loss 1.860577    Objective Loss 1.860577    Top1 59.765625    Top5 94.580357    LR 0.300000    Time 0.032045    
2018-10-21 06:41:54,294 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38454 | -0.00251 |    0.28160 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12417 | -0.00809 |    0.09059 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12038 | -0.01283 |    0.09006 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10867 | -0.00199 |    0.07891 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10730 | -0.00900 |    0.08071 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10320 | -0.00446 |    0.07521 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10299 | -0.00714 |    0.08073 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11370 | -0.00341 |    0.08347 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09940 | -0.01087 |    0.07686 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26024 | -0.00508 |    0.19870 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08748 | -0.00478 |    0.06729 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07699 | -0.01063 |    0.06149 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08407 | -0.00757 |    0.06524 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07498 | -0.01088 |    0.05963 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07463 | -0.00658 |    0.05835 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05960 | -0.00452 |    0.04634 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14211 | -0.01262 |    0.11413 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05647 | -0.00451 |    0.04399 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04397 |  0.00050 |    0.03425 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03877 | -0.00245 |    0.03054 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03499 |  0.00121 |    0.02723 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37953 | -0.00189 |    0.28635 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:41:54,294 - Total sparsity: 0.00

2018-10-21 06:41:54,294 - --- validate (epoch=6)-----------
2018-10-21 06:41:54,294 - 10000 samples (128 per mini-batch)
2018-10-21 06:41:55,513 - Epoch: [6][   50/   78]    Loss 1.863446    Top1 59.656250    Top5 93.609375    
2018-10-21 06:41:56,156 - ==> Top1: 59.400    Top5: 93.360    Loss: 1.866

2018-10-21 06:41:56,157 - ==> Best Top1: 59.400   On Epoch: 6

2018-10-21 06:41:56,157 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:41:56,174 - 

2018-10-21 06:41:56,174 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:41:57,873 - Epoch: [7][   50/  391]    Overall Loss 1.826196    Objective Loss 1.826196    Top1 63.656250    Top5 95.046875    LR 0.300000    Time 0.033923    
2018-10-21 06:41:59,459 - Epoch: [7][  100/  391]    Overall Loss 1.819009    Objective Loss 1.819009    Top1 64.406250    Top5 95.437500    LR 0.300000    Time 0.032798    
2018-10-21 06:42:01,058 - Epoch: [7][  150/  391]    Overall Loss 1.818995    Objective Loss 1.818995    Top1 64.375000    Top5 95.526042    LR 0.300000    Time 0.032508    
2018-10-21 06:42:02,674 - Epoch: [7][  200/  391]    Overall Loss 1.818391    Objective Loss 1.818391    Top1 64.386719    Top5 95.488281    LR 0.300000    Time 0.032447    
2018-10-21 06:42:04,303 - Epoch: [7][  250/  391]    Overall Loss 1.818615    Objective Loss 1.818615    Top1 64.340625    Top5 95.465625    LR 0.300000    Time 0.032467    
2018-10-21 06:42:05,883 - Epoch: [7][  300/  391]    Overall Loss 1.818936    Objective Loss 1.818936    Top1 64.263021    Top5 95.528646    LR 0.300000    Time 0.032314    
2018-10-21 06:42:07,451 - Epoch: [7][  350/  391]    Overall Loss 1.818620    Objective Loss 1.818620    Top1 64.281250    Top5 95.506696    LR 0.300000    Time 0.032171    
2018-10-21 06:42:08,861 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39247 | -0.01076 |    0.28660 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12447 | -0.00955 |    0.08964 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12077 | -0.01362 |    0.08925 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11065 | -0.00423 |    0.07877 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10858 | -0.01073 |    0.07987 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10670 | -0.00447 |    0.07575 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10611 | -0.00652 |    0.08222 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11931 | -0.00579 |    0.08694 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10349 | -0.01107 |    0.07951 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26520 | -0.00379 |    0.20202 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08973 | -0.00537 |    0.06871 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07826 | -0.01115 |    0.06261 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08705 | -0.00712 |    0.06703 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07604 | -0.01227 |    0.06036 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07935 | -0.00673 |    0.06190 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06357 | -0.00544 |    0.04927 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14301 | -0.01321 |    0.11390 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05910 | -0.00510 |    0.04582 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04429 |  0.00074 |    0.03420 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03835 | -0.00239 |    0.03000 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03392 |  0.00118 |    0.02605 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40580 | -0.00168 |    0.30383 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:42:08,861 - Total sparsity: 0.00

2018-10-21 06:42:08,862 - --- validate (epoch=7)-----------
2018-10-21 06:42:08,862 - 10000 samples (128 per mini-batch)
2018-10-21 06:42:10,052 - Epoch: [7][   50/   78]    Loss 1.875601    Top1 57.937500    Top5 92.296875    
2018-10-21 06:42:10,709 - ==> Top1: 58.360    Top5: 92.290    Loss: 1.871

2018-10-21 06:42:10,710 - ==> Best Top1: 59.400   On Epoch: 6

2018-10-21 06:42:10,710 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:42:10,723 - 

2018-10-21 06:42:10,723 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:42:12,510 - Epoch: [8][   50/  391]    Overall Loss 1.805086    Objective Loss 1.805086    Top1 65.593750    Top5 95.953125    LR 0.300000    Time 0.035662    
2018-10-21 06:42:14,121 - Epoch: [8][  100/  391]    Overall Loss 1.808055    Objective Loss 1.808055    Top1 65.218750    Top5 95.984375    LR 0.300000    Time 0.033919    
2018-10-21 06:42:15,731 - Epoch: [8][  150/  391]    Overall Loss 1.807655    Objective Loss 1.807655    Top1 65.338542    Top5 96.078125    LR 0.300000    Time 0.033331    
2018-10-21 06:42:17,346 - Epoch: [8][  200/  391]    Overall Loss 1.807701    Objective Loss 1.807701    Top1 65.300781    Top5 96.035156    LR 0.300000    Time 0.033058    
2018-10-21 06:42:18,906 - Epoch: [8][  250/  391]    Overall Loss 1.807144    Objective Loss 1.807144    Top1 65.350000    Top5 95.975000    LR 0.300000    Time 0.032676    
2018-10-21 06:42:20,478 - Epoch: [8][  300/  391]    Overall Loss 1.804935    Objective Loss 1.804935    Top1 65.598958    Top5 95.966146    LR 0.300000    Time 0.032462    
2018-10-21 06:42:22,074 - Epoch: [8][  350/  391]    Overall Loss 1.803407    Objective Loss 1.803407    Top1 65.723214    Top5 95.937500    LR 0.300000    Time 0.032375    
2018-10-21 06:42:23,501 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40073 | -0.00811 |    0.29156 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12507 | -0.00802 |    0.08765 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12233 | -0.01248 |    0.08994 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11166 | -0.00333 |    0.07803 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10936 | -0.01027 |    0.07963 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10964 | -0.00542 |    0.07684 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10674 | -0.00851 |    0.08190 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12591 | -0.00437 |    0.09213 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10872 | -0.01199 |    0.08314 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27385 | -0.00533 |    0.20628 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09273 | -0.00538 |    0.07090 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08010 | -0.01126 |    0.06399 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09033 | -0.00750 |    0.06916 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07739 | -0.01349 |    0.06118 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08426 | -0.00600 |    0.06546 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06743 | -0.00658 |    0.05220 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14511 | -0.01319 |    0.11433 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06200 | -0.00580 |    0.04776 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04523 |  0.00070 |    0.03458 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03864 | -0.00235 |    0.02995 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03325 |  0.00157 |    0.02513 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41594 | -0.00149 |    0.30732 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:42:23,501 - Total sparsity: 0.00

2018-10-21 06:42:23,501 - --- validate (epoch=8)-----------
2018-10-21 06:42:23,501 - 10000 samples (128 per mini-batch)
2018-10-21 06:42:24,749 - Epoch: [8][   50/   78]    Loss 1.856372    Top1 60.375000    Top5 95.609375    
2018-10-21 06:42:25,431 - ==> Top1: 60.220    Top5: 95.500    Loss: 1.858

2018-10-21 06:42:25,433 - ==> Best Top1: 60.220   On Epoch: 8

2018-10-21 06:42:25,433 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:42:25,449 - 

2018-10-21 06:42:25,450 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:42:27,207 - Epoch: [9][   50/  391]    Overall Loss 1.780188    Objective Loss 1.780188    Top1 68.078125    Top5 96.609375    LR 0.300000    Time 0.035086    
2018-10-21 06:42:28,791 - Epoch: [9][  100/  391]    Overall Loss 1.781919    Objective Loss 1.781919    Top1 67.687500    Top5 96.507812    LR 0.300000    Time 0.033352    
2018-10-21 06:42:30,412 - Epoch: [9][  150/  391]    Overall Loss 1.782353    Objective Loss 1.782353    Top1 67.770833    Top5 96.453125    LR 0.300000    Time 0.033026    
2018-10-21 06:42:31,988 - Epoch: [9][  200/  391]    Overall Loss 1.783858    Objective Loss 1.783858    Top1 67.664062    Top5 96.316406    LR 0.300000    Time 0.032635    
2018-10-21 06:42:33,573 - Epoch: [9][  250/  391]    Overall Loss 1.782116    Objective Loss 1.782116    Top1 67.865625    Top5 96.306250    LR 0.300000    Time 0.032439    
2018-10-21 06:42:35,157 - Epoch: [9][  300/  391]    Overall Loss 1.780393    Objective Loss 1.780393    Top1 68.036458    Top5 96.341146    LR 0.300000    Time 0.032305    
2018-10-21 06:42:36,690 - Epoch: [9][  350/  391]    Overall Loss 1.781353    Objective Loss 1.781353    Top1 67.953125    Top5 96.361607    LR 0.300000    Time 0.032062    
2018-10-21 06:42:38,074 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39879 | -0.00076 |    0.29062 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12459 | -0.00739 |    0.08644 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12137 | -0.01087 |    0.08807 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11006 | -0.00122 |    0.07695 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10843 | -0.01135 |    0.07858 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11095 | -0.00260 |    0.07700 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10718 | -0.00873 |    0.08213 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12873 | -0.00127 |    0.09346 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11137 | -0.01233 |    0.08503 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27433 | -0.00339 |    0.20460 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09336 | -0.00436 |    0.07078 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08060 | -0.01095 |    0.06432 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09048 | -0.00709 |    0.06921 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07735 | -0.01277 |    0.06087 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08769 | -0.00703 |    0.06818 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07114 | -0.00665 |    0.05495 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14587 | -0.01170 |    0.11441 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06542 | -0.00621 |    0.05018 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04620 |  0.00054 |    0.03509 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03879 | -0.00308 |    0.02982 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03258 |  0.00176 |    0.02419 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42234 | -0.00133 |    0.31029 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:42:38,074 - Total sparsity: 0.00

2018-10-21 06:42:38,074 - --- validate (epoch=9)-----------
2018-10-21 06:42:38,074 - 10000 samples (128 per mini-batch)
2018-10-21 06:42:39,262 - Epoch: [9][   50/   78]    Loss 1.797680    Top1 66.406250    Top5 96.390625    
2018-10-21 06:42:39,900 - ==> Top1: 66.180    Top5: 96.610    Loss: 1.798

2018-10-21 06:42:39,902 - ==> Best Top1: 66.180   On Epoch: 9

2018-10-21 06:42:39,902 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:42:39,918 - 

2018-10-21 06:42:39,918 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:42:41,678 - Epoch: [10][   50/  391]    Overall Loss 1.772360    Objective Loss 1.772360    Top1 68.843750    Top5 96.484375    LR 0.300000    Time 0.035132    
2018-10-21 06:42:43,235 - Epoch: [10][  100/  391]    Overall Loss 1.770806    Objective Loss 1.770806    Top1 69.015625    Top5 96.710938    LR 0.300000    Time 0.033103    
2018-10-21 06:42:44,751 - Epoch: [10][  150/  391]    Overall Loss 1.768396    Objective Loss 1.768396    Top1 69.281250    Top5 96.572917    LR 0.300000    Time 0.032164    
2018-10-21 06:42:46,294 - Epoch: [10][  200/  391]    Overall Loss 1.765953    Objective Loss 1.765953    Top1 69.503906    Top5 96.679688    LR 0.300000    Time 0.031824    
2018-10-21 06:42:47,874 - Epoch: [10][  250/  391]    Overall Loss 1.765502    Objective Loss 1.765502    Top1 69.556250    Top5 96.675000    LR 0.300000    Time 0.031768    
2018-10-21 06:42:49,519 - Epoch: [10][  300/  391]    Overall Loss 1.764493    Objective Loss 1.764493    Top1 69.648438    Top5 96.710938    LR 0.300000    Time 0.031946    
2018-10-21 06:42:51,108 - Epoch: [10][  350/  391]    Overall Loss 1.763568    Objective Loss 1.763568    Top1 69.745536    Top5 96.707589    LR 0.300000    Time 0.031918    
2018-10-21 06:42:52,506 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39344 |  0.00072 |    0.28580 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12325 | -0.00913 |    0.08498 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12057 | -0.01103 |    0.08725 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10887 | -0.00201 |    0.07538 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10768 | -0.00880 |    0.07736 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11140 | -0.00433 |    0.07758 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10679 | -0.00625 |    0.08109 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13058 | -0.00263 |    0.09528 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11331 | -0.00993 |    0.08614 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27526 | -0.00559 |    0.20523 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09324 | -0.00423 |    0.07054 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08083 | -0.01068 |    0.06440 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09166 | -0.00661 |    0.06978 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07799 | -0.01155 |    0.06119 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09021 | -0.00713 |    0.07034 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07431 | -0.00739 |    0.05725 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14728 | -0.01226 |    0.11518 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06870 | -0.00652 |    0.05259 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04697 | -0.00013 |    0.03554 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03891 | -0.00306 |    0.02978 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03195 |  0.00175 |    0.02338 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42373 | -0.00118 |    0.30873 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:42:52,506 - Total sparsity: 0.00

2018-10-21 06:42:52,506 - --- validate (epoch=10)-----------
2018-10-21 06:42:52,507 - 10000 samples (128 per mini-batch)
2018-10-21 06:42:53,732 - Epoch: [10][   50/   78]    Loss 1.800118    Top1 66.078125    Top5 96.484375    
2018-10-21 06:42:54,392 - ==> Top1: 66.240    Top5: 96.500    Loss: 1.798

2018-10-21 06:42:54,393 - ==> Best Top1: 66.240   On Epoch: 10

2018-10-21 06:42:54,394 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:42:54,410 - 

2018-10-21 06:42:54,410 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:42:56,207 - Epoch: [11][   50/  391]    Overall Loss 1.756016    Objective Loss 1.756016    Top1 70.453125    Top5 96.875000    LR 0.300000    Time 0.035879    
2018-10-21 06:42:57,821 - Epoch: [11][  100/  391]    Overall Loss 1.755882    Objective Loss 1.755882    Top1 70.468750    Top5 96.835938    LR 0.300000    Time 0.034056    
2018-10-21 06:42:59,442 - Epoch: [11][  150/  391]    Overall Loss 1.759499    Objective Loss 1.759499    Top1 70.130208    Top5 96.869792    LR 0.300000    Time 0.033498    
2018-10-21 06:43:01,037 - Epoch: [11][  200/  391]    Overall Loss 1.760249    Objective Loss 1.760249    Top1 70.078125    Top5 96.808594    LR 0.300000    Time 0.033087    
2018-10-21 06:43:02,597 - Epoch: [11][  250/  391]    Overall Loss 1.760527    Objective Loss 1.760527    Top1 70.050000    Top5 96.756250    LR 0.300000    Time 0.032698    
2018-10-21 06:43:04,167 - Epoch: [11][  300/  391]    Overall Loss 1.759110    Objective Loss 1.759110    Top1 70.174479    Top5 96.763021    LR 0.300000    Time 0.032473    
2018-10-21 06:43:05,724 - Epoch: [11][  350/  391]    Overall Loss 1.758292    Objective Loss 1.758292    Top1 70.247768    Top5 96.738839    LR 0.300000    Time 0.032277    
2018-10-21 06:43:07,150 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39937 | -0.00402 |    0.28717 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12285 | -0.00854 |    0.08405 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12080 | -0.01051 |    0.08694 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10949 | -0.00231 |    0.07561 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10787 | -0.01326 |    0.07751 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11483 | -0.00589 |    0.07949 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10859 | -0.00975 |    0.08164 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13334 | -0.00206 |    0.09705 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11567 | -0.01164 |    0.08762 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27723 | -0.00923 |    0.20643 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09406 | -0.00529 |    0.07129 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08147 | -0.01246 |    0.06516 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09398 | -0.00663 |    0.07119 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07895 | -0.01158 |    0.06144 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09312 | -0.00686 |    0.07233 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07733 | -0.00807 |    0.05948 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14904 | -0.01088 |    0.11631 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07137 | -0.00721 |    0.05455 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04749 | -0.00098 |    0.03588 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03896 | -0.00320 |    0.02962 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03137 |  0.00185 |    0.02262 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42349 | -0.00105 |    0.30674 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:43:07,151 - Total sparsity: 0.00

2018-10-21 06:43:07,151 - --- validate (epoch=11)-----------
2018-10-21 06:43:07,151 - 10000 samples (128 per mini-batch)
2018-10-21 06:43:08,414 - Epoch: [11][   50/   78]    Loss 1.819720    Top1 63.750000    Top5 95.640625    
2018-10-21 06:43:09,048 - ==> Top1: 63.910    Top5: 95.750    Loss: 1.819

2018-10-21 06:43:09,049 - ==> Best Top1: 66.240   On Epoch: 10

2018-10-21 06:43:09,050 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:43:09,062 - 

2018-10-21 06:43:09,063 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:43:10,793 - Epoch: [12][   50/  391]    Overall Loss 1.747666    Objective Loss 1.747666    Top1 71.281250    Top5 97.000000    LR 0.300000    Time 0.034544    
2018-10-21 06:43:12,418 - Epoch: [12][  100/  391]    Overall Loss 1.745783    Objective Loss 1.745783    Top1 71.429688    Top5 97.101562    LR 0.300000    Time 0.033497    
2018-10-21 06:43:14,012 - Epoch: [12][  150/  391]    Overall Loss 1.748451    Objective Loss 1.748451    Top1 71.197917    Top5 97.052083    LR 0.300000    Time 0.032938    
2018-10-21 06:43:15,595 - Epoch: [12][  200/  391]    Overall Loss 1.750815    Objective Loss 1.750815    Top1 70.988281    Top5 96.968750    LR 0.300000    Time 0.032608    
2018-10-21 06:43:17,190 - Epoch: [12][  250/  391]    Overall Loss 1.751006    Objective Loss 1.751006    Top1 70.965625    Top5 96.990625    LR 0.300000    Time 0.032457    
2018-10-21 06:43:18,775 - Epoch: [12][  300/  391]    Overall Loss 1.751559    Objective Loss 1.751559    Top1 70.932292    Top5 96.981771    LR 0.300000    Time 0.032323    
2018-10-21 06:43:20,366 - Epoch: [12][  350/  391]    Overall Loss 1.750246    Objective Loss 1.750246    Top1 71.062500    Top5 97.026786    LR 0.300000    Time 0.032245    
2018-10-21 06:43:21,788 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40599 |  0.00842 |    0.29171 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12292 | -0.00594 |    0.08357 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12122 | -0.00801 |    0.08770 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10952 | -0.00030 |    0.07528 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10850 | -0.01205 |    0.07740 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11641 | -0.00827 |    0.07948 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10912 | -0.00682 |    0.08043 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13402 | -0.00237 |    0.09742 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11652 | -0.01183 |    0.08806 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27836 | -0.01217 |    0.20737 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09418 | -0.00611 |    0.07137 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08210 | -0.01204 |    0.06528 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09446 | -0.00625 |    0.07169 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07869 | -0.01205 |    0.06165 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09456 | -0.00692 |    0.07333 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07884 | -0.00833 |    0.06061 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14935 | -0.00974 |    0.11638 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07305 | -0.00675 |    0.05550 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04782 | -0.00064 |    0.03603 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03889 | -0.00287 |    0.02936 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03096 |  0.00179 |    0.02212 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42505 | -0.00093 |    0.30579 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:43:21,788 - Total sparsity: 0.00

2018-10-21 06:43:21,788 - --- validate (epoch=12)-----------
2018-10-21 06:43:21,788 - 10000 samples (128 per mini-batch)
2018-10-21 06:43:23,033 - Epoch: [12][   50/   78]    Loss 1.798387    Top1 65.984375    Top5 96.890625    
2018-10-21 06:43:23,692 - ==> Top1: 66.150    Top5: 96.910    Loss: 1.797

2018-10-21 06:43:23,693 - ==> Best Top1: 66.240   On Epoch: 10

2018-10-21 06:43:23,694 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:43:23,707 - 

2018-10-21 06:43:23,707 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:43:25,418 - Epoch: [13][   50/  391]    Overall Loss 1.745591    Objective Loss 1.745591    Top1 71.562500    Top5 97.390625    LR 0.300000    Time 0.034147    
2018-10-21 06:43:26,977 - Epoch: [13][  100/  391]    Overall Loss 1.743270    Objective Loss 1.743270    Top1 71.742188    Top5 97.421875    LR 0.300000    Time 0.032636    
2018-10-21 06:43:28,527 - Epoch: [13][  150/  391]    Overall Loss 1.741569    Objective Loss 1.741569    Top1 71.963542    Top5 97.270833    LR 0.300000    Time 0.032074    
2018-10-21 06:43:30,050 - Epoch: [13][  200/  391]    Overall Loss 1.742105    Objective Loss 1.742105    Top1 71.914062    Top5 97.167969    LR 0.300000    Time 0.031658    
2018-10-21 06:43:31,615 - Epoch: [13][  250/  391]    Overall Loss 1.740661    Objective Loss 1.740661    Top1 72.125000    Top5 97.178125    LR 0.300000    Time 0.031579    
2018-10-21 06:43:33,165 - Epoch: [13][  300/  391]    Overall Loss 1.739991    Objective Loss 1.739991    Top1 72.177083    Top5 97.166667    LR 0.300000    Time 0.031476    
2018-10-21 06:43:34,721 - Epoch: [13][  350/  391]    Overall Loss 1.738625    Objective Loss 1.738625    Top1 72.330357    Top5 97.122768    LR 0.300000    Time 0.031415    
2018-10-21 06:43:36,249 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39993 |  0.00759 |    0.28540 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12237 | -0.01080 |    0.08328 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12179 | -0.00745 |    0.08766 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10813 | -0.00226 |    0.07343 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10808 | -0.00983 |    0.07714 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11752 | -0.00560 |    0.07946 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10943 | -0.00786 |    0.08059 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13495 | -0.00348 |    0.09775 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11735 | -0.01073 |    0.08864 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27775 | -0.00980 |    0.20535 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09350 | -0.00571 |    0.07058 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08194 | -0.01129 |    0.06490 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09445 | -0.00714 |    0.07122 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07862 | -0.01148 |    0.06151 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09541 | -0.00756 |    0.07411 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08041 | -0.00821 |    0.06192 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15012 | -0.01030 |    0.11667 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07462 | -0.00776 |    0.05662 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04809 | -0.00042 |    0.03600 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03886 | -0.00279 |    0.02918 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03056 |  0.00213 |    0.02150 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42452 | -0.00083 |    0.30446 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:43:36,250 - Total sparsity: 0.00

2018-10-21 06:43:36,250 - --- validate (epoch=13)-----------
2018-10-21 06:43:36,250 - 10000 samples (128 per mini-batch)
2018-10-21 06:43:37,486 - Epoch: [13][   50/   78]    Loss 1.822997    Top1 63.531250    Top5 94.875000    
2018-10-21 06:43:38,133 - ==> Top1: 63.120    Top5: 94.910    Loss: 1.826

2018-10-21 06:43:38,135 - ==> Best Top1: 66.240   On Epoch: 10

2018-10-21 06:43:38,135 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:43:38,148 - 

2018-10-21 06:43:38,148 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:43:39,962 - Epoch: [14][   50/  391]    Overall Loss 1.728267    Objective Loss 1.728267    Top1 73.203125    Top5 97.531250    LR 0.300000    Time 0.036211    
2018-10-21 06:43:41,596 - Epoch: [14][  100/  391]    Overall Loss 1.735022    Objective Loss 1.735022    Top1 72.601562    Top5 97.343750    LR 0.300000    Time 0.034426    
2018-10-21 06:43:43,159 - Epoch: [14][  150/  391]    Overall Loss 1.739603    Objective Loss 1.739603    Top1 72.171875    Top5 97.197917    LR 0.300000    Time 0.033350    
2018-10-21 06:43:44,746 - Epoch: [14][  200/  391]    Overall Loss 1.736536    Objective Loss 1.736536    Top1 72.449219    Top5 97.238281    LR 0.300000    Time 0.032936    
2018-10-21 06:43:46,320 - Epoch: [14][  250/  391]    Overall Loss 1.736365    Objective Loss 1.736365    Top1 72.428125    Top5 97.193750    LR 0.300000    Time 0.032638    
2018-10-21 06:43:47,903 - Epoch: [14][  300/  391]    Overall Loss 1.737262    Objective Loss 1.737262    Top1 72.317708    Top5 97.171875    LR 0.300000    Time 0.032463    
2018-10-21 06:43:49,506 - Epoch: [14][  350/  391]    Overall Loss 1.735986    Objective Loss 1.735986    Top1 72.486607    Top5 97.203125    LR 0.300000    Time 0.032400    
2018-10-21 06:43:50,948 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39789 | -0.00186 |    0.28311 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12094 | -0.00899 |    0.08169 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12048 | -0.00915 |    0.08738 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10758 | -0.00398 |    0.07232 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10799 | -0.01043 |    0.07658 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11742 | -0.00405 |    0.07828 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10976 | -0.00910 |    0.08048 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13615 | -0.00318 |    0.09891 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11862 | -0.01072 |    0.08983 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27583 | -0.01151 |    0.20315 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09384 | -0.00613 |    0.07084 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08255 | -0.01071 |    0.06522 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09482 | -0.00604 |    0.07147 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07859 | -0.01124 |    0.06109 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09632 | -0.00781 |    0.07486 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08179 | -0.00786 |    0.06295 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14975 | -0.01059 |    0.11621 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07621 | -0.00753 |    0.05781 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04851 | -0.00054 |    0.03623 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03882 | -0.00319 |    0.02908 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03021 |  0.00188 |    0.02110 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42305 | -0.00074 |    0.30017 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:43:50,948 - Total sparsity: 0.00

2018-10-21 06:43:50,949 - --- validate (epoch=14)-----------
2018-10-21 06:43:50,949 - 10000 samples (128 per mini-batch)
2018-10-21 06:43:52,374 - Epoch: [14][   50/   78]    Loss 1.786774    Top1 67.328125    Top5 96.531250    
2018-10-21 06:43:53,135 - ==> Top1: 67.380    Top5: 96.530    Loss: 1.788

2018-10-21 06:43:53,136 - ==> Best Top1: 67.380   On Epoch: 14

2018-10-21 06:43:53,136 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:43:53,150 - 

2018-10-21 06:43:53,151 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:43:54,909 - Epoch: [15][   50/  391]    Overall Loss 1.732861    Objective Loss 1.732861    Top1 72.843750    Top5 97.250000    LR 0.300000    Time 0.035106    
2018-10-21 06:43:56,549 - Epoch: [15][  100/  391]    Overall Loss 1.735497    Objective Loss 1.735497    Top1 72.679688    Top5 97.226562    LR 0.300000    Time 0.033929    
2018-10-21 06:43:58,115 - Epoch: [15][  150/  391]    Overall Loss 1.734990    Objective Loss 1.734990    Top1 72.734375    Top5 97.338542    LR 0.300000    Time 0.033043    
2018-10-21 06:43:59,685 - Epoch: [15][  200/  391]    Overall Loss 1.733830    Objective Loss 1.733830    Top1 72.875000    Top5 97.363281    LR 0.300000    Time 0.032621    
2018-10-21 06:44:01,389 - Epoch: [15][  250/  391]    Overall Loss 1.732509    Objective Loss 1.732509    Top1 72.993750    Top5 97.340625    LR 0.300000    Time 0.032904    
2018-10-21 06:44:02,981 - Epoch: [15][  300/  391]    Overall Loss 1.732501    Objective Loss 1.732501    Top1 73.000000    Top5 97.343750    LR 0.300000    Time 0.032720    
2018-10-21 06:44:04,559 - Epoch: [15][  350/  391]    Overall Loss 1.732664    Objective Loss 1.732664    Top1 72.995536    Top5 97.299107    LR 0.300000    Time 0.032548    
2018-10-21 06:44:05,988 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40037 |  0.00754 |    0.28287 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12258 | -0.01061 |    0.08271 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12229 | -0.00987 |    0.08750 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10786 | -0.00384 |    0.07229 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10901 | -0.01060 |    0.07774 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11814 | -0.00519 |    0.07928 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11109 | -0.01005 |    0.08128 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13767 | -0.00303 |    0.09994 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11967 | -0.01037 |    0.09057 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27606 | -0.01174 |    0.20045 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09489 | -0.00703 |    0.07171 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08304 | -0.01161 |    0.06564 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09531 | -0.00675 |    0.07178 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07866 | -0.01167 |    0.06089 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09724 | -0.00768 |    0.07545 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08290 | -0.00818 |    0.06376 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14933 | -0.01228 |    0.11584 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07728 | -0.00758 |    0.05858 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04874 | -0.00058 |    0.03631 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03902 | -0.00285 |    0.02906 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02990 |  0.00188 |    0.02055 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42301 | -0.00066 |    0.29747 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:44:05,989 - Total sparsity: 0.00

2018-10-21 06:44:05,989 - --- validate (epoch=15)-----------
2018-10-21 06:44:05,989 - 10000 samples (128 per mini-batch)
2018-10-21 06:44:07,328 - Epoch: [15][   50/   78]    Loss 1.749917    Top1 70.937500    Top5 97.718750    
2018-10-21 06:44:08,021 - ==> Top1: 71.100    Top5: 97.760    Loss: 1.749

2018-10-21 06:44:08,022 - ==> Best Top1: 71.100   On Epoch: 15

2018-10-21 06:44:08,022 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:44:08,038 - 

2018-10-21 06:44:08,039 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:44:09,874 - Epoch: [16][   50/  391]    Overall Loss 1.724998    Objective Loss 1.724998    Top1 73.578125    Top5 97.281250    LR 0.300000    Time 0.036642    
2018-10-21 06:44:11,599 - Epoch: [16][  100/  391]    Overall Loss 1.727917    Objective Loss 1.727917    Top1 73.226562    Top5 97.437500    LR 0.300000    Time 0.035556    
2018-10-21 06:44:13,149 - Epoch: [16][  150/  391]    Overall Loss 1.725730    Objective Loss 1.725730    Top1 73.479167    Top5 97.510417    LR 0.300000    Time 0.034019    
2018-10-21 06:44:14,693 - Epoch: [16][  200/  391]    Overall Loss 1.725027    Objective Loss 1.725027    Top1 73.570312    Top5 97.468750    LR 0.300000    Time 0.033223    
2018-10-21 06:44:16,217 - Epoch: [16][  250/  391]    Overall Loss 1.724040    Objective Loss 1.724040    Top1 73.690625    Top5 97.478125    LR 0.300000    Time 0.032666    
2018-10-21 06:44:17,779 - Epoch: [16][  300/  391]    Overall Loss 1.725627    Objective Loss 1.725627    Top1 73.505208    Top5 97.492188    LR 0.300000    Time 0.032420    
2018-10-21 06:44:19,327 - Epoch: [16][  350/  391]    Overall Loss 1.726104    Objective Loss 1.726104    Top1 73.453125    Top5 97.441964    LR 0.300000    Time 0.032202    
2018-10-21 06:44:20,728 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40205 |  0.00893 |    0.28176 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12277 | -0.00727 |    0.08157 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12283 | -0.01159 |    0.08818 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10831 | -0.00173 |    0.07307 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10951 | -0.00901 |    0.07774 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12057 | -0.00586 |    0.08076 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11195 | -0.00763 |    0.08191 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13847 | -0.00200 |    0.10030 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11972 | -0.00996 |    0.09015 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27794 | -0.01388 |    0.20264 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09572 | -0.00641 |    0.07225 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08319 | -0.01168 |    0.06562 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09602 | -0.00712 |    0.07212 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07910 | -0.01153 |    0.06116 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09793 | -0.00818 |    0.07647 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08383 | -0.00787 |    0.06459 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15015 | -0.01458 |    0.11686 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07867 | -0.00721 |    0.05943 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04920 | -0.00031 |    0.03657 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03920 | -0.00328 |    0.02918 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02977 |  0.00208 |    0.02021 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42068 | -0.00058 |    0.29672 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:44:20,729 - Total sparsity: 0.00

2018-10-21 06:44:20,729 - --- validate (epoch=16)-----------
2018-10-21 06:44:20,729 - 10000 samples (128 per mini-batch)
2018-10-21 06:44:21,968 - Epoch: [16][   50/   78]    Loss 1.737951    Top1 72.281250    Top5 96.890625    
2018-10-21 06:44:22,625 - ==> Top1: 72.230    Top5: 96.940    Loss: 1.738

2018-10-21 06:44:22,626 - ==> Best Top1: 72.230   On Epoch: 16

2018-10-21 06:44:22,627 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:44:22,643 - 

2018-10-21 06:44:22,643 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:44:24,420 - Epoch: [17][   50/  391]    Overall Loss 1.722418    Objective Loss 1.722418    Top1 73.687500    Top5 97.046875    LR 0.300000    Time 0.035466    
2018-10-21 06:44:26,005 - Epoch: [17][  100/  391]    Overall Loss 1.718004    Objective Loss 1.718004    Top1 74.125000    Top5 97.421875    LR 0.300000    Time 0.033567    
2018-10-21 06:44:27,582 - Epoch: [17][  150/  391]    Overall Loss 1.719592    Objective Loss 1.719592    Top1 74.020833    Top5 97.354167    LR 0.300000    Time 0.032876    
2018-10-21 06:44:29,191 - Epoch: [17][  200/  391]    Overall Loss 1.719553    Objective Loss 1.719553    Top1 74.101562    Top5 97.386719    LR 0.300000    Time 0.032691    
2018-10-21 06:44:30,793 - Epoch: [17][  250/  391]    Overall Loss 1.719705    Objective Loss 1.719705    Top1 74.118750    Top5 97.450000    LR 0.300000    Time 0.032551    
2018-10-21 06:44:32,430 - Epoch: [17][  300/  391]    Overall Loss 1.720128    Objective Loss 1.720128    Top1 74.054688    Top5 97.468750    LR 0.300000    Time 0.032578    
2018-10-21 06:44:34,037 - Epoch: [17][  350/  391]    Overall Loss 1.721556    Objective Loss 1.721556    Top1 73.921875    Top5 97.466518    LR 0.300000    Time 0.032508    
2018-10-21 06:44:35,469 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40337 |  0.00800 |    0.27912 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12277 | -0.00867 |    0.08083 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12283 | -0.01164 |    0.08826 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10873 | -0.00254 |    0.07320 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10995 | -0.01212 |    0.07828 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12077 | -0.00416 |    0.08031 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11143 | -0.00931 |    0.08053 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13937 | -0.00114 |    0.10070 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11963 | -0.01016 |    0.08990 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28102 | -0.00692 |    0.20562 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09583 | -0.00683 |    0.07249 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08334 | -0.01220 |    0.06587 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09657 | -0.00891 |    0.07286 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07964 | -0.01087 |    0.06123 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09893 | -0.00809 |    0.07716 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08451 | -0.00812 |    0.06501 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15024 | -0.01198 |    0.11588 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07963 | -0.00827 |    0.06026 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04944 | -0.00030 |    0.03675 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03918 | -0.00306 |    0.02905 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02958 |  0.00192 |    0.01996 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42050 | -0.00052 |    0.29547 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:44:35,469 - Total sparsity: 0.00

2018-10-21 06:44:35,469 - --- validate (epoch=17)-----------
2018-10-21 06:44:35,469 - 10000 samples (128 per mini-batch)
2018-10-21 06:44:36,714 - Epoch: [17][   50/   78]    Loss 1.768431    Top1 68.984375    Top5 96.953125    
2018-10-21 06:44:37,366 - ==> Top1: 68.990    Top5: 97.050    Loss: 1.772

2018-10-21 06:44:37,368 - ==> Best Top1: 72.230   On Epoch: 16

2018-10-21 06:44:37,368 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:44:37,386 - 

2018-10-21 06:44:37,386 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:44:39,118 - Epoch: [18][   50/  391]    Overall Loss 1.728137    Objective Loss 1.728137    Top1 73.218750    Top5 97.671875    LR 0.300000    Time 0.034536    
2018-10-21 06:44:40,698 - Epoch: [18][  100/  391]    Overall Loss 1.724426    Objective Loss 1.724426    Top1 73.625000    Top5 97.765625    LR 0.300000    Time 0.033042    
2018-10-21 06:44:42,250 - Epoch: [18][  150/  391]    Overall Loss 1.722181    Objective Loss 1.722181    Top1 73.833333    Top5 97.666667    LR 0.300000    Time 0.032362    
2018-10-21 06:44:43,842 - Epoch: [18][  200/  391]    Overall Loss 1.723290    Objective Loss 1.723290    Top1 73.800781    Top5 97.511719    LR 0.300000    Time 0.032219    
2018-10-21 06:44:45,392 - Epoch: [18][  250/  391]    Overall Loss 1.721222    Objective Loss 1.721222    Top1 74.018750    Top5 97.550000    LR 0.300000    Time 0.031965    
2018-10-21 06:44:46,961 - Epoch: [18][  300/  391]    Overall Loss 1.719397    Objective Loss 1.719397    Top1 74.197917    Top5 97.557292    LR 0.300000    Time 0.031861    
2018-10-21 06:44:48,501 - Epoch: [18][  350/  391]    Overall Loss 1.718215    Objective Loss 1.718215    Top1 74.310268    Top5 97.582589    LR 0.300000    Time 0.031703    
2018-10-21 06:44:49,904 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40345 | -0.00522 |    0.27757 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12309 | -0.00930 |    0.08130 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12285 | -0.01058 |    0.08762 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10864 | -0.00062 |    0.07323 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10923 | -0.01158 |    0.07759 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12101 | -0.00591 |    0.08106 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11058 | -0.00962 |    0.08020 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13945 | -0.00331 |    0.10080 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11931 | -0.01065 |    0.08989 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28150 | -0.00988 |    0.20647 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09604 | -0.00592 |    0.07264 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08363 | -0.01238 |    0.06638 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09653 | -0.00766 |    0.07269 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07977 | -0.00966 |    0.06134 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09934 | -0.00831 |    0.07758 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08515 | -0.00818 |    0.06557 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14910 | -0.01372 |    0.11509 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08034 | -0.00846 |    0.06069 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04958 | -0.00050 |    0.03684 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03914 | -0.00347 |    0.02906 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02942 |  0.00173 |    0.01976 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42128 | -0.00046 |    0.29540 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:44:49,904 - Total sparsity: 0.00

2018-10-21 06:44:49,904 - --- validate (epoch=18)-----------
2018-10-21 06:44:49,905 - 10000 samples (128 per mini-batch)
2018-10-21 06:44:51,152 - Epoch: [18][   50/   78]    Loss 1.809774    Top1 64.734375    Top5 96.781250    
2018-10-21 06:44:51,938 - ==> Top1: 64.850    Top5: 96.740    Loss: 1.810

2018-10-21 06:44:51,940 - ==> Best Top1: 72.230   On Epoch: 16

2018-10-21 06:44:51,940 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:44:51,957 - 

2018-10-21 06:44:51,958 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:44:53,673 - Epoch: [19][   50/  391]    Overall Loss 1.714162    Objective Loss 1.714162    Top1 74.703125    Top5 97.921875    LR 0.300000    Time 0.034231    
2018-10-21 06:44:55,404 - Epoch: [19][  100/  391]    Overall Loss 1.722403    Objective Loss 1.722403    Top1 73.828125    Top5 97.570312    LR 0.300000    Time 0.034399    
2018-10-21 06:44:57,013 - Epoch: [19][  150/  391]    Overall Loss 1.722144    Objective Loss 1.722144    Top1 73.901042    Top5 97.604167    LR 0.300000    Time 0.033641    
2018-10-21 06:44:58,585 - Epoch: [19][  200/  391]    Overall Loss 1.718742    Objective Loss 1.718742    Top1 74.199219    Top5 97.679688    LR 0.300000    Time 0.033076    
2018-10-21 06:45:00,149 - Epoch: [19][  250/  391]    Overall Loss 1.717517    Objective Loss 1.717517    Top1 74.350000    Top5 97.693750    LR 0.300000    Time 0.032706    
2018-10-21 06:45:01,725 - Epoch: [19][  300/  391]    Overall Loss 1.718296    Objective Loss 1.718296    Top1 74.260417    Top5 97.679688    LR 0.300000    Time 0.032502    
2018-10-21 06:45:03,281 - Epoch: [19][  350/  391]    Overall Loss 1.718403    Objective Loss 1.718403    Top1 74.243304    Top5 97.631696    LR 0.300000    Time 0.032299    
2018-10-21 06:45:04,696 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40476 | -0.00230 |    0.28137 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12326 | -0.01171 |    0.08083 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12329 | -0.01056 |    0.08741 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10867 | -0.00122 |    0.07363 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10908 | -0.01166 |    0.07736 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12130 | -0.00847 |    0.08142 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11106 | -0.01196 |    0.08154 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14068 | -0.00305 |    0.10198 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12032 | -0.01044 |    0.09105 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28264 | -0.01710 |    0.20757 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09528 | -0.00570 |    0.07220 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08355 | -0.01184 |    0.06635 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09802 | -0.00824 |    0.07412 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07985 | -0.01049 |    0.06140 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10055 | -0.00865 |    0.07874 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08657 | -0.00816 |    0.06667 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14865 | -0.01396 |    0.11527 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08128 | -0.00850 |    0.06151 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04972 | -0.00117 |    0.03696 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03919 | -0.00348 |    0.02898 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02925 |  0.00176 |    0.01942 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41971 | -0.00041 |    0.29401 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:45:04,697 - Total sparsity: 0.00

2018-10-21 06:45:04,697 - --- validate (epoch=19)-----------
2018-10-21 06:45:04,697 - 10000 samples (128 per mini-batch)
2018-10-21 06:45:05,964 - Epoch: [19][   50/   78]    Loss 1.746340    Top1 71.343750    Top5 96.796875    
2018-10-21 06:45:06,621 - ==> Top1: 71.610    Top5: 96.870    Loss: 1.746

2018-10-21 06:45:06,622 - ==> Best Top1: 72.230   On Epoch: 16

2018-10-21 06:45:06,622 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:45:06,636 - 

2018-10-21 06:45:06,636 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:45:08,447 - Epoch: [20][   50/  391]    Overall Loss 1.719251    Objective Loss 1.719251    Top1 74.171875    Top5 97.234375    LR 0.300000    Time 0.036163    
2018-10-21 06:45:10,061 - Epoch: [20][  100/  391]    Overall Loss 1.718945    Objective Loss 1.718945    Top1 74.171875    Top5 97.273438    LR 0.300000    Time 0.034195    
2018-10-21 06:45:11,645 - Epoch: [20][  150/  391]    Overall Loss 1.719971    Objective Loss 1.719971    Top1 74.098958    Top5 97.369792    LR 0.300000    Time 0.033342    
2018-10-21 06:45:13,243 - Epoch: [20][  200/  391]    Overall Loss 1.718548    Objective Loss 1.718548    Top1 74.324219    Top5 97.425781    LR 0.300000    Time 0.032981    
2018-10-21 06:45:14,838 - Epoch: [20][  250/  391]    Overall Loss 1.717615    Objective Loss 1.717615    Top1 74.378125    Top5 97.465625    LR 0.300000    Time 0.032758    
2018-10-21 06:45:16,405 - Epoch: [20][  300/  391]    Overall Loss 1.717218    Objective Loss 1.717218    Top1 74.388021    Top5 97.549479    LR 0.300000    Time 0.032513    
2018-10-21 06:45:18,009 - Epoch: [20][  350/  391]    Overall Loss 1.715439    Objective Loss 1.715439    Top1 74.600446    Top5 97.595982    LR 0.300000    Time 0.032443    
2018-10-21 06:45:19,441 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40247 |  0.00070 |    0.27920 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12363 | -0.01381 |    0.08173 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12419 | -0.00858 |    0.08788 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10696 | -0.00044 |    0.07293 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10699 | -0.01004 |    0.07551 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12164 | -0.00768 |    0.08158 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11110 | -0.01135 |    0.08103 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14056 | -0.00652 |    0.10207 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12057 | -0.01122 |    0.09109 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28349 | -0.01160 |    0.20763 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09498 | -0.00559 |    0.07221 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08338 | -0.01111 |    0.06628 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09813 | -0.00856 |    0.07420 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08008 | -0.00977 |    0.06176 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10096 | -0.00788 |    0.07920 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08691 | -0.00849 |    0.06709 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14887 | -0.01302 |    0.11522 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08186 | -0.00857 |    0.06192 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05001 | -0.00073 |    0.03711 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03940 | -0.00356 |    0.02916 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02923 |  0.00199 |    0.01937 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41952 | -0.00037 |    0.29381 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:45:19,442 - Total sparsity: 0.00

2018-10-21 06:45:19,442 - --- validate (epoch=20)-----------
2018-10-21 06:45:19,442 - 10000 samples (128 per mini-batch)
2018-10-21 06:45:20,854 - Epoch: [20][   50/   78]    Loss 1.758401    Top1 70.171875    Top5 97.671875    
2018-10-21 06:45:21,611 - ==> Top1: 70.410    Top5: 97.680    Loss: 1.757

2018-10-21 06:45:21,613 - ==> Best Top1: 72.230   On Epoch: 16

2018-10-21 06:45:21,613 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:45:21,626 - 

2018-10-21 06:45:21,626 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:45:23,389 - Epoch: [21][   50/  391]    Overall Loss 1.700207    Objective Loss 1.700207    Top1 76.109375    Top5 97.781250    LR 0.300000    Time 0.035195    
2018-10-21 06:45:25,243 - Epoch: [21][  100/  391]    Overall Loss 1.702393    Objective Loss 1.702393    Top1 75.992188    Top5 97.750000    LR 0.300000    Time 0.036111    
2018-10-21 06:45:26,901 - Epoch: [21][  150/  391]    Overall Loss 1.703956    Objective Loss 1.703956    Top1 75.765625    Top5 97.776042    LR 0.300000    Time 0.035114    
2018-10-21 06:45:28,480 - Epoch: [21][  200/  391]    Overall Loss 1.706059    Objective Loss 1.706059    Top1 75.558594    Top5 97.742188    LR 0.300000    Time 0.034217    
2018-10-21 06:45:30,032 - Epoch: [21][  250/  391]    Overall Loss 1.707837    Objective Loss 1.707837    Top1 75.365625    Top5 97.750000    LR 0.300000    Time 0.033574    
2018-10-21 06:45:31,597 - Epoch: [21][  300/  391]    Overall Loss 1.708496    Objective Loss 1.708496    Top1 75.299479    Top5 97.757812    LR 0.300000    Time 0.033186    
2018-10-21 06:45:33,176 - Epoch: [21][  350/  391]    Overall Loss 1.709154    Objective Loss 1.709154    Top1 75.185268    Top5 97.747768    LR 0.300000    Time 0.032949    
2018-10-21 06:45:34,632 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40109 | -0.00312 |    0.27492 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12354 | -0.01210 |    0.08182 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12511 | -0.00746 |    0.08927 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10704 | -0.00226 |    0.07209 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10654 | -0.01313 |    0.07521 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12222 | -0.00417 |    0.08204 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11108 | -0.01326 |    0.08113 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14008 | -0.00739 |    0.10190 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12089 | -0.01072 |    0.09147 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28341 | -0.01677 |    0.20700 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09509 | -0.00421 |    0.07193 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08323 | -0.01193 |    0.06626 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09829 | -0.00887 |    0.07441 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08015 | -0.01047 |    0.06169 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10088 | -0.00800 |    0.07903 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08740 | -0.00811 |    0.06763 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14906 | -0.01452 |    0.11629 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08260 | -0.00836 |    0.06244 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05016 | -0.00093 |    0.03727 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03935 | -0.00379 |    0.02922 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02914 |  0.00223 |    0.01909 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41915 | -0.00033 |    0.29286 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:45:34,632 - Total sparsity: 0.00

2018-10-21 06:45:34,632 - --- validate (epoch=21)-----------
2018-10-21 06:45:34,632 - 10000 samples (128 per mini-batch)
2018-10-21 06:45:35,874 - Epoch: [21][   50/   78]    Loss 1.771021    Top1 68.703125    Top5 97.328125    
2018-10-21 06:45:36,562 - ==> Top1: 68.810    Top5: 97.490    Loss: 1.769

2018-10-21 06:45:36,564 - ==> Best Top1: 72.230   On Epoch: 16

2018-10-21 06:45:36,564 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:45:36,577 - 

2018-10-21 06:45:36,578 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:45:38,313 - Epoch: [22][   50/  391]    Overall Loss 1.712773    Objective Loss 1.712773    Top1 74.921875    Top5 97.484375    LR 0.300000    Time 0.034633    
2018-10-21 06:45:39,888 - Epoch: [22][  100/  391]    Overall Loss 1.708720    Objective Loss 1.708720    Top1 75.398438    Top5 97.546875    LR 0.300000    Time 0.033042    
2018-10-21 06:45:41,553 - Epoch: [22][  150/  391]    Overall Loss 1.708313    Objective Loss 1.708313    Top1 75.463542    Top5 97.630208    LR 0.300000    Time 0.033110    
2018-10-21 06:45:43,095 - Epoch: [22][  200/  391]    Overall Loss 1.709012    Objective Loss 1.709012    Top1 75.355469    Top5 97.640625    LR 0.300000    Time 0.032531    
2018-10-21 06:45:44,633 - Epoch: [22][  250/  391]    Overall Loss 1.707830    Objective Loss 1.707830    Top1 75.478125    Top5 97.684375    LR 0.300000    Time 0.032167    
2018-10-21 06:45:46,183 - Epoch: [22][  300/  391]    Overall Loss 1.707858    Objective Loss 1.707858    Top1 75.453125    Top5 97.664062    LR 0.300000    Time 0.031967    
2018-10-21 06:45:47,766 - Epoch: [22][  350/  391]    Overall Loss 1.707365    Objective Loss 1.707365    Top1 75.517857    Top5 97.638393    LR 0.300000    Time 0.031916    
2018-10-21 06:45:49,143 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40357 |  0.00459 |    0.27751 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12441 | -0.01057 |    0.08223 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12520 | -0.00872 |    0.08994 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10665 | -0.00294 |    0.07209 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10759 | -0.01139 |    0.07550 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12304 | -0.00492 |    0.08219 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11225 | -0.01260 |    0.08129 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14172 | -0.00637 |    0.10258 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12165 | -0.01000 |    0.09173 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28183 | -0.01253 |    0.20503 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09503 | -0.00326 |    0.07207 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08332 | -0.01246 |    0.06633 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09865 | -0.00890 |    0.07486 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08065 | -0.00933 |    0.06175 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10133 | -0.00792 |    0.07935 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08796 | -0.00811 |    0.06818 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14939 | -0.01471 |    0.11580 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08342 | -0.00852 |    0.06312 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05036 | -0.00097 |    0.03741 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03950 | -0.00367 |    0.02929 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02918 |  0.00213 |    0.01904 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42303 | -0.00029 |    0.29471 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:45:49,143 - Total sparsity: 0.00

2018-10-21 06:45:49,143 - --- validate (epoch=22)-----------
2018-10-21 06:45:49,144 - 10000 samples (128 per mini-batch)
2018-10-21 06:45:50,407 - Epoch: [22][   50/   78]    Loss 1.750526    Top1 70.984375    Top5 96.734375    
2018-10-21 06:45:51,045 - ==> Top1: 71.010    Top5: 96.770    Loss: 1.750

2018-10-21 06:45:51,046 - ==> Best Top1: 72.230   On Epoch: 16

2018-10-21 06:45:51,046 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:45:51,059 - 

2018-10-21 06:45:51,059 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:45:52,802 - Epoch: [23][   50/  391]    Overall Loss 1.706457    Objective Loss 1.706457    Top1 75.359375    Top5 97.828125    LR 0.300000    Time 0.034798    
2018-10-21 06:45:54,389 - Epoch: [23][  100/  391]    Overall Loss 1.712202    Objective Loss 1.712202    Top1 74.851562    Top5 97.546875    LR 0.300000    Time 0.033242    
2018-10-21 06:45:55,999 - Epoch: [23][  150/  391]    Overall Loss 1.711790    Objective Loss 1.711790    Top1 74.885417    Top5 97.656250    LR 0.300000    Time 0.032882    
2018-10-21 06:45:57,596 - Epoch: [23][  200/  391]    Overall Loss 1.710763    Objective Loss 1.710763    Top1 75.031250    Top5 97.683594    LR 0.300000    Time 0.032637    
2018-10-21 06:45:59,157 - Epoch: [23][  250/  391]    Overall Loss 1.709211    Objective Loss 1.709211    Top1 75.200000    Top5 97.737500    LR 0.300000    Time 0.032343    
2018-10-21 06:46:00,732 - Epoch: [23][  300/  391]    Overall Loss 1.708803    Objective Loss 1.708803    Top1 75.242188    Top5 97.750000    LR 0.300000    Time 0.032194    
2018-10-21 06:46:02,287 - Epoch: [23][  350/  391]    Overall Loss 1.709309    Objective Loss 1.709309    Top1 75.194196    Top5 97.770089    LR 0.300000    Time 0.032033    
2018-10-21 06:46:03,714 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40084 |  0.00223 |    0.27705 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12374 | -0.00901 |    0.08216 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12476 | -0.00811 |    0.08886 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10681 | -0.00086 |    0.07181 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10734 | -0.01474 |    0.07536 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12482 | -0.00197 |    0.08391 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11364 | -0.01248 |    0.08214 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14240 | -0.00514 |    0.10346 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12196 | -0.00903 |    0.09174 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28178 | -0.00679 |    0.20048 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09519 | -0.00372 |    0.07212 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08371 | -0.01147 |    0.06639 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09820 | -0.00877 |    0.07438 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08033 | -0.00986 |    0.06159 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10205 | -0.00868 |    0.07982 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08871 | -0.00876 |    0.06878 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14907 | -0.01624 |    0.11701 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08396 | -0.00887 |    0.06370 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05046 | -0.00070 |    0.03741 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03958 | -0.00354 |    0.02925 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02907 |  0.00272 |    0.01884 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41790 | -0.00026 |    0.29052 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:46:03,714 - Total sparsity: 0.00

2018-10-21 06:46:03,714 - --- validate (epoch=23)-----------
2018-10-21 06:46:03,714 - 10000 samples (128 per mini-batch)
2018-10-21 06:46:05,001 - Epoch: [23][   50/   78]    Loss 1.722537    Top1 73.921875    Top5 97.609375    
2018-10-21 06:46:05,684 - ==> Top1: 74.190    Top5: 97.590    Loss: 1.720

2018-10-21 06:46:05,686 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:46:05,686 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:46:05,702 - 

2018-10-21 06:46:05,702 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:46:07,459 - Epoch: [24][   50/  391]    Overall Loss 1.722224    Objective Loss 1.722224    Top1 73.921875    Top5 97.750000    LR 0.300000    Time 0.035074    
2018-10-21 06:46:09,034 - Epoch: [24][  100/  391]    Overall Loss 1.715338    Objective Loss 1.715338    Top1 74.570312    Top5 97.820312    LR 0.300000    Time 0.033273    
2018-10-21 06:46:10,639 - Epoch: [24][  150/  391]    Overall Loss 1.711567    Objective Loss 1.711567    Top1 74.958333    Top5 97.911458    LR 0.300000    Time 0.032868    
2018-10-21 06:46:12,209 - Epoch: [24][  200/  391]    Overall Loss 1.711127    Objective Loss 1.711127    Top1 74.988281    Top5 97.804688    LR 0.300000    Time 0.032488    
2018-10-21 06:46:13,785 - Epoch: [24][  250/  391]    Overall Loss 1.709174    Objective Loss 1.709174    Top1 75.181250    Top5 97.809375    LR 0.300000    Time 0.032285    
2018-10-21 06:46:15,338 - Epoch: [24][  300/  391]    Overall Loss 1.708331    Objective Loss 1.708331    Top1 75.286458    Top5 97.802083    LR 0.300000    Time 0.032074    
2018-10-21 06:46:16,939 - Epoch: [24][  350/  391]    Overall Loss 1.707640    Objective Loss 1.707640    Top1 75.352679    Top5 97.785714    LR 0.300000    Time 0.032059    
2018-10-21 06:46:18,393 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40423 | -0.00577 |    0.28019 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12410 | -0.00906 |    0.08231 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12429 | -0.00861 |    0.08758 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10574 | -0.00188 |    0.07108 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10738 | -0.01195 |    0.07528 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12437 | -0.00095 |    0.08296 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11383 | -0.01185 |    0.08184 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14275 | -0.00301 |    0.10366 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12154 | -0.00857 |    0.09151 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28298 | -0.00731 |    0.20216 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09438 | -0.00370 |    0.07121 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08333 | -0.01181 |    0.06618 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09837 | -0.00892 |    0.07397 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08052 | -0.00980 |    0.06152 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10220 | -0.00925 |    0.07999 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08896 | -0.00886 |    0.06900 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15020 | -0.01642 |    0.11703 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08448 | -0.00881 |    0.06410 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05059 | -0.00073 |    0.03754 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03981 | -0.00356 |    0.02942 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02920 |  0.00256 |    0.01897 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41833 | -0.00023 |    0.28972 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:46:18,393 - Total sparsity: 0.00

2018-10-21 06:46:18,393 - --- validate (epoch=24)-----------
2018-10-21 06:46:18,393 - 10000 samples (128 per mini-batch)
2018-10-21 06:46:19,601 - Epoch: [24][   50/   78]    Loss 1.788967    Top1 67.015625    Top5 97.218750    
2018-10-21 06:46:20,252 - ==> Top1: 66.900    Top5: 97.310    Loss: 1.789

2018-10-21 06:46:20,253 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:46:20,254 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:46:20,267 - 

2018-10-21 06:46:20,267 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:46:21,981 - Epoch: [25][   50/  391]    Overall Loss 1.697752    Objective Loss 1.697752    Top1 76.281250    Top5 97.875000    LR 0.300000    Time 0.034222    
2018-10-21 06:46:23,583 - Epoch: [25][  100/  391]    Overall Loss 1.699542    Objective Loss 1.699542    Top1 76.164062    Top5 97.882812    LR 0.300000    Time 0.033103    
2018-10-21 06:46:25,194 - Epoch: [25][  150/  391]    Overall Loss 1.704123    Objective Loss 1.704123    Top1 75.651042    Top5 97.708333    LR 0.300000    Time 0.032796    
2018-10-21 06:46:26,775 - Epoch: [25][  200/  391]    Overall Loss 1.703753    Objective Loss 1.703753    Top1 75.726562    Top5 97.761719    LR 0.300000    Time 0.032489    
2018-10-21 06:46:28,348 - Epoch: [25][  250/  391]    Overall Loss 1.702839    Objective Loss 1.702839    Top1 75.812500    Top5 97.771875    LR 0.300000    Time 0.032274    
2018-10-21 06:46:29,933 - Epoch: [25][  300/  391]    Overall Loss 1.703191    Objective Loss 1.703191    Top1 75.799479    Top5 97.789062    LR 0.300000    Time 0.032171    
2018-10-21 06:46:31,521 - Epoch: [25][  350/  391]    Overall Loss 1.701754    Objective Loss 1.701754    Top1 75.968750    Top5 97.823661    LR 0.300000    Time 0.032107    
2018-10-21 06:46:32,939 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40045 | -0.00794 |    0.27524 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12308 | -0.01104 |    0.08251 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12289 | -0.00704 |    0.08673 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10455 | -0.00237 |    0.07060 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10584 | -0.01187 |    0.07486 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12365 | -0.00056 |    0.08264 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11387 | -0.01220 |    0.08271 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14223 | -0.00348 |    0.10366 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12071 | -0.01040 |    0.09105 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28094 | -0.00499 |    0.19810 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09333 | -0.00352 |    0.07062 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08261 | -0.01143 |    0.06560 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09748 | -0.00865 |    0.07346 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08039 | -0.00848 |    0.06122 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10223 | -0.00919 |    0.08009 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08902 | -0.00870 |    0.06902 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14911 | -0.01648 |    0.11669 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08458 | -0.00875 |    0.06421 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05074 | -0.00103 |    0.03770 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03990 | -0.00405 |    0.02951 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02919 |  0.00259 |    0.01888 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41934 | -0.00021 |    0.28953 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:46:32,940 - Total sparsity: 0.00

2018-10-21 06:46:32,940 - --- validate (epoch=25)-----------
2018-10-21 06:46:32,940 - 10000 samples (128 per mini-batch)
2018-10-21 06:46:34,140 - Epoch: [25][   50/   78]    Loss 1.726711    Top1 73.421875    Top5 97.328125    
2018-10-21 06:46:34,773 - ==> Top1: 73.410    Top5: 97.530    Loss: 1.725

2018-10-21 06:46:34,774 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:46:34,774 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:46:34,787 - 

2018-10-21 06:46:34,787 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:46:36,523 - Epoch: [26][   50/  391]    Overall Loss 1.708362    Objective Loss 1.708362    Top1 75.125000    Top5 97.578125    LR 0.300000    Time 0.034661    
2018-10-21 06:46:38,095 - Epoch: [26][  100/  391]    Overall Loss 1.703331    Objective Loss 1.703331    Top1 75.843750    Top5 97.765625    LR 0.300000    Time 0.033029    
2018-10-21 06:46:39,673 - Epoch: [26][  150/  391]    Overall Loss 1.706508    Objective Loss 1.706508    Top1 75.500000    Top5 97.781250    LR 0.300000    Time 0.032524    
2018-10-21 06:46:41,257 - Epoch: [26][  200/  391]    Overall Loss 1.701786    Objective Loss 1.701786    Top1 75.992188    Top5 97.914062    LR 0.300000    Time 0.032302    
2018-10-21 06:46:42,820 - Epoch: [26][  250/  391]    Overall Loss 1.700594    Objective Loss 1.700594    Top1 76.081250    Top5 97.934375    LR 0.300000    Time 0.032085    
2018-10-21 06:46:44,392 - Epoch: [26][  300/  391]    Overall Loss 1.701956    Objective Loss 1.701956    Top1 75.934896    Top5 97.908854    LR 0.300000    Time 0.031971    
2018-10-21 06:46:45,944 - Epoch: [26][  350/  391]    Overall Loss 1.701267    Objective Loss 1.701267    Top1 76.033482    Top5 97.850446    LR 0.300000    Time 0.031830    
2018-10-21 06:46:47,364 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40214 | -0.00139 |    0.27705 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12362 | -0.01140 |    0.08202 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12488 | -0.00859 |    0.08822 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10495 | -0.00153 |    0.07030 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10551 | -0.01394 |    0.07446 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12520 | -0.00359 |    0.08387 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11487 | -0.01646 |    0.08291 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14198 | -0.00469 |    0.10283 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12097 | -0.00911 |    0.09093 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28154 | -0.01137 |    0.19826 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09345 | -0.00346 |    0.07110 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08275 | -0.01021 |    0.06521 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09791 | -0.00802 |    0.07387 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08081 | -0.00822 |    0.06142 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10282 | -0.01030 |    0.08093 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08981 | -0.00845 |    0.06961 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14912 | -0.01620 |    0.11681 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08534 | -0.00905 |    0.06472 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05116 | -0.00089 |    0.03786 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04012 | -0.00424 |    0.02976 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02915 |  0.00261 |    0.01882 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42018 | -0.00018 |    0.28939 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:46:47,364 - Total sparsity: 0.00

2018-10-21 06:46:47,364 - --- validate (epoch=26)-----------
2018-10-21 06:46:47,364 - 10000 samples (128 per mini-batch)
2018-10-21 06:46:48,562 - Epoch: [26][   50/   78]    Loss 1.723206    Top1 73.500000    Top5 97.953125    
2018-10-21 06:46:49,197 - ==> Top1: 73.440    Top5: 98.000    Loss: 1.724

2018-10-21 06:46:49,199 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:46:49,199 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:46:49,212 - 

2018-10-21 06:46:49,212 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:46:50,907 - Epoch: [27][   50/  391]    Overall Loss 1.707683    Objective Loss 1.707683    Top1 75.296875    Top5 97.531250    LR 0.300000    Time 0.033830    
2018-10-21 06:46:52,496 - Epoch: [27][  100/  391]    Overall Loss 1.704380    Objective Loss 1.704380    Top1 75.640625    Top5 97.703125    LR 0.300000    Time 0.032782    
2018-10-21 06:46:54,097 - Epoch: [27][  150/  391]    Overall Loss 1.702290    Objective Loss 1.702290    Top1 75.916667    Top5 97.739583    LR 0.300000    Time 0.032517    
2018-10-21 06:46:55,658 - Epoch: [27][  200/  391]    Overall Loss 1.704378    Objective Loss 1.704378    Top1 75.742188    Top5 97.765625    LR 0.300000    Time 0.032180    
2018-10-21 06:46:57,192 - Epoch: [27][  250/  391]    Overall Loss 1.703387    Objective Loss 1.703387    Top1 75.859375    Top5 97.768750    LR 0.300000    Time 0.031872    
2018-10-21 06:46:58,738 - Epoch: [27][  300/  391]    Overall Loss 1.701693    Objective Loss 1.701693    Top1 76.020833    Top5 97.781250    LR 0.300000    Time 0.031706    
2018-10-21 06:47:00,285 - Epoch: [27][  350/  391]    Overall Loss 1.702561    Objective Loss 1.702561    Top1 75.919643    Top5 97.796875    LR 0.300000    Time 0.031588    
2018-10-21 06:47:01,667 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40402 | -0.01064 |    0.27528 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12468 | -0.01236 |    0.08288 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12544 | -0.00965 |    0.08823 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10374 | -0.00148 |    0.07009 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10563 | -0.01300 |    0.07398 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12562 | -0.00504 |    0.08435 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11526 | -0.01376 |    0.08322 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14192 | -0.00592 |    0.10378 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12104 | -0.00778 |    0.09128 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28075 | -0.01074 |    0.19883 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09426 | -0.00410 |    0.07140 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08300 | -0.00983 |    0.06568 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09752 | -0.00808 |    0.07362 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08051 | -0.00808 |    0.06102 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10302 | -0.00963 |    0.08100 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09003 | -0.00860 |    0.07002 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14948 | -0.01458 |    0.11642 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08565 | -0.00907 |    0.06500 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05130 | -0.00066 |    0.03797 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04040 | -0.00438 |    0.02990 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02937 |  0.00267 |    0.01889 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42156 | -0.00016 |    0.28970 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:47:01,667 - Total sparsity: 0.00

2018-10-21 06:47:01,668 - --- validate (epoch=27)-----------
2018-10-21 06:47:01,668 - 10000 samples (128 per mini-batch)
2018-10-21 06:47:02,871 - Epoch: [27][   50/   78]    Loss 1.759719    Top1 69.875000    Top5 97.140625    
2018-10-21 06:47:03,516 - ==> Top1: 69.780    Top5: 97.230    Loss: 1.762

2018-10-21 06:47:03,517 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:47:03,518 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:47:03,530 - 

2018-10-21 06:47:03,530 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:47:05,245 - Epoch: [28][   50/  391]    Overall Loss 1.712667    Objective Loss 1.712667    Top1 74.921875    Top5 97.765625    LR 0.300000    Time 0.034223    
2018-10-21 06:47:06,821 - Epoch: [28][  100/  391]    Overall Loss 1.710909    Objective Loss 1.710909    Top1 75.085938    Top5 97.601562    LR 0.300000    Time 0.032845    
2018-10-21 06:47:08,398 - Epoch: [28][  150/  391]    Overall Loss 1.704430    Objective Loss 1.704430    Top1 75.739583    Top5 97.666667    LR 0.300000    Time 0.032392    
2018-10-21 06:47:09,988 - Epoch: [28][  200/  391]    Overall Loss 1.699463    Objective Loss 1.699463    Top1 76.250000    Top5 97.746094    LR 0.300000    Time 0.032231    
2018-10-21 06:47:11,594 - Epoch: [28][  250/  391]    Overall Loss 1.700501    Objective Loss 1.700501    Top1 76.143750    Top5 97.806250    LR 0.300000    Time 0.032201    
2018-10-21 06:47:13,152 - Epoch: [28][  300/  391]    Overall Loss 1.697375    Objective Loss 1.697375    Top1 76.479167    Top5 97.872396    LR 0.300000    Time 0.032021    
2018-10-21 06:47:14,714 - Epoch: [28][  350/  391]    Overall Loss 1.698588    Objective Loss 1.698588    Top1 76.343750    Top5 97.924107    LR 0.300000    Time 0.031904    
2018-10-21 06:47:16,122 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41254 | -0.00978 |    0.27988 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12581 | -0.00823 |    0.08248 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12448 | -0.00903 |    0.08640 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10288 | -0.00147 |    0.06895 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10570 | -0.01095 |    0.07348 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12671 | -0.00399 |    0.08452 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11529 | -0.01346 |    0.08272 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14233 | -0.00209 |    0.10396 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12118 | -0.00858 |    0.09101 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28169 | -0.00917 |    0.19764 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09394 | -0.00451 |    0.07143 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08285 | -0.00911 |    0.06544 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09793 | -0.00905 |    0.07395 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08097 | -0.00752 |    0.06128 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10342 | -0.00946 |    0.08095 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09067 | -0.00831 |    0.07036 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14907 | -0.01365 |    0.11541 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08627 | -0.00973 |    0.06569 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05153 | -0.00102 |    0.03820 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04051 | -0.00485 |    0.03024 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02929 |  0.00267 |    0.01882 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42144 | -0.00015 |    0.28970 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:47:16,122 - Total sparsity: 0.00

2018-10-21 06:47:16,122 - --- validate (epoch=28)-----------
2018-10-21 06:47:16,123 - 10000 samples (128 per mini-batch)
2018-10-21 06:47:17,327 - Epoch: [28][   50/   78]    Loss 1.775967    Top1 68.546875    Top5 96.218750    
2018-10-21 06:47:17,976 - ==> Top1: 68.160    Top5: 96.300    Loss: 1.779

2018-10-21 06:47:17,978 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:47:17,978 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:47:17,991 - 

2018-10-21 06:47:17,991 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:47:19,713 - Epoch: [29][   50/  391]    Overall Loss 1.705347    Objective Loss 1.705347    Top1 75.453125    Top5 97.859375    LR 0.300000    Time 0.034389    
2018-10-21 06:47:21,273 - Epoch: [29][  100/  391]    Overall Loss 1.700281    Objective Loss 1.700281    Top1 76.085938    Top5 97.875000    LR 0.300000    Time 0.032765    
2018-10-21 06:47:22,840 - Epoch: [29][  150/  391]    Overall Loss 1.697822    Objective Loss 1.697822    Top1 76.359375    Top5 97.953125    LR 0.300000    Time 0.032274    
2018-10-21 06:47:24,383 - Epoch: [29][  200/  391]    Overall Loss 1.700766    Objective Loss 1.700766    Top1 75.984375    Top5 97.886719    LR 0.300000    Time 0.031914    
2018-10-21 06:47:25,946 - Epoch: [29][  250/  391]    Overall Loss 1.699633    Objective Loss 1.699633    Top1 76.118750    Top5 97.890625    LR 0.300000    Time 0.031773    
2018-10-21 06:47:27,488 - Epoch: [29][  300/  391]    Overall Loss 1.701629    Objective Loss 1.701629    Top1 75.864583    Top5 97.854167    LR 0.300000    Time 0.031610    
2018-10-21 06:47:29,057 - Epoch: [29][  350/  391]    Overall Loss 1.701662    Objective Loss 1.701662    Top1 75.886161    Top5 97.828125    LR 0.300000    Time 0.031572    
2018-10-21 06:47:30,488 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41586 | -0.02092 |    0.28553 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12630 | -0.00790 |    0.08235 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12556 | -0.00739 |    0.08812 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10356 | -0.00166 |    0.06976 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10681 | -0.01222 |    0.07440 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12647 | -0.00221 |    0.08384 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11602 | -0.01251 |    0.08380 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14251 | -0.00376 |    0.10432 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12150 | -0.00951 |    0.09168 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28210 | -0.01383 |    0.19695 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09401 | -0.00536 |    0.07146 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08291 | -0.01062 |    0.06581 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09820 | -0.00958 |    0.07400 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08109 | -0.00764 |    0.06138 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10308 | -0.00894 |    0.08071 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09055 | -0.00826 |    0.07035 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14887 | -0.01552 |    0.11493 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08657 | -0.00961 |    0.06604 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05187 | -0.00066 |    0.03845 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04097 | -0.00467 |    0.03036 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02959 |  0.00253 |    0.01886 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41992 | -0.00013 |    0.28687 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:47:30,488 - Total sparsity: 0.00

2018-10-21 06:47:30,488 - --- validate (epoch=29)-----------
2018-10-21 06:47:30,488 - 10000 samples (128 per mini-batch)
2018-10-21 06:47:31,708 - Epoch: [29][   50/   78]    Loss 1.741223    Top1 71.812500    Top5 96.906250    
2018-10-21 06:47:32,354 - ==> Top1: 71.930    Top5: 96.980    Loss: 1.740

2018-10-21 06:47:32,355 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:47:32,355 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:47:32,368 - 

2018-10-21 06:47:32,368 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:47:34,141 - Epoch: [30][   50/  391]    Overall Loss 1.699988    Objective Loss 1.699988    Top1 76.140625    Top5 97.781250    LR 0.300000    Time 0.035411    
2018-10-21 06:47:35,783 - Epoch: [30][  100/  391]    Overall Loss 1.701091    Objective Loss 1.701091    Top1 76.015625    Top5 97.843750    LR 0.300000    Time 0.034101    
2018-10-21 06:47:37,383 - Epoch: [30][  150/  391]    Overall Loss 1.701018    Objective Loss 1.701018    Top1 76.041667    Top5 97.911458    LR 0.300000    Time 0.033387    
2018-10-21 06:47:39,061 - Epoch: [30][  200/  391]    Overall Loss 1.702029    Objective Loss 1.702029    Top1 75.933594    Top5 97.902344    LR 0.300000    Time 0.033418    
2018-10-21 06:47:40,638 - Epoch: [30][  250/  391]    Overall Loss 1.703229    Objective Loss 1.703229    Top1 75.831250    Top5 97.881250    LR 0.300000    Time 0.033034    
2018-10-21 06:47:42,225 - Epoch: [30][  300/  391]    Overall Loss 1.703008    Objective Loss 1.703008    Top1 75.843750    Top5 97.929688    LR 0.300000    Time 0.032810    
2018-10-21 06:47:43,792 - Epoch: [30][  350/  391]    Overall Loss 1.701461    Objective Loss 1.701461    Top1 76.015625    Top5 97.953125    LR 0.300000    Time 0.032595    
2018-10-21 06:47:45,205 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41061 | -0.00027 |    0.28042 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12420 | -0.00682 |    0.08139 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12377 | -0.00839 |    0.08677 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10470 | -0.00048 |    0.07107 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10734 | -0.00943 |    0.07455 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12680 | -0.00126 |    0.08485 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11641 | -0.01435 |    0.08442 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14333 | -0.00412 |    0.10422 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12220 | -0.01014 |    0.09208 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28396 | -0.00986 |    0.19808 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09420 | -0.00496 |    0.07179 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08299 | -0.01088 |    0.06595 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09828 | -0.00947 |    0.07428 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08075 | -0.00781 |    0.06088 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10355 | -0.00894 |    0.08116 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09081 | -0.00820 |    0.07055 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14867 | -0.01456 |    0.11441 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08718 | -0.00978 |    0.06651 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05212 | -0.00112 |    0.03869 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04124 | -0.00451 |    0.03040 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02974 |  0.00242 |    0.01889 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41981 | -0.00012 |    0.28768 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:47:45,205 - Total sparsity: 0.00

2018-10-21 06:47:45,206 - --- validate (epoch=30)-----------
2018-10-21 06:47:45,206 - 10000 samples (128 per mini-batch)
2018-10-21 06:47:46,475 - Epoch: [30][   50/   78]    Loss 1.742446    Top1 71.890625    Top5 96.734375    
2018-10-21 06:47:47,122 - ==> Top1: 71.880    Top5: 96.900    Loss: 1.742

2018-10-21 06:47:47,123 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:47:47,123 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:47:47,136 - 

2018-10-21 06:47:47,136 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:47:48,860 - Epoch: [31][   50/  391]    Overall Loss 1.686792    Objective Loss 1.686792    Top1 77.187500    Top5 98.109375    LR 0.300000    Time 0.034405    
2018-10-21 06:47:50,437 - Epoch: [31][  100/  391]    Overall Loss 1.697167    Objective Loss 1.697167    Top1 76.210938    Top5 98.015625    LR 0.300000    Time 0.032953    
2018-10-21 06:47:52,029 - Epoch: [31][  150/  391]    Overall Loss 1.698156    Objective Loss 1.698156    Top1 76.239583    Top5 98.062500    LR 0.300000    Time 0.032569    
2018-10-21 06:47:53,597 - Epoch: [31][  200/  391]    Overall Loss 1.696206    Objective Loss 1.696206    Top1 76.554688    Top5 98.007812    LR 0.300000    Time 0.032253    
2018-10-21 06:47:55,155 - Epoch: [31][  250/  391]    Overall Loss 1.695193    Objective Loss 1.695193    Top1 76.681250    Top5 98.034375    LR 0.300000    Time 0.032026    
2018-10-21 06:47:56,696 - Epoch: [31][  300/  391]    Overall Loss 1.695314    Objective Loss 1.695314    Top1 76.666667    Top5 97.992188    LR 0.300000    Time 0.031818    
2018-10-21 06:47:58,231 - Epoch: [31][  350/  391]    Overall Loss 1.693338    Objective Loss 1.693338    Top1 76.841518    Top5 98.044643    LR 0.300000    Time 0.031652    
2018-10-21 06:47:59,634 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40677 | -0.01202 |    0.27673 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12456 | -0.00463 |    0.08063 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12348 | -0.01306 |    0.08703 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10516 |  0.00053 |    0.07094 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10712 | -0.01115 |    0.07428 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12714 | -0.00060 |    0.08501 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11593 | -0.01454 |    0.08418 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14276 | -0.00487 |    0.10466 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12182 | -0.00939 |    0.09210 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28498 | -0.00766 |    0.19812 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09425 | -0.00517 |    0.07197 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08296 | -0.01104 |    0.06568 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09778 | -0.01005 |    0.07425 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08039 | -0.00740 |    0.06066 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10375 | -0.00958 |    0.08140 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09104 | -0.00869 |    0.07077 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14768 | -0.01426 |    0.11412 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08725 | -0.00917 |    0.06645 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05225 | -0.00107 |    0.03881 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04139 | -0.00478 |    0.03063 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02983 |  0.00224 |    0.01913 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42233 | -0.00010 |    0.28919 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:47:59,634 - Total sparsity: 0.00

2018-10-21 06:47:59,634 - --- validate (epoch=31)-----------
2018-10-21 06:47:59,634 - 10000 samples (128 per mini-batch)
2018-10-21 06:48:00,871 - Epoch: [31][   50/   78]    Loss 1.767587    Top1 69.234375    Top5 96.062500    
2018-10-21 06:48:01,505 - ==> Top1: 69.740    Top5: 96.200    Loss: 1.763

2018-10-21 06:48:01,506 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:48:01,507 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:48:01,519 - 

2018-10-21 06:48:01,520 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:48:03,221 - Epoch: [32][   50/  391]    Overall Loss 1.695433    Objective Loss 1.695433    Top1 76.437500    Top5 97.687500    LR 0.300000    Time 0.033974    
2018-10-21 06:48:04,780 - Epoch: [32][  100/  391]    Overall Loss 1.698656    Objective Loss 1.698656    Top1 76.164062    Top5 97.882812    LR 0.300000    Time 0.032546    
2018-10-21 06:48:06,359 - Epoch: [32][  150/  391]    Overall Loss 1.697272    Objective Loss 1.697272    Top1 76.375000    Top5 97.916667    LR 0.300000    Time 0.032215    
2018-10-21 06:48:07,929 - Epoch: [32][  200/  391]    Overall Loss 1.694547    Objective Loss 1.694547    Top1 76.648438    Top5 97.996094    LR 0.300000    Time 0.032000    
2018-10-21 06:48:09,487 - Epoch: [32][  250/  391]    Overall Loss 1.692481    Objective Loss 1.692481    Top1 76.881250    Top5 97.978125    LR 0.300000    Time 0.031822    
2018-10-21 06:48:11,033 - Epoch: [32][  300/  391]    Overall Loss 1.692173    Objective Loss 1.692173    Top1 76.919271    Top5 97.963542    LR 0.300000    Time 0.031665    
2018-10-21 06:48:12,569 - Epoch: [32][  350/  391]    Overall Loss 1.693916    Objective Loss 1.693916    Top1 76.741071    Top5 97.977679    LR 0.300000    Time 0.031522    
2018-10-21 06:48:14,006 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40402 | -0.01230 |    0.27642 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12401 | -0.00469 |    0.08013 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12374 | -0.01028 |    0.08662 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10495 |  0.00017 |    0.07075 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10717 | -0.01279 |    0.07526 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12670 | -0.00020 |    0.08424 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11572 | -0.01330 |    0.08407 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14351 | -0.00389 |    0.10490 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12217 | -0.00924 |    0.09209 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28507 | -0.00820 |    0.19641 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09397 | -0.00508 |    0.07173 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08302 | -0.01190 |    0.06568 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09766 | -0.00967 |    0.07426 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08036 | -0.00781 |    0.06049 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10378 | -0.00871 |    0.08107 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09103 | -0.00835 |    0.07082 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14831 | -0.01312 |    0.11501 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08717 | -0.00944 |    0.06670 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05222 | -0.00110 |    0.03880 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04148 | -0.00435 |    0.03059 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02974 |  0.00239 |    0.01908 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42024 | -0.00009 |    0.28853 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:48:14,007 - Total sparsity: 0.00

2018-10-21 06:48:14,007 - --- validate (epoch=32)-----------
2018-10-21 06:48:14,007 - 10000 samples (128 per mini-batch)
2018-10-21 06:48:15,269 - Epoch: [32][   50/   78]    Loss 1.720563    Top1 73.937500    Top5 97.656250    
2018-10-21 06:48:15,942 - ==> Top1: 74.090    Top5: 97.700    Loss: 1.717

2018-10-21 06:48:15,943 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:48:15,943 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:48:15,956 - 

2018-10-21 06:48:15,956 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:48:17,714 - Epoch: [33][   50/  391]    Overall Loss 1.689517    Objective Loss 1.689517    Top1 77.156250    Top5 98.046875    LR 0.300000    Time 0.035095    
2018-10-21 06:48:19,328 - Epoch: [33][  100/  391]    Overall Loss 1.692428    Objective Loss 1.692428    Top1 76.867188    Top5 98.015625    LR 0.300000    Time 0.033665    
2018-10-21 06:48:20,901 - Epoch: [33][  150/  391]    Overall Loss 1.692514    Objective Loss 1.692514    Top1 76.848958    Top5 97.994792    LR 0.300000    Time 0.032915    
2018-10-21 06:48:22,484 - Epoch: [33][  200/  391]    Overall Loss 1.694034    Objective Loss 1.694034    Top1 76.710938    Top5 97.980469    LR 0.300000    Time 0.032588    
2018-10-21 06:48:24,052 - Epoch: [33][  250/  391]    Overall Loss 1.693000    Objective Loss 1.693000    Top1 76.853125    Top5 98.062500    LR 0.300000    Time 0.032333    
2018-10-21 06:48:25,630 - Epoch: [33][  300/  391]    Overall Loss 1.693371    Objective Loss 1.693371    Top1 76.820312    Top5 98.106771    LR 0.300000    Time 0.032196    
2018-10-21 06:48:27,201 - Epoch: [33][  350/  391]    Overall Loss 1.692915    Objective Loss 1.692915    Top1 76.879464    Top5 98.055804    LR 0.300000    Time 0.032080    
2018-10-21 06:48:28,588 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40095 | -0.01486 |    0.27378 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12341 | -0.00597 |    0.07999 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12339 | -0.00916 |    0.08628 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10533 | -0.00159 |    0.07099 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10720 | -0.01371 |    0.07576 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12657 | -0.00274 |    0.08444 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11613 | -0.01443 |    0.08392 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14352 | -0.00417 |    0.10519 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12195 | -0.00949 |    0.09226 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28357 | -0.00897 |    0.19643 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09408 | -0.00517 |    0.07177 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08341 | -0.01082 |    0.06568 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09771 | -0.00952 |    0.07433 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08051 | -0.00723 |    0.06062 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10377 | -0.00794 |    0.08101 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09101 | -0.00860 |    0.07083 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14766 | -0.01374 |    0.11466 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08723 | -0.00923 |    0.06668 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05217 | -0.00113 |    0.03880 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04140 | -0.00477 |    0.03065 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02971 |  0.00256 |    0.01898 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42009 | -0.00008 |    0.28780 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:48:28,588 - Total sparsity: 0.00

2018-10-21 06:48:28,588 - --- validate (epoch=33)-----------
2018-10-21 06:48:28,588 - 10000 samples (128 per mini-batch)
2018-10-21 06:48:29,778 - Epoch: [33][   50/   78]    Loss 1.736651    Top1 72.281250    Top5 96.421875    
2018-10-21 06:48:30,410 - ==> Top1: 72.180    Top5: 96.600    Loss: 1.740

2018-10-21 06:48:30,411 - ==> Best Top1: 74.190   On Epoch: 23

2018-10-21 06:48:30,411 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:48:30,424 - 

2018-10-21 06:48:30,424 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:48:32,194 - Epoch: [34][   50/  391]    Overall Loss 1.690799    Objective Loss 1.690799    Top1 76.937500    Top5 97.875000    LR 0.300000    Time 0.035350    
2018-10-21 06:48:33,835 - Epoch: [34][  100/  391]    Overall Loss 1.685682    Objective Loss 1.685682    Top1 77.523438    Top5 97.992188    LR 0.300000    Time 0.034054    
2018-10-21 06:48:35,445 - Epoch: [34][  150/  391]    Overall Loss 1.686206    Objective Loss 1.686206    Top1 77.598958    Top5 98.041667    LR 0.300000    Time 0.033423    
2018-10-21 06:48:37,038 - Epoch: [34][  200/  391]    Overall Loss 1.687181    Objective Loss 1.687181    Top1 77.546875    Top5 98.007812    LR 0.300000    Time 0.033024    
2018-10-21 06:48:38,634 - Epoch: [34][  250/  391]    Overall Loss 1.689399    Objective Loss 1.689399    Top1 77.346875    Top5 97.971875    LR 0.300000    Time 0.032792    
2018-10-21 06:48:40,243 - Epoch: [34][  300/  391]    Overall Loss 1.689948    Objective Loss 1.689948    Top1 77.278646    Top5 97.994792    LR 0.300000    Time 0.032683    
2018-10-21 06:48:41,858 - Epoch: [34][  350/  391]    Overall Loss 1.691430    Objective Loss 1.691430    Top1 77.102679    Top5 98.000000    LR 0.300000    Time 0.032622    
2018-10-21 06:48:43,291 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40511 | -0.01732 |    0.27862 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12447 | -0.00217 |    0.07982 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12523 | -0.00989 |    0.08745 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10644 | -0.00167 |    0.07179 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10834 | -0.00869 |    0.07629 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12892 | -0.00367 |    0.08642 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11780 | -0.01384 |    0.08536 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14445 | -0.00403 |    0.10592 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12272 | -0.00781 |    0.09314 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28493 | -0.01385 |    0.19708 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09548 | -0.00462 |    0.07291 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08436 | -0.01136 |    0.06670 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09885 | -0.00987 |    0.07533 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08157 | -0.00656 |    0.06126 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10443 | -0.00886 |    0.08183 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09183 | -0.00819 |    0.07155 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14842 | -0.01209 |    0.11358 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08797 | -0.00962 |    0.06709 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05247 | -0.00128 |    0.03909 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04158 | -0.00465 |    0.03079 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02977 |  0.00220 |    0.01901 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42325 | -0.00007 |    0.28908 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:48:43,292 - Total sparsity: 0.00

2018-10-21 06:48:43,292 - --- validate (epoch=34)-----------
2018-10-21 06:48:43,292 - 10000 samples (128 per mini-batch)
2018-10-21 06:48:44,558 - Epoch: [34][   50/   78]    Loss 1.713233    Top1 74.859375    Top5 97.046875    
2018-10-21 06:48:45,209 - ==> Top1: 74.640    Top5: 97.330    Loss: 1.714

2018-10-21 06:48:45,210 - ==> Best Top1: 74.640   On Epoch: 34

2018-10-21 06:48:45,210 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:48:45,227 - 

2018-10-21 06:48:45,227 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:48:47,040 - Epoch: [35][   50/  391]    Overall Loss 1.692023    Objective Loss 1.692023    Top1 76.718750    Top5 98.171875    LR 0.300000    Time 0.036197    
2018-10-21 06:48:48,644 - Epoch: [35][  100/  391]    Overall Loss 1.690253    Objective Loss 1.690253    Top1 77.140625    Top5 98.046875    LR 0.300000    Time 0.034117    
2018-10-21 06:48:50,292 - Epoch: [35][  150/  391]    Overall Loss 1.689368    Objective Loss 1.689368    Top1 77.244792    Top5 97.989583    LR 0.300000    Time 0.033718    
2018-10-21 06:48:51,916 - Epoch: [35][  200/  391]    Overall Loss 1.691237    Objective Loss 1.691237    Top1 77.085938    Top5 98.019531    LR 0.300000    Time 0.033394    
2018-10-21 06:48:53,472 - Epoch: [35][  250/  391]    Overall Loss 1.691570    Objective Loss 1.691570    Top1 77.059375    Top5 97.996875    LR 0.300000    Time 0.032930    
2018-10-21 06:48:55,029 - Epoch: [35][  300/  391]    Overall Loss 1.691252    Objective Loss 1.691252    Top1 77.083333    Top5 98.005208    LR 0.300000    Time 0.032623    
2018-10-21 06:48:56,580 - Epoch: [35][  350/  391]    Overall Loss 1.691095    Objective Loss 1.691095    Top1 77.089286    Top5 98.029018    LR 0.300000    Time 0.032388    
2018-10-21 06:48:57,985 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40698 | -0.01774 |    0.27410 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12465 | -0.00087 |    0.07858 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12437 | -0.00831 |    0.08723 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10594 | -0.00138 |    0.07125 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10808 | -0.01096 |    0.07606 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13006 | -0.00103 |    0.08816 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11798 | -0.01563 |    0.08491 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14524 | -0.00399 |    0.10676 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12294 | -0.00749 |    0.09325 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28542 | -0.01217 |    0.19757 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09529 | -0.00516 |    0.07315 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08412 | -0.01158 |    0.06660 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09905 | -0.00972 |    0.07540 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08153 | -0.00610 |    0.06125 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10426 | -0.00938 |    0.08172 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09178 | -0.00829 |    0.07166 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14876 | -0.01282 |    0.11545 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08789 | -0.00991 |    0.06708 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05258 | -0.00128 |    0.03900 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04182 | -0.00462 |    0.03088 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02994 |  0.00232 |    0.01919 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42029 | -0.00007 |    0.28583 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:48:57,985 - Total sparsity: 0.00

2018-10-21 06:48:57,985 - --- validate (epoch=35)-----------
2018-10-21 06:48:57,985 - 10000 samples (128 per mini-batch)
2018-10-21 06:48:59,242 - Epoch: [35][   50/   78]    Loss 1.716297    Top1 74.484375    Top5 97.500000    
2018-10-21 06:48:59,980 - ==> Top1: 74.620    Top5: 97.610    Loss: 1.714

2018-10-21 06:48:59,981 - ==> Best Top1: 74.640   On Epoch: 34

2018-10-21 06:48:59,981 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:48:59,994 - 

2018-10-21 06:48:59,995 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:49:01,942 - Epoch: [36][   50/  391]    Overall Loss 1.697083    Objective Loss 1.697083    Top1 76.296875    Top5 97.859375    LR 0.300000    Time 0.038892    
2018-10-21 06:49:03,625 - Epoch: [36][  100/  391]    Overall Loss 1.691845    Objective Loss 1.691845    Top1 77.000000    Top5 98.031250    LR 0.300000    Time 0.036251    
2018-10-21 06:49:05,213 - Epoch: [36][  150/  391]    Overall Loss 1.690018    Objective Loss 1.690018    Top1 77.203125    Top5 98.067708    LR 0.300000    Time 0.034741    
2018-10-21 06:49:06,799 - Epoch: [36][  200/  391]    Overall Loss 1.688935    Objective Loss 1.688935    Top1 77.292969    Top5 98.062500    LR 0.300000    Time 0.033974    
2018-10-21 06:49:08,403 - Epoch: [36][  250/  391]    Overall Loss 1.688507    Objective Loss 1.688507    Top1 77.331250    Top5 98.037500    LR 0.300000    Time 0.033586    
2018-10-21 06:49:09,979 - Epoch: [36][  300/  391]    Overall Loss 1.688908    Objective Loss 1.688908    Top1 77.304688    Top5 97.986979    LR 0.300000    Time 0.033235    
2018-10-21 06:49:11,541 - Epoch: [36][  350/  391]    Overall Loss 1.690868    Objective Loss 1.690868    Top1 77.098214    Top5 98.011161    LR 0.300000    Time 0.032943    
2018-10-21 06:49:12,915 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40913 | -0.01242 |    0.27643 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12638 | -0.00541 |    0.08083 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12567 | -0.00806 |    0.08850 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10558 | -0.00242 |    0.07155 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10897 | -0.01088 |    0.07623 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13062 | -0.00119 |    0.08762 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11794 | -0.01636 |    0.08504 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14504 | -0.00738 |    0.10689 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12300 | -0.00773 |    0.09384 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28609 | -0.00933 |    0.19792 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09542 | -0.00574 |    0.07317 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08413 | -0.01099 |    0.06633 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09910 | -0.01013 |    0.07553 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08126 | -0.00608 |    0.06092 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10446 | -0.00915 |    0.08186 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09202 | -0.00830 |    0.07194 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15051 | -0.01329 |    0.11689 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08837 | -0.00990 |    0.06745 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05301 | -0.00125 |    0.03922 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04224 | -0.00495 |    0.03127 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03016 |  0.00257 |    0.01944 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42026 | -0.00006 |    0.28630 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:49:12,915 - Total sparsity: 0.00

2018-10-21 06:49:12,916 - --- validate (epoch=36)-----------
2018-10-21 06:49:12,916 - 10000 samples (128 per mini-batch)
2018-10-21 06:49:14,072 - Epoch: [36][   50/   78]    Loss 1.761274    Top1 69.953125    Top5 96.500000    
2018-10-21 06:49:14,686 - ==> Top1: 69.780    Top5: 96.690    Loss: 1.763

2018-10-21 06:49:14,687 - ==> Best Top1: 74.640   On Epoch: 34

2018-10-21 06:49:14,687 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:49:14,700 - 

2018-10-21 06:49:14,701 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:49:16,493 - Epoch: [37][   50/  391]    Overall Loss 1.699931    Objective Loss 1.699931    Top1 76.343750    Top5 97.843750    LR 0.300000    Time 0.035783    
2018-10-21 06:49:18,153 - Epoch: [37][  100/  391]    Overall Loss 1.693826    Objective Loss 1.693826    Top1 76.906250    Top5 97.859375    LR 0.300000    Time 0.034469    
2018-10-21 06:49:19,721 - Epoch: [37][  150/  391]    Overall Loss 1.693048    Objective Loss 1.693048    Top1 76.901042    Top5 98.005208    LR 0.300000    Time 0.033417    
2018-10-21 06:49:21,284 - Epoch: [37][  200/  391]    Overall Loss 1.695036    Objective Loss 1.695036    Top1 76.742188    Top5 97.996094    LR 0.300000    Time 0.032867    
2018-10-21 06:49:22,869 - Epoch: [37][  250/  391]    Overall Loss 1.692350    Objective Loss 1.692350    Top1 77.009375    Top5 98.003125    LR 0.300000    Time 0.032623    
2018-10-21 06:49:24,458 - Epoch: [37][  300/  391]    Overall Loss 1.691504    Objective Loss 1.691504    Top1 77.057292    Top5 97.973958    LR 0.300000    Time 0.032478    
2018-10-21 06:49:26,046 - Epoch: [37][  350/  391]    Overall Loss 1.689932    Objective Loss 1.689932    Top1 77.250000    Top5 97.966518    LR 0.300000    Time 0.032367    
2018-10-21 06:49:27,474 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40526 | -0.00657 |    0.27475 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12604 | -0.00553 |    0.08014 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12520 | -0.00667 |    0.08756 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10550 | -0.00194 |    0.07150 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10929 | -0.00901 |    0.07615 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13080 |  0.00070 |    0.08712 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11770 | -0.01780 |    0.08508 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14465 | -0.00434 |    0.10654 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12290 | -0.00753 |    0.09360 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28814 | -0.01102 |    0.19909 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09515 | -0.00540 |    0.07276 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08379 | -0.01139 |    0.06588 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09907 | -0.00912 |    0.07543 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08131 | -0.00752 |    0.06116 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10538 | -0.00923 |    0.08282 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09281 | -0.00776 |    0.07254 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15102 | -0.01211 |    0.11637 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08899 | -0.01013 |    0.06814 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05324 | -0.00117 |    0.03944 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04241 | -0.00490 |    0.03146 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03022 |  0.00248 |    0.01950 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42164 | -0.00005 |    0.28791 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:49:27,474 - Total sparsity: 0.00

2018-10-21 06:49:27,474 - --- validate (epoch=37)-----------
2018-10-21 06:49:27,474 - 10000 samples (128 per mini-batch)
2018-10-21 06:49:28,654 - Epoch: [37][   50/   78]    Loss 1.904773    Top1 55.281250    Top5 89.578125    
2018-10-21 06:49:29,293 - ==> Top1: 55.820    Top5: 89.700    Loss: 1.898

2018-10-21 06:49:29,294 - ==> Best Top1: 74.640   On Epoch: 34

2018-10-21 06:49:29,295 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:49:29,307 - 

2018-10-21 06:49:29,307 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:49:31,011 - Epoch: [38][   50/  391]    Overall Loss 1.699773    Objective Loss 1.699773    Top1 76.203125    Top5 97.781250    LR 0.300000    Time 0.034012    
2018-10-21 06:49:32,625 - Epoch: [38][  100/  391]    Overall Loss 1.692644    Objective Loss 1.692644    Top1 77.000000    Top5 97.851562    LR 0.300000    Time 0.033120    
2018-10-21 06:49:34,246 - Epoch: [38][  150/  391]    Overall Loss 1.690883    Objective Loss 1.690883    Top1 77.135417    Top5 97.864583    LR 0.300000    Time 0.032870    
2018-10-21 06:49:35,845 - Epoch: [38][  200/  391]    Overall Loss 1.691185    Objective Loss 1.691185    Top1 77.113281    Top5 97.929688    LR 0.300000    Time 0.032639    
2018-10-21 06:49:37,406 - Epoch: [38][  250/  391]    Overall Loss 1.690251    Objective Loss 1.690251    Top1 77.200000    Top5 97.928125    LR 0.300000    Time 0.032348    
2018-10-21 06:49:38,985 - Epoch: [38][  300/  391]    Overall Loss 1.689369    Objective Loss 1.689369    Top1 77.317708    Top5 97.968750    LR 0.300000    Time 0.032212    
2018-10-21 06:49:40,594 - Epoch: [38][  350/  391]    Overall Loss 1.689224    Objective Loss 1.689224    Top1 77.314732    Top5 98.049107    LR 0.300000    Time 0.032200    
2018-10-21 06:49:42,032 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40382 | -0.01563 |    0.27543 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12506 | -0.00670 |    0.07951 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12466 | -0.00891 |    0.08778 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10562 | -0.00159 |    0.07047 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10881 | -0.01111 |    0.07565 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12996 | -0.00161 |    0.08684 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11714 | -0.01822 |    0.08477 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14454 | -0.00659 |    0.10670 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12294 | -0.00695 |    0.09343 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28879 | -0.00366 |    0.19819 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09504 | -0.00638 |    0.07258 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08349 | -0.01128 |    0.06595 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09879 | -0.00928 |    0.07494 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08129 | -0.00703 |    0.06115 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10585 | -0.00948 |    0.08325 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09278 | -0.00736 |    0.07240 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15030 | -0.01253 |    0.11639 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08876 | -0.01050 |    0.06784 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05315 | -0.00089 |    0.03934 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04255 | -0.00503 |    0.03155 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03049 |  0.00246 |    0.01962 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42447 | -0.00005 |    0.28958 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:49:42,032 - Total sparsity: 0.00

2018-10-21 06:49:42,032 - --- validate (epoch=38)-----------
2018-10-21 06:49:42,032 - 10000 samples (128 per mini-batch)
2018-10-21 06:49:43,199 - Epoch: [38][   50/   78]    Loss 1.701327    Top1 76.140625    Top5 98.046875    
2018-10-21 06:49:43,850 - ==> Top1: 75.910    Top5: 97.990    Loss: 1.704

2018-10-21 06:49:43,851 - ==> Best Top1: 75.910   On Epoch: 38

2018-10-21 06:49:43,851 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:49:43,867 - 

2018-10-21 06:49:43,868 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:49:45,583 - Epoch: [39][   50/  391]    Overall Loss 1.688133    Objective Loss 1.688133    Top1 77.406250    Top5 98.015625    LR 0.300000    Time 0.034252    
2018-10-21 06:49:47,131 - Epoch: [39][  100/  391]    Overall Loss 1.691059    Objective Loss 1.691059    Top1 77.171875    Top5 97.812500    LR 0.300000    Time 0.032583    
2018-10-21 06:49:48,716 - Epoch: [39][  150/  391]    Overall Loss 1.691353    Objective Loss 1.691353    Top1 77.098958    Top5 97.911458    LR 0.300000    Time 0.032272    
2018-10-21 06:49:50,273 - Epoch: [39][  200/  391]    Overall Loss 1.692735    Objective Loss 1.692735    Top1 76.984375    Top5 97.890625    LR 0.300000    Time 0.031980    
2018-10-21 06:49:51,828 - Epoch: [39][  250/  391]    Overall Loss 1.691699    Objective Loss 1.691699    Top1 77.096875    Top5 97.903125    LR 0.300000    Time 0.031795    
2018-10-21 06:49:53,453 - Epoch: [39][  300/  391]    Overall Loss 1.692361    Objective Loss 1.692361    Top1 76.966146    Top5 97.875000    LR 0.300000    Time 0.031905    
2018-10-21 06:49:55,053 - Epoch: [39][  350/  391]    Overall Loss 1.692549    Objective Loss 1.692549    Top1 76.955357    Top5 97.892857    LR 0.300000    Time 0.031910    
2018-10-21 06:49:56,472 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40976 |  0.00153 |    0.28113 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12888 | -0.00454 |    0.08132 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12746 | -0.00933 |    0.08919 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10791 | -0.00240 |    0.07192 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10981 | -0.01223 |    0.07670 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12946 | -0.00206 |    0.08695 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11702 | -0.01793 |    0.08413 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14585 | -0.00711 |    0.10740 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12351 | -0.00828 |    0.09367 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28998 | -0.00612 |    0.19595 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09529 | -0.00488 |    0.07278 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08390 | -0.01172 |    0.06625 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09983 | -0.00897 |    0.07563 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08243 | -0.00881 |    0.06251 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10673 | -0.00876 |    0.08387 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09343 | -0.00766 |    0.07297 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15054 | -0.01267 |    0.11669 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.01017 |    0.06805 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05355 | -0.00084 |    0.03949 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04301 | -0.00456 |    0.03178 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03077 |  0.00244 |    0.01985 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42495 | -0.00004 |    0.28837 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:49:56,472 - Total sparsity: 0.00

2018-10-21 06:49:56,473 - --- validate (epoch=39)-----------
2018-10-21 06:49:56,473 - 10000 samples (128 per mini-batch)
2018-10-21 06:49:57,683 - Epoch: [39][   50/   78]    Loss 1.712389    Top1 74.875000    Top5 96.984375    
2018-10-21 06:49:58,434 - ==> Top1: 74.850    Top5: 97.280    Loss: 1.712

2018-10-21 06:49:58,435 - ==> Best Top1: 75.910   On Epoch: 38

2018-10-21 06:49:58,436 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:49:58,449 - 

2018-10-21 06:49:58,449 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:50:00,138 - Epoch: [40][   50/  391]    Overall Loss 1.682520    Objective Loss 1.682520    Top1 78.015625    Top5 98.125000    LR 0.300000    Time 0.033720    
2018-10-21 06:50:01,693 - Epoch: [40][  100/  391]    Overall Loss 1.682970    Objective Loss 1.682970    Top1 77.921875    Top5 98.156250    LR 0.300000    Time 0.032387    
2018-10-21 06:50:03,263 - Epoch: [40][  150/  391]    Overall Loss 1.685134    Objective Loss 1.685134    Top1 77.687500    Top5 97.973958    LR 0.300000    Time 0.032044    
2018-10-21 06:50:04,827 - Epoch: [40][  200/  391]    Overall Loss 1.685235    Objective Loss 1.685235    Top1 77.632812    Top5 98.050781    LR 0.300000    Time 0.031842    
2018-10-21 06:50:06,411 - Epoch: [40][  250/  391]    Overall Loss 1.683565    Objective Loss 1.683565    Top1 77.828125    Top5 98.018750    LR 0.300000    Time 0.031802    
2018-10-21 06:50:07,975 - Epoch: [40][  300/  391]    Overall Loss 1.684958    Objective Loss 1.684958    Top1 77.710938    Top5 97.971354    LR 0.300000    Time 0.031706    
2018-10-21 06:50:09,517 - Epoch: [40][  350/  391]    Overall Loss 1.684597    Objective Loss 1.684597    Top1 77.774554    Top5 97.991071    LR 0.300000    Time 0.031577    
2018-10-21 06:50:10,924 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41050 | -0.00982 |    0.28055 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12908 | -0.00470 |    0.08187 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12773 | -0.00971 |    0.08887 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10766 | -0.00286 |    0.07240 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10933 | -0.01309 |    0.07696 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12945 |  0.00101 |    0.08719 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11693 | -0.01965 |    0.08437 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14542 | -0.00831 |    0.10737 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12340 | -0.00738 |    0.09350 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29070 | -0.00543 |    0.19767 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09555 | -0.00459 |    0.07277 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08390 | -0.01162 |    0.06635 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09967 | -0.00961 |    0.07590 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08272 | -0.00882 |    0.06271 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10685 | -0.00930 |    0.08397 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09345 | -0.00806 |    0.07303 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15101 | -0.01213 |    0.11643 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08906 | -0.01012 |    0.06795 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05353 | -0.00122 |    0.03961 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04302 | -0.00458 |    0.03175 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03067 |  0.00258 |    0.01974 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42264 | -0.00004 |    0.28670 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:50:10,925 - Total sparsity: 0.00

2018-10-21 06:50:10,925 - --- validate (epoch=40)-----------
2018-10-21 06:50:10,925 - 10000 samples (128 per mini-batch)
2018-10-21 06:50:12,121 - Epoch: [40][   50/   78]    Loss 1.731756    Top1 72.859375    Top5 97.687500    
2018-10-21 06:50:12,771 - ==> Top1: 72.400    Top5: 97.590    Loss: 1.736

2018-10-21 06:50:12,773 - ==> Best Top1: 75.910   On Epoch: 38

2018-10-21 06:50:12,773 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:50:12,786 - 

2018-10-21 06:50:12,786 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:50:14,462 - Epoch: [41][   50/  391]    Overall Loss 1.701044    Objective Loss 1.701044    Top1 76.125000    Top5 97.796875    LR 0.300000    Time 0.033458    
2018-10-21 06:50:16,033 - Epoch: [41][  100/  391]    Overall Loss 1.690607    Objective Loss 1.690607    Top1 77.171875    Top5 98.007812    LR 0.300000    Time 0.032418    
2018-10-21 06:50:17,583 - Epoch: [41][  150/  391]    Overall Loss 1.689901    Objective Loss 1.689901    Top1 77.229167    Top5 98.161458    LR 0.300000    Time 0.031931    
2018-10-21 06:50:19,134 - Epoch: [41][  200/  391]    Overall Loss 1.688058    Objective Loss 1.688058    Top1 77.378906    Top5 98.144531    LR 0.300000    Time 0.031691    
2018-10-21 06:50:20,674 - Epoch: [41][  250/  391]    Overall Loss 1.687642    Objective Loss 1.687642    Top1 77.412500    Top5 98.131250    LR 0.300000    Time 0.031505    
2018-10-21 06:50:22,233 - Epoch: [41][  300/  391]    Overall Loss 1.688186    Objective Loss 1.688186    Top1 77.364583    Top5 98.039062    LR 0.300000    Time 0.031443    
2018-10-21 06:50:23,903 - Epoch: [41][  350/  391]    Overall Loss 1.689096    Objective Loss 1.689096    Top1 77.254464    Top5 98.053571    LR 0.300000    Time 0.031718    
2018-10-21 06:50:25,449 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40755 | -0.00940 |    0.28021 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12860 | -0.00300 |    0.08137 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12799 | -0.00881 |    0.08914 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10816 | -0.00207 |    0.07171 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10959 | -0.01136 |    0.07690 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12906 | -0.00113 |    0.08716 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11804 | -0.01702 |    0.08457 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14607 | -0.00608 |    0.10816 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12354 | -0.00700 |    0.09332 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29220 | -0.00467 |    0.19727 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09527 | -0.00512 |    0.07275 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08379 | -0.01160 |    0.06618 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09955 | -0.00916 |    0.07554 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08277 | -0.00860 |    0.06246 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10691 | -0.00902 |    0.08420 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09350 | -0.00872 |    0.07320 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15174 | -0.01212 |    0.11759 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08892 | -0.01026 |    0.06805 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05351 | -0.00124 |    0.03960 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04314 | -0.00425 |    0.03178 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03063 |  0.00247 |    0.01964 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42143 | -0.00003 |    0.28643 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:50:25,449 - Total sparsity: 0.00

2018-10-21 06:50:25,449 - --- validate (epoch=41)-----------
2018-10-21 06:50:25,449 - 10000 samples (128 per mini-batch)
2018-10-21 06:50:26,622 - Epoch: [41][   50/   78]    Loss 1.699727    Top1 76.203125    Top5 97.781250    
2018-10-21 06:50:27,265 - ==> Top1: 76.530    Top5: 97.940    Loss: 1.696

2018-10-21 06:50:27,267 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:50:27,267 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:50:27,283 - 

2018-10-21 06:50:27,283 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:50:29,008 - Epoch: [42][   50/  391]    Overall Loss 1.678133    Objective Loss 1.678133    Top1 78.375000    Top5 98.437500    LR 0.300000    Time 0.034444    
2018-10-21 06:50:30,590 - Epoch: [42][  100/  391]    Overall Loss 1.683961    Objective Loss 1.683961    Top1 77.835938    Top5 98.265625    LR 0.300000    Time 0.033013    
2018-10-21 06:50:32,122 - Epoch: [42][  150/  391]    Overall Loss 1.686006    Objective Loss 1.686006    Top1 77.609375    Top5 98.156250    LR 0.300000    Time 0.032213    
2018-10-21 06:50:33,653 - Epoch: [42][  200/  391]    Overall Loss 1.686825    Objective Loss 1.686825    Top1 77.472656    Top5 98.050781    LR 0.300000    Time 0.031804    
2018-10-21 06:50:35,232 - Epoch: [42][  250/  391]    Overall Loss 1.687070    Objective Loss 1.687070    Top1 77.453125    Top5 98.081250    LR 0.300000    Time 0.031748    
2018-10-21 06:50:36,774 - Epoch: [42][  300/  391]    Overall Loss 1.685260    Objective Loss 1.685260    Top1 77.627604    Top5 98.114583    LR 0.300000    Time 0.031589    
2018-10-21 06:50:38,317 - Epoch: [42][  350/  391]    Overall Loss 1.685778    Objective Loss 1.685778    Top1 77.560268    Top5 98.082589    LR 0.300000    Time 0.031480    
2018-10-21 06:50:39,800 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40649 | -0.01601 |    0.27989 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12721 | -0.00588 |    0.08042 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12734 | -0.00589 |    0.08891 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10688 | -0.00398 |    0.07157 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10842 | -0.01098 |    0.07518 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12950 | -0.00297 |    0.08669 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11763 | -0.01872 |    0.08404 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14590 | -0.00721 |    0.10797 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12361 | -0.00709 |    0.09371 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29121 | -0.00698 |    0.19640 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09494 | -0.00401 |    0.07245 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08391 | -0.01125 |    0.06596 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09885 | -0.00898 |    0.07503 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08235 | -0.00833 |    0.06198 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10677 | -0.00938 |    0.08422 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09378 | -0.00798 |    0.07327 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15254 | -0.01372 |    0.11813 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08933 | -0.00992 |    0.06824 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05377 | -0.00171 |    0.03982 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04349 | -0.00462 |    0.03205 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03074 |  0.00238 |    0.01980 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42176 | -0.00003 |    0.28601 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:50:39,801 - Total sparsity: 0.00

2018-10-21 06:50:39,801 - --- validate (epoch=42)-----------
2018-10-21 06:50:39,801 - 10000 samples (128 per mini-batch)
2018-10-21 06:50:40,993 - Epoch: [42][   50/   78]    Loss 1.722475    Top1 73.687500    Top5 97.187500    
2018-10-21 06:50:41,654 - ==> Top1: 74.000    Top5: 97.250    Loss: 1.719

2018-10-21 06:50:41,655 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:50:41,655 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:50:41,668 - 

2018-10-21 06:50:41,668 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:50:43,390 - Epoch: [43][   50/  391]    Overall Loss 1.677167    Objective Loss 1.677167    Top1 78.437500    Top5 97.812500    LR 0.300000    Time 0.034377    
2018-10-21 06:50:45,010 - Epoch: [43][  100/  391]    Overall Loss 1.679004    Objective Loss 1.679004    Top1 78.367188    Top5 98.007812    LR 0.300000    Time 0.033362    
2018-10-21 06:50:46,609 - Epoch: [43][  150/  391]    Overall Loss 1.676691    Objective Loss 1.676691    Top1 78.677083    Top5 98.114583    LR 0.300000    Time 0.032891    
2018-10-21 06:50:48,222 - Epoch: [43][  200/  391]    Overall Loss 1.677754    Objective Loss 1.677754    Top1 78.515625    Top5 98.164062    LR 0.300000    Time 0.032721    
2018-10-21 06:50:49,844 - Epoch: [43][  250/  391]    Overall Loss 1.678571    Objective Loss 1.678571    Top1 78.406250    Top5 98.171875    LR 0.300000    Time 0.032656    
2018-10-21 06:50:51,436 - Epoch: [43][  300/  391]    Overall Loss 1.681229    Objective Loss 1.681229    Top1 78.114583    Top5 98.135417    LR 0.300000    Time 0.032514    
2018-10-21 06:50:53,055 - Epoch: [43][  350/  391]    Overall Loss 1.682641    Objective Loss 1.682641    Top1 77.973214    Top5 98.138393    LR 0.300000    Time 0.032487    
2018-10-21 06:50:54,484 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40111 | -0.01274 |    0.27475 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12583 | -0.00504 |    0.07894 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12653 | -0.00654 |    0.08790 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10695 | -0.00454 |    0.07121 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10828 | -0.01184 |    0.07484 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12920 | -0.00073 |    0.08617 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11700 | -0.01923 |    0.08363 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14608 | -0.00646 |    0.10780 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12385 | -0.00754 |    0.09394 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29103 | -0.00699 |    0.19790 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09496 | -0.00478 |    0.07255 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08387 | -0.01086 |    0.06603 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09787 | -0.00889 |    0.07436 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08143 | -0.00705 |    0.06127 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10731 | -0.01005 |    0.08448 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09422 | -0.00765 |    0.07363 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15170 | -0.01493 |    0.11728 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08935 | -0.00995 |    0.06827 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05383 | -0.00150 |    0.03976 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04369 | -0.00473 |    0.03237 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03090 |  0.00224 |    0.01992 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42340 | -0.00003 |    0.28849 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:50:54,484 - Total sparsity: 0.00

2018-10-21 06:50:54,484 - --- validate (epoch=43)-----------
2018-10-21 06:50:54,485 - 10000 samples (128 per mini-batch)
2018-10-21 06:50:55,628 - Epoch: [43][   50/   78]    Loss 1.736634    Top1 72.406250    Top5 96.609375    
2018-10-21 06:50:56,273 - ==> Top1: 73.010    Top5: 96.800    Loss: 1.730

2018-10-21 06:50:56,274 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:50:56,275 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:50:56,288 - 

2018-10-21 06:50:56,288 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:50:57,977 - Epoch: [44][   50/  391]    Overall Loss 1.679347    Objective Loss 1.679347    Top1 78.250000    Top5 98.234375    LR 0.300000    Time 0.033721    
2018-10-21 06:50:59,513 - Epoch: [44][  100/  391]    Overall Loss 1.681712    Objective Loss 1.681712    Top1 78.023438    Top5 98.039062    LR 0.300000    Time 0.032189    
2018-10-21 06:51:01,105 - Epoch: [44][  150/  391]    Overall Loss 1.681863    Objective Loss 1.681863    Top1 77.973958    Top5 98.135417    LR 0.300000    Time 0.032058    
2018-10-21 06:51:02,676 - Epoch: [44][  200/  391]    Overall Loss 1.683417    Objective Loss 1.683417    Top1 77.812500    Top5 98.085938    LR 0.300000    Time 0.031891    
2018-10-21 06:51:04,278 - Epoch: [44][  250/  391]    Overall Loss 1.684001    Objective Loss 1.684001    Top1 77.778125    Top5 98.112500    LR 0.300000    Time 0.031913    
2018-10-21 06:51:05,848 - Epoch: [44][  300/  391]    Overall Loss 1.687151    Objective Loss 1.687151    Top1 77.466146    Top5 98.054688    LR 0.300000    Time 0.031820    
2018-10-21 06:51:07,424 - Epoch: [44][  350/  391]    Overall Loss 1.686701    Objective Loss 1.686701    Top1 77.504464    Top5 98.069196    LR 0.300000    Time 0.031771    
2018-10-21 06:51:08,833 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40391 | -0.01420 |    0.27658 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12712 | -0.00513 |    0.07942 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12865 | -0.00853 |    0.08842 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10833 | -0.00533 |    0.07167 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10902 | -0.01162 |    0.07568 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13005 | -0.00300 |    0.08641 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11801 | -0.01847 |    0.08404 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14653 | -0.00886 |    0.10834 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12402 | -0.00712 |    0.09377 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29171 | -0.00614 |    0.19747 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09482 | -0.00436 |    0.07236 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08321 | -0.01189 |    0.06596 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09881 | -0.00850 |    0.07513 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08202 | -0.00686 |    0.06179 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10776 | -0.00913 |    0.08478 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09455 | -0.00734 |    0.07374 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15261 | -0.01529 |    0.11820 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08988 | -0.00999 |    0.06869 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05418 | -0.00178 |    0.04003 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04413 | -0.00517 |    0.03271 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03125 |  0.00227 |    0.02023 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42306 | -0.00003 |    0.28811 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:51:08,833 - Total sparsity: 0.00

2018-10-21 06:51:08,833 - --- validate (epoch=44)-----------
2018-10-21 06:51:08,833 - 10000 samples (128 per mini-batch)
2018-10-21 06:51:10,021 - Epoch: [44][   50/   78]    Loss 1.763811    Top1 69.546875    Top5 96.906250    
2018-10-21 06:51:10,660 - ==> Top1: 69.390    Top5: 96.860    Loss: 1.766

2018-10-21 06:51:10,662 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:51:10,662 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:51:10,675 - 

2018-10-21 06:51:10,676 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:51:12,361 - Epoch: [45][   50/  391]    Overall Loss 1.682922    Objective Loss 1.682922    Top1 77.968750    Top5 98.296875    LR 0.300000    Time 0.033649    
2018-10-21 06:51:13,939 - Epoch: [45][  100/  391]    Overall Loss 1.682839    Objective Loss 1.682839    Top1 77.921875    Top5 98.148438    LR 0.300000    Time 0.032578    
2018-10-21 06:51:15,517 - Epoch: [45][  150/  391]    Overall Loss 1.682399    Objective Loss 1.682399    Top1 78.015625    Top5 98.208333    LR 0.300000    Time 0.032227    
2018-10-21 06:51:17,079 - Epoch: [45][  200/  391]    Overall Loss 1.681423    Objective Loss 1.681423    Top1 78.097656    Top5 98.222656    LR 0.300000    Time 0.031969    
2018-10-21 06:51:18,654 - Epoch: [45][  250/  391]    Overall Loss 1.683204    Objective Loss 1.683204    Top1 77.868750    Top5 98.187500    LR 0.300000    Time 0.031869    
2018-10-21 06:51:20,209 - Epoch: [45][  300/  391]    Overall Loss 1.685536    Objective Loss 1.685536    Top1 77.622396    Top5 98.083333    LR 0.300000    Time 0.031731    
2018-10-21 06:51:21,782 - Epoch: [45][  350/  391]    Overall Loss 1.684276    Objective Loss 1.684276    Top1 77.758929    Top5 98.098214    LR 0.300000    Time 0.031686    
2018-10-21 06:51:23,180 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40745 |  0.00280 |    0.27664 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12801 | -0.00844 |    0.07897 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12947 | -0.00814 |    0.08995 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10900 | -0.00504 |    0.07180 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10926 | -0.01088 |    0.07565 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13151 | -0.00129 |    0.08735 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11768 | -0.01822 |    0.08388 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14661 | -0.00676 |    0.10750 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12427 | -0.00742 |    0.09414 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29270 | -0.00661 |    0.20001 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09467 | -0.00473 |    0.07224 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08338 | -0.01121 |    0.06588 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09787 | -0.00817 |    0.07431 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08141 | -0.00707 |    0.06145 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10799 | -0.00921 |    0.08488 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09481 | -0.00794 |    0.07407 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15230 | -0.01534 |    0.11738 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09013 | -0.01007 |    0.06872 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05448 | -0.00143 |    0.04042 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04426 | -0.00533 |    0.03282 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03122 |  0.00220 |    0.02020 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42313 | -0.00002 |    0.28762 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:51:23,181 - Total sparsity: 0.00

2018-10-21 06:51:23,181 - --- validate (epoch=45)-----------
2018-10-21 06:51:23,181 - 10000 samples (128 per mini-batch)
2018-10-21 06:51:24,392 - Epoch: [45][   50/   78]    Loss 1.725309    Top1 73.500000    Top5 98.093750    
2018-10-21 06:51:25,028 - ==> Top1: 73.500    Top5: 98.040    Loss: 1.727

2018-10-21 06:51:25,031 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:51:25,031 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:51:25,043 - 

2018-10-21 06:51:25,044 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:51:26,757 - Epoch: [46][   50/  391]    Overall Loss 1.680840    Objective Loss 1.680840    Top1 78.031250    Top5 98.296875    LR 0.300000    Time 0.034215    
2018-10-21 06:51:28,342 - Epoch: [46][  100/  391]    Overall Loss 1.684853    Objective Loss 1.684853    Top1 77.570312    Top5 98.148438    LR 0.300000    Time 0.032926    
2018-10-21 06:51:29,924 - Epoch: [46][  150/  391]    Overall Loss 1.681956    Objective Loss 1.681956    Top1 77.979167    Top5 98.223958    LR 0.300000    Time 0.032489    
2018-10-21 06:51:31,513 - Epoch: [46][  200/  391]    Overall Loss 1.682026    Objective Loss 1.682026    Top1 77.937500    Top5 98.253906    LR 0.300000    Time 0.032298    
2018-10-21 06:51:33,101 - Epoch: [46][  250/  391]    Overall Loss 1.682466    Objective Loss 1.682466    Top1 77.937500    Top5 98.221875    LR 0.300000    Time 0.032182    
2018-10-21 06:51:34,714 - Epoch: [46][  300/  391]    Overall Loss 1.681054    Objective Loss 1.681054    Top1 78.098958    Top5 98.263021    LR 0.300000    Time 0.032184    
2018-10-21 06:51:36,292 - Epoch: [46][  350/  391]    Overall Loss 1.681851    Objective Loss 1.681851    Top1 78.031250    Top5 98.254464    LR 0.300000    Time 0.032089    
2018-10-21 06:51:37,729 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40284 | -0.00832 |    0.27221 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12796 | -0.00642 |    0.07954 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12913 | -0.00611 |    0.08893 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10922 | -0.00358 |    0.07191 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10880 | -0.01357 |    0.07509 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13131 | -0.00458 |    0.08663 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11736 | -0.02280 |    0.08420 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14574 | -0.00633 |    0.10645 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12446 | -0.00816 |    0.09488 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29178 | -0.00664 |    0.19788 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09472 | -0.00439 |    0.07230 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08355 | -0.01168 |    0.06571 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09847 | -0.00786 |    0.07490 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08185 | -0.00758 |    0.06175 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10830 | -0.00845 |    0.08534 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09470 | -0.00729 |    0.07400 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15162 | -0.01709 |    0.11698 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08965 | -0.01038 |    0.06856 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05446 | -0.00163 |    0.04031 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04444 | -0.00569 |    0.03304 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03133 |  0.00233 |    0.02026 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42278 | -0.00002 |    0.28788 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:51:37,730 - Total sparsity: 0.00

2018-10-21 06:51:37,730 - --- validate (epoch=46)-----------
2018-10-21 06:51:37,730 - 10000 samples (128 per mini-batch)
2018-10-21 06:51:38,918 - Epoch: [46][   50/   78]    Loss 1.731374    Top1 72.937500    Top5 96.796875    
2018-10-21 06:51:39,553 - ==> Top1: 73.060    Top5: 96.920    Loss: 1.730

2018-10-21 06:51:39,555 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:51:39,555 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:51:39,568 - 

2018-10-21 06:51:39,568 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:51:41,270 - Epoch: [47][   50/  391]    Overall Loss 1.699888    Objective Loss 1.699888    Top1 76.234375    Top5 98.156250    LR 0.300000    Time 0.033978    
2018-10-21 06:51:42,857 - Epoch: [47][  100/  391]    Overall Loss 1.692809    Objective Loss 1.692809    Top1 76.906250    Top5 98.312500    LR 0.300000    Time 0.032835    
2018-10-21 06:51:44,434 - Epoch: [47][  150/  391]    Overall Loss 1.689768    Objective Loss 1.689768    Top1 77.276042    Top5 98.265625    LR 0.300000    Time 0.032390    
2018-10-21 06:51:45,983 - Epoch: [47][  200/  391]    Overall Loss 1.686486    Objective Loss 1.686486    Top1 77.578125    Top5 98.304688    LR 0.300000    Time 0.032029    
2018-10-21 06:51:47,526 - Epoch: [47][  250/  391]    Overall Loss 1.687166    Objective Loss 1.687166    Top1 77.500000    Top5 98.287500    LR 0.300000    Time 0.031784    
2018-10-21 06:51:49,091 - Epoch: [47][  300/  391]    Overall Loss 1.685348    Objective Loss 1.685348    Top1 77.679688    Top5 98.302083    LR 0.300000    Time 0.031696    
2018-10-21 06:51:50,718 - Epoch: [47][  350/  391]    Overall Loss 1.685043    Objective Loss 1.685043    Top1 77.698661    Top5 98.276786    LR 0.300000    Time 0.031812    
2018-10-21 06:51:52,146 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40442 |  0.00529 |    0.27491 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12879 | -0.00553 |    0.07982 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12945 | -0.00803 |    0.08986 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10809 | -0.00050 |    0.07139 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10727 | -0.01412 |    0.07371 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13156 | -0.00274 |    0.08726 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11812 | -0.01928 |    0.08487 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14596 | -0.00952 |    0.10647 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12437 | -0.00868 |    0.09462 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29134 | -0.01076 |    0.19944 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09475 | -0.00391 |    0.07212 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08357 | -0.01276 |    0.06595 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09894 | -0.00772 |    0.07510 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08224 | -0.00785 |    0.06231 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10837 | -0.00982 |    0.08541 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09507 | -0.00683 |    0.07431 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15269 | -0.01636 |    0.11751 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09000 | -0.00994 |    0.06877 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05469 | -0.00176 |    0.04054 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04467 | -0.00586 |    0.03340 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03141 |  0.00238 |    0.02035 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42220 | -0.00002 |    0.28687 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:51:52,146 - Total sparsity: 0.00

2018-10-21 06:51:52,146 - --- validate (epoch=47)-----------
2018-10-21 06:51:52,147 - 10000 samples (128 per mini-batch)
2018-10-21 06:51:53,321 - Epoch: [47][   50/   78]    Loss 1.722920    Top1 73.765625    Top5 97.593750    
2018-10-21 06:51:53,952 - ==> Top1: 74.070    Top5: 97.680    Loss: 1.720

2018-10-21 06:51:53,953 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:51:53,954 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:51:53,966 - 

2018-10-21 06:51:53,967 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:51:55,703 - Epoch: [48][   50/  391]    Overall Loss 1.684022    Objective Loss 1.684022    Top1 77.890625    Top5 98.031250    LR 0.300000    Time 0.034674    
2018-10-21 06:51:57,275 - Epoch: [48][  100/  391]    Overall Loss 1.679608    Objective Loss 1.679608    Top1 78.312500    Top5 98.109375    LR 0.300000    Time 0.033030    
2018-10-21 06:51:58,821 - Epoch: [48][  150/  391]    Overall Loss 1.678595    Objective Loss 1.678595    Top1 78.458333    Top5 98.161458    LR 0.300000    Time 0.032310    
2018-10-21 06:52:00,369 - Epoch: [48][  200/  391]    Overall Loss 1.678648    Objective Loss 1.678648    Top1 78.425781    Top5 98.257812    LR 0.300000    Time 0.031962    
2018-10-21 06:52:01,917 - Epoch: [48][  250/  391]    Overall Loss 1.679019    Objective Loss 1.679019    Top1 78.356250    Top5 98.193750    LR 0.300000    Time 0.031752    
2018-10-21 06:52:03,467 - Epoch: [48][  300/  391]    Overall Loss 1.679214    Objective Loss 1.679214    Top1 78.369792    Top5 98.218750    LR 0.300000    Time 0.031621    
2018-10-21 06:52:05,085 - Epoch: [48][  350/  391]    Overall Loss 1.680829    Objective Loss 1.680829    Top1 78.189732    Top5 98.194196    LR 0.300000    Time 0.031721    
2018-10-21 06:52:06,531 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40940 | -0.00182 |    0.28075 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13067 | -0.00824 |    0.08128 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13087 | -0.00684 |    0.09150 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10835 | -0.00269 |    0.07141 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10813 | -0.01270 |    0.07450 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13184 | -0.00240 |    0.08765 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11852 | -0.01906 |    0.08580 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14471 | -0.00600 |    0.10600 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12351 | -0.00753 |    0.09429 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29372 | -0.00377 |    0.19911 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09438 | -0.00407 |    0.07193 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08291 | -0.01226 |    0.06540 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09906 | -0.00773 |    0.07513 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08191 | -0.00848 |    0.06236 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10839 | -0.00953 |    0.08549 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09500 | -0.00627 |    0.07440 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15263 | -0.01416 |    0.11679 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08986 | -0.01017 |    0.06875 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05475 | -0.00123 |    0.04042 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04491 | -0.00527 |    0.03347 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03141 |  0.00241 |    0.02025 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42431 | -0.00002 |    0.28646 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:52:06,531 - Total sparsity: 0.00

2018-10-21 06:52:06,531 - --- validate (epoch=48)-----------
2018-10-21 06:52:06,531 - 10000 samples (128 per mini-batch)
2018-10-21 06:52:07,720 - Epoch: [48][   50/   78]    Loss 1.731549    Top1 72.953125    Top5 97.546875    
2018-10-21 06:52:08,340 - ==> Top1: 72.700    Top5: 97.640    Loss: 1.733

2018-10-21 06:52:08,342 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:52:08,342 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:52:08,356 - 

2018-10-21 06:52:08,357 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:52:10,171 - Epoch: [49][   50/  391]    Overall Loss 1.684212    Objective Loss 1.684212    Top1 77.765625    Top5 98.015625    LR 0.300000    Time 0.036219    
2018-10-21 06:52:11,782 - Epoch: [49][  100/  391]    Overall Loss 1.679451    Objective Loss 1.679451    Top1 78.304688    Top5 98.117188    LR 0.300000    Time 0.034196    
2018-10-21 06:52:13,358 - Epoch: [49][  150/  391]    Overall Loss 1.679525    Objective Loss 1.679525    Top1 78.322917    Top5 98.140625    LR 0.300000    Time 0.033290    
2018-10-21 06:52:14,892 - Epoch: [49][  200/  391]    Overall Loss 1.680040    Objective Loss 1.680040    Top1 78.234375    Top5 98.089844    LR 0.300000    Time 0.032629    
2018-10-21 06:52:16,539 - Epoch: [49][  250/  391]    Overall Loss 1.678990    Objective Loss 1.678990    Top1 78.318750    Top5 98.081250    LR 0.300000    Time 0.032682    
2018-10-21 06:52:18,173 - Epoch: [49][  300/  391]    Overall Loss 1.680246    Objective Loss 1.680246    Top1 78.208333    Top5 98.085938    LR 0.300000    Time 0.032676    
2018-10-21 06:52:19,722 - Epoch: [49][  350/  391]    Overall Loss 1.681014    Objective Loss 1.681014    Top1 78.113839    Top5 98.107143    LR 0.300000    Time 0.032426    
2018-10-21 06:52:21,107 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40668 |  0.00273 |    0.27533 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13020 | -0.00898 |    0.08094 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13035 | -0.00720 |    0.09101 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10891 | -0.00261 |    0.07185 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10888 | -0.01265 |    0.07445 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13187 | -0.00141 |    0.08707 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11770 | -0.01784 |    0.08502 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14523 | -0.00640 |    0.10657 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12386 | -0.00936 |    0.09455 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29316 | -0.00421 |    0.20069 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09389 | -0.00374 |    0.07174 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08258 | -0.01209 |    0.06538 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09955 | -0.00765 |    0.07534 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08219 | -0.00769 |    0.06216 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10897 | -0.00914 |    0.08587 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09550 | -0.00690 |    0.07470 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15152 | -0.01407 |    0.11635 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08986 | -0.01055 |    0.06878 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05492 | -0.00109 |    0.04054 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04520 | -0.00564 |    0.03374 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03171 |  0.00219 |    0.02047 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42547 | -0.00002 |    0.28773 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:52:21,108 - Total sparsity: 0.00

2018-10-21 06:52:21,108 - --- validate (epoch=49)-----------
2018-10-21 06:52:21,108 - 10000 samples (128 per mini-batch)
2018-10-21 06:52:22,296 - Epoch: [49][   50/   78]    Loss 1.706510    Top1 75.437500    Top5 98.015625    
2018-10-21 06:52:22,919 - ==> Top1: 75.720    Top5: 98.160    Loss: 1.703

2018-10-21 06:52:22,921 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:52:22,921 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:52:22,934 - 

2018-10-21 06:52:22,934 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:52:24,721 - Epoch: [50][   50/  391]    Overall Loss 1.678232    Objective Loss 1.678232    Top1 78.468750    Top5 98.203125    LR 0.300000    Time 0.035675    
2018-10-21 06:52:26,344 - Epoch: [50][  100/  391]    Overall Loss 1.680753    Objective Loss 1.680753    Top1 78.125000    Top5 98.070312    LR 0.300000    Time 0.034040    
2018-10-21 06:52:27,964 - Epoch: [50][  150/  391]    Overall Loss 1.678242    Objective Loss 1.678242    Top1 78.411458    Top5 97.984375    LR 0.300000    Time 0.033477    
2018-10-21 06:52:29,494 - Epoch: [50][  200/  391]    Overall Loss 1.678947    Objective Loss 1.678947    Top1 78.386719    Top5 97.957031    LR 0.300000    Time 0.032749    
2018-10-21 06:52:31,024 - Epoch: [50][  250/  391]    Overall Loss 1.677741    Objective Loss 1.677741    Top1 78.509375    Top5 98.018750    LR 0.300000    Time 0.032308    
2018-10-21 06:52:32,562 - Epoch: [50][  300/  391]    Overall Loss 1.679248    Objective Loss 1.679248    Top1 78.338542    Top5 98.028646    LR 0.300000    Time 0.032042    
2018-10-21 06:52:34,109 - Epoch: [50][  350/  391]    Overall Loss 1.680617    Objective Loss 1.680617    Top1 78.191964    Top5 98.015625    LR 0.300000    Time 0.031880    
2018-10-21 06:52:35,503 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40844 | -0.01016 |    0.27649 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12902 | -0.00697 |    0.08011 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12933 | -0.00681 |    0.09021 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10874 | -0.00224 |    0.07220 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10891 | -0.01205 |    0.07512 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13086 | -0.00235 |    0.08661 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11805 | -0.01684 |    0.08524 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14496 | -0.00755 |    0.10642 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12384 | -0.00926 |    0.09398 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29473 | -0.00929 |    0.19757 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09343 | -0.00467 |    0.07154 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08248 | -0.01124 |    0.06519 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09887 | -0.00835 |    0.07526 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08194 | -0.00793 |    0.06231 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10918 | -0.00911 |    0.08574 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09573 | -0.00675 |    0.07481 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15108 | -0.01377 |    0.11628 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08955 | -0.01004 |    0.06858 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05487 | -0.00128 |    0.04048 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04556 | -0.00559 |    0.03391 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03199 |  0.00194 |    0.02074 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42735 | -0.00002 |    0.28932 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:52:35,504 - Total sparsity: 0.00

2018-10-21 06:52:35,504 - --- validate (epoch=50)-----------
2018-10-21 06:52:35,504 - 10000 samples (128 per mini-batch)
2018-10-21 06:52:36,700 - Epoch: [50][   50/   78]    Loss 1.748165    Top1 71.250000    Top5 97.218750    
2018-10-21 06:52:37,344 - ==> Top1: 71.650    Top5: 97.260    Loss: 1.743

2018-10-21 06:52:37,345 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:52:37,345 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:52:37,358 - 

2018-10-21 06:52:37,359 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:52:39,044 - Epoch: [51][   50/  391]    Overall Loss 1.682297    Objective Loss 1.682297    Top1 78.015625    Top5 98.453125    LR 0.300000    Time 0.033639    
2018-10-21 06:52:40,587 - Epoch: [51][  100/  391]    Overall Loss 1.689817    Objective Loss 1.689817    Top1 77.226562    Top5 98.242188    LR 0.300000    Time 0.032225    
2018-10-21 06:52:42,121 - Epoch: [51][  150/  391]    Overall Loss 1.688914    Objective Loss 1.688914    Top1 77.312500    Top5 98.145833    LR 0.300000    Time 0.031695    
2018-10-21 06:52:43,697 - Epoch: [51][  200/  391]    Overall Loss 1.688255    Objective Loss 1.688255    Top1 77.347656    Top5 98.093750    LR 0.300000    Time 0.031641    
2018-10-21 06:52:45,227 - Epoch: [51][  250/  391]    Overall Loss 1.689555    Objective Loss 1.689555    Top1 77.218750    Top5 98.093750    LR 0.300000    Time 0.031425    
2018-10-21 06:52:46,727 - Epoch: [51][  300/  391]    Overall Loss 1.686802    Objective Loss 1.686802    Top1 77.489583    Top5 98.088542    LR 0.300000    Time 0.031179    
2018-10-21 06:52:48,253 - Epoch: [51][  350/  391]    Overall Loss 1.687381    Objective Loss 1.687381    Top1 77.441964    Top5 98.075893    LR 0.300000    Time 0.031079    
2018-10-21 06:52:49,672 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41189 | -0.00512 |    0.27298 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12941 | -0.00709 |    0.07978 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12994 | -0.00594 |    0.09024 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10883 | -0.00274 |    0.07172 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10915 | -0.01254 |    0.07536 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13261 | -0.00393 |    0.08810 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11967 | -0.01593 |    0.08699 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14571 | -0.00707 |    0.10706 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12388 | -0.00876 |    0.09409 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29687 | -0.01040 |    0.19723 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09401 | -0.00473 |    0.07222 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08271 | -0.01164 |    0.06553 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09887 | -0.00811 |    0.07473 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08156 | -0.00730 |    0.06180 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10953 | -0.00977 |    0.08619 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09601 | -0.00725 |    0.07509 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15062 | -0.01428 |    0.11621 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08983 | -0.01020 |    0.06892 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05515 | -0.00128 |    0.04063 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04593 | -0.00570 |    0.03428 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03220 |  0.00218 |    0.02087 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42555 | -0.00001 |    0.28805 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:52:49,672 - Total sparsity: 0.00

2018-10-21 06:52:49,672 - --- validate (epoch=51)-----------
2018-10-21 06:52:49,672 - 10000 samples (128 per mini-batch)
2018-10-21 06:52:50,882 - Epoch: [51][   50/   78]    Loss 1.730444    Top1 72.906250    Top5 97.171875    
2018-10-21 06:52:51,543 - ==> Top1: 72.500    Top5: 97.370    Loss: 1.736

2018-10-21 06:52:51,545 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:52:51,545 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:52:51,557 - 

2018-10-21 06:52:51,558 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:52:53,298 - Epoch: [52][   50/  391]    Overall Loss 1.677821    Objective Loss 1.677821    Top1 78.468750    Top5 98.406250    LR 0.300000    Time 0.034742    
2018-10-21 06:52:54,859 - Epoch: [52][  100/  391]    Overall Loss 1.676140    Objective Loss 1.676140    Top1 78.656250    Top5 98.140625    LR 0.300000    Time 0.032962    
2018-10-21 06:52:56,429 - Epoch: [52][  150/  391]    Overall Loss 1.678911    Objective Loss 1.678911    Top1 78.343750    Top5 98.109375    LR 0.300000    Time 0.032429    
2018-10-21 06:52:57,970 - Epoch: [52][  200/  391]    Overall Loss 1.679101    Objective Loss 1.679101    Top1 78.347656    Top5 98.195312    LR 0.300000    Time 0.032013    
2018-10-21 06:52:59,513 - Epoch: [52][  250/  391]    Overall Loss 1.678332    Objective Loss 1.678332    Top1 78.431250    Top5 98.231250    LR 0.300000    Time 0.031775    
2018-10-21 06:53:01,057 - Epoch: [52][  300/  391]    Overall Loss 1.678160    Objective Loss 1.678160    Top1 78.458333    Top5 98.205729    LR 0.300000    Time 0.031617    
2018-10-21 06:53:02,654 - Epoch: [52][  350/  391]    Overall Loss 1.679136    Objective Loss 1.679136    Top1 78.343750    Top5 98.196429    LR 0.300000    Time 0.031658    
2018-10-21 06:53:04,010 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41117 | -0.00219 |    0.27670 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12798 | -0.00602 |    0.07803 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12825 | -0.00637 |    0.08951 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10745 | -0.00282 |    0.07128 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10782 | -0.01146 |    0.07481 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13254 | -0.00210 |    0.08919 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11847 | -0.01930 |    0.08629 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14484 | -0.00618 |    0.10710 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12323 | -0.00964 |    0.09393 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29440 | -0.00894 |    0.19699 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09437 | -0.00422 |    0.07233 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08287 | -0.01101 |    0.06553 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09821 | -0.00778 |    0.07427 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08098 | -0.00758 |    0.06149 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10887 | -0.00967 |    0.08580 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09569 | -0.00751 |    0.07491 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14967 | -0.01417 |    0.11521 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08932 | -0.01069 |    0.06862 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05498 | -0.00159 |    0.04081 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04589 | -0.00592 |    0.03424 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03205 |  0.00233 |    0.02072 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42585 | -0.00001 |    0.28849 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:53:04,010 - Total sparsity: 0.00

2018-10-21 06:53:04,010 - --- validate (epoch=52)-----------
2018-10-21 06:53:04,011 - 10000 samples (128 per mini-batch)
2018-10-21 06:53:05,182 - Epoch: [52][   50/   78]    Loss 1.700775    Top1 76.078125    Top5 98.218750    
2018-10-21 06:53:05,807 - ==> Top1: 75.730    Top5: 98.180    Loss: 1.704

2018-10-21 06:53:05,808 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:53:05,809 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:53:05,822 - 

2018-10-21 06:53:05,822 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:53:07,473 - Epoch: [53][   50/  391]    Overall Loss 1.682764    Objective Loss 1.682764    Top1 77.890625    Top5 98.125000    LR 0.300000    Time 0.032953    
2018-10-21 06:53:09,008 - Epoch: [53][  100/  391]    Overall Loss 1.682279    Objective Loss 1.682279    Top1 77.984375    Top5 98.085938    LR 0.300000    Time 0.031805    
2018-10-21 06:53:10,607 - Epoch: [53][  150/  391]    Overall Loss 1.681185    Objective Loss 1.681185    Top1 78.114583    Top5 98.130208    LR 0.300000    Time 0.031848    
2018-10-21 06:53:12,235 - Epoch: [53][  200/  391]    Overall Loss 1.683448    Objective Loss 1.683448    Top1 77.898438    Top5 98.070312    LR 0.300000    Time 0.032017    
2018-10-21 06:53:13,820 - Epoch: [53][  250/  391]    Overall Loss 1.683692    Objective Loss 1.683692    Top1 77.843750    Top5 98.087500    LR 0.300000    Time 0.031944    
2018-10-21 06:53:15,401 - Epoch: [53][  300/  391]    Overall Loss 1.682896    Objective Loss 1.682896    Top1 77.919271    Top5 98.122396    LR 0.300000    Time 0.031880    
2018-10-21 06:53:16,973 - Epoch: [53][  350/  391]    Overall Loss 1.680717    Objective Loss 1.680717    Top1 78.120536    Top5 98.125000    LR 0.300000    Time 0.031813    
2018-10-21 06:53:18,414 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41545 | -0.00208 |    0.27633 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12864 | -0.00410 |    0.07793 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12797 | -0.00816 |    0.08952 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10750 | -0.00199 |    0.07095 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10715 | -0.01382 |    0.07485 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13200 | -0.00278 |    0.08906 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11886 | -0.01874 |    0.08659 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14557 | -0.00877 |    0.10765 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12354 | -0.00886 |    0.09421 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29393 | -0.00871 |    0.19525 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09411 | -0.00565 |    0.07219 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08319 | -0.01164 |    0.06571 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09869 | -0.00816 |    0.07487 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08112 | -0.00812 |    0.06148 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10853 | -0.00924 |    0.08552 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09539 | -0.00778 |    0.07456 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14977 | -0.01205 |    0.11518 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08922 | -0.01057 |    0.06850 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05486 | -0.00143 |    0.04066 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04599 | -0.00558 |    0.03421 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03213 |  0.00243 |    0.02072 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42566 | -0.00001 |    0.28844 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:53:18,414 - Total sparsity: 0.00

2018-10-21 06:53:18,414 - --- validate (epoch=53)-----------
2018-10-21 06:53:18,414 - 10000 samples (128 per mini-batch)
2018-10-21 06:53:19,735 - Epoch: [53][   50/   78]    Loss 1.704025    Top1 75.562500    Top5 97.984375    
2018-10-21 06:53:20,405 - ==> Top1: 75.980    Top5: 97.950    Loss: 1.700

2018-10-21 06:53:20,407 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:53:20,407 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:53:20,423 - 

2018-10-21 06:53:20,424 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:53:22,211 - Epoch: [54][   50/  391]    Overall Loss 1.674367    Objective Loss 1.674367    Top1 78.781250    Top5 98.515625    LR 0.300000    Time 0.035678    
2018-10-21 06:53:23,823 - Epoch: [54][  100/  391]    Overall Loss 1.676547    Objective Loss 1.676547    Top1 78.484375    Top5 98.343750    LR 0.300000    Time 0.033938    
2018-10-21 06:53:25,413 - Epoch: [54][  150/  391]    Overall Loss 1.678184    Objective Loss 1.678184    Top1 78.359375    Top5 98.223958    LR 0.300000    Time 0.033214    
2018-10-21 06:53:27,003 - Epoch: [54][  200/  391]    Overall Loss 1.677745    Objective Loss 1.677745    Top1 78.449219    Top5 98.281250    LR 0.300000    Time 0.032847    
2018-10-21 06:53:28,689 - Epoch: [54][  250/  391]    Overall Loss 1.677351    Objective Loss 1.677351    Top1 78.468750    Top5 98.281250    LR 0.300000    Time 0.033012    
2018-10-21 06:53:30,305 - Epoch: [54][  300/  391]    Overall Loss 1.678604    Objective Loss 1.678604    Top1 78.315104    Top5 98.276042    LR 0.300000    Time 0.032891    
2018-10-21 06:53:31,886 - Epoch: [54][  350/  391]    Overall Loss 1.681340    Objective Loss 1.681340    Top1 78.053571    Top5 98.223214    LR 0.300000    Time 0.032701    
2018-10-21 06:53:33,295 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41551 |  0.00834 |    0.27895 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12928 | -0.00590 |    0.07863 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12845 | -0.00758 |    0.08794 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10819 | -0.00439 |    0.07176 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10761 | -0.01403 |    0.07438 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13313 | -0.00356 |    0.08997 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12058 | -0.01701 |    0.08709 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14636 | -0.00586 |    0.10796 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12384 | -0.00749 |    0.09439 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29374 | -0.00971 |    0.19663 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09320 | -0.00542 |    0.07133 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08269 | -0.01223 |    0.06552 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09840 | -0.00845 |    0.07502 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08109 | -0.00749 |    0.06127 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10849 | -0.00889 |    0.08566 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09541 | -0.00832 |    0.07476 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15088 | -0.01128 |    0.11607 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08932 | -0.01042 |    0.06860 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05515 | -0.00162 |    0.04082 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04625 | -0.00564 |    0.03444 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03219 |  0.00202 |    0.02101 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42513 | -0.00001 |    0.28851 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:53:33,295 - Total sparsity: 0.00

2018-10-21 06:53:33,296 - --- validate (epoch=54)-----------
2018-10-21 06:53:33,296 - 10000 samples (128 per mini-batch)
2018-10-21 06:53:34,537 - Epoch: [54][   50/   78]    Loss 1.714395    Top1 74.812500    Top5 97.875000    
2018-10-21 06:53:35,222 - ==> Top1: 74.570    Top5: 97.960    Loss: 1.715

2018-10-21 06:53:35,224 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:53:35,224 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:53:35,236 - 

2018-10-21 06:53:35,236 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:53:36,958 - Epoch: [55][   50/  391]    Overall Loss 1.675899    Objective Loss 1.675899    Top1 78.703125    Top5 98.343750    LR 0.300000    Time 0.034352    
2018-10-21 06:53:38,546 - Epoch: [55][  100/  391]    Overall Loss 1.679009    Objective Loss 1.679009    Top1 78.312500    Top5 98.304688    LR 0.300000    Time 0.033034    
2018-10-21 06:53:40,160 - Epoch: [55][  150/  391]    Overall Loss 1.678011    Objective Loss 1.678011    Top1 78.479167    Top5 98.255208    LR 0.300000    Time 0.032767    
2018-10-21 06:53:41,745 - Epoch: [55][  200/  391]    Overall Loss 1.680095    Objective Loss 1.680095    Top1 78.250000    Top5 98.132812    LR 0.300000    Time 0.032490    
2018-10-21 06:53:43,319 - Epoch: [55][  250/  391]    Overall Loss 1.681581    Objective Loss 1.681581    Top1 78.053125    Top5 98.071875    LR 0.300000    Time 0.032281    
2018-10-21 06:53:44,896 - Epoch: [55][  300/  391]    Overall Loss 1.679810    Objective Loss 1.679810    Top1 78.231771    Top5 98.062500    LR 0.300000    Time 0.032148    
2018-10-21 06:53:46,484 - Epoch: [55][  350/  391]    Overall Loss 1.679816    Objective Loss 1.679816    Top1 78.238839    Top5 98.087054    LR 0.300000    Time 0.032087    
2018-10-21 06:53:47,911 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41235 | -0.00345 |    0.27384 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12832 | -0.00405 |    0.07676 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12742 | -0.00800 |    0.08743 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10765 | -0.00132 |    0.07061 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10720 | -0.01481 |    0.07459 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13286 | -0.00306 |    0.08916 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12103 | -0.01671 |    0.08653 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14638 | -0.00656 |    0.10721 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12388 | -0.00912 |    0.09467 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29667 | -0.00678 |    0.19704 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09283 | -0.00561 |    0.07116 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08290 | -0.01294 |    0.06582 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09837 | -0.00841 |    0.07486 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08184 | -0.00731 |    0.06214 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10876 | -0.00939 |    0.08573 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09565 | -0.00783 |    0.07487 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15175 | -0.00898 |    0.11631 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08936 | -0.01019 |    0.06857 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05531 | -0.00128 |    0.04098 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04661 | -0.00572 |    0.03482 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03250 |  0.00190 |    0.02121 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42497 | -0.00001 |    0.28776 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:53:47,911 - Total sparsity: 0.00

2018-10-21 06:53:47,911 - --- validate (epoch=55)-----------
2018-10-21 06:53:47,912 - 10000 samples (128 per mini-batch)
2018-10-21 06:53:49,129 - Epoch: [55][   50/   78]    Loss 1.722719    Top1 73.796875    Top5 97.937500    
2018-10-21 06:53:49,766 - ==> Top1: 73.470    Top5: 97.970    Loss: 1.728

2018-10-21 06:53:49,767 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:53:49,767 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:53:49,780 - 

2018-10-21 06:53:49,781 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:53:51,567 - Epoch: [56][   50/  391]    Overall Loss 1.668487    Objective Loss 1.668487    Top1 79.312500    Top5 98.171875    LR 0.300000    Time 0.035666    
2018-10-21 06:53:53,174 - Epoch: [56][  100/  391]    Overall Loss 1.679335    Objective Loss 1.679335    Top1 78.187500    Top5 97.984375    LR 0.300000    Time 0.033873    
2018-10-21 06:53:54,855 - Epoch: [56][  150/  391]    Overall Loss 1.680370    Objective Loss 1.680370    Top1 78.130208    Top5 98.036458    LR 0.300000    Time 0.033774    
2018-10-21 06:53:56,450 - Epoch: [56][  200/  391]    Overall Loss 1.679108    Objective Loss 1.679108    Top1 78.296875    Top5 98.128906    LR 0.300000    Time 0.033296    
2018-10-21 06:53:58,013 - Epoch: [56][  250/  391]    Overall Loss 1.679626    Objective Loss 1.679626    Top1 78.246875    Top5 98.143750    LR 0.300000    Time 0.032882    
2018-10-21 06:53:59,621 - Epoch: [56][  300/  391]    Overall Loss 1.679689    Objective Loss 1.679689    Top1 78.226562    Top5 98.101562    LR 0.300000    Time 0.032754    
2018-10-21 06:54:01,199 - Epoch: [56][  350/  391]    Overall Loss 1.678555    Objective Loss 1.678555    Top1 78.334821    Top5 98.107143    LR 0.300000    Time 0.032577    
2018-10-21 06:54:02,618 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40832 | -0.00560 |    0.27285 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12683 | -0.00574 |    0.07643 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12631 | -0.00726 |    0.08729 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10785 | -0.00199 |    0.07092 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10672 | -0.01378 |    0.07434 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13112 | -0.00546 |    0.08796 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11986 | -0.01266 |    0.08585 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14594 | -0.00850 |    0.10748 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12368 | -0.00873 |    0.09473 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29570 | -0.01099 |    0.19761 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09235 | -0.00533 |    0.07102 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08237 | -0.01240 |    0.06517 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09790 | -0.00833 |    0.07440 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08098 | -0.00807 |    0.06160 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10818 | -0.00902 |    0.08534 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09519 | -0.00793 |    0.07462 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15107 | -0.01027 |    0.11608 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08882 | -0.01068 |    0.06816 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05516 | -0.00174 |    0.04090 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04678 | -0.00546 |    0.03486 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03240 |  0.00173 |    0.02123 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42578 | -0.00001 |    0.28693 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:54:02,619 - Total sparsity: 0.00

2018-10-21 06:54:02,619 - --- validate (epoch=56)-----------
2018-10-21 06:54:02,619 - 10000 samples (128 per mini-batch)
2018-10-21 06:54:03,872 - Epoch: [56][   50/   78]    Loss 1.713453    Top1 74.500000    Top5 97.437500    
2018-10-21 06:54:04,532 - ==> Top1: 74.650    Top5: 97.580    Loss: 1.713

2018-10-21 06:54:04,534 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:54:04,534 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:54:04,547 - 

2018-10-21 06:54:04,548 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:54:06,448 - Epoch: [57][   50/  391]    Overall Loss 1.676198    Objective Loss 1.676198    Top1 78.656250    Top5 98.250000    LR 0.300000    Time 0.037952    
2018-10-21 06:54:08,050 - Epoch: [57][  100/  391]    Overall Loss 1.680946    Objective Loss 1.680946    Top1 78.125000    Top5 98.281250    LR 0.300000    Time 0.034972    
2018-10-21 06:54:09,646 - Epoch: [57][  150/  391]    Overall Loss 1.681161    Objective Loss 1.681161    Top1 78.083333    Top5 98.286458    LR 0.300000    Time 0.033938    
2018-10-21 06:54:11,268 - Epoch: [57][  200/  391]    Overall Loss 1.680026    Objective Loss 1.680026    Top1 78.207031    Top5 98.242188    LR 0.300000    Time 0.033552    
2018-10-21 06:54:12,803 - Epoch: [57][  250/  391]    Overall Loss 1.680433    Objective Loss 1.680433    Top1 78.187500    Top5 98.171875    LR 0.300000    Time 0.032972    
2018-10-21 06:54:14,374 - Epoch: [57][  300/  391]    Overall Loss 1.679713    Objective Loss 1.679713    Top1 78.242188    Top5 98.125000    LR 0.300000    Time 0.032708    
2018-10-21 06:54:15,928 - Epoch: [57][  350/  391]    Overall Loss 1.681976    Objective Loss 1.681976    Top1 78.031250    Top5 98.080357    LR 0.300000    Time 0.032467    
2018-10-21 06:54:17,314 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40441 | -0.00742 |    0.27202 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12759 | -0.00384 |    0.07673 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12838 | -0.00531 |    0.08825 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10838 | -0.00388 |    0.07140 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10735 | -0.01183 |    0.07465 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13142 | -0.00772 |    0.08743 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12066 | -0.01295 |    0.08721 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14659 | -0.01021 |    0.10822 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12409 | -0.00764 |    0.09481 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29703 | -0.00939 |    0.19706 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09353 | -0.00379 |    0.07147 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08290 | -0.01245 |    0.06571 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09854 | -0.00838 |    0.07510 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08128 | -0.00787 |    0.06171 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10881 | -0.00734 |    0.08551 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09556 | -0.00724 |    0.07498 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15137 | -0.00996 |    0.11596 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08936 | -0.00995 |    0.06858 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05551 | -0.00127 |    0.04111 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04722 | -0.00499 |    0.03515 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03264 |  0.00188 |    0.02150 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42630 | -0.00001 |    0.28781 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:54:17,314 - Total sparsity: 0.00

2018-10-21 06:54:17,315 - --- validate (epoch=57)-----------
2018-10-21 06:54:17,315 - 10000 samples (128 per mini-batch)
2018-10-21 06:54:18,569 - Epoch: [57][   50/   78]    Loss 1.739116    Top1 71.953125    Top5 96.640625    
2018-10-21 06:54:19,237 - ==> Top1: 72.000    Top5: 96.800    Loss: 1.738

2018-10-21 06:54:19,239 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:54:19,239 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:54:19,251 - 

2018-10-21 06:54:19,252 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:54:20,989 - Epoch: [58][   50/  391]    Overall Loss 1.679731    Objective Loss 1.679731    Top1 78.281250    Top5 98.406250    LR 0.300000    Time 0.034677    
2018-10-21 06:54:22,599 - Epoch: [58][  100/  391]    Overall Loss 1.677360    Objective Loss 1.677360    Top1 78.578125    Top5 98.296875    LR 0.300000    Time 0.033420    
2018-10-21 06:54:24,204 - Epoch: [58][  150/  391]    Overall Loss 1.676807    Objective Loss 1.676807    Top1 78.598958    Top5 98.333333    LR 0.300000    Time 0.032960    
2018-10-21 06:54:25,781 - Epoch: [58][  200/  391]    Overall Loss 1.675199    Objective Loss 1.675199    Top1 78.761719    Top5 98.316406    LR 0.300000    Time 0.032596    
2018-10-21 06:54:27,449 - Epoch: [58][  250/  391]    Overall Loss 1.676889    Objective Loss 1.676889    Top1 78.584375    Top5 98.293750    LR 0.300000    Time 0.032742    
2018-10-21 06:54:29,054 - Epoch: [58][  300/  391]    Overall Loss 1.676345    Objective Loss 1.676345    Top1 78.664062    Top5 98.244792    LR 0.300000    Time 0.032627    
2018-10-21 06:54:30,658 - Epoch: [58][  350/  391]    Overall Loss 1.676319    Objective Loss 1.676319    Top1 78.651786    Top5 98.176339    LR 0.300000    Time 0.032541    
2018-10-21 06:54:32,082 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40751 |  0.00296 |    0.27105 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12864 | -0.00468 |    0.07729 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12943 | -0.00474 |    0.08849 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11043 | -0.00238 |    0.07240 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10878 | -0.01084 |    0.07513 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13130 | -0.00667 |    0.08786 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11969 | -0.01361 |    0.08616 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14740 | -0.00924 |    0.10898 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12423 | -0.00903 |    0.09496 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29651 | -0.01190 |    0.19337 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09371 | -0.00322 |    0.07173 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08324 | -0.01186 |    0.06596 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09849 | -0.00903 |    0.07538 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08117 | -0.00705 |    0.06144 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10894 | -0.00798 |    0.08566 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09579 | -0.00718 |    0.07506 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15194 | -0.01141 |    0.11589 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08973 | -0.01044 |    0.06896 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05579 | -0.00178 |    0.04123 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04759 | -0.00529 |    0.03535 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03268 |  0.00207 |    0.02145 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42745 | -0.00001 |    0.28829 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:54:32,083 - Total sparsity: 0.00

2018-10-21 06:54:32,083 - --- validate (epoch=58)-----------
2018-10-21 06:54:32,083 - 10000 samples (128 per mini-batch)
2018-10-21 06:54:33,309 - Epoch: [58][   50/   78]    Loss 1.739899    Top1 71.953125    Top5 96.265625    
2018-10-21 06:54:33,983 - ==> Top1: 71.460    Top5: 96.310    Loss: 1.745

2018-10-21 06:54:33,985 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:54:33,985 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:54:33,998 - 

2018-10-21 06:54:33,998 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:54:35,723 - Epoch: [59][   50/  391]    Overall Loss 1.685753    Objective Loss 1.685753    Top1 77.796875    Top5 97.937500    LR 0.300000    Time 0.034430    
2018-10-21 06:54:37,292 - Epoch: [59][  100/  391]    Overall Loss 1.681078    Objective Loss 1.681078    Top1 78.203125    Top5 98.203125    LR 0.300000    Time 0.032882    
2018-10-21 06:54:38,861 - Epoch: [59][  150/  391]    Overall Loss 1.678968    Objective Loss 1.678968    Top1 78.395833    Top5 98.125000    LR 0.300000    Time 0.032363    
2018-10-21 06:54:40,441 - Epoch: [59][  200/  391]    Overall Loss 1.679194    Objective Loss 1.679194    Top1 78.367188    Top5 98.117188    LR 0.300000    Time 0.032164    
2018-10-21 06:54:42,013 - Epoch: [59][  250/  391]    Overall Loss 1.679121    Objective Loss 1.679121    Top1 78.384375    Top5 98.159375    LR 0.300000    Time 0.032012    
2018-10-21 06:54:43,575 - Epoch: [59][  300/  391]    Overall Loss 1.679783    Objective Loss 1.679783    Top1 78.312500    Top5 98.130208    LR 0.300000    Time 0.031875    
2018-10-21 06:54:45,151 - Epoch: [59][  350/  391]    Overall Loss 1.681104    Objective Loss 1.681104    Top1 78.147321    Top5 98.120536    LR 0.300000    Time 0.031817    
2018-10-21 06:54:46,563 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40546 |  0.00916 |    0.26915 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12718 | -0.00555 |    0.07481 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12851 | -0.00187 |    0.08769 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11002 | -0.00325 |    0.07234 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10829 | -0.01150 |    0.07512 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13156 | -0.00477 |    0.08744 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11860 | -0.01533 |    0.08578 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14789 | -0.00930 |    0.10966 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12485 | -0.00777 |    0.09585 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29767 | -0.01086 |    0.19555 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09355 | -0.00410 |    0.07144 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08358 | -0.01255 |    0.06655 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09897 | -0.00835 |    0.07585 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08133 | -0.00817 |    0.06187 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10949 | -0.00882 |    0.08631 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09644 | -0.00706 |    0.07564 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15259 | -0.01227 |    0.11725 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09009 | -0.01060 |    0.06934 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05610 | -0.00167 |    0.04146 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04800 | -0.00527 |    0.03572 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03289 |  0.00190 |    0.02153 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42733 | -0.00001 |    0.28903 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:54:46,564 - Total sparsity: 0.00

2018-10-21 06:54:46,564 - --- validate (epoch=59)-----------
2018-10-21 06:54:46,564 - 10000 samples (128 per mini-batch)
2018-10-21 06:54:47,794 - Epoch: [59][   50/   78]    Loss 1.736998    Top1 72.343750    Top5 96.515625    
2018-10-21 06:54:48,444 - ==> Top1: 72.450    Top5: 96.470    Loss: 1.735

2018-10-21 06:54:48,445 - ==> Best Top1: 76.530   On Epoch: 41

2018-10-21 06:54:48,445 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:54:48,458 - 

2018-10-21 06:54:48,458 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:54:50,209 - Epoch: [60][   50/  391]    Overall Loss 1.680372    Objective Loss 1.680372    Top1 78.171875    Top5 98.140625    LR 0.300000    Time 0.034956    
2018-10-21 06:54:51,935 - Epoch: [60][  100/  391]    Overall Loss 1.678600    Objective Loss 1.678600    Top1 78.320312    Top5 98.210938    LR 0.300000    Time 0.034713    
2018-10-21 06:54:53,528 - Epoch: [60][  150/  391]    Overall Loss 1.674415    Objective Loss 1.674415    Top1 78.770833    Top5 98.171875    LR 0.300000    Time 0.033747    
2018-10-21 06:54:55,102 - Epoch: [60][  200/  391]    Overall Loss 1.674690    Objective Loss 1.674690    Top1 78.789062    Top5 98.238281    LR 0.300000    Time 0.033172    
2018-10-21 06:54:56,658 - Epoch: [60][  250/  391]    Overall Loss 1.674498    Objective Loss 1.674498    Top1 78.775000    Top5 98.290625    LR 0.300000    Time 0.032753    
2018-10-21 06:54:58,226 - Epoch: [60][  300/  391]    Overall Loss 1.676819    Objective Loss 1.676819    Top1 78.526042    Top5 98.273438    LR 0.300000    Time 0.032511    
2018-10-21 06:54:59,767 - Epoch: [60][  350/  391]    Overall Loss 1.676257    Objective Loss 1.676257    Top1 78.602679    Top5 98.232143    LR 0.300000    Time 0.032264    
2018-10-21 06:55:01,144 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40522 | -0.01633 |    0.26772 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12579 | -0.00620 |    0.07497 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12699 | -0.00327 |    0.08647 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11030 | -0.00289 |    0.07245 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10874 | -0.01107 |    0.07617 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13174 | -0.00602 |    0.08822 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11925 | -0.01427 |    0.08599 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14762 | -0.01004 |    0.10893 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12485 | -0.00752 |    0.09540 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29834 | -0.00991 |    0.19859 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09365 | -0.00420 |    0.07155 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08373 | -0.01259 |    0.06658 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09953 | -0.00828 |    0.07640 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08186 | -0.00822 |    0.06241 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10986 | -0.00822 |    0.08652 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09695 | -0.00697 |    0.07592 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15345 | -0.01126 |    0.11788 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09029 | -0.00993 |    0.06919 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05620 | -0.00184 |    0.04152 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04812 | -0.00528 |    0.03585 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03282 |  0.00181 |    0.02151 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42736 | -0.00001 |    0.28866 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:55:01,144 - Total sparsity: 0.00

2018-10-21 06:55:01,144 - --- validate (epoch=60)-----------
2018-10-21 06:55:01,144 - 10000 samples (128 per mini-batch)
2018-10-21 06:55:02,443 - Epoch: [60][   50/   78]    Loss 1.685717    Top1 77.234375    Top5 97.984375    
2018-10-21 06:55:03,086 - ==> Top1: 77.270    Top5: 98.140    Loss: 1.685

2018-10-21 06:55:03,088 - ==> Best Top1: 77.270   On Epoch: 60

2018-10-21 06:55:03,088 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:55:03,110 - 

2018-10-21 06:55:03,110 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:55:05,202 - Epoch: [61][   50/  391]    Overall Loss 1.679293    Objective Loss 1.679293    Top1 78.156250    Top5 98.109375    LR 0.300000    Time 0.041789    
2018-10-21 06:55:06,894 - Epoch: [61][  100/  391]    Overall Loss 1.674101    Objective Loss 1.674101    Top1 78.726562    Top5 98.093750    LR 0.300000    Time 0.037794    
2018-10-21 06:55:08,508 - Epoch: [61][  150/  391]    Overall Loss 1.674953    Objective Loss 1.674953    Top1 78.625000    Top5 98.098958    LR 0.300000    Time 0.035939    
2018-10-21 06:55:10,101 - Epoch: [61][  200/  391]    Overall Loss 1.672589    Objective Loss 1.672589    Top1 78.871094    Top5 98.132812    LR 0.300000    Time 0.034906    
2018-10-21 06:55:11,690 - Epoch: [61][  250/  391]    Overall Loss 1.676150    Objective Loss 1.676150    Top1 78.500000    Top5 98.150000    LR 0.300000    Time 0.034270    
2018-10-21 06:55:13,269 - Epoch: [61][  300/  391]    Overall Loss 1.676322    Objective Loss 1.676322    Top1 78.500000    Top5 98.195312    LR 0.300000    Time 0.033816    
2018-10-21 06:55:14,861 - Epoch: [61][  350/  391]    Overall Loss 1.675445    Objective Loss 1.675445    Top1 78.616071    Top5 98.196429    LR 0.300000    Time 0.033526    
2018-10-21 06:55:16,271 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39986 | -0.01110 |    0.26763 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12507 | -0.00562 |    0.07417 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12557 | -0.00491 |    0.08554 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10927 | -0.00266 |    0.07174 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10817 | -0.01187 |    0.07555 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13143 | -0.00531 |    0.08723 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11891 | -0.01531 |    0.08640 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14707 | -0.00894 |    0.10829 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12440 | -0.00745 |    0.09497 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29678 | -0.01294 |    0.19947 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09307 | -0.00434 |    0.07124 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08287 | -0.01259 |    0.06576 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09873 | -0.00800 |    0.07561 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08182 | -0.00771 |    0.06243 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10965 | -0.00840 |    0.08640 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09664 | -0.00685 |    0.07562 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15285 | -0.01140 |    0.11808 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08975 | -0.00967 |    0.06896 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05597 | -0.00201 |    0.04144 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04827 | -0.00561 |    0.03597 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03291 |  0.00155 |    0.02171 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42625 | -0.00001 |    0.28701 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:55:16,271 - Total sparsity: 0.00

2018-10-21 06:55:16,271 - --- validate (epoch=61)-----------
2018-10-21 06:55:16,271 - 10000 samples (128 per mini-batch)
2018-10-21 06:55:17,487 - Epoch: [61][   50/   78]    Loss 1.785775    Top1 67.421875    Top5 95.250000    
2018-10-21 06:55:18,121 - ==> Top1: 67.430    Top5: 95.550    Loss: 1.785

2018-10-21 06:55:18,122 - ==> Best Top1: 77.270   On Epoch: 60

2018-10-21 06:55:18,122 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:55:18,135 - 

2018-10-21 06:55:18,136 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:55:19,896 - Epoch: [62][   50/  391]    Overall Loss 1.675973    Objective Loss 1.675973    Top1 78.531250    Top5 98.015625    LR 0.300000    Time 0.035132    
2018-10-21 06:55:21,485 - Epoch: [62][  100/  391]    Overall Loss 1.670822    Objective Loss 1.670822    Top1 79.070312    Top5 98.257812    LR 0.300000    Time 0.033438    
2018-10-21 06:55:23,088 - Epoch: [62][  150/  391]    Overall Loss 1.675235    Objective Loss 1.675235    Top1 78.640625    Top5 98.223958    LR 0.300000    Time 0.032965    
2018-10-21 06:55:24,660 - Epoch: [62][  200/  391]    Overall Loss 1.677523    Objective Loss 1.677523    Top1 78.386719    Top5 98.265625    LR 0.300000    Time 0.032572    
2018-10-21 06:55:26,235 - Epoch: [62][  250/  391]    Overall Loss 1.676370    Objective Loss 1.676370    Top1 78.487500    Top5 98.256250    LR 0.300000    Time 0.032348    
2018-10-21 06:55:27,799 - Epoch: [62][  300/  391]    Overall Loss 1.675156    Objective Loss 1.675156    Top1 78.658854    Top5 98.299479    LR 0.300000    Time 0.032164    
2018-10-21 06:55:29,380 - Epoch: [62][  350/  391]    Overall Loss 1.674786    Objective Loss 1.674786    Top1 78.703125    Top5 98.316964    LR 0.300000    Time 0.032079    
2018-10-21 06:55:30,781 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40194 | -0.00024 |    0.26807 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12608 | -0.00254 |    0.07538 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12616 | -0.00506 |    0.08474 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10687 | -0.00300 |    0.07035 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10703 | -0.01044 |    0.07448 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13011 | -0.00727 |    0.08693 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11742 | -0.01546 |    0.08504 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14653 | -0.00866 |    0.10783 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12428 | -0.00720 |    0.09514 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29515 | -0.01413 |    0.19595 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09312 | -0.00290 |    0.07084 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08238 | -0.01276 |    0.06527 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09760 | -0.00969 |    0.07486 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08107 | -0.00825 |    0.06182 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10934 | -0.00851 |    0.08636 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09614 | -0.00673 |    0.07524 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15218 | -0.01207 |    0.11859 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08911 | -0.01033 |    0.06858 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05575 | -0.00189 |    0.04132 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04829 | -0.00594 |    0.03603 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03292 |  0.00172 |    0.02166 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42400 | -0.00001 |    0.28731 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:55:30,781 - Total sparsity: 0.00

2018-10-21 06:55:30,781 - --- validate (epoch=62)-----------
2018-10-21 06:55:30,781 - 10000 samples (128 per mini-batch)
2018-10-21 06:55:31,978 - Epoch: [62][   50/   78]    Loss 1.692724    Top1 76.656250    Top5 98.046875    
2018-10-21 06:55:32,615 - ==> Top1: 76.380    Top5: 98.170    Loss: 1.694

2018-10-21 06:55:32,617 - ==> Best Top1: 77.270   On Epoch: 60

2018-10-21 06:55:32,617 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:55:32,630 - 

2018-10-21 06:55:32,630 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:55:34,378 - Epoch: [63][   50/  391]    Overall Loss 1.672458    Objective Loss 1.672458    Top1 78.828125    Top5 98.312500    LR 0.300000    Time 0.034899    
2018-10-21 06:55:35,974 - Epoch: [63][  100/  391]    Overall Loss 1.670393    Objective Loss 1.670393    Top1 79.132812    Top5 98.335938    LR 0.300000    Time 0.033380    
2018-10-21 06:55:37,605 - Epoch: [63][  150/  391]    Overall Loss 1.673460    Objective Loss 1.673460    Top1 78.843750    Top5 98.286458    LR 0.300000    Time 0.033117    
2018-10-21 06:55:39,178 - Epoch: [63][  200/  391]    Overall Loss 1.672475    Objective Loss 1.672475    Top1 79.000000    Top5 98.277344    LR 0.300000    Time 0.032690    
2018-10-21 06:55:40,747 - Epoch: [63][  250/  391]    Overall Loss 1.672470    Objective Loss 1.672470    Top1 78.975000    Top5 98.215625    LR 0.300000    Time 0.032418    
2018-10-21 06:55:42,328 - Epoch: [63][  300/  391]    Overall Loss 1.673546    Objective Loss 1.673546    Top1 78.903646    Top5 98.239583    LR 0.300000    Time 0.032278    
2018-10-21 06:55:43,898 - Epoch: [63][  350/  391]    Overall Loss 1.675160    Objective Loss 1.675160    Top1 78.723214    Top5 98.236607    LR 0.300000    Time 0.032146    
2018-10-21 06:55:45,313 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40501 | -0.01034 |    0.27115 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12745 | -0.00352 |    0.07625 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12701 | -0.00523 |    0.08585 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10953 | -0.00302 |    0.07156 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10837 | -0.01314 |    0.07450 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13062 | -0.00549 |    0.08735 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11877 | -0.01708 |    0.08627 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14745 | -0.00593 |    0.10803 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12499 | -0.00778 |    0.09569 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29703 | -0.02174 |    0.19636 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09431 | -0.00381 |    0.07179 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08353 | -0.01161 |    0.06603 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09829 | -0.01054 |    0.07566 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08128 | -0.00799 |    0.06215 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10962 | -0.00885 |    0.08675 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09624 | -0.00674 |    0.07546 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15135 | -0.01181 |    0.11746 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08937 | -0.01075 |    0.06891 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05587 | -0.00196 |    0.04140 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04860 | -0.00556 |    0.03628 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03313 |  0.00196 |    0.02168 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42634 | -0.00001 |    0.28909 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:55:45,313 - Total sparsity: 0.00

2018-10-21 06:55:45,313 - --- validate (epoch=63)-----------
2018-10-21 06:55:45,313 - 10000 samples (128 per mini-batch)
2018-10-21 06:55:46,730 - Epoch: [63][   50/   78]    Loss 1.744402    Top1 71.828125    Top5 97.625000    
2018-10-21 06:55:47,399 - ==> Top1: 71.940    Top5: 97.750    Loss: 1.742

2018-10-21 06:55:47,401 - ==> Best Top1: 77.270   On Epoch: 60

2018-10-21 06:55:47,401 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:55:47,414 - 

2018-10-21 06:55:47,414 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:55:49,132 - Epoch: [64][   50/  391]    Overall Loss 1.669934    Objective Loss 1.669934    Top1 79.046875    Top5 98.593750    LR 0.300000    Time 0.034288    
2018-10-21 06:55:50,723 - Epoch: [64][  100/  391]    Overall Loss 1.668860    Objective Loss 1.668860    Top1 79.304688    Top5 98.562500    LR 0.300000    Time 0.033033    
2018-10-21 06:55:52,382 - Epoch: [64][  150/  391]    Overall Loss 1.668780    Objective Loss 1.668780    Top1 79.359375    Top5 98.541667    LR 0.300000    Time 0.033064    
2018-10-21 06:55:54,009 - Epoch: [64][  200/  391]    Overall Loss 1.673033    Objective Loss 1.673033    Top1 78.957031    Top5 98.375000    LR 0.300000    Time 0.032926    
2018-10-21 06:55:55,622 - Epoch: [64][  250/  391]    Overall Loss 1.672339    Objective Loss 1.672339    Top1 79.000000    Top5 98.412500    LR 0.300000    Time 0.032784    
2018-10-21 06:55:57,240 - Epoch: [64][  300/  391]    Overall Loss 1.671332    Objective Loss 1.671332    Top1 79.098958    Top5 98.375000    LR 0.300000    Time 0.032707    
2018-10-21 06:55:59,082 - Epoch: [64][  350/  391]    Overall Loss 1.672079    Objective Loss 1.672079    Top1 79.022321    Top5 98.383929    LR 0.300000    Time 0.033290    
2018-10-21 06:56:00,755 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40493 | -0.00402 |    0.26955 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12701 | -0.00377 |    0.07596 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12779 | -0.00475 |    0.08598 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10869 | -0.00203 |    0.07107 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10780 | -0.01066 |    0.07417 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13093 | -0.00679 |    0.08679 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11879 | -0.01551 |    0.08549 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14605 | -0.00824 |    0.10688 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12443 | -0.00747 |    0.09538 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29796 | -0.01321 |    0.19590 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09413 | -0.00360 |    0.07177 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08349 | -0.01129 |    0.06591 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09869 | -0.01088 |    0.07612 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08154 | -0.00794 |    0.06245 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10916 | -0.00917 |    0.08653 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09598 | -0.00636 |    0.07527 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15065 | -0.01116 |    0.11600 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08920 | -0.01116 |    0.06877 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05577 | -0.00174 |    0.04127 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04859 | -0.00522 |    0.03615 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03302 |  0.00176 |    0.02170 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42579 | -0.00001 |    0.28811 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:56:00,756 - Total sparsity: 0.00

2018-10-21 06:56:00,756 - --- validate (epoch=64)-----------
2018-10-21 06:56:00,756 - 10000 samples (128 per mini-batch)
2018-10-21 06:56:02,138 - Epoch: [64][   50/   78]    Loss 1.681841    Top1 77.906250    Top5 98.109375    
2018-10-21 06:56:02,794 - ==> Top1: 78.360    Top5: 98.190    Loss: 1.677

2018-10-21 06:56:02,796 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:56:02,796 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:56:02,812 - 

2018-10-21 06:56:02,813 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:56:04,603 - Epoch: [65][   50/  391]    Overall Loss 1.674909    Objective Loss 1.674909    Top1 78.796875    Top5 98.187500    LR 0.300000    Time 0.035748    
2018-10-21 06:56:06,222 - Epoch: [65][  100/  391]    Overall Loss 1.672143    Objective Loss 1.672143    Top1 78.953125    Top5 98.226562    LR 0.300000    Time 0.034040    
2018-10-21 06:56:07,814 - Epoch: [65][  150/  391]    Overall Loss 1.669137    Objective Loss 1.669137    Top1 79.291667    Top5 98.213542    LR 0.300000    Time 0.033291    
2018-10-21 06:56:09,389 - Epoch: [65][  200/  391]    Overall Loss 1.671550    Objective Loss 1.671550    Top1 79.070312    Top5 98.269531    LR 0.300000    Time 0.032831    
2018-10-21 06:56:10,978 - Epoch: [65][  250/  391]    Overall Loss 1.672643    Objective Loss 1.672643    Top1 78.993750    Top5 98.228125    LR 0.300000    Time 0.032615    
2018-10-21 06:56:12,543 - Epoch: [65][  300/  391]    Overall Loss 1.672721    Objective Loss 1.672721    Top1 78.984375    Top5 98.273438    LR 0.300000    Time 0.032389    
2018-10-21 06:56:14,106 - Epoch: [65][  350/  391]    Overall Loss 1.673141    Objective Loss 1.673141    Top1 78.948661    Top5 98.281250    LR 0.300000    Time 0.032221    
2018-10-21 06:56:15,476 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40251 | -0.01354 |    0.26954 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12592 | -0.00274 |    0.07516 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12719 | -0.00626 |    0.08531 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10807 | -0.00261 |    0.07060 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10727 | -0.01135 |    0.07397 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13065 | -0.00631 |    0.08755 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11808 | -0.01401 |    0.08444 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14536 | -0.00932 |    0.10714 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12431 | -0.00909 |    0.09487 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29672 | -0.01314 |    0.19648 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09453 | -0.00384 |    0.07212 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08363 | -0.01168 |    0.06594 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09814 | -0.01067 |    0.07538 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08079 | -0.00781 |    0.06163 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10936 | -0.00853 |    0.08649 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09579 | -0.00674 |    0.07519 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15022 | -0.01261 |    0.11573 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08910 | -0.01115 |    0.06871 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05575 | -0.00217 |    0.04131 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04845 | -0.00537 |    0.03601 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03304 |  0.00174 |    0.02170 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42647 | -0.00001 |    0.28896 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:56:15,476 - Total sparsity: 0.00

2018-10-21 06:56:15,476 - --- validate (epoch=65)-----------
2018-10-21 06:56:15,476 - 10000 samples (128 per mini-batch)
2018-10-21 06:56:16,756 - Epoch: [65][   50/   78]    Loss 1.738821    Top1 72.109375    Top5 96.984375    
2018-10-21 06:56:17,413 - ==> Top1: 72.280    Top5: 97.000    Loss: 1.737

2018-10-21 06:56:17,415 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:56:17,415 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:56:17,427 - 

2018-10-21 06:56:17,428 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:56:19,183 - Epoch: [66][   50/  391]    Overall Loss 1.665647    Objective Loss 1.665647    Top1 79.687500    Top5 98.328125    LR 0.300000    Time 0.035037    
2018-10-21 06:56:20,752 - Epoch: [66][  100/  391]    Overall Loss 1.662665    Objective Loss 1.662665    Top1 79.960938    Top5 98.179688    LR 0.300000    Time 0.033188    
2018-10-21 06:56:22,621 - Epoch: [66][  150/  391]    Overall Loss 1.662052    Objective Loss 1.662052    Top1 80.041667    Top5 98.203125    LR 0.300000    Time 0.034571    
2018-10-21 06:56:24,493 - Epoch: [66][  200/  391]    Overall Loss 1.666178    Objective Loss 1.666178    Top1 79.640625    Top5 98.164062    LR 0.300000    Time 0.035277    
2018-10-21 06:56:26,378 - Epoch: [66][  250/  391]    Overall Loss 1.669064    Objective Loss 1.669064    Top1 79.334375    Top5 98.196875    LR 0.300000    Time 0.035756    
2018-10-21 06:56:28,138 - Epoch: [66][  300/  391]    Overall Loss 1.669219    Objective Loss 1.669219    Top1 79.294271    Top5 98.218750    LR 0.300000    Time 0.035655    
2018-10-21 06:56:29,709 - Epoch: [66][  350/  391]    Overall Loss 1.671745    Objective Loss 1.671745    Top1 79.046875    Top5 98.214286    LR 0.300000    Time 0.035044    
2018-10-21 06:56:31,096 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40082 |  0.00297 |    0.26609 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12658 | -0.00315 |    0.07520 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12829 | -0.00418 |    0.08559 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10832 | -0.00519 |    0.07069 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10762 | -0.00779 |    0.07408 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13003 | -0.00578 |    0.08629 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11830 | -0.01495 |    0.08432 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14560 | -0.00883 |    0.10680 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12441 | -0.00793 |    0.09494 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29586 | -0.01411 |    0.19389 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09525 | -0.00370 |    0.07222 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08405 | -0.01217 |    0.06620 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09833 | -0.00992 |    0.07548 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08086 | -0.00783 |    0.06229 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10962 | -0.00867 |    0.08660 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09601 | -0.00687 |    0.07546 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14944 | -0.01361 |    0.11511 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08926 | -0.01051 |    0.06898 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05605 | -0.00183 |    0.04152 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04879 | -0.00590 |    0.03639 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03333 |  0.00180 |    0.02180 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42933 | -0.00001 |    0.29130 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:56:31,097 - Total sparsity: 0.00

2018-10-21 06:56:31,097 - --- validate (epoch=66)-----------
2018-10-21 06:56:31,097 - 10000 samples (128 per mini-batch)
2018-10-21 06:56:32,503 - Epoch: [66][   50/   78]    Loss 1.736833    Top1 72.203125    Top5 96.312500    
2018-10-21 06:56:33,173 - ==> Top1: 72.170    Top5: 96.270    Loss: 1.738

2018-10-21 06:56:33,175 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:56:33,175 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:56:33,188 - 

2018-10-21 06:56:33,188 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:56:34,991 - Epoch: [67][   50/  391]    Overall Loss 1.666417    Objective Loss 1.666417    Top1 79.734375    Top5 98.593750    LR 0.300000    Time 0.036005    
2018-10-21 06:56:36,566 - Epoch: [67][  100/  391]    Overall Loss 1.675878    Objective Loss 1.675878    Top1 78.640625    Top5 98.195312    LR 0.300000    Time 0.033722    
2018-10-21 06:56:38,210 - Epoch: [67][  150/  391]    Overall Loss 1.679247    Objective Loss 1.679247    Top1 78.302083    Top5 98.104167    LR 0.300000    Time 0.033433    
2018-10-21 06:56:39,818 - Epoch: [67][  200/  391]    Overall Loss 1.678314    Objective Loss 1.678314    Top1 78.343750    Top5 98.164062    LR 0.300000    Time 0.033101    
2018-10-21 06:56:41,498 - Epoch: [67][  250/  391]    Overall Loss 1.677238    Objective Loss 1.677238    Top1 78.462500    Top5 98.203125    LR 0.300000    Time 0.033194    
2018-10-21 06:56:43,071 - Epoch: [67][  300/  391]    Overall Loss 1.676360    Objective Loss 1.676360    Top1 78.565104    Top5 98.226562    LR 0.300000    Time 0.032896    
2018-10-21 06:56:44,653 - Epoch: [67][  350/  391]    Overall Loss 1.676484    Objective Loss 1.676484    Top1 78.531250    Top5 98.225446    LR 0.300000    Time 0.032709    
2018-10-21 06:56:46,106 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40004 | -0.00184 |    0.26866 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12592 | -0.00306 |    0.07502 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12851 | -0.00449 |    0.08527 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10933 | -0.00539 |    0.07086 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10810 | -0.00920 |    0.07351 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13047 | -0.00676 |    0.08742 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11872 | -0.01509 |    0.08508 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14623 | -0.00723 |    0.10777 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12478 | -0.00677 |    0.09516 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29709 | -0.01486 |    0.19597 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09569 | -0.00383 |    0.07269 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08452 | -0.01199 |    0.06673 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09897 | -0.00932 |    0.07587 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08115 | -0.00884 |    0.06256 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11007 | -0.00786 |    0.08672 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09667 | -0.00662 |    0.07609 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15044 | -0.01257 |    0.11562 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08950 | -0.01088 |    0.06915 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05637 | -0.00175 |    0.04178 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04926 | -0.00572 |    0.03677 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03343 |  0.00218 |    0.02192 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42762 | -0.00001 |    0.28954 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:56:46,106 - Total sparsity: 0.00

2018-10-21 06:56:46,106 - --- validate (epoch=67)-----------
2018-10-21 06:56:46,106 - 10000 samples (128 per mini-batch)
2018-10-21 06:56:47,356 - Epoch: [67][   50/   78]    Loss 1.782114    Top1 67.921875    Top5 97.546875    
2018-10-21 06:56:48,024 - ==> Top1: 67.010    Top5: 97.360    Loss: 1.790

2018-10-21 06:56:48,026 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:56:48,026 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:56:48,039 - 

2018-10-21 06:56:48,039 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:56:49,899 - Epoch: [68][   50/  391]    Overall Loss 1.677717    Objective Loss 1.677717    Top1 78.453125    Top5 98.140625    LR 0.300000    Time 0.037144    
2018-10-21 06:56:51,570 - Epoch: [68][  100/  391]    Overall Loss 1.681963    Objective Loss 1.681963    Top1 78.078125    Top5 98.085938    LR 0.300000    Time 0.035263    
2018-10-21 06:56:53,194 - Epoch: [68][  150/  391]    Overall Loss 1.681147    Objective Loss 1.681147    Top1 78.182292    Top5 98.135417    LR 0.300000    Time 0.034318    
2018-10-21 06:56:54,858 - Epoch: [68][  200/  391]    Overall Loss 1.676769    Objective Loss 1.676769    Top1 78.589844    Top5 98.253906    LR 0.300000    Time 0.034047    
2018-10-21 06:56:56,416 - Epoch: [68][  250/  391]    Overall Loss 1.677083    Objective Loss 1.677083    Top1 78.587500    Top5 98.225000    LR 0.300000    Time 0.033460    
2018-10-21 06:56:57,980 - Epoch: [68][  300/  391]    Overall Loss 1.677009    Objective Loss 1.677009    Top1 78.578125    Top5 98.223958    LR 0.300000    Time 0.033090    
2018-10-21 06:56:59,551 - Epoch: [68][  350/  391]    Overall Loss 1.675225    Objective Loss 1.675225    Top1 78.765625    Top5 98.245536    LR 0.300000    Time 0.032844    
2018-10-21 06:57:00,956 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39891 | -0.01458 |    0.26421 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12601 | -0.00462 |    0.07382 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12830 | -0.00447 |    0.08436 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10885 | -0.00498 |    0.07163 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10829 | -0.00985 |    0.07365 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12995 | -0.00477 |    0.08770 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11812 | -0.01589 |    0.08488 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14558 | -0.00999 |    0.10739 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12398 | -0.00865 |    0.09470 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29468 | -0.01343 |    0.19507 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09535 | -0.00450 |    0.07216 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08390 | -0.01165 |    0.06638 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09855 | -0.00934 |    0.07576 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08086 | -0.00879 |    0.06235 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10914 | -0.00785 |    0.08602 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09614 | -0.00686 |    0.07559 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14988 | -0.01266 |    0.11449 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08937 | -0.01033 |    0.06898 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05645 | -0.00255 |    0.04183 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04951 | -0.00589 |    0.03703 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03354 |  0.00181 |    0.02205 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42935 | -0.00001 |    0.29094 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:57:00,956 - Total sparsity: 0.00

2018-10-21 06:57:00,956 - --- validate (epoch=68)-----------
2018-10-21 06:57:00,956 - 10000 samples (128 per mini-batch)
2018-10-21 06:57:02,213 - Epoch: [68][   50/   78]    Loss 1.758426    Top1 70.125000    Top5 96.453125    
2018-10-21 06:57:02,884 - ==> Top1: 69.930    Top5: 96.590    Loss: 1.761

2018-10-21 06:57:02,885 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:57:02,886 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:57:02,898 - 

2018-10-21 06:57:02,899 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:57:04,549 - Epoch: [69][   50/  391]    Overall Loss 1.657575    Objective Loss 1.657575    Top1 80.625000    Top5 98.265625    LR 0.300000    Time 0.032951    
2018-10-21 06:57:06,120 - Epoch: [69][  100/  391]    Overall Loss 1.664416    Objective Loss 1.664416    Top1 79.812500    Top5 98.351562    LR 0.300000    Time 0.032156    
2018-10-21 06:57:07,725 - Epoch: [69][  150/  391]    Overall Loss 1.670000    Objective Loss 1.670000    Top1 79.276042    Top5 98.328125    LR 0.300000    Time 0.032124    
2018-10-21 06:57:09,317 - Epoch: [69][  200/  391]    Overall Loss 1.670542    Objective Loss 1.670542    Top1 79.238281    Top5 98.316406    LR 0.300000    Time 0.032042    
2018-10-21 06:57:10,874 - Epoch: [69][  250/  391]    Overall Loss 1.671353    Objective Loss 1.671353    Top1 79.168750    Top5 98.265625    LR 0.300000    Time 0.031856    
2018-10-21 06:57:12,445 - Epoch: [69][  300/  391]    Overall Loss 1.671432    Objective Loss 1.671432    Top1 79.192708    Top5 98.325521    LR 0.300000    Time 0.031774    
2018-10-21 06:57:14,009 - Epoch: [69][  350/  391]    Overall Loss 1.673652    Objective Loss 1.673652    Top1 78.939732    Top5 98.254464    LR 0.300000    Time 0.031698    
2018-10-21 06:57:15,436 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39627 | -0.01171 |    0.26198 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12548 | -0.00460 |    0.07366 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12779 | -0.00584 |    0.08449 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10847 | -0.00296 |    0.07163 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10885 | -0.00945 |    0.07418 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13025 | -0.00549 |    0.08759 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11796 | -0.01530 |    0.08444 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14530 | -0.01005 |    0.10736 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12381 | -0.00769 |    0.09418 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29383 | -0.01721 |    0.19494 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09497 | -0.00497 |    0.07172 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08322 | -0.01145 |    0.06575 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09876 | -0.00869 |    0.07548 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08060 | -0.01003 |    0.06218 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10937 | -0.00821 |    0.08623 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09651 | -0.00672 |    0.07583 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14888 | -0.01286 |    0.11363 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08930 | -0.01087 |    0.06902 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05662 | -0.00227 |    0.04187 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04981 | -0.00589 |    0.03716 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03376 |  0.00158 |    0.02215 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42917 | -0.00001 |    0.29032 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:57:15,436 - Total sparsity: 0.00

2018-10-21 06:57:15,436 - --- validate (epoch=69)-----------
2018-10-21 06:57:15,437 - 10000 samples (128 per mini-batch)
2018-10-21 06:57:16,615 - Epoch: [69][   50/   78]    Loss 1.767592    Top1 69.296875    Top5 97.312500    
2018-10-21 06:57:17,252 - ==> Top1: 69.140    Top5: 97.400    Loss: 1.767

2018-10-21 06:57:17,254 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:57:17,254 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:57:17,266 - 

2018-10-21 06:57:17,267 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:57:19,055 - Epoch: [70][   50/  391]    Overall Loss 1.670659    Objective Loss 1.670659    Top1 79.203125    Top5 98.328125    LR 0.300000    Time 0.035716    
2018-10-21 06:57:20,620 - Epoch: [70][  100/  391]    Overall Loss 1.671613    Objective Loss 1.671613    Top1 79.140625    Top5 98.398438    LR 0.300000    Time 0.033483    
2018-10-21 06:57:22,239 - Epoch: [70][  150/  391]    Overall Loss 1.672120    Objective Loss 1.672120    Top1 79.125000    Top5 98.364583    LR 0.300000    Time 0.033097    
2018-10-21 06:57:23,829 - Epoch: [70][  200/  391]    Overall Loss 1.673009    Objective Loss 1.673009    Top1 79.019531    Top5 98.343750    LR 0.300000    Time 0.032765    
2018-10-21 06:57:25,355 - Epoch: [70][  250/  391]    Overall Loss 1.672711    Objective Loss 1.672711    Top1 79.059375    Top5 98.359375    LR 0.300000    Time 0.032307    
2018-10-21 06:57:26,891 - Epoch: [70][  300/  391]    Overall Loss 1.672839    Objective Loss 1.672839    Top1 79.033854    Top5 98.296875    LR 0.300000    Time 0.032037    
2018-10-21 06:57:28,406 - Epoch: [70][  350/  391]    Overall Loss 1.673175    Objective Loss 1.673175    Top1 78.968750    Top5 98.316964    LR 0.300000    Time 0.031780    
2018-10-21 06:57:29,804 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40466 | -0.00384 |    0.26536 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12813 | -0.00213 |    0.07579 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13077 | -0.00546 |    0.08546 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10853 | -0.00247 |    0.07158 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10952 | -0.01070 |    0.07480 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12982 | -0.00570 |    0.08652 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11699 | -0.01514 |    0.08375 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14625 | -0.00909 |    0.10830 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12381 | -0.00906 |    0.09483 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29338 | -0.01738 |    0.19620 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09497 | -0.00370 |    0.07162 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08306 | -0.01192 |    0.06548 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09815 | -0.00796 |    0.07504 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08041 | -0.00882 |    0.06164 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10953 | -0.00785 |    0.08615 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09646 | -0.00675 |    0.07587 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14848 | -0.01323 |    0.11311 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08915 | -0.01123 |    0.06864 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05654 | -0.00274 |    0.04178 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04988 | -0.00585 |    0.03719 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03370 |  0.00173 |    0.02207 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42804 | -0.00001 |    0.28933 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:57:29,805 - Total sparsity: 0.00

2018-10-21 06:57:29,805 - --- validate (epoch=70)-----------
2018-10-21 06:57:29,805 - 10000 samples (128 per mini-batch)
2018-10-21 06:57:31,027 - Epoch: [70][   50/   78]    Loss 1.734386    Top1 72.593750    Top5 96.656250    
2018-10-21 06:57:31,679 - ==> Top1: 72.270    Top5: 96.740    Loss: 1.737

2018-10-21 06:57:31,681 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:57:31,681 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:57:31,694 - 

2018-10-21 06:57:31,694 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:57:33,508 - Epoch: [71][   50/  391]    Overall Loss 1.671217    Objective Loss 1.671217    Top1 78.906250    Top5 98.687500    LR 0.300000    Time 0.036206    
2018-10-21 06:57:35,161 - Epoch: [71][  100/  391]    Overall Loss 1.670795    Objective Loss 1.670795    Top1 79.101562    Top5 98.492188    LR 0.300000    Time 0.034616    
2018-10-21 06:57:36,756 - Epoch: [71][  150/  391]    Overall Loss 1.673473    Objective Loss 1.673473    Top1 78.916667    Top5 98.432292    LR 0.300000    Time 0.033698    
2018-10-21 06:57:38,326 - Epoch: [71][  200/  391]    Overall Loss 1.672383    Objective Loss 1.672383    Top1 79.054688    Top5 98.425781    LR 0.300000    Time 0.033113    
2018-10-21 06:57:39,899 - Epoch: [71][  250/  391]    Overall Loss 1.673265    Objective Loss 1.673265    Top1 78.975000    Top5 98.387500    LR 0.300000    Time 0.032773    
2018-10-21 06:57:41,473 - Epoch: [71][  300/  391]    Overall Loss 1.673191    Objective Loss 1.673191    Top1 78.940104    Top5 98.408854    LR 0.300000    Time 0.032547    
2018-10-21 06:57:43,041 - Epoch: [71][  350/  391]    Overall Loss 1.673235    Objective Loss 1.673235    Top1 78.939732    Top5 98.352679    LR 0.300000    Time 0.032374    
2018-10-21 06:57:44,457 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40260 | -0.00550 |    0.26724 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12919 |  0.00008 |    0.07625 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13056 | -0.00135 |    0.08572 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10971 | -0.00261 |    0.07172 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11047 | -0.00740 |    0.07451 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13101 | -0.00626 |    0.08739 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11796 | -0.01329 |    0.08394 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14598 | -0.00725 |    0.10779 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12381 | -0.00797 |    0.09482 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29268 | -0.00901 |    0.19588 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09474 | -0.00471 |    0.07172 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08323 | -0.01113 |    0.06573 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09782 | -0.00870 |    0.07501 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08010 | -0.00862 |    0.06124 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10955 | -0.00785 |    0.08635 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09641 | -0.00614 |    0.07569 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14807 | -0.01367 |    0.11231 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08880 | -0.01169 |    0.06847 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05652 | -0.00279 |    0.04176 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04992 | -0.00569 |    0.03728 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03370 |  0.00195 |    0.02208 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42816 | -0.00001 |    0.28866 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:57:44,457 - Total sparsity: 0.00

2018-10-21 06:57:44,457 - --- validate (epoch=71)-----------
2018-10-21 06:57:44,457 - 10000 samples (128 per mini-batch)
2018-10-21 06:57:45,677 - Epoch: [71][   50/   78]    Loss 1.733201    Top1 72.750000    Top5 97.515625    
2018-10-21 06:57:46,338 - ==> Top1: 72.550    Top5: 97.630    Loss: 1.734

2018-10-21 06:57:46,339 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:57:46,339 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:57:46,352 - 

2018-10-21 06:57:46,352 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:57:48,226 - Epoch: [72][   50/  391]    Overall Loss 1.670430    Objective Loss 1.670430    Top1 79.218750    Top5 98.250000    LR 0.300000    Time 0.037424    
2018-10-21 06:57:49,979 - Epoch: [72][  100/  391]    Overall Loss 1.671928    Objective Loss 1.671928    Top1 79.093750    Top5 98.359375    LR 0.300000    Time 0.036213    
2018-10-21 06:57:51,697 - Epoch: [72][  150/  391]    Overall Loss 1.670331    Objective Loss 1.670331    Top1 79.270833    Top5 98.401042    LR 0.300000    Time 0.035584    
2018-10-21 06:57:53,418 - Epoch: [72][  200/  391]    Overall Loss 1.672303    Objective Loss 1.672303    Top1 79.093750    Top5 98.304688    LR 0.300000    Time 0.035282    
2018-10-21 06:57:55,143 - Epoch: [72][  250/  391]    Overall Loss 1.671451    Objective Loss 1.671451    Top1 79.181250    Top5 98.309375    LR 0.300000    Time 0.035116    
2018-10-21 06:57:56,853 - Epoch: [72][  300/  391]    Overall Loss 1.671479    Objective Loss 1.671479    Top1 79.151042    Top5 98.315104    LR 0.300000    Time 0.034956    
2018-10-21 06:57:58,581 - Epoch: [72][  350/  391]    Overall Loss 1.672807    Objective Loss 1.672807    Top1 79.011161    Top5 98.287946    LR 0.300000    Time 0.034892    
2018-10-21 06:58:00,095 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40249 | -0.00604 |    0.26406 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13260 | -0.00204 |    0.07801 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13202 |  0.00032 |    0.08718 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11122 | -0.00314 |    0.07229 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11130 | -0.00599 |    0.07510 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13213 | -0.00659 |    0.08898 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11788 | -0.01756 |    0.08400 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14731 | -0.00720 |    0.10843 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12520 | -0.00710 |    0.09609 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29548 | -0.01237 |    0.19624 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09505 | -0.00484 |    0.07221 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08379 | -0.01115 |    0.06615 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09851 | -0.01024 |    0.07592 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08003 | -0.00897 |    0.06125 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11061 | -0.00760 |    0.08729 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09697 | -0.00641 |    0.07620 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14928 | -0.01395 |    0.11325 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08906 | -0.01247 |    0.06881 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05690 | -0.00240 |    0.04196 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05015 | -0.00618 |    0.03756 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03376 |  0.00186 |    0.02203 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42939 | -0.00001 |    0.28969 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:58:00,096 - Total sparsity: 0.00

2018-10-21 06:58:00,096 - --- validate (epoch=72)-----------
2018-10-21 06:58:00,096 - 10000 samples (128 per mini-batch)
2018-10-21 06:58:01,460 - Epoch: [72][   50/   78]    Loss 1.707811    Top1 75.468750    Top5 97.453125    
2018-10-21 06:58:02,129 - ==> Top1: 74.910    Top5: 97.460    Loss: 1.713

2018-10-21 06:58:02,131 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:58:02,131 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:58:02,144 - 

2018-10-21 06:58:02,144 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:58:03,908 - Epoch: [73][   50/  391]    Overall Loss 1.678395    Objective Loss 1.678395    Top1 78.531250    Top5 98.343750    LR 0.300000    Time 0.035212    
2018-10-21 06:58:05,486 - Epoch: [73][  100/  391]    Overall Loss 1.679353    Objective Loss 1.679353    Top1 78.375000    Top5 98.226562    LR 0.300000    Time 0.033363    
2018-10-21 06:58:07,056 - Epoch: [73][  150/  391]    Overall Loss 1.679276    Objective Loss 1.679276    Top1 78.302083    Top5 98.229167    LR 0.300000    Time 0.032698    
2018-10-21 06:58:08,613 - Epoch: [73][  200/  391]    Overall Loss 1.677433    Objective Loss 1.677433    Top1 78.457031    Top5 98.269531    LR 0.300000    Time 0.032297    
2018-10-21 06:58:10,171 - Epoch: [73][  250/  391]    Overall Loss 1.675908    Objective Loss 1.675908    Top1 78.646875    Top5 98.296875    LR 0.300000    Time 0.032061    
2018-10-21 06:58:11,726 - Epoch: [73][  300/  391]    Overall Loss 1.674571    Objective Loss 1.674571    Top1 78.789062    Top5 98.289062    LR 0.300000    Time 0.031892    
2018-10-21 06:58:13,365 - Epoch: [73][  350/  391]    Overall Loss 1.673391    Objective Loss 1.673391    Top1 78.917411    Top5 98.296875    LR 0.300000    Time 0.032012    
2018-10-21 06:58:14,774 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40506 | -0.00816 |    0.26904 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13242 | -0.00245 |    0.07759 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13249 | -0.00094 |    0.08754 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11104 | -0.00357 |    0.07169 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10992 | -0.00785 |    0.07447 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13219 | -0.00519 |    0.08881 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11754 | -0.01563 |    0.08325 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14728 | -0.00749 |    0.10914 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12521 | -0.00815 |    0.09631 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29624 | -0.01115 |    0.19381 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09457 | -0.00467 |    0.07161 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08379 | -0.01086 |    0.06607 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09893 | -0.00983 |    0.07591 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08033 | -0.00833 |    0.06182 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11111 | -0.00828 |    0.08775 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09726 | -0.00637 |    0.07634 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15049 | -0.01310 |    0.11414 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08936 | -0.01182 |    0.06886 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05692 | -0.00282 |    0.04199 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05050 | -0.00605 |    0.03777 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03375 |  0.00177 |    0.02206 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42942 | -0.00001 |    0.29024 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:58:14,775 - Total sparsity: 0.00

2018-10-21 06:58:14,775 - --- validate (epoch=73)-----------
2018-10-21 06:58:14,775 - 10000 samples (128 per mini-batch)
2018-10-21 06:58:15,957 - Epoch: [73][   50/   78]    Loss 1.688534    Top1 77.031250    Top5 98.484375    
2018-10-21 06:58:16,565 - ==> Top1: 77.060    Top5: 98.430    Loss: 1.689

2018-10-21 06:58:16,567 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:58:16,567 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:58:16,580 - 

2018-10-21 06:58:16,580 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:58:18,314 - Epoch: [74][   50/  391]    Overall Loss 1.658183    Objective Loss 1.658183    Top1 80.343750    Top5 98.500000    LR 0.300000    Time 0.034621    
2018-10-21 06:58:19,906 - Epoch: [74][  100/  391]    Overall Loss 1.661794    Objective Loss 1.661794    Top1 80.085938    Top5 98.375000    LR 0.300000    Time 0.033203    
2018-10-21 06:58:21,550 - Epoch: [74][  150/  391]    Overall Loss 1.666191    Objective Loss 1.666191    Top1 79.593750    Top5 98.359375    LR 0.300000    Time 0.033085    
2018-10-21 06:58:23,137 - Epoch: [74][  200/  391]    Overall Loss 1.667107    Objective Loss 1.667107    Top1 79.503906    Top5 98.390625    LR 0.300000    Time 0.032738    
2018-10-21 06:58:24,729 - Epoch: [74][  250/  391]    Overall Loss 1.668589    Objective Loss 1.668589    Top1 79.412500    Top5 98.343750    LR 0.300000    Time 0.032548    
2018-10-21 06:58:26,318 - Epoch: [74][  300/  391]    Overall Loss 1.670529    Objective Loss 1.670529    Top1 79.192708    Top5 98.273438    LR 0.300000    Time 0.032413    
2018-10-21 06:58:27,908 - Epoch: [74][  350/  391]    Overall Loss 1.671948    Objective Loss 1.671948    Top1 79.033482    Top5 98.258929    LR 0.300000    Time 0.032320    
2018-10-21 06:58:29,320 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40439 |  0.00798 |    0.26835 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13335 | -0.00272 |    0.07807 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13227 | -0.00066 |    0.08719 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10985 | -0.00300 |    0.07083 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10855 | -0.00742 |    0.07365 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13093 | -0.00770 |    0.08766 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11775 | -0.01677 |    0.08388 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14724 | -0.00841 |    0.10932 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12484 | -0.00831 |    0.09583 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29837 | -0.00719 |    0.19701 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09489 | -0.00507 |    0.07140 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08372 | -0.01072 |    0.06629 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09925 | -0.01011 |    0.07618 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08068 | -0.00850 |    0.06214 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11111 | -0.00886 |    0.08776 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09713 | -0.00620 |    0.07616 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15044 | -0.01215 |    0.11442 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08908 | -0.01232 |    0.06886 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05676 | -0.00280 |    0.04189 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05043 | -0.00572 |    0.03771 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03370 |  0.00179 |    0.02209 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42633 | -0.00001 |    0.28828 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:58:29,320 - Total sparsity: 0.00

2018-10-21 06:58:29,320 - --- validate (epoch=74)-----------
2018-10-21 06:58:29,320 - 10000 samples (128 per mini-batch)
2018-10-21 06:58:30,519 - Epoch: [74][   50/   78]    Loss 1.679512    Top1 77.968750    Top5 98.046875    
2018-10-21 06:58:31,176 - ==> Top1: 77.750    Top5: 98.100    Loss: 1.682

2018-10-21 06:58:31,177 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:58:31,178 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:58:31,190 - 

2018-10-21 06:58:31,191 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:58:32,941 - Epoch: [75][   50/  391]    Overall Loss 1.664265    Objective Loss 1.664265    Top1 79.734375    Top5 98.218750    LR 0.300000    Time 0.034941    
2018-10-21 06:58:34,549 - Epoch: [75][  100/  391]    Overall Loss 1.666454    Objective Loss 1.666454    Top1 79.640625    Top5 98.328125    LR 0.300000    Time 0.033522    
2018-10-21 06:58:36,152 - Epoch: [75][  150/  391]    Overall Loss 1.667476    Objective Loss 1.667476    Top1 79.489583    Top5 98.265625    LR 0.300000    Time 0.033020    
2018-10-21 06:58:37,700 - Epoch: [75][  200/  391]    Overall Loss 1.666472    Objective Loss 1.666472    Top1 79.636719    Top5 98.253906    LR 0.300000    Time 0.032495    
2018-10-21 06:58:39,439 - Epoch: [75][  250/  391]    Overall Loss 1.668247    Objective Loss 1.668247    Top1 79.409375    Top5 98.237500    LR 0.300000    Time 0.032944    
2018-10-21 06:58:41,203 - Epoch: [75][  300/  391]    Overall Loss 1.668346    Objective Loss 1.668346    Top1 79.406250    Top5 98.239583    LR 0.300000    Time 0.033326    
2018-10-21 06:58:42,943 - Epoch: [75][  350/  391]    Overall Loss 1.669104    Objective Loss 1.669104    Top1 79.310268    Top5 98.254464    LR 0.300000    Time 0.033530    
2018-10-21 06:58:44,492 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40005 | -0.01470 |    0.26342 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13022 | -0.00374 |    0.07670 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13059 | -0.00055 |    0.08632 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10971 | -0.00634 |    0.07151 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10849 | -0.00479 |    0.07311 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13023 | -0.00742 |    0.08699 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11822 | -0.01497 |    0.08439 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14638 | -0.00931 |    0.10864 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12470 | -0.00857 |    0.09567 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29821 | -0.01170 |    0.19527 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09451 | -0.00480 |    0.07165 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08333 | -0.01189 |    0.06618 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09922 | -0.01098 |    0.07652 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08065 | -0.00920 |    0.06193 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11059 | -0.00753 |    0.08723 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09689 | -0.00683 |    0.07598 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15100 | -0.01152 |    0.11390 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.01191 |    0.06900 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05671 | -0.00301 |    0.04205 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05048 | -0.00622 |    0.03794 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03378 |  0.00185 |    0.02213 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42673 | -0.00000 |    0.28774 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:58:44,493 - Total sparsity: 0.00

2018-10-21 06:58:44,493 - --- validate (epoch=75)-----------
2018-10-21 06:58:44,493 - 10000 samples (128 per mini-batch)
2018-10-21 06:58:45,739 - Epoch: [75][   50/   78]    Loss 1.695368    Top1 76.421875    Top5 98.109375    
2018-10-21 06:58:46,384 - ==> Top1: 76.060    Top5: 98.190    Loss: 1.699

2018-10-21 06:58:46,386 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:58:46,386 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:58:46,398 - 

2018-10-21 06:58:46,399 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:58:48,131 - Epoch: [76][   50/  391]    Overall Loss 1.666402    Objective Loss 1.666402    Top1 79.546875    Top5 98.093750    LR 0.300000    Time 0.034590    
2018-10-21 06:58:49,770 - Epoch: [76][  100/  391]    Overall Loss 1.669881    Objective Loss 1.669881    Top1 79.242188    Top5 98.140625    LR 0.300000    Time 0.033664    
2018-10-21 06:58:51,330 - Epoch: [76][  150/  391]    Overall Loss 1.669447    Objective Loss 1.669447    Top1 79.276042    Top5 98.203125    LR 0.300000    Time 0.032826    
2018-10-21 06:58:52,908 - Epoch: [76][  200/  391]    Overall Loss 1.669014    Objective Loss 1.669014    Top1 79.328125    Top5 98.199219    LR 0.300000    Time 0.032499    
2018-10-21 06:58:54,468 - Epoch: [76][  250/  391]    Overall Loss 1.669858    Objective Loss 1.669858    Top1 79.225000    Top5 98.290625    LR 0.300000    Time 0.032229    
2018-10-21 06:58:56,064 - Epoch: [76][  300/  391]    Overall Loss 1.671885    Objective Loss 1.671885    Top1 79.036458    Top5 98.265625    LR 0.300000    Time 0.032170    
2018-10-21 06:58:57,594 - Epoch: [76][  350/  391]    Overall Loss 1.671352    Objective Loss 1.671352    Top1 79.093750    Top5 98.283482    LR 0.300000    Time 0.031942    
2018-10-21 06:58:58,972 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39765 | -0.00335 |    0.26113 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13000 | -0.00023 |    0.07652 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13004 | -0.00301 |    0.08508 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10926 | -0.00607 |    0.07159 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10862 | -0.00489 |    0.07286 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12985 | -0.00934 |    0.08659 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11805 | -0.01370 |    0.08467 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14622 | -0.00924 |    0.10854 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12498 | -0.00764 |    0.09591 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29813 | -0.00913 |    0.19612 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09443 | -0.00513 |    0.07155 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08380 | -0.01000 |    0.06617 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09960 | -0.01148 |    0.07663 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08097 | -0.00884 |    0.06197 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11061 | -0.00717 |    0.08695 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09705 | -0.00621 |    0.07605 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15067 | -0.01112 |    0.11439 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08888 | -0.01185 |    0.06859 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05670 | -0.00252 |    0.04197 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05075 | -0.00610 |    0.03802 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03382 |  0.00156 |    0.02233 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42680 | -0.00000 |    0.28817 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:58:58,973 - Total sparsity: 0.00

2018-10-21 06:58:58,973 - --- validate (epoch=76)-----------
2018-10-21 06:58:58,973 - 10000 samples (128 per mini-batch)
2018-10-21 06:59:00,316 - Epoch: [76][   50/   78]    Loss 1.767010    Top1 69.140625    Top5 97.312500    
2018-10-21 06:59:00,989 - ==> Top1: 69.100    Top5: 97.390    Loss: 1.767

2018-10-21 06:59:00,990 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:59:00,990 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:59:01,003 - 

2018-10-21 06:59:01,004 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:59:02,927 - Epoch: [77][   50/  391]    Overall Loss 1.666304    Objective Loss 1.666304    Top1 79.437500    Top5 98.171875    LR 0.300000    Time 0.038400    
2018-10-21 06:59:04,505 - Epoch: [77][  100/  391]    Overall Loss 1.668542    Objective Loss 1.668542    Top1 79.351562    Top5 98.343750    LR 0.300000    Time 0.034957    
2018-10-21 06:59:06,050 - Epoch: [77][  150/  391]    Overall Loss 1.666194    Objective Loss 1.666194    Top1 79.578125    Top5 98.421875    LR 0.300000    Time 0.033591    
2018-10-21 06:59:07,589 - Epoch: [77][  200/  391]    Overall Loss 1.667497    Objective Loss 1.667497    Top1 79.449219    Top5 98.425781    LR 0.300000    Time 0.032875    
2018-10-21 06:59:09,149 - Epoch: [77][  250/  391]    Overall Loss 1.670740    Objective Loss 1.670740    Top1 79.106250    Top5 98.409375    LR 0.300000    Time 0.032531    
2018-10-21 06:59:10,676 - Epoch: [77][  300/  391]    Overall Loss 1.669235    Objective Loss 1.669235    Top1 79.260417    Top5 98.414062    LR 0.300000    Time 0.032191    
2018-10-21 06:59:12,219 - Epoch: [77][  350/  391]    Overall Loss 1.669522    Objective Loss 1.669522    Top1 79.247768    Top5 98.408482    LR 0.300000    Time 0.031996    
2018-10-21 06:59:13,606 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39904 |  0.00626 |    0.25931 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13035 | -0.00373 |    0.07662 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13090 | -0.00086 |    0.08596 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10832 | -0.00670 |    0.07120 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10791 | -0.00549 |    0.07269 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13060 | -0.00955 |    0.08684 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11695 | -0.01389 |    0.08375 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14584 | -0.00920 |    0.10815 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00889 |    0.09559 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29604 | -0.01096 |    0.19172 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09414 | -0.00563 |    0.07101 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08349 | -0.01052 |    0.06583 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09893 | -0.01064 |    0.07601 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08064 | -0.00911 |    0.06175 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11012 | -0.00676 |    0.08642 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09680 | -0.00661 |    0.07601 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15124 | -0.01085 |    0.11496 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08837 | -0.01195 |    0.06848 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05670 | -0.00243 |    0.04193 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05119 | -0.00600 |    0.03835 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03410 |  0.00140 |    0.02261 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42626 | -0.00000 |    0.28865 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:59:13,606 - Total sparsity: 0.00

2018-10-21 06:59:13,606 - --- validate (epoch=77)-----------
2018-10-21 06:59:13,607 - 10000 samples (128 per mini-batch)
2018-10-21 06:59:14,899 - Epoch: [77][   50/   78]    Loss 1.684049    Top1 77.656250    Top5 97.890625    
2018-10-21 06:59:15,562 - ==> Top1: 77.640    Top5: 97.920    Loss: 1.682

2018-10-21 06:59:15,564 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:59:15,564 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:59:15,583 - 

2018-10-21 06:59:15,583 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:59:17,315 - Epoch: [78][   50/  391]    Overall Loss 1.664367    Objective Loss 1.664367    Top1 80.109375    Top5 97.984375    LR 0.300000    Time 0.034586    
2018-10-21 06:59:18,926 - Epoch: [78][  100/  391]    Overall Loss 1.665881    Objective Loss 1.665881    Top1 79.796875    Top5 98.242188    LR 0.300000    Time 0.033376    
2018-10-21 06:59:20,516 - Epoch: [78][  150/  391]    Overall Loss 1.671143    Objective Loss 1.671143    Top1 79.151042    Top5 98.234375    LR 0.300000    Time 0.032833    
2018-10-21 06:59:22,060 - Epoch: [78][  200/  391]    Overall Loss 1.671022    Objective Loss 1.671022    Top1 79.167969    Top5 98.296875    LR 0.300000    Time 0.032334    
2018-10-21 06:59:23,630 - Epoch: [78][  250/  391]    Overall Loss 1.669775    Objective Loss 1.669775    Top1 79.250000    Top5 98.321875    LR 0.300000    Time 0.032140    
2018-10-21 06:59:25,170 - Epoch: [78][  300/  391]    Overall Loss 1.670698    Objective Loss 1.670698    Top1 79.164062    Top5 98.338542    LR 0.300000    Time 0.031909    
2018-10-21 06:59:26,754 - Epoch: [78][  350/  391]    Overall Loss 1.672455    Objective Loss 1.672455    Top1 78.968750    Top5 98.363839    LR 0.300000    Time 0.031870    
2018-10-21 06:59:28,150 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40032 |  0.01558 |    0.25921 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13163 | -0.00378 |    0.07705 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13269 | -0.00206 |    0.08666 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10968 | -0.00755 |    0.07151 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10949 | -0.00473 |    0.07359 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13034 | -0.01325 |    0.08824 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11794 | -0.01512 |    0.08506 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14567 | -0.01031 |    0.10859 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12484 | -0.00796 |    0.09563 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29620 | -0.00919 |    0.19401 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09440 | -0.00420 |    0.07102 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08330 | -0.01070 |    0.06573 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09874 | -0.00949 |    0.07555 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08032 | -0.00866 |    0.06154 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10994 | -0.00668 |    0.08639 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09694 | -0.00617 |    0.07597 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15113 | -0.01205 |    0.11461 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08854 | -0.01190 |    0.06846 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05685 | -0.00234 |    0.04203 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05127 | -0.00603 |    0.03851 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03403 |  0.00148 |    0.02242 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42640 | -0.00000 |    0.28816 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:59:28,151 - Total sparsity: 0.00

2018-10-21 06:59:28,151 - --- validate (epoch=78)-----------
2018-10-21 06:59:28,151 - 10000 samples (128 per mini-batch)
2018-10-21 06:59:29,351 - Epoch: [78][   50/   78]    Loss 1.719701    Top1 74.187500    Top5 98.015625    
2018-10-21 06:59:29,989 - ==> Top1: 74.060    Top5: 98.050    Loss: 1.722

2018-10-21 06:59:29,990 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:59:29,991 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:59:30,003 - 

2018-10-21 06:59:30,004 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:59:31,746 - Epoch: [79][   50/  391]    Overall Loss 1.676410    Objective Loss 1.676410    Top1 78.765625    Top5 98.093750    LR 0.300000    Time 0.034798    
2018-10-21 06:59:33,358 - Epoch: [79][  100/  391]    Overall Loss 1.672525    Objective Loss 1.672525    Top1 79.171875    Top5 98.257812    LR 0.300000    Time 0.033489    
2018-10-21 06:59:34,925 - Epoch: [79][  150/  391]    Overall Loss 1.670015    Objective Loss 1.670015    Top1 79.380208    Top5 98.359375    LR 0.300000    Time 0.032761    
2018-10-21 06:59:36,514 - Epoch: [79][  200/  391]    Overall Loss 1.669603    Objective Loss 1.669603    Top1 79.394531    Top5 98.351562    LR 0.300000    Time 0.032502    
2018-10-21 06:59:38,084 - Epoch: [79][  250/  391]    Overall Loss 1.668878    Objective Loss 1.668878    Top1 79.462500    Top5 98.371875    LR 0.300000    Time 0.032271    
2018-10-21 06:59:39,705 - Epoch: [79][  300/  391]    Overall Loss 1.669553    Objective Loss 1.669553    Top1 79.354167    Top5 98.343750    LR 0.300000    Time 0.032290    
2018-10-21 06:59:41,270 - Epoch: [79][  350/  391]    Overall Loss 1.670886    Objective Loss 1.670886    Top1 79.203125    Top5 98.341518    LR 0.300000    Time 0.032141    
2018-10-21 06:59:42,661 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39827 | -0.01216 |    0.26062 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13167 | -0.00083 |    0.07739 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13243 |  0.00008 |    0.08654 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10976 | -0.00671 |    0.07246 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10991 | -0.00549 |    0.07360 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13153 | -0.01142 |    0.08896 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11816 | -0.01492 |    0.08503 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14563 | -0.00700 |    0.10825 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12425 | -0.00961 |    0.09532 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29685 | -0.00825 |    0.19478 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09436 | -0.00571 |    0.07110 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08323 | -0.01053 |    0.06555 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09957 | -0.01039 |    0.07634 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08102 | -0.00818 |    0.06210 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10959 | -0.00716 |    0.08616 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09682 | -0.00567 |    0.07605 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15131 | -0.01134 |    0.11488 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08868 | -0.01144 |    0.06847 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05699 | -0.00205 |    0.04211 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05150 | -0.00590 |    0.03856 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03405 |  0.00178 |    0.02234 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42713 | -0.00000 |    0.28760 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:59:42,661 - Total sparsity: 0.00

2018-10-21 06:59:42,661 - --- validate (epoch=79)-----------
2018-10-21 06:59:42,661 - 10000 samples (128 per mini-batch)
2018-10-21 06:59:43,892 - Epoch: [79][   50/   78]    Loss 1.817771    Top1 64.109375    Top5 96.484375    
2018-10-21 06:59:44,520 - ==> Top1: 64.440    Top5: 96.330    Loss: 1.814

2018-10-21 06:59:44,521 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:59:44,521 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:59:44,534 - 

2018-10-21 06:59:44,534 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 06:59:46,246 - Epoch: [80][   50/  391]    Overall Loss 1.666433    Objective Loss 1.666433    Top1 79.562500    Top5 98.234375    LR 0.300000    Time 0.034166    
2018-10-21 06:59:47,842 - Epoch: [80][  100/  391]    Overall Loss 1.668143    Objective Loss 1.668143    Top1 79.515625    Top5 98.359375    LR 0.300000    Time 0.033020    
2018-10-21 06:59:49,421 - Epoch: [80][  150/  391]    Overall Loss 1.667119    Objective Loss 1.667119    Top1 79.572917    Top5 98.437500    LR 0.300000    Time 0.032529    
2018-10-21 06:59:50,980 - Epoch: [80][  200/  391]    Overall Loss 1.665337    Objective Loss 1.665337    Top1 79.765625    Top5 98.472656    LR 0.300000    Time 0.032179    
2018-10-21 06:59:52,540 - Epoch: [80][  250/  391]    Overall Loss 1.667589    Objective Loss 1.667589    Top1 79.493750    Top5 98.390625    LR 0.300000    Time 0.031974    
2018-10-21 06:59:54,088 - Epoch: [80][  300/  391]    Overall Loss 1.668623    Objective Loss 1.668623    Top1 79.421875    Top5 98.388021    LR 0.300000    Time 0.031795    
2018-10-21 06:59:55,656 - Epoch: [80][  350/  391]    Overall Loss 1.668864    Objective Loss 1.668864    Top1 79.386161    Top5 98.381696    LR 0.300000    Time 0.031727    
2018-10-21 06:59:57,104 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39976 |  0.00164 |    0.26340 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13168 | -0.00318 |    0.07641 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13248 | -0.00072 |    0.08754 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11045 | -0.00538 |    0.07260 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11083 | -0.00532 |    0.07445 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13277 | -0.00846 |    0.08947 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11944 | -0.01286 |    0.08557 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14526 | -0.00723 |    0.10802 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12401 | -0.00919 |    0.09533 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29872 | -0.01179 |    0.19400 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09462 | -0.00429 |    0.07119 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08275 | -0.01081 |    0.06534 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10021 | -0.00913 |    0.07639 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08121 | -0.00833 |    0.06195 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10945 | -0.00787 |    0.08617 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09636 | -0.00574 |    0.07564 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15049 | -0.01089 |    0.11467 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08850 | -0.01102 |    0.06814 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05694 | -0.00238 |    0.04212 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05171 | -0.00586 |    0.03864 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03438 |  0.00164 |    0.02275 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42709 | -0.00000 |    0.28871 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 06:59:57,104 - Total sparsity: 0.00

2018-10-21 06:59:57,105 - --- validate (epoch=80)-----------
2018-10-21 06:59:57,105 - 10000 samples (128 per mini-batch)
2018-10-21 06:59:58,307 - Epoch: [80][   50/   78]    Loss 1.731123    Top1 73.093750    Top5 97.843750    
2018-10-21 06:59:58,953 - ==> Top1: 72.660    Top5: 97.850    Loss: 1.734

2018-10-21 06:59:58,954 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 06:59:58,954 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 06:59:58,967 - 

2018-10-21 06:59:58,968 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:00:00,706 - Epoch: [81][   50/  391]    Overall Loss 1.667639    Objective Loss 1.667639    Top1 79.562500    Top5 98.234375    LR 0.300000    Time 0.034715    
2018-10-21 07:00:02,312 - Epoch: [81][  100/  391]    Overall Loss 1.664253    Objective Loss 1.664253    Top1 79.890625    Top5 98.289062    LR 0.300000    Time 0.033396    
2018-10-21 07:00:03,930 - Epoch: [81][  150/  391]    Overall Loss 1.663999    Objective Loss 1.663999    Top1 79.781250    Top5 98.359375    LR 0.300000    Time 0.033032    
2018-10-21 07:00:05,526 - Epoch: [81][  200/  391]    Overall Loss 1.664398    Objective Loss 1.664398    Top1 79.746094    Top5 98.339844    LR 0.300000    Time 0.032744    
2018-10-21 07:00:07,131 - Epoch: [81][  250/  391]    Overall Loss 1.664764    Objective Loss 1.664764    Top1 79.737500    Top5 98.309375    LR 0.300000    Time 0.032607    
2018-10-21 07:00:08,740 - Epoch: [81][  300/  391]    Overall Loss 1.667017    Objective Loss 1.667017    Top1 79.533854    Top5 98.320312    LR 0.300000    Time 0.032529    
2018-10-21 07:00:10,305 - Epoch: [81][  350/  391]    Overall Loss 1.667020    Objective Loss 1.667020    Top1 79.526786    Top5 98.292411    LR 0.300000    Time 0.032347    
2018-10-21 07:00:11,687 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40394 |  0.00367 |    0.26543 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13175 | -0.00380 |    0.07588 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13265 | -0.00450 |    0.08769 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11206 | -0.00476 |    0.07294 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11182 | -0.00566 |    0.07437 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13199 | -0.01169 |    0.08934 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11859 | -0.01294 |    0.08534 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14539 | -0.00498 |    0.10728 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12362 | -0.00728 |    0.09469 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29982 | -0.01077 |    0.19354 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09546 | -0.00309 |    0.07176 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08329 | -0.01095 |    0.06571 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09989 | -0.00954 |    0.07641 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08123 | -0.00752 |    0.06192 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10950 | -0.00766 |    0.08594 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09610 | -0.00647 |    0.07549 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15041 | -0.01032 |    0.11386 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08820 | -0.01130 |    0.06796 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05702 | -0.00245 |    0.04207 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05198 | -0.00593 |    0.03884 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03458 |  0.00145 |    0.02287 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43107 | -0.00000 |    0.29164 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:00:11,687 - Total sparsity: 0.00

2018-10-21 07:00:11,687 - --- validate (epoch=81)-----------
2018-10-21 07:00:11,687 - 10000 samples (128 per mini-batch)
2018-10-21 07:00:12,968 - Epoch: [81][   50/   78]    Loss 1.683167    Top1 77.828125    Top5 97.453125    
2018-10-21 07:00:13,628 - ==> Top1: 77.940    Top5: 97.600    Loss: 1.682

2018-10-21 07:00:13,629 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:00:13,630 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:00:13,642 - 

2018-10-21 07:00:13,643 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:00:15,393 - Epoch: [82][   50/  391]    Overall Loss 1.664771    Objective Loss 1.664771    Top1 79.656250    Top5 98.375000    LR 0.300000    Time 0.034934    
2018-10-21 07:00:17,013 - Epoch: [82][  100/  391]    Overall Loss 1.669598    Objective Loss 1.669598    Top1 79.179688    Top5 98.445312    LR 0.300000    Time 0.033647    
2018-10-21 07:00:18,592 - Epoch: [82][  150/  391]    Overall Loss 1.665042    Objective Loss 1.665042    Top1 79.708333    Top5 98.463542    LR 0.300000    Time 0.032939    
2018-10-21 07:00:20,153 - Epoch: [82][  200/  391]    Overall Loss 1.667327    Objective Loss 1.667327    Top1 79.464844    Top5 98.472656    LR 0.300000    Time 0.032499    
2018-10-21 07:00:21,725 - Epoch: [82][  250/  391]    Overall Loss 1.665850    Objective Loss 1.665850    Top1 79.640625    Top5 98.521875    LR 0.300000    Time 0.032278    
2018-10-21 07:00:23,309 - Epoch: [82][  300/  391]    Overall Loss 1.667738    Objective Loss 1.667738    Top1 79.460938    Top5 98.471354    LR 0.300000    Time 0.032169    
2018-10-21 07:00:24,849 - Epoch: [82][  350/  391]    Overall Loss 1.668556    Objective Loss 1.668556    Top1 79.412946    Top5 98.421875    LR 0.300000    Time 0.031968    
2018-10-21 07:00:26,250 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40706 |  0.00083 |    0.26951 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13203 | -0.00348 |    0.07530 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13219 | -0.00233 |    0.08683 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11127 | -0.00673 |    0.07226 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11118 | -0.00775 |    0.07353 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13356 | -0.01008 |    0.09002 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11873 | -0.01420 |    0.08552 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14576 | -0.00781 |    0.10791 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12380 | -0.00855 |    0.09467 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30037 | -0.01025 |    0.19567 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09548 | -0.00208 |    0.07206 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08324 | -0.01264 |    0.06608 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09983 | -0.00956 |    0.07616 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08086 | -0.00840 |    0.06188 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10959 | -0.00803 |    0.08620 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09592 | -0.00673 |    0.07544 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15114 | -0.00960 |    0.11479 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08814 | -0.01175 |    0.06801 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05708 | -0.00240 |    0.04202 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05199 | -0.00641 |    0.03892 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03473 |  0.00154 |    0.02294 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43095 | -0.00000 |    0.29130 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:00:26,250 - Total sparsity: 0.00

2018-10-21 07:00:26,250 - --- validate (epoch=82)-----------
2018-10-21 07:00:26,250 - 10000 samples (128 per mini-batch)
2018-10-21 07:00:27,468 - Epoch: [82][   50/   78]    Loss 1.758841    Top1 69.906250    Top5 96.015625    
2018-10-21 07:00:28,095 - ==> Top1: 69.810    Top5: 96.090    Loss: 1.760

2018-10-21 07:00:28,096 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:00:28,097 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:00:28,109 - 

2018-10-21 07:00:28,110 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:00:29,826 - Epoch: [83][   50/  391]    Overall Loss 1.663143    Objective Loss 1.663143    Top1 80.000000    Top5 98.031250    LR 0.300000    Time 0.034267    
2018-10-21 07:00:31,367 - Epoch: [83][  100/  391]    Overall Loss 1.669746    Objective Loss 1.669746    Top1 79.437500    Top5 98.093750    LR 0.300000    Time 0.032515    
2018-10-21 07:00:32,951 - Epoch: [83][  150/  391]    Overall Loss 1.670182    Objective Loss 1.670182    Top1 79.322917    Top5 98.098958    LR 0.300000    Time 0.032223    
2018-10-21 07:00:34,499 - Epoch: [83][  200/  391]    Overall Loss 1.667881    Objective Loss 1.667881    Top1 79.527344    Top5 98.230469    LR 0.300000    Time 0.031896    
2018-10-21 07:00:36,045 - Epoch: [83][  250/  391]    Overall Loss 1.668594    Objective Loss 1.668594    Top1 79.459375    Top5 98.234375    LR 0.300000    Time 0.031691    
2018-10-21 07:00:37,567 - Epoch: [83][  300/  391]    Overall Loss 1.667573    Objective Loss 1.667573    Top1 79.588542    Top5 98.244792    LR 0.300000    Time 0.031478    
2018-10-21 07:00:39,103 - Epoch: [83][  350/  391]    Overall Loss 1.668405    Objective Loss 1.668405    Top1 79.506696    Top5 98.265625    LR 0.300000    Time 0.031362    
2018-10-21 07:00:40,488 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40661 | -0.00789 |    0.26804 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13380 |  0.00008 |    0.07681 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13412 | -0.00256 |    0.08847 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11117 | -0.00629 |    0.07228 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11115 | -0.00617 |    0.07347 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13411 | -0.01042 |    0.08976 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11813 | -0.01577 |    0.08555 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14539 | -0.00859 |    0.10813 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12363 | -0.00800 |    0.09463 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29851 | -0.00895 |    0.19541 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09569 | -0.00285 |    0.07183 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08362 | -0.01186 |    0.06627 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09891 | -0.00912 |    0.07527 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08047 | -0.00841 |    0.06169 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10986 | -0.00753 |    0.08663 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09607 | -0.00677 |    0.07547 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15027 | -0.01032 |    0.11540 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08811 | -0.01180 |    0.06819 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05716 | -0.00244 |    0.04214 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05201 | -0.00600 |    0.03894 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03464 |  0.00156 |    0.02281 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43069 | -0.00000 |    0.29225 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:00:40,488 - Total sparsity: 0.00

2018-10-21 07:00:40,488 - --- validate (epoch=83)-----------
2018-10-21 07:00:40,488 - 10000 samples (128 per mini-batch)
2018-10-21 07:00:41,731 - Epoch: [83][   50/   78]    Loss 1.733033    Top1 72.609375    Top5 97.015625    
2018-10-21 07:00:42,369 - ==> Top1: 73.070    Top5: 97.030    Loss: 1.731

2018-10-21 07:00:42,370 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:00:42,370 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:00:42,383 - 

2018-10-21 07:00:42,384 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:00:44,157 - Epoch: [84][   50/  391]    Overall Loss 1.656442    Objective Loss 1.656442    Top1 80.671875    Top5 98.437500    LR 0.300000    Time 0.035398    
2018-10-21 07:00:45,765 - Epoch: [84][  100/  391]    Overall Loss 1.659312    Objective Loss 1.659312    Top1 80.367188    Top5 98.460938    LR 0.300000    Time 0.033757    
2018-10-21 07:00:47,441 - Epoch: [84][  150/  391]    Overall Loss 1.663004    Objective Loss 1.663004    Top1 79.994792    Top5 98.338542    LR 0.300000    Time 0.033663    
2018-10-21 07:00:49,017 - Epoch: [84][  200/  391]    Overall Loss 1.662751    Objective Loss 1.662751    Top1 79.949219    Top5 98.386719    LR 0.300000    Time 0.033116    
2018-10-21 07:00:50,586 - Epoch: [84][  250/  391]    Overall Loss 1.663494    Objective Loss 1.663494    Top1 79.900000    Top5 98.387500    LR 0.300000    Time 0.032761    
2018-10-21 07:00:52,157 - Epoch: [84][  300/  391]    Overall Loss 1.664227    Objective Loss 1.664227    Top1 79.791667    Top5 98.377604    LR 0.300000    Time 0.032530    
2018-10-21 07:00:53,700 - Epoch: [84][  350/  391]    Overall Loss 1.664634    Objective Loss 1.664634    Top1 79.752232    Top5 98.368304    LR 0.300000    Time 0.032284    
2018-10-21 07:00:55,108 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40548 | -0.00273 |    0.27031 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13315 | -0.00085 |    0.07700 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13399 | -0.00267 |    0.08799 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11115 | -0.00670 |    0.07223 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11078 | -0.00584 |    0.07332 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13478 | -0.00803 |    0.09051 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11859 | -0.01302 |    0.08585 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14517 | -0.00829 |    0.10781 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12343 | -0.00782 |    0.09448 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29814 | -0.00889 |    0.19592 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09505 | -0.00455 |    0.07192 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08296 | -0.01207 |    0.06557 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09880 | -0.01129 |    0.07585 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08042 | -0.00820 |    0.06158 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10954 | -0.00827 |    0.08638 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09592 | -0.00669 |    0.07537 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14956 | -0.01031 |    0.11517 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08806 | -0.01127 |    0.06801 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05711 | -0.00276 |    0.04210 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05211 | -0.00637 |    0.03917 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03486 |  0.00139 |    0.02306 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43277 | -0.00000 |    0.29265 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:00:55,108 - Total sparsity: 0.00

2018-10-21 07:00:55,108 - --- validate (epoch=84)-----------
2018-10-21 07:00:55,108 - 10000 samples (128 per mini-batch)
2018-10-21 07:00:56,313 - Epoch: [84][   50/   78]    Loss 1.727724    Top1 73.218750    Top5 97.687500    
2018-10-21 07:00:57,025 - ==> Top1: 72.980    Top5: 97.730    Loss: 1.730

2018-10-21 07:00:57,027 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:00:57,028 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:00:57,047 - 

2018-10-21 07:00:57,048 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:00:58,854 - Epoch: [85][   50/  391]    Overall Loss 1.667438    Objective Loss 1.667438    Top1 79.234375    Top5 98.390625    LR 0.300000    Time 0.036068    
2018-10-21 07:01:00,468 - Epoch: [85][  100/  391]    Overall Loss 1.675673    Objective Loss 1.675673    Top1 78.546875    Top5 98.218750    LR 0.300000    Time 0.034144    
2018-10-21 07:01:02,005 - Epoch: [85][  150/  391]    Overall Loss 1.671644    Objective Loss 1.671644    Top1 79.015625    Top5 98.354167    LR 0.300000    Time 0.032998    
2018-10-21 07:01:03,566 - Epoch: [85][  200/  391]    Overall Loss 1.667437    Objective Loss 1.667437    Top1 79.515625    Top5 98.402344    LR 0.300000    Time 0.032540    
2018-10-21 07:01:05,113 - Epoch: [85][  250/  391]    Overall Loss 1.666555    Objective Loss 1.666555    Top1 79.640625    Top5 98.359375    LR 0.300000    Time 0.032211    
2018-10-21 07:01:06,629 - Epoch: [85][  300/  391]    Overall Loss 1.668404    Objective Loss 1.668404    Top1 79.455729    Top5 98.338542    LR 0.300000    Time 0.031889    
2018-10-21 07:01:08,140 - Epoch: [85][  350/  391]    Overall Loss 1.666058    Objective Loss 1.666058    Top1 79.696429    Top5 98.366071    LR 0.300000    Time 0.031643    
2018-10-21 07:01:09,494 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40319 | -0.00513 |    0.26510 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13213 | -0.00062 |    0.07634 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13272 | -0.00075 |    0.08884 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11161 | -0.00431 |    0.07303 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11136 | -0.00590 |    0.07413 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13468 | -0.01072 |    0.09112 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11960 | -0.01582 |    0.08646 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14498 | -0.00728 |    0.10792 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12261 | -0.00892 |    0.09361 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29982 | -0.00831 |    0.19388 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09588 | -0.00395 |    0.07212 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08349 | -0.01112 |    0.06568 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09872 | -0.01090 |    0.07557 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08023 | -0.00785 |    0.06097 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10958 | -0.00776 |    0.08651 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09589 | -0.00674 |    0.07529 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14896 | -0.01143 |    0.11431 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08777 | -0.01148 |    0.06787 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05705 | -0.00255 |    0.04215 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05220 | -0.00652 |    0.03921 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03467 |  0.00131 |    0.02287 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43083 | -0.00000 |    0.29218 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:01:09,494 - Total sparsity: 0.00

2018-10-21 07:01:09,495 - --- validate (epoch=85)-----------
2018-10-21 07:01:09,495 - 10000 samples (128 per mini-batch)
2018-10-21 07:01:10,719 - Epoch: [85][   50/   78]    Loss 1.703369    Top1 75.765625    Top5 98.218750    
2018-10-21 07:01:11,349 - ==> Top1: 75.600    Top5: 98.130    Loss: 1.707

2018-10-21 07:01:11,351 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:01:11,351 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:01:11,364 - 

2018-10-21 07:01:11,365 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:01:13,098 - Epoch: [86][   50/  391]    Overall Loss 1.664537    Objective Loss 1.664537    Top1 79.562500    Top5 98.484375    LR 0.300000    Time 0.034617    
2018-10-21 07:01:14,730 - Epoch: [86][  100/  391]    Overall Loss 1.667602    Objective Loss 1.667602    Top1 79.359375    Top5 98.382812    LR 0.300000    Time 0.033605    
2018-10-21 07:01:16,327 - Epoch: [86][  150/  391]    Overall Loss 1.666969    Objective Loss 1.666969    Top1 79.416667    Top5 98.369792    LR 0.300000    Time 0.033032    
2018-10-21 07:01:17,918 - Epoch: [86][  200/  391]    Overall Loss 1.665403    Objective Loss 1.665403    Top1 79.601562    Top5 98.300781    LR 0.300000    Time 0.032721    
2018-10-21 07:01:19,522 - Epoch: [86][  250/  391]    Overall Loss 1.665168    Objective Loss 1.665168    Top1 79.615625    Top5 98.268750    LR 0.300000    Time 0.032582    
2018-10-21 07:01:21,082 - Epoch: [86][  300/  391]    Overall Loss 1.665833    Objective Loss 1.665833    Top1 79.580729    Top5 98.312500    LR 0.300000    Time 0.032345    
2018-10-21 07:01:22,782 - Epoch: [86][  350/  391]    Overall Loss 1.665438    Objective Loss 1.665438    Top1 79.647321    Top5 98.337054    LR 0.300000    Time 0.032575    
2018-10-21 07:01:24,213 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40733 |  0.00152 |    0.26833 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13187 | -0.00257 |    0.07603 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13191 | -0.00338 |    0.08758 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11129 | -0.00323 |    0.07318 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11173 | -0.00503 |    0.07394 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13555 | -0.01175 |    0.09091 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11977 | -0.01607 |    0.08591 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14505 | -0.00768 |    0.10763 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12250 | -0.00799 |    0.09363 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29908 | -0.01213 |    0.19423 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09530 | -0.00417 |    0.07172 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08317 | -0.01049 |    0.06539 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09918 | -0.01039 |    0.07590 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08059 | -0.00780 |    0.06158 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10927 | -0.00836 |    0.08642 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09577 | -0.00675 |    0.07512 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14882 | -0.01093 |    0.11367 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08779 | -0.01116 |    0.06772 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05721 | -0.00255 |    0.04223 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05228 | -0.00659 |    0.03920 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03467 |  0.00119 |    0.02295 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42993 | -0.00000 |    0.29181 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:01:24,214 - Total sparsity: 0.00

2018-10-21 07:01:24,214 - --- validate (epoch=86)-----------
2018-10-21 07:01:24,214 - 10000 samples (128 per mini-batch)
2018-10-21 07:01:25,407 - Epoch: [86][   50/   78]    Loss 1.717802    Top1 74.156250    Top5 96.343750    
2018-10-21 07:01:26,047 - ==> Top1: 74.290    Top5: 96.370    Loss: 1.716

2018-10-21 07:01:26,049 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:01:26,049 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:01:26,062 - 

2018-10-21 07:01:26,062 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:01:27,844 - Epoch: [87][   50/  391]    Overall Loss 1.655414    Objective Loss 1.655414    Top1 80.703125    Top5 98.468750    LR 0.300000    Time 0.035587    
2018-10-21 07:01:29,450 - Epoch: [87][  100/  391]    Overall Loss 1.661671    Objective Loss 1.661671    Top1 80.007812    Top5 98.367188    LR 0.300000    Time 0.033828    
2018-10-21 07:01:31,051 - Epoch: [87][  150/  391]    Overall Loss 1.662063    Objective Loss 1.662063    Top1 79.994792    Top5 98.296875    LR 0.300000    Time 0.033205    
2018-10-21 07:01:32,636 - Epoch: [87][  200/  391]    Overall Loss 1.663329    Objective Loss 1.663329    Top1 79.886719    Top5 98.277344    LR 0.300000    Time 0.032818    
2018-10-21 07:01:34,239 - Epoch: [87][  250/  391]    Overall Loss 1.663868    Objective Loss 1.663868    Top1 79.818750    Top5 98.315625    LR 0.300000    Time 0.032659    
2018-10-21 07:01:35,841 - Epoch: [87][  300/  391]    Overall Loss 1.664025    Objective Loss 1.664025    Top1 79.807292    Top5 98.286458    LR 0.300000    Time 0.032549    
2018-10-21 07:01:37,449 - Epoch: [87][  350/  391]    Overall Loss 1.664423    Objective Loss 1.664423    Top1 79.772321    Top5 98.319196    LR 0.300000    Time 0.032485    
2018-10-21 07:01:38,885 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40626 | -0.00369 |    0.26597 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13188 | -0.00327 |    0.07622 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13234 | -0.00067 |    0.08796 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11152 | -0.00377 |    0.07318 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11202 | -0.00583 |    0.07415 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13413 | -0.01157 |    0.09047 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11804 | -0.01659 |    0.08427 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14598 | -0.00644 |    0.10819 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12241 | -0.00982 |    0.09335 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29813 | -0.01153 |    0.19091 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09566 | -0.00392 |    0.07192 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08315 | -0.01096 |    0.06544 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09896 | -0.01138 |    0.07561 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08020 | -0.00735 |    0.06132 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10945 | -0.00818 |    0.08653 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09595 | -0.00697 |    0.07533 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14841 | -0.00949 |    0.11274 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08771 | -0.01087 |    0.06754 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05743 | -0.00281 |    0.04250 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05273 | -0.00631 |    0.03951 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03478 |  0.00109 |    0.02311 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42969 | -0.00000 |    0.29226 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:01:38,885 - Total sparsity: 0.00

2018-10-21 07:01:38,885 - --- validate (epoch=87)-----------
2018-10-21 07:01:38,885 - 10000 samples (128 per mini-batch)
2018-10-21 07:01:40,078 - Epoch: [87][   50/   78]    Loss 1.757998    Top1 70.234375    Top5 97.859375    
2018-10-21 07:01:40,737 - ==> Top1: 70.160    Top5: 97.840    Loss: 1.760

2018-10-21 07:01:40,739 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:01:40,739 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:01:40,752 - 

2018-10-21 07:01:40,752 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:01:42,503 - Epoch: [88][   50/  391]    Overall Loss 1.670725    Objective Loss 1.670725    Top1 79.234375    Top5 98.250000    LR 0.300000    Time 0.034949    
2018-10-21 07:01:44,073 - Epoch: [88][  100/  391]    Overall Loss 1.667610    Objective Loss 1.667610    Top1 79.578125    Top5 98.343750    LR 0.300000    Time 0.033150    
2018-10-21 07:01:45,670 - Epoch: [88][  150/  391]    Overall Loss 1.664530    Objective Loss 1.664530    Top1 79.828125    Top5 98.468750    LR 0.300000    Time 0.032729    
2018-10-21 07:01:47,255 - Epoch: [88][  200/  391]    Overall Loss 1.663520    Objective Loss 1.663520    Top1 79.902344    Top5 98.441406    LR 0.300000    Time 0.032464    
2018-10-21 07:01:48,848 - Epoch: [88][  250/  391]    Overall Loss 1.665558    Objective Loss 1.665558    Top1 79.678125    Top5 98.346875    LR 0.300000    Time 0.032335    
2018-10-21 07:01:50,387 - Epoch: [88][  300/  391]    Overall Loss 1.666493    Objective Loss 1.666493    Top1 79.596354    Top5 98.317708    LR 0.300000    Time 0.032067    
2018-10-21 07:01:51,938 - Epoch: [88][  350/  391]    Overall Loss 1.666151    Objective Loss 1.666151    Top1 79.667411    Top5 98.321429    LR 0.300000    Time 0.031912    
2018-10-21 07:01:53,316 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40448 |  0.00310 |    0.26804 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13175 | -0.00336 |    0.07543 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13236 | -0.00097 |    0.08737 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11278 | -0.00477 |    0.07392 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11238 | -0.00440 |    0.07332 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13507 | -0.01146 |    0.09151 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11918 | -0.01739 |    0.08662 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14521 | -0.00707 |    0.10743 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12250 | -0.00923 |    0.09374 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29678 | -0.01195 |    0.18987 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09561 | -0.00292 |    0.07185 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08345 | -0.01006 |    0.06543 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09907 | -0.01072 |    0.07613 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08014 | -0.00687 |    0.06105 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10958 | -0.00776 |    0.08654 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09602 | -0.00664 |    0.07541 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14729 | -0.00779 |    0.11218 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08735 | -0.01079 |    0.06733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05729 | -0.00271 |    0.04242 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05268 | -0.00611 |    0.03956 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03472 |  0.00132 |    0.02310 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43011 | -0.00000 |    0.29178 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:01:53,316 - Total sparsity: 0.00

2018-10-21 07:01:53,316 - --- validate (epoch=88)-----------
2018-10-21 07:01:53,316 - 10000 samples (128 per mini-batch)
2018-10-21 07:01:54,601 - Epoch: [88][   50/   78]    Loss 1.726994    Top1 73.296875    Top5 96.671875    
2018-10-21 07:01:55,252 - ==> Top1: 72.640    Top5: 96.770    Loss: 1.733

2018-10-21 07:01:55,253 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:01:55,254 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:01:55,265 - 

2018-10-21 07:01:55,265 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:01:57,001 - Epoch: [89][   50/  391]    Overall Loss 1.668236    Objective Loss 1.668236    Top1 79.390625    Top5 98.593750    LR 0.300000    Time 0.034650    
2018-10-21 07:01:58,670 - Epoch: [89][  100/  391]    Overall Loss 1.664049    Objective Loss 1.664049    Top1 79.906250    Top5 98.570312    LR 0.300000    Time 0.033992    
2018-10-21 07:02:00,274 - Epoch: [89][  150/  391]    Overall Loss 1.660235    Objective Loss 1.660235    Top1 80.291667    Top5 98.562500    LR 0.300000    Time 0.033345    
2018-10-21 07:02:01,853 - Epoch: [89][  200/  391]    Overall Loss 1.658657    Objective Loss 1.658657    Top1 80.414062    Top5 98.511719    LR 0.300000    Time 0.032891    
2018-10-21 07:02:03,429 - Epoch: [89][  250/  391]    Overall Loss 1.661008    Objective Loss 1.661008    Top1 80.159375    Top5 98.506250    LR 0.300000    Time 0.032610    
2018-10-21 07:02:04,994 - Epoch: [89][  300/  391]    Overall Loss 1.662341    Objective Loss 1.662341    Top1 80.036458    Top5 98.458333    LR 0.300000    Time 0.032381    
2018-10-21 07:02:06,557 - Epoch: [89][  350/  391]    Overall Loss 1.663707    Objective Loss 1.663707    Top1 79.886161    Top5 98.388393    LR 0.300000    Time 0.032215    
2018-10-21 07:02:07,976 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40705 | -0.00614 |    0.26865 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13194 | -0.00614 |    0.07571 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13365 |  0.00034 |    0.08718 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11261 | -0.00378 |    0.07378 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11152 | -0.00347 |    0.07286 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13468 | -0.01395 |    0.09133 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12009 | -0.01509 |    0.08682 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14610 | -0.00775 |    0.10915 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12309 | -0.00904 |    0.09428 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29725 | -0.01056 |    0.19029 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09566 | -0.00344 |    0.07182 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08365 | -0.00981 |    0.06523 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09956 | -0.01070 |    0.07675 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08026 | -0.00680 |    0.06108 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10958 | -0.00808 |    0.08669 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09608 | -0.00657 |    0.07551 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14871 | -0.00708 |    0.11413 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08777 | -0.01045 |    0.06755 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05744 | -0.00334 |    0.04255 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05280 | -0.00609 |    0.03967 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03479 |  0.00115 |    0.02311 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43153 | -0.00000 |    0.29291 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:02:07,977 - Total sparsity: 0.00

2018-10-21 07:02:07,977 - --- validate (epoch=89)-----------
2018-10-21 07:02:07,977 - 10000 samples (128 per mini-batch)
2018-10-21 07:02:09,150 - Epoch: [89][   50/   78]    Loss 1.703172    Top1 75.781250    Top5 97.218750    
2018-10-21 07:02:09,789 - ==> Top1: 75.940    Top5: 97.310    Loss: 1.700

2018-10-21 07:02:09,791 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:02:09,791 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:02:09,804 - 

2018-10-21 07:02:09,804 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:02:11,524 - Epoch: [90][   50/  391]    Overall Loss 1.664489    Objective Loss 1.664489    Top1 79.890625    Top5 98.546875    LR 0.300000    Time 0.034349    
2018-10-21 07:02:13,105 - Epoch: [90][  100/  391]    Overall Loss 1.661382    Objective Loss 1.661382    Top1 80.171875    Top5 98.453125    LR 0.300000    Time 0.032955    
2018-10-21 07:02:14,725 - Epoch: [90][  150/  391]    Overall Loss 1.662159    Objective Loss 1.662159    Top1 80.062500    Top5 98.437500    LR 0.300000    Time 0.032756    
2018-10-21 07:02:16,322 - Epoch: [90][  200/  391]    Overall Loss 1.663905    Objective Loss 1.663905    Top1 79.949219    Top5 98.406250    LR 0.300000    Time 0.032540    
2018-10-21 07:02:17,901 - Epoch: [90][  250/  391]    Overall Loss 1.666047    Objective Loss 1.666047    Top1 79.693750    Top5 98.378125    LR 0.300000    Time 0.032340    
2018-10-21 07:02:19,489 - Epoch: [90][  300/  391]    Overall Loss 1.666992    Objective Loss 1.666992    Top1 79.585938    Top5 98.411458    LR 0.300000    Time 0.032236    
2018-10-21 07:02:21,049 - Epoch: [90][  350/  391]    Overall Loss 1.667487    Objective Loss 1.667487    Top1 79.524554    Top5 98.439732    LR 0.300000    Time 0.032080    
2018-10-21 07:02:22,454 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40864 | -0.00672 |    0.27142 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13444 | -0.00468 |    0.07687 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13478 |  0.00180 |    0.08874 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11203 | -0.00420 |    0.07360 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11117 | -0.00346 |    0.07297 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13414 | -0.01188 |    0.09167 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11910 | -0.01513 |    0.08584 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14578 | -0.00666 |    0.10825 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12327 | -0.00771 |    0.09410 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29840 | -0.00894 |    0.19284 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09575 | -0.00374 |    0.07174 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08376 | -0.01064 |    0.06552 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10048 | -0.00978 |    0.07700 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08080 | -0.00683 |    0.06133 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11021 | -0.00761 |    0.08683 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09649 | -0.00617 |    0.07566 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14873 | -0.00855 |    0.11359 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08805 | -0.01103 |    0.06795 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05773 | -0.00305 |    0.04276 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05317 | -0.00598 |    0.03985 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03503 |  0.00120 |    0.02326 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43013 | -0.00000 |    0.29254 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:02:22,454 - Total sparsity: 0.00

2018-10-21 07:02:22,454 - --- validate (epoch=90)-----------
2018-10-21 07:02:22,454 - 10000 samples (128 per mini-batch)
2018-10-21 07:02:23,656 - Epoch: [90][   50/   78]    Loss 1.712801    Top1 74.859375    Top5 97.671875    
2018-10-21 07:02:24,298 - ==> Top1: 74.780    Top5: 97.790    Loss: 1.712

2018-10-21 07:02:24,299 - ==> Best Top1: 78.360   On Epoch: 64

2018-10-21 07:02:24,300 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:02:24,313 - 

2018-10-21 07:02:24,313 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:02:26,162 - Epoch: [91][   50/  391]    Overall Loss 1.658394    Objective Loss 1.658394    Top1 80.609375    Top5 98.515625    LR 0.300000    Time 0.036916    
2018-10-21 07:02:27,734 - Epoch: [91][  100/  391]    Overall Loss 1.660133    Objective Loss 1.660133    Top1 80.375000    Top5 98.453125    LR 0.300000    Time 0.034158    
2018-10-21 07:02:29,312 - Epoch: [91][  150/  391]    Overall Loss 1.662746    Objective Loss 1.662746    Top1 80.041667    Top5 98.437500    LR 0.300000    Time 0.033280    
2018-10-21 07:02:30,859 - Epoch: [91][  200/  391]    Overall Loss 1.662947    Objective Loss 1.662947    Top1 79.980469    Top5 98.347656    LR 0.300000    Time 0.032684    
2018-10-21 07:02:32,426 - Epoch: [91][  250/  391]    Overall Loss 1.662618    Objective Loss 1.662618    Top1 80.037500    Top5 98.384375    LR 0.300000    Time 0.032405    
2018-10-21 07:02:33,985 - Epoch: [91][  300/  391]    Overall Loss 1.662084    Objective Loss 1.662084    Top1 80.067708    Top5 98.372396    LR 0.300000    Time 0.032192    
2018-10-21 07:02:35,554 - Epoch: [91][  350/  391]    Overall Loss 1.662343    Objective Loss 1.662343    Top1 80.046875    Top5 98.366071    LR 0.300000    Time 0.032070    
2018-10-21 07:02:36,972 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40013 |  0.00356 |    0.26397 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13321 | -0.00327 |    0.07607 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13331 |  0.00079 |    0.08866 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11177 | -0.00480 |    0.07345 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11038 | -0.00451 |    0.07197 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13424 | -0.01171 |    0.09130 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11863 | -0.01501 |    0.08534 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14462 | -0.00836 |    0.10769 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12237 | -0.00810 |    0.09357 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29862 | -0.00801 |    0.19512 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09643 | -0.00348 |    0.07177 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08420 | -0.01083 |    0.06581 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09992 | -0.01048 |    0.07653 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08024 | -0.00591 |    0.06078 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10996 | -0.00705 |    0.08659 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09621 | -0.00660 |    0.07550 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14874 | -0.00943 |    0.11287 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08799 | -0.01120 |    0.06801 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05771 | -0.00293 |    0.04265 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05311 | -0.00645 |    0.03987 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03518 |  0.00109 |    0.02352 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43191 | -0.00000 |    0.29306 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:02:36,972 - Total sparsity: 0.00

2018-10-21 07:02:36,972 - --- validate (epoch=91)-----------
2018-10-21 07:02:36,972 - 10000 samples (128 per mini-batch)
2018-10-21 07:02:38,244 - Epoch: [91][   50/   78]    Loss 1.673164    Top1 78.921875    Top5 98.203125    
2018-10-21 07:02:38,889 - ==> Top1: 78.880    Top5: 98.350    Loss: 1.672

2018-10-21 07:02:38,891 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:02:38,891 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:02:38,907 - 

2018-10-21 07:02:38,907 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:02:40,650 - Epoch: [92][   50/  391]    Overall Loss 1.679904    Objective Loss 1.679904    Top1 78.218750    Top5 98.296875    LR 0.300000    Time 0.034788    
2018-10-21 07:02:42,244 - Epoch: [92][  100/  391]    Overall Loss 1.669174    Objective Loss 1.669174    Top1 79.203125    Top5 98.429688    LR 0.300000    Time 0.033315    
2018-10-21 07:02:43,829 - Epoch: [92][  150/  391]    Overall Loss 1.671188    Objective Loss 1.671188    Top1 79.078125    Top5 98.322917    LR 0.300000    Time 0.032763    
2018-10-21 07:02:45,458 - Epoch: [92][  200/  391]    Overall Loss 1.669781    Objective Loss 1.669781    Top1 79.261719    Top5 98.339844    LR 0.300000    Time 0.032706    
2018-10-21 07:02:47,100 - Epoch: [92][  250/  391]    Overall Loss 1.668390    Objective Loss 1.668390    Top1 79.434375    Top5 98.303125    LR 0.300000    Time 0.032723    
2018-10-21 07:02:48,666 - Epoch: [92][  300/  391]    Overall Loss 1.667267    Objective Loss 1.667267    Top1 79.541667    Top5 98.335938    LR 0.300000    Time 0.032481    
2018-10-21 07:02:50,245 - Epoch: [92][  350/  391]    Overall Loss 1.666312    Objective Loss 1.666312    Top1 79.625000    Top5 98.370536    LR 0.300000    Time 0.032346    
2018-10-21 07:02:51,631 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40098 | -0.00604 |    0.26606 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13369 | -0.00227 |    0.07644 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13282 |  0.00140 |    0.08807 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11162 | -0.00592 |    0.07358 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11057 | -0.00384 |    0.07280 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13320 | -0.01223 |    0.09019 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11902 | -0.01521 |    0.08514 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14358 | -0.00857 |    0.10713 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12163 | -0.00959 |    0.09252 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30270 | -0.01318 |    0.19444 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09666 | -0.00339 |    0.07223 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08421 | -0.01057 |    0.06584 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10028 | -0.01043 |    0.07693 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08055 | -0.00526 |    0.06113 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11036 | -0.00727 |    0.08678 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09632 | -0.00593 |    0.07543 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14808 | -0.01099 |    0.11327 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08787 | -0.01088 |    0.06795 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05765 | -0.00303 |    0.04257 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05321 | -0.00608 |    0.03999 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03527 |  0.00109 |    0.02355 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43218 | -0.00000 |    0.29300 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:02:51,631 - Total sparsity: 0.00

2018-10-21 07:02:51,631 - --- validate (epoch=92)-----------
2018-10-21 07:02:51,631 - 10000 samples (128 per mini-batch)
2018-10-21 07:02:52,855 - Epoch: [92][   50/   78]    Loss 1.704022    Top1 75.625000    Top5 98.078125    
2018-10-21 07:02:53,527 - ==> Top1: 75.630    Top5: 98.010    Loss: 1.704

2018-10-21 07:02:53,529 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:02:53,529 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:02:53,548 - 

2018-10-21 07:02:53,549 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:02:55,303 - Epoch: [93][   50/  391]    Overall Loss 1.662415    Objective Loss 1.662415    Top1 79.953125    Top5 98.218750    LR 0.300000    Time 0.035032    
2018-10-21 07:02:56,882 - Epoch: [93][  100/  391]    Overall Loss 1.660447    Objective Loss 1.660447    Top1 80.203125    Top5 98.476562    LR 0.300000    Time 0.033283    
2018-10-21 07:02:58,451 - Epoch: [93][  150/  391]    Overall Loss 1.660693    Objective Loss 1.660693    Top1 80.177083    Top5 98.427083    LR 0.300000    Time 0.032633    
2018-10-21 07:03:00,013 - Epoch: [93][  200/  391]    Overall Loss 1.662017    Objective Loss 1.662017    Top1 80.074219    Top5 98.417969    LR 0.300000    Time 0.032275    
2018-10-21 07:03:01,577 - Epoch: [93][  250/  391]    Overall Loss 1.665233    Objective Loss 1.665233    Top1 79.778125    Top5 98.353125    LR 0.300000    Time 0.032068    
2018-10-21 07:03:03,121 - Epoch: [93][  300/  391]    Overall Loss 1.665406    Objective Loss 1.665406    Top1 79.744792    Top5 98.333333    LR 0.300000    Time 0.031862    
2018-10-21 07:03:04,665 - Epoch: [93][  350/  391]    Overall Loss 1.667889    Objective Loss 1.667889    Top1 79.484375    Top5 98.330357    LR 0.300000    Time 0.031716    
2018-10-21 07:03:06,062 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40383 | -0.00153 |    0.27412 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13356 | -0.00175 |    0.07587 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13309 |  0.00108 |    0.08790 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11250 | -0.00749 |    0.07372 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11163 | -0.00216 |    0.07389 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13597 | -0.01232 |    0.09277 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12088 | -0.01511 |    0.08677 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14533 | -0.00637 |    0.10827 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12215 | -0.00758 |    0.09273 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30600 | -0.00892 |    0.19876 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09772 | -0.00357 |    0.07306 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08464 | -0.01069 |    0.06610 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10062 | -0.00994 |    0.07713 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08075 | -0.00618 |    0.06124 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11067 | -0.00800 |    0.08721 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09630 | -0.00646 |    0.07548 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14845 | -0.01041 |    0.11322 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08787 | -0.01131 |    0.06803 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05760 | -0.00325 |    0.04248 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05322 | -0.00610 |    0.03994 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03516 |  0.00106 |    0.02346 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43151 | -0.00000 |    0.29217 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:03:06,063 - Total sparsity: 0.00

2018-10-21 07:03:06,063 - --- validate (epoch=93)-----------
2018-10-21 07:03:06,063 - 10000 samples (128 per mini-batch)
2018-10-21 07:03:07,434 - Epoch: [93][   50/   78]    Loss 1.811901    Top1 64.671875    Top5 95.546875    
2018-10-21 07:03:08,193 - ==> Top1: 64.920    Top5: 95.740    Loss: 1.810

2018-10-21 07:03:08,194 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:03:08,195 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:03:08,208 - 

2018-10-21 07:03:08,208 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:03:09,918 - Epoch: [94][   50/  391]    Overall Loss 1.666084    Objective Loss 1.666084    Top1 79.625000    Top5 98.515625    LR 0.300000    Time 0.034145    
2018-10-21 07:03:11,512 - Epoch: [94][  100/  391]    Overall Loss 1.662856    Objective Loss 1.662856    Top1 79.914062    Top5 98.484375    LR 0.300000    Time 0.032985    
2018-10-21 07:03:13,161 - Epoch: [94][  150/  391]    Overall Loss 1.662186    Objective Loss 1.662186    Top1 79.968750    Top5 98.526042    LR 0.300000    Time 0.032965    
2018-10-21 07:03:14,763 - Epoch: [94][  200/  391]    Overall Loss 1.664075    Objective Loss 1.664075    Top1 79.804688    Top5 98.468750    LR 0.300000    Time 0.032726    
2018-10-21 07:03:16,339 - Epoch: [94][  250/  391]    Overall Loss 1.664229    Objective Loss 1.664229    Top1 79.790625    Top5 98.434375    LR 0.300000    Time 0.032474    
2018-10-21 07:03:17,906 - Epoch: [94][  300/  391]    Overall Loss 1.663487    Objective Loss 1.663487    Top1 79.893229    Top5 98.434896    LR 0.300000    Time 0.032280    
2018-10-21 07:03:19,455 - Epoch: [94][  350/  391]    Overall Loss 1.663367    Objective Loss 1.663367    Top1 79.877232    Top5 98.448661    LR 0.300000    Time 0.032088    
2018-10-21 07:03:20,863 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40630 |  0.00741 |    0.27236 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13368 | -0.00404 |    0.07571 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13303 |  0.00089 |    0.08810 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11287 | -0.00745 |    0.07375 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11152 | -0.00334 |    0.07368 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13584 | -0.01361 |    0.09241 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12134 | -0.01529 |    0.08628 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14516 | -0.00811 |    0.10786 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12207 | -0.00921 |    0.09275 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30594 | -0.00654 |    0.19831 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09766 | -0.00323 |    0.07313 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08480 | -0.01098 |    0.06600 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10035 | -0.00878 |    0.07693 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08080 | -0.00701 |    0.06152 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11032 | -0.00837 |    0.08697 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09593 | -0.00628 |    0.07526 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14840 | -0.01302 |    0.11359 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08755 | -0.01135 |    0.06769 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05751 | -0.00343 |    0.04249 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05334 | -0.00615 |    0.04003 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03527 |  0.00115 |    0.02346 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43374 | -0.00000 |    0.29408 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:03:20,863 - Total sparsity: 0.00

2018-10-21 07:03:20,863 - --- validate (epoch=94)-----------
2018-10-21 07:03:20,864 - 10000 samples (128 per mini-batch)
2018-10-21 07:03:22,185 - Epoch: [94][   50/   78]    Loss 1.707950    Top1 75.062500    Top5 98.609375    
2018-10-21 07:03:22,869 - ==> Top1: 75.110    Top5: 98.600    Loss: 1.708

2018-10-21 07:03:22,871 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:03:22,871 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:03:22,884 - 

2018-10-21 07:03:22,884 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:03:24,702 - Epoch: [95][   50/  391]    Overall Loss 1.663051    Objective Loss 1.663051    Top1 79.937500    Top5 98.687500    LR 0.300000    Time 0.036299    
2018-10-21 07:03:26,358 - Epoch: [95][  100/  391]    Overall Loss 1.662745    Objective Loss 1.662745    Top1 79.960938    Top5 98.507812    LR 0.300000    Time 0.034688    
2018-10-21 07:03:27,983 - Epoch: [95][  150/  391]    Overall Loss 1.667204    Objective Loss 1.667204    Top1 79.505208    Top5 98.416667    LR 0.300000    Time 0.033943    
2018-10-21 07:03:29,593 - Epoch: [95][  200/  391]    Overall Loss 1.665919    Objective Loss 1.665919    Top1 79.699219    Top5 98.433594    LR 0.300000    Time 0.033499    
2018-10-21 07:03:31,182 - Epoch: [95][  250/  391]    Overall Loss 1.664649    Objective Loss 1.664649    Top1 79.831250    Top5 98.421875    LR 0.300000    Time 0.033146    
2018-10-21 07:03:32,742 - Epoch: [95][  300/  391]    Overall Loss 1.664716    Objective Loss 1.664716    Top1 79.804688    Top5 98.385417    LR 0.300000    Time 0.032812    
2018-10-21 07:03:34,302 - Epoch: [95][  350/  391]    Overall Loss 1.663886    Objective Loss 1.663886    Top1 79.890625    Top5 98.397321    LR 0.300000    Time 0.032576    
2018-10-21 07:03:35,700 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40850 | -0.00564 |    0.27355 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13267 | -0.00218 |    0.07448 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13243 |  0.00362 |    0.08816 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11333 | -0.00761 |    0.07444 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11205 | -0.00230 |    0.07336 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13581 | -0.01245 |    0.09229 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12209 | -0.01586 |    0.08759 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14450 | -0.00761 |    0.10726 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12196 | -0.00957 |    0.09274 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30483 | -0.01421 |    0.19640 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09794 | -0.00342 |    0.07340 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08493 | -0.01261 |    0.06624 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10019 | -0.00965 |    0.07688 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08079 | -0.00770 |    0.06194 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11033 | -0.00860 |    0.08693 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09608 | -0.00696 |    0.07535 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14778 | -0.01254 |    0.11283 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08758 | -0.01153 |    0.06772 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05762 | -0.00371 |    0.04263 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05365 | -0.00626 |    0.04035 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03548 |  0.00147 |    0.02362 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43548 | -0.00000 |    0.29484 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:03:35,700 - Total sparsity: 0.00

2018-10-21 07:03:35,701 - --- validate (epoch=95)-----------
2018-10-21 07:03:35,701 - 10000 samples (128 per mini-batch)
2018-10-21 07:03:36,944 - Epoch: [95][   50/   78]    Loss 1.687201    Top1 77.218750    Top5 97.921875    
2018-10-21 07:03:37,613 - ==> Top1: 77.340    Top5: 97.950    Loss: 1.687

2018-10-21 07:03:37,614 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:03:37,615 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:03:37,627 - 

2018-10-21 07:03:37,628 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:03:39,413 - Epoch: [96][   50/  391]    Overall Loss 1.662547    Objective Loss 1.662547    Top1 79.765625    Top5 98.312500    LR 0.300000    Time 0.035646    
2018-10-21 07:03:40,990 - Epoch: [96][  100/  391]    Overall Loss 1.660148    Objective Loss 1.660148    Top1 80.156250    Top5 98.351562    LR 0.300000    Time 0.033567    
2018-10-21 07:03:42,575 - Epoch: [96][  150/  391]    Overall Loss 1.660429    Objective Loss 1.660429    Top1 80.151042    Top5 98.401042    LR 0.300000    Time 0.032931    
2018-10-21 07:03:44,137 - Epoch: [96][  200/  391]    Overall Loss 1.660493    Objective Loss 1.660493    Top1 80.195312    Top5 98.429688    LR 0.300000    Time 0.032499    
2018-10-21 07:03:45,702 - Epoch: [96][  250/  391]    Overall Loss 1.661924    Objective Loss 1.661924    Top1 80.059375    Top5 98.403125    LR 0.300000    Time 0.032251    
2018-10-21 07:03:47,274 - Epoch: [96][  300/  391]    Overall Loss 1.663290    Objective Loss 1.663290    Top1 79.934896    Top5 98.393229    LR 0.300000    Time 0.032109    
2018-10-21 07:03:48,870 - Epoch: [96][  350/  391]    Overall Loss 1.663777    Objective Loss 1.663777    Top1 79.875000    Top5 98.395089    LR 0.300000    Time 0.032075    
2018-10-21 07:03:50,287 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40924 |  0.00124 |    0.27117 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13457 | -0.00339 |    0.07623 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13364 | -0.00088 |    0.08869 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11156 | -0.00749 |    0.07272 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11021 | -0.00354 |    0.07255 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13563 | -0.01413 |    0.09264 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12203 | -0.01452 |    0.08695 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14375 | -0.00780 |    0.10615 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12155 | -0.00819 |    0.09219 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30547 | -0.00959 |    0.19601 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09695 | -0.00418 |    0.07245 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08422 | -0.01117 |    0.06534 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10023 | -0.01026 |    0.07677 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08084 | -0.00644 |    0.06172 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11052 | -0.00885 |    0.08696 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09626 | -0.00719 |    0.07554 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14664 | -0.01146 |    0.11236 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08745 | -0.01145 |    0.06769 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05754 | -0.00361 |    0.04243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05342 | -0.00614 |    0.04021 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03537 |  0.00102 |    0.02356 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43398 | -0.00000 |    0.29445 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:03:50,287 - Total sparsity: 0.00

2018-10-21 07:03:50,287 - --- validate (epoch=96)-----------
2018-10-21 07:03:50,287 - 10000 samples (128 per mini-batch)
2018-10-21 07:03:51,499 - Epoch: [96][   50/   78]    Loss 1.710841    Top1 74.875000    Top5 98.421875    
2018-10-21 07:03:52,161 - ==> Top1: 74.560    Top5: 98.390    Loss: 1.713

2018-10-21 07:03:52,163 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:03:52,163 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:03:52,176 - 

2018-10-21 07:03:52,177 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:03:53,983 - Epoch: [97][   50/  391]    Overall Loss 1.654460    Objective Loss 1.654460    Top1 80.734375    Top5 98.421875    LR 0.300000    Time 0.036066    
2018-10-21 07:03:55,635 - Epoch: [97][  100/  391]    Overall Loss 1.661419    Objective Loss 1.661419    Top1 79.984375    Top5 98.382812    LR 0.300000    Time 0.034534    
2018-10-21 07:03:57,298 - Epoch: [97][  150/  391]    Overall Loss 1.661218    Objective Loss 1.661218    Top1 80.046875    Top5 98.447917    LR 0.300000    Time 0.034091    
2018-10-21 07:03:58,971 - Epoch: [97][  200/  391]    Overall Loss 1.660668    Objective Loss 1.660668    Top1 80.082031    Top5 98.410156    LR 0.300000    Time 0.033925    
2018-10-21 07:04:00,619 - Epoch: [97][  250/  391]    Overall Loss 1.661202    Objective Loss 1.661202    Top1 80.087500    Top5 98.346875    LR 0.300000    Time 0.033722    
2018-10-21 07:04:02,242 - Epoch: [97][  300/  391]    Overall Loss 1.660713    Objective Loss 1.660713    Top1 80.106771    Top5 98.346354    LR 0.300000    Time 0.033502    
2018-10-21 07:04:03,840 - Epoch: [97][  350/  391]    Overall Loss 1.660502    Objective Loss 1.660502    Top1 80.169643    Top5 98.386161    LR 0.300000    Time 0.033277    
2018-10-21 07:04:05,274 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40267 |  0.00354 |    0.26748 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13263 | -0.00337 |    0.07507 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13251 | -0.00071 |    0.08765 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11090 | -0.00982 |    0.07181 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11026 | -0.00300 |    0.07254 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13539 | -0.01338 |    0.09289 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12223 | -0.01262 |    0.08694 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14381 | -0.00726 |    0.10706 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12105 | -0.00932 |    0.09179 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30454 | -0.01254 |    0.19507 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09661 | -0.00442 |    0.07225 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08367 | -0.01111 |    0.06515 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10014 | -0.01080 |    0.07629 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08071 | -0.00559 |    0.06144 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11067 | -0.00862 |    0.08698 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09652 | -0.00656 |    0.07557 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14565 | -0.01051 |    0.11116 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08742 | -0.01157 |    0.06784 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05750 | -0.00391 |    0.04238 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05333 | -0.00637 |    0.04014 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03544 |  0.00107 |    0.02346 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43500 | -0.00000 |    0.29448 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:04:05,274 - Total sparsity: 0.00

2018-10-21 07:04:05,274 - --- validate (epoch=97)-----------
2018-10-21 07:04:05,274 - 10000 samples (128 per mini-batch)
2018-10-21 07:04:06,510 - Epoch: [97][   50/   78]    Loss 1.703672    Top1 75.734375    Top5 97.000000    
2018-10-21 07:04:07,174 - ==> Top1: 75.680    Top5: 97.070    Loss: 1.703

2018-10-21 07:04:07,176 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:04:07,176 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:04:07,196 - 

2018-10-21 07:04:07,196 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:04:09,103 - Epoch: [98][   50/  391]    Overall Loss 1.662758    Objective Loss 1.662758    Top1 80.171875    Top5 98.156250    LR 0.300000    Time 0.038079    
2018-10-21 07:04:10,764 - Epoch: [98][  100/  391]    Overall Loss 1.667257    Objective Loss 1.667257    Top1 79.578125    Top5 98.101562    LR 0.300000    Time 0.035625    
2018-10-21 07:04:12,386 - Epoch: [98][  150/  391]    Overall Loss 1.665516    Objective Loss 1.665516    Top1 79.729167    Top5 98.166667    LR 0.300000    Time 0.034545    
2018-10-21 07:04:14,039 - Epoch: [98][  200/  391]    Overall Loss 1.663472    Objective Loss 1.663472    Top1 79.941406    Top5 98.246094    LR 0.300000    Time 0.034167    
2018-10-21 07:04:15,766 - Epoch: [98][  250/  391]    Overall Loss 1.661938    Objective Loss 1.661938    Top1 80.140625    Top5 98.268750    LR 0.300000    Time 0.034230    
2018-10-21 07:04:17,414 - Epoch: [98][  300/  391]    Overall Loss 1.661965    Objective Loss 1.661965    Top1 80.111979    Top5 98.309896    LR 0.300000    Time 0.034010    
2018-10-21 07:04:19,189 - Epoch: [98][  350/  391]    Overall Loss 1.662443    Objective Loss 1.662443    Top1 80.060268    Top5 98.305804    LR 0.300000    Time 0.034219    
2018-10-21 07:04:20,718 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40360 | -0.01080 |    0.26945 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13371 | -0.00213 |    0.07566 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13271 | -0.00024 |    0.08770 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11313 | -0.00974 |    0.07385 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11176 | -0.00249 |    0.07325 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13603 | -0.01308 |    0.09257 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12223 | -0.01349 |    0.08723 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14380 | -0.00840 |    0.10653 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12120 | -0.00895 |    0.09215 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30527 | -0.00650 |    0.19427 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09588 | -0.00537 |    0.07190 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08342 | -0.01083 |    0.06467 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10022 | -0.01112 |    0.07665 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08045 | -0.00539 |    0.06109 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11085 | -0.00905 |    0.08741 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09682 | -0.00670 |    0.07597 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14640 | -0.01053 |    0.11115 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08817 | -0.01157 |    0.06825 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05806 | -0.00358 |    0.04278 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05382 | -0.00609 |    0.04052 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03553 |  0.00129 |    0.02361 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43425 | -0.00000 |    0.29295 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:04:20,718 - Total sparsity: 0.00

2018-10-21 07:04:20,718 - --- validate (epoch=98)-----------
2018-10-21 07:04:20,718 - 10000 samples (128 per mini-batch)
2018-10-21 07:04:21,967 - Epoch: [98][   50/   78]    Loss 1.707120    Top1 75.500000    Top5 97.937500    
2018-10-21 07:04:22,602 - ==> Top1: 75.390    Top5: 97.950    Loss: 1.708

2018-10-21 07:04:22,605 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:04:22,606 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:04:22,623 - 

2018-10-21 07:04:22,624 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:04:24,392 - Epoch: [99][   50/  391]    Overall Loss 1.664543    Objective Loss 1.664543    Top1 79.890625    Top5 98.343750    LR 0.300000    Time 0.035294    
2018-10-21 07:04:26,086 - Epoch: [99][  100/  391]    Overall Loss 1.664717    Objective Loss 1.664717    Top1 79.851562    Top5 98.562500    LR 0.300000    Time 0.034563    
2018-10-21 07:04:27,893 - Epoch: [99][  150/  391]    Overall Loss 1.663465    Objective Loss 1.663465    Top1 79.911458    Top5 98.583333    LR 0.300000    Time 0.035074    
2018-10-21 07:04:29,580 - Epoch: [99][  200/  391]    Overall Loss 1.661759    Objective Loss 1.661759    Top1 80.070312    Top5 98.558594    LR 0.300000    Time 0.034729    
2018-10-21 07:04:31,220 - Epoch: [99][  250/  391]    Overall Loss 1.662072    Objective Loss 1.662072    Top1 80.068750    Top5 98.531250    LR 0.300000    Time 0.034330    
2018-10-21 07:04:32,921 - Epoch: [99][  300/  391]    Overall Loss 1.662296    Objective Loss 1.662296    Top1 80.031250    Top5 98.486979    LR 0.300000    Time 0.034273    
2018-10-21 07:04:34,605 - Epoch: [99][  350/  391]    Overall Loss 1.663296    Objective Loss 1.663296    Top1 79.912946    Top5 98.500000    LR 0.300000    Time 0.034183    
2018-10-21 07:04:36,079 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40347 |  0.00196 |    0.26806 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13464 | -0.00066 |    0.07693 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13315 | -0.00105 |    0.08853 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11302 | -0.01078 |    0.07493 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11239 | -0.00172 |    0.07357 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13549 | -0.01327 |    0.09193 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12230 | -0.01352 |    0.08689 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14409 | -0.00747 |    0.10623 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12167 | -0.00704 |    0.09218 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30629 | -0.01311 |    0.19485 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09655 | -0.00539 |    0.07177 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08383 | -0.01141 |    0.06507 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09960 | -0.01091 |    0.07604 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08013 | -0.00585 |    0.06095 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11128 | -0.00938 |    0.08770 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09692 | -0.00633 |    0.07609 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14631 | -0.00990 |    0.11112 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08813 | -0.01113 |    0.06805 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05821 | -0.00377 |    0.04296 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05402 | -0.00575 |    0.04057 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03563 |  0.00132 |    0.02378 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43617 | -0.00000 |    0.29532 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:04:36,079 - Total sparsity: 0.00

2018-10-21 07:04:36,079 - --- validate (epoch=99)-----------
2018-10-21 07:04:36,080 - 10000 samples (128 per mini-batch)
2018-10-21 07:04:37,303 - Epoch: [99][   50/   78]    Loss 1.711222    Top1 74.906250    Top5 96.984375    
2018-10-21 07:04:37,938 - ==> Top1: 74.900    Top5: 97.170    Loss: 1.711

2018-10-21 07:04:37,939 - ==> Best Top1: 78.880   On Epoch: 91

2018-10-21 07:04:37,939 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:04:37,953 - 

2018-10-21 07:04:37,953 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:04:39,890 - Epoch: [100][   50/  391]    Overall Loss 1.652256    Objective Loss 1.652256    Top1 80.937500    Top5 98.406250    LR 0.030000    Time 0.038667    
2018-10-21 07:04:41,642 - Epoch: [100][  100/  391]    Overall Loss 1.640887    Objective Loss 1.640887    Top1 82.070312    Top5 98.671875    LR 0.030000    Time 0.036826    
2018-10-21 07:04:43,280 - Epoch: [100][  150/  391]    Overall Loss 1.633228    Objective Loss 1.633228    Top1 82.921875    Top5 98.682292    LR 0.030000    Time 0.035459    
2018-10-21 07:04:44,843 - Epoch: [100][  200/  391]    Overall Loss 1.626890    Objective Loss 1.626890    Top1 83.617188    Top5 98.769531    LR 0.030000    Time 0.034394    
2018-10-21 07:04:46,481 - Epoch: [100][  250/  391]    Overall Loss 1.621912    Objective Loss 1.621912    Top1 84.115625    Top5 98.834375    LR 0.030000    Time 0.034060    
2018-10-21 07:04:48,074 - Epoch: [100][  300/  391]    Overall Loss 1.619084    Objective Loss 1.619084    Top1 84.411458    Top5 98.867188    LR 0.030000    Time 0.033685    
2018-10-21 07:04:49,636 - Epoch: [100][  350/  391]    Overall Loss 1.617476    Objective Loss 1.617476    Top1 84.542411    Top5 98.899554    LR 0.030000    Time 0.033330    
2018-10-21 07:04:51,042 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39936 | -0.00169 |    0.26493 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13321 | -0.00105 |    0.07607 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13176 | -0.00093 |    0.08729 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11184 | -0.01060 |    0.07394 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11121 | -0.00181 |    0.07277 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13404 | -0.01352 |    0.09073 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12104 | -0.01328 |    0.08581 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14258 | -0.00743 |    0.10511 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12040 | -0.00708 |    0.09121 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30315 | -0.01231 |    0.19232 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09556 | -0.00508 |    0.07096 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08297 | -0.01119 |    0.06437 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09856 | -0.01086 |    0.07526 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07929 | -0.00586 |    0.06032 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11012 | -0.00936 |    0.08679 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09592 | -0.00630 |    0.07531 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14479 | -0.00990 |    0.11003 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08721 | -0.01110 |    0.06733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05760 | -0.00380 |    0.04252 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05343 | -0.00591 |    0.04019 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03526 |  0.00125 |    0.02352 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43465 | -0.00000 |    0.29477 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:04:51,042 - Total sparsity: 0.00

2018-10-21 07:04:51,042 - --- validate (epoch=100)-----------
2018-10-21 07:04:51,042 - 10000 samples (128 per mini-batch)
2018-10-21 07:04:52,246 - Epoch: [100][   50/   78]    Loss 1.606559    Top1 85.515625    Top5 99.062500    
2018-10-21 07:04:52,883 - ==> Top1: 85.580    Top5: 99.140    Loss: 1.605

2018-10-21 07:04:52,885 - ==> Best Top1: 85.580   On Epoch: 100

2018-10-21 07:04:52,885 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:04:52,902 - 

2018-10-21 07:04:52,902 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:04:54,703 - Epoch: [101][   50/  391]    Overall Loss 1.611734    Objective Loss 1.611734    Top1 85.218750    Top5 99.000000    LR 0.030000    Time 0.035935    
2018-10-21 07:04:56,375 - Epoch: [101][  100/  391]    Overall Loss 1.603784    Objective Loss 1.603784    Top1 85.953125    Top5 99.101562    LR 0.030000    Time 0.034659    
2018-10-21 07:04:58,133 - Epoch: [101][  150/  391]    Overall Loss 1.604450    Objective Loss 1.604450    Top1 85.859375    Top5 99.109375    LR 0.030000    Time 0.034815    
2018-10-21 07:04:59,746 - Epoch: [101][  200/  391]    Overall Loss 1.603687    Objective Loss 1.603687    Top1 85.949219    Top5 99.089844    LR 0.030000    Time 0.034162    
2018-10-21 07:05:01,329 - Epoch: [101][  250/  391]    Overall Loss 1.601162    Objective Loss 1.601162    Top1 86.215625    Top5 99.134375    LR 0.030000    Time 0.033655    
2018-10-21 07:05:02,996 - Epoch: [101][  300/  391]    Overall Loss 1.599983    Objective Loss 1.599983    Top1 86.333333    Top5 99.122396    LR 0.030000    Time 0.033592    
2018-10-21 07:05:04,606 - Epoch: [101][  350/  391]    Overall Loss 1.598336    Objective Loss 1.598336    Top1 86.488839    Top5 99.151786    LR 0.030000    Time 0.033388    
2018-10-21 07:05:06,049 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39510 | -0.00307 |    0.26285 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13177 | -0.00112 |    0.07516 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13034 | -0.00112 |    0.08636 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11061 | -0.01055 |    0.07305 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10999 | -0.00205 |    0.07202 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13262 | -0.01323 |    0.08974 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11976 | -0.01290 |    0.08489 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14104 | -0.00751 |    0.10404 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11912 | -0.00685 |    0.09023 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29992 | -0.01137 |    0.19001 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09453 | -0.00530 |    0.07022 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08211 | -0.01083 |    0.06370 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09749 | -0.01090 |    0.07446 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07846 | -0.00558 |    0.05969 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10894 | -0.00919 |    0.08587 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09489 | -0.00622 |    0.07451 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14325 | -0.00969 |    0.10878 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08626 | -0.01108 |    0.06665 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05698 | -0.00381 |    0.04209 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05284 | -0.00602 |    0.03978 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03489 |  0.00120 |    0.02328 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43325 | -0.00000 |    0.29386 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:05:06,050 - Total sparsity: 0.00

2018-10-21 07:05:06,050 - --- validate (epoch=101)-----------
2018-10-21 07:05:06,050 - 10000 samples (128 per mini-batch)
2018-10-21 07:05:07,239 - Epoch: [101][   50/   78]    Loss 1.597950    Top1 86.406250    Top5 99.140625    
2018-10-21 07:05:07,877 - ==> Top1: 86.420    Top5: 99.260    Loss: 1.598

2018-10-21 07:05:07,879 - ==> Best Top1: 86.420   On Epoch: 101

2018-10-21 07:05:07,879 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:05:07,896 - 

2018-10-21 07:05:07,897 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:05:09,600 - Epoch: [102][   50/  391]    Overall Loss 1.595494    Objective Loss 1.595494    Top1 86.671875    Top5 99.250000    LR 0.030000    Time 0.034002    
2018-10-21 07:05:11,220 - Epoch: [102][  100/  391]    Overall Loss 1.591127    Objective Loss 1.591127    Top1 87.226562    Top5 99.250000    LR 0.030000    Time 0.033175    
2018-10-21 07:05:12,827 - Epoch: [102][  150/  391]    Overall Loss 1.592461    Objective Loss 1.592461    Top1 87.093750    Top5 99.197917    LR 0.030000    Time 0.032812    
2018-10-21 07:05:14,421 - Epoch: [102][  200/  391]    Overall Loss 1.589683    Objective Loss 1.589683    Top1 87.390625    Top5 99.199219    LR 0.030000    Time 0.032569    
2018-10-21 07:05:15,974 - Epoch: [102][  250/  391]    Overall Loss 1.588707    Objective Loss 1.588707    Top1 87.506250    Top5 99.221875    LR 0.030000    Time 0.032255    
2018-10-21 07:05:17,613 - Epoch: [102][  300/  391]    Overall Loss 1.589006    Objective Loss 1.589006    Top1 87.447917    Top5 99.216146    LR 0.030000    Time 0.032337    
2018-10-21 07:05:19,332 - Epoch: [102][  350/  391]    Overall Loss 1.588754    Objective Loss 1.588754    Top1 87.470982    Top5 99.191964    LR 0.030000    Time 0.032619    
2018-10-21 07:05:20,763 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39090 | -0.00210 |    0.25952 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13034 | -0.00108 |    0.07446 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12893 | -0.00113 |    0.08540 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10943 | -0.01026 |    0.07226 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10880 | -0.00183 |    0.07122 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13123 | -0.01286 |    0.08876 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11846 | -0.01286 |    0.08402 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13955 | -0.00706 |    0.10293 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11783 | -0.00696 |    0.08925 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29671 | -0.01085 |    0.18781 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09353 | -0.00521 |    0.06948 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08126 | -0.01059 |    0.06299 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09647 | -0.01070 |    0.07367 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07763 | -0.00546 |    0.05907 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10778 | -0.00907 |    0.08495 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09388 | -0.00612 |    0.07373 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14173 | -0.00938 |    0.10775 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08532 | -0.01110 |    0.06598 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05637 | -0.00383 |    0.04169 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05226 | -0.00611 |    0.03937 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03452 |  0.00116 |    0.02305 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43192 | -0.00000 |    0.29321 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:05:20,763 - Total sparsity: 0.00

2018-10-21 07:05:20,763 - --- validate (epoch=102)-----------
2018-10-21 07:05:20,763 - 10000 samples (128 per mini-batch)
2018-10-21 07:05:22,019 - Epoch: [102][   50/   78]    Loss 1.592787    Top1 87.093750    Top5 99.250000    
2018-10-21 07:05:22,662 - ==> Top1: 87.180    Top5: 99.320    Loss: 1.591

2018-10-21 07:05:22,664 - ==> Best Top1: 87.180   On Epoch: 102

2018-10-21 07:05:22,664 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:05:22,681 - 

2018-10-21 07:05:22,682 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:05:24,402 - Epoch: [103][   50/  391]    Overall Loss 1.583872    Objective Loss 1.583872    Top1 88.062500    Top5 99.250000    LR 0.030000    Time 0.034336    
2018-10-21 07:05:26,078 - Epoch: [103][  100/  391]    Overall Loss 1.584201    Objective Loss 1.584201    Top1 87.960938    Top5 99.195312    LR 0.030000    Time 0.033899    
2018-10-21 07:05:27,726 - Epoch: [103][  150/  391]    Overall Loss 1.585229    Objective Loss 1.585229    Top1 87.817708    Top5 99.244792    LR 0.030000    Time 0.033573    
2018-10-21 07:05:29,389 - Epoch: [103][  200/  391]    Overall Loss 1.586789    Objective Loss 1.586789    Top1 87.660156    Top5 99.230469    LR 0.030000    Time 0.033482    
2018-10-21 07:05:31,082 - Epoch: [103][  250/  391]    Overall Loss 1.585941    Objective Loss 1.585941    Top1 87.740625    Top5 99.268750    LR 0.030000    Time 0.033549    
2018-10-21 07:05:32,795 - Epoch: [103][  300/  391]    Overall Loss 1.585413    Objective Loss 1.585413    Top1 87.799479    Top5 99.263021    LR 0.030000    Time 0.033660    
2018-10-21 07:05:34,456 - Epoch: [103][  350/  391]    Overall Loss 1.584937    Objective Loss 1.584937    Top1 87.841518    Top5 99.265625    LR 0.030000    Time 0.033589    
2018-10-21 07:05:35,937 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38683 | -0.00311 |    0.25682 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12896 | -0.00143 |    0.07372 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12756 | -0.00093 |    0.08453 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10827 | -0.01006 |    0.07149 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10763 | -0.00197 |    0.07045 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12981 | -0.01311 |    0.08764 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11718 | -0.01290 |    0.08311 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13806 | -0.00728 |    0.10182 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11658 | -0.00695 |    0.08827 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29357 | -0.01057 |    0.18598 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09256 | -0.00517 |    0.06874 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08041 | -0.01050 |    0.06236 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09545 | -0.01080 |    0.07297 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07682 | -0.00545 |    0.05844 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10664 | -0.00903 |    0.08402 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09289 | -0.00608 |    0.07298 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14022 | -0.00934 |    0.10663 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08442 | -0.01105 |    0.06531 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05578 | -0.00381 |    0.04128 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05169 | -0.00620 |    0.03897 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03415 |  0.00109 |    0.02282 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43067 | -0.00000 |    0.29249 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:05:35,938 - Total sparsity: 0.00

2018-10-21 07:05:35,938 - --- validate (epoch=103)-----------
2018-10-21 07:05:35,938 - 10000 samples (128 per mini-batch)
2018-10-21 07:05:37,173 - Epoch: [103][   50/   78]    Loss 1.589744    Top1 87.093750    Top5 99.218750    
2018-10-21 07:05:37,878 - ==> Top1: 86.960    Top5: 99.320    Loss: 1.591

2018-10-21 07:05:37,880 - ==> Best Top1: 87.180   On Epoch: 102

2018-10-21 07:05:37,881 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:05:37,894 - 

2018-10-21 07:05:37,895 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:05:39,683 - Epoch: [104][   50/  391]    Overall Loss 1.579679    Objective Loss 1.579679    Top1 88.390625    Top5 99.171875    LR 0.030000    Time 0.035699    
2018-10-21 07:05:41,475 - Epoch: [104][  100/  391]    Overall Loss 1.578471    Objective Loss 1.578471    Top1 88.468750    Top5 99.210938    LR 0.030000    Time 0.035740    
2018-10-21 07:05:43,114 - Epoch: [104][  150/  391]    Overall Loss 1.579451    Objective Loss 1.579451    Top1 88.354167    Top5 99.197917    LR 0.030000    Time 0.034742    
2018-10-21 07:05:44,840 - Epoch: [104][  200/  391]    Overall Loss 1.580252    Objective Loss 1.580252    Top1 88.289062    Top5 99.265625    LR 0.030000    Time 0.034675    
2018-10-21 07:05:46,551 - Epoch: [104][  250/  391]    Overall Loss 1.580234    Objective Loss 1.580234    Top1 88.328125    Top5 99.284375    LR 0.030000    Time 0.034576    
2018-10-21 07:05:48,209 - Epoch: [104][  300/  391]    Overall Loss 1.580980    Objective Loss 1.580980    Top1 88.252604    Top5 99.265625    LR 0.030000    Time 0.034334    
2018-10-21 07:05:49,847 - Epoch: [104][  350/  391]    Overall Loss 1.580951    Objective Loss 1.580951    Top1 88.263393    Top5 99.261161    LR 0.030000    Time 0.034100    
2018-10-21 07:05:51,271 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38277 | -0.00330 |    0.25430 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12758 | -0.00169 |    0.07294 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12620 | -0.00087 |    0.08362 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10710 | -0.01002 |    0.07065 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10646 | -0.00208 |    0.06966 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12842 | -0.01314 |    0.08660 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11596 | -0.01245 |    0.08221 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13656 | -0.00754 |    0.10075 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11534 | -0.00670 |    0.08736 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29046 | -0.01006 |    0.18398 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09160 | -0.00513 |    0.06805 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07956 | -0.01047 |    0.06173 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09446 | -0.01069 |    0.07223 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07601 | -0.00548 |    0.05784 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10550 | -0.00905 |    0.08313 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09191 | -0.00600 |    0.07222 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13873 | -0.00914 |    0.10564 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08352 | -0.01099 |    0.06464 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05519 | -0.00375 |    0.04086 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05114 | -0.00625 |    0.03857 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03379 |  0.00104 |    0.02257 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42938 | -0.00000 |    0.29157 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:05:51,272 - Total sparsity: 0.00

2018-10-21 07:05:51,272 - --- validate (epoch=104)-----------
2018-10-21 07:05:51,272 - 10000 samples (128 per mini-batch)
2018-10-21 07:05:52,503 - Epoch: [104][   50/   78]    Loss 1.587340    Top1 87.625000    Top5 99.328125    
2018-10-21 07:05:53,161 - ==> Top1: 87.710    Top5: 99.390    Loss: 1.586

2018-10-21 07:05:53,163 - ==> Best Top1: 87.710   On Epoch: 104

2018-10-21 07:05:53,163 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:05:53,180 - 

2018-10-21 07:05:53,180 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:05:55,112 - Epoch: [105][   50/  391]    Overall Loss 1.580162    Objective Loss 1.580162    Top1 88.296875    Top5 99.406250    LR 0.030000    Time 0.038573    
2018-10-21 07:05:56,829 - Epoch: [105][  100/  391]    Overall Loss 1.579313    Objective Loss 1.579313    Top1 88.398438    Top5 99.343750    LR 0.030000    Time 0.036435    
2018-10-21 07:05:58,436 - Epoch: [105][  150/  391]    Overall Loss 1.578134    Objective Loss 1.578134    Top1 88.531250    Top5 99.343750    LR 0.030000    Time 0.034988    
2018-10-21 07:06:00,088 - Epoch: [105][  200/  391]    Overall Loss 1.578867    Objective Loss 1.578867    Top1 88.480469    Top5 99.339844    LR 0.030000    Time 0.034489    
2018-10-21 07:06:01,722 - Epoch: [105][  250/  391]    Overall Loss 1.578812    Objective Loss 1.578812    Top1 88.512500    Top5 99.312500    LR 0.030000    Time 0.034116    
2018-10-21 07:06:03,406 - Epoch: [105][  300/  391]    Overall Loss 1.579079    Objective Loss 1.579079    Top1 88.455729    Top5 99.330729    LR 0.030000    Time 0.034036    
2018-10-21 07:06:05,075 - Epoch: [105][  350/  391]    Overall Loss 1.578692    Objective Loss 1.578692    Top1 88.500000    Top5 99.332589    LR 0.030000    Time 0.033936    
2018-10-21 07:06:06,507 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37878 | -0.00446 |    0.25193 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12623 | -0.00218 |    0.07211 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12487 | -0.00051 |    0.08278 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10599 | -0.00971 |    0.06995 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10533 | -0.00199 |    0.06895 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12703 | -0.01359 |    0.08568 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11476 | -0.01213 |    0.08130 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13512 | -0.00747 |    0.09973 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11412 | -0.00673 |    0.08645 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28741 | -0.00942 |    0.18218 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09065 | -0.00521 |    0.06737 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07872 | -0.01049 |    0.06112 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09350 | -0.01060 |    0.07152 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07523 | -0.00543 |    0.05728 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10440 | -0.00884 |    0.08226 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09095 | -0.00594 |    0.07148 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13727 | -0.00903 |    0.10459 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08265 | -0.01092 |    0.06398 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05462 | -0.00374 |    0.04047 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05059 | -0.00633 |    0.03819 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03343 |  0.00097 |    0.02236 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42815 | -0.00000 |    0.29085 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:06:06,507 - Total sparsity: 0.00

2018-10-21 07:06:06,507 - --- validate (epoch=105)-----------
2018-10-21 07:06:06,508 - 10000 samples (128 per mini-batch)
2018-10-21 07:06:07,743 - Epoch: [105][   50/   78]    Loss 1.588306    Top1 87.359375    Top5 99.328125    
2018-10-21 07:06:08,407 - ==> Top1: 87.500    Top5: 99.410    Loss: 1.587

2018-10-21 07:06:08,409 - ==> Best Top1: 87.710   On Epoch: 104

2018-10-21 07:06:08,409 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:06:08,422 - 

2018-10-21 07:06:08,422 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:06:10,415 - Epoch: [106][   50/  391]    Overall Loss 1.576704    Objective Loss 1.576704    Top1 88.796875    Top5 99.265625    LR 0.030000    Time 0.039794    
2018-10-21 07:06:12,040 - Epoch: [106][  100/  391]    Overall Loss 1.576491    Objective Loss 1.576491    Top1 88.664062    Top5 99.281250    LR 0.030000    Time 0.036123    
2018-10-21 07:06:13,626 - Epoch: [106][  150/  391]    Overall Loss 1.576379    Objective Loss 1.576379    Top1 88.713542    Top5 99.302083    LR 0.030000    Time 0.034634    
2018-10-21 07:06:15,267 - Epoch: [106][  200/  391]    Overall Loss 1.575835    Objective Loss 1.575835    Top1 88.761719    Top5 99.308594    LR 0.030000    Time 0.034173    
2018-10-21 07:06:16,930 - Epoch: [106][  250/  391]    Overall Loss 1.575489    Objective Loss 1.575489    Top1 88.821875    Top5 99.331250    LR 0.030000    Time 0.033979    
2018-10-21 07:06:18,631 - Epoch: [106][  300/  391]    Overall Loss 1.575974    Objective Loss 1.575974    Top1 88.752604    Top5 99.335938    LR 0.030000    Time 0.033977    
2018-10-21 07:06:20,271 - Epoch: [106][  350/  391]    Overall Loss 1.576296    Objective Loss 1.576296    Top1 88.718750    Top5 99.337054    LR 0.030000    Time 0.033804    
2018-10-21 07:06:21,702 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37484 | -0.00327 |    0.24928 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12492 | -0.00226 |    0.07125 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12355 | -0.00059 |    0.08191 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10488 | -0.00953 |    0.06919 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10421 | -0.00207 |    0.06825 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12573 | -0.01341 |    0.08469 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11360 | -0.01150 |    0.08041 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13371 | -0.00719 |    0.09869 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11292 | -0.00673 |    0.08552 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28440 | -0.00864 |    0.17972 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08972 | -0.00522 |    0.06667 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07791 | -0.01044 |    0.06050 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09256 | -0.01047 |    0.07079 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07445 | -0.00554 |    0.05668 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10330 | -0.00870 |    0.08136 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09000 | -0.00585 |    0.07074 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13583 | -0.00887 |    0.10344 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08181 | -0.01078 |    0.06336 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05406 | -0.00369 |    0.04006 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05004 | -0.00641 |    0.03779 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03309 |  0.00092 |    0.02212 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42698 | -0.00000 |    0.29023 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:06:21,702 - Total sparsity: 0.00

2018-10-21 07:06:21,702 - --- validate (epoch=106)-----------
2018-10-21 07:06:21,702 - 10000 samples (128 per mini-batch)
2018-10-21 07:06:23,035 - Epoch: [106][   50/   78]    Loss 1.587090    Top1 87.625000    Top5 99.312500    
2018-10-21 07:06:23,725 - ==> Top1: 87.580    Top5: 99.360    Loss: 1.587

2018-10-21 07:06:23,727 - ==> Best Top1: 87.710   On Epoch: 104

2018-10-21 07:06:23,728 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:06:23,744 - 

2018-10-21 07:06:23,744 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:06:25,571 - Epoch: [107][   50/  391]    Overall Loss 1.575251    Objective Loss 1.575251    Top1 88.828125    Top5 99.375000    LR 0.030000    Time 0.036474    
2018-10-21 07:06:27,139 - Epoch: [107][  100/  391]    Overall Loss 1.573719    Objective Loss 1.573719    Top1 89.015625    Top5 99.296875    LR 0.030000    Time 0.033886    
2018-10-21 07:06:28,718 - Epoch: [107][  150/  391]    Overall Loss 1.572751    Objective Loss 1.572751    Top1 89.052083    Top5 99.296875    LR 0.030000    Time 0.033097    
2018-10-21 07:06:30,250 - Epoch: [107][  200/  391]    Overall Loss 1.571101    Objective Loss 1.571101    Top1 89.261719    Top5 99.339844    LR 0.030000    Time 0.032475    
2018-10-21 07:06:31,819 - Epoch: [107][  250/  391]    Overall Loss 1.573676    Objective Loss 1.573676    Top1 88.943750    Top5 99.306250    LR 0.030000    Time 0.032246    
2018-10-21 07:06:33,422 - Epoch: [107][  300/  391]    Overall Loss 1.573926    Objective Loss 1.573926    Top1 88.911458    Top5 99.291667    LR 0.030000    Time 0.032206    
2018-10-21 07:06:34,990 - Epoch: [107][  350/  391]    Overall Loss 1.573746    Objective Loss 1.573746    Top1 88.968750    Top5 99.310268    LR 0.030000    Time 0.032077    
2018-10-21 07:06:36,393 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37102 | -0.00124 |    0.24634 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12362 | -0.00218 |    0.07068 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12227 | -0.00082 |    0.08119 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10378 | -0.00944 |    0.06842 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10311 | -0.00204 |    0.06756 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12441 | -0.01354 |    0.08387 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11242 | -0.01134 |    0.07959 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13232 | -0.00706 |    0.09762 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11173 | -0.00664 |    0.08459 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28141 | -0.00858 |    0.17753 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08881 | -0.00532 |    0.06606 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07711 | -0.01038 |    0.05988 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09160 | -0.01061 |    0.07008 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07370 | -0.00545 |    0.05609 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10222 | -0.00859 |    0.08049 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08907 | -0.00576 |    0.07002 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13441 | -0.00869 |    0.10246 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08097 | -0.01065 |    0.06273 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05351 | -0.00366 |    0.03967 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04951 | -0.00653 |    0.03741 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03274 |  0.00085 |    0.02190 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42590 | -0.00000 |    0.28964 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:06:36,393 - Total sparsity: 0.00

2018-10-21 07:06:36,393 - --- validate (epoch=107)-----------
2018-10-21 07:06:36,393 - 10000 samples (128 per mini-batch)
2018-10-21 07:06:37,657 - Epoch: [107][   50/   78]    Loss 1.582956    Top1 88.000000    Top5 99.203125    
2018-10-21 07:06:38,316 - ==> Top1: 87.960    Top5: 99.300    Loss: 1.582

2018-10-21 07:06:38,317 - ==> Best Top1: 87.960   On Epoch: 107

2018-10-21 07:06:38,318 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:06:38,334 - 

2018-10-21 07:06:38,334 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:06:40,280 - Epoch: [108][   50/  391]    Overall Loss 1.571341    Objective Loss 1.571341    Top1 89.218750    Top5 99.468750    LR 0.030000    Time 0.038854    
2018-10-21 07:06:41,912 - Epoch: [108][  100/  391]    Overall Loss 1.568007    Objective Loss 1.568007    Top1 89.632812    Top5 99.460938    LR 0.030000    Time 0.035715    
2018-10-21 07:06:43,475 - Epoch: [108][  150/  391]    Overall Loss 1.568509    Objective Loss 1.568509    Top1 89.588542    Top5 99.395833    LR 0.030000    Time 0.034211    
2018-10-21 07:06:45,051 - Epoch: [108][  200/  391]    Overall Loss 1.569228    Objective Loss 1.569228    Top1 89.480469    Top5 99.386719    LR 0.030000    Time 0.033524    
2018-10-21 07:06:46,632 - Epoch: [108][  250/  391]    Overall Loss 1.569887    Objective Loss 1.569887    Top1 89.378125    Top5 99.365625    LR 0.030000    Time 0.033134    
2018-10-21 07:06:48,211 - Epoch: [108][  300/  391]    Overall Loss 1.570856    Objective Loss 1.570856    Top1 89.294271    Top5 99.369792    LR 0.030000    Time 0.032865    
2018-10-21 07:06:49,790 - Epoch: [108][  350/  391]    Overall Loss 1.570767    Objective Loss 1.570767    Top1 89.303571    Top5 99.368304    LR 0.030000    Time 0.032676    
2018-10-21 07:06:51,211 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36723 | -0.00249 |    0.24391 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12235 | -0.00223 |    0.06992 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12101 | -0.00083 |    0.08035 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10268 | -0.00964 |    0.06775 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10203 | -0.00214 |    0.06681 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12316 | -0.01339 |    0.08298 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11126 | -0.01126 |    0.07874 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13095 | -0.00696 |    0.09660 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11058 | -0.00652 |    0.08368 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27849 | -0.00880 |    0.17538 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08794 | -0.00518 |    0.06542 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07633 | -0.01038 |    0.05927 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09071 | -0.01054 |    0.06940 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07296 | -0.00551 |    0.05554 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10116 | -0.00854 |    0.07966 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08816 | -0.00569 |    0.06929 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13300 | -0.00874 |    0.10125 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08015 | -0.01059 |    0.06210 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05297 | -0.00366 |    0.03931 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04899 | -0.00661 |    0.03705 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03241 |  0.00077 |    0.02170 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42499 | -0.00000 |    0.28922 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:06:51,212 - Total sparsity: 0.00

2018-10-21 07:06:51,212 - --- validate (epoch=108)-----------
2018-10-21 07:06:51,212 - 10000 samples (128 per mini-batch)
2018-10-21 07:06:52,423 - Epoch: [108][   50/   78]    Loss 1.585683    Top1 87.546875    Top5 99.328125    
2018-10-21 07:06:53,089 - ==> Top1: 87.720    Top5: 99.350    Loss: 1.584

2018-10-21 07:06:53,091 - ==> Best Top1: 87.960   On Epoch: 107

2018-10-21 07:06:53,091 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:06:53,104 - 

2018-10-21 07:06:53,105 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:06:54,884 - Epoch: [109][   50/  391]    Overall Loss 1.574776    Objective Loss 1.574776    Top1 88.859375    Top5 99.312500    LR 0.030000    Time 0.035525    
2018-10-21 07:06:56,474 - Epoch: [109][  100/  391]    Overall Loss 1.570498    Objective Loss 1.570498    Top1 89.406250    Top5 99.343750    LR 0.030000    Time 0.033634    
2018-10-21 07:06:58,079 - Epoch: [109][  150/  391]    Overall Loss 1.571018    Objective Loss 1.571018    Top1 89.286458    Top5 99.401042    LR 0.030000    Time 0.033103    
2018-10-21 07:06:59,625 - Epoch: [109][  200/  391]    Overall Loss 1.569660    Objective Loss 1.569660    Top1 89.425781    Top5 99.398438    LR 0.030000    Time 0.032547    
2018-10-21 07:07:01,209 - Epoch: [109][  250/  391]    Overall Loss 1.570300    Objective Loss 1.570300    Top1 89.375000    Top5 99.418750    LR 0.030000    Time 0.032363    
2018-10-21 07:07:02,729 - Epoch: [109][  300/  391]    Overall Loss 1.569856    Objective Loss 1.569856    Top1 89.395833    Top5 99.419271    LR 0.030000    Time 0.032026    
2018-10-21 07:07:04,315 - Epoch: [109][  350/  391]    Overall Loss 1.569991    Objective Loss 1.569991    Top1 89.363839    Top5 99.408482    LR 0.030000    Time 0.031975    
2018-10-21 07:07:05,679 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36349 | -0.00085 |    0.24130 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12109 | -0.00231 |    0.06923 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11976 | -0.00079 |    0.07951 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10162 | -0.00944 |    0.06703 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10096 | -0.00215 |    0.06623 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12186 | -0.01368 |    0.08213 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11016 | -0.01056 |    0.07793 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12960 | -0.00681 |    0.09561 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10944 | -0.00639 |    0.08280 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27560 | -0.00875 |    0.17374 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08708 | -0.00509 |    0.06483 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07557 | -0.01028 |    0.05870 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08985 | -0.01040 |    0.06873 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07226 | -0.00531 |    0.05503 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10012 | -0.00850 |    0.07886 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08726 | -0.00568 |    0.06859 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13163 | -0.00860 |    0.10036 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07936 | -0.01043 |    0.06149 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05245 | -0.00359 |    0.03895 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04848 | -0.00671 |    0.03671 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03208 |  0.00074 |    0.02149 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42407 | -0.00000 |    0.28859 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:07:05,679 - Total sparsity: 0.00

2018-10-21 07:07:05,679 - --- validate (epoch=109)-----------
2018-10-21 07:07:05,679 - 10000 samples (128 per mini-batch)
2018-10-21 07:07:06,936 - Epoch: [109][   50/   78]    Loss 1.585448    Top1 87.421875    Top5 99.312500    
2018-10-21 07:07:07,589 - ==> Top1: 87.730    Top5: 99.380    Loss: 1.583

2018-10-21 07:07:07,591 - ==> Best Top1: 87.960   On Epoch: 107

2018-10-21 07:07:07,591 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:07:07,604 - 

2018-10-21 07:07:07,604 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:07:09,417 - Epoch: [110][   50/  391]    Overall Loss 1.569437    Objective Loss 1.569437    Top1 89.593750    Top5 99.328125    LR 0.030000    Time 0.036202    
2018-10-21 07:07:10,940 - Epoch: [110][  100/  391]    Overall Loss 1.567657    Objective Loss 1.567657    Top1 89.718750    Top5 99.335938    LR 0.030000    Time 0.033307    
2018-10-21 07:07:12,485 - Epoch: [110][  150/  391]    Overall Loss 1.565527    Objective Loss 1.565527    Top1 89.932292    Top5 99.369792    LR 0.030000    Time 0.032485    
2018-10-21 07:07:14,025 - Epoch: [110][  200/  391]    Overall Loss 1.566001    Objective Loss 1.566001    Top1 89.882812    Top5 99.382812    LR 0.030000    Time 0.032052    
2018-10-21 07:07:15,540 - Epoch: [110][  250/  391]    Overall Loss 1.567205    Objective Loss 1.567205    Top1 89.728125    Top5 99.387500    LR 0.030000    Time 0.031693    
2018-10-21 07:07:17,112 - Epoch: [110][  300/  391]    Overall Loss 1.566797    Objective Loss 1.566797    Top1 89.773438    Top5 99.393229    LR 0.030000    Time 0.031641    
2018-10-21 07:07:18,655 - Epoch: [110][  350/  391]    Overall Loss 1.566857    Objective Loss 1.566857    Top1 89.770089    Top5 99.386161    LR 0.030000    Time 0.031523    
2018-10-21 07:07:20,064 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35980 | -0.00326 |    0.23879 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11985 | -0.00211 |    0.06849 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11853 | -0.00080 |    0.07876 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10055 | -0.00959 |    0.06635 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09992 | -0.00200 |    0.06556 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12067 | -0.01342 |    0.08117 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10903 | -0.01065 |    0.07717 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12830 | -0.00638 |    0.09453 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10832 | -0.00638 |    0.08199 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27279 | -0.00834 |    0.17141 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08625 | -0.00498 |    0.06421 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07485 | -0.01006 |    0.05811 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08899 | -0.01039 |    0.06805 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07156 | -0.00534 |    0.05447 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09909 | -0.00841 |    0.07806 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08638 | -0.00557 |    0.06789 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13027 | -0.00849 |    0.09943 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07856 | -0.01041 |    0.06091 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05193 | -0.00358 |    0.03859 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04798 | -0.00677 |    0.03636 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03175 |  0.00068 |    0.02128 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42336 | -0.00000 |    0.28828 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:07:20,064 - Total sparsity: 0.00

2018-10-21 07:07:20,065 - --- validate (epoch=110)-----------
2018-10-21 07:07:20,065 - 10000 samples (128 per mini-batch)
2018-10-21 07:07:21,309 - Epoch: [110][   50/   78]    Loss 1.583239    Top1 87.953125    Top5 99.453125    
2018-10-21 07:07:22,046 - ==> Top1: 88.090    Top5: 99.450    Loss: 1.581

2018-10-21 07:07:22,048 - ==> Best Top1: 88.090   On Epoch: 110

2018-10-21 07:07:22,048 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:07:22,065 - 

2018-10-21 07:07:22,065 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:07:23,854 - Epoch: [111][   50/  391]    Overall Loss 1.560576    Objective Loss 1.560576    Top1 90.203125    Top5 99.296875    LR 0.030000    Time 0.035709    
2018-10-21 07:07:25,389 - Epoch: [111][  100/  391]    Overall Loss 1.563777    Objective Loss 1.563777    Top1 89.929688    Top5 99.328125    LR 0.030000    Time 0.033175    
2018-10-21 07:07:26,986 - Epoch: [111][  150/  391]    Overall Loss 1.563340    Objective Loss 1.563340    Top1 90.005208    Top5 99.333333    LR 0.030000    Time 0.032746    
2018-10-21 07:07:28,559 - Epoch: [111][  200/  391]    Overall Loss 1.563525    Objective Loss 1.563525    Top1 90.019531    Top5 99.328125    LR 0.030000    Time 0.032412    
2018-10-21 07:07:30,139 - Epoch: [111][  250/  391]    Overall Loss 1.563018    Objective Loss 1.563018    Top1 90.075000    Top5 99.346875    LR 0.030000    Time 0.032241    
2018-10-21 07:07:31,690 - Epoch: [111][  300/  391]    Overall Loss 1.564070    Objective Loss 1.564070    Top1 89.984375    Top5 99.356771    LR 0.030000    Time 0.032029    
2018-10-21 07:07:33,258 - Epoch: [111][  350/  391]    Overall Loss 1.563964    Objective Loss 1.563964    Top1 89.997768    Top5 99.386161    LR 0.030000    Time 0.031926    
2018-10-21 07:07:34,693 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35626 | -0.00299 |    0.23634 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11863 | -0.00263 |    0.06784 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11733 | -0.00068 |    0.07789 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09952 | -0.00958 |    0.06561 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09890 | -0.00210 |    0.06501 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11945 | -0.01352 |    0.08037 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10793 | -0.01046 |    0.07653 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12701 | -0.00613 |    0.09374 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10721 | -0.00640 |    0.08113 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27004 | -0.00768 |    0.16980 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08544 | -0.00488 |    0.06366 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07415 | -0.00979 |    0.05755 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08817 | -0.01024 |    0.06747 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07088 | -0.00518 |    0.05393 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09809 | -0.00824 |    0.07730 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08551 | -0.00559 |    0.06722 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12893 | -0.00835 |    0.09826 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07779 | -0.01032 |    0.06035 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05143 | -0.00347 |    0.03823 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04749 | -0.00683 |    0.03604 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03143 |  0.00056 |    0.02108 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42254 | -0.00000 |    0.28783 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:07:34,693 - Total sparsity: 0.00

2018-10-21 07:07:34,693 - --- validate (epoch=111)-----------
2018-10-21 07:07:34,693 - 10000 samples (128 per mini-batch)
2018-10-21 07:07:35,903 - Epoch: [111][   50/   78]    Loss 1.582822    Top1 87.953125    Top5 99.312500    
2018-10-21 07:07:36,534 - ==> Top1: 88.080    Top5: 99.430    Loss: 1.581

2018-10-21 07:07:36,535 - ==> Best Top1: 88.090   On Epoch: 110

2018-10-21 07:07:36,536 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:07:36,548 - 

2018-10-21 07:07:36,549 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:07:38,293 - Epoch: [112][   50/  391]    Overall Loss 1.562657    Objective Loss 1.562657    Top1 90.046875    Top5 99.421875    LR 0.030000    Time 0.034812    
2018-10-21 07:07:39,916 - Epoch: [112][  100/  391]    Overall Loss 1.564482    Objective Loss 1.564482    Top1 89.929688    Top5 99.421875    LR 0.030000    Time 0.033611    
2018-10-21 07:07:41,492 - Epoch: [112][  150/  391]    Overall Loss 1.565580    Objective Loss 1.565580    Top1 89.807292    Top5 99.421875    LR 0.030000    Time 0.032897    
2018-10-21 07:07:43,084 - Epoch: [112][  200/  391]    Overall Loss 1.564940    Objective Loss 1.564940    Top1 89.894531    Top5 99.425781    LR 0.030000    Time 0.032624    
2018-10-21 07:07:44,646 - Epoch: [112][  250/  391]    Overall Loss 1.565401    Objective Loss 1.565401    Top1 89.862500    Top5 99.409375    LR 0.030000    Time 0.032335    
2018-10-21 07:07:46,224 - Epoch: [112][  300/  391]    Overall Loss 1.564925    Objective Loss 1.564925    Top1 89.906250    Top5 99.408854    LR 0.030000    Time 0.032196    
2018-10-21 07:07:47,783 - Epoch: [112][  350/  391]    Overall Loss 1.564528    Objective Loss 1.564528    Top1 89.964286    Top5 99.399554    LR 0.030000    Time 0.032044    
2018-10-21 07:07:49,161 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35280 | -0.00241 |    0.23381 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11745 | -0.00235 |    0.06722 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11615 | -0.00058 |    0.07706 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09856 | -0.00921 |    0.06496 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09791 | -0.00224 |    0.06447 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11832 | -0.01303 |    0.07962 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10680 | -0.01074 |    0.07575 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12575 | -0.00573 |    0.09281 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10612 | -0.00656 |    0.08032 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26733 | -0.00744 |    0.16815 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08463 | -0.00502 |    0.06310 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07346 | -0.00968 |    0.05701 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08737 | -0.01021 |    0.06694 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07022 | -0.00520 |    0.05346 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09710 | -0.00821 |    0.07652 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08466 | -0.00558 |    0.06656 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12763 | -0.00822 |    0.09718 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07704 | -0.01027 |    0.05978 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05094 | -0.00350 |    0.03787 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04703 | -0.00682 |    0.03572 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03112 |  0.00056 |    0.02088 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42179 | -0.00000 |    0.28754 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:07:49,162 - Total sparsity: 0.00

2018-10-21 07:07:49,162 - --- validate (epoch=112)-----------
2018-10-21 07:07:49,162 - 10000 samples (128 per mini-batch)
2018-10-21 07:07:50,383 - Epoch: [112][   50/   78]    Loss 1.585185    Top1 87.593750    Top5 99.390625    
2018-10-21 07:07:51,057 - ==> Top1: 87.830    Top5: 99.410    Loss: 1.584

2018-10-21 07:07:51,058 - ==> Best Top1: 88.090   On Epoch: 110

2018-10-21 07:07:51,058 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:07:51,071 - 

2018-10-21 07:07:51,072 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:07:52,780 - Epoch: [113][   50/  391]    Overall Loss 1.561139    Objective Loss 1.561139    Top1 90.375000    Top5 99.500000    LR 0.030000    Time 0.034101    
2018-10-21 07:07:54,336 - Epoch: [113][  100/  391]    Overall Loss 1.560301    Objective Loss 1.560301    Top1 90.453125    Top5 99.492188    LR 0.030000    Time 0.032580    
2018-10-21 07:07:55,897 - Epoch: [113][  150/  391]    Overall Loss 1.561036    Objective Loss 1.561036    Top1 90.328125    Top5 99.473958    LR 0.030000    Time 0.032116    
2018-10-21 07:07:57,479 - Epoch: [113][  200/  391]    Overall Loss 1.562027    Objective Loss 1.562027    Top1 90.207031    Top5 99.484375    LR 0.030000    Time 0.031985    
2018-10-21 07:07:59,077 - Epoch: [113][  250/  391]    Overall Loss 1.561667    Objective Loss 1.561667    Top1 90.228125    Top5 99.493750    LR 0.030000    Time 0.031970    
2018-10-21 07:08:00,652 - Epoch: [113][  300/  391]    Overall Loss 1.562026    Objective Loss 1.562026    Top1 90.182292    Top5 99.471354    LR 0.030000    Time 0.031882    
2018-10-21 07:08:02,172 - Epoch: [113][  350/  391]    Overall Loss 1.561616    Objective Loss 1.561616    Top1 90.225446    Top5 99.470982    LR 0.030000    Time 0.031664    
2018-10-21 07:08:03,618 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34932 | -0.00156 |    0.23172 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11627 | -0.00257 |    0.06664 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11499 | -0.00021 |    0.07633 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09761 | -0.00881 |    0.06437 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09693 | -0.00195 |    0.06378 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11720 | -0.01263 |    0.07885 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10571 | -0.01094 |    0.07500 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12449 | -0.00561 |    0.09176 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10508 | -0.00615 |    0.07955 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26467 | -0.00675 |    0.16612 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08386 | -0.00491 |    0.06247 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07278 | -0.00959 |    0.05651 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08661 | -0.01002 |    0.06633 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06958 | -0.00524 |    0.05296 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09613 | -0.00815 |    0.07577 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08384 | -0.00547 |    0.06592 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12636 | -0.00792 |    0.09624 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07631 | -0.01017 |    0.05922 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05047 | -0.00348 |    0.03756 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04657 | -0.00684 |    0.03538 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03081 |  0.00053 |    0.02070 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42098 | -0.00000 |    0.28701 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:08:03,618 - Total sparsity: 0.00

2018-10-21 07:08:03,618 - --- validate (epoch=113)-----------
2018-10-21 07:08:03,618 - 10000 samples (128 per mini-batch)
2018-10-21 07:08:04,862 - Epoch: [113][   50/   78]    Loss 1.584329    Top1 87.734375    Top5 99.375000    
2018-10-21 07:08:05,524 - ==> Top1: 88.000    Top5: 99.430    Loss: 1.581

2018-10-21 07:08:05,526 - ==> Best Top1: 88.090   On Epoch: 110

2018-10-21 07:08:05,526 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:08:05,538 - 

2018-10-21 07:08:05,539 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:08:07,309 - Epoch: [114][   50/  391]    Overall Loss 1.559812    Objective Loss 1.559812    Top1 90.453125    Top5 99.437500    LR 0.030000    Time 0.035334    
2018-10-21 07:08:08,880 - Epoch: [114][  100/  391]    Overall Loss 1.557287    Objective Loss 1.557287    Top1 90.640625    Top5 99.468750    LR 0.030000    Time 0.033358    
2018-10-21 07:08:10,424 - Epoch: [114][  150/  391]    Overall Loss 1.557934    Objective Loss 1.557934    Top1 90.619792    Top5 99.453125    LR 0.030000    Time 0.032513    
2018-10-21 07:08:11,985 - Epoch: [114][  200/  391]    Overall Loss 1.559439    Objective Loss 1.559439    Top1 90.472656    Top5 99.441406    LR 0.030000    Time 0.032178    
2018-10-21 07:08:13,554 - Epoch: [114][  250/  391]    Overall Loss 1.559057    Objective Loss 1.559057    Top1 90.515625    Top5 99.475000    LR 0.030000    Time 0.032009    
2018-10-21 07:08:15,127 - Epoch: [114][  300/  391]    Overall Loss 1.558413    Objective Loss 1.558413    Top1 90.562500    Top5 99.484375    LR 0.030000    Time 0.031910    
2018-10-21 07:08:16,700 - Epoch: [114][  350/  391]    Overall Loss 1.558655    Objective Loss 1.558655    Top1 90.531250    Top5 99.468750    LR 0.030000    Time 0.031838    
2018-10-21 07:08:18,123 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34587 | -0.00249 |    0.22932 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11512 | -0.00275 |    0.06594 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11386 | -0.00011 |    0.07545 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09662 | -0.00890 |    0.06372 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09595 | -0.00184 |    0.06308 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11603 | -0.01268 |    0.07812 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10473 | -0.00996 |    0.07416 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12323 | -0.00576 |    0.09085 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10402 | -0.00614 |    0.07877 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26200 | -0.00689 |    0.16404 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08308 | -0.00479 |    0.06187 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07210 | -0.00944 |    0.05600 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08586 | -0.00975 |    0.06570 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06895 | -0.00515 |    0.05250 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09517 | -0.00815 |    0.07497 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08302 | -0.00545 |    0.06527 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12508 | -0.00786 |    0.09524 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07558 | -0.01013 |    0.05869 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05000 | -0.00339 |    0.03724 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04612 | -0.00681 |    0.03505 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03050 |  0.00051 |    0.02049 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42037 | -0.00000 |    0.28677 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:08:18,123 - Total sparsity: 0.00

2018-10-21 07:08:18,123 - --- validate (epoch=114)-----------
2018-10-21 07:08:18,123 - 10000 samples (128 per mini-batch)
2018-10-21 07:08:19,318 - Epoch: [114][   50/   78]    Loss 1.581306    Top1 88.218750    Top5 99.375000    
2018-10-21 07:08:19,952 - ==> Top1: 88.220    Top5: 99.420    Loss: 1.580

2018-10-21 07:08:19,954 - ==> Best Top1: 88.220   On Epoch: 114

2018-10-21 07:08:19,954 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:08:19,970 - 

2018-10-21 07:08:19,970 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:08:21,712 - Epoch: [115][   50/  391]    Overall Loss 1.555915    Objective Loss 1.555915    Top1 90.734375    Top5 99.453125    LR 0.030000    Time 0.034760    
2018-10-21 07:08:23,287 - Epoch: [115][  100/  391]    Overall Loss 1.556176    Objective Loss 1.556176    Top1 90.718750    Top5 99.507812    LR 0.030000    Time 0.033109    
2018-10-21 07:08:24,860 - Epoch: [115][  150/  391]    Overall Loss 1.557810    Objective Loss 1.557810    Top1 90.562500    Top5 99.500000    LR 0.030000    Time 0.032543    
2018-10-21 07:08:26,486 - Epoch: [115][  200/  391]    Overall Loss 1.557851    Objective Loss 1.557851    Top1 90.617188    Top5 99.468750    LR 0.030000    Time 0.032524    
2018-10-21 07:08:28,070 - Epoch: [115][  250/  391]    Overall Loss 1.559078    Objective Loss 1.559078    Top1 90.468750    Top5 99.443750    LR 0.030000    Time 0.032343    
2018-10-21 07:08:29,612 - Epoch: [115][  300/  391]    Overall Loss 1.559441    Objective Loss 1.559441    Top1 90.429688    Top5 99.440104    LR 0.030000    Time 0.032087    
2018-10-21 07:08:31,148 - Epoch: [115][  350/  391]    Overall Loss 1.559670    Objective Loss 1.559670    Top1 90.428571    Top5 99.448661    LR 0.030000    Time 0.031883    
2018-10-21 07:08:32,547 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34245 | -0.00456 |    0.22683 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11398 | -0.00309 |    0.06515 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11276 | -0.00041 |    0.07477 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09568 | -0.00879 |    0.06318 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09500 | -0.00163 |    0.06258 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11488 | -0.01272 |    0.07731 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10370 | -0.00967 |    0.07341 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12200 | -0.00578 |    0.08994 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10300 | -0.00593 |    0.07795 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25942 | -0.00645 |    0.16270 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08233 | -0.00481 |    0.06130 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07145 | -0.00931 |    0.05549 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08510 | -0.00981 |    0.06518 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06835 | -0.00491 |    0.05201 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09423 | -0.00807 |    0.07420 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08222 | -0.00544 |    0.06467 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12382 | -0.00786 |    0.09434 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07490 | -0.00993 |    0.05817 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04955 | -0.00341 |    0.03693 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04567 | -0.00689 |    0.03472 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03020 |  0.00045 |    0.02031 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41981 | -0.00000 |    0.28661 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:08:32,547 - Total sparsity: 0.00

2018-10-21 07:08:32,547 - --- validate (epoch=115)-----------
2018-10-21 07:08:32,547 - 10000 samples (128 per mini-batch)
2018-10-21 07:08:33,743 - Epoch: [115][   50/   78]    Loss 1.581482    Top1 87.921875    Top5 99.343750    
2018-10-21 07:08:34,387 - ==> Top1: 88.120    Top5: 99.410    Loss: 1.580

2018-10-21 07:08:34,388 - ==> Best Top1: 88.220   On Epoch: 114

2018-10-21 07:08:34,389 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:08:34,401 - 

2018-10-21 07:08:34,402 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:08:36,136 - Epoch: [116][   50/  391]    Overall Loss 1.556828    Objective Loss 1.556828    Top1 90.843750    Top5 99.484375    LR 0.030000    Time 0.034613    
2018-10-21 07:08:37,791 - Epoch: [116][  100/  391]    Overall Loss 1.556842    Objective Loss 1.556842    Top1 90.804688    Top5 99.437500    LR 0.030000    Time 0.033826    
2018-10-21 07:08:39,439 - Epoch: [116][  150/  391]    Overall Loss 1.557358    Objective Loss 1.557358    Top1 90.718750    Top5 99.421875    LR 0.030000    Time 0.033523    
2018-10-21 07:08:41,265 - Epoch: [116][  200/  391]    Overall Loss 1.558765    Objective Loss 1.558765    Top1 90.570312    Top5 99.410156    LR 0.030000    Time 0.034260    
2018-10-21 07:08:42,843 - Epoch: [116][  250/  391]    Overall Loss 1.557741    Objective Loss 1.557741    Top1 90.668750    Top5 99.443750    LR 0.030000    Time 0.033711    
2018-10-21 07:08:44,490 - Epoch: [116][  300/  391]    Overall Loss 1.558246    Objective Loss 1.558246    Top1 90.625000    Top5 99.458333    LR 0.030000    Time 0.033573    
2018-10-21 07:08:46,099 - Epoch: [116][  350/  391]    Overall Loss 1.558189    Objective Loss 1.558189    Top1 90.631696    Top5 99.446429    LR 0.030000    Time 0.033368    
2018-10-21 07:08:47,565 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33929 | -0.00490 |    0.22503 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11292 | -0.00311 |    0.06462 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11170 | -0.00072 |    0.07401 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09476 | -0.00889 |    0.06259 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09409 | -0.00187 |    0.06199 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11381 | -0.01257 |    0.07650 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10264 | -0.01018 |    0.07276 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12081 | -0.00590 |    0.08913 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10199 | -0.00605 |    0.07722 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25689 | -0.00640 |    0.16164 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08161 | -0.00481 |    0.06077 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07083 | -0.00916 |    0.05500 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08441 | -0.00959 |    0.06457 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06778 | -0.00481 |    0.05161 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09334 | -0.00790 |    0.07350 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08146 | -0.00535 |    0.06409 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12262 | -0.00772 |    0.09343 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07424 | -0.00983 |    0.05769 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04912 | -0.00340 |    0.03664 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04526 | -0.00686 |    0.03443 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02991 |  0.00044 |    0.02013 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41930 | -0.00000 |    0.28636 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:08:47,566 - Total sparsity: 0.00

2018-10-21 07:08:47,566 - --- validate (epoch=116)-----------
2018-10-21 07:08:47,566 - 10000 samples (128 per mini-batch)
2018-10-21 07:08:48,759 - Epoch: [116][   50/   78]    Loss 1.582516    Top1 88.000000    Top5 99.531250    
2018-10-21 07:08:49,389 - ==> Top1: 88.160    Top5: 99.530    Loss: 1.580

2018-10-21 07:08:49,390 - ==> Best Top1: 88.220   On Epoch: 114

2018-10-21 07:08:49,391 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:08:49,404 - 

2018-10-21 07:08:49,404 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:08:51,168 - Epoch: [117][   50/  391]    Overall Loss 1.556848    Objective Loss 1.556848    Top1 90.812500    Top5 99.437500    LR 0.030000    Time 0.035211    
2018-10-21 07:08:52,822 - Epoch: [117][  100/  391]    Overall Loss 1.556015    Objective Loss 1.556015    Top1 90.882812    Top5 99.453125    LR 0.030000    Time 0.034115    
2018-10-21 07:08:54,379 - Epoch: [117][  150/  391]    Overall Loss 1.556748    Objective Loss 1.556748    Top1 90.750000    Top5 99.458333    LR 0.030000    Time 0.033110    
2018-10-21 07:08:55,945 - Epoch: [117][  200/  391]    Overall Loss 1.556235    Objective Loss 1.556235    Top1 90.789062    Top5 99.472656    LR 0.030000    Time 0.032650    
2018-10-21 07:08:57,496 - Epoch: [117][  250/  391]    Overall Loss 1.556348    Objective Loss 1.556348    Top1 90.778125    Top5 99.471875    LR 0.030000    Time 0.032313    
2018-10-21 07:08:59,040 - Epoch: [117][  300/  391]    Overall Loss 1.555623    Objective Loss 1.555623    Top1 90.843750    Top5 99.450521    LR 0.030000    Time 0.032066    
2018-10-21 07:09:00,583 - Epoch: [117][  350/  391]    Overall Loss 1.556181    Objective Loss 1.556181    Top1 90.783482    Top5 99.466518    LR 0.030000    Time 0.031886    
2018-10-21 07:09:01,989 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33609 | -0.00369 |    0.22289 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11186 | -0.00332 |    0.06399 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11066 | -0.00063 |    0.07342 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09387 | -0.00869 |    0.06194 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09318 | -0.00187 |    0.06137 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11277 | -0.01204 |    0.07563 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10163 | -0.01029 |    0.07196 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11964 | -0.00559 |    0.08829 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10103 | -0.00555 |    0.07651 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25436 | -0.00588 |    0.15953 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08088 | -0.00470 |    0.06027 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07022 | -0.00893 |    0.05449 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08369 | -0.00967 |    0.06410 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06719 | -0.00482 |    0.05116 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09244 | -0.00775 |    0.07283 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08069 | -0.00532 |    0.06349 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12140 | -0.00770 |    0.09254 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07355 | -0.00983 |    0.05718 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04869 | -0.00336 |    0.03634 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04484 | -0.00686 |    0.03412 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02963 |  0.00044 |    0.01995 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41878 | -0.00000 |    0.28604 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:09:01,989 - Total sparsity: 0.00

2018-10-21 07:09:01,989 - --- validate (epoch=117)-----------
2018-10-21 07:09:01,989 - 10000 samples (128 per mini-batch)
2018-10-21 07:09:03,257 - Epoch: [117][   50/   78]    Loss 1.583597    Top1 87.765625    Top5 99.437500    
2018-10-21 07:09:03,953 - ==> Top1: 87.780    Top5: 99.420    Loss: 1.583

2018-10-21 07:09:03,955 - ==> Best Top1: 88.220   On Epoch: 114

2018-10-21 07:09:03,955 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:09:03,968 - 

2018-10-21 07:09:03,968 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:09:05,772 - Epoch: [118][   50/  391]    Overall Loss 1.552392    Objective Loss 1.552392    Top1 91.390625    Top5 99.546875    LR 0.030000    Time 0.036012    
2018-10-21 07:09:07,503 - Epoch: [118][  100/  391]    Overall Loss 1.551835    Objective Loss 1.551835    Top1 91.265625    Top5 99.468750    LR 0.030000    Time 0.035289    
2018-10-21 07:09:09,087 - Epoch: [118][  150/  391]    Overall Loss 1.552529    Objective Loss 1.552529    Top1 91.177083    Top5 99.479167    LR 0.030000    Time 0.034071    
2018-10-21 07:09:10,673 - Epoch: [118][  200/  391]    Overall Loss 1.553187    Objective Loss 1.553187    Top1 91.105469    Top5 99.476562    LR 0.030000    Time 0.033470    
2018-10-21 07:09:12,242 - Epoch: [118][  250/  391]    Overall Loss 1.553626    Objective Loss 1.553626    Top1 91.075000    Top5 99.481250    LR 0.030000    Time 0.033041    
2018-10-21 07:09:13,802 - Epoch: [118][  300/  391]    Overall Loss 1.554771    Objective Loss 1.554771    Top1 90.958333    Top5 99.473958    LR 0.030000    Time 0.032727    
2018-10-21 07:09:15,380 - Epoch: [118][  350/  391]    Overall Loss 1.554741    Objective Loss 1.554741    Top1 90.959821    Top5 99.488839    LR 0.030000    Time 0.032551    
2018-10-21 07:09:16,783 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33292 | -0.00385 |    0.22070 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11084 | -0.00325 |    0.06340 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10965 | -0.00087 |    0.07274 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09300 | -0.00871 |    0.06142 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09230 | -0.00172 |    0.06078 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11172 | -0.01193 |    0.07492 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10062 | -0.01051 |    0.07124 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11850 | -0.00554 |    0.08738 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10006 | -0.00552 |    0.07576 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25190 | -0.00623 |    0.15811 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08020 | -0.00466 |    0.05972 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06965 | -0.00867 |    0.05403 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08303 | -0.00938 |    0.06352 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06663 | -0.00474 |    0.05080 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09156 | -0.00768 |    0.07214 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07996 | -0.00525 |    0.06293 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12021 | -0.00770 |    0.09161 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07294 | -0.00962 |    0.05668 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04829 | -0.00324 |    0.03605 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04444 | -0.00683 |    0.03381 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02935 |  0.00039 |    0.01976 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41844 | -0.00000 |    0.28603 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:09:16,784 - Total sparsity: 0.00

2018-10-21 07:09:16,784 - --- validate (epoch=118)-----------
2018-10-21 07:09:16,784 - 10000 samples (128 per mini-batch)
2018-10-21 07:09:18,053 - Epoch: [118][   50/   78]    Loss 1.586284    Top1 87.546875    Top5 99.531250    
2018-10-21 07:09:18,726 - ==> Top1: 87.660    Top5: 99.520    Loss: 1.585

2018-10-21 07:09:18,727 - ==> Best Top1: 88.220   On Epoch: 114

2018-10-21 07:09:18,727 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:09:18,740 - 

2018-10-21 07:09:18,741 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:09:20,466 - Epoch: [119][   50/  391]    Overall Loss 1.551727    Objective Loss 1.551727    Top1 91.234375    Top5 99.500000    LR 0.030000    Time 0.034446    
2018-10-21 07:09:22,094 - Epoch: [119][  100/  391]    Overall Loss 1.555021    Objective Loss 1.555021    Top1 90.890625    Top5 99.523438    LR 0.030000    Time 0.033472    
2018-10-21 07:09:23,686 - Epoch: [119][  150/  391]    Overall Loss 1.555666    Objective Loss 1.555666    Top1 90.833333    Top5 99.479167    LR 0.030000    Time 0.032917    
2018-10-21 07:09:25,290 - Epoch: [119][  200/  391]    Overall Loss 1.555483    Objective Loss 1.555483    Top1 90.875000    Top5 99.472656    LR 0.030000    Time 0.032692    
2018-10-21 07:09:26,870 - Epoch: [119][  250/  391]    Overall Loss 1.554788    Objective Loss 1.554788    Top1 90.962500    Top5 99.478125    LR 0.030000    Time 0.032465    
2018-10-21 07:09:28,459 - Epoch: [119][  300/  391]    Overall Loss 1.554943    Objective Loss 1.554943    Top1 90.927083    Top5 99.481771    LR 0.030000    Time 0.032343    
2018-10-21 07:09:30,061 - Epoch: [119][  350/  391]    Overall Loss 1.554991    Objective Loss 1.554991    Top1 90.908482    Top5 99.453125    LR 0.030000    Time 0.032292    
2018-10-21 07:09:31,489 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32988 | -0.00537 |    0.21903 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10981 | -0.00376 |    0.06288 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10864 | -0.00040 |    0.07198 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09215 | -0.00867 |    0.06090 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09144 | -0.00163 |    0.06024 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11068 | -0.01231 |    0.07433 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09967 | -0.01048 |    0.07059 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11737 | -0.00562 |    0.08650 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09912 | -0.00544 |    0.07503 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24947 | -0.00627 |    0.15633 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07954 | -0.00459 |    0.05933 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06906 | -0.00868 |    0.05359 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08237 | -0.00935 |    0.06307 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06609 | -0.00478 |    0.05038 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09069 | -0.00771 |    0.07147 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07923 | -0.00523 |    0.06237 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11905 | -0.00766 |    0.09065 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07231 | -0.00957 |    0.05620 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04789 | -0.00323 |    0.03577 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04405 | -0.00685 |    0.03354 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02907 |  0.00039 |    0.01958 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41780 | -0.00000 |    0.28570 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:09:31,489 - Total sparsity: 0.00

2018-10-21 07:09:31,489 - --- validate (epoch=119)-----------
2018-10-21 07:09:31,489 - 10000 samples (128 per mini-batch)
2018-10-21 07:09:32,732 - Epoch: [119][   50/   78]    Loss 1.581935    Top1 88.000000    Top5 99.468750    
2018-10-21 07:09:33,372 - ==> Top1: 88.160    Top5: 99.520    Loss: 1.581

2018-10-21 07:09:33,374 - ==> Best Top1: 88.220   On Epoch: 114

2018-10-21 07:09:33,374 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:09:33,387 - 

2018-10-21 07:09:33,387 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:09:35,170 - Epoch: [120][   50/  391]    Overall Loss 1.552871    Objective Loss 1.552871    Top1 91.031250    Top5 99.625000    LR 0.030000    Time 0.035590    
2018-10-21 07:09:36,850 - Epoch: [120][  100/  391]    Overall Loss 1.552820    Objective Loss 1.552820    Top1 91.140625    Top5 99.515625    LR 0.030000    Time 0.034565    
2018-10-21 07:09:38,445 - Epoch: [120][  150/  391]    Overall Loss 1.552378    Objective Loss 1.552378    Top1 91.177083    Top5 99.515625    LR 0.030000    Time 0.033660    
2018-10-21 07:09:40,027 - Epoch: [120][  200/  391]    Overall Loss 1.551863    Objective Loss 1.551863    Top1 91.234375    Top5 99.531250    LR 0.030000    Time 0.033141    
2018-10-21 07:09:41,607 - Epoch: [120][  250/  391]    Overall Loss 1.551694    Objective Loss 1.551694    Top1 91.278125    Top5 99.515625    LR 0.030000    Time 0.032824    
2018-10-21 07:09:43,177 - Epoch: [120][  300/  391]    Overall Loss 1.553097    Objective Loss 1.553097    Top1 91.106771    Top5 99.507812    LR 0.030000    Time 0.032579    
2018-10-21 07:09:44,722 - Epoch: [120][  350/  391]    Overall Loss 1.553338    Objective Loss 1.553338    Top1 91.100446    Top5 99.502232    LR 0.030000    Time 0.032331    
2018-10-21 07:09:46,134 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32704 | -0.00448 |    0.21801 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10883 | -0.00386 |    0.06215 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10765 | -0.00074 |    0.07135 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09134 | -0.00880 |    0.06034 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09061 | -0.00173 |    0.05970 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10974 | -0.01171 |    0.07375 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09879 | -0.00996 |    0.06979 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11631 | -0.00509 |    0.08582 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09821 | -0.00521 |    0.07436 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24713 | -0.00610 |    0.15453 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07890 | -0.00450 |    0.05884 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06850 | -0.00862 |    0.05323 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08175 | -0.00944 |    0.06262 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06557 | -0.00483 |    0.05001 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08986 | -0.00757 |    0.07077 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07853 | -0.00518 |    0.06182 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11791 | -0.00763 |    0.08979 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07171 | -0.00946 |    0.05574 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04751 | -0.00314 |    0.03550 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04367 | -0.00688 |    0.03327 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02881 |  0.00035 |    0.01942 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41717 | -0.00000 |    0.28536 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:09:46,134 - Total sparsity: 0.00

2018-10-21 07:09:46,134 - --- validate (epoch=120)-----------
2018-10-21 07:09:46,134 - 10000 samples (128 per mini-batch)
2018-10-21 07:09:47,386 - Epoch: [120][   50/   78]    Loss 1.579040    Top1 88.468750    Top5 99.500000    
2018-10-21 07:09:48,054 - ==> Top1: 88.520    Top5: 99.560    Loss: 1.577

2018-10-21 07:09:48,055 - ==> Best Top1: 88.520   On Epoch: 120

2018-10-21 07:09:48,055 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:09:48,072 - 

2018-10-21 07:09:48,072 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:09:49,816 - Epoch: [121][   50/  391]    Overall Loss 1.552278    Objective Loss 1.552278    Top1 91.218750    Top5 99.375000    LR 0.030000    Time 0.034803    
2018-10-21 07:09:51,424 - Epoch: [121][  100/  391]    Overall Loss 1.554120    Objective Loss 1.554120    Top1 91.164062    Top5 99.421875    LR 0.030000    Time 0.033459    
2018-10-21 07:09:53,040 - Epoch: [121][  150/  391]    Overall Loss 1.554930    Objective Loss 1.554930    Top1 91.031250    Top5 99.411458    LR 0.030000    Time 0.033062    
2018-10-21 07:09:54,729 - Epoch: [121][  200/  391]    Overall Loss 1.552966    Objective Loss 1.552966    Top1 91.160156    Top5 99.453125    LR 0.030000    Time 0.033229    
2018-10-21 07:09:56,289 - Epoch: [121][  250/  391]    Overall Loss 1.552125    Objective Loss 1.552125    Top1 91.215625    Top5 99.450000    LR 0.030000    Time 0.032816    
2018-10-21 07:09:57,839 - Epoch: [121][  300/  391]    Overall Loss 1.552762    Objective Loss 1.552762    Top1 91.132812    Top5 99.442708    LR 0.030000    Time 0.032505    
2018-10-21 07:09:59,377 - Epoch: [121][  350/  391]    Overall Loss 1.552834    Objective Loss 1.552834    Top1 91.138393    Top5 99.457589    LR 0.030000    Time 0.032248    
2018-10-21 07:10:00,792 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32411 | -0.00301 |    0.21510 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10786 | -0.00415 |    0.06165 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10667 | -0.00078 |    0.07057 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09057 | -0.00851 |    0.05971 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08978 | -0.00188 |    0.05923 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10875 | -0.01196 |    0.07302 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09784 | -0.01026 |    0.06927 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11526 | -0.00466 |    0.08507 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09730 | -0.00539 |    0.07368 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24488 | -0.00550 |    0.15318 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07829 | -0.00455 |    0.05841 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06798 | -0.00850 |    0.05282 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08119 | -0.00906 |    0.06224 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06509 | -0.00460 |    0.04963 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08905 | -0.00747 |    0.07012 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07786 | -0.00503 |    0.06130 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11679 | -0.00767 |    0.08897 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07115 | -0.00925 |    0.05530 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04714 | -0.00315 |    0.03528 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04332 | -0.00676 |    0.03299 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02855 |  0.00033 |    0.01927 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41677 | -0.00000 |    0.28526 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:10:00,792 - Total sparsity: 0.00

2018-10-21 07:10:00,793 - --- validate (epoch=121)-----------
2018-10-21 07:10:00,793 - 10000 samples (128 per mini-batch)
2018-10-21 07:10:02,038 - Epoch: [121][   50/   78]    Loss 1.577807    Top1 88.562500    Top5 99.390625    
2018-10-21 07:10:02,697 - ==> Top1: 88.700    Top5: 99.460    Loss: 1.575

2018-10-21 07:10:02,699 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:10:02,699 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:10:02,715 - 

2018-10-21 07:10:02,715 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:10:04,490 - Epoch: [122][   50/  391]    Overall Loss 1.551145    Objective Loss 1.551145    Top1 91.296875    Top5 99.562500    LR 0.030000    Time 0.035445    
2018-10-21 07:10:06,071 - Epoch: [122][  100/  391]    Overall Loss 1.549158    Objective Loss 1.549158    Top1 91.445312    Top5 99.531250    LR 0.030000    Time 0.033506    
2018-10-21 07:10:07,675 - Epoch: [122][  150/  391]    Overall Loss 1.550166    Objective Loss 1.550166    Top1 91.468750    Top5 99.583333    LR 0.030000    Time 0.033009    
2018-10-21 07:10:09,248 - Epoch: [122][  200/  391]    Overall Loss 1.550872    Objective Loss 1.550872    Top1 91.386719    Top5 99.539062    LR 0.030000    Time 0.032610    
2018-10-21 07:10:10,755 - Epoch: [122][  250/  391]    Overall Loss 1.551692    Objective Loss 1.551692    Top1 91.296875    Top5 99.509375    LR 0.030000    Time 0.032105    
2018-10-21 07:10:12,300 - Epoch: [122][  300/  391]    Overall Loss 1.552218    Objective Loss 1.552218    Top1 91.231771    Top5 99.476562    LR 0.030000    Time 0.031898    
2018-10-21 07:10:13,981 - Epoch: [122][  350/  391]    Overall Loss 1.551843    Objective Loss 1.551843    Top1 91.265625    Top5 99.468750    LR 0.030000    Time 0.032137    
2018-10-21 07:10:15,430 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32118 | -0.00509 |    0.21301 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10688 | -0.00415 |    0.06107 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10570 | -0.00026 |    0.07002 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08975 | -0.00853 |    0.05912 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08897 | -0.00225 |    0.05871 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10783 | -0.01153 |    0.07246 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09696 | -0.00986 |    0.06854 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11417 | -0.00524 |    0.08436 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09641 | -0.00531 |    0.07302 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24261 | -0.00537 |    0.15183 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07768 | -0.00447 |    0.05791 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06743 | -0.00860 |    0.05247 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08062 | -0.00884 |    0.06172 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06459 | -0.00477 |    0.04924 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08826 | -0.00722 |    0.06946 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07718 | -0.00509 |    0.06078 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11569 | -0.00762 |    0.08803 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07057 | -0.00919 |    0.05490 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04678 | -0.00317 |    0.03503 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04295 | -0.00680 |    0.03275 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02829 |  0.00031 |    0.01908 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41622 | -0.00000 |    0.28494 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:10:15,431 - Total sparsity: 0.00

2018-10-21 07:10:15,431 - --- validate (epoch=122)-----------
2018-10-21 07:10:15,431 - 10000 samples (128 per mini-batch)
2018-10-21 07:10:16,641 - Epoch: [122][   50/   78]    Loss 1.584842    Top1 87.687500    Top5 99.265625    
2018-10-21 07:10:17,281 - ==> Top1: 87.710    Top5: 99.320    Loss: 1.584

2018-10-21 07:10:17,283 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:10:17,283 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:10:17,302 - 

2018-10-21 07:10:17,302 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:10:19,034 - Epoch: [123][   50/  391]    Overall Loss 1.544318    Objective Loss 1.544318    Top1 92.031250    Top5 99.343750    LR 0.030000    Time 0.034575    
2018-10-21 07:10:20,626 - Epoch: [123][  100/  391]    Overall Loss 1.547936    Objective Loss 1.547936    Top1 91.648438    Top5 99.398438    LR 0.030000    Time 0.033184    
2018-10-21 07:10:22,176 - Epoch: [123][  150/  391]    Overall Loss 1.548405    Objective Loss 1.548405    Top1 91.593750    Top5 99.411458    LR 0.030000    Time 0.032442    
2018-10-21 07:10:23,723 - Epoch: [123][  200/  391]    Overall Loss 1.549750    Objective Loss 1.549750    Top1 91.472656    Top5 99.429688    LR 0.030000    Time 0.032054    
2018-10-21 07:10:25,294 - Epoch: [123][  250/  391]    Overall Loss 1.551309    Objective Loss 1.551309    Top1 91.328125    Top5 99.440625    LR 0.030000    Time 0.031922    
2018-10-21 07:10:26,838 - Epoch: [123][  300/  391]    Overall Loss 1.551985    Objective Loss 1.551985    Top1 91.234375    Top5 99.447917    LR 0.030000    Time 0.031740    
2018-10-21 07:10:28,399 - Epoch: [123][  350/  391]    Overall Loss 1.552356    Objective Loss 1.552356    Top1 91.194196    Top5 99.437500    LR 0.030000    Time 0.031657    
2018-10-21 07:10:29,889 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31828 | -0.00263 |    0.21108 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10593 | -0.00405 |    0.06037 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10476 | -0.00025 |    0.06941 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08901 | -0.00830 |    0.05868 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08821 | -0.00177 |    0.05822 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10689 | -0.01170 |    0.07194 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09612 | -0.00947 |    0.06794 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11315 | -0.00476 |    0.08360 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09555 | -0.00503 |    0.07232 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24040 | -0.00487 |    0.15021 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07710 | -0.00427 |    0.05753 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06692 | -0.00848 |    0.05208 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08007 | -0.00864 |    0.06126 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06412 | -0.00470 |    0.04893 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08746 | -0.00716 |    0.06884 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07654 | -0.00488 |    0.06027 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11464 | -0.00743 |    0.08726 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07002 | -0.00915 |    0.05448 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04642 | -0.00325 |    0.03481 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04261 | -0.00678 |    0.03252 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02804 |  0.00026 |    0.01890 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41573 | -0.00000 |    0.28479 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:10:29,889 - Total sparsity: 0.00

2018-10-21 07:10:29,889 - --- validate (epoch=123)-----------
2018-10-21 07:10:29,890 - 10000 samples (128 per mini-batch)
2018-10-21 07:10:31,158 - Epoch: [123][   50/   78]    Loss 1.577659    Top1 88.312500    Top5 99.562500    
2018-10-21 07:10:31,805 - ==> Top1: 88.520    Top5: 99.550    Loss: 1.576

2018-10-21 07:10:31,807 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:10:31,807 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:10:31,820 - 

2018-10-21 07:10:31,820 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:10:33,639 - Epoch: [124][   50/  391]    Overall Loss 1.551890    Objective Loss 1.551890    Top1 91.187500    Top5 99.375000    LR 0.030000    Time 0.036315    
2018-10-21 07:10:35,329 - Epoch: [124][  100/  391]    Overall Loss 1.549540    Objective Loss 1.549540    Top1 91.468750    Top5 99.476562    LR 0.030000    Time 0.035032    
2018-10-21 07:10:36,916 - Epoch: [124][  150/  391]    Overall Loss 1.550562    Objective Loss 1.550562    Top1 91.364583    Top5 99.463542    LR 0.030000    Time 0.033921    
2018-10-21 07:10:38,516 - Epoch: [124][  200/  391]    Overall Loss 1.549071    Objective Loss 1.549071    Top1 91.578125    Top5 99.496094    LR 0.030000    Time 0.033429    
2018-10-21 07:10:40,084 - Epoch: [124][  250/  391]    Overall Loss 1.548774    Objective Loss 1.548774    Top1 91.615625    Top5 99.503125    LR 0.030000    Time 0.033003    
2018-10-21 07:10:41,630 - Epoch: [124][  300/  391]    Overall Loss 1.548350    Objective Loss 1.548350    Top1 91.656250    Top5 99.515625    LR 0.030000    Time 0.032648    
2018-10-21 07:10:43,198 - Epoch: [124][  350/  391]    Overall Loss 1.549174    Objective Loss 1.549174    Top1 91.566964    Top5 99.517857    LR 0.030000    Time 0.032457    
2018-10-21 07:10:44,591 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31545 | -0.00102 |    0.21007 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10502 | -0.00410 |    0.05993 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10384 | -0.00046 |    0.06876 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08829 | -0.00803 |    0.05816 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08743 | -0.00174 |    0.05773 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10592 | -0.01193 |    0.07120 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09518 | -0.01013 |    0.06732 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11213 | -0.00491 |    0.08289 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09469 | -0.00512 |    0.07161 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23821 | -0.00375 |    0.14874 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07652 | -0.00419 |    0.05719 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06645 | -0.00827 |    0.05171 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07947 | -0.00903 |    0.06092 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06366 | -0.00469 |    0.04861 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08669 | -0.00710 |    0.06826 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07589 | -0.00492 |    0.05974 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11359 | -0.00745 |    0.08669 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06947 | -0.00914 |    0.05410 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04609 | -0.00320 |    0.03459 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04227 | -0.00682 |    0.03228 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02779 |  0.00028 |    0.01873 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41563 | -0.00000 |    0.28491 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:10:44,592 - Total sparsity: 0.00

2018-10-21 07:10:44,592 - --- validate (epoch=124)-----------
2018-10-21 07:10:44,592 - 10000 samples (128 per mini-batch)
2018-10-21 07:10:45,867 - Epoch: [124][   50/   78]    Loss 1.579144    Top1 88.343750    Top5 99.484375    
2018-10-21 07:10:46,535 - ==> Top1: 88.360    Top5: 99.510    Loss: 1.578

2018-10-21 07:10:46,537 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:10:46,537 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:10:46,550 - 

2018-10-21 07:10:46,550 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:10:48,323 - Epoch: [125][   50/  391]    Overall Loss 1.556348    Objective Loss 1.556348    Top1 90.718750    Top5 99.390625    LR 0.030000    Time 0.035386    
2018-10-21 07:10:49,971 - Epoch: [125][  100/  391]    Overall Loss 1.554063    Objective Loss 1.554063    Top1 90.992188    Top5 99.453125    LR 0.030000    Time 0.034142    
2018-10-21 07:10:51,556 - Epoch: [125][  150/  391]    Overall Loss 1.552897    Objective Loss 1.552897    Top1 91.109375    Top5 99.479167    LR 0.030000    Time 0.033313    
2018-10-21 07:10:53,115 - Epoch: [125][  200/  391]    Overall Loss 1.551895    Objective Loss 1.551895    Top1 91.187500    Top5 99.453125    LR 0.030000    Time 0.032770    
2018-10-21 07:10:54,690 - Epoch: [125][  250/  391]    Overall Loss 1.552006    Objective Loss 1.552006    Top1 91.184375    Top5 99.431250    LR 0.030000    Time 0.032507    
2018-10-21 07:10:56,260 - Epoch: [125][  300/  391]    Overall Loss 1.552375    Objective Loss 1.552375    Top1 91.169271    Top5 99.408854    LR 0.030000    Time 0.032311    
2018-10-21 07:10:57,825 - Epoch: [125][  350/  391]    Overall Loss 1.552185    Objective Loss 1.552185    Top1 91.180804    Top5 99.415179    LR 0.030000    Time 0.032162    
2018-10-21 07:10:59,228 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31283 | -0.00220 |    0.20833 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10414 | -0.00436 |    0.05935 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10296 |  0.00001 |    0.06811 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08752 | -0.00829 |    0.05777 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08669 | -0.00149 |    0.05725 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10504 | -0.01206 |    0.07073 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09441 | -0.00951 |    0.06672 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11118 | -0.00441 |    0.08215 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09386 | -0.00540 |    0.07101 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23614 | -0.00432 |    0.14774 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07598 | -0.00435 |    0.05677 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06596 | -0.00842 |    0.05138 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07898 | -0.00886 |    0.06049 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06324 | -0.00463 |    0.04833 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08596 | -0.00687 |    0.06766 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07528 | -0.00495 |    0.05926 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11257 | -0.00746 |    0.08592 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06897 | -0.00905 |    0.05373 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04577 | -0.00321 |    0.03438 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04196 | -0.00676 |    0.03204 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02756 |  0.00024 |    0.01859 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41523 | -0.00000 |    0.28474 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:10:59,228 - Total sparsity: 0.00

2018-10-21 07:10:59,229 - --- validate (epoch=125)-----------
2018-10-21 07:10:59,229 - 10000 samples (128 per mini-batch)
2018-10-21 07:11:00,495 - Epoch: [125][   50/   78]    Loss 1.577993    Top1 88.328125    Top5 99.562500    
2018-10-21 07:11:01,144 - ==> Top1: 88.470    Top5: 99.540    Loss: 1.576

2018-10-21 07:11:01,145 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:11:01,145 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:11:01,158 - 

2018-10-21 07:11:01,158 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:11:02,888 - Epoch: [126][   50/  391]    Overall Loss 1.546818    Objective Loss 1.546818    Top1 91.609375    Top5 99.375000    LR 0.030000    Time 0.034530    
2018-10-21 07:11:04,499 - Epoch: [126][  100/  391]    Overall Loss 1.545764    Objective Loss 1.545764    Top1 91.890625    Top5 99.445312    LR 0.030000    Time 0.033348    
2018-10-21 07:11:06,088 - Epoch: [126][  150/  391]    Overall Loss 1.547306    Objective Loss 1.547306    Top1 91.760417    Top5 99.458333    LR 0.030000    Time 0.032808    
2018-10-21 07:11:07,634 - Epoch: [126][  200/  391]    Overall Loss 1.548544    Objective Loss 1.548544    Top1 91.628906    Top5 99.484375    LR 0.030000    Time 0.032323    
2018-10-21 07:11:09,250 - Epoch: [126][  250/  391]    Overall Loss 1.548084    Objective Loss 1.548084    Top1 91.706250    Top5 99.500000    LR 0.030000    Time 0.032314    
2018-10-21 07:11:10,826 - Epoch: [126][  300/  391]    Overall Loss 1.547990    Objective Loss 1.547990    Top1 91.708333    Top5 99.473958    LR 0.030000    Time 0.032173    
2018-10-21 07:11:12,378 - Epoch: [126][  350/  391]    Overall Loss 1.548913    Objective Loss 1.548913    Top1 91.607143    Top5 99.475446    LR 0.030000    Time 0.032004    
2018-10-21 07:11:13,771 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31017 | -0.00097 |    0.20614 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10329 | -0.00434 |    0.05910 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10209 |  0.00045 |    0.06764 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08681 | -0.00807 |    0.05738 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08597 | -0.00156 |    0.05677 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10421 | -0.01169 |    0.07019 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09354 | -0.00985 |    0.06622 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11022 | -0.00444 |    0.08143 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09307 | -0.00515 |    0.07037 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23405 | -0.00447 |    0.14656 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07547 | -0.00402 |    0.05637 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06548 | -0.00852 |    0.05097 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07854 | -0.00847 |    0.06013 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06283 | -0.00462 |    0.04807 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08524 | -0.00681 |    0.06709 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07470 | -0.00485 |    0.05880 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11157 | -0.00736 |    0.08517 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06846 | -0.00907 |    0.05338 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04547 | -0.00316 |    0.03416 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04167 | -0.00669 |    0.03178 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02733 |  0.00027 |    0.01845 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41500 | -0.00000 |    0.28476 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:11:13,772 - Total sparsity: 0.00

2018-10-21 07:11:13,772 - --- validate (epoch=126)-----------
2018-10-21 07:11:13,772 - 10000 samples (128 per mini-batch)
2018-10-21 07:11:14,945 - Epoch: [126][   50/   78]    Loss 1.581043    Top1 88.046875    Top5 99.546875    
2018-10-21 07:11:15,588 - ==> Top1: 88.130    Top5: 99.480    Loss: 1.581

2018-10-21 07:11:15,589 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:11:15,589 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:11:15,603 - 

2018-10-21 07:11:15,603 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:11:17,336 - Epoch: [127][   50/  391]    Overall Loss 1.548416    Objective Loss 1.548416    Top1 91.625000    Top5 99.296875    LR 0.030000    Time 0.034588    
2018-10-21 07:11:18,929 - Epoch: [127][  100/  391]    Overall Loss 1.547173    Objective Loss 1.547173    Top1 91.835938    Top5 99.375000    LR 0.030000    Time 0.033206    
2018-10-21 07:11:20,513 - Epoch: [127][  150/  391]    Overall Loss 1.545273    Objective Loss 1.545273    Top1 92.015625    Top5 99.473958    LR 0.030000    Time 0.032680    
2018-10-21 07:11:22,057 - Epoch: [127][  200/  391]    Overall Loss 1.546769    Objective Loss 1.546769    Top1 91.839844    Top5 99.476562    LR 0.030000    Time 0.032215    
2018-10-21 07:11:23,608 - Epoch: [127][  250/  391]    Overall Loss 1.548052    Objective Loss 1.548052    Top1 91.721875    Top5 99.468750    LR 0.030000    Time 0.031968    
2018-10-21 07:11:25,175 - Epoch: [127][  300/  391]    Overall Loss 1.548646    Objective Loss 1.548646    Top1 91.648438    Top5 99.497396    LR 0.030000    Time 0.031855    
2018-10-21 07:11:26,730 - Epoch: [127][  350/  391]    Overall Loss 1.548220    Objective Loss 1.548220    Top1 91.691964    Top5 99.486607    LR 0.030000    Time 0.031741    
2018-10-21 07:11:28,127 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30764 | -0.00445 |    0.20417 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10247 | -0.00399 |    0.05859 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10125 |  0.00041 |    0.06681 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08612 | -0.00808 |    0.05701 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08528 | -0.00147 |    0.05624 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10348 | -0.01082 |    0.06960 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09272 | -0.01021 |    0.06566 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10929 | -0.00449 |    0.08080 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09229 | -0.00513 |    0.06984 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23203 | -0.00457 |    0.14488 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07498 | -0.00387 |    0.05602 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06510 | -0.00803 |    0.05065 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07807 | -0.00837 |    0.05974 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06244 | -0.00447 |    0.04781 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08453 | -0.00684 |    0.06653 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07412 | -0.00484 |    0.05836 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11060 | -0.00715 |    0.08451 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06800 | -0.00898 |    0.05302 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04517 | -0.00316 |    0.03399 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04136 | -0.00671 |    0.03157 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02710 |  0.00022 |    0.01831 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41478 | -0.00000 |    0.28462 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:11:28,127 - Total sparsity: 0.00

2018-10-21 07:11:28,127 - --- validate (epoch=127)-----------
2018-10-21 07:11:28,128 - 10000 samples (128 per mini-batch)
2018-10-21 07:11:29,435 - Epoch: [127][   50/   78]    Loss 1.579932    Top1 88.281250    Top5 99.484375    
2018-10-21 07:11:30,113 - ==> Top1: 88.240    Top5: 99.500    Loss: 1.580

2018-10-21 07:11:30,114 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:11:30,115 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:11:30,127 - 

2018-10-21 07:11:30,128 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:11:31,834 - Epoch: [128][   50/  391]    Overall Loss 1.540514    Objective Loss 1.540514    Top1 92.546875    Top5 99.484375    LR 0.030000    Time 0.034054    
2018-10-21 07:11:33,475 - Epoch: [128][  100/  391]    Overall Loss 1.545208    Objective Loss 1.545208    Top1 91.992188    Top5 99.437500    LR 0.030000    Time 0.033418    
2018-10-21 07:11:35,060 - Epoch: [128][  150/  391]    Overall Loss 1.544636    Objective Loss 1.544636    Top1 92.083333    Top5 99.473958    LR 0.030000    Time 0.032827    
2018-10-21 07:11:36,632 - Epoch: [128][  200/  391]    Overall Loss 1.545931    Objective Loss 1.545931    Top1 91.902344    Top5 99.484375    LR 0.030000    Time 0.032466    
2018-10-21 07:11:38,168 - Epoch: [128][  250/  391]    Overall Loss 1.545384    Objective Loss 1.545384    Top1 91.937500    Top5 99.500000    LR 0.030000    Time 0.032107    
2018-10-21 07:11:39,679 - Epoch: [128][  300/  391]    Overall Loss 1.547043    Objective Loss 1.547043    Top1 91.752604    Top5 99.494792    LR 0.030000    Time 0.031784    
2018-10-21 07:11:41,209 - Epoch: [128][  350/  391]    Overall Loss 1.547455    Objective Loss 1.547455    Top1 91.700893    Top5 99.473214    LR 0.030000    Time 0.031608    
2018-10-21 07:11:42,590 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30527 | -0.00187 |    0.20280 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10166 | -0.00353 |    0.05827 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10043 |  0.00041 |    0.06634 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08554 | -0.00731 |    0.05665 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08460 | -0.00116 |    0.05588 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10267 | -0.01087 |    0.06917 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09195 | -0.01007 |    0.06507 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10837 | -0.00456 |    0.08013 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09151 | -0.00531 |    0.06928 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23006 | -0.00407 |    0.14354 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07449 | -0.00383 |    0.05573 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06469 | -0.00804 |    0.05039 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07764 | -0.00830 |    0.05946 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06208 | -0.00430 |    0.04755 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08383 | -0.00678 |    0.06600 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07356 | -0.00479 |    0.05792 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10966 | -0.00705 |    0.08377 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06753 | -0.00903 |    0.05268 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04489 | -0.00312 |    0.03377 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04108 | -0.00666 |    0.03137 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02688 |  0.00014 |    0.01817 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41451 | -0.00000 |    0.28466 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:11:42,590 - Total sparsity: 0.00

2018-10-21 07:11:42,591 - --- validate (epoch=128)-----------
2018-10-21 07:11:42,591 - 10000 samples (128 per mini-batch)
2018-10-21 07:11:43,815 - Epoch: [128][   50/   78]    Loss 1.579377    Top1 88.484375    Top5 99.531250    
2018-10-21 07:11:44,529 - ==> Top1: 88.470    Top5: 99.560    Loss: 1.577

2018-10-21 07:11:44,530 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:11:44,530 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:11:44,544 - 

2018-10-21 07:11:44,544 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:11:46,243 - Epoch: [129][   50/  391]    Overall Loss 1.549106    Objective Loss 1.549106    Top1 91.468750    Top5 99.531250    LR 0.030000    Time 0.033922    
2018-10-21 07:11:47,837 - Epoch: [129][  100/  391]    Overall Loss 1.549533    Objective Loss 1.549533    Top1 91.468750    Top5 99.460938    LR 0.030000    Time 0.032875    
2018-10-21 07:11:49,434 - Epoch: [129][  150/  391]    Overall Loss 1.550872    Objective Loss 1.550872    Top1 91.312500    Top5 99.442708    LR 0.030000    Time 0.032546    
2018-10-21 07:11:51,015 - Epoch: [129][  200/  391]    Overall Loss 1.548975    Objective Loss 1.548975    Top1 91.542969    Top5 99.429688    LR 0.030000    Time 0.032305    
2018-10-21 07:11:52,590 - Epoch: [129][  250/  391]    Overall Loss 1.549349    Objective Loss 1.549349    Top1 91.509375    Top5 99.415625    LR 0.030000    Time 0.032133    
2018-10-21 07:11:54,152 - Epoch: [129][  300/  391]    Overall Loss 1.548353    Objective Loss 1.548353    Top1 91.591146    Top5 99.411458    LR 0.030000    Time 0.031975    
2018-10-21 07:11:55,715 - Epoch: [129][  350/  391]    Overall Loss 1.548229    Objective Loss 1.548229    Top1 91.625000    Top5 99.426339    LR 0.030000    Time 0.031865    
2018-10-21 07:11:57,142 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30283 | -0.00306 |    0.20139 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10088 | -0.00375 |    0.05773 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09964 |  0.00024 |    0.06587 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08486 | -0.00742 |    0.05598 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08392 | -0.00157 |    0.05547 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10183 | -0.01116 |    0.06885 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09119 | -0.00997 |    0.06455 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10748 | -0.00445 |    0.07957 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09076 | -0.00528 |    0.06874 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22814 | -0.00370 |    0.14246 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07400 | -0.00396 |    0.05534 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06429 | -0.00792 |    0.05007 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07722 | -0.00824 |    0.05913 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06173 | -0.00432 |    0.04735 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08315 | -0.00678 |    0.06547 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07301 | -0.00485 |    0.05749 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10874 | -0.00680 |    0.08302 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06708 | -0.00897 |    0.05234 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04462 | -0.00314 |    0.03360 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04081 | -0.00659 |    0.03116 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02667 |  0.00016 |    0.01803 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41417 | -0.00000 |    0.28441 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:11:57,142 - Total sparsity: 0.00

2018-10-21 07:11:57,143 - --- validate (epoch=129)-----------
2018-10-21 07:11:57,143 - 10000 samples (128 per mini-batch)
2018-10-21 07:11:58,334 - Epoch: [129][   50/   78]    Loss 1.586256    Top1 87.500000    Top5 99.453125    
2018-10-21 07:11:58,963 - ==> Top1: 87.860    Top5: 99.480    Loss: 1.582

2018-10-21 07:11:58,965 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:11:58,965 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:11:58,978 - 

2018-10-21 07:11:58,978 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:12:00,743 - Epoch: [130][   50/  391]    Overall Loss 1.549402    Objective Loss 1.549402    Top1 91.437500    Top5 99.296875    LR 0.030000    Time 0.035235    
2018-10-21 07:12:02,393 - Epoch: [130][  100/  391]    Overall Loss 1.550105    Objective Loss 1.550105    Top1 91.390625    Top5 99.296875    LR 0.030000    Time 0.034094    
2018-10-21 07:12:03,986 - Epoch: [130][  150/  391]    Overall Loss 1.548712    Objective Loss 1.548712    Top1 91.526042    Top5 99.364583    LR 0.030000    Time 0.033337    
2018-10-21 07:12:05,577 - Epoch: [130][  200/  391]    Overall Loss 1.547954    Objective Loss 1.547954    Top1 91.636719    Top5 99.363281    LR 0.030000    Time 0.032945    
2018-10-21 07:12:07,195 - Epoch: [130][  250/  391]    Overall Loss 1.547642    Objective Loss 1.547642    Top1 91.662500    Top5 99.400000    LR 0.030000    Time 0.032818    
2018-10-21 07:12:08,780 - Epoch: [130][  300/  391]    Overall Loss 1.548185    Objective Loss 1.548185    Top1 91.614583    Top5 99.416667    LR 0.030000    Time 0.032624    
2018-10-21 07:12:10,372 - Epoch: [130][  350/  391]    Overall Loss 1.548781    Objective Loss 1.548781    Top1 91.575893    Top5 99.417411    LR 0.030000    Time 0.032507    
2018-10-21 07:12:11,826 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30037 | -0.00432 |    0.19917 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10009 | -0.00380 |    0.05729 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09885 |  0.00026 |    0.06526 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08421 | -0.00740 |    0.05554 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08325 | -0.00173 |    0.05510 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10110 | -0.01083 |    0.06832 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09051 | -0.00938 |    0.06399 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10660 | -0.00438 |    0.07891 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09004 | -0.00487 |    0.06819 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22619 | -0.00407 |    0.14116 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07354 | -0.00367 |    0.05495 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06389 | -0.00771 |    0.04973 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07678 | -0.00831 |    0.05883 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06138 | -0.00423 |    0.04715 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08248 | -0.00676 |    0.06497 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07247 | -0.00485 |    0.05706 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10782 | -0.00656 |    0.08224 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06667 | -0.00879 |    0.05201 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04435 | -0.00319 |    0.03343 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04054 | -0.00658 |    0.03097 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02646 |  0.00021 |    0.01788 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41370 | -0.00001 |    0.28428 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:12:11,826 - Total sparsity: 0.00

2018-10-21 07:12:11,826 - --- validate (epoch=130)-----------
2018-10-21 07:12:11,826 - 10000 samples (128 per mini-batch)
2018-10-21 07:12:13,019 - Epoch: [130][   50/   78]    Loss 1.582626    Top1 87.937500    Top5 99.453125    
2018-10-21 07:12:13,681 - ==> Top1: 88.090    Top5: 99.490    Loss: 1.580

2018-10-21 07:12:13,683 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:12:13,683 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:12:13,695 - 

2018-10-21 07:12:13,695 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:12:15,438 - Epoch: [131][   50/  391]    Overall Loss 1.545299    Objective Loss 1.545299    Top1 92.000000    Top5 99.453125    LR 0.030000    Time 0.034797    
2018-10-21 07:12:17,036 - Epoch: [131][  100/  391]    Overall Loss 1.543243    Objective Loss 1.543243    Top1 92.125000    Top5 99.492188    LR 0.030000    Time 0.033344    
2018-10-21 07:12:18,642 - Epoch: [131][  150/  391]    Overall Loss 1.543551    Objective Loss 1.543551    Top1 92.130208    Top5 99.484375    LR 0.030000    Time 0.032918    
2018-10-21 07:12:20,230 - Epoch: [131][  200/  391]    Overall Loss 1.544595    Objective Loss 1.544595    Top1 92.007812    Top5 99.488281    LR 0.030000    Time 0.032618    
2018-10-21 07:12:21,830 - Epoch: [131][  250/  391]    Overall Loss 1.544949    Objective Loss 1.544949    Top1 91.990625    Top5 99.487500    LR 0.030000    Time 0.032485    
2018-10-21 07:12:23,421 - Epoch: [131][  300/  391]    Overall Loss 1.544885    Objective Loss 1.544885    Top1 92.015625    Top5 99.497396    LR 0.030000    Time 0.032370    
2018-10-21 07:12:25,011 - Epoch: [131][  350/  391]    Overall Loss 1.544780    Objective Loss 1.544780    Top1 92.013393    Top5 99.484375    LR 0.030000    Time 0.032280    
2018-10-21 07:12:26,434 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29803 | -0.00195 |    0.19822 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09930 | -0.00366 |    0.05686 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09806 |  0.00051 |    0.06499 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08357 | -0.00746 |    0.05520 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08259 | -0.00182 |    0.05463 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10034 | -0.01076 |    0.06780 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08980 | -0.00913 |    0.06373 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10575 | -0.00432 |    0.07820 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08931 | -0.00497 |    0.06768 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22429 | -0.00410 |    0.13980 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07307 | -0.00365 |    0.05456 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06350 | -0.00756 |    0.04944 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07639 | -0.00804 |    0.05848 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06105 | -0.00410 |    0.04691 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08183 | -0.00673 |    0.06447 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07196 | -0.00463 |    0.05666 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10690 | -0.00643 |    0.08151 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06624 | -0.00873 |    0.05168 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04409 | -0.00317 |    0.03325 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04026 | -0.00657 |    0.03076 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02624 |  0.00021 |    0.01772 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41359 | -0.00001 |    0.28422 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:12:26,435 - Total sparsity: 0.00

2018-10-21 07:12:26,435 - --- validate (epoch=131)-----------
2018-10-21 07:12:26,435 - 10000 samples (128 per mini-batch)
2018-10-21 07:12:27,666 - Epoch: [131][   50/   78]    Loss 1.577198    Top1 88.625000    Top5 99.531250    
2018-10-21 07:12:28,296 - ==> Top1: 88.640    Top5: 99.540    Loss: 1.576

2018-10-21 07:12:28,297 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:12:28,298 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:12:28,311 - 

2018-10-21 07:12:28,311 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:12:30,060 - Epoch: [132][   50/  391]    Overall Loss 1.543285    Objective Loss 1.543285    Top1 92.140625    Top5 99.484375    LR 0.030000    Time 0.034924    
2018-10-21 07:12:31,706 - Epoch: [132][  100/  391]    Overall Loss 1.541173    Objective Loss 1.541173    Top1 92.367188    Top5 99.445312    LR 0.030000    Time 0.033901    
2018-10-21 07:12:33,304 - Epoch: [132][  150/  391]    Overall Loss 1.543177    Objective Loss 1.543177    Top1 92.156250    Top5 99.453125    LR 0.030000    Time 0.033235    
2018-10-21 07:12:34,870 - Epoch: [132][  200/  391]    Overall Loss 1.544505    Objective Loss 1.544505    Top1 92.027344    Top5 99.457031    LR 0.030000    Time 0.032746    
2018-10-21 07:12:36,405 - Epoch: [132][  250/  391]    Overall Loss 1.545399    Objective Loss 1.545399    Top1 91.946875    Top5 99.493750    LR 0.030000    Time 0.032330    
2018-10-21 07:12:37,957 - Epoch: [132][  300/  391]    Overall Loss 1.545593    Objective Loss 1.545593    Top1 91.934896    Top5 99.497396    LR 0.030000    Time 0.032105    
2018-10-21 07:12:39,500 - Epoch: [132][  350/  391]    Overall Loss 1.545676    Objective Loss 1.545676    Top1 91.939732    Top5 99.484375    LR 0.030000    Time 0.031921    
2018-10-21 07:12:40,903 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29574 | -0.00123 |    0.19585 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09856 | -0.00364 |    0.05637 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09730 |  0.00103 |    0.06442 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08297 | -0.00730 |    0.05482 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08197 | -0.00169 |    0.05436 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09958 | -0.01124 |    0.06741 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08910 | -0.00924 |    0.06328 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10495 | -0.00402 |    0.07771 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08865 | -0.00455 |    0.06715 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22253 | -0.00304 |    0.13914 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07262 | -0.00378 |    0.05429 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06314 | -0.00738 |    0.04922 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07601 | -0.00817 |    0.05828 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06074 | -0.00414 |    0.04672 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08120 | -0.00683 |    0.06397 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07146 | -0.00468 |    0.05627 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10602 | -0.00636 |    0.08077 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06586 | -0.00860 |    0.05142 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04385 | -0.00318 |    0.03308 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04002 | -0.00658 |    0.03062 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02605 |  0.00021 |    0.01760 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41346 | -0.00001 |    0.28427 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:12:40,903 - Total sparsity: 0.00

2018-10-21 07:12:40,903 - --- validate (epoch=132)-----------
2018-10-21 07:12:40,903 - 10000 samples (128 per mini-batch)
2018-10-21 07:12:42,190 - Epoch: [132][   50/   78]    Loss 1.584674    Top1 87.687500    Top5 99.375000    
2018-10-21 07:12:42,837 - ==> Top1: 87.940    Top5: 99.390    Loss: 1.581

2018-10-21 07:12:42,838 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:12:42,839 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:12:42,852 - 

2018-10-21 07:12:42,852 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:12:44,665 - Epoch: [133][   50/  391]    Overall Loss 1.542609    Objective Loss 1.542609    Top1 92.515625    Top5 99.531250    LR 0.030000    Time 0.036187    
2018-10-21 07:12:46,294 - Epoch: [133][  100/  391]    Overall Loss 1.546010    Objective Loss 1.546010    Top1 91.984375    Top5 99.500000    LR 0.030000    Time 0.034358    
2018-10-21 07:12:47,875 - Epoch: [133][  150/  391]    Overall Loss 1.545741    Objective Loss 1.545741    Top1 91.932292    Top5 99.473958    LR 0.030000    Time 0.033430    
2018-10-21 07:12:49,461 - Epoch: [133][  200/  391]    Overall Loss 1.546893    Objective Loss 1.546893    Top1 91.792969    Top5 99.464844    LR 0.030000    Time 0.032992    
2018-10-21 07:12:51,033 - Epoch: [133][  250/  391]    Overall Loss 1.547174    Objective Loss 1.547174    Top1 91.737500    Top5 99.465625    LR 0.030000    Time 0.032675    
2018-10-21 07:12:52,592 - Epoch: [133][  300/  391]    Overall Loss 1.547353    Objective Loss 1.547353    Top1 91.713542    Top5 99.486979    LR 0.030000    Time 0.032418    
2018-10-21 07:12:54,152 - Epoch: [133][  350/  391]    Overall Loss 1.547753    Objective Loss 1.547753    Top1 91.687500    Top5 99.473214    LR 0.030000    Time 0.032236    
2018-10-21 07:12:55,581 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29359 | -0.00141 |    0.19441 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09789 | -0.00367 |    0.05596 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09661 |  0.00079 |    0.06392 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08239 | -0.00704 |    0.05449 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08140 | -0.00123 |    0.05391 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09896 | -0.01062 |    0.06716 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08844 | -0.00925 |    0.06276 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10418 | -0.00390 |    0.07712 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08798 | -0.00469 |    0.06666 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22079 | -0.00370 |    0.13718 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07224 | -0.00375 |    0.05396 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06279 | -0.00749 |    0.04894 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07563 | -0.00830 |    0.05800 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06044 | -0.00412 |    0.04651 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08062 | -0.00661 |    0.06355 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07099 | -0.00470 |    0.05592 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10515 | -0.00639 |    0.08013 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06548 | -0.00862 |    0.05116 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04364 | -0.00311 |    0.03294 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03979 | -0.00663 |    0.03046 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02587 |  0.00019 |    0.01748 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41330 | -0.00001 |    0.28431 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:12:55,581 - Total sparsity: 0.00

2018-10-21 07:12:55,581 - --- validate (epoch=133)-----------
2018-10-21 07:12:55,581 - 10000 samples (128 per mini-batch)
2018-10-21 07:12:56,949 - Epoch: [133][   50/   78]    Loss 1.580086    Top1 88.093750    Top5 99.437500    
2018-10-21 07:12:57,646 - ==> Top1: 88.240    Top5: 99.500    Loss: 1.579

2018-10-21 07:12:57,647 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:12:57,647 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:12:57,660 - 

2018-10-21 07:12:57,660 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:12:59,484 - Epoch: [134][   50/  391]    Overall Loss 1.545519    Objective Loss 1.545519    Top1 91.812500    Top5 99.515625    LR 0.030000    Time 0.036411    
2018-10-21 07:13:01,109 - Epoch: [134][  100/  391]    Overall Loss 1.542987    Objective Loss 1.542987    Top1 92.156250    Top5 99.515625    LR 0.030000    Time 0.034438    
2018-10-21 07:13:02,713 - Epoch: [134][  150/  391]    Overall Loss 1.545858    Objective Loss 1.545858    Top1 91.817708    Top5 99.484375    LR 0.030000    Time 0.033635    
2018-10-21 07:13:04,261 - Epoch: [134][  200/  391]    Overall Loss 1.546234    Objective Loss 1.546234    Top1 91.777344    Top5 99.503906    LR 0.030000    Time 0.032953    
2018-10-21 07:13:05,824 - Epoch: [134][  250/  391]    Overall Loss 1.545851    Objective Loss 1.545851    Top1 91.840625    Top5 99.512500    LR 0.030000    Time 0.032608    
2018-10-21 07:13:07,384 - Epoch: [134][  300/  391]    Overall Loss 1.545576    Objective Loss 1.545576    Top1 91.861979    Top5 99.494792    LR 0.030000    Time 0.032365    
2018-10-21 07:13:08,958 - Epoch: [134][  350/  391]    Overall Loss 1.545905    Objective Loss 1.545905    Top1 91.832589    Top5 99.495536    LR 0.030000    Time 0.032233    
2018-10-21 07:13:10,351 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29145 | -0.00180 |    0.19329 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09724 | -0.00322 |    0.05556 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09596 |  0.00065 |    0.06360 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08181 | -0.00713 |    0.05412 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08080 | -0.00139 |    0.05348 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09830 | -0.01024 |    0.06664 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08777 | -0.00936 |    0.06206 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10341 | -0.00397 |    0.07651 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08734 | -0.00464 |    0.06619 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21908 | -0.00359 |    0.13593 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07187 | -0.00355 |    0.05370 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06248 | -0.00734 |    0.04870 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07532 | -0.00802 |    0.05777 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06016 | -0.00398 |    0.04633 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08004 | -0.00667 |    0.06308 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07054 | -0.00457 |    0.05556 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10430 | -0.00640 |    0.07948 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06514 | -0.00850 |    0.05091 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04343 | -0.00317 |    0.03282 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03957 | -0.00664 |    0.03029 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02568 |  0.00018 |    0.01736 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41294 | -0.00001 |    0.28416 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:13:10,352 - Total sparsity: 0.00

2018-10-21 07:13:10,352 - --- validate (epoch=134)-----------
2018-10-21 07:13:10,352 - 10000 samples (128 per mini-batch)
2018-10-21 07:13:11,620 - Epoch: [134][   50/   78]    Loss 1.582276    Top1 88.125000    Top5 99.546875    
2018-10-21 07:13:12,353 - ==> Top1: 88.200    Top5: 99.520    Loss: 1.580

2018-10-21 07:13:12,355 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:13:12,355 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:13:12,368 - 

2018-10-21 07:13:12,368 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:13:14,127 - Epoch: [135][   50/  391]    Overall Loss 1.540558    Objective Loss 1.540558    Top1 92.312500    Top5 99.468750    LR 0.030000    Time 0.035110    
2018-10-21 07:13:15,753 - Epoch: [135][  100/  391]    Overall Loss 1.542134    Objective Loss 1.542134    Top1 92.273438    Top5 99.398438    LR 0.030000    Time 0.033799    
2018-10-21 07:13:17,352 - Epoch: [135][  150/  391]    Overall Loss 1.543432    Objective Loss 1.543432    Top1 92.135417    Top5 99.432292    LR 0.030000    Time 0.033175    
2018-10-21 07:13:18,954 - Epoch: [135][  200/  391]    Overall Loss 1.543189    Objective Loss 1.543189    Top1 92.136719    Top5 99.449219    LR 0.030000    Time 0.032883    
2018-10-21 07:13:20,546 - Epoch: [135][  250/  391]    Overall Loss 1.543472    Objective Loss 1.543472    Top1 92.106250    Top5 99.462500    LR 0.030000    Time 0.032663    
2018-10-21 07:13:22,130 - Epoch: [135][  300/  391]    Overall Loss 1.543348    Objective Loss 1.543348    Top1 92.117188    Top5 99.466146    LR 0.030000    Time 0.032493    
2018-10-21 07:13:23,676 - Epoch: [135][  350/  391]    Overall Loss 1.543936    Objective Loss 1.543936    Top1 92.055804    Top5 99.453125    LR 0.030000    Time 0.032263    
2018-10-21 07:13:25,089 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28937 | -0.00350 |    0.19253 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09659 | -0.00330 |    0.05514 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09527 |  0.00104 |    0.06324 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08125 | -0.00680 |    0.05369 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08023 | -0.00094 |    0.05302 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09763 | -0.01013 |    0.06613 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08711 | -0.00934 |    0.06151 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10266 | -0.00356 |    0.07593 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08671 | -0.00447 |    0.06567 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21741 | -0.00342 |    0.13555 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07148 | -0.00342 |    0.05347 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06217 | -0.00727 |    0.04849 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07501 | -0.00787 |    0.05750 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05987 | -0.00397 |    0.04614 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07948 | -0.00640 |    0.06264 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07009 | -0.00466 |    0.05519 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10346 | -0.00643 |    0.07866 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06480 | -0.00837 |    0.05063 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04322 | -0.00312 |    0.03271 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03935 | -0.00666 |    0.03013 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02550 |  0.00018 |    0.01722 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41267 | -0.00001 |    0.28399 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:13:25,089 - Total sparsity: 0.00

2018-10-21 07:13:25,089 - --- validate (epoch=135)-----------
2018-10-21 07:13:25,089 - 10000 samples (128 per mini-batch)
2018-10-21 07:13:26,278 - Epoch: [135][   50/   78]    Loss 1.578676    Top1 88.453125    Top5 99.281250    
2018-10-21 07:13:26,890 - ==> Top1: 88.030    Top5: 99.410    Loss: 1.582

2018-10-21 07:13:26,891 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:13:26,891 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:13:26,904 - 

2018-10-21 07:13:26,904 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:13:28,831 - Epoch: [136][   50/  391]    Overall Loss 1.543602    Objective Loss 1.543602    Top1 92.046875    Top5 99.578125    LR 0.030000    Time 0.038477    
2018-10-21 07:13:30,469 - Epoch: [136][  100/  391]    Overall Loss 1.543439    Objective Loss 1.543439    Top1 92.054688    Top5 99.523438    LR 0.030000    Time 0.035590    
2018-10-21 07:13:32,082 - Epoch: [136][  150/  391]    Overall Loss 1.544328    Objective Loss 1.544328    Top1 91.994792    Top5 99.494792    LR 0.030000    Time 0.034462    
2018-10-21 07:13:33,670 - Epoch: [136][  200/  391]    Overall Loss 1.544287    Objective Loss 1.544287    Top1 92.023438    Top5 99.519531    LR 0.030000    Time 0.033777    
2018-10-21 07:13:35,266 - Epoch: [136][  250/  391]    Overall Loss 1.543828    Objective Loss 1.543828    Top1 92.071875    Top5 99.521875    LR 0.030000    Time 0.033398    
2018-10-21 07:13:36,851 - Epoch: [136][  300/  391]    Overall Loss 1.544362    Objective Loss 1.544362    Top1 92.018229    Top5 99.513021    LR 0.030000    Time 0.033108    
2018-10-21 07:13:38,419 - Epoch: [136][  350/  391]    Overall Loss 1.544160    Objective Loss 1.544160    Top1 92.031250    Top5 99.502232    LR 0.030000    Time 0.032852    
2018-10-21 07:13:39,859 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28727 | -0.00164 |    0.19004 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09598 | -0.00320 |    0.05490 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09463 |  0.00071 |    0.06287 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08068 | -0.00707 |    0.05349 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07966 | -0.00105 |    0.05264 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09695 | -0.01034 |    0.06580 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08650 | -0.00896 |    0.06107 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10192 | -0.00356 |    0.07536 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08608 | -0.00461 |    0.06512 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21575 | -0.00304 |    0.13409 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07112 | -0.00327 |    0.05319 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06187 | -0.00722 |    0.04820 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07471 | -0.00783 |    0.05728 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05958 | -0.00408 |    0.04593 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07892 | -0.00626 |    0.06220 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06965 | -0.00463 |    0.05487 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10263 | -0.00633 |    0.07801 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06444 | -0.00840 |    0.05039 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04302 | -0.00307 |    0.03253 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03915 | -0.00655 |    0.02998 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02532 |  0.00015 |    0.01712 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41234 | -0.00001 |    0.28392 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:13:39,859 - Total sparsity: 0.00

2018-10-21 07:13:39,859 - --- validate (epoch=136)-----------
2018-10-21 07:13:39,859 - 10000 samples (128 per mini-batch)
2018-10-21 07:13:41,120 - Epoch: [136][   50/   78]    Loss 1.580459    Top1 88.265625    Top5 99.453125    
2018-10-21 07:13:41,782 - ==> Top1: 88.270    Top5: 99.500    Loss: 1.579

2018-10-21 07:13:41,783 - ==> Best Top1: 88.700   On Epoch: 121

2018-10-21 07:13:41,783 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:13:41,797 - 

2018-10-21 07:13:41,797 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:13:43,570 - Epoch: [137][   50/  391]    Overall Loss 1.546532    Objective Loss 1.546532    Top1 91.734375    Top5 99.406250    LR 0.030000    Time 0.035398    
2018-10-21 07:13:45,182 - Epoch: [137][  100/  391]    Overall Loss 1.543606    Objective Loss 1.543606    Top1 92.007812    Top5 99.421875    LR 0.030000    Time 0.033796    
2018-10-21 07:13:46,792 - Epoch: [137][  150/  391]    Overall Loss 1.544450    Objective Loss 1.544450    Top1 91.937500    Top5 99.380208    LR 0.030000    Time 0.033248    
2018-10-21 07:13:48,388 - Epoch: [137][  200/  391]    Overall Loss 1.542905    Objective Loss 1.542905    Top1 92.117188    Top5 99.375000    LR 0.030000    Time 0.032902    
2018-10-21 07:13:49,975 - Epoch: [137][  250/  391]    Overall Loss 1.542468    Objective Loss 1.542468    Top1 92.181250    Top5 99.418750    LR 0.030000    Time 0.032661    
2018-10-21 07:13:51,556 - Epoch: [137][  300/  391]    Overall Loss 1.542117    Objective Loss 1.542117    Top1 92.226562    Top5 99.442708    LR 0.030000    Time 0.032482    
2018-10-21 07:13:53,145 - Epoch: [137][  350/  391]    Overall Loss 1.542248    Objective Loss 1.542248    Top1 92.194196    Top5 99.446429    LR 0.030000    Time 0.032373    
2018-10-21 07:13:54,585 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28509 | -0.00300 |    0.18931 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09534 | -0.00356 |    0.05462 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09399 |  0.00032 |    0.06260 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08012 | -0.00701 |    0.05316 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07909 | -0.00119 |    0.05213 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09626 | -0.01038 |    0.06543 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08593 | -0.00849 |    0.06073 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10119 | -0.00325 |    0.07486 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08548 | -0.00452 |    0.06475 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21411 | -0.00332 |    0.13354 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07075 | -0.00331 |    0.05297 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06158 | -0.00712 |    0.04803 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07439 | -0.00770 |    0.05697 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05929 | -0.00415 |    0.04573 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07838 | -0.00608 |    0.06181 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06923 | -0.00453 |    0.05453 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10180 | -0.00628 |    0.07736 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06411 | -0.00832 |    0.05011 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04282 | -0.00313 |    0.03241 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03893 | -0.00654 |    0.02981 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02514 |  0.00014 |    0.01700 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41210 | -0.00001 |    0.28387 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:13:54,585 - Total sparsity: 0.00

2018-10-21 07:13:54,585 - --- validate (epoch=137)-----------
2018-10-21 07:13:54,586 - 10000 samples (128 per mini-batch)
2018-10-21 07:13:55,923 - Epoch: [137][   50/   78]    Loss 1.574670    Top1 88.734375    Top5 99.453125    
2018-10-21 07:13:56,611 - ==> Top1: 89.000    Top5: 99.530    Loss: 1.572

2018-10-21 07:13:56,613 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:13:56,613 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:13:56,630 - 

2018-10-21 07:13:56,631 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:13:58,329 - Epoch: [138][   50/  391]    Overall Loss 1.540360    Objective Loss 1.540360    Top1 92.343750    Top5 99.421875    LR 0.030000    Time 0.033902    
2018-10-21 07:14:00,021 - Epoch: [138][  100/  391]    Overall Loss 1.541023    Objective Loss 1.541023    Top1 92.343750    Top5 99.476562    LR 0.030000    Time 0.033849    
2018-10-21 07:14:01,629 - Epoch: [138][  150/  391]    Overall Loss 1.542677    Objective Loss 1.542677    Top1 92.203125    Top5 99.453125    LR 0.030000    Time 0.033272    
2018-10-21 07:14:03,240 - Epoch: [138][  200/  391]    Overall Loss 1.542986    Objective Loss 1.542986    Top1 92.179688    Top5 99.441406    LR 0.030000    Time 0.032995    
2018-10-21 07:14:04,845 - Epoch: [138][  250/  391]    Overall Loss 1.544128    Objective Loss 1.544128    Top1 92.081250    Top5 99.443750    LR 0.030000    Time 0.032809    
2018-10-21 07:14:06,420 - Epoch: [138][  300/  391]    Overall Loss 1.544270    Objective Loss 1.544270    Top1 92.065104    Top5 99.458333    LR 0.030000    Time 0.032584    
2018-10-21 07:14:08,004 - Epoch: [138][  350/  391]    Overall Loss 1.544583    Objective Loss 1.544583    Top1 92.022321    Top5 99.468750    LR 0.030000    Time 0.032449    
2018-10-21 07:14:09,419 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28313 | -0.00337 |    0.18818 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09473 | -0.00360 |    0.05422 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09338 |  0.00066 |    0.06220 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07965 | -0.00692 |    0.05279 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07858 | -0.00113 |    0.05172 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09564 | -0.01035 |    0.06489 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08538 | -0.00840 |    0.06033 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10050 | -0.00328 |    0.07432 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08491 | -0.00449 |    0.06428 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21259 | -0.00301 |    0.13269 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07045 | -0.00331 |    0.05279 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06129 | -0.00734 |    0.04783 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07408 | -0.00790 |    0.05674 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05902 | -0.00421 |    0.04560 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07787 | -0.00611 |    0.06139 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06883 | -0.00459 |    0.05424 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10102 | -0.00609 |    0.07695 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06384 | -0.00816 |    0.04991 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04266 | -0.00315 |    0.03232 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03874 | -0.00658 |    0.02968 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02498 |  0.00013 |    0.01688 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41182 | -0.00001 |    0.28380 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:14:09,419 - Total sparsity: 0.00

2018-10-21 07:14:09,419 - --- validate (epoch=138)-----------
2018-10-21 07:14:09,419 - 10000 samples (128 per mini-batch)
2018-10-21 07:14:10,633 - Epoch: [138][   50/   78]    Loss 1.576383    Top1 88.546875    Top5 99.421875    
2018-10-21 07:14:11,281 - ==> Top1: 88.650    Top5: 99.490    Loss: 1.575

2018-10-21 07:14:11,283 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:14:11,283 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:14:11,296 - 

2018-10-21 07:14:11,297 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:14:13,094 - Epoch: [139][   50/  391]    Overall Loss 1.542761    Objective Loss 1.542761    Top1 92.421875    Top5 99.484375    LR 0.030000    Time 0.035888    
2018-10-21 07:14:14,707 - Epoch: [139][  100/  391]    Overall Loss 1.542711    Objective Loss 1.542711    Top1 92.257812    Top5 99.476562    LR 0.030000    Time 0.034045    
2018-10-21 07:14:16,293 - Epoch: [139][  150/  391]    Overall Loss 1.542405    Objective Loss 1.542405    Top1 92.218750    Top5 99.453125    LR 0.030000    Time 0.033258    
2018-10-21 07:14:17,885 - Epoch: [139][  200/  391]    Overall Loss 1.542908    Objective Loss 1.542908    Top1 92.152344    Top5 99.464844    LR 0.030000    Time 0.032891    
2018-10-21 07:14:19,465 - Epoch: [139][  250/  391]    Overall Loss 1.543125    Objective Loss 1.543125    Top1 92.168750    Top5 99.490625    LR 0.030000    Time 0.032624    
2018-10-21 07:14:21,077 - Epoch: [139][  300/  391]    Overall Loss 1.543183    Objective Loss 1.543183    Top1 92.143229    Top5 99.507812    LR 0.030000    Time 0.032554    
2018-10-21 07:14:22,681 - Epoch: [139][  350/  391]    Overall Loss 1.543934    Objective Loss 1.543934    Top1 92.071429    Top5 99.484375    LR 0.030000    Time 0.032479    
2018-10-21 07:14:24,115 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28132 | -0.00440 |    0.18667 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09417 | -0.00361 |    0.05403 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09283 |  0.00077 |    0.06183 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07919 | -0.00702 |    0.05226 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07809 | -0.00123 |    0.05135 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09503 | -0.01076 |    0.06461 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08484 | -0.00831 |    0.05999 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09983 | -0.00367 |    0.07387 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08437 | -0.00445 |    0.06392 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21113 | -0.00348 |    0.13165 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07014 | -0.00348 |    0.05253 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06104 | -0.00751 |    0.04764 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07387 | -0.00779 |    0.05655 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05879 | -0.00439 |    0.04540 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07739 | -0.00600 |    0.06101 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06847 | -0.00460 |    0.05396 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10029 | -0.00593 |    0.07645 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06356 | -0.00813 |    0.04971 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04251 | -0.00306 |    0.03222 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03857 | -0.00661 |    0.02957 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02482 |  0.00014 |    0.01678 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41164 | -0.00001 |    0.28382 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:14:24,115 - Total sparsity: 0.00

2018-10-21 07:14:24,115 - --- validate (epoch=139)-----------
2018-10-21 07:14:24,116 - 10000 samples (128 per mini-batch)
2018-10-21 07:14:25,516 - Epoch: [139][   50/   78]    Loss 1.577051    Top1 88.625000    Top5 99.593750    
2018-10-21 07:14:26,277 - ==> Top1: 88.470    Top5: 99.570    Loss: 1.577

2018-10-21 07:14:26,279 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:14:26,279 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:14:26,296 - 

2018-10-21 07:14:26,296 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:14:28,226 - Epoch: [140][   50/  391]    Overall Loss 1.533459    Objective Loss 1.533459    Top1 93.171875    Top5 99.703125    LR 0.030000    Time 0.038529    
2018-10-21 07:14:29,870 - Epoch: [140][  100/  391]    Overall Loss 1.538337    Objective Loss 1.538337    Top1 92.664062    Top5 99.648438    LR 0.030000    Time 0.035674    
2018-10-21 07:14:31,442 - Epoch: [140][  150/  391]    Overall Loss 1.540495    Objective Loss 1.540495    Top1 92.442708    Top5 99.588542    LR 0.030000    Time 0.034250    
2018-10-21 07:14:33,015 - Epoch: [140][  200/  391]    Overall Loss 1.542844    Objective Loss 1.542844    Top1 92.214844    Top5 99.593750    LR 0.030000    Time 0.033542    
2018-10-21 07:14:34,653 - Epoch: [140][  250/  391]    Overall Loss 1.543783    Objective Loss 1.543783    Top1 92.140625    Top5 99.556250    LR 0.030000    Time 0.033375    
2018-10-21 07:14:36,292 - Epoch: [140][  300/  391]    Overall Loss 1.544612    Objective Loss 1.544612    Top1 92.044271    Top5 99.536458    LR 0.030000    Time 0.033268    
2018-10-21 07:14:37,907 - Epoch: [140][  350/  391]    Overall Loss 1.544478    Objective Loss 1.544478    Top1 92.051339    Top5 99.549107    LR 0.030000    Time 0.033125    
2018-10-21 07:14:39,328 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27942 | -0.00436 |    0.18586 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09365 | -0.00369 |    0.05388 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09232 |  0.00057 |    0.06173 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07871 | -0.00718 |    0.05202 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07759 | -0.00142 |    0.05082 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09449 | -0.01041 |    0.06420 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08432 | -0.00816 |    0.05965 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09919 | -0.00369 |    0.07334 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08384 | -0.00446 |    0.06349 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20973 | -0.00267 |    0.13036 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06989 | -0.00297 |    0.05229 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06085 | -0.00729 |    0.04744 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07362 | -0.00780 |    0.05647 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05859 | -0.00427 |    0.04525 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07692 | -0.00598 |    0.06067 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06812 | -0.00442 |    0.05371 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09956 | -0.00602 |    0.07591 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06328 | -0.00816 |    0.04949 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04236 | -0.00307 |    0.03213 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03841 | -0.00661 |    0.02947 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02467 |  0.00015 |    0.01667 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41144 | -0.00001 |    0.28380 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:14:39,329 - Total sparsity: 0.00

2018-10-21 07:14:39,329 - --- validate (epoch=140)-----------
2018-10-21 07:14:39,329 - 10000 samples (128 per mini-batch)
2018-10-21 07:14:40,602 - Epoch: [140][   50/   78]    Loss 1.581105    Top1 88.046875    Top5 99.234375    
2018-10-21 07:14:41,261 - ==> Top1: 87.900    Top5: 99.290    Loss: 1.583

2018-10-21 07:14:41,262 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:14:41,263 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:14:41,277 - 

2018-10-21 07:14:41,277 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:14:43,142 - Epoch: [141][   50/  391]    Overall Loss 1.536299    Objective Loss 1.536299    Top1 92.921875    Top5 99.484375    LR 0.030000    Time 0.037237    
2018-10-21 07:14:44,809 - Epoch: [141][  100/  391]    Overall Loss 1.537321    Objective Loss 1.537321    Top1 92.703125    Top5 99.500000    LR 0.030000    Time 0.035262    
2018-10-21 07:14:46,505 - Epoch: [141][  150/  391]    Overall Loss 1.538404    Objective Loss 1.538404    Top1 92.593750    Top5 99.520833    LR 0.030000    Time 0.034800    
2018-10-21 07:14:48,147 - Epoch: [141][  200/  391]    Overall Loss 1.539232    Objective Loss 1.539232    Top1 92.523438    Top5 99.523438    LR 0.030000    Time 0.034301    
2018-10-21 07:14:49,793 - Epoch: [141][  250/  391]    Overall Loss 1.539466    Objective Loss 1.539466    Top1 92.503125    Top5 99.540625    LR 0.030000    Time 0.034013    
2018-10-21 07:14:51,422 - Epoch: [141][  300/  391]    Overall Loss 1.540635    Objective Loss 1.540635    Top1 92.414062    Top5 99.523438    LR 0.030000    Time 0.033769    
2018-10-21 07:14:53,023 - Epoch: [141][  350/  391]    Overall Loss 1.541189    Objective Loss 1.541189    Top1 92.352679    Top5 99.520089    LR 0.030000    Time 0.033513    
2018-10-21 07:14:54,543 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27772 | -0.00222 |    0.18382 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09315 | -0.00375 |    0.05381 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09183 |  0.00070 |    0.06135 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07828 | -0.00694 |    0.05176 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07713 | -0.00167 |    0.05059 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09392 | -0.01025 |    0.06390 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08383 | -0.00785 |    0.05937 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09857 | -0.00362 |    0.07295 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08334 | -0.00455 |    0.06307 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20832 | -0.00268 |    0.12853 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06960 | -0.00307 |    0.05213 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06062 | -0.00720 |    0.04728 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07339 | -0.00796 |    0.05629 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05837 | -0.00441 |    0.04512 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07645 | -0.00594 |    0.06024 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06779 | -0.00422 |    0.05342 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09885 | -0.00599 |    0.07540 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06305 | -0.00803 |    0.04933 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04222 | -0.00312 |    0.03207 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03826 | -0.00660 |    0.02937 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02452 |  0.00016 |    0.01656 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41136 | -0.00001 |    0.28392 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:14:54,544 - Total sparsity: 0.00

2018-10-21 07:14:54,544 - --- validate (epoch=141)-----------
2018-10-21 07:14:54,544 - 10000 samples (128 per mini-batch)
2018-10-21 07:14:55,941 - Epoch: [141][   50/   78]    Loss 1.582408    Top1 88.046875    Top5 99.593750    
2018-10-21 07:14:56,702 - ==> Top1: 88.180    Top5: 99.570    Loss: 1.580

2018-10-21 07:14:56,704 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:14:56,704 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:14:56,717 - 

2018-10-21 07:14:56,718 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:14:58,435 - Epoch: [142][   50/  391]    Overall Loss 1.547048    Objective Loss 1.547048    Top1 91.578125    Top5 99.406250    LR 0.030000    Time 0.034287    
2018-10-21 07:15:00,002 - Epoch: [142][  100/  391]    Overall Loss 1.542510    Objective Loss 1.542510    Top1 92.054688    Top5 99.445312    LR 0.030000    Time 0.032792    
2018-10-21 07:15:01,554 - Epoch: [142][  150/  391]    Overall Loss 1.543394    Objective Loss 1.543394    Top1 92.026042    Top5 99.463542    LR 0.030000    Time 0.032196    
2018-10-21 07:15:03,150 - Epoch: [142][  200/  391]    Overall Loss 1.542745    Objective Loss 1.542745    Top1 92.105469    Top5 99.492188    LR 0.030000    Time 0.032117    
2018-10-21 07:15:04,726 - Epoch: [142][  250/  391]    Overall Loss 1.542539    Objective Loss 1.542539    Top1 92.162500    Top5 99.475000    LR 0.030000    Time 0.031988    
2018-10-21 07:15:06,369 - Epoch: [142][  300/  391]    Overall Loss 1.542732    Objective Loss 1.542732    Top1 92.145833    Top5 99.492188    LR 0.030000    Time 0.032126    
2018-10-21 07:15:07,958 - Epoch: [142][  350/  391]    Overall Loss 1.543002    Objective Loss 1.543002    Top1 92.133929    Top5 99.482143    LR 0.030000    Time 0.032070    
2018-10-21 07:15:09,382 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27602 | -0.00401 |    0.18348 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09267 | -0.00403 |    0.05344 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09133 |  0.00044 |    0.06092 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07793 | -0.00630 |    0.05145 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07667 | -0.00155 |    0.05035 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09335 | -0.01038 |    0.06346 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08329 | -0.00815 |    0.05891 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09794 | -0.00338 |    0.07237 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08281 | -0.00494 |    0.06268 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20695 | -0.00200 |    0.12848 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06932 | -0.00291 |    0.05195 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06040 | -0.00720 |    0.04709 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07314 | -0.00804 |    0.05600 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05817 | -0.00431 |    0.04493 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07600 | -0.00583 |    0.05993 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06745 | -0.00417 |    0.05316 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09816 | -0.00578 |    0.07496 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06280 | -0.00799 |    0.04915 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04210 | -0.00307 |    0.03200 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03812 | -0.00658 |    0.02928 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02438 |  0.00017 |    0.01646 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41100 | -0.00001 |    0.28386 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:15:09,382 - Total sparsity: 0.00

2018-10-21 07:15:09,382 - --- validate (epoch=142)-----------
2018-10-21 07:15:09,382 - 10000 samples (128 per mini-batch)
2018-10-21 07:15:10,637 - Epoch: [142][   50/   78]    Loss 1.584061    Top1 87.812500    Top5 99.625000    
2018-10-21 07:15:11,290 - ==> Top1: 87.780    Top5: 99.580    Loss: 1.584

2018-10-21 07:15:11,291 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:15:11,292 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:15:11,305 - 

2018-10-21 07:15:11,305 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:15:13,062 - Epoch: [143][   50/  391]    Overall Loss 1.547780    Objective Loss 1.547780    Top1 91.609375    Top5 99.484375    LR 0.030000    Time 0.035092    
2018-10-21 07:15:14,715 - Epoch: [143][  100/  391]    Overall Loss 1.544492    Objective Loss 1.544492    Top1 92.078125    Top5 99.406250    LR 0.030000    Time 0.034051    
2018-10-21 07:15:16,326 - Epoch: [143][  150/  391]    Overall Loss 1.541679    Objective Loss 1.541679    Top1 92.333333    Top5 99.432292    LR 0.030000    Time 0.033424    
2018-10-21 07:15:17,908 - Epoch: [143][  200/  391]    Overall Loss 1.542018    Objective Loss 1.542018    Top1 92.343750    Top5 99.433594    LR 0.030000    Time 0.032968    
2018-10-21 07:15:19,483 - Epoch: [143][  250/  391]    Overall Loss 1.542657    Objective Loss 1.542657    Top1 92.259375    Top5 99.459375    LR 0.030000    Time 0.032667    
2018-10-21 07:15:21,061 - Epoch: [143][  300/  391]    Overall Loss 1.542711    Objective Loss 1.542711    Top1 92.247396    Top5 99.466146    LR 0.030000    Time 0.032474    
2018-10-21 07:15:22,623 - Epoch: [143][  350/  391]    Overall Loss 1.542335    Objective Loss 1.542335    Top1 92.294643    Top5 99.475446    LR 0.030000    Time 0.032292    
2018-10-21 07:15:24,054 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27466 | -0.00110 |    0.18250 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09223 | -0.00347 |    0.05306 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09087 |  0.00045 |    0.06064 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07754 | -0.00603 |    0.05122 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07622 | -0.00138 |    0.04993 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09279 | -0.01082 |    0.06332 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08279 | -0.00821 |    0.05843 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09737 | -0.00307 |    0.07197 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08235 | -0.00490 |    0.06238 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20564 | -0.00133 |    0.12756 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06908 | -0.00292 |    0.05167 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06023 | -0.00719 |    0.04702 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07293 | -0.00785 |    0.05584 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05797 | -0.00433 |    0.04478 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07557 | -0.00584 |    0.05963 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06714 | -0.00412 |    0.05290 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09748 | -0.00578 |    0.07446 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06255 | -0.00809 |    0.04898 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04197 | -0.00305 |    0.03191 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03800 | -0.00651 |    0.02918 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02425 |  0.00023 |    0.01638 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41093 | -0.00001 |    0.28395 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:15:24,054 - Total sparsity: 0.00

2018-10-21 07:15:24,054 - --- validate (epoch=143)-----------
2018-10-21 07:15:24,055 - 10000 samples (128 per mini-batch)
2018-10-21 07:15:25,263 - Epoch: [143][   50/   78]    Loss 1.589512    Top1 87.281250    Top5 99.453125    
2018-10-21 07:15:25,918 - ==> Top1: 87.350    Top5: 99.460    Loss: 1.588

2018-10-21 07:15:25,919 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:15:25,920 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:15:25,932 - 

2018-10-21 07:15:25,932 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:15:27,749 - Epoch: [144][   50/  391]    Overall Loss 1.538992    Objective Loss 1.538992    Top1 92.546875    Top5 99.437500    LR 0.030000    Time 0.036266    
2018-10-21 07:15:29,354 - Epoch: [144][  100/  391]    Overall Loss 1.540416    Objective Loss 1.540416    Top1 92.367188    Top5 99.476562    LR 0.030000    Time 0.034167    
2018-10-21 07:15:31,008 - Epoch: [144][  150/  391]    Overall Loss 1.541933    Objective Loss 1.541933    Top1 92.255208    Top5 99.442708    LR 0.030000    Time 0.033786    
2018-10-21 07:15:32,598 - Epoch: [144][  200/  391]    Overall Loss 1.543387    Objective Loss 1.543387    Top1 92.132812    Top5 99.468750    LR 0.030000    Time 0.033278    
2018-10-21 07:15:34,145 - Epoch: [144][  250/  391]    Overall Loss 1.542750    Objective Loss 1.542750    Top1 92.203125    Top5 99.518750    LR 0.030000    Time 0.032804    
2018-10-21 07:15:35,670 - Epoch: [144][  300/  391]    Overall Loss 1.542499    Objective Loss 1.542499    Top1 92.223958    Top5 99.544271    LR 0.030000    Time 0.032413    
2018-10-21 07:15:37,187 - Epoch: [144][  350/  391]    Overall Loss 1.541815    Objective Loss 1.541815    Top1 92.296875    Top5 99.522321    LR 0.030000    Time 0.032108    
2018-10-21 07:15:38,609 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27293 |  0.00000 |    0.18080 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09168 | -0.00314 |    0.05274 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09033 |  0.00028 |    0.06025 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07713 | -0.00613 |    0.05101 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07576 | -0.00146 |    0.04966 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09227 | -0.01072 |    0.06295 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08231 | -0.00789 |    0.05812 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09679 | -0.00315 |    0.07142 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08190 | -0.00457 |    0.06203 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20429 | -0.00114 |    0.12622 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06882 | -0.00284 |    0.05151 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06004 | -0.00711 |    0.04693 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07271 | -0.00752 |    0.05566 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05780 | -0.00428 |    0.04467 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07516 | -0.00562 |    0.05927 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06683 | -0.00408 |    0.05267 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09681 | -0.00579 |    0.07382 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 | -0.00794 |    0.04886 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04185 | -0.00304 |    0.03181 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03783 | -0.00662 |    0.02907 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02412 |  0.00013 |    0.01631 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41066 | -0.00001 |    0.28386 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:15:38,609 - Total sparsity: 0.00

2018-10-21 07:15:38,609 - --- validate (epoch=144)-----------
2018-10-21 07:15:38,609 - 10000 samples (128 per mini-batch)
2018-10-21 07:15:39,902 - Epoch: [144][   50/   78]    Loss 1.576661    Top1 88.625000    Top5 99.328125    
2018-10-21 07:15:40,566 - ==> Top1: 88.540    Top5: 99.390    Loss: 1.577

2018-10-21 07:15:40,568 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:15:40,568 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:15:40,581 - 

2018-10-21 07:15:40,581 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:15:42,332 - Epoch: [145][   50/  391]    Overall Loss 1.543151    Objective Loss 1.543151    Top1 92.078125    Top5 99.421875    LR 0.030000    Time 0.034953    
2018-10-21 07:15:43,902 - Epoch: [145][  100/  391]    Overall Loss 1.541243    Objective Loss 1.541243    Top1 92.250000    Top5 99.539062    LR 0.030000    Time 0.033152    
2018-10-21 07:15:45,463 - Epoch: [145][  150/  391]    Overall Loss 1.541201    Objective Loss 1.541201    Top1 92.286458    Top5 99.552083    LR 0.030000    Time 0.032491    
2018-10-21 07:15:47,106 - Epoch: [145][  200/  391]    Overall Loss 1.540779    Objective Loss 1.540779    Top1 92.324219    Top5 99.531250    LR 0.030000    Time 0.032574    
2018-10-21 07:15:48,679 - Epoch: [145][  250/  391]    Overall Loss 1.541449    Objective Loss 1.541449    Top1 92.250000    Top5 99.515625    LR 0.030000    Time 0.032341    
2018-10-21 07:15:50,259 - Epoch: [145][  300/  391]    Overall Loss 1.541918    Objective Loss 1.541918    Top1 92.203125    Top5 99.526042    LR 0.030000    Time 0.032211    
2018-10-21 07:15:51,844 - Epoch: [145][  350/  391]    Overall Loss 1.542540    Objective Loss 1.542540    Top1 92.142857    Top5 99.522321    LR 0.030000    Time 0.032131    
2018-10-21 07:15:53,275 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27132 | -0.00363 |    0.17944 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09121 | -0.00335 |    0.05250 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08985 |  0.00073 |    0.06012 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07681 | -0.00566 |    0.05096 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07538 | -0.00106 |    0.04965 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09177 | -0.01094 |    0.06259 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08186 | -0.00778 |    0.05771 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09624 | -0.00332 |    0.07112 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08148 | -0.00439 |    0.06173 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20308 | -0.00176 |    0.12525 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06858 | -0.00263 |    0.05128 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05987 | -0.00701 |    0.04686 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07251 | -0.00770 |    0.05548 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05767 | -0.00416 |    0.04458 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07477 | -0.00571 |    0.05901 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06657 | -0.00407 |    0.05244 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09614 | -0.00591 |    0.07337 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06217 | -0.00792 |    0.04874 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04177 | -0.00305 |    0.03177 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03772 | -0.00656 |    0.02901 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02399 |  0.00010 |    0.01622 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41025 | -0.00001 |    0.28364 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:15:53,276 - Total sparsity: 0.00

2018-10-21 07:15:53,276 - --- validate (epoch=145)-----------
2018-10-21 07:15:53,276 - 10000 samples (128 per mini-batch)
2018-10-21 07:15:54,514 - Epoch: [145][   50/   78]    Loss 1.581273    Top1 88.078125    Top5 99.531250    
2018-10-21 07:15:55,161 - ==> Top1: 88.010    Top5: 99.580    Loss: 1.582

2018-10-21 07:15:55,163 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:15:55,163 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:15:55,176 - 

2018-10-21 07:15:55,176 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:15:56,917 - Epoch: [146][   50/  391]    Overall Loss 1.544071    Objective Loss 1.544071    Top1 92.187500    Top5 99.656250    LR 0.030000    Time 0.034745    
2018-10-21 07:15:58,484 - Epoch: [146][  100/  391]    Overall Loss 1.543643    Objective Loss 1.543643    Top1 92.195312    Top5 99.593750    LR 0.030000    Time 0.033016    
2018-10-21 07:16:00,035 - Epoch: [146][  150/  391]    Overall Loss 1.543209    Objective Loss 1.543209    Top1 92.177083    Top5 99.541667    LR 0.030000    Time 0.032334    
2018-10-21 07:16:01,608 - Epoch: [146][  200/  391]    Overall Loss 1.542762    Objective Loss 1.542762    Top1 92.167969    Top5 99.562500    LR 0.030000    Time 0.032105    
2018-10-21 07:16:03,169 - Epoch: [146][  250/  391]    Overall Loss 1.541744    Objective Loss 1.541744    Top1 92.306250    Top5 99.578125    LR 0.030000    Time 0.031918    
2018-10-21 07:16:04,726 - Epoch: [146][  300/  391]    Overall Loss 1.540807    Objective Loss 1.540807    Top1 92.411458    Top5 99.570312    LR 0.030000    Time 0.031782    
2018-10-21 07:16:06,298 - Epoch: [146][  350/  391]    Overall Loss 1.541090    Objective Loss 1.541090    Top1 92.370536    Top5 99.560268    LR 0.030000    Time 0.031725    
2018-10-21 07:16:07,715 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26986 | -0.00037 |    0.17896 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09076 | -0.00365 |    0.05229 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08941 |  0.00014 |    0.05986 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07641 | -0.00582 |    0.05054 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07498 | -0.00108 |    0.04930 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09128 | -0.01098 |    0.06231 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08132 | -0.00822 |    0.05754 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09570 | -0.00332 |    0.07081 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08102 | -0.00484 |    0.06141 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20182 | -0.00259 |    0.12400 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06830 | -0.00285 |    0.05116 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05967 | -0.00707 |    0.04672 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07230 | -0.00778 |    0.05539 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05751 | -0.00412 |    0.04446 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07439 | -0.00570 |    0.05875 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06632 | -0.00397 |    0.05225 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09550 | -0.00586 |    0.07293 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06198 | -0.00789 |    0.04859 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04168 | -0.00297 |    0.03170 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03760 | -0.00657 |    0.02894 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02386 |  0.00011 |    0.01614 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41016 | -0.00001 |    0.28372 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:16:07,715 - Total sparsity: 0.00

2018-10-21 07:16:07,716 - --- validate (epoch=146)-----------
2018-10-21 07:16:07,716 - 10000 samples (128 per mini-batch)
2018-10-21 07:16:09,070 - Epoch: [146][   50/   78]    Loss 1.580481    Top1 88.171875    Top5 99.500000    
2018-10-21 07:16:09,773 - ==> Top1: 88.470    Top5: 99.490    Loss: 1.578

2018-10-21 07:16:09,774 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:16:09,775 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:16:09,788 - 

2018-10-21 07:16:09,789 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:16:11,508 - Epoch: [147][   50/  391]    Overall Loss 1.538973    Objective Loss 1.538973    Top1 92.531250    Top5 99.546875    LR 0.030000    Time 0.034323    
2018-10-21 07:16:13,092 - Epoch: [147][  100/  391]    Overall Loss 1.541068    Objective Loss 1.541068    Top1 92.289062    Top5 99.492188    LR 0.030000    Time 0.032979    
2018-10-21 07:16:14,673 - Epoch: [147][  150/  391]    Overall Loss 1.541829    Objective Loss 1.541829    Top1 92.213542    Top5 99.531250    LR 0.030000    Time 0.032505    
2018-10-21 07:16:16,244 - Epoch: [147][  200/  391]    Overall Loss 1.541841    Objective Loss 1.541841    Top1 92.250000    Top5 99.488281    LR 0.030000    Time 0.032226    
2018-10-21 07:16:17,794 - Epoch: [147][  250/  391]    Overall Loss 1.541842    Objective Loss 1.541842    Top1 92.290625    Top5 99.503125    LR 0.030000    Time 0.031973    
2018-10-21 07:16:19,353 - Epoch: [147][  300/  391]    Overall Loss 1.542512    Objective Loss 1.542512    Top1 92.231771    Top5 99.500000    LR 0.030000    Time 0.031833    
2018-10-21 07:16:20,920 - Epoch: [147][  350/  391]    Overall Loss 1.542497    Objective Loss 1.542497    Top1 92.207589    Top5 99.506696    LR 0.030000    Time 0.031757    
2018-10-21 07:16:22,337 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26833 | -0.00133 |    0.17740 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09040 | -0.00331 |    0.05193 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08899 |  0.00053 |    0.05968 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07607 | -0.00597 |    0.05049 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07462 | -0.00129 |    0.04904 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09083 | -0.01089 |    0.06206 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08087 | -0.00805 |    0.05704 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09522 | -0.00325 |    0.07053 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08064 | -0.00429 |    0.06114 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20060 | -0.00162 |    0.12416 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06807 | -0.00278 |    0.05102 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05951 | -0.00693 |    0.04658 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07215 | -0.00750 |    0.05529 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05733 | -0.00432 |    0.04437 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07403 | -0.00562 |    0.05841 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06606 | -0.00406 |    0.05203 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09484 | -0.00579 |    0.07243 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06182 | -0.00777 |    0.04847 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04160 | -0.00291 |    0.03166 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03747 | -0.00662 |    0.02886 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02374 |  0.00006 |    0.01607 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40975 | -0.00001 |    0.28354 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:16:22,337 - Total sparsity: 0.00

2018-10-21 07:16:22,338 - --- validate (epoch=147)-----------
2018-10-21 07:16:22,338 - 10000 samples (128 per mini-batch)
2018-10-21 07:16:23,572 - Epoch: [147][   50/   78]    Loss 1.585485    Top1 87.734375    Top5 99.515625    
2018-10-21 07:16:24,213 - ==> Top1: 87.470    Top5: 99.490    Loss: 1.587

2018-10-21 07:16:24,215 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:16:24,216 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:16:24,229 - 

2018-10-21 07:16:24,229 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:16:25,976 - Epoch: [148][   50/  391]    Overall Loss 1.540329    Objective Loss 1.540329    Top1 92.484375    Top5 99.453125    LR 0.030000    Time 0.034870    
2018-10-21 07:16:27,560 - Epoch: [148][  100/  391]    Overall Loss 1.539020    Objective Loss 1.539020    Top1 92.585938    Top5 99.476562    LR 0.030000    Time 0.033247    
2018-10-21 07:16:29,131 - Epoch: [148][  150/  391]    Overall Loss 1.538558    Objective Loss 1.538558    Top1 92.619792    Top5 99.500000    LR 0.030000    Time 0.032629    
2018-10-21 07:16:30,715 - Epoch: [148][  200/  391]    Overall Loss 1.539112    Objective Loss 1.539112    Top1 92.546875    Top5 99.488281    LR 0.030000    Time 0.032380    
2018-10-21 07:16:32,284 - Epoch: [148][  250/  391]    Overall Loss 1.538657    Objective Loss 1.538657    Top1 92.534375    Top5 99.509375    LR 0.030000    Time 0.032168    
2018-10-21 07:16:33,856 - Epoch: [148][  300/  391]    Overall Loss 1.539565    Objective Loss 1.539565    Top1 92.442708    Top5 99.523438    LR 0.030000    Time 0.032041    
2018-10-21 07:16:35,406 - Epoch: [148][  350/  391]    Overall Loss 1.540086    Objective Loss 1.540086    Top1 92.392857    Top5 99.517857    LR 0.030000    Time 0.031885    
2018-10-21 07:16:36,826 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26700 | -0.00329 |    0.17704 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08999 | -0.00333 |    0.05170 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08857 |  0.00097 |    0.05944 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07573 | -0.00598 |    0.05032 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07429 | -0.00099 |    0.04882 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09036 | -0.01078 |    0.06160 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08045 | -0.00810 |    0.05681 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09478 | -0.00279 |    0.07014 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08025 | -0.00429 |    0.06084 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19942 | -0.00135 |    0.12357 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06788 | -0.00281 |    0.05091 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05937 | -0.00686 |    0.04649 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07200 | -0.00722 |    0.05511 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05717 | -0.00436 |    0.04426 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07367 | -0.00572 |    0.05815 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06582 | -0.00388 |    0.05185 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09421 | -0.00578 |    0.07201 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06162 | -0.00791 |    0.04837 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04152 | -0.00293 |    0.03162 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03736 | -0.00667 |    0.02880 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02362 |  0.00000 |    0.01599 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40944 | -0.00001 |    0.28337 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:16:36,826 - Total sparsity: 0.00

2018-10-21 07:16:36,826 - --- validate (epoch=148)-----------
2018-10-21 07:16:36,827 - 10000 samples (128 per mini-batch)
2018-10-21 07:16:38,046 - Epoch: [148][   50/   78]    Loss 1.578933    Top1 88.515625    Top5 99.406250    
2018-10-21 07:16:38,687 - ==> Top1: 88.400    Top5: 99.460    Loss: 1.579

2018-10-21 07:16:38,688 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:16:38,689 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:16:38,702 - 

2018-10-21 07:16:38,702 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:16:40,443 - Epoch: [149][   50/  391]    Overall Loss 1.536841    Objective Loss 1.536841    Top1 92.843750    Top5 99.500000    LR 0.030000    Time 0.034757    
2018-10-21 07:16:42,016 - Epoch: [149][  100/  391]    Overall Loss 1.537925    Objective Loss 1.537925    Top1 92.671875    Top5 99.515625    LR 0.030000    Time 0.033089    
2018-10-21 07:16:43,602 - Epoch: [149][  150/  391]    Overall Loss 1.539454    Objective Loss 1.539454    Top1 92.489583    Top5 99.473958    LR 0.030000    Time 0.032618    
2018-10-21 07:16:45,180 - Epoch: [149][  200/  391]    Overall Loss 1.539969    Objective Loss 1.539969    Top1 92.472656    Top5 99.476562    LR 0.030000    Time 0.032341    
2018-10-21 07:16:46,738 - Epoch: [149][  250/  391]    Overall Loss 1.542290    Objective Loss 1.542290    Top1 92.206250    Top5 99.496875    LR 0.030000    Time 0.032097    
2018-10-21 07:16:48,333 - Epoch: [149][  300/  391]    Overall Loss 1.542098    Objective Loss 1.542098    Top1 92.210938    Top5 99.539062    LR 0.030000    Time 0.032055    
2018-10-21 07:16:49,945 - Epoch: [149][  350/  391]    Overall Loss 1.542205    Objective Loss 1.542205    Top1 92.194196    Top5 99.531250    LR 0.030000    Time 0.032074    
2018-10-21 07:16:51,368 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26555 | -0.00142 |    0.17646 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08964 | -0.00354 |    0.05150 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08818 |  0.00087 |    0.05928 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07546 | -0.00604 |    0.05015 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07399 | -0.00098 |    0.04876 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08998 | -0.01011 |    0.06156 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08001 | -0.00820 |    0.05655 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09432 | -0.00292 |    0.06975 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07985 | -0.00447 |    0.06064 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19829 | -0.00021 |    0.12278 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06767 | -0.00284 |    0.05075 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05918 | -0.00703 |    0.04637 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07185 | -0.00722 |    0.05488 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05705 | -0.00431 |    0.04414 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07332 | -0.00568 |    0.05789 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06557 | -0.00395 |    0.05166 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09360 | -0.00567 |    0.07161 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06144 | -0.00797 |    0.04825 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04144 | -0.00295 |    0.03157 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03727 | -0.00665 |    0.02875 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02352 |  0.00001 |    0.01592 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40917 | -0.00001 |    0.28320 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:16:51,368 - Total sparsity: 0.00

2018-10-21 07:16:51,368 - --- validate (epoch=149)-----------
2018-10-21 07:16:51,369 - 10000 samples (128 per mini-batch)
2018-10-21 07:16:52,591 - Epoch: [149][   50/   78]    Loss 1.583646    Top1 87.781250    Top5 99.390625    
2018-10-21 07:16:53,222 - ==> Top1: 87.870    Top5: 99.430    Loss: 1.582

2018-10-21 07:16:53,224 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:16:53,224 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:16:53,238 - 

2018-10-21 07:16:53,238 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:16:55,039 - Epoch: [150][   50/  391]    Overall Loss 1.536150    Objective Loss 1.536150    Top1 92.750000    Top5 99.531250    LR 0.030000    Time 0.035952    
2018-10-21 07:16:56,685 - Epoch: [150][  100/  391]    Overall Loss 1.539826    Objective Loss 1.539826    Top1 92.468750    Top5 99.484375    LR 0.030000    Time 0.034412    
2018-10-21 07:16:58,295 - Epoch: [150][  150/  391]    Overall Loss 1.539121    Objective Loss 1.539121    Top1 92.578125    Top5 99.484375    LR 0.030000    Time 0.033662    
2018-10-21 07:16:59,893 - Epoch: [150][  200/  391]    Overall Loss 1.540116    Objective Loss 1.540116    Top1 92.457031    Top5 99.480469    LR 0.030000    Time 0.033227    
2018-10-21 07:17:01,490 - Epoch: [150][  250/  391]    Overall Loss 1.539500    Objective Loss 1.539500    Top1 92.518750    Top5 99.503125    LR 0.030000    Time 0.032962    
2018-10-21 07:17:03,074 - Epoch: [150][  300/  391]    Overall Loss 1.540302    Objective Loss 1.540302    Top1 92.445312    Top5 99.497396    LR 0.030000    Time 0.032740    
2018-10-21 07:17:04,658 - Epoch: [150][  350/  391]    Overall Loss 1.540598    Objective Loss 1.540598    Top1 92.410714    Top5 99.500000    LR 0.030000    Time 0.032582    
2018-10-21 07:17:06,084 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26411 | -0.00199 |    0.17516 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08925 | -0.00315 |    0.05139 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08773 |  0.00119 |    0.05899 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07515 | -0.00603 |    0.05017 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07366 | -0.00086 |    0.04841 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08957 | -0.01029 |    0.06153 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07964 | -0.00795 |    0.05615 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09386 | -0.00318 |    0.06958 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07950 | -0.00433 |    0.06027 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19720 | -0.00008 |    0.12145 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06746 | -0.00285 |    0.05056 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05904 | -0.00692 |    0.04620 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07168 | -0.00732 |    0.05480 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05694 | -0.00409 |    0.04406 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07300 | -0.00559 |    0.05758 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06534 | -0.00409 |    0.05151 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09305 | -0.00545 |    0.07113 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06131 | -0.00783 |    0.04813 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04139 | -0.00303 |    0.03155 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03721 | -0.00657 |    0.02870 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02341 | -0.00000 |    0.01585 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40887 | -0.00001 |    0.28301 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:17:06,084 - Total sparsity: 0.00

2018-10-21 07:17:06,084 - --- validate (epoch=150)-----------
2018-10-21 07:17:06,085 - 10000 samples (128 per mini-batch)
2018-10-21 07:17:07,304 - Epoch: [150][   50/   78]    Loss 1.582816    Top1 87.906250    Top5 99.468750    
2018-10-21 07:17:07,953 - ==> Top1: 87.830    Top5: 99.450    Loss: 1.583

2018-10-21 07:17:07,955 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:17:07,955 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:17:07,968 - 

2018-10-21 07:17:07,968 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:17:09,739 - Epoch: [151][   50/  391]    Overall Loss 1.537711    Objective Loss 1.537711    Top1 92.765625    Top5 99.453125    LR 0.030000    Time 0.035348    
2018-10-21 07:17:11,355 - Epoch: [151][  100/  391]    Overall Loss 1.539335    Objective Loss 1.539335    Top1 92.609375    Top5 99.476562    LR 0.030000    Time 0.033812    
2018-10-21 07:17:12,964 - Epoch: [151][  150/  391]    Overall Loss 1.538998    Objective Loss 1.538998    Top1 92.598958    Top5 99.510417    LR 0.030000    Time 0.033255    
2018-10-21 07:17:14,558 - Epoch: [151][  200/  391]    Overall Loss 1.538659    Objective Loss 1.538659    Top1 92.621094    Top5 99.496094    LR 0.030000    Time 0.032899    
2018-10-21 07:17:16,131 - Epoch: [151][  250/  391]    Overall Loss 1.540302    Objective Loss 1.540302    Top1 92.446875    Top5 99.490625    LR 0.030000    Time 0.032601    
2018-10-21 07:17:17,727 - Epoch: [151][  300/  391]    Overall Loss 1.541061    Objective Loss 1.541061    Top1 92.372396    Top5 99.507812    LR 0.030000    Time 0.032480    
2018-10-21 07:17:19,313 - Epoch: [151][  350/  391]    Overall Loss 1.541365    Objective Loss 1.541365    Top1 92.345982    Top5 99.520089    LR 0.030000    Time 0.032366    
2018-10-21 07:17:20,745 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26286 | -0.00288 |    0.17446 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08890 | -0.00297 |    0.05108 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08735 |  0.00080 |    0.05863 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07486 | -0.00596 |    0.04997 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07334 | -0.00079 |    0.04818 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08926 | -0.00963 |    0.06116 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07924 | -0.00805 |    0.05606 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09345 | -0.00325 |    0.06926 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07915 | -0.00455 |    0.06008 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19612 | -0.00078 |    0.12165 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06726 | -0.00285 |    0.05042 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05887 | -0.00702 |    0.04611 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07152 | -0.00743 |    0.05462 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05683 | -0.00406 |    0.04403 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07265 | -0.00592 |    0.05735 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06512 | -0.00411 |    0.05135 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09248 | -0.00548 |    0.07060 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06115 | -0.00790 |    0.04806 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04135 | -0.00288 |    0.03156 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03714 | -0.00652 |    0.02864 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02332 |  0.00005 |    0.01580 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40878 | -0.00001 |    0.28311 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:17:20,745 - Total sparsity: 0.00

2018-10-21 07:17:20,746 - --- validate (epoch=151)-----------
2018-10-21 07:17:20,746 - 10000 samples (128 per mini-batch)
2018-10-21 07:17:21,986 - Epoch: [151][   50/   78]    Loss 1.579125    Top1 88.375000    Top5 99.375000    
2018-10-21 07:17:22,629 - ==> Top1: 88.370    Top5: 99.430    Loss: 1.578

2018-10-21 07:17:22,630 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:17:22,631 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:17:22,644 - 

2018-10-21 07:17:22,645 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:17:24,442 - Epoch: [152][   50/  391]    Overall Loss 1.541308    Objective Loss 1.541308    Top1 92.078125    Top5 99.515625    LR 0.030000    Time 0.035892    
2018-10-21 07:17:26,078 - Epoch: [152][  100/  391]    Overall Loss 1.539759    Objective Loss 1.539759    Top1 92.289062    Top5 99.539062    LR 0.030000    Time 0.034272    
2018-10-21 07:17:27,709 - Epoch: [152][  150/  391]    Overall Loss 1.541866    Objective Loss 1.541866    Top1 92.125000    Top5 99.520833    LR 0.030000    Time 0.033709    
2018-10-21 07:17:29,271 - Epoch: [152][  200/  391]    Overall Loss 1.541009    Objective Loss 1.541009    Top1 92.253906    Top5 99.542969    LR 0.030000    Time 0.033079    
2018-10-21 07:17:30,841 - Epoch: [152][  250/  391]    Overall Loss 1.542516    Objective Loss 1.542516    Top1 92.140625    Top5 99.543750    LR 0.030000    Time 0.032738    
2018-10-21 07:17:32,438 - Epoch: [152][  300/  391]    Overall Loss 1.542169    Objective Loss 1.542169    Top1 92.205729    Top5 99.541667    LR 0.030000    Time 0.032598    
2018-10-21 07:17:34,009 - Epoch: [152][  350/  391]    Overall Loss 1.542118    Objective Loss 1.542118    Top1 92.216518    Top5 99.553571    LR 0.030000    Time 0.032423    
2018-10-21 07:17:35,420 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26183 | -0.00199 |    0.17445 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08855 | -0.00324 |    0.05093 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08701 |  0.00102 |    0.05829 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07461 | -0.00583 |    0.04967 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07301 | -0.00082 |    0.04793 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08885 | -0.01027 |    0.06102 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07890 | -0.00802 |    0.05575 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09305 | -0.00344 |    0.06891 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07886 | -0.00399 |    0.05983 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19513 | -0.00068 |    0.12004 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06710 | -0.00265 |    0.05034 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05875 | -0.00693 |    0.04595 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07146 | -0.00708 |    0.05458 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05676 | -0.00400 |    0.04396 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07236 | -0.00571 |    0.05713 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06492 | -0.00409 |    0.05117 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09199 | -0.00521 |    0.07025 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06103 | -0.00783 |    0.04796 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04131 | -0.00286 |    0.03153 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03709 | -0.00644 |    0.02858 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02322 |  0.00002 |    0.01572 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40844 | -0.00001 |    0.28301 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:17:35,421 - Total sparsity: 0.00

2018-10-21 07:17:35,421 - --- validate (epoch=152)-----------
2018-10-21 07:17:35,421 - 10000 samples (128 per mini-batch)
2018-10-21 07:17:36,629 - Epoch: [152][   50/   78]    Loss 1.593478    Top1 86.718750    Top5 99.031250    
2018-10-21 07:17:37,273 - ==> Top1: 86.790    Top5: 99.180    Loss: 1.595

2018-10-21 07:17:37,275 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:17:37,275 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:17:37,288 - 

2018-10-21 07:17:37,288 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:17:39,161 - Epoch: [153][   50/  391]    Overall Loss 1.541027    Objective Loss 1.541027    Top1 92.312500    Top5 99.484375    LR 0.030000    Time 0.037387    
2018-10-21 07:17:40,724 - Epoch: [153][  100/  391]    Overall Loss 1.542616    Objective Loss 1.542616    Top1 92.132812    Top5 99.500000    LR 0.030000    Time 0.034289    
2018-10-21 07:17:42,399 - Epoch: [153][  150/  391]    Overall Loss 1.541243    Objective Loss 1.541243    Top1 92.270833    Top5 99.552083    LR 0.030000    Time 0.034011    
2018-10-21 07:17:44,163 - Epoch: [153][  200/  391]    Overall Loss 1.539274    Objective Loss 1.539274    Top1 92.468750    Top5 99.539062    LR 0.030000    Time 0.034319    
2018-10-21 07:17:45,939 - Epoch: [153][  250/  391]    Overall Loss 1.539034    Objective Loss 1.539034    Top1 92.506250    Top5 99.518750    LR 0.030000    Time 0.034549    
2018-10-21 07:17:47,688 - Epoch: [153][  300/  391]    Overall Loss 1.539726    Objective Loss 1.539726    Top1 92.442708    Top5 99.497396    LR 0.030000    Time 0.034612    
2018-10-21 07:17:49,245 - Epoch: [153][  350/  391]    Overall Loss 1.539801    Objective Loss 1.539801    Top1 92.457589    Top5 99.511161    LR 0.030000    Time 0.034111    
2018-10-21 07:17:50,639 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26067 | -0.00202 |    0.17356 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08816 | -0.00313 |    0.05062 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08669 |  0.00090 |    0.05812 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07429 | -0.00645 |    0.04936 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07268 | -0.00118 |    0.04779 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08853 | -0.01051 |    0.06105 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07856 | -0.00799 |    0.05548 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09261 | -0.00368 |    0.06858 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07851 | -0.00410 |    0.05954 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19406 | -0.00112 |    0.11920 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06695 | -0.00294 |    0.05019 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05866 | -0.00674 |    0.04582 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07134 | -0.00703 |    0.05450 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05664 | -0.00420 |    0.04392 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07206 | -0.00570 |    0.05695 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06474 | -0.00412 |    0.05102 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09150 | -0.00522 |    0.06975 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06093 | -0.00774 |    0.04785 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04128 | -0.00285 |    0.03152 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03701 | -0.00651 |    0.02855 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02313 |  0.00004 |    0.01568 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40834 | -0.00001 |    0.28314 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:17:50,640 - Total sparsity: 0.00

2018-10-21 07:17:50,640 - --- validate (epoch=153)-----------
2018-10-21 07:17:50,640 - 10000 samples (128 per mini-batch)
2018-10-21 07:17:51,902 - Epoch: [153][   50/   78]    Loss 1.578726    Top1 88.140625    Top5 99.421875    
2018-10-21 07:17:52,570 - ==> Top1: 88.170    Top5: 99.470    Loss: 1.579

2018-10-21 07:17:52,571 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:17:52,571 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:17:52,584 - 

2018-10-21 07:17:52,585 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:17:54,513 - Epoch: [154][   50/  391]    Overall Loss 1.537553    Objective Loss 1.537553    Top1 92.781250    Top5 99.484375    LR 0.030000    Time 0.038502    
2018-10-21 07:17:56,295 - Epoch: [154][  100/  391]    Overall Loss 1.539023    Objective Loss 1.539023    Top1 92.585938    Top5 99.531250    LR 0.030000    Time 0.037048    
2018-10-21 07:17:58,067 - Epoch: [154][  150/  391]    Overall Loss 1.540161    Objective Loss 1.540161    Top1 92.463542    Top5 99.536458    LR 0.030000    Time 0.036497    
2018-10-21 07:17:59,845 - Epoch: [154][  200/  391]    Overall Loss 1.540013    Objective Loss 1.540013    Top1 92.460938    Top5 99.507812    LR 0.030000    Time 0.036247    
2018-10-21 07:18:01,586 - Epoch: [154][  250/  391]    Overall Loss 1.540918    Objective Loss 1.540918    Top1 92.359375    Top5 99.496875    LR 0.030000    Time 0.035952    
2018-10-21 07:18:03,218 - Epoch: [154][  300/  391]    Overall Loss 1.540980    Objective Loss 1.540980    Top1 92.377604    Top5 99.486979    LR 0.030000    Time 0.035393    
2018-10-21 07:18:04,756 - Epoch: [154][  350/  391]    Overall Loss 1.541701    Objective Loss 1.541701    Top1 92.296875    Top5 99.479911    LR 0.030000    Time 0.034726    
2018-10-21 07:18:06,205 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25974 | -0.00118 |    0.17325 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08785 | -0.00306 |    0.05068 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08639 |  0.00098 |    0.05780 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07406 | -0.00609 |    0.04926 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07238 | -0.00124 |    0.04764 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08826 | -0.01072 |    0.06096 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07829 | -0.00761 |    0.05527 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09225 | -0.00371 |    0.06842 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07823 | -0.00424 |    0.05936 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19313 | -0.00116 |    0.11878 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06693 | -0.00256 |    0.05015 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05860 | -0.00676 |    0.04583 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07126 | -0.00694 |    0.05442 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05659 | -0.00401 |    0.04389 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07181 | -0.00562 |    0.05682 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06458 | -0.00409 |    0.05094 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09106 | -0.00515 |    0.06942 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06083 | -0.00779 |    0.04781 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04123 | -0.00293 |    0.03149 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03693 | -0.00659 |    0.02853 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02304 |  0.00001 |    0.01562 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40830 | -0.00001 |    0.28319 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:18:06,205 - Total sparsity: 0.00

2018-10-21 07:18:06,205 - --- validate (epoch=154)-----------
2018-10-21 07:18:06,206 - 10000 samples (128 per mini-batch)
2018-10-21 07:18:07,431 - Epoch: [154][   50/   78]    Loss 1.588028    Top1 87.281250    Top5 99.265625    
2018-10-21 07:18:08,078 - ==> Top1: 87.310    Top5: 99.300    Loss: 1.589

2018-10-21 07:18:08,080 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:18:08,081 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:18:08,095 - 

2018-10-21 07:18:08,095 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:18:10,068 - Epoch: [155][   50/  391]    Overall Loss 1.542968    Objective Loss 1.542968    Top1 92.343750    Top5 99.500000    LR 0.030000    Time 0.039401    
2018-10-21 07:18:11,696 - Epoch: [155][  100/  391]    Overall Loss 1.540954    Objective Loss 1.540954    Top1 92.507812    Top5 99.562500    LR 0.030000    Time 0.035949    
2018-10-21 07:18:13,283 - Epoch: [155][  150/  391]    Overall Loss 1.541789    Objective Loss 1.541789    Top1 92.364583    Top5 99.541667    LR 0.030000    Time 0.034536    
2018-10-21 07:18:14,849 - Epoch: [155][  200/  391]    Overall Loss 1.543372    Objective Loss 1.543372    Top1 92.156250    Top5 99.539062    LR 0.030000    Time 0.033718    
2018-10-21 07:18:16,434 - Epoch: [155][  250/  391]    Overall Loss 1.542289    Objective Loss 1.542289    Top1 92.234375    Top5 99.559375    LR 0.030000    Time 0.033308    
2018-10-21 07:18:17,968 - Epoch: [155][  300/  391]    Overall Loss 1.542336    Objective Loss 1.542336    Top1 92.229167    Top5 99.559896    LR 0.030000    Time 0.032863    
2018-10-21 07:18:19,522 - Epoch: [155][  350/  391]    Overall Loss 1.542405    Objective Loss 1.542405    Top1 92.229911    Top5 99.555804    LR 0.030000    Time 0.032600    
2018-10-21 07:18:20,942 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25884 | -0.00323 |    0.17264 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08759 | -0.00299 |    0.05051 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08613 |  0.00072 |    0.05768 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07382 | -0.00639 |    0.04938 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07208 | -0.00148 |    0.04745 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08798 | -0.01025 |    0.06075 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07797 | -0.00793 |    0.05495 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09190 | -0.00291 |    0.06804 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07793 | -0.00436 |    0.05913 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19224 | -0.00092 |    0.11802 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06682 | -0.00296 |    0.05020 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05853 | -0.00678 |    0.04577 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07116 | -0.00684 |    0.05435 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05649 | -0.00433 |    0.04378 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07156 | -0.00568 |    0.05657 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06443 | -0.00390 |    0.05084 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09061 | -0.00491 |    0.06909 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06074 | -0.00777 |    0.04775 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04121 | -0.00285 |    0.03149 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03688 | -0.00655 |    0.02847 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02295 |  0.00005 |    0.01555 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40809 | -0.00001 |    0.28314 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:18:20,943 - Total sparsity: 0.00

2018-10-21 07:18:20,943 - --- validate (epoch=155)-----------
2018-10-21 07:18:20,943 - 10000 samples (128 per mini-batch)
2018-10-21 07:18:22,155 - Epoch: [155][   50/   78]    Loss 1.578296    Top1 88.187500    Top5 99.468750    
2018-10-21 07:18:22,802 - ==> Top1: 88.560    Top5: 99.520    Loss: 1.576

2018-10-21 07:18:22,804 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:18:22,804 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:18:22,817 - 

2018-10-21 07:18:22,817 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:18:24,596 - Epoch: [156][   50/  391]    Overall Loss 1.537651    Objective Loss 1.537651    Top1 92.781250    Top5 99.437500    LR 0.030000    Time 0.035499    
2018-10-21 07:18:26,165 - Epoch: [156][  100/  391]    Overall Loss 1.539175    Objective Loss 1.539175    Top1 92.601562    Top5 99.554688    LR 0.030000    Time 0.033416    
2018-10-21 07:18:27,730 - Epoch: [156][  150/  391]    Overall Loss 1.537765    Objective Loss 1.537765    Top1 92.729167    Top5 99.598958    LR 0.030000    Time 0.032697    
2018-10-21 07:18:29,364 - Epoch: [156][  200/  391]    Overall Loss 1.538486    Objective Loss 1.538486    Top1 92.625000    Top5 99.554688    LR 0.030000    Time 0.032682    
2018-10-21 07:18:30,907 - Epoch: [156][  250/  391]    Overall Loss 1.539611    Objective Loss 1.539611    Top1 92.528125    Top5 99.559375    LR 0.030000    Time 0.032307    
2018-10-21 07:18:32,416 - Epoch: [156][  300/  391]    Overall Loss 1.539501    Objective Loss 1.539501    Top1 92.539062    Top5 99.572917    LR 0.030000    Time 0.031946    
2018-10-21 07:18:33,965 - Epoch: [156][  350/  391]    Overall Loss 1.540549    Objective Loss 1.540549    Top1 92.426339    Top5 99.566964    LR 0.030000    Time 0.031801    
2018-10-21 07:18:35,340 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25773 | -0.00209 |    0.17172 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08726 | -0.00367 |    0.05026 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08583 |  0.00068 |    0.05747 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07354 | -0.00657 |    0.04917 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07178 | -0.00142 |    0.04721 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08770 | -0.01025 |    0.06033 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07765 | -0.00811 |    0.05466 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09150 | -0.00292 |    0.06778 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07763 | -0.00429 |    0.05891 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19136 | -0.00077 |    0.11855 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06668 | -0.00317 |    0.05014 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05845 | -0.00671 |    0.04567 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07098 | -0.00715 |    0.05425 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05638 | -0.00421 |    0.04366 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07131 | -0.00558 |    0.05637 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06426 | -0.00400 |    0.05073 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09016 | -0.00509 |    0.06865 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06064 | -0.00771 |    0.04769 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04117 | -0.00292 |    0.03147 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03682 | -0.00653 |    0.02845 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02286 |  0.00008 |    0.01548 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40797 | -0.00001 |    0.28320 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:18:35,341 - Total sparsity: 0.00

2018-10-21 07:18:35,341 - --- validate (epoch=156)-----------
2018-10-21 07:18:35,341 - 10000 samples (128 per mini-batch)
2018-10-21 07:18:36,576 - Epoch: [156][   50/   78]    Loss 1.575252    Top1 88.687500    Top5 99.359375    
2018-10-21 07:18:37,221 - ==> Top1: 88.830    Top5: 99.440    Loss: 1.574

2018-10-21 07:18:37,222 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:18:37,223 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:18:37,238 - 

2018-10-21 07:18:37,239 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:18:39,030 - Epoch: [157][   50/  391]    Overall Loss 1.532274    Objective Loss 1.532274    Top1 93.187500    Top5 99.562500    LR 0.030000    Time 0.035774    
2018-10-21 07:18:40,645 - Epoch: [157][  100/  391]    Overall Loss 1.535967    Objective Loss 1.535967    Top1 92.890625    Top5 99.578125    LR 0.030000    Time 0.034004    
2018-10-21 07:18:42,239 - Epoch: [157][  150/  391]    Overall Loss 1.537349    Objective Loss 1.537349    Top1 92.744792    Top5 99.546875    LR 0.030000    Time 0.033279    
2018-10-21 07:18:43,807 - Epoch: [157][  200/  391]    Overall Loss 1.538349    Objective Loss 1.538349    Top1 92.675781    Top5 99.542969    LR 0.030000    Time 0.032793    
2018-10-21 07:18:45,342 - Epoch: [157][  250/  391]    Overall Loss 1.538693    Objective Loss 1.538693    Top1 92.596875    Top5 99.556250    LR 0.030000    Time 0.032366    
2018-10-21 07:18:46,979 - Epoch: [157][  300/  391]    Overall Loss 1.540162    Objective Loss 1.540162    Top1 92.442708    Top5 99.539062    LR 0.030000    Time 0.032419    
2018-10-21 07:18:48,570 - Epoch: [157][  350/  391]    Overall Loss 1.539735    Objective Loss 1.539735    Top1 92.493304    Top5 99.566964    LR 0.030000    Time 0.032327    
2018-10-21 07:18:50,012 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25668 | -0.00025 |    0.17041 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08695 | -0.00413 |    0.05019 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08554 |  0.00123 |    0.05719 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07327 | -0.00677 |    0.04909 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07148 | -0.00136 |    0.04702 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08733 | -0.01075 |    0.06025 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07740 | -0.00756 |    0.05452 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09111 | -0.00319 |    0.06753 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07736 | -0.00380 |    0.05872 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19050 | -0.00079 |    0.11770 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06658 | -0.00301 |    0.05009 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05834 | -0.00685 |    0.04563 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07085 | -0.00714 |    0.05415 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05627 | -0.00432 |    0.04366 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07107 | -0.00541 |    0.05621 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06409 | -0.00408 |    0.05061 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08976 | -0.00481 |    0.06826 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06054 | -0.00761 |    0.04761 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04115 | -0.00291 |    0.03146 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03678 | -0.00653 |    0.02840 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02278 |  0.00006 |    0.01544 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40784 | -0.00001 |    0.28323 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:18:50,012 - Total sparsity: 0.00

2018-10-21 07:18:50,012 - --- validate (epoch=157)-----------
2018-10-21 07:18:50,013 - 10000 samples (128 per mini-batch)
2018-10-21 07:18:51,238 - Epoch: [157][   50/   78]    Loss 1.578683    Top1 88.375000    Top5 99.406250    
2018-10-21 07:18:51,882 - ==> Top1: 88.440    Top5: 99.460    Loss: 1.578

2018-10-21 07:18:51,884 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:18:51,885 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:18:51,898 - 

2018-10-21 07:18:51,898 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:18:53,671 - Epoch: [158][   50/  391]    Overall Loss 1.538492    Objective Loss 1.538492    Top1 92.703125    Top5 99.468750    LR 0.030000    Time 0.035398    
2018-10-21 07:18:55,266 - Epoch: [158][  100/  391]    Overall Loss 1.538637    Objective Loss 1.538637    Top1 92.625000    Top5 99.515625    LR 0.030000    Time 0.033631    
2018-10-21 07:18:56,859 - Epoch: [158][  150/  391]    Overall Loss 1.538952    Objective Loss 1.538952    Top1 92.583333    Top5 99.536458    LR 0.030000    Time 0.033027    
2018-10-21 07:18:58,448 - Epoch: [158][  200/  391]    Overall Loss 1.539766    Objective Loss 1.539766    Top1 92.503906    Top5 99.539062    LR 0.030000    Time 0.032704    
2018-10-21 07:19:00,047 - Epoch: [158][  250/  391]    Overall Loss 1.540109    Objective Loss 1.540109    Top1 92.418750    Top5 99.531250    LR 0.030000    Time 0.032551    
2018-10-21 07:19:01,668 - Epoch: [158][  300/  391]    Overall Loss 1.539862    Objective Loss 1.539862    Top1 92.450521    Top5 99.536458    LR 0.030000    Time 0.032523    
2018-10-21 07:19:03,278 - Epoch: [158][  350/  391]    Overall Loss 1.539486    Objective Loss 1.539486    Top1 92.488839    Top5 99.546875    LR 0.030000    Time 0.032468    
2018-10-21 07:19:04,721 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25574 | -0.00429 |    0.17029 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08670 | -0.00424 |    0.05004 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08525 |  0.00145 |    0.05713 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07308 | -0.00650 |    0.04913 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07122 | -0.00179 |    0.04699 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08713 | -0.01018 |    0.06002 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07716 | -0.00734 |    0.05440 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09078 | -0.00317 |    0.06732 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07708 | -0.00417 |    0.05857 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18976 | -0.00028 |    0.11667 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06652 | -0.00297 |    0.05002 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05828 | -0.00693 |    0.04560 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07082 | -0.00681 |    0.05408 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05622 | -0.00422 |    0.04372 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07083 | -0.00548 |    0.05600 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06394 | -0.00406 |    0.05048 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08934 | -0.00487 |    0.06812 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06043 | -0.00766 |    0.04756 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04114 | -0.00290 |    0.03147 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03673 | -0.00653 |    0.02838 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02270 |  0.00012 |    0.01538 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40769 | -0.00001 |    0.28322 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:19:04,721 - Total sparsity: 0.00

2018-10-21 07:19:04,722 - --- validate (epoch=158)-----------
2018-10-21 07:19:04,722 - 10000 samples (128 per mini-batch)
2018-10-21 07:19:05,945 - Epoch: [158][   50/   78]    Loss 1.578565    Top1 88.281250    Top5 99.468750    
2018-10-21 07:19:06,601 - ==> Top1: 88.520    Top5: 99.510    Loss: 1.577

2018-10-21 07:19:06,602 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:19:06,602 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:19:06,615 - 

2018-10-21 07:19:06,616 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:19:08,323 - Epoch: [159][   50/  391]    Overall Loss 1.537085    Objective Loss 1.537085    Top1 92.578125    Top5 99.640625    LR 0.030000    Time 0.034093    
2018-10-21 07:19:09,878 - Epoch: [159][  100/  391]    Overall Loss 1.537544    Objective Loss 1.537544    Top1 92.578125    Top5 99.546875    LR 0.030000    Time 0.032568    
2018-10-21 07:19:11,448 - Epoch: [159][  150/  391]    Overall Loss 1.537036    Objective Loss 1.537036    Top1 92.729167    Top5 99.557292    LR 0.030000    Time 0.032163    
2018-10-21 07:19:13,007 - Epoch: [159][  200/  391]    Overall Loss 1.538712    Objective Loss 1.538712    Top1 92.539062    Top5 99.546875    LR 0.030000    Time 0.031907    
2018-10-21 07:19:14,542 - Epoch: [159][  250/  391]    Overall Loss 1.538431    Objective Loss 1.538431    Top1 92.578125    Top5 99.540625    LR 0.030000    Time 0.031657    
2018-10-21 07:19:16,075 - Epoch: [159][  300/  391]    Overall Loss 1.538109    Objective Loss 1.538109    Top1 92.619792    Top5 99.557292    LR 0.030000    Time 0.031483    
2018-10-21 07:19:17,598 - Epoch: [159][  350/  391]    Overall Loss 1.538613    Objective Loss 1.538613    Top1 92.566964    Top5 99.544643    LR 0.030000    Time 0.031332    
2018-10-21 07:19:19,032 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25474 | -0.00303 |    0.16886 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08651 | -0.00280 |    0.05002 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08496 |  0.00117 |    0.05698 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07289 | -0.00628 |    0.04873 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07099 | -0.00141 |    0.04684 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08683 | -0.00989 |    0.05991 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07682 | -0.00778 |    0.05409 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09042 | -0.00321 |    0.06717 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07679 | -0.00431 |    0.05837 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18891 | -0.00113 |    0.11697 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06642 | -0.00277 |    0.04997 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05820 | -0.00689 |    0.04552 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07071 | -0.00691 |    0.05401 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05612 | -0.00409 |    0.04357 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07059 | -0.00543 |    0.05587 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06379 | -0.00398 |    0.05040 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08893 | -0.00490 |    0.06782 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06033 | -0.00760 |    0.04749 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04112 | -0.00286 |    0.03146 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03669 | -0.00648 |    0.02835 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02262 |  0.00006 |    0.01535 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40751 | -0.00001 |    0.28318 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:19:19,032 - Total sparsity: 0.00

2018-10-21 07:19:19,032 - --- validate (epoch=159)-----------
2018-10-21 07:19:19,033 - 10000 samples (128 per mini-batch)
2018-10-21 07:19:20,273 - Epoch: [159][   50/   78]    Loss 1.584696    Top1 87.781250    Top5 99.171875    
2018-10-21 07:19:20,926 - ==> Top1: 87.790    Top5: 99.250    Loss: 1.584

2018-10-21 07:19:20,928 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:19:20,928 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:19:20,941 - 

2018-10-21 07:19:20,941 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:19:22,631 - Epoch: [160][   50/  391]    Overall Loss 1.534591    Objective Loss 1.534591    Top1 92.953125    Top5 99.546875    LR 0.030000    Time 0.033730    
2018-10-21 07:19:24,191 - Epoch: [160][  100/  391]    Overall Loss 1.536382    Objective Loss 1.536382    Top1 92.882812    Top5 99.460938    LR 0.030000    Time 0.032437    
2018-10-21 07:19:25,750 - Epoch: [160][  150/  391]    Overall Loss 1.536556    Objective Loss 1.536556    Top1 92.848958    Top5 99.458333    LR 0.030000    Time 0.032003    
2018-10-21 07:19:27,338 - Epoch: [160][  200/  391]    Overall Loss 1.537422    Objective Loss 1.537422    Top1 92.750000    Top5 99.527344    LR 0.030000    Time 0.031931    
2018-10-21 07:19:28,921 - Epoch: [160][  250/  391]    Overall Loss 1.538551    Objective Loss 1.538551    Top1 92.637500    Top5 99.525000    LR 0.030000    Time 0.031872    
2018-10-21 07:19:30,470 - Epoch: [160][  300/  391]    Overall Loss 1.539283    Objective Loss 1.539283    Top1 92.588542    Top5 99.520833    LR 0.030000    Time 0.031714    
2018-10-21 07:19:32,097 - Epoch: [160][  350/  391]    Overall Loss 1.539550    Objective Loss 1.539550    Top1 92.562500    Top5 99.542411    LR 0.030000    Time 0.031827    
2018-10-21 07:19:33,514 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25398 |  0.00062 |    0.16873 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08632 | -0.00266 |    0.05007 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08470 |  0.00121 |    0.05706 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07277 | -0.00574 |    0.04873 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07079 | -0.00156 |    0.04667 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08658 | -0.00988 |    0.05985 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07659 | -0.00766 |    0.05388 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09010 | -0.00298 |    0.06693 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07659 | -0.00379 |    0.05822 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18819 | -0.00073 |    0.11594 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06632 | -0.00297 |    0.05004 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05815 | -0.00677 |    0.04554 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07064 | -0.00710 |    0.05398 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05605 | -0.00437 |    0.04355 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07038 | -0.00542 |    0.05564 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06367 | -0.00395 |    0.05031 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08854 | -0.00500 |    0.06764 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06027 | -0.00758 |    0.04742 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04114 | -0.00291 |    0.03151 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03664 | -0.00661 |    0.02833 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02255 |  0.00008 |    0.01530 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40745 | -0.00001 |    0.28331 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:19:33,515 - Total sparsity: 0.00

2018-10-21 07:19:33,515 - --- validate (epoch=160)-----------
2018-10-21 07:19:33,515 - 10000 samples (128 per mini-batch)
2018-10-21 07:19:34,739 - Epoch: [160][   50/   78]    Loss 1.582688    Top1 87.859375    Top5 99.343750    
2018-10-21 07:19:35,393 - ==> Top1: 88.110    Top5: 99.320    Loss: 1.580

2018-10-21 07:19:35,395 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:19:35,395 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:19:35,409 - 

2018-10-21 07:19:35,409 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:19:37,111 - Epoch: [161][   50/  391]    Overall Loss 1.534521    Objective Loss 1.534521    Top1 93.015625    Top5 99.515625    LR 0.030000    Time 0.033975    
2018-10-21 07:19:38,670 - Epoch: [161][  100/  391]    Overall Loss 1.536399    Objective Loss 1.536399    Top1 92.812500    Top5 99.531250    LR 0.030000    Time 0.032559    
2018-10-21 07:19:40,255 - Epoch: [161][  150/  391]    Overall Loss 1.538639    Objective Loss 1.538639    Top1 92.578125    Top5 99.500000    LR 0.030000    Time 0.032258    
2018-10-21 07:19:41,782 - Epoch: [161][  200/  391]    Overall Loss 1.539877    Objective Loss 1.539877    Top1 92.437500    Top5 99.484375    LR 0.030000    Time 0.031813    
2018-10-21 07:19:43,310 - Epoch: [161][  250/  391]    Overall Loss 1.540497    Objective Loss 1.540497    Top1 92.425000    Top5 99.518750    LR 0.030000    Time 0.031554    
2018-10-21 07:19:44,842 - Epoch: [161][  300/  391]    Overall Loss 1.539851    Objective Loss 1.539851    Top1 92.468750    Top5 99.541667    LR 0.030000    Time 0.031395    
2018-10-21 07:19:46,397 - Epoch: [161][  350/  391]    Overall Loss 1.540140    Objective Loss 1.540140    Top1 92.439732    Top5 99.531250    LR 0.030000    Time 0.031348    
2018-10-21 07:19:47,823 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25288 |  0.00118 |    0.16882 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08608 | -0.00375 |    0.04988 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08442 |  0.00053 |    0.05678 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07259 | -0.00553 |    0.04854 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07053 | -0.00134 |    0.04635 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08628 | -0.01000 |    0.05967 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07629 | -0.00749 |    0.05378 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08975 | -0.00302 |    0.06657 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07632 | -0.00409 |    0.05804 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18734 | -0.00035 |    0.11507 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06619 | -0.00274 |    0.04989 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05803 | -0.00689 |    0.04547 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07052 | -0.00714 |    0.05394 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05595 | -0.00442 |    0.04351 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07013 | -0.00553 |    0.05548 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06351 | -0.00390 |    0.05016 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08813 | -0.00500 |    0.06724 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06016 | -0.00751 |    0.04733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04110 | -0.00301 |    0.03151 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03658 | -0.00659 |    0.02828 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02246 |  0.00015 |    0.01527 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40709 | -0.00001 |    0.28316 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:19:47,823 - Total sparsity: 0.00

2018-10-21 07:19:47,823 - --- validate (epoch=161)-----------
2018-10-21 07:19:47,824 - 10000 samples (128 per mini-batch)
2018-10-21 07:19:49,047 - Epoch: [161][   50/   78]    Loss 1.584063    Top1 87.812500    Top5 99.484375    
2018-10-21 07:19:49,695 - ==> Top1: 87.870    Top5: 99.500    Loss: 1.583

2018-10-21 07:19:49,696 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:19:49,696 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:19:49,709 - 

2018-10-21 07:19:49,709 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:19:51,444 - Epoch: [162][   50/  391]    Overall Loss 1.536822    Objective Loss 1.536822    Top1 92.984375    Top5 99.546875    LR 0.030000    Time 0.034616    
2018-10-21 07:19:53,014 - Epoch: [162][  100/  391]    Overall Loss 1.537796    Objective Loss 1.537796    Top1 92.789062    Top5 99.523438    LR 0.030000    Time 0.032988    
2018-10-21 07:19:54,576 - Epoch: [162][  150/  391]    Overall Loss 1.536462    Objective Loss 1.536462    Top1 92.890625    Top5 99.557292    LR 0.030000    Time 0.032384    
2018-10-21 07:19:56,136 - Epoch: [162][  200/  391]    Overall Loss 1.537656    Objective Loss 1.537656    Top1 92.746094    Top5 99.570312    LR 0.030000    Time 0.032077    
2018-10-21 07:19:57,696 - Epoch: [162][  250/  391]    Overall Loss 1.537715    Objective Loss 1.537715    Top1 92.750000    Top5 99.550000    LR 0.030000    Time 0.031893    
2018-10-21 07:19:59,230 - Epoch: [162][  300/  391]    Overall Loss 1.537460    Objective Loss 1.537460    Top1 92.770833    Top5 99.552083    LR 0.030000    Time 0.031683    
2018-10-21 07:20:00,761 - Epoch: [162][  350/  391]    Overall Loss 1.538144    Objective Loss 1.538144    Top1 92.698661    Top5 99.540179    LR 0.030000    Time 0.031526    
2018-10-21 07:20:02,166 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25199 |  0.00214 |    0.16769 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08583 | -0.00363 |    0.04963 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08419 |  0.00097 |    0.05652 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07249 | -0.00504 |    0.04869 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07037 | -0.00138 |    0.04644 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08619 | -0.00927 |    0.05928 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07607 | -0.00763 |    0.05368 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08950 | -0.00305 |    0.06635 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07617 | -0.00394 |    0.05785 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18664 | -0.00036 |    0.11509 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06612 | -0.00298 |    0.04987 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05803 | -0.00662 |    0.04537 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07050 | -0.00693 |    0.05401 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05592 | -0.00433 |    0.04353 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06997 | -0.00540 |    0.05535 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06343 | -0.00395 |    0.05008 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08779 | -0.00477 |    0.06702 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06012 | -0.00747 |    0.04730 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04111 | -0.00302 |    0.03153 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03656 | -0.00657 |    0.02826 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02239 |  0.00007 |    0.01523 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40715 | -0.00001 |    0.28333 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:20:02,166 - Total sparsity: 0.00

2018-10-21 07:20:02,166 - --- validate (epoch=162)-----------
2018-10-21 07:20:02,167 - 10000 samples (128 per mini-batch)
2018-10-21 07:20:03,393 - Epoch: [162][   50/   78]    Loss 1.581194    Top1 88.000000    Top5 99.312500    
2018-10-21 07:20:04,070 - ==> Top1: 88.060    Top5: 99.370    Loss: 1.581

2018-10-21 07:20:04,072 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:20:04,072 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:20:04,092 - 

2018-10-21 07:20:04,092 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:20:05,777 - Epoch: [163][   50/  391]    Overall Loss 1.536879    Objective Loss 1.536879    Top1 92.640625    Top5 99.531250    LR 0.030000    Time 0.033633    
2018-10-21 07:20:07,321 - Epoch: [163][  100/  391]    Overall Loss 1.536889    Objective Loss 1.536889    Top1 92.609375    Top5 99.507812    LR 0.030000    Time 0.032231    
2018-10-21 07:20:08,850 - Epoch: [163][  150/  391]    Overall Loss 1.537005    Objective Loss 1.537005    Top1 92.666667    Top5 99.500000    LR 0.030000    Time 0.031665    
2018-10-21 07:20:10,412 - Epoch: [163][  200/  391]    Overall Loss 1.538635    Objective Loss 1.538635    Top1 92.519531    Top5 99.515625    LR 0.030000    Time 0.031547    
2018-10-21 07:20:11,956 - Epoch: [163][  250/  391]    Overall Loss 1.538605    Objective Loss 1.538605    Top1 92.553125    Top5 99.512500    LR 0.030000    Time 0.031406    
2018-10-21 07:20:13,506 - Epoch: [163][  300/  391]    Overall Loss 1.538342    Objective Loss 1.538342    Top1 92.598958    Top5 99.497396    LR 0.030000    Time 0.031330    
2018-10-21 07:20:15,034 - Epoch: [163][  350/  391]    Overall Loss 1.538728    Objective Loss 1.538728    Top1 92.580357    Top5 99.504464    LR 0.030000    Time 0.031214    
2018-10-21 07:20:16,454 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25112 | -0.00058 |    0.16687 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08570 | -0.00297 |    0.04961 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08403 |  0.00151 |    0.05632 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07227 | -0.00560 |    0.04856 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07019 | -0.00113 |    0.04633 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08595 | -0.00903 |    0.05932 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07582 | -0.00790 |    0.05353 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08921 | -0.00282 |    0.06596 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07596 | -0.00382 |    0.05772 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18600 | -0.00064 |    0.11523 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06601 | -0.00315 |    0.04979 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05797 | -0.00663 |    0.04536 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07042 | -0.00706 |    0.05388 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05587 | -0.00428 |    0.04353 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06979 | -0.00540 |    0.05527 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06333 | -0.00387 |    0.05003 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08744 | -0.00481 |    0.06696 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06007 | -0.00751 |    0.04730 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04113 | -0.00301 |    0.03159 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03655 | -0.00653 |    0.02827 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02232 |  0.00003 |    0.01520 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40710 | -0.00001 |    0.28342 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:20:16,454 - Total sparsity: 0.00

2018-10-21 07:20:16,455 - --- validate (epoch=163)-----------
2018-10-21 07:20:16,455 - 10000 samples (128 per mini-batch)
2018-10-21 07:20:17,683 - Epoch: [163][   50/   78]    Loss 1.578073    Top1 88.453125    Top5 99.546875    
2018-10-21 07:20:18,352 - ==> Top1: 88.430    Top5: 99.520    Loss: 1.577

2018-10-21 07:20:18,354 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:20:18,354 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:20:18,367 - 

2018-10-21 07:20:18,367 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:20:20,114 - Epoch: [164][   50/  391]    Overall Loss 1.529338    Objective Loss 1.529338    Top1 93.546875    Top5 99.656250    LR 0.030000    Time 0.034882    
2018-10-21 07:20:21,686 - Epoch: [164][  100/  391]    Overall Loss 1.531378    Objective Loss 1.531378    Top1 93.406250    Top5 99.570312    LR 0.030000    Time 0.033134    
2018-10-21 07:20:23,239 - Epoch: [164][  150/  391]    Overall Loss 1.534158    Objective Loss 1.534158    Top1 93.088542    Top5 99.593750    LR 0.030000    Time 0.032430    
2018-10-21 07:20:24,788 - Epoch: [164][  200/  391]    Overall Loss 1.535846    Objective Loss 1.535846    Top1 92.878906    Top5 99.550781    LR 0.030000    Time 0.032057    
2018-10-21 07:20:26,356 - Epoch: [164][  250/  391]    Overall Loss 1.537352    Objective Loss 1.537352    Top1 92.737500    Top5 99.518750    LR 0.030000    Time 0.031908    
2018-10-21 07:20:27,917 - Epoch: [164][  300/  391]    Overall Loss 1.537481    Objective Loss 1.537481    Top1 92.736979    Top5 99.518229    LR 0.030000    Time 0.031787    
2018-10-21 07:20:29,563 - Epoch: [164][  350/  391]    Overall Loss 1.538086    Objective Loss 1.538086    Top1 92.676339    Top5 99.504464    LR 0.030000    Time 0.031942    
2018-10-21 07:20:31,032 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25025 |  0.00063 |    0.16613 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08550 | -0.00325 |    0.04957 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08386 |  0.00100 |    0.05628 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07216 | -0.00543 |    0.04848 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07003 | -0.00169 |    0.04616 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08575 | -0.00943 |    0.05906 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07563 | -0.00772 |    0.05347 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08895 | -0.00255 |    0.06582 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07574 | -0.00394 |    0.05759 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18533 | -0.00024 |    0.11435 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06595 | -0.00304 |    0.04971 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05792 | -0.00656 |    0.04538 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07035 | -0.00665 |    0.05374 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05585 | -0.00383 |    0.04344 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06960 | -0.00533 |    0.05517 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06323 | -0.00375 |    0.04996 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08709 | -0.00467 |    0.06672 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05999 | -0.00762 |    0.04728 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04113 | -0.00309 |    0.03159 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03654 | -0.00649 |    0.02824 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02226 |  0.00002 |    0.01514 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40703 | -0.00001 |    0.28338 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:20:31,032 - Total sparsity: 0.00

2018-10-21 07:20:31,032 - --- validate (epoch=164)-----------
2018-10-21 07:20:31,033 - 10000 samples (128 per mini-batch)
2018-10-21 07:20:32,255 - Epoch: [164][   50/   78]    Loss 1.576580    Top1 88.453125    Top5 99.484375    
2018-10-21 07:20:32,920 - ==> Top1: 88.530    Top5: 99.500    Loss: 1.576

2018-10-21 07:20:32,922 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:20:32,923 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:20:32,936 - 

2018-10-21 07:20:32,936 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:20:34,666 - Epoch: [165][   50/  391]    Overall Loss 1.530323    Objective Loss 1.530323    Top1 93.437500    Top5 99.484375    LR 0.030000    Time 0.034521    
2018-10-21 07:20:36,248 - Epoch: [165][  100/  391]    Overall Loss 1.532876    Objective Loss 1.532876    Top1 93.195312    Top5 99.500000    LR 0.030000    Time 0.033055    
2018-10-21 07:20:37,779 - Epoch: [165][  150/  391]    Overall Loss 1.535214    Objective Loss 1.535214    Top1 92.958333    Top5 99.526042    LR 0.030000    Time 0.032233    
2018-10-21 07:20:39,340 - Epoch: [165][  200/  391]    Overall Loss 1.538096    Objective Loss 1.538096    Top1 92.660156    Top5 99.535156    LR 0.030000    Time 0.031968    
2018-10-21 07:20:40,890 - Epoch: [165][  250/  391]    Overall Loss 1.538794    Objective Loss 1.538794    Top1 92.603125    Top5 99.556250    LR 0.030000    Time 0.031765    
2018-10-21 07:20:42,464 - Epoch: [165][  300/  391]    Overall Loss 1.539513    Objective Loss 1.539513    Top1 92.497396    Top5 99.526042    LR 0.030000    Time 0.031710    
2018-10-21 07:20:43,991 - Epoch: [165][  350/  391]    Overall Loss 1.538747    Objective Loss 1.538747    Top1 92.580357    Top5 99.549107    LR 0.030000    Time 0.031537    
2018-10-21 07:20:45,383 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24948 | -0.00264 |    0.16550 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08523 | -0.00311 |    0.04925 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08363 |  0.00034 |    0.05593 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07204 | -0.00558 |    0.04844 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06984 | -0.00186 |    0.04608 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08564 | -0.00877 |    0.05915 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07543 | -0.00793 |    0.05345 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08866 | -0.00284 |    0.06580 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07553 | -0.00364 |    0.05747 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18474 | -0.00007 |    0.11394 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06588 | -0.00289 |    0.04967 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05787 | -0.00660 |    0.04533 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07028 | -0.00694 |    0.05379 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05580 | -0.00390 |    0.04342 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06942 | -0.00542 |    0.05501 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06314 | -0.00370 |    0.04988 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08677 | -0.00458 |    0.06662 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05996 | -0.00755 |    0.04724 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04115 | -0.00302 |    0.03157 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03652 | -0.00655 |    0.02824 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02220 |  0.00009 |    0.01508 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40696 | -0.00001 |    0.28343 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:20:45,384 - Total sparsity: 0.00

2018-10-21 07:20:45,384 - --- validate (epoch=165)-----------
2018-10-21 07:20:45,384 - 10000 samples (128 per mini-batch)
2018-10-21 07:20:46,626 - Epoch: [165][   50/   78]    Loss 1.593072    Top1 86.921875    Top5 99.390625    
2018-10-21 07:20:47,286 - ==> Top1: 86.830    Top5: 99.470    Loss: 1.594

2018-10-21 07:20:47,287 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:20:47,287 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:20:47,300 - 

2018-10-21 07:20:47,301 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:20:49,135 - Epoch: [166][   50/  391]    Overall Loss 1.541224    Objective Loss 1.541224    Top1 92.296875    Top5 99.531250    LR 0.030000    Time 0.036625    
2018-10-21 07:20:50,735 - Epoch: [166][  100/  391]    Overall Loss 1.539583    Objective Loss 1.539583    Top1 92.531250    Top5 99.578125    LR 0.030000    Time 0.034293    
2018-10-21 07:20:52,341 - Epoch: [166][  150/  391]    Overall Loss 1.540517    Objective Loss 1.540517    Top1 92.427083    Top5 99.500000    LR 0.030000    Time 0.033558    
2018-10-21 07:20:53,921 - Epoch: [166][  200/  391]    Overall Loss 1.539884    Objective Loss 1.539884    Top1 92.500000    Top5 99.507812    LR 0.030000    Time 0.033056    
2018-10-21 07:20:55,494 - Epoch: [166][  250/  391]    Overall Loss 1.540642    Objective Loss 1.540642    Top1 92.418750    Top5 99.506250    LR 0.030000    Time 0.032727    
2018-10-21 07:20:57,091 - Epoch: [166][  300/  391]    Overall Loss 1.540548    Objective Loss 1.540548    Top1 92.434896    Top5 99.523438    LR 0.030000    Time 0.032588    
2018-10-21 07:20:58,687 - Epoch: [166][  350/  391]    Overall Loss 1.540660    Objective Loss 1.540660    Top1 92.433036    Top5 99.524554    LR 0.030000    Time 0.032488    
2018-10-21 07:21:00,099 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24901 |  0.00017 |    0.16542 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08500 | -0.00336 |    0.04922 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08345 |  0.00103 |    0.05577 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07193 | -0.00527 |    0.04832 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06965 | -0.00196 |    0.04594 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08545 | -0.00912 |    0.05912 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07537 | -0.00713 |    0.05331 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08842 | -0.00272 |    0.06566 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07531 | -0.00387 |    0.05728 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18417 | -0.00055 |    0.11368 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06581 | -0.00304 |    0.04964 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05783 | -0.00651 |    0.04528 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07019 | -0.00723 |    0.05381 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05574 | -0.00401 |    0.04337 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06927 | -0.00530 |    0.05486 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06307 | -0.00370 |    0.04984 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08644 | -0.00485 |    0.06624 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05996 | -0.00743 |    0.04720 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04116 | -0.00313 |    0.03163 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03652 | -0.00651 |    0.02823 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02216 |  0.00007 |    0.01505 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40695 | -0.00001 |    0.28348 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:21:00,099 - Total sparsity: 0.00

2018-10-21 07:21:00,099 - --- validate (epoch=166)-----------
2018-10-21 07:21:00,100 - 10000 samples (128 per mini-batch)
2018-10-21 07:21:01,314 - Epoch: [166][   50/   78]    Loss 1.578119    Top1 88.343750    Top5 99.250000    
2018-10-21 07:21:01,977 - ==> Top1: 88.350    Top5: 99.310    Loss: 1.578

2018-10-21 07:21:01,979 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:21:01,979 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:21:01,992 - 

2018-10-21 07:21:01,993 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:21:03,770 - Epoch: [167][   50/  391]    Overall Loss 1.528685    Objective Loss 1.528685    Top1 93.843750    Top5 99.656250    LR 0.030000    Time 0.035477    
2018-10-21 07:21:05,342 - Epoch: [167][  100/  391]    Overall Loss 1.534271    Objective Loss 1.534271    Top1 93.140625    Top5 99.609375    LR 0.030000    Time 0.033437    
2018-10-21 07:21:06,913 - Epoch: [167][  150/  391]    Overall Loss 1.535158    Objective Loss 1.535158    Top1 92.994792    Top5 99.572917    LR 0.030000    Time 0.032753    
2018-10-21 07:21:08,496 - Epoch: [167][  200/  391]    Overall Loss 1.537123    Objective Loss 1.537123    Top1 92.785156    Top5 99.570312    LR 0.030000    Time 0.032468    
2018-10-21 07:21:10,083 - Epoch: [167][  250/  391]    Overall Loss 1.537075    Objective Loss 1.537075    Top1 92.806250    Top5 99.581250    LR 0.030000    Time 0.032314    
2018-10-21 07:21:11,663 - Epoch: [167][  300/  391]    Overall Loss 1.537661    Objective Loss 1.537661    Top1 92.729167    Top5 99.562500    LR 0.030000    Time 0.032188    
2018-10-21 07:21:13,219 - Epoch: [167][  350/  391]    Overall Loss 1.538269    Objective Loss 1.538269    Top1 92.671875    Top5 99.553571    LR 0.030000    Time 0.032028    
2018-10-21 07:21:14,632 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24853 |  0.00013 |    0.16479 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08488 | -0.00356 |    0.04913 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08335 |  0.00111 |    0.05589 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07183 | -0.00502 |    0.04819 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06951 | -0.00181 |    0.04592 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08536 | -0.00949 |    0.05927 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07521 | -0.00771 |    0.05324 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08823 | -0.00226 |    0.06569 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07514 | -0.00384 |    0.05711 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18367 | -0.00030 |    0.11364 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06578 | -0.00270 |    0.04962 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05779 | -0.00672 |    0.04528 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07013 | -0.00729 |    0.05372 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05571 | -0.00373 |    0.04329 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06915 | -0.00526 |    0.05474 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06300 | -0.00370 |    0.04978 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08613 | -0.00522 |    0.06608 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05992 | -0.00748 |    0.04722 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04117 | -0.00323 |    0.03165 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03650 | -0.00662 |    0.02825 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02210 |  0.00004 |    0.01506 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40698 | -0.00001 |    0.28373 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:21:14,632 - Total sparsity: 0.00

2018-10-21 07:21:14,632 - --- validate (epoch=167)-----------
2018-10-21 07:21:14,632 - 10000 samples (128 per mini-batch)
2018-10-21 07:21:15,873 - Epoch: [167][   50/   78]    Loss 1.588629    Top1 87.484375    Top5 99.218750    
2018-10-21 07:21:16,514 - ==> Top1: 87.440    Top5: 99.270    Loss: 1.588

2018-10-21 07:21:16,516 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:21:16,516 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:21:16,529 - 

2018-10-21 07:21:16,529 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:21:18,305 - Epoch: [168][   50/  391]    Overall Loss 1.535165    Objective Loss 1.535165    Top1 93.062500    Top5 99.593750    LR 0.030000    Time 0.035450    
2018-10-21 07:21:19,946 - Epoch: [168][  100/  391]    Overall Loss 1.537449    Objective Loss 1.537449    Top1 92.648438    Top5 99.562500    LR 0.030000    Time 0.034111    
2018-10-21 07:21:21,576 - Epoch: [168][  150/  391]    Overall Loss 1.539007    Objective Loss 1.539007    Top1 92.473958    Top5 99.515625    LR 0.030000    Time 0.033597    
2018-10-21 07:21:23,187 - Epoch: [168][  200/  391]    Overall Loss 1.539025    Objective Loss 1.539025    Top1 92.484375    Top5 99.519531    LR 0.030000    Time 0.033242    
2018-10-21 07:21:24,787 - Epoch: [168][  250/  391]    Overall Loss 1.538691    Objective Loss 1.538691    Top1 92.543750    Top5 99.537500    LR 0.030000    Time 0.032983    
2018-10-21 07:21:26,397 - Epoch: [168][  300/  391]    Overall Loss 1.538000    Objective Loss 1.538000    Top1 92.614583    Top5 99.549479    LR 0.030000    Time 0.032847    
2018-10-21 07:21:28,050 - Epoch: [168][  350/  391]    Overall Loss 1.538485    Objective Loss 1.538485    Top1 92.560268    Top5 99.531250    LR 0.030000    Time 0.032871    
2018-10-21 07:21:29,495 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24775 | -0.00166 |    0.16469 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08472 | -0.00299 |    0.04910 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08318 |  0.00098 |    0.05579 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07171 | -0.00506 |    0.04820 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06934 | -0.00209 |    0.04583 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08517 | -0.00949 |    0.05885 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07505 | -0.00781 |    0.05313 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08799 | -0.00299 |    0.06536 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07496 | -0.00413 |    0.05700 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18317 |  0.00013 |    0.11303 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06574 | -0.00299 |    0.04959 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05779 | -0.00668 |    0.04527 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07007 | -0.00751 |    0.05368 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05568 | -0.00390 |    0.04331 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06900 | -0.00535 |    0.05468 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06294 | -0.00365 |    0.04970 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08581 | -0.00529 |    0.06599 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05987 | -0.00760 |    0.04722 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04118 | -0.00329 |    0.03169 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03653 | -0.00651 |    0.02827 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02208 |  0.00004 |    0.01505 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40667 | -0.00001 |    0.28362 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:21:29,495 - Total sparsity: 0.00

2018-10-21 07:21:29,495 - --- validate (epoch=168)-----------
2018-10-21 07:21:29,496 - 10000 samples (128 per mini-batch)
2018-10-21 07:21:30,909 - Epoch: [168][   50/   78]    Loss 1.579488    Top1 88.140625    Top5 99.359375    
2018-10-21 07:21:31,694 - ==> Top1: 88.450    Top5: 99.390    Loss: 1.577

2018-10-21 07:21:31,695 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:21:31,695 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:21:31,709 - 

2018-10-21 07:21:31,709 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:21:33,494 - Epoch: [169][   50/  391]    Overall Loss 1.545005    Objective Loss 1.545005    Top1 92.078125    Top5 99.468750    LR 0.030000    Time 0.035639    
2018-10-21 07:21:35,192 - Epoch: [169][  100/  391]    Overall Loss 1.540572    Objective Loss 1.540572    Top1 92.460938    Top5 99.468750    LR 0.030000    Time 0.034775    
2018-10-21 07:21:37,014 - Epoch: [169][  150/  391]    Overall Loss 1.540597    Objective Loss 1.540597    Top1 92.390625    Top5 99.500000    LR 0.030000    Time 0.035313    
2018-10-21 07:21:38,786 - Epoch: [169][  200/  391]    Overall Loss 1.539040    Objective Loss 1.539040    Top1 92.535156    Top5 99.511719    LR 0.030000    Time 0.035334    
2018-10-21 07:21:40,590 - Epoch: [169][  250/  391]    Overall Loss 1.539068    Objective Loss 1.539068    Top1 92.559375    Top5 99.484375    LR 0.030000    Time 0.035476    
2018-10-21 07:21:42,295 - Epoch: [169][  300/  391]    Overall Loss 1.539149    Objective Loss 1.539149    Top1 92.520833    Top5 99.502604    LR 0.030000    Time 0.035238    
2018-10-21 07:21:43,879 - Epoch: [169][  350/  391]    Overall Loss 1.539325    Objective Loss 1.539325    Top1 92.488839    Top5 99.493304    LR 0.030000    Time 0.034725    
2018-10-21 07:21:45,284 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24699 | -0.00092 |    0.16377 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08453 | -0.00299 |    0.04902 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08298 |  0.00129 |    0.05582 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07152 | -0.00543 |    0.04802 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06916 | -0.00211 |    0.04562 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08502 | -0.00927 |    0.05865 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07483 | -0.00798 |    0.05288 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08774 | -0.00319 |    0.06524 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07479 | -0.00430 |    0.05695 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18258 | -0.00043 |    0.11182 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06572 | -0.00278 |    0.04958 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05776 | -0.00678 |    0.04525 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07003 | -0.00740 |    0.05371 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05568 | -0.00376 |    0.04329 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06887 | -0.00540 |    0.05456 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06288 | -0.00358 |    0.04968 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08555 | -0.00514 |    0.06567 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05991 | -0.00729 |    0.04719 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04123 | -0.00312 |    0.03173 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03653 | -0.00656 |    0.02829 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02204 |  0.00010 |    0.01500 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40650 | -0.00001 |    0.28355 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:21:45,285 - Total sparsity: 0.00

2018-10-21 07:21:45,285 - --- validate (epoch=169)-----------
2018-10-21 07:21:45,285 - 10000 samples (128 per mini-batch)
2018-10-21 07:21:46,499 - Epoch: [169][   50/   78]    Loss 1.581646    Top1 87.984375    Top5 99.406250    
2018-10-21 07:21:47,131 - ==> Top1: 88.170    Top5: 99.440    Loss: 1.580

2018-10-21 07:21:47,133 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:21:47,133 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:21:47,151 - 

2018-10-21 07:21:47,151 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:21:49,160 - Epoch: [170][   50/  391]    Overall Loss 1.532962    Objective Loss 1.532962    Top1 93.109375    Top5 99.625000    LR 0.030000    Time 0.040125    
2018-10-21 07:21:50,938 - Epoch: [170][  100/  391]    Overall Loss 1.533598    Objective Loss 1.533598    Top1 93.085938    Top5 99.554688    LR 0.030000    Time 0.037819    
2018-10-21 07:21:52,652 - Epoch: [170][  150/  391]    Overall Loss 1.535528    Objective Loss 1.535528    Top1 92.880208    Top5 99.593750    LR 0.030000    Time 0.036621    
2018-10-21 07:21:54,260 - Epoch: [170][  200/  391]    Overall Loss 1.535986    Objective Loss 1.535986    Top1 92.824219    Top5 99.597656    LR 0.030000    Time 0.035494    
2018-10-21 07:21:55,819 - Epoch: [170][  250/  391]    Overall Loss 1.536365    Objective Loss 1.536365    Top1 92.800000    Top5 99.587500    LR 0.030000    Time 0.034621    
2018-10-21 07:21:57,335 - Epoch: [170][  300/  391]    Overall Loss 1.537281    Objective Loss 1.537281    Top1 92.700521    Top5 99.583333    LR 0.030000    Time 0.033897    
2018-10-21 07:21:58,889 - Epoch: [170][  350/  391]    Overall Loss 1.538150    Objective Loss 1.538150    Top1 92.613839    Top5 99.562500    LR 0.030000    Time 0.033488    
2018-10-21 07:22:00,277 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24627 |  0.00049 |    0.16399 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08445 | -0.00390 |    0.04914 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08291 |  0.00101 |    0.05586 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07138 | -0.00545 |    0.04799 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06901 | -0.00230 |    0.04545 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08488 | -0.00926 |    0.05859 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07468 | -0.00790 |    0.05288 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08755 | -0.00294 |    0.06502 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07466 | -0.00412 |    0.05683 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18209 | -0.00016 |    0.11097 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06571 | -0.00289 |    0.04952 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05773 | -0.00684 |    0.04531 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07009 | -0.00708 |    0.05371 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05571 | -0.00375 |    0.04337 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06878 | -0.00525 |    0.05450 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06284 | -0.00371 |    0.04967 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08529 | -0.00511 |    0.06554 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05990 | -0.00718 |    0.04716 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04126 | -0.00317 |    0.03176 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03657 | -0.00639 |    0.02832 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02201 |  0.00008 |    0.01496 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40644 | -0.00001 |    0.28366 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:22:00,277 - Total sparsity: 0.00

2018-10-21 07:22:00,277 - --- validate (epoch=170)-----------
2018-10-21 07:22:00,277 - 10000 samples (128 per mini-batch)
2018-10-21 07:22:01,503 - Epoch: [170][   50/   78]    Loss 1.589642    Top1 87.312500    Top5 99.218750    
2018-10-21 07:22:02,153 - ==> Top1: 87.510    Top5: 99.270    Loss: 1.587

2018-10-21 07:22:02,155 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:22:02,155 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:22:02,172 - 

2018-10-21 07:22:02,172 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:22:03,878 - Epoch: [171][   50/  391]    Overall Loss 1.541635    Objective Loss 1.541635    Top1 92.390625    Top5 99.437500    LR 0.030000    Time 0.034038    
2018-10-21 07:22:05,388 - Epoch: [171][  100/  391]    Overall Loss 1.535430    Objective Loss 1.535430    Top1 93.007812    Top5 99.578125    LR 0.030000    Time 0.032088    
2018-10-21 07:22:06,877 - Epoch: [171][  150/  391]    Overall Loss 1.537021    Objective Loss 1.537021    Top1 92.807292    Top5 99.588542    LR 0.030000    Time 0.031302    
2018-10-21 07:22:08,371 - Epoch: [171][  200/  391]    Overall Loss 1.537740    Objective Loss 1.537740    Top1 92.718750    Top5 99.582031    LR 0.030000    Time 0.030928    
2018-10-21 07:22:09,859 - Epoch: [171][  250/  391]    Overall Loss 1.537566    Objective Loss 1.537566    Top1 92.731250    Top5 99.578125    LR 0.030000    Time 0.030681    
2018-10-21 07:22:11,329 - Epoch: [171][  300/  391]    Overall Loss 1.538691    Objective Loss 1.538691    Top1 92.575521    Top5 99.562500    LR 0.030000    Time 0.030461    
2018-10-21 07:22:12,849 - Epoch: [171][  350/  391]    Overall Loss 1.538467    Objective Loss 1.538467    Top1 92.604911    Top5 99.573661    LR 0.030000    Time 0.030447    
2018-10-21 07:22:14,258 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24587 | -0.00012 |    0.16313 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08440 | -0.00328 |    0.04877 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08281 |  0.00109 |    0.05597 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07128 | -0.00587 |    0.04796 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06891 | -0.00192 |    0.04545 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08471 | -0.00909 |    0.05847 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07458 | -0.00728 |    0.05281 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08737 | -0.00318 |    0.06499 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07454 | -0.00416 |    0.05679 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18150 | -0.00041 |    0.11094 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06572 | -0.00286 |    0.04941 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05777 | -0.00681 |    0.04530 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07008 | -0.00701 |    0.05362 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05571 | -0.00394 |    0.04340 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06866 | -0.00535 |    0.05436 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06279 | -0.00368 |    0.04965 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08506 | -0.00501 |    0.06527 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05989 | -0.00707 |    0.04714 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04127 | -0.00321 |    0.03177 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03655 | -0.00650 |    0.02830 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02197 |  0.00005 |    0.01494 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40631 | -0.00001 |    0.28360 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:22:14,258 - Total sparsity: 0.00

2018-10-21 07:22:14,259 - --- validate (epoch=171)-----------
2018-10-21 07:22:14,259 - 10000 samples (128 per mini-batch)
2018-10-21 07:22:15,386 - Epoch: [171][   50/   78]    Loss 1.580850    Top1 88.031250    Top5 99.328125    
2018-10-21 07:22:16,008 - ==> Top1: 88.030    Top5: 99.350    Loss: 1.580

2018-10-21 07:22:16,010 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:22:16,010 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:22:16,027 - 

2018-10-21 07:22:16,027 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:22:17,774 - Epoch: [172][   50/  391]    Overall Loss 1.534526    Objective Loss 1.534526    Top1 93.046875    Top5 99.484375    LR 0.030000    Time 0.034867    
2018-10-21 07:22:19,322 - Epoch: [172][  100/  391]    Overall Loss 1.537820    Objective Loss 1.537820    Top1 92.640625    Top5 99.578125    LR 0.030000    Time 0.032884    
2018-10-21 07:22:20,899 - Epoch: [172][  150/  391]    Overall Loss 1.537445    Objective Loss 1.537445    Top1 92.713542    Top5 99.562500    LR 0.030000    Time 0.032419    
2018-10-21 07:22:22,449 - Epoch: [172][  200/  391]    Overall Loss 1.537021    Objective Loss 1.537021    Top1 92.726562    Top5 99.566406    LR 0.030000    Time 0.032054    
2018-10-21 07:22:23,991 - Epoch: [172][  250/  391]    Overall Loss 1.537314    Objective Loss 1.537314    Top1 92.728125    Top5 99.540625    LR 0.030000    Time 0.031799    
2018-10-21 07:22:25,592 - Epoch: [172][  300/  391]    Overall Loss 1.538087    Objective Loss 1.538087    Top1 92.666667    Top5 99.546875    LR 0.030000    Time 0.031830    
2018-10-21 07:22:27,117 - Epoch: [172][  350/  391]    Overall Loss 1.538775    Objective Loss 1.538775    Top1 92.580357    Top5 99.542411    LR 0.030000    Time 0.031631    
2018-10-21 07:22:28,520 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24533 | -0.00279 |    0.16318 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08427 | -0.00367 |    0.04859 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08270 |  0.00111 |    0.05574 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07121 | -0.00631 |    0.04809 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06887 | -0.00167 |    0.04526 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08450 | -0.00982 |    0.05857 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07451 | -0.00669 |    0.05266 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08720 | -0.00352 |    0.06489 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07443 | -0.00394 |    0.05668 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18090 | -0.00127 |    0.11034 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06568 | -0.00288 |    0.04942 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05773 | -0.00702 |    0.04528 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07008 | -0.00702 |    0.05365 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05574 | -0.00402 |    0.04339 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06854 | -0.00535 |    0.05419 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06276 | -0.00376 |    0.04963 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08486 | -0.00508 |    0.06516 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05986 | -0.00724 |    0.04718 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04131 | -0.00312 |    0.03177 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03656 | -0.00639 |    0.02831 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02194 |  0.00006 |    0.01495 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40618 | -0.00001 |    0.28375 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:22:28,521 - Total sparsity: 0.00

2018-10-21 07:22:28,521 - --- validate (epoch=172)-----------
2018-10-21 07:22:28,521 - 10000 samples (128 per mini-batch)
2018-10-21 07:22:29,695 - Epoch: [172][   50/   78]    Loss 1.586146    Top1 87.562500    Top5 99.375000    
2018-10-21 07:22:30,330 - ==> Top1: 87.710    Top5: 99.430    Loss: 1.584

2018-10-21 07:22:30,332 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:22:30,332 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:22:30,346 - 

2018-10-21 07:22:30,346 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:22:32,101 - Epoch: [173][   50/  391]    Overall Loss 1.539177    Objective Loss 1.539177    Top1 92.546875    Top5 99.437500    LR 0.030000    Time 0.035019    
2018-10-21 07:22:33,673 - Epoch: [173][  100/  391]    Overall Loss 1.538092    Objective Loss 1.538092    Top1 92.710938    Top5 99.539062    LR 0.030000    Time 0.033201    
2018-10-21 07:22:35,224 - Epoch: [173][  150/  391]    Overall Loss 1.538371    Objective Loss 1.538371    Top1 92.619792    Top5 99.583333    LR 0.030000    Time 0.032461    
2018-10-21 07:22:36,788 - Epoch: [173][  200/  391]    Overall Loss 1.537763    Objective Loss 1.537763    Top1 92.703125    Top5 99.589844    LR 0.030000    Time 0.032152    
2018-10-21 07:22:38,371 - Epoch: [173][  250/  391]    Overall Loss 1.538023    Objective Loss 1.538023    Top1 92.678125    Top5 99.593750    LR 0.030000    Time 0.032044    
2018-10-21 07:22:39,951 - Epoch: [173][  300/  391]    Overall Loss 1.538084    Objective Loss 1.538084    Top1 92.671875    Top5 99.557292    LR 0.030000    Time 0.031961    
2018-10-21 07:22:41,473 - Epoch: [173][  350/  391]    Overall Loss 1.539503    Objective Loss 1.539503    Top1 92.529018    Top5 99.542411    LR 0.030000    Time 0.031736    
2018-10-21 07:22:42,856 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24453 | -0.00169 |    0.16273 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08413 | -0.00361 |    0.04854 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08256 |  0.00092 |    0.05556 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07112 | -0.00640 |    0.04786 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06878 | -0.00151 |    0.04532 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08442 | -0.00998 |    0.05847 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07435 | -0.00722 |    0.05255 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08706 | -0.00375 |    0.06470 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07431 | -0.00390 |    0.05660 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18037 | -0.00154 |    0.11079 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06565 | -0.00258 |    0.04947 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05773 | -0.00689 |    0.04534 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07004 | -0.00722 |    0.05366 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05578 | -0.00390 |    0.04355 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06846 | -0.00535 |    0.05409 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06274 | -0.00380 |    0.04960 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08470 | -0.00493 |    0.06509 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05987 | -0.00722 |    0.04720 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04134 | -0.00321 |    0.03182 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03658 | -0.00636 |    0.02833 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02191 |  0.00004 |    0.01489 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40612 | -0.00001 |    0.28381 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:22:42,856 - Total sparsity: 0.00

2018-10-21 07:22:42,856 - --- validate (epoch=173)-----------
2018-10-21 07:22:42,856 - 10000 samples (128 per mini-batch)
2018-10-21 07:22:44,056 - Epoch: [173][   50/   78]    Loss 1.585572    Top1 87.718750    Top5 99.343750    
2018-10-21 07:22:44,689 - ==> Top1: 87.630    Top5: 99.410    Loss: 1.586

2018-10-21 07:22:44,691 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:22:44,691 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:22:44,704 - 

2018-10-21 07:22:44,704 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:22:46,617 - Epoch: [174][   50/  391]    Overall Loss 1.533117    Objective Loss 1.533117    Top1 93.093750    Top5 99.625000    LR 0.030000    Time 0.038182    
2018-10-21 07:22:48,384 - Epoch: [174][  100/  391]    Overall Loss 1.536577    Objective Loss 1.536577    Top1 92.781250    Top5 99.578125    LR 0.030000    Time 0.036733    
2018-10-21 07:22:50,146 - Epoch: [174][  150/  391]    Overall Loss 1.536328    Objective Loss 1.536328    Top1 92.812500    Top5 99.541667    LR 0.030000    Time 0.036221    
2018-10-21 07:22:51,898 - Epoch: [174][  200/  391]    Overall Loss 1.538172    Objective Loss 1.538172    Top1 92.632812    Top5 99.539062    LR 0.030000    Time 0.035915    
2018-10-21 07:22:53,650 - Epoch: [174][  250/  391]    Overall Loss 1.537583    Objective Loss 1.537583    Top1 92.690625    Top5 99.553125    LR 0.030000    Time 0.035732    
2018-10-21 07:22:55,366 - Epoch: [174][  300/  391]    Overall Loss 1.538141    Objective Loss 1.538141    Top1 92.643229    Top5 99.565104    LR 0.030000    Time 0.035490    
2018-10-21 07:22:57,127 - Epoch: [174][  350/  391]    Overall Loss 1.539108    Objective Loss 1.539108    Top1 92.546875    Top5 99.573661    LR 0.030000    Time 0.035443    
2018-10-21 07:22:58,688 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24423 |  0.00004 |    0.16230 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08404 | -0.00356 |    0.04868 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08251 |  0.00102 |    0.05563 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07110 | -0.00624 |    0.04779 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06872 | -0.00166 |    0.04520 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08427 | -0.00987 |    0.05833 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07418 | -0.00752 |    0.05232 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08688 | -0.00352 |    0.06446 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07420 | -0.00386 |    0.05645 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17999 | -0.00040 |    0.11081 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06560 | -0.00250 |    0.04948 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05772 | -0.00663 |    0.04528 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07004 | -0.00684 |    0.05364 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05574 | -0.00412 |    0.04351 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06836 | -0.00534 |    0.05401 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06271 | -0.00375 |    0.04962 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08449 | -0.00480 |    0.06467 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05987 | -0.00718 |    0.04720 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04138 | -0.00319 |    0.03184 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03659 | -0.00641 |    0.02835 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02189 |  0.00008 |    0.01488 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40610 | -0.00001 |    0.28385 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:22:58,688 - Total sparsity: 0.00

2018-10-21 07:22:58,689 - --- validate (epoch=174)-----------
2018-10-21 07:22:58,689 - 10000 samples (128 per mini-batch)
2018-10-21 07:22:59,879 - Epoch: [174][   50/   78]    Loss 1.574261    Top1 88.765625    Top5 99.453125    
2018-10-21 07:23:00,511 - ==> Top1: 88.790    Top5: 99.510    Loss: 1.574

2018-10-21 07:23:00,512 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:23:00,513 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:23:00,527 - 

2018-10-21 07:23:00,527 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:23:02,243 - Epoch: [175][   50/  391]    Overall Loss 1.534493    Objective Loss 1.534493    Top1 92.968750    Top5 99.500000    LR 0.030000    Time 0.034247    
2018-10-21 07:23:03,797 - Epoch: [175][  100/  391]    Overall Loss 1.534015    Objective Loss 1.534015    Top1 93.015625    Top5 99.539062    LR 0.030000    Time 0.032643    
2018-10-21 07:23:05,366 - Epoch: [175][  150/  391]    Overall Loss 1.534539    Objective Loss 1.534539    Top1 92.984375    Top5 99.531250    LR 0.030000    Time 0.032208    
2018-10-21 07:23:06,914 - Epoch: [175][  200/  391]    Overall Loss 1.536523    Objective Loss 1.536523    Top1 92.820312    Top5 99.539062    LR 0.030000    Time 0.031883    
2018-10-21 07:23:08,454 - Epoch: [175][  250/  391]    Overall Loss 1.537632    Objective Loss 1.537632    Top1 92.718750    Top5 99.553125    LR 0.030000    Time 0.031656    
2018-10-21 07:23:09,996 - Epoch: [175][  300/  391]    Overall Loss 1.537413    Objective Loss 1.537413    Top1 92.729167    Top5 99.544271    LR 0.030000    Time 0.031511    
2018-10-21 07:23:11,556 - Epoch: [175][  350/  391]    Overall Loss 1.536869    Objective Loss 1.536869    Top1 92.787946    Top5 99.555804    LR 0.030000    Time 0.031462    
2018-10-21 07:23:12,967 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24372 | -0.00332 |    0.16190 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08404 | -0.00306 |    0.04855 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08248 |  0.00049 |    0.05565 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07101 | -0.00597 |    0.04785 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06859 | -0.00198 |    0.04525 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08416 | -0.00943 |    0.05826 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07411 | -0.00664 |    0.05224 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08671 | -0.00345 |    0.06440 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07410 | -0.00375 |    0.05635 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17965 | -0.00122 |    0.11057 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06560 | -0.00234 |    0.04944 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05773 | -0.00678 |    0.04534 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07006 | -0.00694 |    0.05364 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05575 | -0.00401 |    0.04351 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06827 | -0.00536 |    0.05394 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06270 | -0.00358 |    0.04960 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08427 | -0.00452 |    0.06456 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05983 | -0.00732 |    0.04717 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04140 | -0.00314 |    0.03186 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03660 | -0.00642 |    0.02835 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02185 |  0.00010 |    0.01485 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40608 | -0.00001 |    0.28394 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:23:12,967 - Total sparsity: 0.00

2018-10-21 07:23:12,967 - --- validate (epoch=175)-----------
2018-10-21 07:23:12,968 - 10000 samples (128 per mini-batch)
2018-10-21 07:23:14,168 - Epoch: [175][   50/   78]    Loss 1.574332    Top1 88.843750    Top5 99.468750    
2018-10-21 07:23:14,813 - ==> Top1: 88.810    Top5: 99.440    Loss: 1.575

2018-10-21 07:23:14,815 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:23:14,815 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:23:14,829 - 

2018-10-21 07:23:14,829 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:23:16,602 - Epoch: [176][   50/  391]    Overall Loss 1.531364    Objective Loss 1.531364    Top1 93.250000    Top5 99.734375    LR 0.030000    Time 0.035390    
2018-10-21 07:23:18,193 - Epoch: [176][  100/  391]    Overall Loss 1.532300    Objective Loss 1.532300    Top1 93.195312    Top5 99.648438    LR 0.030000    Time 0.033589    
2018-10-21 07:23:19,726 - Epoch: [176][  150/  391]    Overall Loss 1.531851    Objective Loss 1.531851    Top1 93.281250    Top5 99.635417    LR 0.030000    Time 0.032589    
2018-10-21 07:23:21,265 - Epoch: [176][  200/  391]    Overall Loss 1.533907    Objective Loss 1.533907    Top1 93.089844    Top5 99.605469    LR 0.030000    Time 0.032125    
2018-10-21 07:23:22,805 - Epoch: [176][  250/  391]    Overall Loss 1.534687    Objective Loss 1.534687    Top1 93.000000    Top5 99.606250    LR 0.030000    Time 0.031852    
2018-10-21 07:23:24,323 - Epoch: [176][  300/  391]    Overall Loss 1.535273    Objective Loss 1.535273    Top1 92.947917    Top5 99.575521    LR 0.030000    Time 0.031596    
2018-10-21 07:23:25,865 - Epoch: [176][  350/  391]    Overall Loss 1.536524    Objective Loss 1.536524    Top1 92.814732    Top5 99.582589    LR 0.030000    Time 0.031483    
2018-10-21 07:23:27,267 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24315 | -0.00110 |    0.16172 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08394 | -0.00324 |    0.04846 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08236 |  0.00033 |    0.05550 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07089 | -0.00595 |    0.04786 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06844 | -0.00225 |    0.04513 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08400 | -0.00939 |    0.05825 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07392 | -0.00661 |    0.05220 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08650 | -0.00348 |    0.06430 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07397 | -0.00348 |    0.05629 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17923 | -0.00212 |    0.11090 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06558 | -0.00250 |    0.04944 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05774 | -0.00678 |    0.04533 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07001 | -0.00725 |    0.05359 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05573 | -0.00391 |    0.04352 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06816 | -0.00526 |    0.05387 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06263 | -0.00365 |    0.04955 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08403 | -0.00437 |    0.06434 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05979 | -0.00729 |    0.04713 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04142 | -0.00310 |    0.03186 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03660 | -0.00645 |    0.02836 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02181 |  0.00006 |    0.01482 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40589 | -0.00001 |    0.28379 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:23:27,267 - Total sparsity: 0.00

2018-10-21 07:23:27,267 - --- validate (epoch=176)-----------
2018-10-21 07:23:27,268 - 10000 samples (128 per mini-batch)
2018-10-21 07:23:28,473 - Epoch: [176][   50/   78]    Loss 1.574631    Top1 88.828125    Top5 99.375000    
2018-10-21 07:23:29,110 - ==> Top1: 88.820    Top5: 99.430    Loss: 1.574

2018-10-21 07:23:29,111 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:23:29,112 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:23:29,125 - 

2018-10-21 07:23:29,125 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:23:30,838 - Epoch: [177][   50/  391]    Overall Loss 1.539052    Objective Loss 1.539052    Top1 92.593750    Top5 99.484375    LR 0.030000    Time 0.034197    
2018-10-21 07:23:32,412 - Epoch: [177][  100/  391]    Overall Loss 1.535166    Objective Loss 1.535166    Top1 93.007812    Top5 99.531250    LR 0.030000    Time 0.032807    
2018-10-21 07:23:34,018 - Epoch: [177][  150/  391]    Overall Loss 1.536384    Objective Loss 1.536384    Top1 92.864583    Top5 99.510417    LR 0.030000    Time 0.032563    
2018-10-21 07:23:35,578 - Epoch: [177][  200/  391]    Overall Loss 1.537405    Objective Loss 1.537405    Top1 92.726562    Top5 99.558594    LR 0.030000    Time 0.032210    
2018-10-21 07:23:37,113 - Epoch: [177][  250/  391]    Overall Loss 1.537273    Objective Loss 1.537273    Top1 92.756250    Top5 99.562500    LR 0.030000    Time 0.031901    
2018-10-21 07:23:38,634 - Epoch: [177][  300/  391]    Overall Loss 1.536724    Objective Loss 1.536724    Top1 92.799479    Top5 99.544271    LR 0.030000    Time 0.031644    
2018-10-21 07:23:40,142 - Epoch: [177][  350/  391]    Overall Loss 1.536457    Objective Loss 1.536457    Top1 92.830357    Top5 99.520089    LR 0.030000    Time 0.031424    
2018-10-21 07:23:41,525 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24275 |  0.00016 |    0.16137 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08394 | -0.00306 |    0.04851 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08227 |  0.00012 |    0.05554 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07078 | -0.00596 |    0.04775 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06833 | -0.00209 |    0.04506 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08384 | -0.00964 |    0.05831 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07377 | -0.00678 |    0.05197 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08632 | -0.00312 |    0.06429 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07384 | -0.00372 |    0.05622 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17892 | -0.00101 |    0.11035 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06557 | -0.00238 |    0.04945 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05777 | -0.00672 |    0.04540 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07006 | -0.00683 |    0.05361 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05571 | -0.00400 |    0.04346 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06806 | -0.00529 |    0.05373 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06259 | -0.00362 |    0.04951 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08382 | -0.00441 |    0.06425 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05977 | -0.00736 |    0.04714 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04144 | -0.00311 |    0.03189 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03664 | -0.00639 |    0.02839 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02178 |  0.00011 |    0.01481 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40579 | -0.00001 |    0.28385 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:23:41,525 - Total sparsity: 0.00

2018-10-21 07:23:41,525 - --- validate (epoch=177)-----------
2018-10-21 07:23:41,525 - 10000 samples (128 per mini-batch)
2018-10-21 07:23:42,697 - Epoch: [177][   50/   78]    Loss 1.580067    Top1 88.218750    Top5 99.343750    
2018-10-21 07:23:43,348 - ==> Top1: 88.130    Top5: 99.440    Loss: 1.581

2018-10-21 07:23:43,350 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:23:43,350 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:23:43,363 - 

2018-10-21 07:23:43,363 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:23:45,075 - Epoch: [178][   50/  391]    Overall Loss 1.532284    Objective Loss 1.532284    Top1 93.281250    Top5 99.578125    LR 0.030000    Time 0.034160    
2018-10-21 07:23:46,660 - Epoch: [178][  100/  391]    Overall Loss 1.536135    Objective Loss 1.536135    Top1 92.890625    Top5 99.554688    LR 0.030000    Time 0.032906    
2018-10-21 07:23:48,204 - Epoch: [178][  150/  391]    Overall Loss 1.535726    Objective Loss 1.535726    Top1 92.859375    Top5 99.562500    LR 0.030000    Time 0.032215    
2018-10-21 07:23:49,749 - Epoch: [178][  200/  391]    Overall Loss 1.535980    Objective Loss 1.535980    Top1 92.820312    Top5 99.574219    LR 0.030000    Time 0.031877    
2018-10-21 07:23:51,330 - Epoch: [178][  250/  391]    Overall Loss 1.535788    Objective Loss 1.535788    Top1 92.875000    Top5 99.565625    LR 0.030000    Time 0.031814    
2018-10-21 07:23:52,862 - Epoch: [178][  300/  391]    Overall Loss 1.536437    Objective Loss 1.536437    Top1 92.796875    Top5 99.533854    LR 0.030000    Time 0.031609    
2018-10-21 07:23:54,448 - Epoch: [178][  350/  391]    Overall Loss 1.536605    Objective Loss 1.536605    Top1 92.792411    Top5 99.533482    LR 0.030000    Time 0.031618    
2018-10-21 07:23:55,801 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24220 |  0.00015 |    0.16116 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08378 | -0.00311 |    0.04856 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08211 | -0.00003 |    0.05556 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07066 | -0.00567 |    0.04761 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06820 | -0.00204 |    0.04486 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08372 | -0.00963 |    0.05802 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07361 | -0.00692 |    0.05207 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08611 | -0.00352 |    0.06411 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07368 | -0.00402 |    0.05605 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17851 | -0.00142 |    0.10992 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06554 | -0.00229 |    0.04946 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05775 | -0.00675 |    0.04533 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07004 | -0.00648 |    0.05355 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05568 | -0.00384 |    0.04337 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06797 | -0.00511 |    0.05364 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06255 | -0.00351 |    0.04949 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08363 | -0.00406 |    0.06401 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05979 | -0.00726 |    0.04716 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04148 | -0.00305 |    0.03194 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03666 | -0.00643 |    0.02843 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02176 |  0.00012 |    0.01479 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40551 | -0.00001 |    0.28386 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:23:55,801 - Total sparsity: 0.00

2018-10-21 07:23:55,801 - --- validate (epoch=178)-----------
2018-10-21 07:23:55,802 - 10000 samples (128 per mini-batch)
2018-10-21 07:23:57,007 - Epoch: [178][   50/   78]    Loss 1.579188    Top1 88.359375    Top5 99.421875    
2018-10-21 07:23:57,804 - ==> Top1: 88.420    Top5: 99.390    Loss: 1.578

2018-10-21 07:23:57,806 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:23:57,806 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:23:57,823 - 

2018-10-21 07:23:57,823 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:23:59,540 - Epoch: [179][   50/  391]    Overall Loss 1.532538    Objective Loss 1.532538    Top1 93.453125    Top5 99.656250    LR 0.030000    Time 0.034260    
2018-10-21 07:24:01,109 - Epoch: [179][  100/  391]    Overall Loss 1.534847    Objective Loss 1.534847    Top1 93.101562    Top5 99.664062    LR 0.030000    Time 0.032790    
2018-10-21 07:24:02,697 - Epoch: [179][  150/  391]    Overall Loss 1.534756    Objective Loss 1.534756    Top1 93.104167    Top5 99.625000    LR 0.030000    Time 0.032431    
2018-10-21 07:24:04,266 - Epoch: [179][  200/  391]    Overall Loss 1.535743    Objective Loss 1.535743    Top1 92.972656    Top5 99.609375    LR 0.030000    Time 0.032157    
2018-10-21 07:24:05,796 - Epoch: [179][  250/  391]    Overall Loss 1.536421    Objective Loss 1.536421    Top1 92.903125    Top5 99.559375    LR 0.030000    Time 0.031838    
2018-10-21 07:24:07,313 - Epoch: [179][  300/  391]    Overall Loss 1.536398    Objective Loss 1.536398    Top1 92.908854    Top5 99.554688    LR 0.030000    Time 0.031580    
2018-10-21 07:24:08,866 - Epoch: [179][  350/  391]    Overall Loss 1.536461    Objective Loss 1.536461    Top1 92.888393    Top5 99.562500    LR 0.030000    Time 0.031496    
2018-10-21 07:24:10,244 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24186 | -0.00038 |    0.16147 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08374 | -0.00399 |    0.04873 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08209 |  0.00037 |    0.05548 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07058 | -0.00594 |    0.04768 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06814 | -0.00225 |    0.04490 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08371 | -0.00949 |    0.05805 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07352 | -0.00659 |    0.05193 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08604 | -0.00305 |    0.06395 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07361 | -0.00400 |    0.05612 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17826 | -0.00105 |    0.10975 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06560 | -0.00265 |    0.04955 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05783 | -0.00661 |    0.04547 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07005 | -0.00664 |    0.05357 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05571 | -0.00377 |    0.04344 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06787 | -0.00534 |    0.05363 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06252 | -0.00357 |    0.04948 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08347 | -0.00394 |    0.06380 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05979 | -0.00732 |    0.04717 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04152 | -0.00311 |    0.03196 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03670 | -0.00634 |    0.02844 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02173 |  0.00004 |    0.01478 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40547 | -0.00001 |    0.28400 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:24:10,244 - Total sparsity: 0.00

2018-10-21 07:24:10,245 - --- validate (epoch=179)-----------
2018-10-21 07:24:10,245 - 10000 samples (128 per mini-batch)
2018-10-21 07:24:11,638 - Epoch: [179][   50/   78]    Loss 1.585340    Top1 87.562500    Top5 99.406250    
2018-10-21 07:24:12,371 - ==> Top1: 87.810    Top5: 99.510    Loss: 1.583

2018-10-21 07:24:12,373 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:24:12,373 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:24:12,386 - 

2018-10-21 07:24:12,386 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:24:14,270 - Epoch: [180][   50/  391]    Overall Loss 1.534447    Objective Loss 1.534447    Top1 93.046875    Top5 99.609375    LR 0.030000    Time 0.037618    
2018-10-21 07:24:16,009 - Epoch: [180][  100/  391]    Overall Loss 1.535240    Objective Loss 1.535240    Top1 92.945312    Top5 99.570312    LR 0.030000    Time 0.036175    
2018-10-21 07:24:17,653 - Epoch: [180][  150/  391]    Overall Loss 1.535519    Objective Loss 1.535519    Top1 92.869792    Top5 99.567708    LR 0.030000    Time 0.035051    
2018-10-21 07:24:19,191 - Epoch: [180][  200/  391]    Overall Loss 1.537319    Objective Loss 1.537319    Top1 92.707031    Top5 99.554688    LR 0.030000    Time 0.033967    
2018-10-21 07:24:20,727 - Epoch: [180][  250/  391]    Overall Loss 1.538492    Objective Loss 1.538492    Top1 92.587500    Top5 99.543750    LR 0.030000    Time 0.033307    
2018-10-21 07:24:22,278 - Epoch: [180][  300/  391]    Overall Loss 1.537924    Objective Loss 1.537924    Top1 92.635417    Top5 99.546875    LR 0.030000    Time 0.032919    
2018-10-21 07:24:23,812 - Epoch: [180][  350/  391]    Overall Loss 1.538284    Objective Loss 1.538284    Top1 92.595982    Top5 99.549107    LR 0.030000    Time 0.032593    
2018-10-21 07:24:25,234 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24130 | -0.00268 |    0.16090 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08367 | -0.00378 |    0.04849 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08196 | -0.00006 |    0.05554 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07047 | -0.00617 |    0.04759 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06803 | -0.00213 |    0.04487 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08354 | -0.00985 |    0.05812 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07339 | -0.00664 |    0.05169 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08587 | -0.00306 |    0.06380 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07351 | -0.00392 |    0.05603 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17797 | -0.00109 |    0.10995 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06564 | -0.00242 |    0.04955 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05785 | -0.00673 |    0.04539 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07004 | -0.00680 |    0.05361 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05571 | -0.00374 |    0.04346 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06778 | -0.00519 |    0.05356 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06245 | -0.00365 |    0.04942 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08330 | -0.00397 |    0.06393 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05976 | -0.00734 |    0.04712 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04154 | -0.00310 |    0.03200 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03671 | -0.00640 |    0.02844 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02171 |  0.00007 |    0.01474 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40530 | -0.00001 |    0.28404 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:24:25,234 - Total sparsity: 0.00

2018-10-21 07:24:25,234 - --- validate (epoch=180)-----------
2018-10-21 07:24:25,235 - 10000 samples (128 per mini-batch)
2018-10-21 07:24:26,455 - Epoch: [180][   50/   78]    Loss 1.577355    Top1 88.500000    Top5 99.437500    
2018-10-21 07:24:27,101 - ==> Top1: 88.520    Top5: 99.470    Loss: 1.577

2018-10-21 07:24:27,103 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:24:27,103 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:24:27,118 - 

2018-10-21 07:24:27,118 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:24:28,823 - Epoch: [181][   50/  391]    Overall Loss 1.531291    Objective Loss 1.531291    Top1 93.328125    Top5 99.625000    LR 0.030000    Time 0.034032    
2018-10-21 07:24:30,364 - Epoch: [181][  100/  391]    Overall Loss 1.533182    Objective Loss 1.533182    Top1 93.203125    Top5 99.617188    LR 0.030000    Time 0.032402    
2018-10-21 07:24:31,939 - Epoch: [181][  150/  391]    Overall Loss 1.532424    Objective Loss 1.532424    Top1 93.229167    Top5 99.578125    LR 0.030000    Time 0.032086    
2018-10-21 07:24:33,482 - Epoch: [181][  200/  391]    Overall Loss 1.534002    Objective Loss 1.534002    Top1 93.074219    Top5 99.578125    LR 0.030000    Time 0.031764    
2018-10-21 07:24:35,012 - Epoch: [181][  250/  391]    Overall Loss 1.533612    Objective Loss 1.533612    Top1 93.093750    Top5 99.568750    LR 0.030000    Time 0.031522    
2018-10-21 07:24:36,537 - Epoch: [181][  300/  391]    Overall Loss 1.534303    Objective Loss 1.534303    Top1 92.994792    Top5 99.554688    LR 0.030000    Time 0.031346    
2018-10-21 07:24:38,101 - Epoch: [181][  350/  391]    Overall Loss 1.535023    Objective Loss 1.535023    Top1 92.915179    Top5 99.526786    LR 0.030000    Time 0.031327    
2018-10-21 07:24:39,451 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24096 | -0.00361 |    0.16057 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08360 | -0.00355 |    0.04845 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08188 | -0.00016 |    0.05546 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07043 | -0.00632 |    0.04760 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06796 | -0.00238 |    0.04480 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08349 | -0.00943 |    0.05814 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07328 | -0.00708 |    0.05168 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08574 | -0.00329 |    0.06371 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07340 | -0.00410 |    0.05607 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17761 | -0.00173 |    0.10961 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06562 | -0.00217 |    0.04950 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05786 | -0.00679 |    0.04544 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07006 | -0.00673 |    0.05368 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05573 | -0.00389 |    0.04346 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06769 | -0.00521 |    0.05345 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06241 | -0.00366 |    0.04936 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08317 | -0.00382 |    0.06381 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05975 | -0.00730 |    0.04711 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04156 | -0.00310 |    0.03201 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03670 | -0.00649 |    0.02846 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02168 |  0.00007 |    0.01472 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40521 | -0.00001 |    0.28404 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:24:39,451 - Total sparsity: 0.00

2018-10-21 07:24:39,451 - --- validate (epoch=181)-----------
2018-10-21 07:24:39,451 - 10000 samples (128 per mini-batch)
2018-10-21 07:24:40,676 - Epoch: [181][   50/   78]    Loss 1.586744    Top1 87.593750    Top5 99.453125    
2018-10-21 07:24:41,326 - ==> Top1: 87.580    Top5: 99.500    Loss: 1.587

2018-10-21 07:24:41,328 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:24:41,328 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:24:41,342 - 

2018-10-21 07:24:41,343 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:24:43,031 - Epoch: [182][   50/  391]    Overall Loss 1.537291    Objective Loss 1.537291    Top1 92.734375    Top5 99.703125    LR 0.030000    Time 0.033708    
2018-10-21 07:24:44,595 - Epoch: [182][  100/  391]    Overall Loss 1.535428    Objective Loss 1.535428    Top1 92.890625    Top5 99.593750    LR 0.030000    Time 0.032466    
2018-10-21 07:24:46,194 - Epoch: [182][  150/  391]    Overall Loss 1.535488    Objective Loss 1.535488    Top1 92.869792    Top5 99.604167    LR 0.030000    Time 0.032285    
2018-10-21 07:24:47,730 - Epoch: [182][  200/  391]    Overall Loss 1.535657    Objective Loss 1.535657    Top1 92.847656    Top5 99.640625    LR 0.030000    Time 0.031881    
2018-10-21 07:24:49,266 - Epoch: [182][  250/  391]    Overall Loss 1.535641    Objective Loss 1.535641    Top1 92.875000    Top5 99.618750    LR 0.030000    Time 0.031642    
2018-10-21 07:24:50,786 - Epoch: [182][  300/  391]    Overall Loss 1.536592    Objective Loss 1.536592    Top1 92.786458    Top5 99.593750    LR 0.030000    Time 0.031426    
2018-10-21 07:24:52,289 - Epoch: [182][  350/  391]    Overall Loss 1.536610    Objective Loss 1.536610    Top1 92.772321    Top5 99.584821    LR 0.030000    Time 0.031221    
2018-10-21 07:24:53,669 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24055 |  0.00090 |    0.16026 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08351 | -0.00389 |    0.04872 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08178 |  0.00027 |    0.05525 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07037 | -0.00624 |    0.04753 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06784 | -0.00263 |    0.04472 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08324 | -0.01034 |    0.05808 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07319 | -0.00679 |    0.05156 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08556 | -0.00393 |    0.06366 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07329 | -0.00431 |    0.05602 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17722 | -0.00192 |    0.10897 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06557 | -0.00241 |    0.04943 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05784 | -0.00684 |    0.04545 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07007 | -0.00685 |    0.05375 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05575 | -0.00401 |    0.04348 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06760 | -0.00527 |    0.05340 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 | -0.00350 |    0.04934 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08303 | -0.00364 |    0.06360 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05973 | -0.00739 |    0.04713 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04159 | -0.00314 |    0.03205 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03674 | -0.00635 |    0.02848 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02165 |  0.00007 |    0.01469 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40524 | -0.00001 |    0.28420 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:24:53,669 - Total sparsity: 0.00

2018-10-21 07:24:53,670 - --- validate (epoch=182)-----------
2018-10-21 07:24:53,670 - 10000 samples (128 per mini-batch)
2018-10-21 07:24:54,890 - Epoch: [182][   50/   78]    Loss 1.583234    Top1 87.765625    Top5 99.468750    
2018-10-21 07:24:55,570 - ==> Top1: 87.650    Top5: 99.480    Loss: 1.585

2018-10-21 07:24:55,572 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:24:55,573 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:24:55,586 - 

2018-10-21 07:24:55,587 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:24:57,238 - Epoch: [183][   50/  391]    Overall Loss 1.531737    Objective Loss 1.531737    Top1 93.375000    Top5 99.625000    LR 0.030000    Time 0.032960    
2018-10-21 07:24:58,778 - Epoch: [183][  100/  391]    Overall Loss 1.535757    Objective Loss 1.535757    Top1 92.882812    Top5 99.617188    LR 0.030000    Time 0.031857    
2018-10-21 07:25:00,316 - Epoch: [183][  150/  391]    Overall Loss 1.536360    Objective Loss 1.536360    Top1 92.833333    Top5 99.552083    LR 0.030000    Time 0.031475    
2018-10-21 07:25:01,842 - Epoch: [183][  200/  391]    Overall Loss 1.537829    Objective Loss 1.537829    Top1 92.707031    Top5 99.527344    LR 0.030000    Time 0.031227    
2018-10-21 07:25:03,374 - Epoch: [183][  250/  391]    Overall Loss 1.537911    Objective Loss 1.537911    Top1 92.681250    Top5 99.528125    LR 0.030000    Time 0.031099    
2018-10-21 07:25:04,931 - Epoch: [183][  300/  391]    Overall Loss 1.538141    Objective Loss 1.538141    Top1 92.627604    Top5 99.531250    LR 0.030000    Time 0.031098    
2018-10-21 07:25:06,456 - Epoch: [183][  350/  391]    Overall Loss 1.538402    Objective Loss 1.538402    Top1 92.591518    Top5 99.537946    LR 0.030000    Time 0.031006    
2018-10-21 07:25:07,822 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24016 |  0.00055 |    0.15887 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08353 | -0.00324 |    0.04864 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08175 |  0.00091 |    0.05528 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07030 | -0.00613 |    0.04757 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06777 | -0.00236 |    0.04446 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08321 | -0.00975 |    0.05809 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07310 | -0.00653 |    0.05144 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08547 | -0.00373 |    0.06361 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07329 | -0.00393 |    0.05597 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17701 | -0.00144 |    0.10902 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06564 | -0.00253 |    0.04959 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05789 | -0.00678 |    0.04550 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07015 | -0.00689 |    0.05382 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05583 | -0.00390 |    0.04350 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06757 | -0.00518 |    0.05335 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 | -0.00352 |    0.04935 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08294 | -0.00369 |    0.06342 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05977 | -0.00737 |    0.04718 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04167 | -0.00312 |    0.03211 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03680 | -0.00632 |    0.02854 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02165 |  0.00010 |    0.01470 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40523 | -0.00001 |    0.28436 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:25:07,822 - Total sparsity: 0.00

2018-10-21 07:25:07,822 - --- validate (epoch=183)-----------
2018-10-21 07:25:07,822 - 10000 samples (128 per mini-batch)
2018-10-21 07:25:09,017 - Epoch: [183][   50/   78]    Loss 1.579065    Top1 88.234375    Top5 99.375000    
2018-10-21 07:25:09,657 - ==> Top1: 88.530    Top5: 99.470    Loss: 1.576

2018-10-21 07:25:09,658 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:25:09,658 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:25:09,671 - 

2018-10-21 07:25:09,671 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:25:11,390 - Epoch: [184][   50/  391]    Overall Loss 1.533105    Objective Loss 1.533105    Top1 93.203125    Top5 99.609375    LR 0.030000    Time 0.034307    
2018-10-21 07:25:12,956 - Epoch: [184][  100/  391]    Overall Loss 1.534608    Objective Loss 1.534608    Top1 93.031250    Top5 99.632812    LR 0.030000    Time 0.032796    
2018-10-21 07:25:14,538 - Epoch: [184][  150/  391]    Overall Loss 1.536002    Objective Loss 1.536002    Top1 92.885417    Top5 99.583333    LR 0.030000    Time 0.032389    
2018-10-21 07:25:16,082 - Epoch: [184][  200/  391]    Overall Loss 1.535356    Objective Loss 1.535356    Top1 92.933594    Top5 99.605469    LR 0.030000    Time 0.032001    
2018-10-21 07:25:17,648 - Epoch: [184][  250/  391]    Overall Loss 1.536546    Objective Loss 1.536546    Top1 92.796875    Top5 99.612500    LR 0.030000    Time 0.031855    
2018-10-21 07:25:19,243 - Epoch: [184][  300/  391]    Overall Loss 1.536243    Objective Loss 1.536243    Top1 92.815104    Top5 99.593750    LR 0.030000    Time 0.031852    
2018-10-21 07:25:20,792 - Epoch: [184][  350/  391]    Overall Loss 1.536480    Objective Loss 1.536480    Top1 92.794643    Top5 99.598214    LR 0.030000    Time 0.031720    
2018-10-21 07:25:22,211 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23975 | -0.00049 |    0.15871 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08347 | -0.00319 |    0.04874 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08166 |  0.00088 |    0.05533 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07020 | -0.00660 |    0.04757 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06767 | -0.00215 |    0.04433 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08319 | -0.01013 |    0.05816 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07295 | -0.00720 |    0.05135 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08533 | -0.00362 |    0.06351 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07320 | -0.00437 |    0.05584 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17669 | -0.00042 |    0.10829 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06565 | -0.00230 |    0.04960 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05792 | -0.00683 |    0.04554 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07015 | -0.00711 |    0.05377 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05588 | -0.00401 |    0.04369 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06752 | -0.00524 |    0.05331 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06235 | -0.00364 |    0.04935 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08280 | -0.00395 |    0.06345 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05979 | -0.00744 |    0.04721 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04171 | -0.00319 |    0.03214 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03682 | -0.00631 |    0.02859 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02162 |  0.00008 |    0.01468 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40532 | -0.00001 |    0.28450 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:25:22,211 - Total sparsity: 0.00

2018-10-21 07:25:22,211 - --- validate (epoch=184)-----------
2018-10-21 07:25:22,212 - 10000 samples (128 per mini-batch)
2018-10-21 07:25:23,415 - Epoch: [184][   50/   78]    Loss 1.581973    Top1 88.125000    Top5 99.421875    
2018-10-21 07:25:24,060 - ==> Top1: 88.210    Top5: 99.460    Loss: 1.581

2018-10-21 07:25:24,061 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:25:24,062 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:25:24,074 - 

2018-10-21 07:25:24,075 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:25:25,966 - Epoch: [185][   50/  391]    Overall Loss 1.532694    Objective Loss 1.532694    Top1 93.093750    Top5 99.593750    LR 0.030000    Time 0.037757    
2018-10-21 07:25:27,729 - Epoch: [185][  100/  391]    Overall Loss 1.532049    Objective Loss 1.532049    Top1 93.250000    Top5 99.578125    LR 0.030000    Time 0.036486    
2018-10-21 07:25:29,475 - Epoch: [185][  150/  391]    Overall Loss 1.532445    Objective Loss 1.532445    Top1 93.171875    Top5 99.578125    LR 0.030000    Time 0.035947    
2018-10-21 07:25:31,192 - Epoch: [185][  200/  391]    Overall Loss 1.533340    Objective Loss 1.533340    Top1 93.074219    Top5 99.550781    LR 0.030000    Time 0.035532    
2018-10-21 07:25:32,974 - Epoch: [185][  250/  391]    Overall Loss 1.534089    Objective Loss 1.534089    Top1 93.012500    Top5 99.537500    LR 0.030000    Time 0.035543    
2018-10-21 07:25:34,785 - Epoch: [185][  300/  391]    Overall Loss 1.535402    Objective Loss 1.535402    Top1 92.906250    Top5 99.536458    LR 0.030000    Time 0.035649    
2018-10-21 07:25:36,392 - Epoch: [185][  350/  391]    Overall Loss 1.536712    Objective Loss 1.536712    Top1 92.796875    Top5 99.520089    LR 0.030000    Time 0.035141    
2018-10-21 07:25:37,801 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23936 | -0.00199 |    0.15871 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08347 | -0.00316 |    0.04852 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08162 |  0.00093 |    0.05533 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07022 | -0.00632 |    0.04766 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06763 | -0.00198 |    0.04427 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08318 | -0.00976 |    0.05806 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07295 | -0.00685 |    0.05137 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08520 | -0.00346 |    0.06342 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07314 | -0.00385 |    0.05580 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17645 | -0.00160 |    0.10860 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06564 | -0.00230 |    0.04952 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05791 | -0.00697 |    0.04559 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07023 | -0.00677 |    0.05378 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05593 | -0.00408 |    0.04376 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06749 | -0.00521 |    0.05325 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 | -0.00354 |    0.04934 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08266 | -0.00377 |    0.06342 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05982 | -0.00746 |    0.04724 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04176 | -0.00320 |    0.03218 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03684 | -0.00638 |    0.02860 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02161 |  0.00002 |    0.01468 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40538 | -0.00001 |    0.28467 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:25:37,802 - Total sparsity: 0.00

2018-10-21 07:25:37,802 - --- validate (epoch=185)-----------
2018-10-21 07:25:37,802 - 10000 samples (128 per mini-batch)
2018-10-21 07:25:38,959 - Epoch: [185][   50/   78]    Loss 1.579919    Top1 88.218750    Top5 99.359375    
2018-10-21 07:25:39,588 - ==> Top1: 87.810    Top5: 99.420    Loss: 1.582

2018-10-21 07:25:39,591 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:25:39,591 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:25:39,604 - 

2018-10-21 07:25:39,604 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:25:41,329 - Epoch: [186][   50/  391]    Overall Loss 1.529310    Objective Loss 1.529310    Top1 93.406250    Top5 99.562500    LR 0.030000    Time 0.034423    
2018-10-21 07:25:42,886 - Epoch: [186][  100/  391]    Overall Loss 1.533411    Objective Loss 1.533411    Top1 93.007812    Top5 99.585938    LR 0.030000    Time 0.032755    
2018-10-21 07:25:44,465 - Epoch: [186][  150/  391]    Overall Loss 1.534700    Objective Loss 1.534700    Top1 92.906250    Top5 99.593750    LR 0.030000    Time 0.032349    
2018-10-21 07:25:46,026 - Epoch: [186][  200/  391]    Overall Loss 1.535070    Objective Loss 1.535070    Top1 92.910156    Top5 99.625000    LR 0.030000    Time 0.032056    
2018-10-21 07:25:47,607 - Epoch: [186][  250/  391]    Overall Loss 1.535117    Objective Loss 1.535117    Top1 92.909375    Top5 99.628125    LR 0.030000    Time 0.031959    
2018-10-21 07:25:49,222 - Epoch: [186][  300/  391]    Overall Loss 1.535623    Objective Loss 1.535623    Top1 92.864583    Top5 99.619792    LR 0.030000    Time 0.032005    
2018-10-21 07:25:50,788 - Epoch: [186][  350/  391]    Overall Loss 1.535818    Objective Loss 1.535818    Top1 92.848214    Top5 99.618304    LR 0.030000    Time 0.031901    
2018-10-21 07:25:52,242 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23900 | -0.00252 |    0.15867 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08348 | -0.00350 |    0.04870 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08162 |  0.00148 |    0.05531 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07019 | -0.00680 |    0.04754 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06764 | -0.00190 |    0.04432 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08315 | -0.00968 |    0.05804 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07292 | -0.00714 |    0.05135 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08512 | -0.00350 |    0.06344 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07309 | -0.00387 |    0.05573 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17632 | -0.00062 |    0.10846 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06564 | -0.00234 |    0.04950 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05792 | -0.00703 |    0.04565 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07025 | -0.00654 |    0.05385 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05597 | -0.00406 |    0.04385 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06749 | -0.00488 |    0.05322 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06236 | -0.00364 |    0.04936 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08256 | -0.00385 |    0.06319 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05986 | -0.00734 |    0.04726 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04181 | -0.00319 |    0.03220 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03683 | -0.00652 |    0.02864 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02158 |  0.00001 |    0.01467 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40538 | -0.00001 |    0.28476 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:25:52,242 - Total sparsity: 0.00

2018-10-21 07:25:52,242 - --- validate (epoch=186)-----------
2018-10-21 07:25:52,243 - 10000 samples (128 per mini-batch)
2018-10-21 07:25:53,624 - Epoch: [186][   50/   78]    Loss 1.592411    Top1 87.156250    Top5 99.265625    
2018-10-21 07:25:54,364 - ==> Top1: 87.110    Top5: 99.380    Loss: 1.591

2018-10-21 07:25:54,366 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:25:54,367 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:25:54,389 - 

2018-10-21 07:25:54,389 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:25:56,118 - Epoch: [187][   50/  391]    Overall Loss 1.537293    Objective Loss 1.537293    Top1 92.593750    Top5 99.640625    LR 0.030000    Time 0.034509    
2018-10-21 07:25:57,717 - Epoch: [187][  100/  391]    Overall Loss 1.538933    Objective Loss 1.538933    Top1 92.468750    Top5 99.648438    LR 0.030000    Time 0.033213    
2018-10-21 07:25:59,275 - Epoch: [187][  150/  391]    Overall Loss 1.537623    Objective Loss 1.537623    Top1 92.645833    Top5 99.619792    LR 0.030000    Time 0.032514    
2018-10-21 07:26:00,822 - Epoch: [187][  200/  391]    Overall Loss 1.536508    Objective Loss 1.536508    Top1 92.773438    Top5 99.628906    LR 0.030000    Time 0.032112    
2018-10-21 07:26:02,401 - Epoch: [187][  250/  391]    Overall Loss 1.536286    Objective Loss 1.536286    Top1 92.790625    Top5 99.609375    LR 0.030000    Time 0.031996    
2018-10-21 07:26:03,930 - Epoch: [187][  300/  391]    Overall Loss 1.536039    Objective Loss 1.536039    Top1 92.848958    Top5 99.593750    LR 0.030000    Time 0.031753    
2018-10-21 07:26:05,439 - Epoch: [187][  350/  391]    Overall Loss 1.535976    Objective Loss 1.535976    Top1 92.881696    Top5 99.582589    LR 0.030000    Time 0.031520    
2018-10-21 07:26:06,831 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23876 | -0.00191 |    0.15795 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08352 | -0.00321 |    0.04866 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08162 |  0.00093 |    0.05536 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07012 | -0.00749 |    0.04761 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06759 | -0.00242 |    0.04432 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08309 | -0.00981 |    0.05798 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07297 | -0.00665 |    0.05154 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08507 | -0.00324 |    0.06342 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07305 | -0.00371 |    0.05569 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17603 | -0.00065 |    0.10844 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06567 | -0.00261 |    0.04956 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05795 | -0.00715 |    0.04571 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07022 | -0.00680 |    0.05381 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05599 | -0.00387 |    0.04382 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06743 | -0.00507 |    0.05322 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 | -0.00349 |    0.04940 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08244 | -0.00433 |    0.06307 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05988 | -0.00740 |    0.04728 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04186 | -0.00322 |    0.03226 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03688 | -0.00644 |    0.02868 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02158 |  0.00004 |    0.01469 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40557 | -0.00001 |    0.28492 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:26:06,831 - Total sparsity: 0.00

2018-10-21 07:26:06,831 - --- validate (epoch=187)-----------
2018-10-21 07:26:06,832 - 10000 samples (128 per mini-batch)
2018-10-21 07:26:08,012 - Epoch: [187][   50/   78]    Loss 1.584841    Top1 87.703125    Top5 99.281250    
2018-10-21 07:26:08,658 - ==> Top1: 87.420    Top5: 99.280    Loss: 1.586

2018-10-21 07:26:08,659 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:26:08,660 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:26:08,671 - 

2018-10-21 07:26:08,671 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:26:10,363 - Epoch: [188][   50/  391]    Overall Loss 1.529102    Objective Loss 1.529102    Top1 93.640625    Top5 99.640625    LR 0.030000    Time 0.033762    
2018-10-21 07:26:11,980 - Epoch: [188][  100/  391]    Overall Loss 1.530979    Objective Loss 1.530979    Top1 93.406250    Top5 99.609375    LR 0.030000    Time 0.033032    
2018-10-21 07:26:13,507 - Epoch: [188][  150/  391]    Overall Loss 1.533062    Objective Loss 1.533062    Top1 93.156250    Top5 99.557292    LR 0.030000    Time 0.032179    
2018-10-21 07:26:15,030 - Epoch: [188][  200/  391]    Overall Loss 1.534762    Objective Loss 1.534762    Top1 92.996094    Top5 99.550781    LR 0.030000    Time 0.031736    
2018-10-21 07:26:16,562 - Epoch: [188][  250/  391]    Overall Loss 1.535496    Objective Loss 1.535496    Top1 92.937500    Top5 99.553125    LR 0.030000    Time 0.031507    
2018-10-21 07:26:18,111 - Epoch: [188][  300/  391]    Overall Loss 1.535575    Objective Loss 1.535575    Top1 92.932292    Top5 99.578125    LR 0.030000    Time 0.031412    
2018-10-21 07:26:19,688 - Epoch: [188][  350/  391]    Overall Loss 1.537124    Objective Loss 1.537124    Top1 92.776786    Top5 99.560268    LR 0.030000    Time 0.031424    
2018-10-21 07:26:21,051 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23845 | -0.00181 |    0.15743 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08350 | -0.00320 |    0.04862 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08159 |  0.00090 |    0.05513 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07012 | -0.00694 |    0.04744 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06752 | -0.00269 |    0.04420 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08314 | -0.00966 |    0.05808 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07302 | -0.00648 |    0.05150 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08502 | -0.00306 |    0.06332 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07303 | -0.00361 |    0.05564 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17598 | -0.00051 |    0.10852 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06578 | -0.00247 |    0.04970 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05805 | -0.00701 |    0.04579 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07024 | -0.00695 |    0.05384 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05602 | -0.00399 |    0.04381 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06744 | -0.00519 |    0.05326 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06241 | -0.00355 |    0.04944 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08231 | -0.00435 |    0.06306 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05993 | -0.00742 |    0.04733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04194 | -0.00329 |    0.03235 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03693 | -0.00655 |    0.02872 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02158 |  0.00009 |    0.01469 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40557 | -0.00001 |    0.28499 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:26:21,051 - Total sparsity: 0.00

2018-10-21 07:26:21,052 - --- validate (epoch=188)-----------
2018-10-21 07:26:21,052 - 10000 samples (128 per mini-batch)
2018-10-21 07:26:22,260 - Epoch: [188][   50/   78]    Loss 1.586582    Top1 87.453125    Top5 99.140625    
2018-10-21 07:26:22,888 - ==> Top1: 87.720    Top5: 99.200    Loss: 1.584

2018-10-21 07:26:22,890 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:26:22,890 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:26:22,903 - 

2018-10-21 07:26:22,904 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:26:24,810 - Epoch: [189][   50/  391]    Overall Loss 1.531245    Objective Loss 1.531245    Top1 93.578125    Top5 99.656250    LR 0.030000    Time 0.038055    
2018-10-21 07:26:26,545 - Epoch: [189][  100/  391]    Overall Loss 1.532308    Objective Loss 1.532308    Top1 93.382812    Top5 99.578125    LR 0.030000    Time 0.036355    
2018-10-21 07:26:28,276 - Epoch: [189][  150/  391]    Overall Loss 1.534588    Objective Loss 1.534588    Top1 93.083333    Top5 99.520833    LR 0.030000    Time 0.035761    
2018-10-21 07:26:30,028 - Epoch: [189][  200/  391]    Overall Loss 1.535327    Objective Loss 1.535327    Top1 92.992188    Top5 99.535156    LR 0.030000    Time 0.035572    
2018-10-21 07:26:31,735 - Epoch: [189][  250/  391]    Overall Loss 1.534785    Objective Loss 1.534785    Top1 93.040625    Top5 99.565625    LR 0.030000    Time 0.035276    
2018-10-21 07:26:33,448 - Epoch: [189][  300/  391]    Overall Loss 1.535143    Objective Loss 1.535143    Top1 92.971354    Top5 99.549479    LR 0.030000    Time 0.035098    
2018-10-21 07:26:35,149 - Epoch: [189][  350/  391]    Overall Loss 1.535353    Objective Loss 1.535353    Top1 92.955357    Top5 99.566964    LR 0.030000    Time 0.034935    
2018-10-21 07:26:36,699 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23818 |  0.00035 |    0.15747 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08340 | -0.00335 |    0.04854 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08149 |  0.00096 |    0.05523 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07009 | -0.00651 |    0.04746 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06745 | -0.00263 |    0.04415 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08310 | -0.00958 |    0.05801 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07296 | -0.00673 |    0.05165 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08492 | -0.00309 |    0.06326 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07291 | -0.00392 |    0.05564 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17564 | -0.00120 |    0.10839 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06576 | -0.00250 |    0.04970 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05802 | -0.00724 |    0.04580 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07022 | -0.00681 |    0.05374 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05600 | -0.00416 |    0.04374 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06738 | -0.00511 |    0.05323 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06239 | -0.00346 |    0.04941 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08213 | -0.00452 |    0.06304 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05993 | -0.00735 |    0.04730 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04197 | -0.00320 |    0.03237 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03697 | -0.00647 |    0.02876 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02157 |  0.00008 |    0.01467 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40564 | -0.00001 |    0.28515 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:26:36,699 - Total sparsity: 0.00

2018-10-21 07:26:36,699 - --- validate (epoch=189)-----------
2018-10-21 07:26:36,700 - 10000 samples (128 per mini-batch)
2018-10-21 07:26:37,891 - Epoch: [189][   50/   78]    Loss 1.580949    Top1 88.312500    Top5 99.453125    
2018-10-21 07:26:38,528 - ==> Top1: 88.330    Top5: 99.390    Loss: 1.581

2018-10-21 07:26:38,529 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:26:38,529 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:26:38,542 - 

2018-10-21 07:26:38,542 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:26:40,202 - Epoch: [190][   50/  391]    Overall Loss 1.530309    Objective Loss 1.530309    Top1 93.281250    Top5 99.593750    LR 0.030000    Time 0.033134    
2018-10-21 07:26:41,775 - Epoch: [190][  100/  391]    Overall Loss 1.530148    Objective Loss 1.530148    Top1 93.421875    Top5 99.562500    LR 0.030000    Time 0.032276    
2018-10-21 07:26:43,344 - Epoch: [190][  150/  391]    Overall Loss 1.533505    Objective Loss 1.533505    Top1 93.166667    Top5 99.536458    LR 0.030000    Time 0.031953    
2018-10-21 07:26:44,889 - Epoch: [190][  200/  391]    Overall Loss 1.533972    Objective Loss 1.533972    Top1 93.125000    Top5 99.542969    LR 0.030000    Time 0.031677    
2018-10-21 07:26:46,427 - Epoch: [190][  250/  391]    Overall Loss 1.534105    Objective Loss 1.534105    Top1 93.096875    Top5 99.537500    LR 0.030000    Time 0.031485    
2018-10-21 07:26:47,962 - Epoch: [190][  300/  391]    Overall Loss 1.534738    Objective Loss 1.534738    Top1 93.020833    Top5 99.531250    LR 0.030000    Time 0.031345    
2018-10-21 07:26:49,501 - Epoch: [190][  350/  391]    Overall Loss 1.534752    Objective Loss 1.534752    Top1 93.017857    Top5 99.551339    LR 0.030000    Time 0.031259    
2018-10-21 07:26:50,893 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23764 | -0.00233 |    0.15760 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08328 | -0.00368 |    0.04846 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08136 |  0.00125 |    0.05497 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07005 | -0.00674 |    0.04740 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06741 | -0.00219 |    0.04426 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08299 | -0.00973 |    0.05794 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07292 | -0.00645 |    0.05162 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08484 | -0.00254 |    0.06327 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07283 | -0.00366 |    0.05556 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17529 | -0.00151 |    0.10796 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06572 | -0.00223 |    0.04958 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05802 | -0.00723 |    0.04577 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07018 | -0.00685 |    0.05375 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05599 | -0.00424 |    0.04377 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06732 | -0.00513 |    0.05312 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 | -0.00340 |    0.04939 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08194 | -0.00450 |    0.06277 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05992 | -0.00733 |    0.04731 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04199 | -0.00330 |    0.03238 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03700 | -0.00642 |    0.02879 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02156 |  0.00008 |    0.01465 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40563 | -0.00001 |    0.28526 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:26:50,893 - Total sparsity: 0.00

2018-10-21 07:26:50,894 - --- validate (epoch=190)-----------
2018-10-21 07:26:50,894 - 10000 samples (128 per mini-batch)
2018-10-21 07:26:52,112 - Epoch: [190][   50/   78]    Loss 1.572166    Top1 89.125000    Top5 99.421875    
2018-10-21 07:26:52,749 - ==> Top1: 88.940    Top5: 99.510    Loss: 1.573

2018-10-21 07:26:52,751 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:26:52,751 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:26:52,766 - 

2018-10-21 07:26:52,766 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:26:54,689 - Epoch: [191][   50/  391]    Overall Loss 1.527354    Objective Loss 1.527354    Top1 93.812500    Top5 99.609375    LR 0.030000    Time 0.038399    
2018-10-21 07:26:56,466 - Epoch: [191][  100/  391]    Overall Loss 1.530824    Objective Loss 1.530824    Top1 93.390625    Top5 99.609375    LR 0.030000    Time 0.036945    
2018-10-21 07:26:58,118 - Epoch: [191][  150/  391]    Overall Loss 1.532760    Objective Loss 1.532760    Top1 93.250000    Top5 99.567708    LR 0.030000    Time 0.035626    
2018-10-21 07:26:59,680 - Epoch: [191][  200/  391]    Overall Loss 1.533603    Objective Loss 1.533603    Top1 93.167969    Top5 99.566406    LR 0.030000    Time 0.034519    
2018-10-21 07:27:01,246 - Epoch: [191][  250/  391]    Overall Loss 1.533608    Objective Loss 1.533608    Top1 93.171875    Top5 99.600000    LR 0.030000    Time 0.033870    
2018-10-21 07:27:02,806 - Epoch: [191][  300/  391]    Overall Loss 1.534083    Objective Loss 1.534083    Top1 93.130208    Top5 99.575521    LR 0.030000    Time 0.033415    
2018-10-21 07:27:04,352 - Epoch: [191][  350/  391]    Overall Loss 1.535026    Objective Loss 1.535026    Top1 93.011161    Top5 99.566964    LR 0.030000    Time 0.033053    
2018-10-21 07:27:05,751 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23744 | -0.00042 |    0.15674 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08330 | -0.00414 |    0.04862 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08136 |  0.00143 |    0.05505 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07010 | -0.00697 |    0.04736 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06739 | -0.00219 |    0.04422 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08301 | -0.00980 |    0.05803 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07297 | -0.00631 |    0.05145 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08479 | -0.00260 |    0.06333 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07283 | -0.00365 |    0.05550 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17508 | -0.00087 |    0.10767 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06575 | -0.00206 |    0.04969 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05805 | -0.00744 |    0.04579 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07025 | -0.00674 |    0.05383 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05608 | -0.00402 |    0.04380 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06729 | -0.00519 |    0.05317 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 | -0.00355 |    0.04938 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08181 | -0.00460 |    0.06269 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05996 | -0.00718 |    0.04735 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04204 | -0.00325 |    0.03243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03705 | -0.00644 |    0.02883 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02155 |  0.00013 |    0.01466 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40553 | -0.00001 |    0.28528 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:27:05,751 - Total sparsity: 0.00

2018-10-21 07:27:05,752 - --- validate (epoch=191)-----------
2018-10-21 07:27:05,752 - 10000 samples (128 per mini-batch)
2018-10-21 07:27:06,931 - Epoch: [191][   50/   78]    Loss 1.585734    Top1 87.718750    Top5 99.125000    
2018-10-21 07:27:07,572 - ==> Top1: 87.900    Top5: 99.230    Loss: 1.583

2018-10-21 07:27:07,574 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:27:07,574 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:27:07,587 - 

2018-10-21 07:27:07,588 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:27:09,277 - Epoch: [192][   50/  391]    Overall Loss 1.530743    Objective Loss 1.530743    Top1 93.531250    Top5 99.531250    LR 0.030000    Time 0.033722    
2018-10-21 07:27:10,789 - Epoch: [192][  100/  391]    Overall Loss 1.531390    Objective Loss 1.531390    Top1 93.343750    Top5 99.554688    LR 0.030000    Time 0.031950    
2018-10-21 07:27:12,323 - Epoch: [192][  150/  391]    Overall Loss 1.532000    Objective Loss 1.532000    Top1 93.302083    Top5 99.567708    LR 0.030000    Time 0.031512    
2018-10-21 07:27:13,839 - Epoch: [192][  200/  391]    Overall Loss 1.532717    Objective Loss 1.532717    Top1 93.226562    Top5 99.582031    LR 0.030000    Time 0.031203    
2018-10-21 07:27:15,370 - Epoch: [192][  250/  391]    Overall Loss 1.533440    Objective Loss 1.533440    Top1 93.165625    Top5 99.584375    LR 0.030000    Time 0.031078    
2018-10-21 07:27:16,865 - Epoch: [192][  300/  391]    Overall Loss 1.533817    Objective Loss 1.533817    Top1 93.098958    Top5 99.604167    LR 0.030000    Time 0.030877    
2018-10-21 07:27:18,388 - Epoch: [192][  350/  391]    Overall Loss 1.533560    Objective Loss 1.533560    Top1 93.113839    Top5 99.602679    LR 0.030000    Time 0.030810    
2018-10-21 07:27:19,757 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23702 | -0.00019 |    0.15659 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08328 | -0.00419 |    0.04847 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08134 |  0.00103 |    0.05507 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07002 | -0.00736 |    0.04739 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06731 | -0.00188 |    0.04406 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08294 | -0.00989 |    0.05820 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07288 | -0.00679 |    0.05148 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08472 | -0.00327 |    0.06332 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07276 | -0.00402 |    0.05545 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17487 | -0.00080 |    0.10762 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06577 | -0.00205 |    0.04961 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05808 | -0.00734 |    0.04584 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07028 | -0.00637 |    0.05374 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05610 | -0.00397 |    0.04383 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06726 | -0.00518 |    0.05316 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 | -0.00343 |    0.04937 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08169 | -0.00468 |    0.06252 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05999 | -0.00720 |    0.04737 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04209 | -0.00327 |    0.03248 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03710 | -0.00645 |    0.02886 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02154 |  0.00020 |    0.01467 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40540 | -0.00001 |    0.28534 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:27:19,757 - Total sparsity: 0.00

2018-10-21 07:27:19,757 - --- validate (epoch=192)-----------
2018-10-21 07:27:19,757 - 10000 samples (128 per mini-batch)
2018-10-21 07:27:20,948 - Epoch: [192][   50/   78]    Loss 1.578572    Top1 88.625000    Top5 99.500000    
2018-10-21 07:27:21,592 - ==> Top1: 88.540    Top5: 99.610    Loss: 1.578

2018-10-21 07:27:21,594 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:27:21,594 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:27:21,607 - 

2018-10-21 07:27:21,607 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:27:23,315 - Epoch: [193][   50/  391]    Overall Loss 1.527292    Objective Loss 1.527292    Top1 93.750000    Top5 99.625000    LR 0.030000    Time 0.034080    
2018-10-21 07:27:24,882 - Epoch: [193][  100/  391]    Overall Loss 1.531562    Objective Loss 1.531562    Top1 93.273438    Top5 99.593750    LR 0.030000    Time 0.032692    
2018-10-21 07:27:26,444 - Epoch: [193][  150/  391]    Overall Loss 1.533421    Objective Loss 1.533421    Top1 93.083333    Top5 99.572917    LR 0.030000    Time 0.032190    
2018-10-21 07:27:27,972 - Epoch: [193][  200/  391]    Overall Loss 1.534279    Objective Loss 1.534279    Top1 93.007812    Top5 99.585938    LR 0.030000    Time 0.031773    
2018-10-21 07:27:29,503 - Epoch: [193][  250/  391]    Overall Loss 1.535432    Objective Loss 1.535432    Top1 92.884375    Top5 99.587500    LR 0.030000    Time 0.031532    
2018-10-21 07:27:31,147 - Epoch: [193][  300/  391]    Overall Loss 1.533668    Objective Loss 1.533668    Top1 93.080729    Top5 99.578125    LR 0.030000    Time 0.031749    
2018-10-21 07:27:32,713 - Epoch: [193][  350/  391]    Overall Loss 1.533002    Objective Loss 1.533002    Top1 93.183036    Top5 99.593750    LR 0.030000    Time 0.031682    
2018-10-21 07:27:34,122 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23660 | -0.00106 |    0.15635 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08319 | -0.00421 |    0.04869 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08124 |  0.00129 |    0.05505 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06993 | -0.00717 |    0.04738 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06718 | -0.00183 |    0.04408 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08286 | -0.00967 |    0.05797 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07276 | -0.00674 |    0.05145 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08460 | -0.00301 |    0.06328 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07265 | -0.00388 |    0.05540 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17454 | -0.00065 |    0.10752 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06572 | -0.00219 |    0.04956 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05806 | -0.00736 |    0.04586 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07021 | -0.00656 |    0.05376 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05610 | -0.00399 |    0.04389 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06718 | -0.00522 |    0.05309 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06236 | -0.00331 |    0.04935 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08155 | -0.00465 |    0.06252 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06000 | -0.00712 |    0.04737 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04211 | -0.00331 |    0.03251 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03708 | -0.00673 |    0.02892 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02152 |  0.00011 |    0.01466 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40541 | -0.00001 |    0.28548 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:27:34,122 - Total sparsity: 0.00

2018-10-21 07:27:34,122 - --- validate (epoch=193)-----------
2018-10-21 07:27:34,123 - 10000 samples (128 per mini-batch)
2018-10-21 07:27:35,308 - Epoch: [193][   50/   78]    Loss 1.575346    Top1 88.750000    Top5 99.265625    
2018-10-21 07:27:35,953 - ==> Top1: 88.440    Top5: 99.290    Loss: 1.577

2018-10-21 07:27:35,954 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:27:35,955 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:27:35,967 - 

2018-10-21 07:27:35,968 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:27:37,743 - Epoch: [194][   50/  391]    Overall Loss 1.527770    Objective Loss 1.527770    Top1 93.531250    Top5 99.718750    LR 0.030000    Time 0.035434    
2018-10-21 07:27:39,385 - Epoch: [194][  100/  391]    Overall Loss 1.531194    Objective Loss 1.531194    Top1 93.250000    Top5 99.625000    LR 0.030000    Time 0.034115    
2018-10-21 07:27:40,957 - Epoch: [194][  150/  391]    Overall Loss 1.531942    Objective Loss 1.531942    Top1 93.218750    Top5 99.552083    LR 0.030000    Time 0.033203    
2018-10-21 07:27:42,492 - Epoch: [194][  200/  391]    Overall Loss 1.533343    Objective Loss 1.533343    Top1 93.109375    Top5 99.535156    LR 0.030000    Time 0.032569    
2018-10-21 07:27:44,021 - Epoch: [194][  250/  391]    Overall Loss 1.534097    Objective Loss 1.534097    Top1 92.987500    Top5 99.521875    LR 0.030000    Time 0.032160    
2018-10-21 07:27:45,557 - Epoch: [194][  300/  391]    Overall Loss 1.535330    Objective Loss 1.535330    Top1 92.854167    Top5 99.533854    LR 0.030000    Time 0.031912    
2018-10-21 07:27:47,123 - Epoch: [194][  350/  391]    Overall Loss 1.535257    Objective Loss 1.535257    Top1 92.879464    Top5 99.546875    LR 0.030000    Time 0.031820    
2018-10-21 07:27:48,532 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23630 | -0.00268 |    0.15584 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08321 | -0.00366 |    0.04878 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08119 |  0.00210 |    0.05498 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06994 | -0.00730 |    0.04743 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06717 | -0.00215 |    0.04412 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08274 | -0.01039 |    0.05793 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07271 | -0.00663 |    0.05145 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08453 | -0.00302 |    0.06320 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07261 | -0.00390 |    0.05530 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17429 | -0.00132 |    0.10748 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06576 | -0.00243 |    0.04962 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05810 | -0.00751 |    0.04579 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07021 | -0.00678 |    0.05382 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05614 | -0.00407 |    0.04387 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06717 | -0.00519 |    0.05306 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 | -0.00342 |    0.04939 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08144 | -0.00430 |    0.06218 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06000 | -0.00738 |    0.04740 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04217 | -0.00323 |    0.03255 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03713 | -0.00680 |    0.02896 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02152 |  0.00015 |    0.01467 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40522 | -0.00001 |    0.28535 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:27:48,532 - Total sparsity: 0.00

2018-10-21 07:27:48,532 - --- validate (epoch=194)-----------
2018-10-21 07:27:48,532 - 10000 samples (128 per mini-batch)
2018-10-21 07:27:49,765 - Epoch: [194][   50/   78]    Loss 1.580459    Top1 87.937500    Top5 99.312500    
2018-10-21 07:27:50,397 - ==> Top1: 87.920    Top5: 99.250    Loss: 1.583

2018-10-21 07:27:50,399 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:27:50,399 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:27:50,412 - 

2018-10-21 07:27:50,412 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:27:52,397 - Epoch: [195][   50/  391]    Overall Loss 1.533528    Objective Loss 1.533528    Top1 93.031250    Top5 99.437500    LR 0.030000    Time 0.039625    
2018-10-21 07:27:54,142 - Epoch: [195][  100/  391]    Overall Loss 1.533951    Objective Loss 1.533951    Top1 93.000000    Top5 99.570312    LR 0.030000    Time 0.037232    
2018-10-21 07:27:55,851 - Epoch: [195][  150/  391]    Overall Loss 1.534656    Objective Loss 1.534656    Top1 92.895833    Top5 99.619792    LR 0.030000    Time 0.036196    
2018-10-21 07:27:57,567 - Epoch: [195][  200/  391]    Overall Loss 1.535003    Objective Loss 1.535003    Top1 92.902344    Top5 99.628906    LR 0.030000    Time 0.035717    
2018-10-21 07:27:59,338 - Epoch: [195][  250/  391]    Overall Loss 1.534205    Objective Loss 1.534205    Top1 93.021875    Top5 99.621875    LR 0.030000    Time 0.035647    
2018-10-21 07:28:01,064 - Epoch: [195][  300/  391]    Overall Loss 1.535297    Objective Loss 1.535297    Top1 92.916667    Top5 99.611979    LR 0.030000    Time 0.035450    
2018-10-21 07:28:02,790 - Epoch: [195][  350/  391]    Overall Loss 1.535840    Objective Loss 1.535840    Top1 92.854911    Top5 99.613839    LR 0.030000    Time 0.035308    
2018-10-21 07:28:04,180 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23617 | -0.00087 |    0.15587 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08328 | -0.00352 |    0.04871 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08127 |  0.00085 |    0.05498 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07007 | -0.00668 |    0.04763 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06718 | -0.00237 |    0.04403 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08284 | -0.01006 |    0.05806 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07270 | -0.00680 |    0.05137 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08453 | -0.00273 |    0.06306 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07261 | -0.00350 |    0.05532 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17411 | -0.00138 |    0.10688 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06578 | -0.00238 |    0.04965 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05819 | -0.00716 |    0.04590 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07028 | -0.00684 |    0.05380 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05620 | -0.00432 |    0.04396 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06714 | -0.00519 |    0.05305 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06239 | -0.00338 |    0.04942 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08134 | -0.00427 |    0.06218 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06005 | -0.00733 |    0.04741 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04222 | -0.00327 |    0.03259 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03720 | -0.00673 |    0.02903 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02152 |  0.00024 |    0.01467 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40508 | -0.00001 |    0.28541 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:28:04,180 - Total sparsity: 0.00

2018-10-21 07:28:04,180 - --- validate (epoch=195)-----------
2018-10-21 07:28:04,180 - 10000 samples (128 per mini-batch)
2018-10-21 07:28:05,370 - Epoch: [195][   50/   78]    Loss 1.577710    Top1 88.671875    Top5 99.218750    
2018-10-21 07:28:06,003 - ==> Top1: 88.570    Top5: 99.260    Loss: 1.577

2018-10-21 07:28:06,005 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:28:06,005 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:28:06,018 - 

2018-10-21 07:28:06,018 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:28:07,931 - Epoch: [196][   50/  391]    Overall Loss 1.537564    Objective Loss 1.537564    Top1 92.546875    Top5 99.515625    LR 0.030000    Time 0.038187    
2018-10-21 07:28:09,668 - Epoch: [196][  100/  391]    Overall Loss 1.533145    Objective Loss 1.533145    Top1 93.101562    Top5 99.554688    LR 0.030000    Time 0.036438    
2018-10-21 07:28:11,388 - Epoch: [196][  150/  391]    Overall Loss 1.533965    Objective Loss 1.533965    Top1 93.020833    Top5 99.557292    LR 0.030000    Time 0.035743    
2018-10-21 07:28:13,120 - Epoch: [196][  200/  391]    Overall Loss 1.532917    Objective Loss 1.532917    Top1 93.164062    Top5 99.535156    LR 0.030000    Time 0.035450    
2018-10-21 07:28:14,860 - Epoch: [196][  250/  391]    Overall Loss 1.532387    Objective Loss 1.532387    Top1 93.231250    Top5 99.546875    LR 0.030000    Time 0.035315    
2018-10-21 07:28:16,612 - Epoch: [196][  300/  391]    Overall Loss 1.532579    Objective Loss 1.532579    Top1 93.200521    Top5 99.552083    LR 0.030000    Time 0.035259    
2018-10-21 07:28:18,326 - Epoch: [196][  350/  391]    Overall Loss 1.533294    Objective Loss 1.533294    Top1 93.129464    Top5 99.578125    LR 0.030000    Time 0.035112    
2018-10-21 07:28:19,901 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23591 | -0.00295 |    0.15621 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08322 | -0.00386 |    0.04849 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08121 |  0.00138 |    0.05513 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07006 | -0.00633 |    0.04767 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06712 | -0.00259 |    0.04400 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08280 | -0.00991 |    0.05795 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07260 | -0.00710 |    0.05109 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08446 | -0.00313 |    0.06298 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07258 | -0.00380 |    0.05534 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17383 | -0.00091 |    0.10691 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06582 | -0.00234 |    0.04969 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05826 | -0.00693 |    0.04583 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07030 | -0.00670 |    0.05382 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05624 | -0.00408 |    0.04403 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06710 | -0.00532 |    0.05302 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06239 | -0.00345 |    0.04943 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08122 | -0.00431 |    0.06201 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06006 | -0.00725 |    0.04744 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04226 | -0.00327 |    0.03264 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03724 | -0.00669 |    0.02906 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02151 |  0.00016 |    0.01467 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40492 | -0.00001 |    0.28530 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:28:19,901 - Total sparsity: 0.00

2018-10-21 07:28:19,901 - --- validate (epoch=196)-----------
2018-10-21 07:28:19,902 - 10000 samples (128 per mini-batch)
2018-10-21 07:28:21,077 - Epoch: [196][   50/   78]    Loss 1.575052    Top1 88.750000    Top5 99.390625    
2018-10-21 07:28:21,701 - ==> Top1: 88.710    Top5: 99.480    Loss: 1.575

2018-10-21 07:28:21,703 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:28:21,703 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:28:21,716 - 

2018-10-21 07:28:21,717 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:28:23,605 - Epoch: [197][   50/  391]    Overall Loss 1.533704    Objective Loss 1.533704    Top1 93.000000    Top5 99.609375    LR 0.030000    Time 0.037698    
2018-10-21 07:28:25,347 - Epoch: [197][  100/  391]    Overall Loss 1.530613    Objective Loss 1.530613    Top1 93.390625    Top5 99.593750    LR 0.030000    Time 0.036251    
2018-10-21 07:28:27,086 - Epoch: [197][  150/  391]    Overall Loss 1.532283    Objective Loss 1.532283    Top1 93.307292    Top5 99.489583    LR 0.030000    Time 0.035744    
2018-10-21 07:28:28,794 - Epoch: [197][  200/  391]    Overall Loss 1.531067    Objective Loss 1.531067    Top1 93.441406    Top5 99.535156    LR 0.030000    Time 0.035331    
2018-10-21 07:28:30,505 - Epoch: [197][  250/  391]    Overall Loss 1.533062    Objective Loss 1.533062    Top1 93.200000    Top5 99.537500    LR 0.030000    Time 0.035099    
2018-10-21 07:28:32,245 - Epoch: [197][  300/  391]    Overall Loss 1.533677    Objective Loss 1.533677    Top1 93.127604    Top5 99.546875    LR 0.030000    Time 0.035042    
2018-10-21 07:28:33,800 - Epoch: [197][  350/  391]    Overall Loss 1.533754    Objective Loss 1.533754    Top1 93.127232    Top5 99.560268    LR 0.030000    Time 0.034471    
2018-10-21 07:28:35,178 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23550 | -0.00175 |    0.15520 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08322 | -0.00293 |    0.04840 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08114 |  0.00143 |    0.05515 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07003 | -0.00646 |    0.04764 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06705 | -0.00249 |    0.04391 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08273 | -0.00959 |    0.05778 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07250 | -0.00717 |    0.05105 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08438 | -0.00322 |    0.06309 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07255 | -0.00342 |    0.05529 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17362 | -0.00025 |    0.10676 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06582 | -0.00272 |    0.04968 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05827 | -0.00703 |    0.04584 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07031 | -0.00686 |    0.05393 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05628 | -0.00401 |    0.04403 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06707 | -0.00536 |    0.05302 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06241 | -0.00331 |    0.04942 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08113 | -0.00428 |    0.06186 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06010 | -0.00727 |    0.04751 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04232 | -0.00339 |    0.03269 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03731 | -0.00659 |    0.02910 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02151 |  0.00020 |    0.01469 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40488 | -0.00001 |    0.28537 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:28:35,178 - Total sparsity: 0.00

2018-10-21 07:28:35,178 - --- validate (epoch=197)-----------
2018-10-21 07:28:35,178 - 10000 samples (128 per mini-batch)
2018-10-21 07:28:36,367 - Epoch: [197][   50/   78]    Loss 1.575584    Top1 88.531250    Top5 99.359375    
2018-10-21 07:28:37,013 - ==> Top1: 88.410    Top5: 99.440    Loss: 1.576

2018-10-21 07:28:37,016 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:28:37,016 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:28:37,028 - 

2018-10-21 07:28:37,028 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:28:38,761 - Epoch: [198][   50/  391]    Overall Loss 1.533481    Objective Loss 1.533481    Top1 92.984375    Top5 99.562500    LR 0.030000    Time 0.034604    
2018-10-21 07:28:40,334 - Epoch: [198][  100/  391]    Overall Loss 1.532026    Objective Loss 1.532026    Top1 93.242188    Top5 99.601562    LR 0.030000    Time 0.033003    
2018-10-21 07:28:41,919 - Epoch: [198][  150/  391]    Overall Loss 1.532989    Objective Loss 1.532989    Top1 93.156250    Top5 99.604167    LR 0.030000    Time 0.032550    
2018-10-21 07:28:43,467 - Epoch: [198][  200/  391]    Overall Loss 1.531853    Objective Loss 1.531853    Top1 93.277344    Top5 99.625000    LR 0.030000    Time 0.032144    
2018-10-21 07:28:45,023 - Epoch: [198][  250/  391]    Overall Loss 1.532582    Objective Loss 1.532582    Top1 93.193750    Top5 99.615625    LR 0.030000    Time 0.031929    
2018-10-21 07:28:46,566 - Epoch: [198][  300/  391]    Overall Loss 1.532357    Objective Loss 1.532357    Top1 93.203125    Top5 99.601562    LR 0.030000    Time 0.031743    
2018-10-21 07:28:48,159 - Epoch: [198][  350/  391]    Overall Loss 1.532631    Objective Loss 1.532631    Top1 93.176339    Top5 99.584821    LR 0.030000    Time 0.031751    
2018-10-21 07:28:49,498 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23533 | -0.00049 |    0.15591 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08314 | -0.00328 |    0.04851 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08112 |  0.00176 |    0.05516 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07008 | -0.00635 |    0.04758 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06704 | -0.00248 |    0.04390 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08256 | -0.01034 |    0.05755 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07253 | -0.00653 |    0.05096 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08430 | -0.00330 |    0.06313 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07252 | -0.00350 |    0.05528 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17336 |  0.00021 |    0.10713 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06584 | -0.00280 |    0.04968 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05828 | -0.00709 |    0.04582 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07029 | -0.00698 |    0.05393 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05629 | -0.00403 |    0.04409 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06705 | -0.00532 |    0.05306 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06242 | -0.00337 |    0.04945 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08101 | -0.00432 |    0.06179 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06011 | -0.00730 |    0.04751 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04237 | -0.00335 |    0.03274 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03731 | -0.00677 |    0.02914 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02150 |  0.00022 |    0.01469 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40491 | -0.00001 |    0.28549 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:28:49,498 - Total sparsity: 0.00

2018-10-21 07:28:49,498 - --- validate (epoch=198)-----------
2018-10-21 07:28:49,499 - 10000 samples (128 per mini-batch)
2018-10-21 07:28:50,690 - Epoch: [198][   50/   78]    Loss 1.584323    Top1 87.859375    Top5 99.421875    
2018-10-21 07:28:51,336 - ==> Top1: 87.670    Top5: 99.450    Loss: 1.585

2018-10-21 07:28:51,337 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:28:51,337 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:28:51,351 - 

2018-10-21 07:28:51,351 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:28:53,077 - Epoch: [199][   50/  391]    Overall Loss 1.534621    Objective Loss 1.534621    Top1 93.000000    Top5 99.500000    LR 0.030000    Time 0.034455    
2018-10-21 07:28:54,646 - Epoch: [199][  100/  391]    Overall Loss 1.532477    Objective Loss 1.532477    Top1 93.250000    Top5 99.570312    LR 0.030000    Time 0.032895    
2018-10-21 07:28:56,205 - Epoch: [199][  150/  391]    Overall Loss 1.531794    Objective Loss 1.531794    Top1 93.312500    Top5 99.614583    LR 0.030000    Time 0.032304    
2018-10-21 07:28:57,752 - Epoch: [199][  200/  391]    Overall Loss 1.532770    Objective Loss 1.532770    Top1 93.218750    Top5 99.644531    LR 0.030000    Time 0.031952    
2018-10-21 07:28:59,305 - Epoch: [199][  250/  391]    Overall Loss 1.533953    Objective Loss 1.533953    Top1 93.115625    Top5 99.637500    LR 0.030000    Time 0.031766    
2018-10-21 07:29:00,865 - Epoch: [199][  300/  391]    Overall Loss 1.534431    Objective Loss 1.534431    Top1 93.059896    Top5 99.609375    LR 0.030000    Time 0.031662    
2018-10-21 07:29:02,363 - Epoch: [199][  350/  391]    Overall Loss 1.534665    Objective Loss 1.534665    Top1 93.031250    Top5 99.593750    LR 0.030000    Time 0.031412    
2018-10-21 07:29:03,772 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23519 | -0.00288 |    0.15621 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08312 | -0.00289 |    0.04836 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08113 |  0.00121 |    0.05512 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07011 | -0.00637 |    0.04746 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06702 | -0.00250 |    0.04398 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08256 | -0.00991 |    0.05744 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07245 | -0.00687 |    0.05085 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08422 | -0.00360 |    0.06311 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07250 | -0.00352 |    0.05532 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17325 | -0.00057 |    0.10735 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06588 | -0.00270 |    0.04981 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05832 | -0.00710 |    0.04585 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07032 | -0.00690 |    0.05390 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05632 | -0.00393 |    0.04413 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06705 | -0.00508 |    0.05303 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06243 | -0.00346 |    0.04947 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08089 | -0.00456 |    0.06180 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06013 | -0.00729 |    0.04752 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04242 | -0.00339 |    0.03280 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03736 | -0.00672 |    0.02918 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02149 |  0.00021 |    0.01468 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40504 | -0.00001 |    0.28562 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:29:03,773 - Total sparsity: 0.00

2018-10-21 07:29:03,773 - --- validate (epoch=199)-----------
2018-10-21 07:29:03,773 - 10000 samples (128 per mini-batch)
2018-10-21 07:29:04,931 - Epoch: [199][   50/   78]    Loss 1.589863    Top1 87.328125    Top5 99.031250    
2018-10-21 07:29:05,561 - ==> Top1: 87.150    Top5: 99.090    Loss: 1.591

2018-10-21 07:29:05,563 - ==> Best Top1: 89.000   On Epoch: 137

2018-10-21 07:29:05,564 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:29:05,577 - 

2018-10-21 07:29:05,577 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:29:07,322 - Epoch: [200][   50/  391]    Overall Loss 1.533858    Objective Loss 1.533858    Top1 93.109375    Top5 99.593750    LR 0.003000    Time 0.034833    
2018-10-21 07:29:08,909 - Epoch: [200][  100/  391]    Overall Loss 1.526114    Objective Loss 1.526114    Top1 93.835938    Top5 99.695312    LR 0.003000    Time 0.033261    
2018-10-21 07:29:10,439 - Epoch: [200][  150/  391]    Overall Loss 1.523600    Objective Loss 1.523600    Top1 94.078125    Top5 99.645833    LR 0.003000    Time 0.032358    
2018-10-21 07:29:11,960 - Epoch: [200][  200/  391]    Overall Loss 1.522525    Objective Loss 1.522525    Top1 94.199219    Top5 99.644531    LR 0.003000    Time 0.031860    
2018-10-21 07:29:13,493 - Epoch: [200][  250/  391]    Overall Loss 1.521584    Objective Loss 1.521584    Top1 94.293750    Top5 99.634375    LR 0.003000    Time 0.031614    
2018-10-21 07:29:14,988 - Epoch: [200][  300/  391]    Overall Loss 1.520469    Objective Loss 1.520469    Top1 94.411458    Top5 99.619792    LR 0.003000    Time 0.031318    
2018-10-21 07:29:16,504 - Epoch: [200][  350/  391]    Overall Loss 1.519719    Objective Loss 1.519719    Top1 94.473214    Top5 99.620536    LR 0.003000    Time 0.031169    
2018-10-21 07:29:17,864 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23495 | -0.00244 |    0.15593 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08303 | -0.00293 |    0.04836 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08104 |  0.00124 |    0.05498 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07004 | -0.00627 |    0.04741 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06695 | -0.00241 |    0.04393 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08247 | -0.00994 |    0.05739 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07237 | -0.00695 |    0.05080 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08413 | -0.00353 |    0.06304 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07242 | -0.00360 |    0.05525 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17307 | -0.00033 |    0.10722 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06581 | -0.00278 |    0.04976 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05826 | -0.00712 |    0.04580 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07024 | -0.00689 |    0.05385 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05626 | -0.00393 |    0.04408 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06698 | -0.00505 |    0.05297 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 | -0.00344 |    0.04942 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08080 | -0.00454 |    0.06172 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06007 | -0.00730 |    0.04748 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04238 | -0.00337 |    0.03276 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03732 | -0.00673 |    0.02916 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02147 |  0.00021 |    0.01466 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40500 | -0.00001 |    0.28565 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:29:17,865 - Total sparsity: 0.00

2018-10-21 07:29:17,865 - --- validate (epoch=200)-----------
2018-10-21 07:29:17,865 - 10000 samples (128 per mini-batch)
2018-10-21 07:29:19,162 - Epoch: [200][   50/   78]    Loss 1.556549    Top1 90.562500    Top5 99.515625    
2018-10-21 07:29:19,785 - ==> Top1: 90.430    Top5: 99.550    Loss: 1.557

2018-10-21 07:29:19,787 - ==> Best Top1: 90.430   On Epoch: 200

2018-10-21 07:29:19,787 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:29:19,803 - 

2018-10-21 07:29:19,804 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:29:21,507 - Epoch: [201][   50/  391]    Overall Loss 1.507655    Objective Loss 1.507655    Top1 95.750000    Top5 99.703125    LR 0.003000    Time 0.033996    
2018-10-21 07:29:23,074 - Epoch: [201][  100/  391]    Overall Loss 1.508499    Objective Loss 1.508499    Top1 95.562500    Top5 99.617188    LR 0.003000    Time 0.032651    
2018-10-21 07:29:24,604 - Epoch: [201][  150/  391]    Overall Loss 1.510280    Objective Loss 1.510280    Top1 95.401042    Top5 99.593750    LR 0.003000    Time 0.031946    
2018-10-21 07:29:26,123 - Epoch: [201][  200/  391]    Overall Loss 1.511683    Objective Loss 1.511683    Top1 95.277344    Top5 99.593750    LR 0.003000    Time 0.031546    
2018-10-21 07:29:27,669 - Epoch: [201][  250/  391]    Overall Loss 1.510907    Objective Loss 1.510907    Top1 95.393750    Top5 99.609375    LR 0.003000    Time 0.031410    
2018-10-21 07:29:29,151 - Epoch: [201][  300/  391]    Overall Loss 1.511104    Objective Loss 1.511104    Top1 95.385417    Top5 99.632812    LR 0.003000    Time 0.031107    
2018-10-21 07:29:30,637 - Epoch: [201][  350/  391]    Overall Loss 1.511185    Objective Loss 1.511185    Top1 95.368304    Top5 99.633929    LR 0.003000    Time 0.030902    
2018-10-21 07:29:31,993 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23469 | -0.00281 |    0.15578 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08294 | -0.00297 |    0.04832 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08095 |  0.00125 |    0.05492 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06996 | -0.00633 |    0.04736 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06688 | -0.00248 |    0.04388 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08236 | -0.01013 |    0.05732 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07229 | -0.00697 |    0.05075 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08404 | -0.00352 |    0.06296 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07234 | -0.00360 |    0.05518 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17288 | -0.00025 |    0.10702 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06574 | -0.00276 |    0.04970 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05819 | -0.00712 |    0.04577 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07017 | -0.00687 |    0.05380 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05620 | -0.00394 |    0.04402 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06691 | -0.00505 |    0.05291 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06230 | -0.00346 |    0.04937 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08071 | -0.00456 |    0.06163 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06001 | -0.00729 |    0.04743 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04233 | -0.00338 |    0.03273 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03728 | -0.00675 |    0.02913 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02145 |  0.00022 |    0.01464 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40492 | -0.00001 |    0.28561 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:29:31,993 - Total sparsity: 0.00

2018-10-21 07:29:31,993 - --- validate (epoch=201)-----------
2018-10-21 07:29:31,994 - 10000 samples (128 per mini-batch)
2018-10-21 07:29:33,386 - Epoch: [201][   50/   78]    Loss 1.556386    Top1 90.406250    Top5 99.546875    
2018-10-21 07:29:34,065 - ==> Top1: 90.440    Top5: 99.570    Loss: 1.556

2018-10-21 07:29:34,066 - ==> Best Top1: 90.440   On Epoch: 201

2018-10-21 07:29:34,067 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:29:34,082 - 

2018-10-21 07:29:34,083 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:29:35,797 - Epoch: [202][   50/  391]    Overall Loss 1.511701    Objective Loss 1.511701    Top1 95.234375    Top5 99.656250    LR 0.003000    Time 0.034234    
2018-10-21 07:29:37,315 - Epoch: [202][  100/  391]    Overall Loss 1.509955    Objective Loss 1.509955    Top1 95.382812    Top5 99.648438    LR 0.003000    Time 0.032270    
2018-10-21 07:29:38,901 - Epoch: [202][  150/  391]    Overall Loss 1.509057    Objective Loss 1.509057    Top1 95.500000    Top5 99.677083    LR 0.003000    Time 0.032071    
2018-10-21 07:29:40,476 - Epoch: [202][  200/  391]    Overall Loss 1.508453    Objective Loss 1.508453    Top1 95.546875    Top5 99.687500    LR 0.003000    Time 0.031916    
2018-10-21 07:29:42,037 - Epoch: [202][  250/  391]    Overall Loss 1.508426    Objective Loss 1.508426    Top1 95.559375    Top5 99.668750    LR 0.003000    Time 0.031768    
2018-10-21 07:29:43,598 - Epoch: [202][  300/  391]    Overall Loss 1.508567    Objective Loss 1.508567    Top1 95.546875    Top5 99.658854    LR 0.003000    Time 0.031667    
2018-10-21 07:29:45,126 - Epoch: [202][  350/  391]    Overall Loss 1.508768    Objective Loss 1.508768    Top1 95.533482    Top5 99.654018    LR 0.003000    Time 0.031503    
2018-10-21 07:29:46,520 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23443 | -0.00253 |    0.15553 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08285 | -0.00298 |    0.04824 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08086 |  0.00126 |    0.05482 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06989 | -0.00629 |    0.04731 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06680 | -0.00254 |    0.04384 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08227 | -0.01009 |    0.05727 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07220 | -0.00702 |    0.05069 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08395 | -0.00347 |    0.06291 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07226 | -0.00358 |    0.05511 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17269 | -0.00028 |    0.10674 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06567 | -0.00275 |    0.04964 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05813 | -0.00716 |    0.04572 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07009 | -0.00686 |    0.05374 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05614 | -0.00396 |    0.04397 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06684 | -0.00503 |    0.05285 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06223 | -0.00343 |    0.04932 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08062 | -0.00456 |    0.06157 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05994 | -0.00727 |    0.04738 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04229 | -0.00336 |    0.03270 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03723 | -0.00676 |    0.02910 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02142 |  0.00022 |    0.01463 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40484 | -0.00001 |    0.28557 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:29:46,520 - Total sparsity: 0.00

2018-10-21 07:29:46,520 - --- validate (epoch=202)-----------
2018-10-21 07:29:46,521 - 10000 samples (128 per mini-batch)
2018-10-21 07:29:47,723 - Epoch: [202][   50/   78]    Loss 1.555143    Top1 90.531250    Top5 99.578125    
2018-10-21 07:29:48,362 - ==> Top1: 90.550    Top5: 99.620    Loss: 1.555

2018-10-21 07:29:48,363 - ==> Best Top1: 90.550   On Epoch: 202

2018-10-21 07:29:48,364 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:29:48,380 - 

2018-10-21 07:29:48,380 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:29:50,291 - Epoch: [203][   50/  391]    Overall Loss 1.504629    Objective Loss 1.504629    Top1 96.000000    Top5 99.593750    LR 0.003000    Time 0.038154    
2018-10-21 07:29:52,029 - Epoch: [203][  100/  391]    Overall Loss 1.505995    Objective Loss 1.505995    Top1 95.835938    Top5 99.585938    LR 0.003000    Time 0.036427    
2018-10-21 07:29:53,752 - Epoch: [203][  150/  391]    Overall Loss 1.506759    Objective Loss 1.506759    Top1 95.708333    Top5 99.630208    LR 0.003000    Time 0.035757    
2018-10-21 07:29:55,456 - Epoch: [203][  200/  391]    Overall Loss 1.506903    Objective Loss 1.506903    Top1 95.726562    Top5 99.644531    LR 0.003000    Time 0.035328    
2018-10-21 07:29:57,122 - Epoch: [203][  250/  391]    Overall Loss 1.506489    Objective Loss 1.506489    Top1 95.793750    Top5 99.662500    LR 0.003000    Time 0.034916    
2018-10-21 07:29:58,808 - Epoch: [203][  300/  391]    Overall Loss 1.507104    Objective Loss 1.507104    Top1 95.736979    Top5 99.664062    LR 0.003000    Time 0.034708    
2018-10-21 07:30:00,510 - Epoch: [203][  350/  391]    Overall Loss 1.506867    Objective Loss 1.506867    Top1 95.743304    Top5 99.665179    LR 0.003000    Time 0.034606    
2018-10-21 07:30:02,052 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23418 | -0.00217 |    0.15542 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08276 | -0.00301 |    0.04821 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08078 |  0.00127 |    0.05474 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06981 | -0.00631 |    0.04726 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06673 | -0.00253 |    0.04380 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08217 | -0.01015 |    0.05722 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07213 | -0.00695 |    0.05065 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08386 | -0.00354 |    0.06286 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07218 | -0.00361 |    0.05506 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17250 | -0.00019 |    0.10656 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06560 | -0.00275 |    0.04958 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05806 | -0.00717 |    0.04568 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07002 | -0.00686 |    0.05368 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05608 | -0.00396 |    0.04392 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06676 | -0.00503 |    0.05280 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06217 | -0.00341 |    0.04927 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08053 | -0.00458 |    0.06149 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05988 | -0.00726 |    0.04733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04224 | -0.00336 |    0.03267 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03719 | -0.00678 |    0.02907 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02140 |  0.00022 |    0.01461 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40474 | -0.00001 |    0.28551 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:30:02,052 - Total sparsity: 0.00

2018-10-21 07:30:02,052 - --- validate (epoch=203)-----------
2018-10-21 07:30:02,053 - 10000 samples (128 per mini-batch)
2018-10-21 07:30:03,270 - Epoch: [203][   50/   78]    Loss 1.554468    Top1 90.890625    Top5 99.562500    
2018-10-21 07:30:03,934 - ==> Top1: 90.760    Top5: 99.570    Loss: 1.555

2018-10-21 07:30:03,936 - ==> Best Top1: 90.760   On Epoch: 203

2018-10-21 07:30:03,936 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:30:03,954 - 

2018-10-21 07:30:03,955 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:30:05,717 - Epoch: [204][   50/  391]    Overall Loss 1.505729    Objective Loss 1.505729    Top1 95.890625    Top5 99.640625    LR 0.003000    Time 0.035165    
2018-10-21 07:30:07,272 - Epoch: [204][  100/  391]    Overall Loss 1.504391    Objective Loss 1.504391    Top1 95.992188    Top5 99.710938    LR 0.003000    Time 0.033103    
2018-10-21 07:30:08,819 - Epoch: [204][  150/  391]    Overall Loss 1.503785    Objective Loss 1.503785    Top1 96.062500    Top5 99.713542    LR 0.003000    Time 0.032363    
2018-10-21 07:30:10,336 - Epoch: [204][  200/  391]    Overall Loss 1.504662    Objective Loss 1.504662    Top1 96.000000    Top5 99.718750    LR 0.003000    Time 0.031843    
2018-10-21 07:30:11,869 - Epoch: [204][  250/  391]    Overall Loss 1.504803    Objective Loss 1.504803    Top1 95.975000    Top5 99.696875    LR 0.003000    Time 0.031599    
2018-10-21 07:30:13,398 - Epoch: [204][  300/  391]    Overall Loss 1.505000    Objective Loss 1.505000    Top1 95.942708    Top5 99.669271    LR 0.003000    Time 0.031423    
2018-10-21 07:30:14,950 - Epoch: [204][  350/  391]    Overall Loss 1.504951    Objective Loss 1.504951    Top1 95.939732    Top5 99.685268    LR 0.003000    Time 0.031360    
2018-10-21 07:30:16,324 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23393 | -0.00177 |    0.15529 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08267 | -0.00294 |    0.04817 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08069 |  0.00121 |    0.05469 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06973 | -0.00632 |    0.04721 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06665 | -0.00254 |    0.04377 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08207 | -0.01025 |    0.05717 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07205 | -0.00689 |    0.05060 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08376 | -0.00351 |    0.06278 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07210 | -0.00359 |    0.05499 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17231 | -0.00014 |    0.10639 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06552 | -0.00277 |    0.04952 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05800 | -0.00713 |    0.04562 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06994 | -0.00687 |    0.05362 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05602 | -0.00395 |    0.04387 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06669 | -0.00502 |    0.05274 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06210 | -0.00340 |    0.04921 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08044 | -0.00456 |    0.06143 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05981 | -0.00726 |    0.04728 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04219 | -0.00335 |    0.03263 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03715 | -0.00678 |    0.02904 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02138 |  0.00022 |    0.01460 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40465 | -0.00001 |    0.28545 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:30:16,324 - Total sparsity: 0.00

2018-10-21 07:30:16,324 - --- validate (epoch=204)-----------
2018-10-21 07:30:16,324 - 10000 samples (128 per mini-batch)
2018-10-21 07:30:17,521 - Epoch: [204][   50/   78]    Loss 1.553114    Top1 90.890625    Top5 99.578125    
2018-10-21 07:30:18,168 - ==> Top1: 90.840    Top5: 99.590    Loss: 1.553

2018-10-21 07:30:18,170 - ==> Best Top1: 90.840   On Epoch: 204

2018-10-21 07:30:18,171 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:30:18,194 - 

2018-10-21 07:30:18,194 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:30:20,103 - Epoch: [205][   50/  391]    Overall Loss 1.503705    Objective Loss 1.503705    Top1 95.937500    Top5 99.718750    LR 0.003000    Time 0.038106    
2018-10-21 07:30:21,871 - Epoch: [205][  100/  391]    Overall Loss 1.503580    Objective Loss 1.503580    Top1 96.078125    Top5 99.703125    LR 0.003000    Time 0.036711    
2018-10-21 07:30:23,619 - Epoch: [205][  150/  391]    Overall Loss 1.503107    Objective Loss 1.503107    Top1 96.104167    Top5 99.697917    LR 0.003000    Time 0.036106    
2018-10-21 07:30:25,326 - Epoch: [205][  200/  391]    Overall Loss 1.504003    Objective Loss 1.504003    Top1 96.042969    Top5 99.710938    LR 0.003000    Time 0.035602    
2018-10-21 07:30:27,043 - Epoch: [205][  250/  391]    Overall Loss 1.503585    Objective Loss 1.503585    Top1 96.096875    Top5 99.700000    LR 0.003000    Time 0.035339    
2018-10-21 07:30:28,649 - Epoch: [205][  300/  391]    Overall Loss 1.503646    Objective Loss 1.503646    Top1 96.075521    Top5 99.695312    LR 0.003000    Time 0.034797    
2018-10-21 07:30:30,174 - Epoch: [205][  350/  391]    Overall Loss 1.503956    Objective Loss 1.503956    Top1 96.046875    Top5 99.667411    LR 0.003000    Time 0.034176    
2018-10-21 07:30:31,549 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23367 | -0.00175 |    0.15517 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08258 | -0.00298 |    0.04811 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08060 |  0.00118 |    0.05463 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06965 | -0.00631 |    0.04718 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06658 | -0.00250 |    0.04373 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08198 | -0.01019 |    0.05713 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07197 | -0.00691 |    0.05055 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08367 | -0.00344 |    0.06270 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07202 | -0.00358 |    0.05493 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17212 | -0.00001 |    0.10621 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06545 | -0.00276 |    0.04946 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05794 | -0.00711 |    0.04557 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06986 | -0.00685 |    0.05356 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05595 | -0.00395 |    0.04382 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06662 | -0.00502 |    0.05268 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06203 | -0.00340 |    0.04916 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08035 | -0.00456 |    0.06137 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05975 | -0.00724 |    0.04723 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04215 | -0.00334 |    0.03260 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03710 | -0.00678 |    0.02901 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02135 |  0.00020 |    0.01458 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40457 | -0.00001 |    0.28540 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:30:31,549 - Total sparsity: 0.00

2018-10-21 07:30:31,549 - --- validate (epoch=205)-----------
2018-10-21 07:30:31,549 - 10000 samples (128 per mini-batch)
2018-10-21 07:30:32,780 - Epoch: [205][   50/   78]    Loss 1.554910    Top1 90.640625    Top5 99.593750    
2018-10-21 07:30:33,429 - ==> Top1: 90.530    Top5: 99.590    Loss: 1.556

2018-10-21 07:30:33,431 - ==> Best Top1: 90.840   On Epoch: 204

2018-10-21 07:30:33,432 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:30:33,446 - 

2018-10-21 07:30:33,447 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:30:35,381 - Epoch: [206][   50/  391]    Overall Loss 1.505346    Objective Loss 1.505346    Top1 95.859375    Top5 99.765625    LR 0.003000    Time 0.038618    
2018-10-21 07:30:37,158 - Epoch: [206][  100/  391]    Overall Loss 1.505491    Objective Loss 1.505491    Top1 95.820312    Top5 99.609375    LR 0.003000    Time 0.037054    
2018-10-21 07:30:38,800 - Epoch: [206][  150/  391]    Overall Loss 1.504754    Objective Loss 1.504754    Top1 95.895833    Top5 99.656250    LR 0.003000    Time 0.035631    
2018-10-21 07:30:40,339 - Epoch: [206][  200/  391]    Overall Loss 1.504044    Objective Loss 1.504044    Top1 96.000000    Top5 99.679688    LR 0.003000    Time 0.034407    
2018-10-21 07:30:41,872 - Epoch: [206][  250/  391]    Overall Loss 1.504173    Objective Loss 1.504173    Top1 96.000000    Top5 99.681250    LR 0.003000    Time 0.033647    
2018-10-21 07:30:43,414 - Epoch: [206][  300/  391]    Overall Loss 1.503479    Objective Loss 1.503479    Top1 96.078125    Top5 99.692708    LR 0.003000    Time 0.033171    
2018-10-21 07:30:44,950 - Epoch: [206][  350/  391]    Overall Loss 1.503309    Objective Loss 1.503309    Top1 96.082589    Top5 99.696429    LR 0.003000    Time 0.032816    
2018-10-21 07:30:46,342 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23341 | -0.00186 |    0.15506 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08248 | -0.00305 |    0.04805 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08051 |  0.00121 |    0.05458 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06958 | -0.00628 |    0.04712 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06651 | -0.00245 |    0.04367 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08189 | -0.01023 |    0.05706 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07190 | -0.00685 |    0.05050 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08358 | -0.00340 |    0.06263 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07194 | -0.00361 |    0.05487 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17193 |  0.00000 |    0.10608 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06538 | -0.00273 |    0.04941 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05788 | -0.00708 |    0.04553 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06979 | -0.00682 |    0.05349 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05589 | -0.00394 |    0.04378 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06654 | -0.00503 |    0.05262 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06196 | -0.00336 |    0.04911 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08027 | -0.00454 |    0.06131 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05968 | -0.00723 |    0.04718 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04210 | -0.00332 |    0.03256 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03706 | -0.00680 |    0.02898 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02133 |  0.00020 |    0.01457 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40447 | -0.00001 |    0.28533 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:30:46,342 - Total sparsity: 0.00

2018-10-21 07:30:46,342 - --- validate (epoch=206)-----------
2018-10-21 07:30:46,343 - 10000 samples (128 per mini-batch)
2018-10-21 07:30:47,534 - Epoch: [206][   50/   78]    Loss 1.553535    Top1 90.859375    Top5 99.656250    
2018-10-21 07:30:48,177 - ==> Top1: 90.750    Top5: 99.650    Loss: 1.554

2018-10-21 07:30:48,179 - ==> Best Top1: 90.840   On Epoch: 204

2018-10-21 07:30:48,179 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:30:48,193 - 

2018-10-21 07:30:48,193 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:30:49,879 - Epoch: [207][   50/  391]    Overall Loss 1.504122    Objective Loss 1.504122    Top1 96.000000    Top5 99.593750    LR 0.003000    Time 0.033650    
2018-10-21 07:30:51,429 - Epoch: [207][  100/  391]    Overall Loss 1.503626    Objective Loss 1.503626    Top1 96.062500    Top5 99.656250    LR 0.003000    Time 0.032300    
2018-10-21 07:30:52,979 - Epoch: [207][  150/  391]    Overall Loss 1.503473    Objective Loss 1.503473    Top1 96.078125    Top5 99.635417    LR 0.003000    Time 0.031848    
2018-10-21 07:30:54,526 - Epoch: [207][  200/  391]    Overall Loss 1.502723    Objective Loss 1.502723    Top1 96.152344    Top5 99.664062    LR 0.003000    Time 0.031610    
2018-10-21 07:30:56,053 - Epoch: [207][  250/  391]    Overall Loss 1.502726    Objective Loss 1.502726    Top1 96.159375    Top5 99.693750    LR 0.003000    Time 0.031388    
2018-10-21 07:30:57,566 - Epoch: [207][  300/  391]    Overall Loss 1.502123    Objective Loss 1.502123    Top1 96.205729    Top5 99.700521    LR 0.003000    Time 0.031191    
2018-10-21 07:30:59,089 - Epoch: [207][  350/  391]    Overall Loss 1.502179    Objective Loss 1.502179    Top1 96.198661    Top5 99.685268    LR 0.003000    Time 0.031081    
2018-10-21 07:31:00,475 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23316 | -0.00157 |    0.15487 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08240 | -0.00303 |    0.04803 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08042 |  0.00123 |    0.05452 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06950 | -0.00626 |    0.04709 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06644 | -0.00242 |    0.04362 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08180 | -0.01025 |    0.05701 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07181 | -0.00694 |    0.05044 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08349 | -0.00335 |    0.06257 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07186 | -0.00360 |    0.05480 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17174 |  0.00001 |    0.10596 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06531 | -0.00271 |    0.04935 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05781 | -0.00708 |    0.04548 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06971 | -0.00681 |    0.05343 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05583 | -0.00394 |    0.04374 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06647 | -0.00504 |    0.05257 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06190 | -0.00337 |    0.04906 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08018 | -0.00456 |    0.06125 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05962 | -0.00721 |    0.04712 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04206 | -0.00332 |    0.03253 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03702 | -0.00681 |    0.02895 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02131 |  0.00020 |    0.01456 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40438 | -0.00001 |    0.28527 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:31:00,475 - Total sparsity: 0.00

2018-10-21 07:31:00,475 - --- validate (epoch=207)-----------
2018-10-21 07:31:00,475 - 10000 samples (128 per mini-batch)
2018-10-21 07:31:01,685 - Epoch: [207][   50/   78]    Loss 1.553967    Top1 90.796875    Top5 99.578125    
2018-10-21 07:31:02,335 - ==> Top1: 90.660    Top5: 99.640    Loss: 1.554

2018-10-21 07:31:02,337 - ==> Best Top1: 90.840   On Epoch: 204

2018-10-21 07:31:02,337 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:31:02,350 - 

2018-10-21 07:31:02,350 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:31:04,198 - Epoch: [208][   50/  391]    Overall Loss 1.503005    Objective Loss 1.503005    Top1 96.109375    Top5 99.781250    LR 0.003000    Time 0.036902    
2018-10-21 07:31:05,964 - Epoch: [208][  100/  391]    Overall Loss 1.501658    Objective Loss 1.501658    Top1 96.257812    Top5 99.765625    LR 0.003000    Time 0.036082    
2018-10-21 07:31:07,720 - Epoch: [208][  150/  391]    Overall Loss 1.501580    Objective Loss 1.501580    Top1 96.208333    Top5 99.770833    LR 0.003000    Time 0.035744    
2018-10-21 07:31:09,432 - Epoch: [208][  200/  391]    Overall Loss 1.501154    Objective Loss 1.501154    Top1 96.273438    Top5 99.750000    LR 0.003000    Time 0.035356    
2018-10-21 07:31:11,072 - Epoch: [208][  250/  391]    Overall Loss 1.501493    Objective Loss 1.501493    Top1 96.234375    Top5 99.746875    LR 0.003000    Time 0.034834    
2018-10-21 07:31:12,599 - Epoch: [208][  300/  391]    Overall Loss 1.502340    Objective Loss 1.502340    Top1 96.164062    Top5 99.729167    LR 0.003000    Time 0.034110    
2018-10-21 07:31:14,130 - Epoch: [208][  350/  391]    Overall Loss 1.502530    Objective Loss 1.502530    Top1 96.154018    Top5 99.709821    LR 0.003000    Time 0.033606    
2018-10-21 07:31:15,505 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23290 | -0.00202 |    0.15481 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08230 | -0.00306 |    0.04801 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08033 |  0.00122 |    0.05446 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06943 | -0.00625 |    0.04705 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06637 | -0.00242 |    0.04356 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08170 | -0.01025 |    0.05694 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07174 | -0.00689 |    0.05039 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08341 | -0.00326 |    0.06250 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07178 | -0.00362 |    0.05474 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17155 |  0.00005 |    0.10590 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06524 | -0.00266 |    0.04929 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05775 | -0.00708 |    0.04543 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06964 | -0.00678 |    0.05337 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05577 | -0.00393 |    0.04369 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06640 | -0.00503 |    0.05253 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06183 | -0.00335 |    0.04900 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08009 | -0.00454 |    0.06119 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05955 | -0.00720 |    0.04707 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04201 | -0.00332 |    0.03250 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03698 | -0.00681 |    0.02892 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02128 |  0.00019 |    0.01454 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40429 | -0.00001 |    0.28522 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:31:15,505 - Total sparsity: 0.00

2018-10-21 07:31:15,505 - --- validate (epoch=208)-----------
2018-10-21 07:31:15,505 - 10000 samples (128 per mini-batch)
2018-10-21 07:31:16,690 - Epoch: [208][   50/   78]    Loss 1.553762    Top1 90.875000    Top5 99.609375    
2018-10-21 07:31:17,324 - ==> Top1: 90.790    Top5: 99.620    Loss: 1.554

2018-10-21 07:31:17,326 - ==> Best Top1: 90.840   On Epoch: 204

2018-10-21 07:31:17,326 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:31:17,339 - 

2018-10-21 07:31:17,340 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:31:19,027 - Epoch: [209][   50/  391]    Overall Loss 1.503490    Objective Loss 1.503490    Top1 96.046875    Top5 99.671875    LR 0.003000    Time 0.033688    
2018-10-21 07:31:20,560 - Epoch: [209][  100/  391]    Overall Loss 1.502981    Objective Loss 1.502981    Top1 96.078125    Top5 99.601562    LR 0.003000    Time 0.032149    
2018-10-21 07:31:22,084 - Epoch: [209][  150/  391]    Overall Loss 1.502177    Objective Loss 1.502177    Top1 96.171875    Top5 99.593750    LR 0.003000    Time 0.031577    
2018-10-21 07:31:23,650 - Epoch: [209][  200/  391]    Overall Loss 1.502349    Objective Loss 1.502349    Top1 96.164062    Top5 99.628906    LR 0.003000    Time 0.031500    
2018-10-21 07:31:25,177 - Epoch: [209][  250/  391]    Overall Loss 1.501485    Objective Loss 1.501485    Top1 96.246875    Top5 99.646875    LR 0.003000    Time 0.031298    
2018-10-21 07:31:26,711 - Epoch: [209][  300/  391]    Overall Loss 1.501144    Objective Loss 1.501144    Top1 96.291667    Top5 99.658854    LR 0.003000    Time 0.031186    
2018-10-21 07:31:28,243 - Epoch: [209][  350/  391]    Overall Loss 1.501461    Objective Loss 1.501461    Top1 96.238839    Top5 99.654018    LR 0.003000    Time 0.031101    
2018-10-21 07:31:29,607 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23265 | -0.00174 |    0.15470 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08221 | -0.00303 |    0.04795 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08025 |  0.00118 |    0.05442 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06935 | -0.00621 |    0.04701 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06629 | -0.00238 |    0.04353 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08162 | -0.01017 |    0.05689 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07166 | -0.00682 |    0.05032 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08331 | -0.00325 |    0.06243 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07171 | -0.00357 |    0.05467 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17137 |  0.00009 |    0.10580 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06517 | -0.00265 |    0.04924 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05769 | -0.00706 |    0.04538 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06956 | -0.00679 |    0.05331 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05571 | -0.00393 |    0.04363 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06632 | -0.00505 |    0.05247 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06176 | -0.00335 |    0.04895 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08000 | -0.00453 |    0.06111 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05949 | -0.00719 |    0.04703 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04197 | -0.00332 |    0.03246 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03693 | -0.00681 |    0.02889 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02126 |  0.00019 |    0.01453 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40418 | -0.00001 |    0.28514 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:31:29,608 - Total sparsity: 0.00

2018-10-21 07:31:29,608 - --- validate (epoch=209)-----------
2018-10-21 07:31:29,608 - 10000 samples (128 per mini-batch)
2018-10-21 07:31:30,802 - Epoch: [209][   50/   78]    Loss 1.553941    Top1 90.625000    Top5 99.640625    
2018-10-21 07:31:31,441 - ==> Top1: 90.660    Top5: 99.650    Loss: 1.554

2018-10-21 07:31:31,442 - ==> Best Top1: 90.840   On Epoch: 204

2018-10-21 07:31:31,442 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:31:31,455 - 

2018-10-21 07:31:31,455 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:31:33,106 - Epoch: [210][   50/  391]    Overall Loss 1.501805    Objective Loss 1.501805    Top1 96.218750    Top5 99.734375    LR 0.003000    Time 0.032943    
2018-10-21 07:31:34,744 - Epoch: [210][  100/  391]    Overall Loss 1.500948    Objective Loss 1.500948    Top1 96.351562    Top5 99.718750    LR 0.003000    Time 0.032825    
2018-10-21 07:31:36,350 - Epoch: [210][  150/  391]    Overall Loss 1.501504    Objective Loss 1.501504    Top1 96.281250    Top5 99.677083    LR 0.003000    Time 0.032565    
2018-10-21 07:31:37,875 - Epoch: [210][  200/  391]    Overall Loss 1.501119    Objective Loss 1.501119    Top1 96.296875    Top5 99.671875    LR 0.003000    Time 0.032032    
2018-10-21 07:31:39,421 - Epoch: [210][  250/  391]    Overall Loss 1.500608    Objective Loss 1.500608    Top1 96.368750    Top5 99.668750    LR 0.003000    Time 0.031800    
2018-10-21 07:31:40,942 - Epoch: [210][  300/  391]    Overall Loss 1.500349    Objective Loss 1.500349    Top1 96.393229    Top5 99.677083    LR 0.003000    Time 0.031565    
2018-10-21 07:31:42,488 - Epoch: [210][  350/  391]    Overall Loss 1.500170    Objective Loss 1.500170    Top1 96.397321    Top5 99.680804    LR 0.003000    Time 0.031462    
2018-10-21 07:31:43,827 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23239 | -0.00201 |    0.15442 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08212 | -0.00304 |    0.04789 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08016 |  0.00122 |    0.05436 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06927 | -0.00625 |    0.04697 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06622 | -0.00245 |    0.04351 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08152 | -0.01024 |    0.05684 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07158 | -0.00682 |    0.05027 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08322 | -0.00333 |    0.06237 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07163 | -0.00356 |    0.05462 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17118 | -0.00004 |    0.10556 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06510 | -0.00265 |    0.04918 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05763 | -0.00703 |    0.04533 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06949 | -0.00678 |    0.05325 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05565 | -0.00391 |    0.04358 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06625 | -0.00504 |    0.05240 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06169 | -0.00334 |    0.04890 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07991 | -0.00454 |    0.06106 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05942 | -0.00718 |    0.04698 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04192 | -0.00331 |    0.03243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03689 | -0.00682 |    0.02886 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02124 |  0.00018 |    0.01452 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40409 | -0.00001 |    0.28509 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:31:43,827 - Total sparsity: 0.00

2018-10-21 07:31:43,827 - --- validate (epoch=210)-----------
2018-10-21 07:31:43,827 - 10000 samples (128 per mini-batch)
2018-10-21 07:31:44,970 - Epoch: [210][   50/   78]    Loss 1.552456    Top1 90.968750    Top5 99.625000    
2018-10-21 07:31:45,589 - ==> Top1: 90.990    Top5: 99.620    Loss: 1.552

2018-10-21 07:31:45,591 - ==> Best Top1: 90.990   On Epoch: 210

2018-10-21 07:31:45,591 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:31:45,608 - 

2018-10-21 07:31:45,608 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:31:47,325 - Epoch: [211][   50/  391]    Overall Loss 1.502719    Objective Loss 1.502719    Top1 96.109375    Top5 99.656250    LR 0.003000    Time 0.034256    
2018-10-21 07:31:48,902 - Epoch: [211][  100/  391]    Overall Loss 1.498730    Objective Loss 1.498730    Top1 96.531250    Top5 99.726562    LR 0.003000    Time 0.032874    
2018-10-21 07:31:50,477 - Epoch: [211][  150/  391]    Overall Loss 1.498750    Objective Loss 1.498750    Top1 96.567708    Top5 99.729167    LR 0.003000    Time 0.032396    
2018-10-21 07:31:52,003 - Epoch: [211][  200/  391]    Overall Loss 1.499443    Objective Loss 1.499443    Top1 96.503906    Top5 99.722656    LR 0.003000    Time 0.031916    
2018-10-21 07:31:53,489 - Epoch: [211][  250/  391]    Overall Loss 1.499827    Objective Loss 1.499827    Top1 96.456250    Top5 99.718750    LR 0.003000    Time 0.031469    
2018-10-21 07:31:54,960 - Epoch: [211][  300/  391]    Overall Loss 1.499446    Objective Loss 1.499446    Top1 96.486979    Top5 99.713542    LR 0.003000    Time 0.031120    
2018-10-21 07:31:56,425 - Epoch: [211][  350/  391]    Overall Loss 1.499504    Objective Loss 1.499504    Top1 96.482143    Top5 99.703125    LR 0.003000    Time 0.030850    
2018-10-21 07:31:57,759 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23213 | -0.00182 |    0.15408 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08203 | -0.00303 |    0.04784 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08007 |  0.00111 |    0.05430 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06920 | -0.00626 |    0.04693 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06615 | -0.00243 |    0.04344 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08143 | -0.01029 |    0.05680 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07150 | -0.00684 |    0.05021 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08313 | -0.00335 |    0.06229 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07155 | -0.00358 |    0.05456 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17099 |  0.00006 |    0.10538 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06503 | -0.00261 |    0.04913 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05757 | -0.00702 |    0.04529 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06941 | -0.00674 |    0.05319 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05559 | -0.00391 |    0.04353 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06618 | -0.00502 |    0.05234 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06163 | -0.00333 |    0.04885 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07982 | -0.00453 |    0.06097 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05936 | -0.00718 |    0.04693 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04188 | -0.00330 |    0.03240 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03685 | -0.00683 |    0.02883 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02121 |  0.00018 |    0.01450 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40401 | -0.00001 |    0.28504 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:31:57,759 - Total sparsity: 0.00

2018-10-21 07:31:57,759 - --- validate (epoch=211)-----------
2018-10-21 07:31:57,759 - 10000 samples (128 per mini-batch)
2018-10-21 07:31:58,947 - Epoch: [211][   50/   78]    Loss 1.551408    Top1 91.046875    Top5 99.593750    
2018-10-21 07:31:59,601 - ==> Top1: 90.900    Top5: 99.610    Loss: 1.552

2018-10-21 07:31:59,602 - ==> Best Top1: 90.990   On Epoch: 210

2018-10-21 07:31:59,603 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:31:59,616 - 

2018-10-21 07:31:59,617 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:32:01,337 - Epoch: [212][   50/  391]    Overall Loss 1.502993    Objective Loss 1.502993    Top1 96.140625    Top5 99.718750    LR 0.003000    Time 0.034345    
2018-10-21 07:32:02,892 - Epoch: [212][  100/  391]    Overall Loss 1.500691    Objective Loss 1.500691    Top1 96.375000    Top5 99.640625    LR 0.003000    Time 0.032692    
2018-10-21 07:32:04,434 - Epoch: [212][  150/  391]    Overall Loss 1.500375    Objective Loss 1.500375    Top1 96.416667    Top5 99.640625    LR 0.003000    Time 0.032053    
2018-10-21 07:32:05,968 - Epoch: [212][  200/  391]    Overall Loss 1.500066    Objective Loss 1.500066    Top1 96.468750    Top5 99.652344    LR 0.003000    Time 0.031699    
2018-10-21 07:32:07,499 - Epoch: [212][  250/  391]    Overall Loss 1.499600    Objective Loss 1.499600    Top1 96.500000    Top5 99.659375    LR 0.003000    Time 0.031475    
2018-10-21 07:32:09,017 - Epoch: [212][  300/  391]    Overall Loss 1.499747    Objective Loss 1.499747    Top1 96.471354    Top5 99.669271    LR 0.003000    Time 0.031280    
2018-10-21 07:32:10,585 - Epoch: [212][  350/  391]    Overall Loss 1.500325    Objective Loss 1.500325    Top1 96.406250    Top5 99.685268    LR 0.003000    Time 0.031283    
2018-10-21 07:32:11,982 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23188 | -0.00187 |    0.15398 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08194 | -0.00303 |    0.04779 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07998 |  0.00112 |    0.05427 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06912 | -0.00624 |    0.04686 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06607 | -0.00251 |    0.04340 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08134 | -0.01028 |    0.05674 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07142 | -0.00682 |    0.05015 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08303 | -0.00338 |    0.06222 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07147 | -0.00358 |    0.05451 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17080 | -0.00001 |    0.10528 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06496 | -0.00264 |    0.04908 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05751 | -0.00699 |    0.04523 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06934 | -0.00675 |    0.05315 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05553 | -0.00391 |    0.04348 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06611 | -0.00499 |    0.05228 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06156 | -0.00332 |    0.04879 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07973 | -0.00452 |    0.06091 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05930 | -0.00716 |    0.04688 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04183 | -0.00331 |    0.03236 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03680 | -0.00684 |    0.02880 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02119 |  0.00017 |    0.01449 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40393 | -0.00001 |    0.28498 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:32:11,982 - Total sparsity: 0.00

2018-10-21 07:32:11,983 - --- validate (epoch=212)-----------
2018-10-21 07:32:11,983 - 10000 samples (128 per mini-batch)
2018-10-21 07:32:13,392 - Epoch: [212][   50/   78]    Loss 1.551885    Top1 91.125000    Top5 99.625000    
2018-10-21 07:32:14,049 - ==> Top1: 91.090    Top5: 99.630    Loss: 1.552

2018-10-21 07:32:14,051 - ==> Best Top1: 91.090   On Epoch: 212

2018-10-21 07:32:14,051 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:32:14,067 - 

2018-10-21 07:32:14,068 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:32:15,960 - Epoch: [213][   50/  391]    Overall Loss 1.497774    Objective Loss 1.497774    Top1 96.812500    Top5 99.578125    LR 0.003000    Time 0.037771    
2018-10-21 07:32:17,698 - Epoch: [213][  100/  391]    Overall Loss 1.498252    Objective Loss 1.498252    Top1 96.664062    Top5 99.648438    LR 0.003000    Time 0.036246    
2018-10-21 07:32:19,411 - Epoch: [213][  150/  391]    Overall Loss 1.498952    Objective Loss 1.498952    Top1 96.567708    Top5 99.635417    LR 0.003000    Time 0.035574    
2018-10-21 07:32:21,151 - Epoch: [213][  200/  391]    Overall Loss 1.498353    Objective Loss 1.498353    Top1 96.652344    Top5 99.660156    LR 0.003000    Time 0.035365    
2018-10-21 07:32:22,882 - Epoch: [213][  250/  391]    Overall Loss 1.498909    Objective Loss 1.498909    Top1 96.584375    Top5 99.671875    LR 0.003000    Time 0.035209    
2018-10-21 07:32:24,612 - Epoch: [213][  300/  391]    Overall Loss 1.498740    Objective Loss 1.498740    Top1 96.596354    Top5 99.695312    LR 0.003000    Time 0.035098    
2018-10-21 07:32:26,343 - Epoch: [213][  350/  391]    Overall Loss 1.499043    Objective Loss 1.499043    Top1 96.553571    Top5 99.696429    LR 0.003000    Time 0.035021    
2018-10-21 07:32:27,903 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23163 | -0.00174 |    0.15387 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08185 | -0.00302 |    0.04774 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07990 |  0.00108 |    0.05420 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06904 | -0.00632 |    0.04680 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06600 | -0.00251 |    0.04336 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08125 | -0.01025 |    0.05667 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07135 | -0.00681 |    0.05010 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08294 | -0.00330 |    0.06214 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07139 | -0.00359 |    0.05444 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17061 |  0.00001 |    0.10517 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06489 | -0.00262 |    0.04902 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05744 | -0.00701 |    0.04519 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06926 | -0.00673 |    0.05308 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05547 | -0.00391 |    0.04344 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06603 | -0.00500 |    0.05223 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06149 | -0.00331 |    0.04874 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07964 | -0.00452 |    0.06084 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05923 | -0.00716 |    0.04683 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04179 | -0.00331 |    0.03233 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03676 | -0.00684 |    0.02877 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02117 |  0.00016 |    0.01448 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40384 | -0.00001 |    0.28493 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:32:27,903 - Total sparsity: 0.00

2018-10-21 07:32:27,903 - --- validate (epoch=213)-----------
2018-10-21 07:32:27,903 - 10000 samples (128 per mini-batch)
2018-10-21 07:32:29,097 - Epoch: [213][   50/   78]    Loss 1.550524    Top1 91.281250    Top5 99.562500    
2018-10-21 07:32:29,734 - ==> Top1: 91.160    Top5: 99.570    Loss: 1.551

2018-10-21 07:32:29,735 - ==> Best Top1: 91.160   On Epoch: 213

2018-10-21 07:32:29,735 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:32:29,751 - 

2018-10-21 07:32:29,752 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:32:31,490 - Epoch: [214][   50/  391]    Overall Loss 1.498999    Objective Loss 1.498999    Top1 96.468750    Top5 99.546875    LR 0.003000    Time 0.034715    
2018-10-21 07:32:33,079 - Epoch: [214][  100/  391]    Overall Loss 1.497587    Objective Loss 1.497587    Top1 96.625000    Top5 99.648438    LR 0.003000    Time 0.033217    
2018-10-21 07:32:34,610 - Epoch: [214][  150/  391]    Overall Loss 1.498244    Objective Loss 1.498244    Top1 96.557292    Top5 99.645833    LR 0.003000    Time 0.032332    
2018-10-21 07:32:36,150 - Epoch: [214][  200/  391]    Overall Loss 1.498149    Objective Loss 1.498149    Top1 96.589844    Top5 99.656250    LR 0.003000    Time 0.031940    
2018-10-21 07:32:37,714 - Epoch: [214][  250/  391]    Overall Loss 1.498968    Objective Loss 1.498968    Top1 96.503125    Top5 99.662500    LR 0.003000    Time 0.031797    
2018-10-21 07:32:39,270 - Epoch: [214][  300/  391]    Overall Loss 1.498846    Objective Loss 1.498846    Top1 96.510417    Top5 99.671875    LR 0.003000    Time 0.031676    
2018-10-21 07:32:40,812 - Epoch: [214][  350/  391]    Overall Loss 1.499206    Objective Loss 1.499206    Top1 96.477679    Top5 99.678571    LR 0.003000    Time 0.031550    
2018-10-21 07:32:42,214 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23137 | -0.00167 |    0.15372 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08176 | -0.00305 |    0.04766 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07981 |  0.00105 |    0.05414 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06896 | -0.00630 |    0.04675 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06593 | -0.00253 |    0.04331 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08116 | -0.01027 |    0.05664 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07127 | -0.00681 |    0.05004 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08285 | -0.00328 |    0.06207 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07131 | -0.00356 |    0.05437 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17042 | -0.00006 |    0.10501 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06482 | -0.00262 |    0.04897 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05738 | -0.00698 |    0.04514 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06919 | -0.00670 |    0.05303 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05541 | -0.00388 |    0.04339 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06596 | -0.00501 |    0.05217 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06143 | -0.00332 |    0.04869 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07955 | -0.00453 |    0.06077 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05916 | -0.00716 |    0.04679 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04174 | -0.00331 |    0.03230 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03672 | -0.00684 |    0.02874 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02114 |  0.00015 |    0.01446 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40374 | -0.00001 |    0.28488 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:32:42,214 - Total sparsity: 0.00

2018-10-21 07:32:42,214 - --- validate (epoch=214)-----------
2018-10-21 07:32:42,214 - 10000 samples (128 per mini-batch)
2018-10-21 07:32:43,430 - Epoch: [214][   50/   78]    Loss 1.551160    Top1 91.218750    Top5 99.609375    
2018-10-21 07:32:44,076 - ==> Top1: 91.030    Top5: 99.650    Loss: 1.552

2018-10-21 07:32:44,078 - ==> Best Top1: 91.160   On Epoch: 213

2018-10-21 07:32:44,079 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:32:44,092 - 

2018-10-21 07:32:44,092 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:32:46,091 - Epoch: [215][   50/  391]    Overall Loss 1.500612    Objective Loss 1.500612    Top1 96.453125    Top5 99.625000    LR 0.003000    Time 0.039922    
2018-10-21 07:32:47,875 - Epoch: [215][  100/  391]    Overall Loss 1.501491    Objective Loss 1.501491    Top1 96.359375    Top5 99.625000    LR 0.003000    Time 0.037769    
2018-10-21 07:32:49,607 - Epoch: [215][  150/  391]    Overall Loss 1.500254    Objective Loss 1.500254    Top1 96.416667    Top5 99.630208    LR 0.003000    Time 0.036711    
2018-10-21 07:32:51,160 - Epoch: [215][  200/  391]    Overall Loss 1.499404    Objective Loss 1.499404    Top1 96.527344    Top5 99.683594    LR 0.003000    Time 0.035289    
2018-10-21 07:32:52,711 - Epoch: [215][  250/  391]    Overall Loss 1.498924    Objective Loss 1.498924    Top1 96.571875    Top5 99.675000    LR 0.003000    Time 0.034423    
2018-10-21 07:32:54,276 - Epoch: [215][  300/  391]    Overall Loss 1.498876    Objective Loss 1.498876    Top1 96.565104    Top5 99.677083    LR 0.003000    Time 0.033895    
2018-10-21 07:32:55,823 - Epoch: [215][  350/  391]    Overall Loss 1.498364    Objective Loss 1.498364    Top1 96.613839    Top5 99.691964    LR 0.003000    Time 0.033468    
2018-10-21 07:32:57,216 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23112 | -0.00173 |    0.15353 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08167 | -0.00305 |    0.04760 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07972 |  0.00109 |    0.05411 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06888 | -0.00633 |    0.04672 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06585 | -0.00254 |    0.04325 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08107 | -0.01023 |    0.05659 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07119 | -0.00680 |    0.05000 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08276 | -0.00329 |    0.06200 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07124 | -0.00351 |    0.05431 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17023 | -0.00006 |    0.10487 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06475 | -0.00257 |    0.04891 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05732 | -0.00697 |    0.04509 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06911 | -0.00668 |    0.05297 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05535 | -0.00388 |    0.04334 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06589 | -0.00500 |    0.05210 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06136 | -0.00332 |    0.04864 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07947 | -0.00453 |    0.06069 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05910 | -0.00715 |    0.04674 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04169 | -0.00331 |    0.03226 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03668 | -0.00685 |    0.02871 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02112 |  0.00015 |    0.01445 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40365 | -0.00001 |    0.28482 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:32:57,216 - Total sparsity: 0.00

2018-10-21 07:32:57,216 - --- validate (epoch=215)-----------
2018-10-21 07:32:57,216 - 10000 samples (128 per mini-batch)
2018-10-21 07:32:58,423 - Epoch: [215][   50/   78]    Loss 1.551058    Top1 91.062500    Top5 99.640625    
2018-10-21 07:32:59,059 - ==> Top1: 91.170    Top5: 99.650    Loss: 1.550

2018-10-21 07:32:59,061 - ==> Best Top1: 91.170   On Epoch: 215

2018-10-21 07:32:59,061 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:32:59,077 - 

2018-10-21 07:32:59,078 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:33:00,960 - Epoch: [216][   50/  391]    Overall Loss 1.497913    Objective Loss 1.497913    Top1 96.656250    Top5 99.703125    LR 0.003000    Time 0.037570    
2018-10-21 07:33:02,728 - Epoch: [216][  100/  391]    Overall Loss 1.498499    Objective Loss 1.498499    Top1 96.554688    Top5 99.742188    LR 0.003000    Time 0.036442    
2018-10-21 07:33:04,476 - Epoch: [216][  150/  391]    Overall Loss 1.498122    Objective Loss 1.498122    Top1 96.609375    Top5 99.750000    LR 0.003000    Time 0.035932    
2018-10-21 07:33:06,175 - Epoch: [216][  200/  391]    Overall Loss 1.498442    Objective Loss 1.498442    Top1 96.554688    Top5 99.742188    LR 0.003000    Time 0.035433    
2018-10-21 07:33:07,922 - Epoch: [216][  250/  391]    Overall Loss 1.498611    Objective Loss 1.498611    Top1 96.537500    Top5 99.731250    LR 0.003000    Time 0.035325    
2018-10-21 07:33:09,663 - Epoch: [216][  300/  391]    Overall Loss 1.498568    Objective Loss 1.498568    Top1 96.559896    Top5 99.731771    LR 0.003000    Time 0.035234    
2018-10-21 07:33:11,398 - Epoch: [216][  350/  391]    Overall Loss 1.497977    Objective Loss 1.497977    Top1 96.625000    Top5 99.743304    LR 0.003000    Time 0.035150    
2018-10-21 07:33:12,948 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23087 | -0.00147 |    0.15337 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08158 | -0.00306 |    0.04754 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07963 |  0.00111 |    0.05402 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06881 | -0.00635 |    0.04667 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06578 | -0.00254 |    0.04318 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08099 | -0.01017 |    0.05652 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07110 | -0.00685 |    0.04995 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08267 | -0.00329 |    0.06193 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07116 | -0.00354 |    0.05425 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17005 | -0.00008 |    0.10477 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06468 | -0.00255 |    0.04885 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05726 | -0.00696 |    0.04504 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06904 | -0.00664 |    0.05291 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05529 | -0.00387 |    0.04330 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06581 | -0.00498 |    0.05205 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06129 | -0.00333 |    0.04859 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07938 | -0.00451 |    0.06063 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05904 | -0.00713 |    0.04669 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04165 | -0.00329 |    0.03223 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03664 | -0.00685 |    0.02868 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02110 |  0.00015 |    0.01443 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40355 | -0.00001 |    0.28475 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:33:12,948 - Total sparsity: 0.00

2018-10-21 07:33:12,948 - --- validate (epoch=216)-----------
2018-10-21 07:33:12,948 - 10000 samples (128 per mini-batch)
2018-10-21 07:33:14,134 - Epoch: [216][   50/   78]    Loss 1.550925    Top1 91.312500    Top5 99.593750    
2018-10-21 07:33:14,764 - ==> Top1: 91.200    Top5: 99.610    Loss: 1.552

2018-10-21 07:33:14,766 - ==> Best Top1: 91.200   On Epoch: 216

2018-10-21 07:33:14,766 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:33:14,783 - 

2018-10-21 07:33:14,783 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:33:16,568 - Epoch: [217][   50/  391]    Overall Loss 1.496632    Objective Loss 1.496632    Top1 96.781250    Top5 99.687500    LR 0.003000    Time 0.035633    
2018-10-21 07:33:18,119 - Epoch: [217][  100/  391]    Overall Loss 1.496484    Objective Loss 1.496484    Top1 96.789062    Top5 99.679688    LR 0.003000    Time 0.033304    
2018-10-21 07:33:19,678 - Epoch: [217][  150/  391]    Overall Loss 1.496468    Objective Loss 1.496468    Top1 96.838542    Top5 99.708333    LR 0.003000    Time 0.032579    
2018-10-21 07:33:21,222 - Epoch: [217][  200/  391]    Overall Loss 1.496842    Objective Loss 1.496842    Top1 96.804688    Top5 99.703125    LR 0.003000    Time 0.032143    
2018-10-21 07:33:22,758 - Epoch: [217][  250/  391]    Overall Loss 1.496721    Objective Loss 1.496721    Top1 96.803125    Top5 99.703125    LR 0.003000    Time 0.031851    
2018-10-21 07:33:24,303 - Epoch: [217][  300/  391]    Overall Loss 1.497507    Objective Loss 1.497507    Top1 96.713542    Top5 99.697917    LR 0.003000    Time 0.031684    
2018-10-21 07:33:25,841 - Epoch: [217][  350/  391]    Overall Loss 1.497786    Objective Loss 1.497786    Top1 96.689732    Top5 99.696429    LR 0.003000    Time 0.031546    
2018-10-21 07:33:27,231 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23061 | -0.00165 |    0.15309 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08149 | -0.00306 |    0.04752 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07954 |  0.00114 |    0.05398 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06873 | -0.00636 |    0.04662 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06571 | -0.00249 |    0.04313 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08089 | -0.01022 |    0.05647 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07103 | -0.00679 |    0.04988 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08258 | -0.00320 |    0.06186 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07108 | -0.00351 |    0.05419 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16986 | -0.00003 |    0.10461 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06461 | -0.00254 |    0.04879 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05720 | -0.00691 |    0.04498 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06897 | -0.00662 |    0.05286 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05523 | -0.00385 |    0.04325 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06574 | -0.00498 |    0.05199 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06122 | -0.00331 |    0.04854 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07929 | -0.00453 |    0.06055 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05897 | -0.00713 |    0.04665 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04161 | -0.00328 |    0.03219 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03660 | -0.00684 |    0.02865 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02108 |  0.00014 |    0.01442 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40347 | -0.00001 |    0.28470 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:33:27,232 - Total sparsity: 0.00

2018-10-21 07:33:27,232 - --- validate (epoch=217)-----------
2018-10-21 07:33:27,232 - 10000 samples (128 per mini-batch)
2018-10-21 07:33:28,480 - Epoch: [217][   50/   78]    Loss 1.551260    Top1 91.171875    Top5 99.578125    
2018-10-21 07:33:29,115 - ==> Top1: 91.120    Top5: 99.600    Loss: 1.551

2018-10-21 07:33:29,116 - ==> Best Top1: 91.200   On Epoch: 216

2018-10-21 07:33:29,117 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:33:29,130 - 

2018-10-21 07:33:29,130 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:33:30,865 - Epoch: [218][   50/  391]    Overall Loss 1.497517    Objective Loss 1.497517    Top1 96.781250    Top5 99.734375    LR 0.003000    Time 0.034636    
2018-10-21 07:33:32,496 - Epoch: [218][  100/  391]    Overall Loss 1.498132    Objective Loss 1.498132    Top1 96.687500    Top5 99.703125    LR 0.003000    Time 0.033603    
2018-10-21 07:33:34,080 - Epoch: [218][  150/  391]    Overall Loss 1.498297    Objective Loss 1.498297    Top1 96.682292    Top5 99.703125    LR 0.003000    Time 0.032947    
2018-10-21 07:33:35,616 - Epoch: [218][  200/  391]    Overall Loss 1.497790    Objective Loss 1.497790    Top1 96.722656    Top5 99.695312    LR 0.003000    Time 0.032371    
2018-10-21 07:33:37,136 - Epoch: [218][  250/  391]    Overall Loss 1.497629    Objective Loss 1.497629    Top1 96.725000    Top5 99.712500    LR 0.003000    Time 0.031969    
2018-10-21 07:33:38,678 - Epoch: [218][  300/  391]    Overall Loss 1.497763    Objective Loss 1.497763    Top1 96.684896    Top5 99.695312    LR 0.003000    Time 0.031772    
2018-10-21 07:33:40,204 - Epoch: [218][  350/  391]    Overall Loss 1.497580    Objective Loss 1.497580    Top1 96.700893    Top5 99.698661    LR 0.003000    Time 0.031586    
2018-10-21 07:33:41,554 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23036 | -0.00135 |    0.15302 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08140 | -0.00309 |    0.04748 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07946 |  0.00122 |    0.05390 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06865 | -0.00637 |    0.04656 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06564 | -0.00245 |    0.04310 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08080 | -0.01024 |    0.05641 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07095 | -0.00678 |    0.04984 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08249 | -0.00315 |    0.06180 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07100 | -0.00353 |    0.05412 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16967 |  0.00005 |    0.10448 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06454 | -0.00254 |    0.04873 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05714 | -0.00689 |    0.04494 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06890 | -0.00659 |    0.05279 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05517 | -0.00383 |    0.04320 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06567 | -0.00498 |    0.05193 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06116 | -0.00330 |    0.04849 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07920 | -0.00453 |    0.06047 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05891 | -0.00712 |    0.04660 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04156 | -0.00327 |    0.03216 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03656 | -0.00685 |    0.02862 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02105 |  0.00014 |    0.01441 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40339 | -0.00001 |    0.28465 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:33:41,554 - Total sparsity: 0.00

2018-10-21 07:33:41,554 - --- validate (epoch=218)-----------
2018-10-21 07:33:41,555 - 10000 samples (128 per mini-batch)
2018-10-21 07:33:42,800 - Epoch: [218][   50/   78]    Loss 1.549695    Top1 91.296875    Top5 99.609375    
2018-10-21 07:33:43,425 - ==> Top1: 91.150    Top5: 99.610    Loss: 1.550

2018-10-21 07:33:43,427 - ==> Best Top1: 91.200   On Epoch: 216

2018-10-21 07:33:43,427 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:33:43,441 - 

2018-10-21 07:33:43,442 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:33:45,382 - Epoch: [219][   50/  391]    Overall Loss 1.496517    Objective Loss 1.496517    Top1 96.890625    Top5 99.734375    LR 0.003000    Time 0.038726    
2018-10-21 07:33:47,123 - Epoch: [219][  100/  391]    Overall Loss 1.497989    Objective Loss 1.497989    Top1 96.703125    Top5 99.718750    LR 0.003000    Time 0.036745    
2018-10-21 07:33:48,819 - Epoch: [219][  150/  391]    Overall Loss 1.498377    Objective Loss 1.498377    Top1 96.645833    Top5 99.718750    LR 0.003000    Time 0.035787    
2018-10-21 07:33:50,504 - Epoch: [219][  200/  391]    Overall Loss 1.498766    Objective Loss 1.498766    Top1 96.578125    Top5 99.695312    LR 0.003000    Time 0.035257    
2018-10-21 07:33:52,167 - Epoch: [219][  250/  391]    Overall Loss 1.498427    Objective Loss 1.498427    Top1 96.612500    Top5 99.712500    LR 0.003000    Time 0.034848    
2018-10-21 07:33:53,663 - Epoch: [219][  300/  391]    Overall Loss 1.498281    Objective Loss 1.498281    Top1 96.625000    Top5 99.710938    LR 0.003000    Time 0.034016    
2018-10-21 07:33:55,154 - Epoch: [219][  350/  391]    Overall Loss 1.497633    Objective Loss 1.497633    Top1 96.678571    Top5 99.720982    LR 0.003000    Time 0.033408    
2018-10-21 07:33:56,509 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23011 | -0.00131 |    0.15288 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08131 | -0.00309 |    0.04742 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07937 |  0.00116 |    0.05385 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06858 | -0.00639 |    0.04652 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06557 | -0.00245 |    0.04307 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08071 | -0.01022 |    0.05635 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07088 | -0.00670 |    0.04978 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08240 | -0.00313 |    0.06173 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07092 | -0.00355 |    0.05405 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16948 |  0.00007 |    0.10433 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06447 | -0.00251 |    0.04866 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05707 | -0.00690 |    0.04490 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06882 | -0.00660 |    0.05274 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05511 | -0.00384 |    0.04315 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06560 | -0.00496 |    0.05188 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06109 | -0.00330 |    0.04843 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07911 | -0.00454 |    0.06040 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05885 | -0.00711 |    0.04655 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04152 | -0.00328 |    0.03212 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03652 | -0.00684 |    0.02859 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02103 |  0.00014 |    0.01440 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40330 | -0.00001 |    0.28459 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:33:56,509 - Total sparsity: 0.00

2018-10-21 07:33:56,510 - --- validate (epoch=219)-----------
2018-10-21 07:33:56,510 - 10000 samples (128 per mini-batch)
2018-10-21 07:33:57,896 - Epoch: [219][   50/   78]    Loss 1.551120    Top1 91.046875    Top5 99.625000    
2018-10-21 07:33:58,602 - ==> Top1: 90.990    Top5: 99.590    Loss: 1.551

2018-10-21 07:33:58,604 - ==> Best Top1: 91.200   On Epoch: 216

2018-10-21 07:33:58,604 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:33:58,617 - 

2018-10-21 07:33:58,617 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:34:00,282 - Epoch: [220][   50/  391]    Overall Loss 1.498824    Objective Loss 1.498824    Top1 96.515625    Top5 99.625000    LR 0.003000    Time 0.033233    
2018-10-21 07:34:01,796 - Epoch: [220][  100/  391]    Overall Loss 1.498080    Objective Loss 1.498080    Top1 96.593750    Top5 99.648438    LR 0.003000    Time 0.031729    
2018-10-21 07:34:03,370 - Epoch: [220][  150/  391]    Overall Loss 1.498219    Objective Loss 1.498219    Top1 96.598958    Top5 99.630208    LR 0.003000    Time 0.031625    
2018-10-21 07:34:04,865 - Epoch: [220][  200/  391]    Overall Loss 1.497674    Objective Loss 1.497674    Top1 96.656250    Top5 99.644531    LR 0.003000    Time 0.031180    
2018-10-21 07:34:06,377 - Epoch: [220][  250/  391]    Overall Loss 1.497465    Objective Loss 1.497465    Top1 96.675000    Top5 99.656250    LR 0.003000    Time 0.030982    
2018-10-21 07:34:07,935 - Epoch: [220][  300/  391]    Overall Loss 1.497275    Objective Loss 1.497275    Top1 96.687500    Top5 99.674479    LR 0.003000    Time 0.031004    
2018-10-21 07:34:09,432 - Epoch: [220][  350/  391]    Overall Loss 1.496998    Objective Loss 1.496998    Top1 96.718750    Top5 99.687500    LR 0.003000    Time 0.030844    
2018-10-21 07:34:10,792 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22986 | -0.00136 |    0.15281 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08122 | -0.00311 |    0.04738 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07928 |  0.00111 |    0.05378 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06850 | -0.00635 |    0.04644 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06549 | -0.00247 |    0.04300 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08064 | -0.01010 |    0.05626 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07080 | -0.00671 |    0.04973 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08231 | -0.00317 |    0.06164 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07085 | -0.00353 |    0.05399 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16930 |  0.00013 |    0.10426 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06440 | -0.00252 |    0.04862 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05701 | -0.00689 |    0.04485 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06875 | -0.00659 |    0.05269 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05505 | -0.00383 |    0.04311 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06553 | -0.00494 |    0.05182 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06102 | -0.00330 |    0.04838 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07902 | -0.00453 |    0.06033 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05878 | -0.00710 |    0.04650 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04147 | -0.00329 |    0.03209 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03648 | -0.00684 |    0.02856 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02101 |  0.00013 |    0.01438 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40320 | -0.00001 |    0.28453 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:34:10,792 - Total sparsity: 0.00

2018-10-21 07:34:10,792 - --- validate (epoch=220)-----------
2018-10-21 07:34:10,793 - 10000 samples (128 per mini-batch)
2018-10-21 07:34:11,995 - Epoch: [220][   50/   78]    Loss 1.550103    Top1 91.265625    Top5 99.609375    
2018-10-21 07:34:12,643 - ==> Top1: 91.180    Top5: 99.620    Loss: 1.550

2018-10-21 07:34:12,644 - ==> Best Top1: 91.200   On Epoch: 216

2018-10-21 07:34:12,645 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:34:12,658 - 

2018-10-21 07:34:12,659 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:34:14,357 - Epoch: [221][   50/  391]    Overall Loss 1.498288    Objective Loss 1.498288    Top1 96.515625    Top5 99.796875    LR 0.003000    Time 0.033900    
2018-10-21 07:34:15,870 - Epoch: [221][  100/  391]    Overall Loss 1.497884    Objective Loss 1.497884    Top1 96.539062    Top5 99.734375    LR 0.003000    Time 0.032055    
2018-10-21 07:34:17,435 - Epoch: [221][  150/  391]    Overall Loss 1.496430    Objective Loss 1.496430    Top1 96.729167    Top5 99.713542    LR 0.003000    Time 0.031791    
2018-10-21 07:34:18,968 - Epoch: [221][  200/  391]    Overall Loss 1.496405    Objective Loss 1.496405    Top1 96.761719    Top5 99.707031    LR 0.003000    Time 0.031495    
2018-10-21 07:34:20,466 - Epoch: [221][  250/  391]    Overall Loss 1.495914    Objective Loss 1.495914    Top1 96.818750    Top5 99.734375    LR 0.003000    Time 0.031182    
2018-10-21 07:34:21,974 - Epoch: [221][  300/  391]    Overall Loss 1.496054    Objective Loss 1.496054    Top1 96.812500    Top5 99.729167    LR 0.003000    Time 0.031002    
2018-10-21 07:34:23,470 - Epoch: [221][  350/  391]    Overall Loss 1.495599    Objective Loss 1.495599    Top1 96.866071    Top5 99.716518    LR 0.003000    Time 0.030842    
2018-10-21 07:34:24,830 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22961 | -0.00141 |    0.15248 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08113 | -0.00316 |    0.04734 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07919 |  0.00115 |    0.05373 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06843 | -0.00635 |    0.04640 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06543 | -0.00235 |    0.04296 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08054 | -0.01012 |    0.05622 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07072 | -0.00673 |    0.04970 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08222 | -0.00325 |    0.06159 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07077 | -0.00356 |    0.05393 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16911 |  0.00016 |    0.10405 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06433 | -0.00255 |    0.04856 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05695 | -0.00689 |    0.04480 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06867 | -0.00660 |    0.05264 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05499 | -0.00382 |    0.04306 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06546 | -0.00494 |    0.05177 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06096 | -0.00330 |    0.04833 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07893 | -0.00453 |    0.06026 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05872 | -0.00709 |    0.04645 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04143 | -0.00329 |    0.03206 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03644 | -0.00684 |    0.02853 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02098 |  0.00013 |    0.01437 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40311 | -0.00001 |    0.28447 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:34:24,831 - Total sparsity: 0.00

2018-10-21 07:34:24,831 - --- validate (epoch=221)-----------
2018-10-21 07:34:24,831 - 10000 samples (128 per mini-batch)
2018-10-21 07:34:26,031 - Epoch: [221][   50/   78]    Loss 1.551957    Top1 90.875000    Top5 99.640625    
2018-10-21 07:34:26,658 - ==> Top1: 90.880    Top5: 99.670    Loss: 1.552

2018-10-21 07:34:26,660 - ==> Best Top1: 91.200   On Epoch: 216

2018-10-21 07:34:26,660 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:34:26,673 - 

2018-10-21 07:34:26,673 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:34:28,294 - Epoch: [222][   50/  391]    Overall Loss 1.497974    Objective Loss 1.497974    Top1 96.578125    Top5 99.625000    LR 0.003000    Time 0.032371    
2018-10-21 07:34:29,928 - Epoch: [222][  100/  391]    Overall Loss 1.495515    Objective Loss 1.495515    Top1 96.843750    Top5 99.632812    LR 0.003000    Time 0.032499    
2018-10-21 07:34:31,467 - Epoch: [222][  150/  391]    Overall Loss 1.496368    Objective Loss 1.496368    Top1 96.760417    Top5 99.614583    LR 0.003000    Time 0.031914    
2018-10-21 07:34:33,029 - Epoch: [222][  200/  391]    Overall Loss 1.495251    Objective Loss 1.495251    Top1 96.875000    Top5 99.652344    LR 0.003000    Time 0.031734    
2018-10-21 07:34:34,598 - Epoch: [222][  250/  391]    Overall Loss 1.495801    Objective Loss 1.495801    Top1 96.815625    Top5 99.656250    LR 0.003000    Time 0.031654    
2018-10-21 07:34:36,136 - Epoch: [222][  300/  391]    Overall Loss 1.496049    Objective Loss 1.496049    Top1 96.809896    Top5 99.674479    LR 0.003000    Time 0.031496    
2018-10-21 07:34:37,634 - Epoch: [222][  350/  391]    Overall Loss 1.496432    Objective Loss 1.496432    Top1 96.779018    Top5 99.676339    LR 0.003000    Time 0.031268    
2018-10-21 07:34:39,034 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22935 | -0.00154 |    0.15226 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08104 | -0.00308 |    0.04730 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07911 |  0.00115 |    0.05367 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06835 | -0.00634 |    0.04635 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06535 | -0.00234 |    0.04289 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08045 | -0.01012 |    0.05616 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07065 | -0.00668 |    0.04966 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08213 | -0.00315 |    0.06151 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07069 | -0.00349 |    0.05387 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16892 |  0.00014 |    0.10394 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06426 | -0.00252 |    0.04851 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05689 | -0.00688 |    0.04475 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06860 | -0.00656 |    0.05258 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05493 | -0.00382 |    0.04300 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06539 | -0.00491 |    0.05171 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06089 | -0.00328 |    0.04828 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07885 | -0.00454 |    0.06020 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05865 | -0.00709 |    0.04641 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04138 | -0.00328 |    0.03203 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03640 | -0.00684 |    0.02850 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02096 |  0.00012 |    0.01435 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40301 | -0.00001 |    0.28440 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:34:39,034 - Total sparsity: 0.00

2018-10-21 07:34:39,035 - --- validate (epoch=222)-----------
2018-10-21 07:34:39,035 - 10000 samples (128 per mini-batch)
2018-10-21 07:34:40,221 - Epoch: [222][   50/   78]    Loss 1.549852    Top1 91.281250    Top5 99.656250    
2018-10-21 07:34:40,868 - ==> Top1: 91.220    Top5: 99.640    Loss: 1.550

2018-10-21 07:34:40,870 - ==> Best Top1: 91.220   On Epoch: 222

2018-10-21 07:34:40,871 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:34:40,887 - 

2018-10-21 07:34:40,887 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:34:42,632 - Epoch: [223][   50/  391]    Overall Loss 1.498388    Objective Loss 1.498388    Top1 96.640625    Top5 99.546875    LR 0.003000    Time 0.034827    
2018-10-21 07:34:44,189 - Epoch: [223][  100/  391]    Overall Loss 1.496727    Objective Loss 1.496727    Top1 96.765625    Top5 99.664062    LR 0.003000    Time 0.032958    
2018-10-21 07:34:45,756 - Epoch: [223][  150/  391]    Overall Loss 1.496419    Objective Loss 1.496419    Top1 96.781250    Top5 99.682292    LR 0.003000    Time 0.032399    
2018-10-21 07:34:47,305 - Epoch: [223][  200/  391]    Overall Loss 1.496517    Objective Loss 1.496517    Top1 96.757812    Top5 99.636719    LR 0.003000    Time 0.032033    
2018-10-21 07:34:48,858 - Epoch: [223][  250/  391]    Overall Loss 1.496002    Objective Loss 1.496002    Top1 96.815625    Top5 99.659375    LR 0.003000    Time 0.031828    
2018-10-21 07:34:50,406 - Epoch: [223][  300/  391]    Overall Loss 1.495631    Objective Loss 1.495631    Top1 96.856771    Top5 99.684896    LR 0.003000    Time 0.031675    
2018-10-21 07:34:51,922 - Epoch: [223][  350/  391]    Overall Loss 1.495813    Objective Loss 1.495813    Top1 96.837054    Top5 99.685268    LR 0.003000    Time 0.031478    
2018-10-21 07:34:53,295 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22910 | -0.00132 |    0.15207 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08095 | -0.00312 |    0.04725 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07902 |  0.00112 |    0.05363 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06828 | -0.00632 |    0.04630 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06528 | -0.00230 |    0.04285 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08036 | -0.01013 |    0.05612 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07057 | -0.00662 |    0.04959 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08204 | -0.00310 |    0.06144 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07061 | -0.00349 |    0.05381 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16874 |  0.00015 |    0.10379 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06419 | -0.00251 |    0.04846 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05683 | -0.00686 |    0.04470 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06853 | -0.00653 |    0.05252 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05487 | -0.00384 |    0.04296 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06531 | -0.00490 |    0.05165 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06083 | -0.00328 |    0.04822 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07876 | -0.00458 |    0.06014 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05859 | -0.00708 |    0.04636 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04134 | -0.00327 |    0.03199 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03635 | -0.00684 |    0.02847 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02094 |  0.00011 |    0.01434 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40291 | -0.00001 |    0.28434 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:34:53,295 - Total sparsity: 0.00

2018-10-21 07:34:53,295 - --- validate (epoch=223)-----------
2018-10-21 07:34:53,295 - 10000 samples (128 per mini-batch)
2018-10-21 07:34:54,480 - Epoch: [223][   50/   78]    Loss 1.549650    Top1 91.312500    Top5 99.640625    
2018-10-21 07:34:55,105 - ==> Top1: 91.280    Top5: 99.620    Loss: 1.550

2018-10-21 07:34:55,107 - ==> Best Top1: 91.280   On Epoch: 223

2018-10-21 07:34:55,107 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:34:55,121 - 

2018-10-21 07:34:55,121 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:34:56,741 - Epoch: [224][   50/  391]    Overall Loss 1.498484    Objective Loss 1.498484    Top1 96.562500    Top5 99.734375    LR 0.003000    Time 0.032337    
2018-10-21 07:34:58,328 - Epoch: [224][  100/  391]    Overall Loss 1.496216    Objective Loss 1.496216    Top1 96.875000    Top5 99.718750    LR 0.003000    Time 0.032009    
2018-10-21 07:34:59,870 - Epoch: [224][  150/  391]    Overall Loss 1.495686    Objective Loss 1.495686    Top1 96.890625    Top5 99.755208    LR 0.003000    Time 0.031605    
2018-10-21 07:35:01,402 - Epoch: [224][  200/  391]    Overall Loss 1.495872    Objective Loss 1.495872    Top1 96.855469    Top5 99.734375    LR 0.003000    Time 0.031349    
2018-10-21 07:35:02,985 - Epoch: [224][  250/  391]    Overall Loss 1.494802    Objective Loss 1.494802    Top1 96.971875    Top5 99.746875    LR 0.003000    Time 0.031399    
2018-10-21 07:35:04,527 - Epoch: [224][  300/  391]    Overall Loss 1.495564    Objective Loss 1.495564    Top1 96.888021    Top5 99.739583    LR 0.003000    Time 0.031297    
2018-10-21 07:35:06,074 - Epoch: [224][  350/  391]    Overall Loss 1.495847    Objective Loss 1.495847    Top1 96.850446    Top5 99.736607    LR 0.003000    Time 0.031241    
2018-10-21 07:35:07,485 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22885 | -0.00112 |    0.15197 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08087 | -0.00305 |    0.04722 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07893 |  0.00114 |    0.05358 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06821 | -0.00625 |    0.04624 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06521 | -0.00229 |    0.04282 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08029 | -0.01004 |    0.05605 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07049 | -0.00664 |    0.04953 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08195 | -0.00309 |    0.06138 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07054 | -0.00349 |    0.05375 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16855 |  0.00004 |    0.10369 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06412 | -0.00250 |    0.04841 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05677 | -0.00686 |    0.04466 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06845 | -0.00654 |    0.05246 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05481 | -0.00381 |    0.04291 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06524 | -0.00488 |    0.05158 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06076 | -0.00327 |    0.04817 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07867 | -0.00452 |    0.06008 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05852 | -0.00709 |    0.04631 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04129 | -0.00327 |    0.03196 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03631 | -0.00685 |    0.02843 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02091 |  0.00011 |    0.01432 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40283 | -0.00001 |    0.28428 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:35:07,485 - Total sparsity: 0.00

2018-10-21 07:35:07,485 - --- validate (epoch=224)-----------
2018-10-21 07:35:07,486 - 10000 samples (128 per mini-batch)
2018-10-21 07:35:08,681 - Epoch: [224][   50/   78]    Loss 1.549180    Top1 91.343750    Top5 99.609375    
2018-10-21 07:35:09,312 - ==> Top1: 91.290    Top5: 99.630    Loss: 1.549

2018-10-21 07:35:09,314 - ==> Best Top1: 91.290   On Epoch: 224

2018-10-21 07:35:09,314 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:35:09,331 - 

2018-10-21 07:35:09,331 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:35:11,069 - Epoch: [225][   50/  391]    Overall Loss 1.491386    Objective Loss 1.491386    Top1 97.296875    Top5 99.625000    LR 0.003000    Time 0.034688    
2018-10-21 07:35:12,609 - Epoch: [225][  100/  391]    Overall Loss 1.493393    Objective Loss 1.493393    Top1 97.093750    Top5 99.609375    LR 0.003000    Time 0.032720    
2018-10-21 07:35:14,120 - Epoch: [225][  150/  391]    Overall Loss 1.494805    Objective Loss 1.494805    Top1 96.937500    Top5 99.625000    LR 0.003000    Time 0.031872    
2018-10-21 07:35:15,657 - Epoch: [225][  200/  391]    Overall Loss 1.495513    Objective Loss 1.495513    Top1 96.863281    Top5 99.652344    LR 0.003000    Time 0.031579    
2018-10-21 07:35:17,206 - Epoch: [225][  250/  391]    Overall Loss 1.495542    Objective Loss 1.495542    Top1 96.850000    Top5 99.662500    LR 0.003000    Time 0.031448    
2018-10-21 07:35:18,759 - Epoch: [225][  300/  391]    Overall Loss 1.495424    Objective Loss 1.495424    Top1 96.856771    Top5 99.684896    LR 0.003000    Time 0.031376    
2018-10-21 07:35:20,306 - Epoch: [225][  350/  391]    Overall Loss 1.495372    Objective Loss 1.495372    Top1 96.857143    Top5 99.687500    LR 0.003000    Time 0.031307    
2018-10-21 07:35:21,686 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22860 | -0.00123 |    0.15182 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08078 | -0.00307 |    0.04716 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07885 |  0.00113 |    0.05354 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06813 | -0.00627 |    0.04621 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06514 | -0.00230 |    0.04277 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08020 | -0.01000 |    0.05600 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07042 | -0.00662 |    0.04949 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08186 | -0.00313 |    0.06130 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07046 | -0.00348 |    0.05369 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16836 |  0.00005 |    0.10355 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06405 | -0.00250 |    0.04836 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05670 | -0.00686 |    0.04461 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06838 | -0.00652 |    0.05240 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05475 | -0.00383 |    0.04286 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06517 | -0.00486 |    0.05152 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06069 | -0.00327 |    0.04811 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07858 | -0.00451 |    0.06000 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05846 | -0.00707 |    0.04626 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04125 | -0.00326 |    0.03193 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03627 | -0.00684 |    0.02840 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02089 |  0.00011 |    0.01431 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40274 | -0.00001 |    0.28423 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:35:21,686 - Total sparsity: 0.00

2018-10-21 07:35:21,687 - --- validate (epoch=225)-----------
2018-10-21 07:35:21,687 - 10000 samples (128 per mini-batch)
2018-10-21 07:35:22,905 - Epoch: [225][   50/   78]    Loss 1.549932    Top1 91.296875    Top5 99.578125    
2018-10-21 07:35:23,545 - ==> Top1: 91.210    Top5: 99.610    Loss: 1.550

2018-10-21 07:35:23,546 - ==> Best Top1: 91.290   On Epoch: 224

2018-10-21 07:35:23,546 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:35:23,559 - 

2018-10-21 07:35:23,559 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:35:25,204 - Epoch: [226][   50/  391]    Overall Loss 1.496130    Objective Loss 1.496130    Top1 96.828125    Top5 99.750000    LR 0.003000    Time 0.032819    
2018-10-21 07:35:26,755 - Epoch: [226][  100/  391]    Overall Loss 1.495478    Objective Loss 1.495478    Top1 96.875000    Top5 99.742188    LR 0.003000    Time 0.031894    
2018-10-21 07:35:28,321 - Epoch: [226][  150/  391]    Overall Loss 1.496655    Objective Loss 1.496655    Top1 96.739583    Top5 99.682292    LR 0.003000    Time 0.031681    
2018-10-21 07:35:29,891 - Epoch: [226][  200/  391]    Overall Loss 1.495581    Objective Loss 1.495581    Top1 96.847656    Top5 99.683594    LR 0.003000    Time 0.031600    
2018-10-21 07:35:31,470 - Epoch: [226][  250/  391]    Overall Loss 1.495087    Objective Loss 1.495087    Top1 96.906250    Top5 99.668750    LR 0.003000    Time 0.031588    
2018-10-21 07:35:33,054 - Epoch: [226][  300/  391]    Overall Loss 1.495305    Objective Loss 1.495305    Top1 96.880208    Top5 99.674479    LR 0.003000    Time 0.031594    
2018-10-21 07:35:34,873 - Epoch: [226][  350/  391]    Overall Loss 1.495048    Objective Loss 1.495048    Top1 96.912946    Top5 99.669643    LR 0.003000    Time 0.032272    
2018-10-21 07:35:36,414 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22835 | -0.00104 |    0.15171 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08069 | -0.00315 |    0.04711 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07876 |  0.00112 |    0.05348 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06805 | -0.00632 |    0.04618 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06507 | -0.00231 |    0.04271 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08011 | -0.00997 |    0.05593 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07034 | -0.00662 |    0.04943 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08177 | -0.00305 |    0.06123 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07038 | -0.00348 |    0.05363 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16818 |  0.00010 |    0.10343 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06398 | -0.00247 |    0.04831 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05664 | -0.00686 |    0.04455 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06830 | -0.00652 |    0.05235 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05469 | -0.00381 |    0.04282 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06510 | -0.00486 |    0.05147 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06063 | -0.00329 |    0.04806 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07850 | -0.00451 |    0.05992 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05840 | -0.00706 |    0.04622 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04120 | -0.00327 |    0.03190 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03623 | -0.00683 |    0.02838 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02087 |  0.00010 |    0.01430 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40265 | -0.00001 |    0.28417 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:35:36,414 - Total sparsity: 0.00

2018-10-21 07:35:36,414 - --- validate (epoch=226)-----------
2018-10-21 07:35:36,414 - 10000 samples (128 per mini-batch)
2018-10-21 07:35:37,586 - Epoch: [226][   50/   78]    Loss 1.550278    Top1 91.187500    Top5 99.578125    
2018-10-21 07:35:38,211 - ==> Top1: 91.200    Top5: 99.610    Loss: 1.550

2018-10-21 07:35:38,213 - ==> Best Top1: 91.290   On Epoch: 224

2018-10-21 07:35:38,213 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:35:38,226 - 

2018-10-21 07:35:38,227 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:35:39,969 - Epoch: [227][   50/  391]    Overall Loss 1.495318    Objective Loss 1.495318    Top1 97.015625    Top5 99.703125    LR 0.003000    Time 0.034789    
2018-10-21 07:35:41,567 - Epoch: [227][  100/  391]    Overall Loss 1.494154    Objective Loss 1.494154    Top1 97.117188    Top5 99.718750    LR 0.003000    Time 0.033340    
2018-10-21 07:35:43,124 - Epoch: [227][  150/  391]    Overall Loss 1.492668    Objective Loss 1.492668    Top1 97.244792    Top5 99.703125    LR 0.003000    Time 0.032591    
2018-10-21 07:35:44,654 - Epoch: [227][  200/  391]    Overall Loss 1.493709    Objective Loss 1.493709    Top1 97.117188    Top5 99.695312    LR 0.003000    Time 0.032080    
2018-10-21 07:35:46,178 - Epoch: [227][  250/  391]    Overall Loss 1.494031    Objective Loss 1.494031    Top1 97.075000    Top5 99.700000    LR 0.003000    Time 0.031751    
2018-10-21 07:35:47,778 - Epoch: [227][  300/  391]    Overall Loss 1.494306    Objective Loss 1.494306    Top1 97.023438    Top5 99.721354    LR 0.003000    Time 0.031784    
2018-10-21 07:35:49,282 - Epoch: [227][  350/  391]    Overall Loss 1.494629    Objective Loss 1.494629    Top1 96.991071    Top5 99.714286    LR 0.003000    Time 0.031533    
2018-10-21 07:35:50,662 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22810 | -0.00118 |    0.15139 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08059 | -0.00323 |    0.04708 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07867 |  0.00114 |    0.05342 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06798 | -0.00636 |    0.04614 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06500 | -0.00233 |    0.04267 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08002 | -0.01002 |    0.05588 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07025 | -0.00669 |    0.04936 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08168 | -0.00302 |    0.06116 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07030 | -0.00348 |    0.05357 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16799 |  0.00006 |    0.10327 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06391 | -0.00247 |    0.04824 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05658 | -0.00688 |    0.04451 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06823 | -0.00653 |    0.05229 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05463 | -0.00384 |    0.04278 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06503 | -0.00486 |    0.05142 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06056 | -0.00327 |    0.04801 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07841 | -0.00450 |    0.05985 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05834 | -0.00705 |    0.04617 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04116 | -0.00326 |    0.03187 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03620 | -0.00682 |    0.02834 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02085 |  0.00010 |    0.01428 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40257 | -0.00001 |    0.28413 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:35:50,662 - Total sparsity: 0.00

2018-10-21 07:35:50,662 - --- validate (epoch=227)-----------
2018-10-21 07:35:50,663 - 10000 samples (128 per mini-batch)
2018-10-21 07:35:51,862 - Epoch: [227][   50/   78]    Loss 1.548426    Top1 91.375000    Top5 99.578125    
2018-10-21 07:35:52,508 - ==> Top1: 91.390    Top5: 99.560    Loss: 1.548

2018-10-21 07:35:52,510 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:35:52,510 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:35:52,527 - 

2018-10-21 07:35:52,527 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:35:54,201 - Epoch: [228][   50/  391]    Overall Loss 1.495471    Objective Loss 1.495471    Top1 96.828125    Top5 99.593750    LR 0.003000    Time 0.033392    
2018-10-21 07:35:55,689 - Epoch: [228][  100/  391]    Overall Loss 1.494637    Objective Loss 1.494637    Top1 96.960938    Top5 99.648438    LR 0.003000    Time 0.031554    
2018-10-21 07:35:57,197 - Epoch: [228][  150/  391]    Overall Loss 1.494482    Objective Loss 1.494482    Top1 97.020833    Top5 99.651042    LR 0.003000    Time 0.031071    
2018-10-21 07:35:58,717 - Epoch: [228][  200/  391]    Overall Loss 1.494340    Objective Loss 1.494340    Top1 97.019531    Top5 99.671875    LR 0.003000    Time 0.030891    
2018-10-21 07:36:00,216 - Epoch: [228][  250/  391]    Overall Loss 1.494792    Objective Loss 1.494792    Top1 96.990625    Top5 99.690625    LR 0.003000    Time 0.030698    
2018-10-21 07:36:01,710 - Epoch: [228][  300/  391]    Overall Loss 1.494497    Objective Loss 1.494497    Top1 97.005208    Top5 99.677083    LR 0.003000    Time 0.030555    
2018-10-21 07:36:03,236 - Epoch: [228][  350/  391]    Overall Loss 1.494876    Objective Loss 1.494876    Top1 96.962054    Top5 99.680804    LR 0.003000    Time 0.030540    
2018-10-21 07:36:04,594 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22785 | -0.00105 |    0.15135 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08051 | -0.00321 |    0.04702 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07859 |  0.00110 |    0.05334 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06790 | -0.00634 |    0.04610 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06493 | -0.00228 |    0.04262 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07992 | -0.01010 |    0.05582 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07018 | -0.00668 |    0.04932 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08159 | -0.00309 |    0.06110 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07023 | -0.00351 |    0.05351 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16781 |  0.00012 |    0.10299 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06384 | -0.00245 |    0.04819 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05652 | -0.00685 |    0.04446 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06815 | -0.00652 |    0.05224 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05458 | -0.00382 |    0.04274 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06496 | -0.00486 |    0.05136 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06050 | -0.00325 |    0.04796 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07832 | -0.00450 |    0.05978 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05827 | -0.00705 |    0.04612 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04112 | -0.00325 |    0.03183 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03615 | -0.00684 |    0.02831 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02082 |  0.00009 |    0.01427 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40248 | -0.00001 |    0.28406 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:36:04,594 - Total sparsity: 0.00

2018-10-21 07:36:04,594 - --- validate (epoch=228)-----------
2018-10-21 07:36:04,594 - 10000 samples (128 per mini-batch)
2018-10-21 07:36:05,804 - Epoch: [228][   50/   78]    Loss 1.550848    Top1 91.125000    Top5 99.562500    
2018-10-21 07:36:06,439 - ==> Top1: 91.140    Top5: 99.570    Loss: 1.551

2018-10-21 07:36:06,441 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:36:06,441 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:36:06,452 - 

2018-10-21 07:36:06,453 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:36:08,118 - Epoch: [229][   50/  391]    Overall Loss 1.495265    Objective Loss 1.495265    Top1 96.937500    Top5 99.703125    LR 0.003000    Time 0.033243    
2018-10-21 07:36:09,676 - Epoch: [229][  100/  391]    Overall Loss 1.494857    Objective Loss 1.494857    Top1 96.960938    Top5 99.687500    LR 0.003000    Time 0.032175    
2018-10-21 07:36:11,244 - Epoch: [229][  150/  391]    Overall Loss 1.494586    Objective Loss 1.494586    Top1 96.994792    Top5 99.682292    LR 0.003000    Time 0.031887    
2018-10-21 07:36:12,773 - Epoch: [229][  200/  391]    Overall Loss 1.494717    Objective Loss 1.494717    Top1 96.996094    Top5 99.695312    LR 0.003000    Time 0.031548    
2018-10-21 07:36:14,295 - Epoch: [229][  250/  391]    Overall Loss 1.494565    Objective Loss 1.494565    Top1 97.000000    Top5 99.693750    LR 0.003000    Time 0.031317    
2018-10-21 07:36:15,828 - Epoch: [229][  300/  391]    Overall Loss 1.493876    Objective Loss 1.493876    Top1 97.075521    Top5 99.713542    LR 0.003000    Time 0.031201    
2018-10-21 07:36:17,353 - Epoch: [229][  350/  391]    Overall Loss 1.494570    Objective Loss 1.494570    Top1 97.000000    Top5 99.707589    LR 0.003000    Time 0.031096    
2018-10-21 07:36:18,765 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22760 | -0.00065 |    0.15120 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08042 | -0.00326 |    0.04696 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07850 |  0.00114 |    0.05330 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06783 | -0.00634 |    0.04606 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06486 | -0.00225 |    0.04257 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07984 | -0.01001 |    0.05578 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07010 | -0.00667 |    0.04925 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08150 | -0.00303 |    0.06101 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07015 | -0.00352 |    0.05344 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16762 |  0.00005 |    0.10299 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06377 | -0.00242 |    0.04815 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05646 | -0.00684 |    0.04441 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06808 | -0.00652 |    0.05218 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05451 | -0.00384 |    0.04268 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06489 | -0.00482 |    0.05130 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06043 | -0.00324 |    0.04791 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07823 | -0.00452 |    0.05970 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05821 | -0.00705 |    0.04608 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04107 | -0.00325 |    0.03180 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03611 | -0.00684 |    0.02828 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02080 |  0.00009 |    0.01426 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40240 | -0.00001 |    0.28401 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:36:18,765 - Total sparsity: 0.00

2018-10-21 07:36:18,765 - --- validate (epoch=229)-----------
2018-10-21 07:36:18,765 - 10000 samples (128 per mini-batch)
2018-10-21 07:36:19,955 - Epoch: [229][   50/   78]    Loss 1.549266    Top1 91.312500    Top5 99.656250    
2018-10-21 07:36:20,597 - ==> Top1: 91.350    Top5: 99.640    Loss: 1.549

2018-10-21 07:36:20,598 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:36:20,599 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:36:20,612 - 

2018-10-21 07:36:20,612 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:36:22,381 - Epoch: [230][   50/  391]    Overall Loss 1.492394    Objective Loss 1.492394    Top1 97.203125    Top5 99.718750    LR 0.003000    Time 0.035315    
2018-10-21 07:36:23,987 - Epoch: [230][  100/  391]    Overall Loss 1.494886    Objective Loss 1.494886    Top1 96.906250    Top5 99.679688    LR 0.003000    Time 0.033687    
2018-10-21 07:36:25,542 - Epoch: [230][  150/  391]    Overall Loss 1.495580    Objective Loss 1.495580    Top1 96.864583    Top5 99.692708    LR 0.003000    Time 0.032812    
2018-10-21 07:36:27,094 - Epoch: [230][  200/  391]    Overall Loss 1.494352    Objective Loss 1.494352    Top1 96.992188    Top5 99.703125    LR 0.003000    Time 0.032356    
2018-10-21 07:36:28,643 - Epoch: [230][  250/  391]    Overall Loss 1.494203    Objective Loss 1.494203    Top1 97.000000    Top5 99.700000    LR 0.003000    Time 0.032069    
2018-10-21 07:36:30,189 - Epoch: [230][  300/  391]    Overall Loss 1.494231    Objective Loss 1.494231    Top1 97.002604    Top5 99.703125    LR 0.003000    Time 0.031871    
2018-10-21 07:36:31,704 - Epoch: [230][  350/  391]    Overall Loss 1.493964    Objective Loss 1.493964    Top1 97.022321    Top5 99.712054    LR 0.003000    Time 0.031639    
2018-10-21 07:36:33,113 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22735 | -0.00092 |    0.15100 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08033 | -0.00325 |    0.04690 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07842 |  0.00114 |    0.05324 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06775 | -0.00637 |    0.04601 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06479 | -0.00224 |    0.04254 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07975 | -0.01003 |    0.05572 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07002 | -0.00670 |    0.04920 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08141 | -0.00299 |    0.06094 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07007 | -0.00348 |    0.05339 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16744 |  0.00008 |    0.10298 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06371 | -0.00240 |    0.04809 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05640 | -0.00683 |    0.04436 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06801 | -0.00650 |    0.05212 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05446 | -0.00385 |    0.04264 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06482 | -0.00480 |    0.05125 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06036 | -0.00322 |    0.04786 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07815 | -0.00453 |    0.05965 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05814 | -0.00704 |    0.04603 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04103 | -0.00324 |    0.03177 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03607 | -0.00684 |    0.02825 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02078 |  0.00008 |    0.01424 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40232 | -0.00001 |    0.28397 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:36:33,114 - Total sparsity: 0.00

2018-10-21 07:36:33,114 - --- validate (epoch=230)-----------
2018-10-21 07:36:33,114 - 10000 samples (128 per mini-batch)
2018-10-21 07:36:34,300 - Epoch: [230][   50/   78]    Loss 1.551479    Top1 90.984375    Top5 99.562500    
2018-10-21 07:36:34,936 - ==> Top1: 91.080    Top5: 99.570    Loss: 1.551

2018-10-21 07:36:34,938 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:36:34,938 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:36:34,950 - 

2018-10-21 07:36:34,950 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:36:36,601 - Epoch: [231][   50/  391]    Overall Loss 1.495879    Objective Loss 1.495879    Top1 96.765625    Top5 99.625000    LR 0.003000    Time 0.032964    
2018-10-21 07:36:38,169 - Epoch: [231][  100/  391]    Overall Loss 1.496349    Objective Loss 1.496349    Top1 96.757812    Top5 99.593750    LR 0.003000    Time 0.032134    
2018-10-21 07:36:39,737 - Epoch: [231][  150/  391]    Overall Loss 1.496111    Objective Loss 1.496111    Top1 96.781250    Top5 99.578125    LR 0.003000    Time 0.031862    
2018-10-21 07:36:41,284 - Epoch: [231][  200/  391]    Overall Loss 1.494900    Objective Loss 1.494900    Top1 96.949219    Top5 99.621094    LR 0.003000    Time 0.031621    
2018-10-21 07:36:42,829 - Epoch: [231][  250/  391]    Overall Loss 1.494061    Objective Loss 1.494061    Top1 97.034375    Top5 99.653125    LR 0.003000    Time 0.031470    
2018-10-21 07:36:44,370 - Epoch: [231][  300/  391]    Overall Loss 1.494539    Objective Loss 1.494539    Top1 96.968750    Top5 99.656250    LR 0.003000    Time 0.031353    
2018-10-21 07:36:45,958 - Epoch: [231][  350/  391]    Overall Loss 1.493640    Objective Loss 1.493640    Top1 97.055804    Top5 99.671875    LR 0.003000    Time 0.031406    
2018-10-21 07:36:47,402 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22710 | -0.00074 |    0.15087 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08024 | -0.00323 |    0.04684 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07833 |  0.00112 |    0.05317 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06767 | -0.00640 |    0.04595 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06472 | -0.00226 |    0.04249 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07965 | -0.01008 |    0.05566 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06995 | -0.00665 |    0.04916 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08133 | -0.00292 |    0.06088 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07000 | -0.00345 |    0.05332 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16725 |  0.00005 |    0.10285 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06364 | -0.00240 |    0.04805 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05633 | -0.00684 |    0.04432 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06793 | -0.00649 |    0.05206 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05440 | -0.00385 |    0.04260 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06475 | -0.00480 |    0.05119 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06030 | -0.00321 |    0.04781 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07806 | -0.00451 |    0.05958 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05808 | -0.00704 |    0.04598 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04098 | -0.00324 |    0.03174 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03603 | -0.00683 |    0.02822 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02075 |  0.00008 |    0.01423 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40223 | -0.00001 |    0.28391 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:36:47,403 - Total sparsity: 0.00

2018-10-21 07:36:47,403 - --- validate (epoch=231)-----------
2018-10-21 07:36:47,403 - 10000 samples (128 per mini-batch)
2018-10-21 07:36:48,709 - Epoch: [231][   50/   78]    Loss 1.552084    Top1 90.859375    Top5 99.593750    
2018-10-21 07:36:49,405 - ==> Top1: 90.900    Top5: 99.620    Loss: 1.552

2018-10-21 07:36:49,407 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:36:49,407 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:36:49,420 - 

2018-10-21 07:36:49,420 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:36:51,180 - Epoch: [232][   50/  391]    Overall Loss 1.493339    Objective Loss 1.493339    Top1 97.140625    Top5 99.843750    LR 0.003000    Time 0.035134    
2018-10-21 07:36:52,788 - Epoch: [232][  100/  391]    Overall Loss 1.494605    Objective Loss 1.494605    Top1 96.953125    Top5 99.789062    LR 0.003000    Time 0.033623    
2018-10-21 07:36:54,390 - Epoch: [232][  150/  391]    Overall Loss 1.493715    Objective Loss 1.493715    Top1 97.036458    Top5 99.760417    LR 0.003000    Time 0.033080    
2018-10-21 07:36:55,989 - Epoch: [232][  200/  391]    Overall Loss 1.492940    Objective Loss 1.492940    Top1 97.089844    Top5 99.734375    LR 0.003000    Time 0.032795    
2018-10-21 07:36:57,550 - Epoch: [232][  250/  391]    Overall Loss 1.493090    Objective Loss 1.493090    Top1 97.068750    Top5 99.706250    LR 0.003000    Time 0.032471    
2018-10-21 07:36:59,177 - Epoch: [232][  300/  391]    Overall Loss 1.493039    Objective Loss 1.493039    Top1 97.088542    Top5 99.705729    LR 0.003000    Time 0.032477    
2018-10-21 07:37:00,755 - Epoch: [232][  350/  391]    Overall Loss 1.493303    Objective Loss 1.493303    Top1 97.071429    Top5 99.705357    LR 0.003000    Time 0.032340    
2018-10-21 07:37:02,163 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22685 | -0.00076 |    0.15076 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08015 | -0.00328 |    0.04678 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07824 |  0.00112 |    0.05310 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06760 | -0.00638 |    0.04592 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06465 | -0.00226 |    0.04244 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07957 | -0.01003 |    0.05559 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06987 | -0.00667 |    0.04911 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08124 | -0.00292 |    0.06080 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06992 | -0.00345 |    0.05325 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16707 |  0.00012 |    0.10266 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06357 | -0.00237 |    0.04799 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05627 | -0.00682 |    0.04428 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06786 | -0.00647 |    0.05200 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05434 | -0.00386 |    0.04255 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06468 | -0.00478 |    0.05113 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06023 | -0.00320 |    0.04775 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07797 | -0.00451 |    0.05953 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05801 | -0.00706 |    0.04593 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04094 | -0.00324 |    0.03171 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03600 | -0.00682 |    0.02819 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02073 |  0.00008 |    0.01421 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40213 | -0.00001 |    0.28385 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:37:02,164 - Total sparsity: 0.00

2018-10-21 07:37:02,164 - --- validate (epoch=232)-----------
2018-10-21 07:37:02,164 - 10000 samples (128 per mini-batch)
2018-10-21 07:37:03,366 - Epoch: [232][   50/   78]    Loss 1.551520    Top1 91.171875    Top5 99.609375    
2018-10-21 07:37:04,002 - ==> Top1: 91.140    Top5: 99.620    Loss: 1.551

2018-10-21 07:37:04,004 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:37:04,004 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:37:04,025 - 

2018-10-21 07:37:04,026 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:37:05,795 - Epoch: [233][   50/  391]    Overall Loss 1.492071    Objective Loss 1.492071    Top1 97.234375    Top5 99.671875    LR 0.003000    Time 0.035310    
2018-10-21 07:37:07,363 - Epoch: [233][  100/  391]    Overall Loss 1.491221    Objective Loss 1.491221    Top1 97.289062    Top5 99.765625    LR 0.003000    Time 0.033305    
2018-10-21 07:37:08,917 - Epoch: [233][  150/  391]    Overall Loss 1.491272    Objective Loss 1.491272    Top1 97.302083    Top5 99.781250    LR 0.003000    Time 0.032547    
2018-10-21 07:37:10,498 - Epoch: [233][  200/  391]    Overall Loss 1.491520    Objective Loss 1.491520    Top1 97.285156    Top5 99.796875    LR 0.003000    Time 0.032302    
2018-10-21 07:37:12,125 - Epoch: [233][  250/  391]    Overall Loss 1.492703    Objective Loss 1.492703    Top1 97.162500    Top5 99.771875    LR 0.003000    Time 0.032340    
2018-10-21 07:37:13,707 - Epoch: [233][  300/  391]    Overall Loss 1.493095    Objective Loss 1.493095    Top1 97.106771    Top5 99.750000    LR 0.003000    Time 0.032216    
2018-10-21 07:37:15,339 - Epoch: [233][  350/  391]    Overall Loss 1.493260    Objective Loss 1.493260    Top1 97.095982    Top5 99.745536    LR 0.003000    Time 0.032271    
2018-10-21 07:37:16,792 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22660 | -0.00100 |    0.15050 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08006 | -0.00327 |    0.04675 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07816 |  0.00108 |    0.05305 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06752 | -0.00639 |    0.04586 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06457 | -0.00231 |    0.04239 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07949 | -0.00999 |    0.05551 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06978 | -0.00672 |    0.04906 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08115 | -0.00298 |    0.06074 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06984 | -0.00342 |    0.05318 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16688 |  0.00007 |    0.10256 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06350 | -0.00233 |    0.04794 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05621 | -0.00683 |    0.04424 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06779 | -0.00644 |    0.05195 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05428 | -0.00385 |    0.04252 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06461 | -0.00478 |    0.05107 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06017 | -0.00321 |    0.04771 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07789 | -0.00451 |    0.05947 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05795 | -0.00703 |    0.04588 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04090 | -0.00324 |    0.03168 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03595 | -0.00683 |    0.02817 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02071 |  0.00007 |    0.01420 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40205 | -0.00001 |    0.28379 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:37:16,792 - Total sparsity: 0.00

2018-10-21 07:37:16,792 - --- validate (epoch=233)-----------
2018-10-21 07:37:16,793 - 10000 samples (128 per mini-batch)
2018-10-21 07:37:18,004 - Epoch: [233][   50/   78]    Loss 1.550318    Top1 91.218750    Top5 99.640625    
2018-10-21 07:37:18,651 - ==> Top1: 91.330    Top5: 99.610    Loss: 1.549

2018-10-21 07:37:18,653 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:37:18,653 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:37:18,667 - 

2018-10-21 07:37:18,667 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:37:20,445 - Epoch: [234][   50/  391]    Overall Loss 1.493426    Objective Loss 1.493426    Top1 97.046875    Top5 99.578125    LR 0.003000    Time 0.035499    
2018-10-21 07:37:22,030 - Epoch: [234][  100/  391]    Overall Loss 1.494084    Objective Loss 1.494084    Top1 97.007812    Top5 99.648438    LR 0.003000    Time 0.033578    
2018-10-21 07:37:23,668 - Epoch: [234][  150/  391]    Overall Loss 1.491910    Objective Loss 1.491910    Top1 97.270833    Top5 99.692708    LR 0.003000    Time 0.033286    
2018-10-21 07:37:25,277 - Epoch: [234][  200/  391]    Overall Loss 1.492737    Objective Loss 1.492737    Top1 97.179688    Top5 99.667969    LR 0.003000    Time 0.032996    
2018-10-21 07:37:26,851 - Epoch: [234][  250/  391]    Overall Loss 1.492838    Objective Loss 1.492838    Top1 97.175000    Top5 99.681250    LR 0.003000    Time 0.032682    
2018-10-21 07:37:28,484 - Epoch: [234][  300/  391]    Overall Loss 1.492709    Objective Loss 1.492709    Top1 97.179688    Top5 99.700521    LR 0.003000    Time 0.032671    
2018-10-21 07:37:30,103 - Epoch: [234][  350/  391]    Overall Loss 1.493409    Objective Loss 1.493409    Top1 97.098214    Top5 99.689732    LR 0.003000    Time 0.032624    
2018-10-21 07:37:31,526 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22636 | -0.00117 |    0.15024 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07998 | -0.00325 |    0.04669 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07807 |  0.00113 |    0.05300 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06746 | -0.00633 |    0.04582 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06450 | -0.00231 |    0.04235 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07940 | -0.00997 |    0.05546 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06971 | -0.00672 |    0.04901 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08106 | -0.00294 |    0.06066 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06977 | -0.00343 |    0.05313 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16670 |  0.00014 |    0.10247 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06343 | -0.00232 |    0.04788 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05615 | -0.00681 |    0.04419 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06772 | -0.00644 |    0.05189 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05422 | -0.00383 |    0.04247 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06453 | -0.00478 |    0.05101 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06010 | -0.00322 |    0.04765 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07780 | -0.00450 |    0.05940 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05789 | -0.00702 |    0.04584 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04085 | -0.00324 |    0.03164 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03591 | -0.00683 |    0.02814 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02069 |  0.00007 |    0.01418 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40195 | -0.00001 |    0.28373 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:37:31,527 - Total sparsity: 0.00

2018-10-21 07:37:31,527 - --- validate (epoch=234)-----------
2018-10-21 07:37:31,527 - 10000 samples (128 per mini-batch)
2018-10-21 07:37:32,752 - Epoch: [234][   50/   78]    Loss 1.549973    Top1 91.265625    Top5 99.562500    
2018-10-21 07:37:33,400 - ==> Top1: 91.270    Top5: 99.610    Loss: 1.550

2018-10-21 07:37:33,402 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:37:33,403 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:37:33,416 - 

2018-10-21 07:37:33,416 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:37:35,250 - Epoch: [235][   50/  391]    Overall Loss 1.494529    Objective Loss 1.494529    Top1 97.000000    Top5 99.515625    LR 0.003000    Time 0.036621    
2018-10-21 07:37:37,044 - Epoch: [235][  100/  391]    Overall Loss 1.493190    Objective Loss 1.493190    Top1 97.140625    Top5 99.601562    LR 0.003000    Time 0.036217    
2018-10-21 07:37:38,764 - Epoch: [235][  150/  391]    Overall Loss 1.492860    Objective Loss 1.492860    Top1 97.187500    Top5 99.619792    LR 0.003000    Time 0.035597    
2018-10-21 07:37:40,407 - Epoch: [235][  200/  391]    Overall Loss 1.492652    Objective Loss 1.492652    Top1 97.199219    Top5 99.636719    LR 0.003000    Time 0.034898    
2018-10-21 07:37:42,006 - Epoch: [235][  250/  391]    Overall Loss 1.493070    Objective Loss 1.493070    Top1 97.146875    Top5 99.650000    LR 0.003000    Time 0.034308    
2018-10-21 07:37:43,626 - Epoch: [235][  300/  391]    Overall Loss 1.492431    Objective Loss 1.492431    Top1 97.200521    Top5 99.664062    LR 0.003000    Time 0.033983    
2018-10-21 07:37:45,179 - Epoch: [235][  350/  391]    Overall Loss 1.492421    Objective Loss 1.492421    Top1 97.198661    Top5 99.674107    LR 0.003000    Time 0.033559    
2018-10-21 07:37:46,618 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22611 | -0.00085 |    0.15029 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07989 | -0.00324 |    0.04665 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07799 |  0.00110 |    0.05294 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06738 | -0.00635 |    0.04575 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06443 | -0.00234 |    0.04229 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07932 | -0.00990 |    0.05538 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06963 | -0.00676 |    0.04895 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08097 | -0.00289 |    0.06060 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06969 | -0.00344 |    0.05307 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16651 |  0.00015 |    0.10237 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06336 | -0.00229 |    0.04784 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05609 | -0.00680 |    0.04414 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06764 | -0.00643 |    0.05182 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05416 | -0.00378 |    0.04244 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06446 | -0.00478 |    0.05096 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06004 | -0.00319 |    0.04760 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07771 | -0.00450 |    0.05934 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05783 | -0.00702 |    0.04579 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04081 | -0.00325 |    0.03161 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03587 | -0.00683 |    0.02811 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02066 |  0.00006 |    0.01417 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40187 | -0.00001 |    0.28369 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:37:46,618 - Total sparsity: 0.00

2018-10-21 07:37:46,618 - --- validate (epoch=235)-----------
2018-10-21 07:37:46,619 - 10000 samples (128 per mini-batch)
2018-10-21 07:37:48,042 - Epoch: [235][   50/   78]    Loss 1.550712    Top1 91.265625    Top5 99.593750    
2018-10-21 07:37:48,814 - ==> Top1: 91.160    Top5: 99.610    Loss: 1.551

2018-10-21 07:37:48,815 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:37:48,815 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:37:48,829 - 

2018-10-21 07:37:48,829 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:37:50,598 - Epoch: [236][   50/  391]    Overall Loss 1.497868    Objective Loss 1.497868    Top1 96.718750    Top5 99.640625    LR 0.003000    Time 0.035324    
2018-10-21 07:37:52,367 - Epoch: [236][  100/  391]    Overall Loss 1.496834    Objective Loss 1.496834    Top1 96.718750    Top5 99.648438    LR 0.003000    Time 0.035333    
2018-10-21 07:37:54,150 - Epoch: [236][  150/  391]    Overall Loss 1.495606    Objective Loss 1.495606    Top1 96.828125    Top5 99.708333    LR 0.003000    Time 0.035425    
2018-10-21 07:37:55,802 - Epoch: [236][  200/  391]    Overall Loss 1.494691    Objective Loss 1.494691    Top1 96.933594    Top5 99.695312    LR 0.003000    Time 0.034818    
2018-10-21 07:37:57,402 - Epoch: [236][  250/  391]    Overall Loss 1.493912    Objective Loss 1.493912    Top1 97.015625    Top5 99.687500    LR 0.003000    Time 0.034245    
2018-10-21 07:37:59,014 - Epoch: [236][  300/  391]    Overall Loss 1.493429    Objective Loss 1.493429    Top1 97.057292    Top5 99.695312    LR 0.003000    Time 0.033905    
2018-10-21 07:38:00,597 - Epoch: [236][  350/  391]    Overall Loss 1.493114    Objective Loss 1.493114    Top1 97.095982    Top5 99.709821    LR 0.003000    Time 0.033577    
2018-10-21 07:38:02,010 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22586 | -0.00098 |    0.14998 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07980 | -0.00324 |    0.04662 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07790 |  0.00107 |    0.05287 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06731 | -0.00635 |    0.04569 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06436 | -0.00238 |    0.04224 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07923 | -0.00995 |    0.05534 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06955 | -0.00673 |    0.04889 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08088 | -0.00299 |    0.06055 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06961 | -0.00345 |    0.05301 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16633 |  0.00016 |    0.10217 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06329 | -0.00232 |    0.04778 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05603 | -0.00677 |    0.04410 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06757 | -0.00642 |    0.05178 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05410 | -0.00380 |    0.04239 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06439 | -0.00479 |    0.05091 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05997 | -0.00320 |    0.04755 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07763 | -0.00450 |    0.05927 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05776 | -0.00701 |    0.04575 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04076 | -0.00324 |    0.03158 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03583 | -0.00683 |    0.02808 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02064 |  0.00007 |    0.01416 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40178 | -0.00001 |    0.28362 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:38:02,011 - Total sparsity: 0.00

2018-10-21 07:38:02,011 - --- validate (epoch=236)-----------
2018-10-21 07:38:02,011 - 10000 samples (128 per mini-batch)
2018-10-21 07:38:03,268 - Epoch: [236][   50/   78]    Loss 1.549532    Top1 91.359375    Top5 99.656250    
2018-10-21 07:38:03,933 - ==> Top1: 91.240    Top5: 99.640    Loss: 1.550

2018-10-21 07:38:03,935 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:38:03,935 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:38:03,949 - 

2018-10-21 07:38:03,949 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:38:05,714 - Epoch: [237][   50/  391]    Overall Loss 1.491493    Objective Loss 1.491493    Top1 97.281250    Top5 99.546875    LR 0.003000    Time 0.035233    
2018-10-21 07:38:07,319 - Epoch: [237][  100/  391]    Overall Loss 1.492017    Objective Loss 1.492017    Top1 97.195312    Top5 99.648438    LR 0.003000    Time 0.033648    
2018-10-21 07:38:08,875 - Epoch: [237][  150/  391]    Overall Loss 1.492864    Objective Loss 1.492864    Top1 97.140625    Top5 99.677083    LR 0.003000    Time 0.032791    
2018-10-21 07:38:10,454 - Epoch: [237][  200/  391]    Overall Loss 1.493360    Objective Loss 1.493360    Top1 97.066406    Top5 99.695312    LR 0.003000    Time 0.032476    
2018-10-21 07:38:12,058 - Epoch: [237][  250/  391]    Overall Loss 1.493395    Objective Loss 1.493395    Top1 97.068750    Top5 99.703125    LR 0.003000    Time 0.032388    
2018-10-21 07:38:13,647 - Epoch: [237][  300/  391]    Overall Loss 1.493043    Objective Loss 1.493043    Top1 97.104167    Top5 99.716146    LR 0.003000    Time 0.032278    
2018-10-21 07:38:15,219 - Epoch: [237][  350/  391]    Overall Loss 1.492963    Objective Loss 1.492963    Top1 97.129464    Top5 99.716518    LR 0.003000    Time 0.032153    
2018-10-21 07:38:16,671 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22561 | -0.00089 |    0.14972 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07971 | -0.00326 |    0.04655 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07782 |  0.00108 |    0.05283 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06724 | -0.00631 |    0.04566 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06429 | -0.00235 |    0.04219 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07914 | -0.00994 |    0.05527 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06947 | -0.00675 |    0.04883 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08079 | -0.00300 |    0.06047 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06954 | -0.00346 |    0.05296 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16614 |  0.00013 |    0.10205 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06322 | -0.00235 |    0.04772 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05597 | -0.00679 |    0.04405 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06750 | -0.00643 |    0.05173 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05405 | -0.00379 |    0.04234 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06432 | -0.00477 |    0.05085 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05991 | -0.00319 |    0.04750 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07754 | -0.00447 |    0.05921 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05771 | -0.00699 |    0.04571 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04072 | -0.00324 |    0.03154 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03579 | -0.00684 |    0.02805 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02062 |  0.00006 |    0.01414 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40169 | -0.00001 |    0.28356 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:38:16,671 - Total sparsity: 0.00

2018-10-21 07:38:16,671 - --- validate (epoch=237)-----------
2018-10-21 07:38:16,672 - 10000 samples (128 per mini-batch)
2018-10-21 07:38:17,941 - Epoch: [237][   50/   78]    Loss 1.549282    Top1 91.359375    Top5 99.593750    
2018-10-21 07:38:18,669 - ==> Top1: 91.320    Top5: 99.600    Loss: 1.550

2018-10-21 07:38:18,671 - ==> Best Top1: 91.390   On Epoch: 227

2018-10-21 07:38:18,671 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:38:18,683 - 

2018-10-21 07:38:18,683 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:38:20,588 - Epoch: [238][   50/  391]    Overall Loss 1.489469    Objective Loss 1.489469    Top1 97.515625    Top5 99.734375    LR 0.003000    Time 0.038038    
2018-10-21 07:38:22,322 - Epoch: [238][  100/  391]    Overall Loss 1.489753    Objective Loss 1.489753    Top1 97.460938    Top5 99.710938    LR 0.003000    Time 0.036333    
2018-10-21 07:38:23,937 - Epoch: [238][  150/  391]    Overall Loss 1.491185    Objective Loss 1.491185    Top1 97.296875    Top5 99.697917    LR 0.003000    Time 0.034978    
2018-10-21 07:38:25,550 - Epoch: [238][  200/  391]    Overall Loss 1.492305    Objective Loss 1.492305    Top1 97.191406    Top5 99.691406    LR 0.003000    Time 0.034288    
2018-10-21 07:38:27,165 - Epoch: [238][  250/  391]    Overall Loss 1.492969    Objective Loss 1.492969    Top1 97.121875    Top5 99.690625    LR 0.003000    Time 0.033880    
2018-10-21 07:38:28,831 - Epoch: [238][  300/  391]    Overall Loss 1.492704    Objective Loss 1.492704    Top1 97.161458    Top5 99.700521    LR 0.003000    Time 0.033779    
2018-10-21 07:38:30,410 - Epoch: [238][  350/  391]    Overall Loss 1.492759    Objective Loss 1.492759    Top1 97.151786    Top5 99.691964    LR 0.003000    Time 0.033460    
2018-10-21 07:38:31,841 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22536 | -0.00113 |    0.14956 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07963 | -0.00329 |    0.04649 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07773 |  0.00103 |    0.05278 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06716 | -0.00632 |    0.04561 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06422 | -0.00236 |    0.04211 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07906 | -0.00989 |    0.05523 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06940 | -0.00674 |    0.04877 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08070 | -0.00305 |    0.06039 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06946 | -0.00341 |    0.05290 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16596 |  0.00016 |    0.10199 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06316 | -0.00231 |    0.04767 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05591 | -0.00677 |    0.04400 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06742 | -0.00641 |    0.05167 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05399 | -0.00377 |    0.04229 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06425 | -0.00477 |    0.05080 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05984 | -0.00319 |    0.04745 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07745 | -0.00446 |    0.05914 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05764 | -0.00699 |    0.04566 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04068 | -0.00325 |    0.03151 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03576 | -0.00683 |    0.02802 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02060 |  0.00006 |    0.01413 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40160 | -0.00001 |    0.28350 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:38:31,841 - Total sparsity: 0.00

2018-10-21 07:38:31,841 - --- validate (epoch=238)-----------
2018-10-21 07:38:31,842 - 10000 samples (128 per mini-batch)
2018-10-21 07:38:33,121 - Epoch: [238][   50/   78]    Loss 1.547142    Top1 91.640625    Top5 99.609375    
2018-10-21 07:38:33,776 - ==> Top1: 91.480    Top5: 99.600    Loss: 1.548

2018-10-21 07:38:33,777 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:38:33,777 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:38:33,793 - 

2018-10-21 07:38:33,794 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:38:35,518 - Epoch: [239][   50/  391]    Overall Loss 1.489548    Objective Loss 1.489548    Top1 97.453125    Top5 99.718750    LR 0.003000    Time 0.034426    
2018-10-21 07:38:37,214 - Epoch: [239][  100/  391]    Overall Loss 1.490860    Objective Loss 1.490860    Top1 97.312500    Top5 99.757812    LR 0.003000    Time 0.034154    
2018-10-21 07:38:38,896 - Epoch: [239][  150/  391]    Overall Loss 1.491796    Objective Loss 1.491796    Top1 97.234375    Top5 99.750000    LR 0.003000    Time 0.033967    
2018-10-21 07:38:40,579 - Epoch: [239][  200/  391]    Overall Loss 1.491867    Objective Loss 1.491867    Top1 97.222656    Top5 99.726562    LR 0.003000    Time 0.033879    
2018-10-21 07:38:42,187 - Epoch: [239][  250/  391]    Overall Loss 1.491788    Objective Loss 1.491788    Top1 97.228125    Top5 99.737500    LR 0.003000    Time 0.033525    
2018-10-21 07:38:43,798 - Epoch: [239][  300/  391]    Overall Loss 1.492208    Objective Loss 1.492208    Top1 97.177083    Top5 99.721354    LR 0.003000    Time 0.033300    
2018-10-21 07:38:45,429 - Epoch: [239][  350/  391]    Overall Loss 1.492417    Objective Loss 1.492417    Top1 97.147321    Top5 99.718750    LR 0.003000    Time 0.033197    
2018-10-21 07:38:46,994 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22511 | -0.00134 |    0.14943 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07954 | -0.00320 |    0.04646 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07765 |  0.00106 |    0.05270 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06709 | -0.00635 |    0.04557 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06415 | -0.00239 |    0.04207 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07897 | -0.00989 |    0.05516 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06932 | -0.00672 |    0.04872 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08061 | -0.00300 |    0.06033 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06938 | -0.00343 |    0.05284 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16578 |  0.00015 |    0.10185 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06309 | -0.00233 |    0.04762 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05585 | -0.00677 |    0.04396 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06736 | -0.00636 |    0.05160 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05393 | -0.00377 |    0.04224 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06418 | -0.00474 |    0.05075 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05978 | -0.00319 |    0.04739 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07737 | -0.00444 |    0.05909 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05758 | -0.00698 |    0.04561 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04063 | -0.00325 |    0.03148 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03572 | -0.00682 |    0.02799 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02057 |  0.00006 |    0.01411 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40149 | -0.00001 |    0.28343 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:38:46,995 - Total sparsity: 0.00

2018-10-21 07:38:46,995 - --- validate (epoch=239)-----------
2018-10-21 07:38:46,995 - 10000 samples (128 per mini-batch)
2018-10-21 07:38:48,245 - Epoch: [239][   50/   78]    Loss 1.549505    Top1 91.437500    Top5 99.593750    
2018-10-21 07:38:48,909 - ==> Top1: 91.320    Top5: 99.610    Loss: 1.550

2018-10-21 07:38:48,910 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:38:48,911 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:38:48,923 - 

2018-10-21 07:38:48,924 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:38:50,687 - Epoch: [240][   50/  391]    Overall Loss 1.494397    Objective Loss 1.494397    Top1 97.093750    Top5 99.671875    LR 0.003000    Time 0.035210    
2018-10-21 07:38:52,309 - Epoch: [240][  100/  391]    Overall Loss 1.493290    Objective Loss 1.493290    Top1 97.164062    Top5 99.656250    LR 0.003000    Time 0.033798    
2018-10-21 07:38:53,978 - Epoch: [240][  150/  391]    Overall Loss 1.494048    Objective Loss 1.494048    Top1 97.088542    Top5 99.619792    LR 0.003000    Time 0.033645    
2018-10-21 07:38:55,585 - Epoch: [240][  200/  391]    Overall Loss 1.493343    Objective Loss 1.493343    Top1 97.144531    Top5 99.640625    LR 0.003000    Time 0.033256    
2018-10-21 07:38:57,234 - Epoch: [240][  250/  391]    Overall Loss 1.492684    Objective Loss 1.492684    Top1 97.187500    Top5 99.637500    LR 0.003000    Time 0.033194    
2018-10-21 07:38:58,884 - Epoch: [240][  300/  391]    Overall Loss 1.492044    Objective Loss 1.492044    Top1 97.244792    Top5 99.671875    LR 0.003000    Time 0.033153    
2018-10-21 07:39:00,546 - Epoch: [240][  350/  391]    Overall Loss 1.491793    Objective Loss 1.491793    Top1 97.265625    Top5 99.685268    LR 0.003000    Time 0.033161    
2018-10-21 07:39:02,040 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22487 | -0.00155 |    0.14930 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07945 | -0.00323 |    0.04639 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07756 |  0.00107 |    0.05265 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06701 | -0.00631 |    0.04552 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06408 | -0.00233 |    0.04201 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07888 | -0.00994 |    0.05511 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06924 | -0.00677 |    0.04867 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08052 | -0.00295 |    0.06025 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06931 | -0.00345 |    0.05277 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16560 |  0.00010 |    0.10163 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06302 | -0.00233 |    0.04757 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05579 | -0.00676 |    0.04391 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06728 | -0.00639 |    0.05155 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05387 | -0.00376 |    0.04220 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06411 | -0.00474 |    0.05070 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05971 | -0.00321 |    0.04734 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07728 | -0.00442 |    0.05901 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05752 | -0.00697 |    0.04556 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04059 | -0.00325 |    0.03144 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03568 | -0.00682 |    0.02797 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02055 |  0.00006 |    0.01410 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40141 | -0.00001 |    0.28338 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:39:02,041 - Total sparsity: 0.00

2018-10-21 07:39:02,041 - --- validate (epoch=240)-----------
2018-10-21 07:39:02,041 - 10000 samples (128 per mini-batch)
2018-10-21 07:39:03,237 - Epoch: [240][   50/   78]    Loss 1.549526    Top1 91.218750    Top5 99.593750    
2018-10-21 07:39:03,875 - ==> Top1: 91.200    Top5: 99.600    Loss: 1.549

2018-10-21 07:39:03,876 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:39:03,877 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:39:03,890 - 

2018-10-21 07:39:03,890 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:39:05,668 - Epoch: [241][   50/  391]    Overall Loss 1.491486    Objective Loss 1.491486    Top1 97.296875    Top5 99.656250    LR 0.003000    Time 0.035497    
2018-10-21 07:39:07,378 - Epoch: [241][  100/  391]    Overall Loss 1.492403    Objective Loss 1.492403    Top1 97.125000    Top5 99.664062    LR 0.003000    Time 0.034829    
2018-10-21 07:39:09,050 - Epoch: [241][  150/  391]    Overall Loss 1.492837    Objective Loss 1.492837    Top1 97.140625    Top5 99.645833    LR 0.003000    Time 0.034349    
2018-10-21 07:39:10,729 - Epoch: [241][  200/  391]    Overall Loss 1.492818    Objective Loss 1.492818    Top1 97.132812    Top5 99.675781    LR 0.003000    Time 0.034148    
2018-10-21 07:39:12,342 - Epoch: [241][  250/  391]    Overall Loss 1.492823    Objective Loss 1.492823    Top1 97.140625    Top5 99.700000    LR 0.003000    Time 0.033760    
2018-10-21 07:39:13,921 - Epoch: [241][  300/  391]    Overall Loss 1.492502    Objective Loss 1.492502    Top1 97.169271    Top5 99.687500    LR 0.003000    Time 0.033391    
2018-10-21 07:39:15,563 - Epoch: [241][  350/  391]    Overall Loss 1.492542    Objective Loss 1.492542    Top1 97.178571    Top5 99.698661    LR 0.003000    Time 0.033306    
2018-10-21 07:39:17,034 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22462 | -0.00119 |    0.14918 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07937 | -0.00321 |    0.04635 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07748 |  0.00104 |    0.05262 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06694 | -0.00629 |    0.04547 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06401 | -0.00234 |    0.04195 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07879 | -0.00993 |    0.05505 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06916 | -0.00681 |    0.04861 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08044 | -0.00290 |    0.06018 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06923 | -0.00351 |    0.05271 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16541 |  0.00006 |    0.10157 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06295 | -0.00229 |    0.04751 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05573 | -0.00677 |    0.04385 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06721 | -0.00639 |    0.05149 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05381 | -0.00376 |    0.04216 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06404 | -0.00471 |    0.05064 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05965 | -0.00319 |    0.04729 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07720 | -0.00440 |    0.05894 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05746 | -0.00695 |    0.04551 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04055 | -0.00324 |    0.03141 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03564 | -0.00682 |    0.02794 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02053 |  0.00006 |    0.01408 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40133 | -0.00001 |    0.28333 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:39:17,034 - Total sparsity: 0.00

2018-10-21 07:39:17,035 - --- validate (epoch=241)-----------
2018-10-21 07:39:17,035 - 10000 samples (128 per mini-batch)
2018-10-21 07:39:18,234 - Epoch: [241][   50/   78]    Loss 1.551259    Top1 91.171875    Top5 99.625000    
2018-10-21 07:39:18,864 - ==> Top1: 91.200    Top5: 99.640    Loss: 1.550

2018-10-21 07:39:18,865 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:39:18,865 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:39:18,878 - 

2018-10-21 07:39:18,878 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:39:20,619 - Epoch: [242][   50/  391]    Overall Loss 1.492380    Objective Loss 1.492380    Top1 97.093750    Top5 99.765625    LR 0.003000    Time 0.034753    
2018-10-21 07:39:22,289 - Epoch: [242][  100/  391]    Overall Loss 1.492132    Objective Loss 1.492132    Top1 97.187500    Top5 99.750000    LR 0.003000    Time 0.034052    
2018-10-21 07:39:24,069 - Epoch: [242][  150/  391]    Overall Loss 1.491844    Objective Loss 1.491844    Top1 97.234375    Top5 99.739583    LR 0.003000    Time 0.034550    
2018-10-21 07:39:25,699 - Epoch: [242][  200/  391]    Overall Loss 1.491792    Objective Loss 1.491792    Top1 97.257812    Top5 99.707031    LR 0.003000    Time 0.034052    
2018-10-21 07:39:27,393 - Epoch: [242][  250/  391]    Overall Loss 1.491730    Objective Loss 1.491730    Top1 97.262500    Top5 99.725000    LR 0.003000    Time 0.034011    
2018-10-21 07:39:29,210 - Epoch: [242][  300/  391]    Overall Loss 1.491909    Objective Loss 1.491909    Top1 97.236979    Top5 99.708333    LR 0.003000    Time 0.034393    
2018-10-21 07:39:31,032 - Epoch: [242][  350/  391]    Overall Loss 1.492152    Objective Loss 1.492152    Top1 97.220982    Top5 99.691964    LR 0.003000    Time 0.034676    
2018-10-21 07:39:32,648 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22438 | -0.00094 |    0.14895 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07928 | -0.00326 |    0.04630 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07739 |  0.00107 |    0.05255 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06687 | -0.00633 |    0.04542 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06394 | -0.00235 |    0.04192 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07871 | -0.00990 |    0.05500 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06909 | -0.00678 |    0.04858 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08035 | -0.00299 |    0.06011 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06915 | -0.00349 |    0.05265 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16523 |  0.00006 |    0.10141 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06289 | -0.00228 |    0.04746 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05567 | -0.00676 |    0.04381 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06713 | -0.00639 |    0.05144 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05376 | -0.00377 |    0.04211 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06397 | -0.00471 |    0.05059 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05958 | -0.00320 |    0.04724 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07711 | -0.00441 |    0.05888 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05740 | -0.00693 |    0.04546 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04050 | -0.00324 |    0.03138 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03560 | -0.00682 |    0.02791 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02051 |  0.00005 |    0.01407 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40124 | -0.00001 |    0.28328 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:39:32,648 - Total sparsity: 0.00

2018-10-21 07:39:32,649 - --- validate (epoch=242)-----------
2018-10-21 07:39:32,649 - 10000 samples (128 per mini-batch)
2018-10-21 07:39:33,832 - Epoch: [242][   50/   78]    Loss 1.550237    Top1 91.328125    Top5 99.640625    
2018-10-21 07:39:34,464 - ==> Top1: 91.220    Top5: 99.670    Loss: 1.550

2018-10-21 07:39:34,466 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:39:34,466 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:39:34,479 - 

2018-10-21 07:39:34,480 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:39:36,256 - Epoch: [243][   50/  391]    Overall Loss 1.491416    Objective Loss 1.491416    Top1 97.281250    Top5 99.812500    LR 0.003000    Time 0.035468    
2018-10-21 07:39:38,085 - Epoch: [243][  100/  391]    Overall Loss 1.491267    Objective Loss 1.491267    Top1 97.289062    Top5 99.679688    LR 0.003000    Time 0.035998    
2018-10-21 07:39:39,682 - Epoch: [243][  150/  391]    Overall Loss 1.490090    Objective Loss 1.490090    Top1 97.421875    Top5 99.739583    LR 0.003000    Time 0.034630    
2018-10-21 07:39:41,278 - Epoch: [243][  200/  391]    Overall Loss 1.490253    Objective Loss 1.490253    Top1 97.410156    Top5 99.730469    LR 0.003000    Time 0.033943    
2018-10-21 07:39:42,863 - Epoch: [243][  250/  391]    Overall Loss 1.490637    Objective Loss 1.490637    Top1 97.362500    Top5 99.734375    LR 0.003000    Time 0.033484    
2018-10-21 07:39:44,500 - Epoch: [243][  300/  391]    Overall Loss 1.490801    Objective Loss 1.490801    Top1 97.346354    Top5 99.736979    LR 0.003000    Time 0.033352    
2018-10-21 07:39:46,102 - Epoch: [243][  350/  391]    Overall Loss 1.491325    Objective Loss 1.491325    Top1 97.301339    Top5 99.720982    LR 0.003000    Time 0.033161    
2018-10-21 07:39:47,531 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22413 | -0.00105 |    0.14872 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07919 | -0.00326 |    0.04626 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07731 |  0.00104 |    0.05248 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06679 | -0.00632 |    0.04537 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06387 | -0.00233 |    0.04189 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07862 | -0.00989 |    0.05493 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06901 | -0.00683 |    0.04851 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08026 | -0.00299 |    0.06005 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06908 | -0.00348 |    0.05260 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16505 |  0.00002 |    0.10130 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06282 | -0.00230 |    0.04740 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05561 | -0.00674 |    0.04376 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06706 | -0.00639 |    0.05139 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05370 | -0.00378 |    0.04207 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06390 | -0.00468 |    0.05053 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05952 | -0.00319 |    0.04719 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07703 | -0.00442 |    0.05882 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05733 | -0.00692 |    0.04541 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04046 | -0.00323 |    0.03135 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03556 | -0.00681 |    0.02788 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02048 |  0.00004 |    0.01406 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40115 | -0.00001 |    0.28321 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:39:47,532 - Total sparsity: 0.00

2018-10-21 07:39:47,532 - --- validate (epoch=243)-----------
2018-10-21 07:39:47,532 - 10000 samples (128 per mini-batch)
2018-10-21 07:39:48,884 - Epoch: [243][   50/   78]    Loss 1.550273    Top1 91.265625    Top5 99.609375    
2018-10-21 07:39:49,529 - ==> Top1: 91.240    Top5: 99.630    Loss: 1.550

2018-10-21 07:39:49,530 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:39:49,530 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:39:49,543 - 

2018-10-21 07:39:49,544 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:39:51,289 - Epoch: [244][   50/  391]    Overall Loss 1.491834    Objective Loss 1.491834    Top1 97.234375    Top5 99.578125    LR 0.003000    Time 0.034850    
2018-10-21 07:39:52,919 - Epoch: [244][  100/  391]    Overall Loss 1.491762    Objective Loss 1.491762    Top1 97.218750    Top5 99.710938    LR 0.003000    Time 0.033703    
2018-10-21 07:39:54,541 - Epoch: [244][  150/  391]    Overall Loss 1.491712    Objective Loss 1.491712    Top1 97.229167    Top5 99.734375    LR 0.003000    Time 0.033263    
2018-10-21 07:39:56,125 - Epoch: [244][  200/  391]    Overall Loss 1.491310    Objective Loss 1.491310    Top1 97.285156    Top5 99.734375    LR 0.003000    Time 0.032858    
2018-10-21 07:39:57,891 - Epoch: [244][  250/  391]    Overall Loss 1.491728    Objective Loss 1.491728    Top1 97.246875    Top5 99.721875    LR 0.003000    Time 0.033341    
2018-10-21 07:39:59,611 - Epoch: [244][  300/  391]    Overall Loss 1.491385    Objective Loss 1.491385    Top1 97.286458    Top5 99.729167    LR 0.003000    Time 0.033508    
2018-10-21 07:40:01,227 - Epoch: [244][  350/  391]    Overall Loss 1.491792    Objective Loss 1.491792    Top1 97.236607    Top5 99.729911    LR 0.003000    Time 0.033333    
2018-10-21 07:40:02,813 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22389 | -0.00041 |    0.14862 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07911 | -0.00322 |    0.04621 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07722 |  0.00100 |    0.05245 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06672 | -0.00632 |    0.04532 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06380 | -0.00230 |    0.04186 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07854 | -0.00988 |    0.05489 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06893 | -0.00682 |    0.04847 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08017 | -0.00294 |    0.05998 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06900 | -0.00345 |    0.05254 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16487 |  0.00009 |    0.10121 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06275 | -0.00227 |    0.04736 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05555 | -0.00671 |    0.04372 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06699 | -0.00637 |    0.05134 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05364 | -0.00380 |    0.04202 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06383 | -0.00469 |    0.05048 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05945 | -0.00318 |    0.04715 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07694 | -0.00442 |    0.05874 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05727 | -0.00692 |    0.04536 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04042 | -0.00322 |    0.03132 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03552 | -0.00682 |    0.02785 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02046 |  0.00004 |    0.01404 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40106 | -0.00001 |    0.28316 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:40:02,814 - Total sparsity: 0.00

2018-10-21 07:40:02,814 - --- validate (epoch=244)-----------
2018-10-21 07:40:02,814 - 10000 samples (128 per mini-batch)
2018-10-21 07:40:04,070 - Epoch: [244][   50/   78]    Loss 1.550715    Top1 91.078125    Top5 99.718750    
2018-10-21 07:40:04,699 - ==> Top1: 90.960    Top5: 99.700    Loss: 1.551

2018-10-21 07:40:04,701 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:40:04,701 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:40:04,714 - 

2018-10-21 07:40:04,715 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:40:06,583 - Epoch: [245][   50/  391]    Overall Loss 1.488888    Objective Loss 1.488888    Top1 97.531250    Top5 99.750000    LR 0.003000    Time 0.037310    
2018-10-21 07:40:08,278 - Epoch: [245][  100/  391]    Overall Loss 1.489280    Objective Loss 1.489280    Top1 97.500000    Top5 99.734375    LR 0.003000    Time 0.035586    
2018-10-21 07:40:09,898 - Epoch: [245][  150/  391]    Overall Loss 1.490534    Objective Loss 1.490534    Top1 97.406250    Top5 99.723958    LR 0.003000    Time 0.034510    
2018-10-21 07:40:11,504 - Epoch: [245][  200/  391]    Overall Loss 1.491723    Objective Loss 1.491723    Top1 97.296875    Top5 99.707031    LR 0.003000    Time 0.033897    
2018-10-21 07:40:13,161 - Epoch: [245][  250/  391]    Overall Loss 1.491499    Objective Loss 1.491499    Top1 97.290625    Top5 99.715625    LR 0.003000    Time 0.033739    
2018-10-21 07:40:14,815 - Epoch: [245][  300/  391]    Overall Loss 1.491402    Objective Loss 1.491402    Top1 97.302083    Top5 99.697917    LR 0.003000    Time 0.033620    
2018-10-21 07:40:16,401 - Epoch: [245][  350/  391]    Overall Loss 1.491590    Objective Loss 1.491590    Top1 97.285714    Top5 99.714286    LR 0.003000    Time 0.033345    
2018-10-21 07:40:17,871 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22364 | -0.00070 |    0.14848 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07902 | -0.00322 |    0.04616 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07714 |  0.00097 |    0.05238 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06666 | -0.00623 |    0.04526 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06373 | -0.00226 |    0.04181 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07846 | -0.00985 |    0.05483 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06886 | -0.00681 |    0.04842 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08008 | -0.00291 |    0.05990 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06892 | -0.00351 |    0.05248 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16469 |  0.00017 |    0.10115 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06268 | -0.00227 |    0.04732 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05549 | -0.00673 |    0.04368 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06692 | -0.00634 |    0.05128 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05358 | -0.00382 |    0.04198 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06376 | -0.00468 |    0.05042 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05939 | -0.00317 |    0.04710 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07686 | -0.00439 |    0.05866 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05721 | -0.00690 |    0.04532 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04037 | -0.00322 |    0.03129 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03548 | -0.00682 |    0.02782 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02044 |  0.00003 |    0.01403 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40097 | -0.00001 |    0.28312 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:40:17,871 - Total sparsity: 0.00

2018-10-21 07:40:17,871 - --- validate (epoch=245)-----------
2018-10-21 07:40:17,872 - 10000 samples (128 per mini-batch)
2018-10-21 07:40:19,046 - Epoch: [245][   50/   78]    Loss 1.550357    Top1 91.156250    Top5 99.656250    
2018-10-21 07:40:19,715 - ==> Top1: 91.100    Top5: 99.650    Loss: 1.551

2018-10-21 07:40:19,716 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:40:19,717 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:40:19,729 - 

2018-10-21 07:40:19,730 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:40:21,507 - Epoch: [246][   50/  391]    Overall Loss 1.491667    Objective Loss 1.491667    Top1 97.187500    Top5 99.781250    LR 0.003000    Time 0.035482    
2018-10-21 07:40:23,207 - Epoch: [246][  100/  391]    Overall Loss 1.492382    Objective Loss 1.492382    Top1 97.171875    Top5 99.757812    LR 0.003000    Time 0.034716    
2018-10-21 07:40:24,798 - Epoch: [246][  150/  391]    Overall Loss 1.491101    Objective Loss 1.491101    Top1 97.317708    Top5 99.760417    LR 0.003000    Time 0.033739    
2018-10-21 07:40:26,434 - Epoch: [246][  200/  391]    Overall Loss 1.490988    Objective Loss 1.490988    Top1 97.312500    Top5 99.761719    LR 0.003000    Time 0.033474    
2018-10-21 07:40:28,066 - Epoch: [246][  250/  391]    Overall Loss 1.490805    Objective Loss 1.490805    Top1 97.343750    Top5 99.750000    LR 0.003000    Time 0.033298    
2018-10-21 07:40:29,743 - Epoch: [246][  300/  391]    Overall Loss 1.491031    Objective Loss 1.491031    Top1 97.309896    Top5 99.755208    LR 0.003000    Time 0.033331    
2018-10-21 07:40:31,357 - Epoch: [246][  350/  391]    Overall Loss 1.491258    Objective Loss 1.491258    Top1 97.283482    Top5 99.732143    LR 0.003000    Time 0.033175    
2018-10-21 07:40:32,792 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22340 | -0.00070 |    0.14834 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07893 | -0.00324 |    0.04611 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07706 |  0.00098 |    0.05233 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06658 | -0.00626 |    0.04521 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06366 | -0.00226 |    0.04177 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07837 | -0.00987 |    0.05478 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06879 | -0.00675 |    0.04838 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08000 | -0.00294 |    0.05983 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06885 | -0.00352 |    0.05243 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16450 |  0.00021 |    0.10103 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06261 | -0.00226 |    0.04726 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05543 | -0.00670 |    0.04364 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06685 | -0.00635 |    0.05122 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05352 | -0.00378 |    0.04193 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06369 | -0.00468 |    0.05037 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05932 | -0.00320 |    0.04705 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07677 | -0.00438 |    0.05860 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05715 | -0.00688 |    0.04527 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04033 | -0.00321 |    0.03126 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03544 | -0.00683 |    0.02779 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02042 |  0.00003 |    0.01401 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40088 | -0.00001 |    0.28306 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:40:32,792 - Total sparsity: 0.00

2018-10-21 07:40:32,792 - --- validate (epoch=246)-----------
2018-10-21 07:40:32,792 - 10000 samples (128 per mini-batch)
2018-10-21 07:40:34,063 - Epoch: [246][   50/   78]    Loss 1.550322    Top1 91.250000    Top5 99.625000    
2018-10-21 07:40:34,735 - ==> Top1: 91.130    Top5: 99.620    Loss: 1.551

2018-10-21 07:40:34,737 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:40:34,737 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:40:34,750 - 

2018-10-21 07:40:34,750 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:40:36,494 - Epoch: [247][   50/  391]    Overall Loss 1.490026    Objective Loss 1.490026    Top1 97.296875    Top5 99.703125    LR 0.003000    Time 0.034811    
2018-10-21 07:40:38,151 - Epoch: [247][  100/  391]    Overall Loss 1.491240    Objective Loss 1.491240    Top1 97.234375    Top5 99.750000    LR 0.003000    Time 0.033959    
2018-10-21 07:40:39,781 - Epoch: [247][  150/  391]    Overall Loss 1.491352    Objective Loss 1.491352    Top1 97.229167    Top5 99.734375    LR 0.003000    Time 0.033494    
2018-10-21 07:40:41,394 - Epoch: [247][  200/  391]    Overall Loss 1.491610    Objective Loss 1.491610    Top1 97.222656    Top5 99.726562    LR 0.003000    Time 0.033172    
2018-10-21 07:40:43,089 - Epoch: [247][  250/  391]    Overall Loss 1.491487    Objective Loss 1.491487    Top1 97.231250    Top5 99.728125    LR 0.003000    Time 0.033310    
2018-10-21 07:40:44,843 - Epoch: [247][  300/  391]    Overall Loss 1.491521    Objective Loss 1.491521    Top1 97.242188    Top5 99.731771    LR 0.003000    Time 0.033599    
2018-10-21 07:40:46,498 - Epoch: [247][  350/  391]    Overall Loss 1.491753    Objective Loss 1.491753    Top1 97.225446    Top5 99.718750    LR 0.003000    Time 0.033521    
2018-10-21 07:40:47,936 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22315 | -0.00062 |    0.14818 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07885 | -0.00325 |    0.04607 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07697 |  0.00099 |    0.05229 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06651 | -0.00624 |    0.04519 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06359 | -0.00231 |    0.04173 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07829 | -0.00976 |    0.05472 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06871 | -0.00672 |    0.04832 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07991 | -0.00298 |    0.05977 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06877 | -0.00350 |    0.05236 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16432 |  0.00012 |    0.10097 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06255 | -0.00224 |    0.04721 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05538 | -0.00669 |    0.04359 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06677 | -0.00637 |    0.05117 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05347 | -0.00378 |    0.04188 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06362 | -0.00467 |    0.05031 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05926 | -0.00318 |    0.04700 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07668 | -0.00437 |    0.05854 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05709 | -0.00689 |    0.04522 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04029 | -0.00320 |    0.03123 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03540 | -0.00683 |    0.02776 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02040 |  0.00003 |    0.01400 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40079 | -0.00001 |    0.28300 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:40:47,936 - Total sparsity: 0.00

2018-10-21 07:40:47,937 - --- validate (epoch=247)-----------
2018-10-21 07:40:47,937 - 10000 samples (128 per mini-batch)
2018-10-21 07:40:49,146 - Epoch: [247][   50/   78]    Loss 1.551617    Top1 91.031250    Top5 99.671875    
2018-10-21 07:40:49,801 - ==> Top1: 91.120    Top5: 99.650    Loss: 1.551

2018-10-21 07:40:49,802 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:40:49,803 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:40:49,815 - 

2018-10-21 07:40:49,815 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:40:51,559 - Epoch: [248][   50/  391]    Overall Loss 1.488705    Objective Loss 1.488705    Top1 97.609375    Top5 99.750000    LR 0.003000    Time 0.034804    
2018-10-21 07:40:53,205 - Epoch: [248][  100/  391]    Overall Loss 1.489364    Objective Loss 1.489364    Top1 97.492188    Top5 99.757812    LR 0.003000    Time 0.033836    
2018-10-21 07:40:54,899 - Epoch: [248][  150/  391]    Overall Loss 1.489490    Objective Loss 1.489490    Top1 97.468750    Top5 99.744792    LR 0.003000    Time 0.033835    
2018-10-21 07:40:56,553 - Epoch: [248][  200/  391]    Overall Loss 1.489753    Objective Loss 1.489753    Top1 97.453125    Top5 99.761719    LR 0.003000    Time 0.033632    
2018-10-21 07:40:58,198 - Epoch: [248][  250/  391]    Overall Loss 1.490479    Objective Loss 1.490479    Top1 97.381250    Top5 99.750000    LR 0.003000    Time 0.033478    
2018-10-21 07:40:59,851 - Epoch: [248][  300/  391]    Overall Loss 1.490112    Objective Loss 1.490112    Top1 97.411458    Top5 99.765625    LR 0.003000    Time 0.033400    
2018-10-21 07:41:01,480 - Epoch: [248][  350/  391]    Overall Loss 1.490365    Objective Loss 1.490365    Top1 97.386161    Top5 99.763393    LR 0.003000    Time 0.033279    
2018-10-21 07:41:03,003 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22291 | -0.00062 |    0.14804 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07876 | -0.00326 |    0.04601 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07689 |  0.00096 |    0.05225 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06644 | -0.00622 |    0.04513 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06352 | -0.00230 |    0.04166 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07819 | -0.00988 |    0.05467 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06864 | -0.00662 |    0.04826 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07982 | -0.00298 |    0.05969 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06870 | -0.00346 |    0.05230 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16414 |  0.00015 |    0.10081 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06248 | -0.00225 |    0.04716 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05532 | -0.00668 |    0.04355 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06670 | -0.00636 |    0.05111 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05341 | -0.00377 |    0.04183 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06355 | -0.00467 |    0.05026 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05920 | -0.00314 |    0.04695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07660 | -0.00435 |    0.05847 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05702 | -0.00690 |    0.04517 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04025 | -0.00320 |    0.03119 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03536 | -0.00683 |    0.02773 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02037 |  0.00002 |    0.01398 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40070 | -0.00001 |    0.28295 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:41:03,003 - Total sparsity: 0.00

2018-10-21 07:41:03,003 - --- validate (epoch=248)-----------
2018-10-21 07:41:03,004 - 10000 samples (128 per mini-batch)
2018-10-21 07:41:04,250 - Epoch: [248][   50/   78]    Loss 1.550300    Top1 91.078125    Top5 99.609375    
2018-10-21 07:41:04,883 - ==> Top1: 91.140    Top5: 99.640    Loss: 1.550

2018-10-21 07:41:04,885 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:41:04,885 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:41:04,898 - 

2018-10-21 07:41:04,898 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:41:06,598 - Epoch: [249][   50/  391]    Overall Loss 1.487907    Objective Loss 1.487907    Top1 97.687500    Top5 99.734375    LR 0.003000    Time 0.033943    
2018-10-21 07:41:08,162 - Epoch: [249][  100/  391]    Overall Loss 1.489843    Objective Loss 1.489843    Top1 97.500000    Top5 99.718750    LR 0.003000    Time 0.032588    
2018-10-21 07:41:09,781 - Epoch: [249][  150/  391]    Overall Loss 1.489931    Objective Loss 1.489931    Top1 97.463542    Top5 99.713542    LR 0.003000    Time 0.032504    
2018-10-21 07:41:11,393 - Epoch: [249][  200/  391]    Overall Loss 1.490360    Objective Loss 1.490360    Top1 97.421875    Top5 99.730469    LR 0.003000    Time 0.032423    
2018-10-21 07:41:12,994 - Epoch: [249][  250/  391]    Overall Loss 1.490511    Objective Loss 1.490511    Top1 97.387500    Top5 99.725000    LR 0.003000    Time 0.032336    
2018-10-21 07:41:14,599 - Epoch: [249][  300/  391]    Overall Loss 1.490367    Objective Loss 1.490367    Top1 97.393229    Top5 99.723958    LR 0.003000    Time 0.032290    
2018-10-21 07:41:16,190 - Epoch: [249][  350/  391]    Overall Loss 1.490286    Objective Loss 1.490286    Top1 97.386161    Top5 99.727679    LR 0.003000    Time 0.032216    
2018-10-21 07:41:17,611 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22266 | -0.00111 |    0.14778 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07867 | -0.00336 |    0.04597 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07680 |  0.00097 |    0.05217 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06637 | -0.00620 |    0.04507 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06345 | -0.00231 |    0.04162 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07810 | -0.00989 |    0.05462 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06857 | -0.00664 |    0.04823 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07973 | -0.00302 |    0.05963 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06862 | -0.00347 |    0.05224 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16396 |  0.00019 |    0.10066 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06241 | -0.00224 |    0.04711 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05525 | -0.00669 |    0.04350 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06663 | -0.00635 |    0.05105 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05335 | -0.00376 |    0.04178 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06349 | -0.00465 |    0.05021 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05913 | -0.00314 |    0.04690 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07652 | -0.00430 |    0.05840 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05696 | -0.00690 |    0.04512 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04020 | -0.00321 |    0.03116 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03532 | -0.00684 |    0.02770 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02035 |  0.00002 |    0.01397 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40062 | -0.00001 |    0.28290 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:41:17,611 - Total sparsity: 0.00

2018-10-21 07:41:17,611 - --- validate (epoch=249)-----------
2018-10-21 07:41:17,611 - 10000 samples (128 per mini-batch)
2018-10-21 07:41:18,830 - Epoch: [249][   50/   78]    Loss 1.551075    Top1 90.984375    Top5 99.656250    
2018-10-21 07:41:19,475 - ==> Top1: 90.930    Top5: 99.660    Loss: 1.551

2018-10-21 07:41:19,477 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:41:19,477 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:41:19,490 - 

2018-10-21 07:41:19,490 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:41:21,157 - Epoch: [250][   50/  391]    Overall Loss 1.492120    Objective Loss 1.492120    Top1 97.203125    Top5 99.625000    LR 0.001500    Time 0.033292    
2018-10-21 07:41:22,730 - Epoch: [250][  100/  391]    Overall Loss 1.491659    Objective Loss 1.491659    Top1 97.257812    Top5 99.695312    LR 0.001500    Time 0.032346    
2018-10-21 07:41:24,290 - Epoch: [250][  150/  391]    Overall Loss 1.491318    Objective Loss 1.491318    Top1 97.296875    Top5 99.687500    LR 0.001500    Time 0.031946    
2018-10-21 07:41:25,858 - Epoch: [250][  200/  391]    Overall Loss 1.489915    Objective Loss 1.489915    Top1 97.429688    Top5 99.707031    LR 0.001500    Time 0.031790    
2018-10-21 07:41:27,443 - Epoch: [250][  250/  391]    Overall Loss 1.490228    Objective Loss 1.490228    Top1 97.396875    Top5 99.709375    LR 0.001500    Time 0.031762    
2018-10-21 07:41:29,017 - Epoch: [250][  300/  391]    Overall Loss 1.489816    Objective Loss 1.489816    Top1 97.424479    Top5 99.716146    LR 0.001500    Time 0.031709    
2018-10-21 07:41:30,570 - Epoch: [250][  350/  391]    Overall Loss 1.489686    Objective Loss 1.489686    Top1 97.441964    Top5 99.720982    LR 0.001500    Time 0.031609    
2018-10-21 07:41:31,955 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22253 | -0.00132 |    0.14770 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07863 | -0.00332 |    0.04596 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07676 |  0.00099 |    0.05215 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06633 | -0.00619 |    0.04505 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06342 | -0.00232 |    0.04160 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07807 | -0.00979 |    0.05459 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06853 | -0.00665 |    0.04820 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07968 | -0.00305 |    0.05960 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06859 | -0.00345 |    0.05221 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16387 |  0.00016 |    0.10055 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 | -0.00223 |    0.04709 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05522 | -0.00668 |    0.04348 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06659 | -0.00633 |    0.05102 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05332 | -0.00376 |    0.04176 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06345 | -0.00465 |    0.05018 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05910 | -0.00314 |    0.04688 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07647 | -0.00431 |    0.05836 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05693 | -0.00689 |    0.04510 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04018 | -0.00321 |    0.03114 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03530 | -0.00683 |    0.02768 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02034 |  0.00001 |    0.01396 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40058 | -0.00001 |    0.28287 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:41:31,955 - Total sparsity: 0.00

2018-10-21 07:41:31,955 - --- validate (epoch=250)-----------
2018-10-21 07:41:31,956 - 10000 samples (128 per mini-batch)
2018-10-21 07:41:33,119 - Epoch: [250][   50/   78]    Loss 1.550333    Top1 91.234375    Top5 99.609375    
2018-10-21 07:41:33,749 - ==> Top1: 91.180    Top5: 99.630    Loss: 1.550

2018-10-21 07:41:33,750 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:41:33,751 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:41:33,763 - 

2018-10-21 07:41:33,764 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:41:35,486 - Epoch: [251][   50/  391]    Overall Loss 1.488566    Objective Loss 1.488566    Top1 97.515625    Top5 99.765625    LR 0.001500    Time 0.034387    
2018-10-21 07:41:37,038 - Epoch: [251][  100/  391]    Overall Loss 1.489795    Objective Loss 1.489795    Top1 97.414062    Top5 99.757812    LR 0.001500    Time 0.032692    
2018-10-21 07:41:38,596 - Epoch: [251][  150/  391]    Overall Loss 1.489026    Objective Loss 1.489026    Top1 97.505208    Top5 99.729167    LR 0.001500    Time 0.032162    
2018-10-21 07:41:40,157 - Epoch: [251][  200/  391]    Overall Loss 1.489883    Objective Loss 1.489883    Top1 97.414062    Top5 99.726562    LR 0.001500    Time 0.031918    
2018-10-21 07:41:41,717 - Epoch: [251][  250/  391]    Overall Loss 1.489719    Objective Loss 1.489719    Top1 97.440625    Top5 99.728125    LR 0.001500    Time 0.031763    
2018-10-21 07:41:43,264 - Epoch: [251][  300/  391]    Overall Loss 1.489997    Objective Loss 1.489997    Top1 97.414062    Top5 99.726562    LR 0.001500    Time 0.031619    
2018-10-21 07:41:44,797 - Epoch: [251][  350/  391]    Overall Loss 1.489778    Objective Loss 1.489778    Top1 97.435268    Top5 99.725446    LR 0.001500    Time 0.031475    
2018-10-21 07:41:46,207 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22241 | -0.00088 |    0.14764 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07858 | -0.00330 |    0.04592 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07672 |  0.00100 |    0.05213 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06630 | -0.00617 |    0.04501 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06338 | -0.00233 |    0.04157 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07803 | -0.00977 |    0.05455 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06849 | -0.00667 |    0.04816 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07964 | -0.00303 |    0.05957 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06855 | -0.00346 |    0.05218 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16377 |  0.00016 |    0.10051 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 | -0.00223 |    0.04706 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05519 | -0.00667 |    0.04346 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06656 | -0.00632 |    0.05099 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05329 | -0.00374 |    0.04173 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06341 | -0.00464 |    0.05015 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05907 | -0.00313 |    0.04685 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07643 | -0.00432 |    0.05833 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05690 | -0.00688 |    0.04508 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04016 | -0.00321 |    0.03113 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03528 | -0.00683 |    0.02767 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02033 |  0.00001 |    0.01396 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40053 | -0.00001 |    0.28284 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:41:46,208 - Total sparsity: 0.00

2018-10-21 07:41:46,208 - --- validate (epoch=251)-----------
2018-10-21 07:41:46,208 - 10000 samples (128 per mini-batch)
2018-10-21 07:41:47,421 - Epoch: [251][   50/   78]    Loss 1.550260    Top1 91.218750    Top5 99.593750    
2018-10-21 07:41:48,066 - ==> Top1: 91.250    Top5: 99.620    Loss: 1.550

2018-10-21 07:41:48,067 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:41:48,067 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:41:48,080 - 

2018-10-21 07:41:48,080 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:41:49,806 - Epoch: [252][   50/  391]    Overall Loss 1.486144    Objective Loss 1.486144    Top1 97.812500    Top5 99.765625    LR 0.001500    Time 0.034458    
2018-10-21 07:41:51,546 - Epoch: [252][  100/  391]    Overall Loss 1.486029    Objective Loss 1.486029    Top1 97.890625    Top5 99.742188    LR 0.001500    Time 0.034603    
2018-10-21 07:41:53,093 - Epoch: [252][  150/  391]    Overall Loss 1.487883    Objective Loss 1.487883    Top1 97.692708    Top5 99.718750    LR 0.001500    Time 0.033368    
2018-10-21 07:41:54,629 - Epoch: [252][  200/  391]    Overall Loss 1.488452    Objective Loss 1.488452    Top1 97.613281    Top5 99.710938    LR 0.001500    Time 0.032695    
2018-10-21 07:41:56,150 - Epoch: [252][  250/  391]    Overall Loss 1.489266    Objective Loss 1.489266    Top1 97.525000    Top5 99.693750    LR 0.001500    Time 0.032232    
2018-10-21 07:41:57,702 - Epoch: [252][  300/  391]    Overall Loss 1.489291    Objective Loss 1.489291    Top1 97.515625    Top5 99.705729    LR 0.001500    Time 0.032025    
2018-10-21 07:41:59,243 - Epoch: [252][  350/  391]    Overall Loss 1.489483    Objective Loss 1.489483    Top1 97.488839    Top5 99.703125    LR 0.001500    Time 0.031847    
2018-10-21 07:42:00,611 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22228 | -0.00092 |    0.14755 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07854 | -0.00332 |    0.04590 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07667 |  0.00101 |    0.05210 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06626 | -0.00617 |    0.04499 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06335 | -0.00231 |    0.04155 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07798 | -0.00981 |    0.05452 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06845 | -0.00662 |    0.04813 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07959 | -0.00306 |    0.05953 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06851 | -0.00347 |    0.05215 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16368 |  0.00012 |    0.10048 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06231 | -0.00223 |    0.04704 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05516 | -0.00667 |    0.04343 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06652 | -0.00630 |    0.05096 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05326 | -0.00373 |    0.04171 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06338 | -0.00464 |    0.05012 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05903 | -0.00313 |    0.04682 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07638 | -0.00432 |    0.05830 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05687 | -0.00688 |    0.04505 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04013 | -0.00322 |    0.03111 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03526 | -0.00683 |    0.02765 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02032 |  0.00001 |    0.01395 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40049 | -0.00001 |    0.28282 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:42:00,612 - Total sparsity: 0.00

2018-10-21 07:42:00,612 - --- validate (epoch=252)-----------
2018-10-21 07:42:00,612 - 10000 samples (128 per mini-batch)
2018-10-21 07:42:01,835 - Epoch: [252][   50/   78]    Loss 1.549901    Top1 91.125000    Top5 99.656250    
2018-10-21 07:42:02,502 - ==> Top1: 91.190    Top5: 99.640    Loss: 1.550

2018-10-21 07:42:02,503 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:42:02,504 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:42:02,516 - 

2018-10-21 07:42:02,517 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:42:04,251 - Epoch: [253][   50/  391]    Overall Loss 1.490223    Objective Loss 1.490223    Top1 97.406250    Top5 99.656250    LR 0.001500    Time 0.034623    
2018-10-21 07:42:05,850 - Epoch: [253][  100/  391]    Overall Loss 1.489239    Objective Loss 1.489239    Top1 97.468750    Top5 99.718750    LR 0.001500    Time 0.033283    
2018-10-21 07:42:07,429 - Epoch: [253][  150/  391]    Overall Loss 1.489587    Objective Loss 1.489587    Top1 97.432292    Top5 99.703125    LR 0.001500    Time 0.032700    
2018-10-21 07:42:08,986 - Epoch: [253][  200/  391]    Overall Loss 1.489378    Objective Loss 1.489378    Top1 97.445312    Top5 99.707031    LR 0.001500    Time 0.032295    
2018-10-21 07:42:10,567 - Epoch: [253][  250/  391]    Overall Loss 1.489271    Objective Loss 1.489271    Top1 97.465625    Top5 99.721875    LR 0.001500    Time 0.032152    
2018-10-21 07:42:12,115 - Epoch: [253][  300/  391]    Overall Loss 1.489503    Objective Loss 1.489503    Top1 97.432292    Top5 99.731771    LR 0.001500    Time 0.031948    
2018-10-21 07:42:13,691 - Epoch: [253][  350/  391]    Overall Loss 1.489400    Objective Loss 1.489400    Top1 97.448661    Top5 99.743304    LR 0.001500    Time 0.031881    
2018-10-21 07:42:15,086 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22216 | -0.00111 |    0.14744 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07849 | -0.00331 |    0.04587 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07663 |  0.00102 |    0.05206 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06622 | -0.00618 |    0.04496 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06331 | -0.00236 |    0.04152 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07794 | -0.00980 |    0.05448 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06841 | -0.00662 |    0.04810 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07955 | -0.00304 |    0.05950 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06847 | -0.00348 |    0.05212 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16359 |  0.00013 |    0.10050 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06227 | -0.00221 |    0.04701 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05513 | -0.00667 |    0.04341 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06648 | -0.00630 |    0.05093 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05323 | -0.00373 |    0.04169 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06334 | -0.00464 |    0.05009 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05900 | -0.00312 |    0.04679 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07634 | -0.00431 |    0.05826 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05683 | -0.00688 |    0.04503 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04011 | -0.00322 |    0.03109 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03524 | -0.00682 |    0.02764 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02031 |  0.00001 |    0.01394 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40044 | -0.00001 |    0.28278 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:42:15,087 - Total sparsity: 0.00

2018-10-21 07:42:15,087 - --- validate (epoch=253)-----------
2018-10-21 07:42:15,087 - 10000 samples (128 per mini-batch)
2018-10-21 07:42:16,380 - Epoch: [253][   50/   78]    Loss 1.549306    Top1 91.328125    Top5 99.640625    
2018-10-21 07:42:17,049 - ==> Top1: 91.280    Top5: 99.630    Loss: 1.549

2018-10-21 07:42:17,050 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:42:17,051 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:42:17,063 - 

2018-10-21 07:42:17,064 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:42:18,886 - Epoch: [254][   50/  391]    Overall Loss 1.489522    Objective Loss 1.489522    Top1 97.437500    Top5 99.750000    LR 0.001500    Time 0.036399    
2018-10-21 07:42:20,609 - Epoch: [254][  100/  391]    Overall Loss 1.489091    Objective Loss 1.489091    Top1 97.515625    Top5 99.804688    LR 0.001500    Time 0.035405    
2018-10-21 07:42:22,231 - Epoch: [254][  150/  391]    Overall Loss 1.489666    Objective Loss 1.489666    Top1 97.479167    Top5 99.770833    LR 0.001500    Time 0.034400    
2018-10-21 07:42:23,913 - Epoch: [254][  200/  391]    Overall Loss 1.489479    Objective Loss 1.489479    Top1 97.484375    Top5 99.742188    LR 0.001500    Time 0.034200    
2018-10-21 07:42:25,484 - Epoch: [254][  250/  391]    Overall Loss 1.488898    Objective Loss 1.488898    Top1 97.550000    Top5 99.753125    LR 0.001500    Time 0.033636    
2018-10-21 07:42:27,060 - Epoch: [254][  300/  391]    Overall Loss 1.489245    Objective Loss 1.489245    Top1 97.510417    Top5 99.739583    LR 0.001500    Time 0.033273    
2018-10-21 07:42:28,634 - Epoch: [254][  350/  391]    Overall Loss 1.489430    Objective Loss 1.489430    Top1 97.482143    Top5 99.727679    LR 0.001500    Time 0.033010    
2018-10-21 07:42:30,066 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22203 | -0.00118 |    0.14736 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07845 | -0.00329 |    0.04585 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07659 |  0.00101 |    0.05203 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06618 | -0.00621 |    0.04493 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06327 | -0.00236 |    0.04150 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07789 | -0.00979 |    0.05444 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06837 | -0.00661 |    0.04808 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07950 | -0.00300 |    0.05947 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06843 | -0.00345 |    0.05209 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16349 |  0.00012 |    0.10043 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06224 | -0.00222 |    0.04699 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05510 | -0.00668 |    0.04339 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06645 | -0.00629 |    0.05090 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05320 | -0.00374 |    0.04167 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06331 | -0.00465 |    0.05006 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05897 | -0.00311 |    0.04677 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07630 | -0.00431 |    0.05823 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05680 | -0.00688 |    0.04500 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04009 | -0.00322 |    0.03108 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03522 | -0.00682 |    0.02762 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02029 |  0.00001 |    0.01393 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40039 | -0.00001 |    0.28275 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:42:30,067 - Total sparsity: 0.00

2018-10-21 07:42:30,067 - --- validate (epoch=254)-----------
2018-10-21 07:42:30,067 - 10000 samples (128 per mini-batch)
2018-10-21 07:42:31,268 - Epoch: [254][   50/   78]    Loss 1.550238    Top1 91.343750    Top5 99.640625    
2018-10-21 07:42:31,923 - ==> Top1: 91.290    Top5: 99.640    Loss: 1.550

2018-10-21 07:42:31,924 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:42:31,925 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:42:31,939 - 

2018-10-21 07:42:31,939 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:42:33,723 - Epoch: [255][   50/  391]    Overall Loss 1.487774    Objective Loss 1.487774    Top1 97.671875    Top5 99.734375    LR 0.001500    Time 0.035627    
2018-10-21 07:42:35,305 - Epoch: [255][  100/  391]    Overall Loss 1.487203    Objective Loss 1.487203    Top1 97.687500    Top5 99.750000    LR 0.001500    Time 0.033611    
2018-10-21 07:42:36,860 - Epoch: [255][  150/  391]    Overall Loss 1.487583    Objective Loss 1.487583    Top1 97.635417    Top5 99.765625    LR 0.001500    Time 0.032757    
2018-10-21 07:42:38,412 - Epoch: [255][  200/  391]    Overall Loss 1.487503    Objective Loss 1.487503    Top1 97.652344    Top5 99.761719    LR 0.001500    Time 0.032317    
2018-10-21 07:42:39,994 - Epoch: [255][  250/  391]    Overall Loss 1.487743    Objective Loss 1.487743    Top1 97.640625    Top5 99.743750    LR 0.001500    Time 0.032174    
2018-10-21 07:42:41,571 - Epoch: [255][  300/  391]    Overall Loss 1.488442    Objective Loss 1.488442    Top1 97.559896    Top5 99.736979    LR 0.001500    Time 0.032060    
2018-10-21 07:42:43,170 - Epoch: [255][  350/  391]    Overall Loss 1.488587    Objective Loss 1.488587    Top1 97.551339    Top5 99.725446    LR 0.001500    Time 0.032043    
2018-10-21 07:42:44,561 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22190 | -0.00108 |    0.14723 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07840 | -0.00330 |    0.04582 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07654 |  0.00099 |    0.05200 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06614 | -0.00623 |    0.04491 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06324 | -0.00237 |    0.04148 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07785 | -0.00977 |    0.05441 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06834 | -0.00660 |    0.04806 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07946 | -0.00300 |    0.05943 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06839 | -0.00344 |    0.05205 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16340 |  0.00014 |    0.10038 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06220 | -0.00221 |    0.04696 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05507 | -0.00666 |    0.04336 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06641 | -0.00629 |    0.05087 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05317 | -0.00373 |    0.04165 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06327 | -0.00464 |    0.05004 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05893 | -0.00312 |    0.04674 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07625 | -0.00431 |    0.05819 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05677 | -0.00687 |    0.04498 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04007 | -0.00322 |    0.03106 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03520 | -0.00682 |    0.02761 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02028 |  0.00001 |    0.01393 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40034 | -0.00001 |    0.28271 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:42:44,561 - Total sparsity: 0.00

2018-10-21 07:42:44,562 - --- validate (epoch=255)-----------
2018-10-21 07:42:44,562 - 10000 samples (128 per mini-batch)
2018-10-21 07:42:45,721 - Epoch: [255][   50/   78]    Loss 1.549747    Top1 91.453125    Top5 99.593750    
2018-10-21 07:42:46,352 - ==> Top1: 91.410    Top5: 99.600    Loss: 1.549

2018-10-21 07:42:46,353 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:42:46,353 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:42:46,366 - 

2018-10-21 07:42:46,367 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:42:48,101 - Epoch: [256][   50/  391]    Overall Loss 1.488839    Objective Loss 1.488839    Top1 97.468750    Top5 99.718750    LR 0.001500    Time 0.034614    
2018-10-21 07:42:49,680 - Epoch: [256][  100/  391]    Overall Loss 1.487054    Objective Loss 1.487054    Top1 97.656250    Top5 99.765625    LR 0.001500    Time 0.033084    
2018-10-21 07:42:51,253 - Epoch: [256][  150/  391]    Overall Loss 1.487952    Objective Loss 1.487952    Top1 97.614583    Top5 99.739583    LR 0.001500    Time 0.032527    
2018-10-21 07:42:52,798 - Epoch: [256][  200/  391]    Overall Loss 1.487725    Objective Loss 1.487725    Top1 97.644531    Top5 99.738281    LR 0.001500    Time 0.032105    
2018-10-21 07:42:54,383 - Epoch: [256][  250/  391]    Overall Loss 1.488341    Objective Loss 1.488341    Top1 97.606250    Top5 99.718750    LR 0.001500    Time 0.032015    
2018-10-21 07:42:55,922 - Epoch: [256][  300/  391]    Overall Loss 1.488540    Objective Loss 1.488540    Top1 97.588542    Top5 99.718750    LR 0.001500    Time 0.031802    
2018-10-21 07:42:57,461 - Epoch: [256][  350/  391]    Overall Loss 1.488513    Objective Loss 1.488513    Top1 97.595982    Top5 99.714286    LR 0.001500    Time 0.031650    
2018-10-21 07:42:58,862 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22178 | -0.00117 |    0.14715 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07836 | -0.00327 |    0.04580 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07650 |  0.00098 |    0.05198 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06610 | -0.00623 |    0.04489 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06320 | -0.00236 |    0.04145 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07781 | -0.00977 |    0.05439 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06830 | -0.00660 |    0.04804 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07941 | -0.00297 |    0.05939 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06835 | -0.00348 |    0.05202 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16331 |  0.00009 |    0.10034 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06217 | -0.00220 |    0.04694 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05504 | -0.00666 |    0.04333 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06637 | -0.00629 |    0.05084 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05314 | -0.00373 |    0.04162 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06323 | -0.00464 |    0.05001 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05890 | -0.00311 |    0.04671 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07621 | -0.00431 |    0.05817 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05674 | -0.00686 |    0.04496 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04004 | -0.00322 |    0.03104 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03518 | -0.00682 |    0.02760 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02027 |  0.00001 |    0.01392 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40030 | -0.00001 |    0.28268 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:42:58,863 - Total sparsity: 0.00

2018-10-21 07:42:58,863 - --- validate (epoch=256)-----------
2018-10-21 07:42:58,863 - 10000 samples (128 per mini-batch)
2018-10-21 07:43:00,074 - Epoch: [256][   50/   78]    Loss 1.549291    Top1 91.406250    Top5 99.593750    
2018-10-21 07:43:00,766 - ==> Top1: 91.310    Top5: 99.590    Loss: 1.549

2018-10-21 07:43:00,767 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:43:00,768 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:43:00,781 - 

2018-10-21 07:43:00,781 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:43:02,457 - Epoch: [257][   50/  391]    Overall Loss 1.488655    Objective Loss 1.488655    Top1 97.546875    Top5 99.734375    LR 0.001500    Time 0.033458    
2018-10-21 07:43:03,995 - Epoch: [257][  100/  391]    Overall Loss 1.488666    Objective Loss 1.488666    Top1 97.554688    Top5 99.734375    LR 0.001500    Time 0.032084    
2018-10-21 07:43:05,551 - Epoch: [257][  150/  391]    Overall Loss 1.488210    Objective Loss 1.488210    Top1 97.578125    Top5 99.734375    LR 0.001500    Time 0.031750    
2018-10-21 07:43:07,100 - Epoch: [257][  200/  391]    Overall Loss 1.488180    Objective Loss 1.488180    Top1 97.585938    Top5 99.746094    LR 0.001500    Time 0.031544    
2018-10-21 07:43:08,638 - Epoch: [257][  250/  391]    Overall Loss 1.488565    Objective Loss 1.488565    Top1 97.559375    Top5 99.734375    LR 0.001500    Time 0.031381    
2018-10-21 07:43:10,178 - Epoch: [257][  300/  391]    Overall Loss 1.488764    Objective Loss 1.488764    Top1 97.536458    Top5 99.697917    LR 0.001500    Time 0.031276    
2018-10-21 07:43:11,714 - Epoch: [257][  350/  391]    Overall Loss 1.489052    Objective Loss 1.489052    Top1 97.515625    Top5 99.696429    LR 0.001500    Time 0.031189    
2018-10-21 07:43:13,110 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22165 | -0.00115 |    0.14708 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07832 | -0.00324 |    0.04578 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07646 |  0.00094 |    0.05196 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06606 | -0.00623 |    0.04487 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06316 | -0.00236 |    0.04143 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07776 | -0.00978 |    0.05437 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06826 | -0.00659 |    0.04801 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07937 | -0.00293 |    0.05937 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06831 | -0.00348 |    0.05199 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16322 |  0.00014 |    0.10025 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06213 | -0.00220 |    0.04691 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05501 | -0.00666 |    0.04331 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06633 | -0.00629 |    0.05081 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05311 | -0.00372 |    0.04160 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06320 | -0.00464 |    0.04998 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05887 | -0.00311 |    0.04669 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07617 | -0.00430 |    0.05813 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05671 | -0.00685 |    0.04493 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04002 | -0.00322 |    0.03103 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03516 | -0.00682 |    0.02758 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02026 |  0.00001 |    0.01391 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40026 | -0.00001 |    0.28265 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:43:13,110 - Total sparsity: 0.00

2018-10-21 07:43:13,110 - --- validate (epoch=257)-----------
2018-10-21 07:43:13,111 - 10000 samples (128 per mini-batch)
2018-10-21 07:43:14,372 - Epoch: [257][   50/   78]    Loss 1.549835    Top1 91.234375    Top5 99.609375    
2018-10-21 07:43:15,080 - ==> Top1: 91.240    Top5: 99.640    Loss: 1.550

2018-10-21 07:43:15,082 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:43:15,082 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:43:15,095 - 

2018-10-21 07:43:15,095 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:43:16,814 - Epoch: [258][   50/  391]    Overall Loss 1.486893    Objective Loss 1.486893    Top1 97.718750    Top5 99.796875    LR 0.001500    Time 0.034315    
2018-10-21 07:43:18,485 - Epoch: [258][  100/  391]    Overall Loss 1.487498    Objective Loss 1.487498    Top1 97.710938    Top5 99.750000    LR 0.001500    Time 0.033839    
2018-10-21 07:43:20,057 - Epoch: [258][  150/  391]    Overall Loss 1.488208    Objective Loss 1.488208    Top1 97.598958    Top5 99.739583    LR 0.001500    Time 0.033024    
2018-10-21 07:43:21,603 - Epoch: [258][  200/  391]    Overall Loss 1.488724    Objective Loss 1.488724    Top1 97.554688    Top5 99.699219    LR 0.001500    Time 0.032487    
2018-10-21 07:43:23,125 - Epoch: [258][  250/  391]    Overall Loss 1.489242    Objective Loss 1.489242    Top1 97.493750    Top5 99.718750    LR 0.001500    Time 0.032070    
2018-10-21 07:43:24,679 - Epoch: [258][  300/  391]    Overall Loss 1.488696    Objective Loss 1.488696    Top1 97.562500    Top5 99.729167    LR 0.001500    Time 0.031897    
2018-10-21 07:43:26,219 - Epoch: [258][  350/  391]    Overall Loss 1.488859    Objective Loss 1.488859    Top1 97.546875    Top5 99.723214    LR 0.001500    Time 0.031735    
2018-10-21 07:43:27,616 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22153 | -0.00096 |    0.14699 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07827 | -0.00325 |    0.04576 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07641 |  0.00090 |    0.05194 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06602 | -0.00626 |    0.04485 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06313 | -0.00239 |    0.04141 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07772 | -0.00977 |    0.05433 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06822 | -0.00658 |    0.04798 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07932 | -0.00295 |    0.05934 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06827 | -0.00348 |    0.05196 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16312 |  0.00010 |    0.10025 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06210 | -0.00218 |    0.04688 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05497 | -0.00667 |    0.04328 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06630 | -0.00628 |    0.05078 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05308 | -0.00373 |    0.04157 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06316 | -0.00464 |    0.04995 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05883 | -0.00310 |    0.04666 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07612 | -0.00431 |    0.05810 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05667 | -0.00685 |    0.04491 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04000 | -0.00322 |    0.03101 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03514 | -0.00682 |    0.02756 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02025 |  0.00001 |    0.01390 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40021 | -0.00001 |    0.28261 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:43:27,617 - Total sparsity: 0.00

2018-10-21 07:43:27,617 - --- validate (epoch=258)-----------
2018-10-21 07:43:27,617 - 10000 samples (128 per mini-batch)
2018-10-21 07:43:28,833 - Epoch: [258][   50/   78]    Loss 1.549248    Top1 91.390625    Top5 99.625000    
2018-10-21 07:43:29,499 - ==> Top1: 91.370    Top5: 99.650    Loss: 1.549

2018-10-21 07:43:29,501 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:43:29,501 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:43:29,514 - 

2018-10-21 07:43:29,514 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:43:31,211 - Epoch: [259][   50/  391]    Overall Loss 1.486506    Objective Loss 1.486506    Top1 97.765625    Top5 99.796875    LR 0.001500    Time 0.033861    
2018-10-21 07:43:32,799 - Epoch: [259][  100/  391]    Overall Loss 1.488083    Objective Loss 1.488083    Top1 97.609375    Top5 99.765625    LR 0.001500    Time 0.032790    
2018-10-21 07:43:34,378 - Epoch: [259][  150/  391]    Overall Loss 1.488384    Objective Loss 1.488384    Top1 97.567708    Top5 99.723958    LR 0.001500    Time 0.032375    
2018-10-21 07:43:35,960 - Epoch: [259][  200/  391]    Overall Loss 1.488135    Objective Loss 1.488135    Top1 97.597656    Top5 99.718750    LR 0.001500    Time 0.032181    
2018-10-21 07:43:37,538 - Epoch: [259][  250/  391]    Overall Loss 1.488527    Objective Loss 1.488527    Top1 97.562500    Top5 99.709375    LR 0.001500    Time 0.032048    
2018-10-21 07:43:39,143 - Epoch: [259][  300/  391]    Overall Loss 1.488856    Objective Loss 1.488856    Top1 97.533854    Top5 99.716146    LR 0.001500    Time 0.032048    
2018-10-21 07:43:40,702 - Epoch: [259][  350/  391]    Overall Loss 1.488297    Objective Loss 1.488297    Top1 97.589286    Top5 99.709821    LR 0.001500    Time 0.031918    
2018-10-21 07:43:42,136 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22140 | -0.00113 |    0.14692 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07823 | -0.00322 |    0.04574 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07637 |  0.00087 |    0.05190 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06599 | -0.00625 |    0.04484 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06309 | -0.00238 |    0.04139 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07767 | -0.00975 |    0.05431 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06818 | -0.00660 |    0.04796 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07928 | -0.00296 |    0.05930 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06823 | -0.00348 |    0.05193 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16303 |  0.00011 |    0.10018 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06206 | -0.00219 |    0.04686 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05494 | -0.00667 |    0.04326 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06626 | -0.00626 |    0.05075 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05305 | -0.00373 |    0.04155 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06313 | -0.00463 |    0.04992 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05880 | -0.00310 |    0.04663 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07608 | -0.00430 |    0.05807 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05664 | -0.00685 |    0.04488 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03998 | -0.00322 |    0.03099 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03512 | -0.00681 |    0.02755 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02024 |  0.00001 |    0.01390 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40016 | -0.00001 |    0.28258 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:43:42,136 - Total sparsity: 0.00

2018-10-21 07:43:42,136 - --- validate (epoch=259)-----------
2018-10-21 07:43:42,136 - 10000 samples (128 per mini-batch)
2018-10-21 07:43:43,415 - Epoch: [259][   50/   78]    Loss 1.549789    Top1 91.171875    Top5 99.625000    
2018-10-21 07:43:44,098 - ==> Top1: 91.220    Top5: 99.650    Loss: 1.549

2018-10-21 07:43:44,100 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:43:44,100 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:43:44,112 - 

2018-10-21 07:43:44,113 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:43:46,056 - Epoch: [260][   50/  391]    Overall Loss 1.486653    Objective Loss 1.486653    Top1 97.765625    Top5 99.812500    LR 0.001500    Time 0.038795    
2018-10-21 07:43:47,706 - Epoch: [260][  100/  391]    Overall Loss 1.486031    Objective Loss 1.486031    Top1 97.820312    Top5 99.734375    LR 0.001500    Time 0.035879    
2018-10-21 07:43:49,289 - Epoch: [260][  150/  391]    Overall Loss 1.486602    Objective Loss 1.486602    Top1 97.765625    Top5 99.723958    LR 0.001500    Time 0.034457    
2018-10-21 07:43:50,850 - Epoch: [260][  200/  391]    Overall Loss 1.487700    Objective Loss 1.487700    Top1 97.648438    Top5 99.707031    LR 0.001500    Time 0.033634    
2018-10-21 07:43:52,413 - Epoch: [260][  250/  391]    Overall Loss 1.487678    Objective Loss 1.487678    Top1 97.650000    Top5 99.718750    LR 0.001500    Time 0.033152    
2018-10-21 07:43:53,999 - Epoch: [260][  300/  391]    Overall Loss 1.487845    Objective Loss 1.487845    Top1 97.653646    Top5 99.721354    LR 0.001500    Time 0.032900    
2018-10-21 07:43:55,568 - Epoch: [260][  350/  391]    Overall Loss 1.487906    Objective Loss 1.487906    Top1 97.647321    Top5 99.712054    LR 0.001500    Time 0.032678    
2018-10-21 07:43:56,989 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22127 | -0.00113 |    0.14683 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07819 | -0.00323 |    0.04572 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07633 |  0.00085 |    0.05186 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06595 | -0.00623 |    0.04481 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06306 | -0.00237 |    0.04136 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07763 | -0.00972 |    0.05427 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06814 | -0.00659 |    0.04793 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07924 | -0.00292 |    0.05926 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06819 | -0.00349 |    0.05191 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16294 |  0.00012 |    0.10015 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06203 | -0.00219 |    0.04683 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05491 | -0.00666 |    0.04324 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06622 | -0.00627 |    0.05073 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05302 | -0.00373 |    0.04152 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06309 | -0.00463 |    0.04989 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05877 | -0.00311 |    0.04660 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07604 | -0.00429 |    0.05804 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05661 | -0.00684 |    0.04486 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03995 | -0.00321 |    0.03098 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03510 | -0.00681 |    0.02753 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02022 |  0.00001 |    0.01389 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40011 | -0.00001 |    0.28256 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:43:56,989 - Total sparsity: 0.00

2018-10-21 07:43:56,989 - --- validate (epoch=260)-----------
2018-10-21 07:43:56,989 - 10000 samples (128 per mini-batch)
2018-10-21 07:43:58,282 - Epoch: [260][   50/   78]    Loss 1.549383    Top1 91.375000    Top5 99.609375    
2018-10-21 07:43:58,972 - ==> Top1: 91.240    Top5: 99.630    Loss: 1.549

2018-10-21 07:43:58,973 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:43:58,973 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:43:58,986 - 

2018-10-21 07:43:58,987 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:44:00,775 - Epoch: [261][   50/  391]    Overall Loss 1.487736    Objective Loss 1.487736    Top1 97.593750    Top5 99.812500    LR 0.001500    Time 0.035700    
2018-10-21 07:44:02,397 - Epoch: [261][  100/  391]    Overall Loss 1.488987    Objective Loss 1.488987    Top1 97.492188    Top5 99.789062    LR 0.001500    Time 0.034047    
2018-10-21 07:44:04,008 - Epoch: [261][  150/  391]    Overall Loss 1.489008    Objective Loss 1.489008    Top1 97.505208    Top5 99.776042    LR 0.001500    Time 0.033426    
2018-10-21 07:44:05,605 - Epoch: [261][  200/  391]    Overall Loss 1.488890    Objective Loss 1.488890    Top1 97.535156    Top5 99.769531    LR 0.001500    Time 0.033042    
2018-10-21 07:44:07,222 - Epoch: [261][  250/  391]    Overall Loss 1.488811    Objective Loss 1.488811    Top1 97.537500    Top5 99.756250    LR 0.001500    Time 0.032891    
2018-10-21 07:44:08,824 - Epoch: [261][  300/  391]    Overall Loss 1.488341    Objective Loss 1.488341    Top1 97.591146    Top5 99.768229    LR 0.001500    Time 0.032744    
2018-10-21 07:44:10,388 - Epoch: [261][  350/  391]    Overall Loss 1.488611    Objective Loss 1.488611    Top1 97.558036    Top5 99.754464    LR 0.001500    Time 0.032527    
2018-10-21 07:44:11,814 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22115 | -0.00094 |    0.14680 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07814 | -0.00324 |    0.04569 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07628 |  0.00089 |    0.05183 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06592 | -0.00621 |    0.04479 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06302 | -0.00236 |    0.04133 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07759 | -0.00974 |    0.05423 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06810 | -0.00658 |    0.04790 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07919 | -0.00287 |    0.05922 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06816 | -0.00349 |    0.05188 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16284 |  0.00016 |    0.10007 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06199 | -0.00219 |    0.04680 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05488 | -0.00666 |    0.04322 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06618 | -0.00626 |    0.05069 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05299 | -0.00373 |    0.04150 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06305 | -0.00464 |    0.04986 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05873 | -0.00312 |    0.04658 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07599 | -0.00429 |    0.05802 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05658 | -0.00683 |    0.04483 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03993 | -0.00321 |    0.03096 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03508 | -0.00681 |    0.02752 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02021 |  0.00000 |    0.01388 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40007 | -0.00001 |    0.28252 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:44:11,814 - Total sparsity: 0.00

2018-10-21 07:44:11,814 - --- validate (epoch=261)-----------
2018-10-21 07:44:11,815 - 10000 samples (128 per mini-batch)
2018-10-21 07:44:13,072 - Epoch: [261][   50/   78]    Loss 1.549169    Top1 91.328125    Top5 99.656250    
2018-10-21 07:44:13,718 - ==> Top1: 91.300    Top5: 99.640    Loss: 1.549

2018-10-21 07:44:13,719 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:44:13,720 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:44:13,732 - 

2018-10-21 07:44:13,733 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:44:15,543 - Epoch: [262][   50/  391]    Overall Loss 1.490473    Objective Loss 1.490473    Top1 97.375000    Top5 99.625000    LR 0.001500    Time 0.036141    
2018-10-21 07:44:17,221 - Epoch: [262][  100/  391]    Overall Loss 1.489933    Objective Loss 1.489933    Top1 97.476562    Top5 99.648438    LR 0.001500    Time 0.034832    
2018-10-21 07:44:18,812 - Epoch: [262][  150/  391]    Overall Loss 1.488220    Objective Loss 1.488220    Top1 97.635417    Top5 99.661458    LR 0.001500    Time 0.033811    
2018-10-21 07:44:20,386 - Epoch: [262][  200/  391]    Overall Loss 1.488131    Objective Loss 1.488131    Top1 97.644531    Top5 99.695312    LR 0.001500    Time 0.033219    
2018-10-21 07:44:21,984 - Epoch: [262][  250/  391]    Overall Loss 1.488450    Objective Loss 1.488450    Top1 97.593750    Top5 99.675000    LR 0.001500    Time 0.032956    
2018-10-21 07:44:23,551 - Epoch: [262][  300/  391]    Overall Loss 1.488289    Objective Loss 1.488289    Top1 97.617188    Top5 99.703125    LR 0.001500    Time 0.032679    
2018-10-21 07:44:25,113 - Epoch: [262][  350/  391]    Overall Loss 1.487865    Objective Loss 1.487865    Top1 97.662946    Top5 99.720982    LR 0.001500    Time 0.032467    
2018-10-21 07:44:26,484 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22102 | -0.00087 |    0.14665 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07810 | -0.00324 |    0.04565 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07624 |  0.00091 |    0.05180 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06588 | -0.00620 |    0.04477 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06299 | -0.00236 |    0.04131 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07754 | -0.00975 |    0.05420 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06806 | -0.00662 |    0.04788 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07915 | -0.00284 |    0.05919 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06812 | -0.00351 |    0.05185 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16275 |  0.00015 |    0.10001 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06196 | -0.00219 |    0.04677 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05485 | -0.00665 |    0.04319 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06615 | -0.00627 |    0.05066 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05296 | -0.00373 |    0.04148 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06302 | -0.00463 |    0.04983 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05870 | -0.00310 |    0.04655 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07595 | -0.00428 |    0.05799 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05655 | -0.00683 |    0.04481 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03991 | -0.00322 |    0.03094 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03506 | -0.00680 |    0.02750 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02020 |  0.00000 |    0.01388 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40003 | -0.00001 |    0.28250 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:44:26,484 - Total sparsity: 0.00

2018-10-21 07:44:26,484 - --- validate (epoch=262)-----------
2018-10-21 07:44:26,484 - 10000 samples (128 per mini-batch)
2018-10-21 07:44:27,686 - Epoch: [262][   50/   78]    Loss 1.549044    Top1 91.281250    Top5 99.593750    
2018-10-21 07:44:28,328 - ==> Top1: 91.400    Top5: 99.610    Loss: 1.548

2018-10-21 07:44:28,330 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:44:28,330 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:44:28,343 - 

2018-10-21 07:44:28,343 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:44:30,070 - Epoch: [263][   50/  391]    Overall Loss 1.485271    Objective Loss 1.485271    Top1 97.906250    Top5 99.781250    LR 0.001500    Time 0.034478    
2018-10-21 07:44:31,629 - Epoch: [263][  100/  391]    Overall Loss 1.486372    Objective Loss 1.486372    Top1 97.843750    Top5 99.742188    LR 0.001500    Time 0.032804    
2018-10-21 07:44:33,210 - Epoch: [263][  150/  391]    Overall Loss 1.486895    Objective Loss 1.486895    Top1 97.744792    Top5 99.765625    LR 0.001500    Time 0.032390    
2018-10-21 07:44:34,777 - Epoch: [263][  200/  391]    Overall Loss 1.487225    Objective Loss 1.487225    Top1 97.695312    Top5 99.746094    LR 0.001500    Time 0.032116    
2018-10-21 07:44:36,336 - Epoch: [263][  250/  391]    Overall Loss 1.487211    Objective Loss 1.487211    Top1 97.703125    Top5 99.750000    LR 0.001500    Time 0.031918    
2018-10-21 07:44:38,016 - Epoch: [263][  300/  391]    Overall Loss 1.487395    Objective Loss 1.487395    Top1 97.679688    Top5 99.736979    LR 0.001500    Time 0.032194    
2018-10-21 07:44:39,698 - Epoch: [263][  350/  391]    Overall Loss 1.487751    Objective Loss 1.487751    Top1 97.665179    Top5 99.736607    LR 0.001500    Time 0.032393    
2018-10-21 07:44:41,278 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22090 | -0.00091 |    0.14654 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07805 | -0.00326 |    0.04563 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07620 |  0.00091 |    0.05176 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06584 | -0.00618 |    0.04475 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06295 | -0.00238 |    0.04129 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07750 | -0.00972 |    0.05417 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06802 | -0.00660 |    0.04785 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07910 | -0.00285 |    0.05916 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06808 | -0.00350 |    0.05182 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16266 |  0.00016 |    0.09996 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06192 | -0.00220 |    0.04674 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05482 | -0.00666 |    0.04316 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06611 | -0.00627 |    0.05063 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05293 | -0.00374 |    0.04146 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06298 | -0.00462 |    0.04980 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05867 | -0.00310 |    0.04652 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07591 | -0.00429 |    0.05795 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05652 | -0.00683 |    0.04479 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03989 | -0.00321 |    0.03093 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03504 | -0.00680 |    0.02748 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02019 |  0.00000 |    0.01387 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39998 | -0.00001 |    0.28247 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:44:41,278 - Total sparsity: 0.00

2018-10-21 07:44:41,278 - --- validate (epoch=263)-----------
2018-10-21 07:44:41,278 - 10000 samples (128 per mini-batch)
2018-10-21 07:44:42,499 - Epoch: [263][   50/   78]    Loss 1.549170    Top1 91.375000    Top5 99.640625    
2018-10-21 07:44:43,156 - ==> Top1: 91.430    Top5: 99.650    Loss: 1.548

2018-10-21 07:44:43,158 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:44:43,158 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:44:43,169 - 

2018-10-21 07:44:43,169 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:44:44,858 - Epoch: [264][   50/  391]    Overall Loss 1.490650    Objective Loss 1.490650    Top1 97.328125    Top5 99.796875    LR 0.001500    Time 0.033714    
2018-10-21 07:44:46,461 - Epoch: [264][  100/  391]    Overall Loss 1.490093    Objective Loss 1.490093    Top1 97.414062    Top5 99.750000    LR 0.001500    Time 0.032862    
2018-10-21 07:44:48,066 - Epoch: [264][  150/  391]    Overall Loss 1.489340    Objective Loss 1.489340    Top1 97.479167    Top5 99.692708    LR 0.001500    Time 0.032594    
2018-10-21 07:44:49,659 - Epoch: [264][  200/  391]    Overall Loss 1.488774    Objective Loss 1.488774    Top1 97.527344    Top5 99.726562    LR 0.001500    Time 0.032397    
2018-10-21 07:44:51,282 - Epoch: [264][  250/  391]    Overall Loss 1.489149    Objective Loss 1.489149    Top1 97.509375    Top5 99.740625    LR 0.001500    Time 0.032399    
2018-10-21 07:44:52,862 - Epoch: [264][  300/  391]    Overall Loss 1.488852    Objective Loss 1.488852    Top1 97.533854    Top5 99.723958    LR 0.001500    Time 0.032262    
2018-10-21 07:44:54,457 - Epoch: [264][  350/  391]    Overall Loss 1.488201    Objective Loss 1.488201    Top1 97.604911    Top5 99.732143    LR 0.001500    Time 0.032203    
2018-10-21 07:44:55,880 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22077 | -0.00093 |    0.14652 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07801 | -0.00326 |    0.04561 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07615 |  0.00093 |    0.05173 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06581 | -0.00619 |    0.04472 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06291 | -0.00235 |    0.04126 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07745 | -0.00973 |    0.05412 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06798 | -0.00661 |    0.04783 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07906 | -0.00286 |    0.05912 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06804 | -0.00352 |    0.05179 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16257 |  0.00015 |    0.09993 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06189 | -0.00219 |    0.04672 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05479 | -0.00666 |    0.04314 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06607 | -0.00625 |    0.05060 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05290 | -0.00373 |    0.04143 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06295 | -0.00462 |    0.04978 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05863 | -0.00309 |    0.04650 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07586 | -0.00430 |    0.05791 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05648 | -0.00683 |    0.04476 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03986 | -0.00321 |    0.03091 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03502 | -0.00680 |    0.02747 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02018 |  0.00000 |    0.01386 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39994 | -0.00001 |    0.28245 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:44:55,881 - Total sparsity: 0.00

2018-10-21 07:44:55,881 - --- validate (epoch=264)-----------
2018-10-21 07:44:55,881 - 10000 samples (128 per mini-batch)
2018-10-21 07:44:57,114 - Epoch: [264][   50/   78]    Loss 1.549671    Top1 91.203125    Top5 99.625000    
2018-10-21 07:44:57,750 - ==> Top1: 91.320    Top5: 99.610    Loss: 1.549

2018-10-21 07:44:57,751 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:44:57,752 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:44:57,765 - 

2018-10-21 07:44:57,765 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:44:59,509 - Epoch: [265][   50/  391]    Overall Loss 1.488363    Objective Loss 1.488363    Top1 97.578125    Top5 99.703125    LR 0.001500    Time 0.034824    
2018-10-21 07:45:01,081 - Epoch: [265][  100/  391]    Overall Loss 1.488195    Objective Loss 1.488195    Top1 97.648438    Top5 99.687500    LR 0.001500    Time 0.033114    
2018-10-21 07:45:02,629 - Epoch: [265][  150/  391]    Overall Loss 1.486611    Objective Loss 1.486611    Top1 97.828125    Top5 99.739583    LR 0.001500    Time 0.032381    
2018-10-21 07:45:04,193 - Epoch: [265][  200/  391]    Overall Loss 1.486756    Objective Loss 1.486756    Top1 97.808594    Top5 99.746094    LR 0.001500    Time 0.032093    
2018-10-21 07:45:05,787 - Epoch: [265][  250/  391]    Overall Loss 1.487399    Objective Loss 1.487399    Top1 97.737500    Top5 99.753125    LR 0.001500    Time 0.032042    
2018-10-21 07:45:07,325 - Epoch: [265][  300/  391]    Overall Loss 1.486824    Objective Loss 1.486824    Top1 97.791667    Top5 99.742188    LR 0.001500    Time 0.031819    
2018-10-21 07:45:08,874 - Epoch: [265][  350/  391]    Overall Loss 1.486906    Objective Loss 1.486906    Top1 97.772321    Top5 99.729911    LR 0.001500    Time 0.031694    
2018-10-21 07:45:10,276 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22065 | -0.00100 |    0.14644 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07796 | -0.00325 |    0.04558 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07611 |  0.00095 |    0.05171 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06577 | -0.00619 |    0.04470 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06288 | -0.00234 |    0.04125 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07741 | -0.00973 |    0.05408 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06795 | -0.00659 |    0.04780 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07901 | -0.00287 |    0.05908 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06800 | -0.00352 |    0.05176 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16247 |  0.00021 |    0.09992 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06185 | -0.00218 |    0.04669 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05476 | -0.00667 |    0.04312 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06604 | -0.00624 |    0.05059 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05287 | -0.00373 |    0.04141 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06291 | -0.00462 |    0.04975 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05860 | -0.00309 |    0.04647 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07582 | -0.00429 |    0.05789 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05645 | -0.00682 |    0.04474 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03984 | -0.00321 |    0.03089 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03500 | -0.00681 |    0.02746 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02017 |  0.00000 |    0.01385 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39989 | -0.00001 |    0.28242 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:45:10,277 - Total sparsity: 0.00

2018-10-21 07:45:10,277 - --- validate (epoch=265)-----------
2018-10-21 07:45:10,277 - 10000 samples (128 per mini-batch)
2018-10-21 07:45:11,499 - Epoch: [265][   50/   78]    Loss 1.549561    Top1 91.375000    Top5 99.578125    
2018-10-21 07:45:12,130 - ==> Top1: 91.480    Top5: 99.600    Loss: 1.549

2018-10-21 07:45:12,131 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:45:12,131 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:45:12,144 - 

2018-10-21 07:45:12,144 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:45:13,854 - Epoch: [266][   50/  391]    Overall Loss 1.486089    Objective Loss 1.486089    Top1 97.781250    Top5 99.765625    LR 0.001500    Time 0.034140    
2018-10-21 07:45:15,443 - Epoch: [266][  100/  391]    Overall Loss 1.486888    Objective Loss 1.486888    Top1 97.765625    Top5 99.718750    LR 0.001500    Time 0.032938    
2018-10-21 07:45:17,024 - Epoch: [266][  150/  391]    Overall Loss 1.487259    Objective Loss 1.487259    Top1 97.723958    Top5 99.755208    LR 0.001500    Time 0.032482    
2018-10-21 07:45:18,614 - Epoch: [266][  200/  391]    Overall Loss 1.487122    Objective Loss 1.487122    Top1 97.714844    Top5 99.769531    LR 0.001500    Time 0.032299    
2018-10-21 07:45:20,209 - Epoch: [266][  250/  391]    Overall Loss 1.487915    Objective Loss 1.487915    Top1 97.631250    Top5 99.750000    LR 0.001500    Time 0.032213    
2018-10-21 07:45:21,759 - Epoch: [266][  300/  391]    Overall Loss 1.487723    Objective Loss 1.487723    Top1 97.645833    Top5 99.723958    LR 0.001500    Time 0.032003    
2018-10-21 07:45:23,371 - Epoch: [266][  350/  391]    Overall Loss 1.487750    Objective Loss 1.487750    Top1 97.654018    Top5 99.720982    LR 0.001500    Time 0.032029    
2018-10-21 07:45:24,827 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22052 | -0.00105 |    0.14637 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07792 | -0.00326 |    0.04556 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07607 |  0.00092 |    0.05167 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06573 | -0.00620 |    0.04467 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06284 | -0.00235 |    0.04123 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07736 | -0.00976 |    0.05406 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06791 | -0.00659 |    0.04777 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07897 | -0.00289 |    0.05905 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06796 | -0.00348 |    0.05173 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16238 |  0.00022 |    0.09983 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06182 | -0.00218 |    0.04667 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05473 | -0.00665 |    0.04309 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06600 | -0.00624 |    0.05055 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05285 | -0.00371 |    0.04138 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06288 | -0.00462 |    0.04972 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05857 | -0.00308 |    0.04645 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07577 | -0.00429 |    0.05785 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05642 | -0.00681 |    0.04471 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03982 | -0.00320 |    0.03087 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03498 | -0.00680 |    0.02744 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02016 | -0.00000 |    0.01385 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39986 | -0.00001 |    0.28240 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:45:24,827 - Total sparsity: 0.00

2018-10-21 07:45:24,827 - --- validate (epoch=266)-----------
2018-10-21 07:45:24,827 - 10000 samples (128 per mini-batch)
2018-10-21 07:45:26,001 - Epoch: [266][   50/   78]    Loss 1.549246    Top1 91.250000    Top5 99.593750    
2018-10-21 07:45:26,628 - ==> Top1: 91.150    Top5: 99.610    Loss: 1.550

2018-10-21 07:45:26,630 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:45:26,630 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:45:26,643 - 

2018-10-21 07:45:26,644 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:45:28,331 - Epoch: [267][   50/  391]    Overall Loss 1.487669    Objective Loss 1.487669    Top1 97.609375    Top5 99.718750    LR 0.001500    Time 0.033697    
2018-10-21 07:45:29,867 - Epoch: [267][  100/  391]    Overall Loss 1.487828    Objective Loss 1.487828    Top1 97.617188    Top5 99.757812    LR 0.001500    Time 0.032184    
2018-10-21 07:45:31,453 - Epoch: [267][  150/  391]    Overall Loss 1.489121    Objective Loss 1.489121    Top1 97.489583    Top5 99.744792    LR 0.001500    Time 0.032009    
2018-10-21 07:45:33,102 - Epoch: [267][  200/  391]    Overall Loss 1.489261    Objective Loss 1.489261    Top1 97.480469    Top5 99.699219    LR 0.001500    Time 0.032246    
2018-10-21 07:45:34,749 - Epoch: [267][  250/  391]    Overall Loss 1.489073    Objective Loss 1.489073    Top1 97.484375    Top5 99.721875    LR 0.001500    Time 0.032373    
2018-10-21 07:45:36,372 - Epoch: [267][  300/  391]    Overall Loss 1.488599    Objective Loss 1.488599    Top1 97.539062    Top5 99.731771    LR 0.001500    Time 0.032381    
2018-10-21 07:45:38,034 - Epoch: [267][  350/  391]    Overall Loss 1.488427    Objective Loss 1.488427    Top1 97.551339    Top5 99.736607    LR 0.001500    Time 0.032496    
2018-10-21 07:45:39,471 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22040 | -0.00084 |    0.14627 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07787 | -0.00324 |    0.04553 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07603 |  0.00092 |    0.05164 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06569 | -0.00621 |    0.04465 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06281 | -0.00236 |    0.04121 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07732 | -0.00977 |    0.05403 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06787 | -0.00654 |    0.04775 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07892 | -0.00289 |    0.05902 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06792 | -0.00348 |    0.05170 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16229 |  0.00015 |    0.09981 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06178 | -0.00217 |    0.04664 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05470 | -0.00665 |    0.04307 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06596 | -0.00625 |    0.05052 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05282 | -0.00371 |    0.04137 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06284 | -0.00463 |    0.04969 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05853 | -0.00308 |    0.04642 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07573 | -0.00429 |    0.05782 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05639 | -0.00679 |    0.04469 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03980 | -0.00319 |    0.03086 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03496 | -0.00681 |    0.02743 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02015 | -0.00001 |    0.01384 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39981 | -0.00001 |    0.28236 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:45:39,472 - Total sparsity: 0.00

2018-10-21 07:45:39,472 - --- validate (epoch=267)-----------
2018-10-21 07:45:39,472 - 10000 samples (128 per mini-batch)
2018-10-21 07:45:40,669 - Epoch: [267][   50/   78]    Loss 1.550125    Top1 91.171875    Top5 99.640625    
2018-10-21 07:45:41,305 - ==> Top1: 91.250    Top5: 99.620    Loss: 1.549

2018-10-21 07:45:41,307 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:45:41,307 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:45:41,320 - 

2018-10-21 07:45:41,320 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:45:42,968 - Epoch: [268][   50/  391]    Overall Loss 1.486327    Objective Loss 1.486327    Top1 97.875000    Top5 99.781250    LR 0.001500    Time 0.032892    
2018-10-21 07:45:44,570 - Epoch: [268][  100/  391]    Overall Loss 1.485914    Objective Loss 1.485914    Top1 97.875000    Top5 99.804688    LR 0.001500    Time 0.032445    
2018-10-21 07:45:46,191 - Epoch: [268][  150/  391]    Overall Loss 1.486547    Objective Loss 1.486547    Top1 97.817708    Top5 99.781250    LR 0.001500    Time 0.032421    
2018-10-21 07:45:47,797 - Epoch: [268][  200/  391]    Overall Loss 1.486960    Objective Loss 1.486960    Top1 97.753906    Top5 99.773438    LR 0.001500    Time 0.032338    
2018-10-21 07:45:49,389 - Epoch: [268][  250/  391]    Overall Loss 1.487015    Objective Loss 1.487015    Top1 97.746875    Top5 99.743750    LR 0.001500    Time 0.032228    
2018-10-21 07:45:50,971 - Epoch: [268][  300/  391]    Overall Loss 1.487190    Objective Loss 1.487190    Top1 97.721354    Top5 99.739583    LR 0.001500    Time 0.032123    
2018-10-21 07:45:52,553 - Epoch: [268][  350/  391]    Overall Loss 1.487529    Objective Loss 1.487529    Top1 97.698661    Top5 99.723214    LR 0.001500    Time 0.032046    
2018-10-21 07:45:53,983 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22027 | -0.00087 |    0.14619 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07783 | -0.00328 |    0.04549 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07598 |  0.00089 |    0.05162 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06565 | -0.00623 |    0.04462 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06277 | -0.00238 |    0.04119 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07727 | -0.00981 |    0.05400 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06783 | -0.00654 |    0.04771 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07888 | -0.00287 |    0.05898 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06789 | -0.00344 |    0.05167 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16220 |  0.00012 |    0.09974 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06175 | -0.00216 |    0.04661 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05466 | -0.00664 |    0.04305 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06593 | -0.00623 |    0.05049 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05278 | -0.00372 |    0.04134 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06280 | -0.00462 |    0.04966 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05850 | -0.00307 |    0.04639 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07569 | -0.00429 |    0.05779 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05636 | -0.00678 |    0.04466 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03978 | -0.00319 |    0.03084 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03494 | -0.00682 |    0.02741 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02013 | -0.00001 |    0.01384 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39977 | -0.00001 |    0.28234 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:45:53,983 - Total sparsity: 0.00

2018-10-21 07:45:53,984 - --- validate (epoch=268)-----------
2018-10-21 07:45:53,984 - 10000 samples (128 per mini-batch)
2018-10-21 07:45:55,338 - Epoch: [268][   50/   78]    Loss 1.550060    Top1 91.359375    Top5 99.593750    
2018-10-21 07:45:56,021 - ==> Top1: 91.360    Top5: 99.620    Loss: 1.549

2018-10-21 07:45:56,023 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:45:56,023 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:45:56,036 - 

2018-10-21 07:45:56,036 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:45:57,829 - Epoch: [269][   50/  391]    Overall Loss 1.489146    Objective Loss 1.489146    Top1 97.437500    Top5 99.656250    LR 0.001500    Time 0.035789    
2018-10-21 07:45:59,530 - Epoch: [269][  100/  391]    Overall Loss 1.487123    Objective Loss 1.487123    Top1 97.687500    Top5 99.640625    LR 0.001500    Time 0.034884    
2018-10-21 07:46:01,319 - Epoch: [269][  150/  391]    Overall Loss 1.486994    Objective Loss 1.486994    Top1 97.697917    Top5 99.687500    LR 0.001500    Time 0.035164    
2018-10-21 07:46:02,998 - Epoch: [269][  200/  391]    Overall Loss 1.487173    Objective Loss 1.487173    Top1 97.675781    Top5 99.687500    LR 0.001500    Time 0.034756    
2018-10-21 07:46:04,623 - Epoch: [269][  250/  391]    Overall Loss 1.486954    Objective Loss 1.486954    Top1 97.706250    Top5 99.700000    LR 0.001500    Time 0.034297    
2018-10-21 07:46:06,261 - Epoch: [269][  300/  391]    Overall Loss 1.487189    Objective Loss 1.487189    Top1 97.669271    Top5 99.687500    LR 0.001500    Time 0.034034    
2018-10-21 07:46:07,822 - Epoch: [269][  350/  391]    Overall Loss 1.487637    Objective Loss 1.487637    Top1 97.625000    Top5 99.687500    LR 0.001500    Time 0.033626    
2018-10-21 07:46:09,209 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22015 | -0.00090 |    0.14609 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07779 | -0.00325 |    0.04548 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07594 |  0.00090 |    0.05158 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06561 | -0.00625 |    0.04460 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06273 | -0.00241 |    0.04116 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07722 | -0.00980 |    0.05396 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06780 | -0.00654 |    0.04769 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07883 | -0.00286 |    0.05895 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06785 | -0.00346 |    0.05164 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16210 |  0.00016 |    0.09963 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06171 | -0.00217 |    0.04659 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05463 | -0.00665 |    0.04302 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06589 | -0.00623 |    0.05046 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05276 | -0.00372 |    0.04131 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06277 | -0.00462 |    0.04964 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05847 | -0.00307 |    0.04637 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07564 | -0.00429 |    0.05776 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05633 | -0.00678 |    0.04464 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03975 | -0.00319 |    0.03082 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03492 | -0.00682 |    0.02740 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02012 | -0.00001 |    0.01383 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39971 | -0.00001 |    0.28230 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:46:09,210 - Total sparsity: 0.00

2018-10-21 07:46:09,210 - --- validate (epoch=269)-----------
2018-10-21 07:46:09,210 - 10000 samples (128 per mini-batch)
2018-10-21 07:46:10,436 - Epoch: [269][   50/   78]    Loss 1.549984    Top1 91.234375    Top5 99.640625    
2018-10-21 07:46:11,084 - ==> Top1: 91.220    Top5: 99.640    Loss: 1.550

2018-10-21 07:46:11,086 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:46:11,086 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:46:11,099 - 

2018-10-21 07:46:11,099 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:46:12,851 - Epoch: [270][   50/  391]    Overall Loss 1.487910    Objective Loss 1.487910    Top1 97.625000    Top5 99.750000    LR 0.001500    Time 0.034973    
2018-10-21 07:46:14,497 - Epoch: [270][  100/  391]    Overall Loss 1.487717    Objective Loss 1.487717    Top1 97.671875    Top5 99.734375    LR 0.001500    Time 0.033927    
2018-10-21 07:46:16,107 - Epoch: [270][  150/  391]    Overall Loss 1.486892    Objective Loss 1.486892    Top1 97.781250    Top5 99.770833    LR 0.001500    Time 0.033338    
2018-10-21 07:46:17,692 - Epoch: [270][  200/  391]    Overall Loss 1.487090    Objective Loss 1.487090    Top1 97.738281    Top5 99.753906    LR 0.001500    Time 0.032916    
2018-10-21 07:46:19,268 - Epoch: [270][  250/  391]    Overall Loss 1.487296    Objective Loss 1.487296    Top1 97.721875    Top5 99.743750    LR 0.001500    Time 0.032629    
2018-10-21 07:46:20,818 - Epoch: [270][  300/  391]    Overall Loss 1.487876    Objective Loss 1.487876    Top1 97.656250    Top5 99.739583    LR 0.001500    Time 0.032348    
2018-10-21 07:46:22,393 - Epoch: [270][  350/  391]    Overall Loss 1.487950    Objective Loss 1.487950    Top1 97.651786    Top5 99.736607    LR 0.001500    Time 0.032223    
2018-10-21 07:46:23,840 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22002 | -0.00093 |    0.14601 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07774 | -0.00324 |    0.04545 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07590 |  0.00088 |    0.05155 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06558 | -0.00624 |    0.04458 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06270 | -0.00239 |    0.04114 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07718 | -0.00978 |    0.05393 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06775 | -0.00657 |    0.04765 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07879 | -0.00287 |    0.05892 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06781 | -0.00345 |    0.05161 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16201 |  0.00013 |    0.09959 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06168 | -0.00217 |    0.04657 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05460 | -0.00664 |    0.04300 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06585 | -0.00622 |    0.05043 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05273 | -0.00371 |    0.04129 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06273 | -0.00462 |    0.04961 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05844 | -0.00307 |    0.04634 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07560 | -0.00428 |    0.05772 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05630 | -0.00678 |    0.04461 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03973 | -0.00319 |    0.03081 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03490 | -0.00682 |    0.02738 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02011 | -0.00001 |    0.01382 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39967 | -0.00001 |    0.28227 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:46:23,841 - Total sparsity: 0.00

2018-10-21 07:46:23,841 - --- validate (epoch=270)-----------
2018-10-21 07:46:23,841 - 10000 samples (128 per mini-batch)
2018-10-21 07:46:25,255 - Epoch: [270][   50/   78]    Loss 1.550856    Top1 91.125000    Top5 99.593750    
2018-10-21 07:46:25,992 - ==> Top1: 91.250    Top5: 99.570    Loss: 1.549

2018-10-21 07:46:25,994 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:46:25,994 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:46:26,007 - 

2018-10-21 07:46:26,007 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:46:27,830 - Epoch: [271][   50/  391]    Overall Loss 1.489345    Objective Loss 1.489345    Top1 97.500000    Top5 99.718750    LR 0.001500    Time 0.036394    
2018-10-21 07:46:29,426 - Epoch: [271][  100/  391]    Overall Loss 1.487107    Objective Loss 1.487107    Top1 97.679688    Top5 99.734375    LR 0.001500    Time 0.034130    
2018-10-21 07:46:30,978 - Epoch: [271][  150/  391]    Overall Loss 1.486542    Objective Loss 1.486542    Top1 97.750000    Top5 99.718750    LR 0.001500    Time 0.033088    
2018-10-21 07:46:32,535 - Epoch: [271][  200/  391]    Overall Loss 1.486745    Objective Loss 1.486745    Top1 97.746094    Top5 99.707031    LR 0.001500    Time 0.032588    
2018-10-21 07:46:34,120 - Epoch: [271][  250/  391]    Overall Loss 1.486835    Objective Loss 1.486835    Top1 97.731250    Top5 99.700000    LR 0.001500    Time 0.032401    
2018-10-21 07:46:35,680 - Epoch: [271][  300/  391]    Overall Loss 1.486864    Objective Loss 1.486864    Top1 97.736979    Top5 99.684896    LR 0.001500    Time 0.032194    
2018-10-21 07:46:37,189 - Epoch: [271][  350/  391]    Overall Loss 1.487123    Objective Loss 1.487123    Top1 97.707589    Top5 99.700893    LR 0.001500    Time 0.031900    
2018-10-21 07:46:38,750 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21990 | -0.00088 |    0.14592 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07770 | -0.00324 |    0.04542 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07585 |  0.00089 |    0.05153 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06554 | -0.00623 |    0.04455 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06266 | -0.00240 |    0.04113 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07713 | -0.00982 |    0.05390 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06772 | -0.00655 |    0.04762 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07874 | -0.00286 |    0.05888 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06777 | -0.00344 |    0.05157 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16192 |  0.00013 |    0.09952 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06165 | -0.00215 |    0.04654 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05457 | -0.00662 |    0.04297 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06582 | -0.00621 |    0.05041 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05270 | -0.00370 |    0.04127 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06270 | -0.00462 |    0.04958 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05840 | -0.00306 |    0.04631 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07556 | -0.00428 |    0.05768 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05627 | -0.00677 |    0.04459 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03971 | -0.00319 |    0.03079 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03488 | -0.00682 |    0.02737 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02010 | -0.00002 |    0.01381 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39963 | -0.00001 |    0.28223 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:46:38,750 - Total sparsity: 0.00

2018-10-21 07:46:38,751 - --- validate (epoch=271)-----------
2018-10-21 07:46:38,751 - 10000 samples (128 per mini-batch)
2018-10-21 07:46:39,960 - Epoch: [271][   50/   78]    Loss 1.550517    Top1 91.281250    Top5 99.625000    
2018-10-21 07:46:40,613 - ==> Top1: 91.330    Top5: 99.610    Loss: 1.550

2018-10-21 07:46:40,614 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:46:40,615 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:46:40,627 - 

2018-10-21 07:46:40,628 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:46:42,401 - Epoch: [272][   50/  391]    Overall Loss 1.487071    Objective Loss 1.487071    Top1 97.796875    Top5 99.859375    LR 0.001500    Time 0.035409    
2018-10-21 07:46:43,990 - Epoch: [272][  100/  391]    Overall Loss 1.488615    Objective Loss 1.488615    Top1 97.531250    Top5 99.742188    LR 0.001500    Time 0.033568    
2018-10-21 07:46:45,608 - Epoch: [272][  150/  391]    Overall Loss 1.488790    Objective Loss 1.488790    Top1 97.515625    Top5 99.734375    LR 0.001500    Time 0.033150    
2018-10-21 07:46:47,210 - Epoch: [272][  200/  391]    Overall Loss 1.488101    Objective Loss 1.488101    Top1 97.593750    Top5 99.730469    LR 0.001500    Time 0.032863    
2018-10-21 07:46:48,781 - Epoch: [272][  250/  391]    Overall Loss 1.487928    Objective Loss 1.487928    Top1 97.612500    Top5 99.728125    LR 0.001500    Time 0.032564    
2018-10-21 07:46:50,458 - Epoch: [272][  300/  391]    Overall Loss 1.487532    Objective Loss 1.487532    Top1 97.651042    Top5 99.750000    LR 0.001500    Time 0.032720    
2018-10-21 07:46:52,043 - Epoch: [272][  350/  391]    Overall Loss 1.487657    Objective Loss 1.487657    Top1 97.640625    Top5 99.738839    LR 0.001500    Time 0.032567    
2018-10-21 07:46:53,478 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21978 | -0.00052 |    0.14580 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07765 | -0.00321 |    0.04540 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07581 |  0.00089 |    0.05151 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06551 | -0.00621 |    0.04452 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06263 | -0.00238 |    0.04110 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07709 | -0.00980 |    0.05386 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06768 | -0.00655 |    0.04760 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07870 | -0.00284 |    0.05885 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06773 | -0.00344 |    0.05154 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16183 |  0.00014 |    0.09948 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06161 | -0.00214 |    0.04651 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05454 | -0.00662 |    0.04295 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06578 | -0.00619 |    0.05038 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05267 | -0.00369 |    0.04125 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06266 | -0.00461 |    0.04955 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05837 | -0.00306 |    0.04629 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07551 | -0.00428 |    0.05766 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05623 | -0.00677 |    0.04456 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03969 | -0.00318 |    0.03078 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03486 | -0.00682 |    0.02735 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02009 | -0.00001 |    0.01381 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39958 | -0.00001 |    0.28221 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:46:53,478 - Total sparsity: 0.00

2018-10-21 07:46:53,478 - --- validate (epoch=272)-----------
2018-10-21 07:46:53,478 - 10000 samples (128 per mini-batch)
2018-10-21 07:46:54,716 - Epoch: [272][   50/   78]    Loss 1.549855    Top1 91.406250    Top5 99.625000    
2018-10-21 07:46:55,378 - ==> Top1: 91.460    Top5: 99.630    Loss: 1.549

2018-10-21 07:46:55,379 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:46:55,379 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:46:55,392 - 

2018-10-21 07:46:55,392 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:46:57,130 - Epoch: [273][   50/  391]    Overall Loss 1.486011    Objective Loss 1.486011    Top1 97.812500    Top5 99.765625    LR 0.001500    Time 0.034699    
2018-10-21 07:46:58,719 - Epoch: [273][  100/  391]    Overall Loss 1.487178    Objective Loss 1.487178    Top1 97.679688    Top5 99.750000    LR 0.001500    Time 0.033215    
2018-10-21 07:47:00,295 - Epoch: [273][  150/  391]    Overall Loss 1.487399    Objective Loss 1.487399    Top1 97.661458    Top5 99.739583    LR 0.001500    Time 0.032631    
2018-10-21 07:47:01,861 - Epoch: [273][  200/  391]    Overall Loss 1.486390    Objective Loss 1.486390    Top1 97.765625    Top5 99.769531    LR 0.001500    Time 0.032296    
2018-10-21 07:47:03,443 - Epoch: [273][  250/  391]    Overall Loss 1.486351    Objective Loss 1.486351    Top1 97.762500    Top5 99.762500    LR 0.001500    Time 0.032154    
2018-10-21 07:47:05,020 - Epoch: [273][  300/  391]    Overall Loss 1.486621    Objective Loss 1.486621    Top1 97.755208    Top5 99.760417    LR 0.001500    Time 0.032045    
2018-10-21 07:47:06,630 - Epoch: [273][  350/  391]    Overall Loss 1.487133    Objective Loss 1.487133    Top1 97.700893    Top5 99.741071    LR 0.001500    Time 0.032062    
2018-10-21 07:47:08,054 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21965 | -0.00066 |    0.14579 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07761 | -0.00323 |    0.04537 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07577 |  0.00090 |    0.05148 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06547 | -0.00623 |    0.04450 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06259 | -0.00238 |    0.04108 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07705 | -0.00976 |    0.05385 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06764 | -0.00659 |    0.04757 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07866 | -0.00283 |    0.05882 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06769 | -0.00345 |    0.05151 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16174 |  0.00009 |    0.09943 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06158 | -0.00214 |    0.04649 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05451 | -0.00662 |    0.04292 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06574 | -0.00618 |    0.05035 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05264 | -0.00369 |    0.04122 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06263 | -0.00461 |    0.04952 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05834 | -0.00306 |    0.04626 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07547 | -0.00428 |    0.05762 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05620 | -0.00676 |    0.04454 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03967 | -0.00318 |    0.03076 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03484 | -0.00682 |    0.02734 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02008 | -0.00001 |    0.01380 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39953 | -0.00001 |    0.28218 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:47:08,055 - Total sparsity: 0.00

2018-10-21 07:47:08,055 - --- validate (epoch=273)-----------
2018-10-21 07:47:08,055 - 10000 samples (128 per mini-batch)
2018-10-21 07:47:09,327 - Epoch: [273][   50/   78]    Loss 1.549457    Top1 91.328125    Top5 99.625000    
2018-10-21 07:47:10,016 - ==> Top1: 91.470    Top5: 99.620    Loss: 1.548

2018-10-21 07:47:10,017 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:47:10,017 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:47:10,030 - 

2018-10-21 07:47:10,030 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:47:11,866 - Epoch: [274][   50/  391]    Overall Loss 1.488931    Objective Loss 1.488931    Top1 97.531250    Top5 99.718750    LR 0.001500    Time 0.036642    
2018-10-21 07:47:13,552 - Epoch: [274][  100/  391]    Overall Loss 1.488093    Objective Loss 1.488093    Top1 97.609375    Top5 99.781250    LR 0.001500    Time 0.035149    
2018-10-21 07:47:15,091 - Epoch: [274][  150/  391]    Overall Loss 1.487237    Objective Loss 1.487237    Top1 97.703125    Top5 99.781250    LR 0.001500    Time 0.033679    
2018-10-21 07:47:16,621 - Epoch: [274][  200/  391]    Overall Loss 1.487652    Objective Loss 1.487652    Top1 97.664062    Top5 99.742188    LR 0.001500    Time 0.032899    
2018-10-21 07:47:18,191 - Epoch: [274][  250/  391]    Overall Loss 1.487261    Objective Loss 1.487261    Top1 97.690625    Top5 99.765625    LR 0.001500    Time 0.032589    
2018-10-21 07:47:19,718 - Epoch: [274][  300/  391]    Overall Loss 1.487002    Objective Loss 1.487002    Top1 97.708333    Top5 99.744792    LR 0.001500    Time 0.032241    
2018-10-21 07:47:21,225 - Epoch: [274][  350/  391]    Overall Loss 1.487237    Objective Loss 1.487237    Top1 97.696429    Top5 99.761161    LR 0.001500    Time 0.031937    
2018-10-21 07:47:22,593 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21953 | -0.00062 |    0.14574 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07757 | -0.00323 |    0.04536 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07573 |  0.00087 |    0.05145 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06543 | -0.00623 |    0.04447 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06256 | -0.00240 |    0.04106 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07701 | -0.00970 |    0.05382 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06760 | -0.00657 |    0.04756 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07861 | -0.00279 |    0.05878 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06766 | -0.00345 |    0.05148 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16164 |  0.00009 |    0.09938 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06154 | -0.00215 |    0.04646 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05448 | -0.00662 |    0.04290 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06571 | -0.00616 |    0.05033 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05261 | -0.00369 |    0.04120 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06259 | -0.00460 |    0.04949 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05830 | -0.00306 |    0.04624 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07543 | -0.00427 |    0.05759 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05617 | -0.00675 |    0.04452 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03964 | -0.00319 |    0.03074 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03482 | -0.00682 |    0.02732 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02007 | -0.00002 |    0.01379 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39949 | -0.00001 |    0.28215 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:47:22,593 - Total sparsity: 0.00

2018-10-21 07:47:22,593 - --- validate (epoch=274)-----------
2018-10-21 07:47:22,593 - 10000 samples (128 per mini-batch)
2018-10-21 07:47:23,941 - Epoch: [274][   50/   78]    Loss 1.550464    Top1 91.234375    Top5 99.625000    
2018-10-21 07:47:24,710 - ==> Top1: 91.310    Top5: 99.620    Loss: 1.549

2018-10-21 07:47:24,712 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:47:24,712 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:47:24,731 - 

2018-10-21 07:47:24,732 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:47:26,552 - Epoch: [275][   50/  391]    Overall Loss 1.484982    Objective Loss 1.484982    Top1 97.953125    Top5 99.781250    LR 0.001500    Time 0.036346    
2018-10-21 07:47:28,137 - Epoch: [275][  100/  391]    Overall Loss 1.485614    Objective Loss 1.485614    Top1 97.875000    Top5 99.781250    LR 0.001500    Time 0.034001    
2018-10-21 07:47:29,722 - Epoch: [275][  150/  391]    Overall Loss 1.486425    Objective Loss 1.486425    Top1 97.822917    Top5 99.729167    LR 0.001500    Time 0.033218    
2018-10-21 07:47:31,269 - Epoch: [275][  200/  391]    Overall Loss 1.486394    Objective Loss 1.486394    Top1 97.800781    Top5 99.722656    LR 0.001500    Time 0.032636    
2018-10-21 07:47:32,879 - Epoch: [275][  250/  391]    Overall Loss 1.486273    Objective Loss 1.486273    Top1 97.806250    Top5 99.721875    LR 0.001500    Time 0.032540    
2018-10-21 07:47:34,491 - Epoch: [275][  300/  391]    Overall Loss 1.485978    Objective Loss 1.485978    Top1 97.833333    Top5 99.739583    LR 0.001500    Time 0.032482    
2018-10-21 07:47:36,070 - Epoch: [275][  350/  391]    Overall Loss 1.486079    Objective Loss 1.486079    Top1 97.830357    Top5 99.732143    LR 0.001500    Time 0.032346    
2018-10-21 07:47:37,461 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21940 | -0.00043 |    0.14556 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07752 | -0.00323 |    0.04534 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07568 |  0.00088 |    0.05143 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06539 | -0.00624 |    0.04444 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06252 | -0.00240 |    0.04104 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07697 | -0.00969 |    0.05380 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06756 | -0.00657 |    0.04754 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07857 | -0.00279 |    0.05873 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06762 | -0.00344 |    0.05145 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16155 |  0.00010 |    0.09934 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06151 | -0.00216 |    0.04643 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05445 | -0.00660 |    0.04288 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06567 | -0.00616 |    0.05030 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05258 | -0.00368 |    0.04117 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06255 | -0.00460 |    0.04946 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05827 | -0.00305 |    0.04621 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07539 | -0.00425 |    0.05756 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05614 | -0.00675 |    0.04449 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03962 | -0.00319 |    0.03072 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03480 | -0.00682 |    0.02731 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02005 | -0.00002 |    0.01378 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39945 | -0.00001 |    0.28212 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:47:37,461 - Total sparsity: 0.00

2018-10-21 07:47:37,461 - --- validate (epoch=275)-----------
2018-10-21 07:47:37,462 - 10000 samples (128 per mini-batch)
2018-10-21 07:47:38,874 - Epoch: [275][   50/   78]    Loss 1.551052    Top1 91.156250    Top5 99.593750    
2018-10-21 07:47:39,654 - ==> Top1: 91.310    Top5: 99.600    Loss: 1.549

2018-10-21 07:47:39,655 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:47:39,656 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:47:39,668 - 

2018-10-21 07:47:39,669 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:47:41,439 - Epoch: [276][   50/  391]    Overall Loss 1.486352    Objective Loss 1.486352    Top1 97.812500    Top5 99.718750    LR 0.001500    Time 0.035344    
2018-10-21 07:47:43,138 - Epoch: [276][  100/  391]    Overall Loss 1.485821    Objective Loss 1.485821    Top1 97.796875    Top5 99.679688    LR 0.001500    Time 0.034644    
2018-10-21 07:47:44,745 - Epoch: [276][  150/  391]    Overall Loss 1.486444    Objective Loss 1.486444    Top1 97.744792    Top5 99.656250    LR 0.001500    Time 0.033793    
2018-10-21 07:47:46,362 - Epoch: [276][  200/  391]    Overall Loss 1.486690    Objective Loss 1.486690    Top1 97.722656    Top5 99.660156    LR 0.001500    Time 0.033418    
2018-10-21 07:47:47,989 - Epoch: [276][  250/  391]    Overall Loss 1.487211    Objective Loss 1.487211    Top1 97.668750    Top5 99.656250    LR 0.001500    Time 0.033234    
2018-10-21 07:47:49,557 - Epoch: [276][  300/  391]    Overall Loss 1.487343    Objective Loss 1.487343    Top1 97.661458    Top5 99.656250    LR 0.001500    Time 0.032912    
2018-10-21 07:47:51,104 - Epoch: [276][  350/  391]    Overall Loss 1.486634    Objective Loss 1.486634    Top1 97.729911    Top5 99.678571    LR 0.001500    Time 0.032624    
2018-10-21 07:47:52,514 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21928 | -0.00070 |    0.14552 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07748 | -0.00322 |    0.04530 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07564 |  0.00090 |    0.05141 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06535 | -0.00626 |    0.04441 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06249 | -0.00238 |    0.04103 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07692 | -0.00971 |    0.05376 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06752 | -0.00656 |    0.04751 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07852 | -0.00279 |    0.05870 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06758 | -0.00343 |    0.05141 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16146 |  0.00005 |    0.09927 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06147 | -0.00215 |    0.04641 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05442 | -0.00659 |    0.04286 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06563 | -0.00616 |    0.05027 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05255 | -0.00368 |    0.04115 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06252 | -0.00461 |    0.04943 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05824 | -0.00306 |    0.04619 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07534 | -0.00424 |    0.05752 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05611 | -0.00675 |    0.04446 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03960 | -0.00319 |    0.03071 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03478 | -0.00682 |    0.02729 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02004 | -0.00002 |    0.01378 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39941 | -0.00001 |    0.28209 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:47:52,515 - Total sparsity: 0.00

2018-10-21 07:47:52,515 - --- validate (epoch=276)-----------
2018-10-21 07:47:52,515 - 10000 samples (128 per mini-batch)
2018-10-21 07:47:53,789 - Epoch: [276][   50/   78]    Loss 1.549159    Top1 91.421875    Top5 99.625000    
2018-10-21 07:47:54,445 - ==> Top1: 91.370    Top5: 99.630    Loss: 1.549

2018-10-21 07:47:54,447 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:47:54,447 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:47:54,460 - 

2018-10-21 07:47:54,461 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:47:56,293 - Epoch: [277][   50/  391]    Overall Loss 1.483907    Objective Loss 1.483907    Top1 98.031250    Top5 99.765625    LR 0.001500    Time 0.036584    
2018-10-21 07:47:57,951 - Epoch: [277][  100/  391]    Overall Loss 1.485905    Objective Loss 1.485905    Top1 97.820312    Top5 99.687500    LR 0.001500    Time 0.034843    
2018-10-21 07:47:59,608 - Epoch: [277][  150/  391]    Overall Loss 1.485739    Objective Loss 1.485739    Top1 97.843750    Top5 99.703125    LR 0.001500    Time 0.034267    
2018-10-21 07:48:01,252 - Epoch: [277][  200/  391]    Overall Loss 1.486249    Objective Loss 1.486249    Top1 97.789062    Top5 99.695312    LR 0.001500    Time 0.033905    
2018-10-21 07:48:02,834 - Epoch: [277][  250/  391]    Overall Loss 1.486432    Objective Loss 1.486432    Top1 97.781250    Top5 99.684375    LR 0.001500    Time 0.033443    
2018-10-21 07:48:04,418 - Epoch: [277][  300/  391]    Overall Loss 1.486448    Objective Loss 1.486448    Top1 97.786458    Top5 99.682292    LR 0.001500    Time 0.033143    
2018-10-21 07:48:05,976 - Epoch: [277][  350/  391]    Overall Loss 1.486343    Objective Loss 1.486343    Top1 97.796875    Top5 99.700893    LR 0.001500    Time 0.032852    
2018-10-21 07:48:07,403 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21915 | -0.00070 |    0.14543 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07743 | -0.00323 |    0.04527 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07560 |  0.00091 |    0.05137 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06532 | -0.00625 |    0.04439 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06245 | -0.00238 |    0.04099 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07689 | -0.00964 |    0.05374 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06749 | -0.00655 |    0.04749 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07848 | -0.00278 |    0.05867 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06754 | -0.00344 |    0.05139 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16137 |  0.00004 |    0.09926 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06144 | -0.00214 |    0.04639 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05439 | -0.00660 |    0.04283 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06560 | -0.00617 |    0.05024 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05252 | -0.00369 |    0.04113 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06248 | -0.00461 |    0.04941 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05821 | -0.00305 |    0.04616 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07530 | -0.00425 |    0.05749 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05608 | -0.00675 |    0.04444 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03958 | -0.00320 |    0.03069 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03476 | -0.00682 |    0.02728 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02003 | -0.00002 |    0.01377 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39936 | -0.00001 |    0.28207 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:48:07,403 - Total sparsity: 0.00

2018-10-21 07:48:07,403 - --- validate (epoch=277)-----------
2018-10-21 07:48:07,403 - 10000 samples (128 per mini-batch)
2018-10-21 07:48:08,652 - Epoch: [277][   50/   78]    Loss 1.549761    Top1 91.265625    Top5 99.656250    
2018-10-21 07:48:09,325 - ==> Top1: 91.360    Top5: 99.650    Loss: 1.549

2018-10-21 07:48:09,327 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:48:09,327 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:48:09,340 - 

2018-10-21 07:48:09,340 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:48:11,148 - Epoch: [278][   50/  391]    Overall Loss 1.486828    Objective Loss 1.486828    Top1 97.703125    Top5 99.656250    LR 0.001500    Time 0.036100    
2018-10-21 07:48:12,856 - Epoch: [278][  100/  391]    Overall Loss 1.485749    Objective Loss 1.485749    Top1 97.765625    Top5 99.742188    LR 0.001500    Time 0.035099    
2018-10-21 07:48:14,497 - Epoch: [278][  150/  391]    Overall Loss 1.486086    Objective Loss 1.486086    Top1 97.750000    Top5 99.723958    LR 0.001500    Time 0.034327    
2018-10-21 07:48:16,072 - Epoch: [278][  200/  391]    Overall Loss 1.485913    Objective Loss 1.485913    Top1 97.800781    Top5 99.730469    LR 0.001500    Time 0.033610    
2018-10-21 07:48:17,628 - Epoch: [278][  250/  391]    Overall Loss 1.486523    Objective Loss 1.486523    Top1 97.734375    Top5 99.700000    LR 0.001500    Time 0.033101    
2018-10-21 07:48:19,185 - Epoch: [278][  300/  391]    Overall Loss 1.486708    Objective Loss 1.486708    Top1 97.731771    Top5 99.695312    LR 0.001500    Time 0.032766    
2018-10-21 07:48:20,723 - Epoch: [278][  350/  391]    Overall Loss 1.486788    Objective Loss 1.486788    Top1 97.736607    Top5 99.707589    LR 0.001500    Time 0.032475    
2018-10-21 07:48:22,127 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21903 | -0.00073 |    0.14530 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07739 | -0.00323 |    0.04525 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07555 |  0.00090 |    0.05134 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06528 | -0.00620 |    0.04436 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06242 | -0.00234 |    0.04096 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07684 | -0.00964 |    0.05370 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06745 | -0.00654 |    0.04746 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07843 | -0.00278 |    0.05864 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06750 | -0.00342 |    0.05136 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16128 |  0.00008 |    0.09918 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06140 | -0.00214 |    0.04637 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05436 | -0.00659 |    0.04281 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06556 | -0.00618 |    0.05021 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05249 | -0.00370 |    0.04110 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06245 | -0.00461 |    0.04938 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05817 | -0.00305 |    0.04613 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07526 | -0.00425 |    0.05746 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05604 | -0.00674 |    0.04442 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03955 | -0.00319 |    0.03068 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03474 | -0.00682 |    0.02726 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02002 | -0.00002 |    0.01376 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39931 | -0.00001 |    0.28204 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:48:22,127 - Total sparsity: 0.00

2018-10-21 07:48:22,128 - --- validate (epoch=278)-----------
2018-10-21 07:48:22,128 - 10000 samples (128 per mini-batch)
2018-10-21 07:48:23,339 - Epoch: [278][   50/   78]    Loss 1.549581    Top1 91.390625    Top5 99.687500    
2018-10-21 07:48:23,998 - ==> Top1: 91.290    Top5: 99.670    Loss: 1.550

2018-10-21 07:48:24,000 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:48:24,000 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:48:24,013 - 

2018-10-21 07:48:24,014 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:48:25,787 - Epoch: [279][   50/  391]    Overall Loss 1.485339    Objective Loss 1.485339    Top1 97.890625    Top5 99.750000    LR 0.001500    Time 0.035400    
2018-10-21 07:48:27,447 - Epoch: [279][  100/  391]    Overall Loss 1.485267    Objective Loss 1.485267    Top1 97.937500    Top5 99.757812    LR 0.001500    Time 0.034281    
2018-10-21 07:48:29,061 - Epoch: [279][  150/  391]    Overall Loss 1.486390    Objective Loss 1.486390    Top1 97.828125    Top5 99.718750    LR 0.001500    Time 0.033599    
2018-10-21 07:48:30,606 - Epoch: [279][  200/  391]    Overall Loss 1.487394    Objective Loss 1.487394    Top1 97.730469    Top5 99.722656    LR 0.001500    Time 0.032913    
2018-10-21 07:48:32,146 - Epoch: [279][  250/  391]    Overall Loss 1.487607    Objective Loss 1.487607    Top1 97.687500    Top5 99.731250    LR 0.001500    Time 0.032479    
2018-10-21 07:48:33,729 - Epoch: [279][  300/  391]    Overall Loss 1.487448    Objective Loss 1.487448    Top1 97.697917    Top5 99.729167    LR 0.001500    Time 0.032338    
2018-10-21 07:48:35,249 - Epoch: [279][  350/  391]    Overall Loss 1.487725    Objective Loss 1.487725    Top1 97.669643    Top5 99.727679    LR 0.001500    Time 0.032055    
2018-10-21 07:48:36,646 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21890 | -0.00063 |    0.14521 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07735 | -0.00322 |    0.04521 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07551 |  0.00091 |    0.05131 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06524 | -0.00622 |    0.04433 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 | -0.00234 |    0.04094 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07680 | -0.00962 |    0.05367 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06741 | -0.00654 |    0.04743 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07839 | -0.00277 |    0.05861 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06746 | -0.00341 |    0.05132 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16118 |  0.00007 |    0.09910 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06137 | -0.00214 |    0.04634 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05433 | -0.00659 |    0.04279 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06552 | -0.00618 |    0.05019 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05246 | -0.00369 |    0.04108 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06241 | -0.00461 |    0.04935 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05814 | -0.00304 |    0.04611 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07521 | -0.00425 |    0.05742 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05601 | -0.00674 |    0.04439 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03953 | -0.00318 |    0.03066 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03472 | -0.00681 |    0.02725 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02001 | -0.00002 |    0.01376 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39927 | -0.00001 |    0.28201 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:48:36,646 - Total sparsity: 0.00

2018-10-21 07:48:36,646 - --- validate (epoch=279)-----------
2018-10-21 07:48:36,646 - 10000 samples (128 per mini-batch)
2018-10-21 07:48:37,810 - Epoch: [279][   50/   78]    Loss 1.549751    Top1 91.359375    Top5 99.609375    
2018-10-21 07:48:38,476 - ==> Top1: 91.310    Top5: 99.580    Loss: 1.549

2018-10-21 07:48:38,478 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:48:38,478 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:48:38,491 - 

2018-10-21 07:48:38,491 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:48:40,169 - Epoch: [280][   50/  391]    Overall Loss 1.485978    Objective Loss 1.485978    Top1 97.781250    Top5 99.796875    LR 0.001500    Time 0.033499    
2018-10-21 07:48:41,735 - Epoch: [280][  100/  391]    Overall Loss 1.486024    Objective Loss 1.486024    Top1 97.812500    Top5 99.765625    LR 0.001500    Time 0.032384    
2018-10-21 07:48:43,305 - Epoch: [280][  150/  391]    Overall Loss 1.486041    Objective Loss 1.486041    Top1 97.802083    Top5 99.770833    LR 0.001500    Time 0.032044    
2018-10-21 07:48:44,902 - Epoch: [280][  200/  391]    Overall Loss 1.486856    Objective Loss 1.486856    Top1 97.726562    Top5 99.750000    LR 0.001500    Time 0.032009    
2018-10-21 07:48:46,462 - Epoch: [280][  250/  391]    Overall Loss 1.486948    Objective Loss 1.486948    Top1 97.715625    Top5 99.753125    LR 0.001500    Time 0.031838    
2018-10-21 07:48:48,040 - Epoch: [280][  300/  391]    Overall Loss 1.486281    Objective Loss 1.486281    Top1 97.809896    Top5 99.773438    LR 0.001500    Time 0.031785    
2018-10-21 07:48:49,594 - Epoch: [280][  350/  391]    Overall Loss 1.486407    Objective Loss 1.486407    Top1 97.794643    Top5 99.761161    LR 0.001500    Time 0.031677    
2018-10-21 07:48:50,992 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21878 | -0.00076 |    0.14514 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07730 | -0.00322 |    0.04519 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07547 |  0.00090 |    0.05129 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06521 | -0.00622 |    0.04431 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06235 | -0.00235 |    0.04092 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07676 | -0.00962 |    0.05363 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06737 | -0.00654 |    0.04740 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07835 | -0.00276 |    0.05858 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06743 | -0.00341 |    0.05130 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16109 |  0.00004 |    0.09905 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06133 | -0.00214 |    0.04631 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05430 | -0.00659 |    0.04276 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06548 | -0.00617 |    0.05016 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05243 | -0.00369 |    0.04106 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 | -0.00460 |    0.04932 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05811 | -0.00303 |    0.04608 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07517 | -0.00425 |    0.05739 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05598 | -0.00673 |    0.04437 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03951 | -0.00318 |    0.03064 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03470 | -0.00681 |    0.02723 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02000 | -0.00002 |    0.01375 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39923 | -0.00001 |    0.28198 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:48:50,992 - Total sparsity: 0.00

2018-10-21 07:48:50,992 - --- validate (epoch=280)-----------
2018-10-21 07:48:50,992 - 10000 samples (128 per mini-batch)
2018-10-21 07:48:52,226 - Epoch: [280][   50/   78]    Loss 1.549223    Top1 91.390625    Top5 99.625000    
2018-10-21 07:48:52,873 - ==> Top1: 91.320    Top5: 99.620    Loss: 1.549

2018-10-21 07:48:52,875 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:48:52,875 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:48:52,888 - 

2018-10-21 07:48:52,888 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:48:54,642 - Epoch: [281][   50/  391]    Overall Loss 1.486460    Objective Loss 1.486460    Top1 97.734375    Top5 99.656250    LR 0.001500    Time 0.035015    
2018-10-21 07:48:56,217 - Epoch: [281][  100/  391]    Overall Loss 1.487269    Objective Loss 1.487269    Top1 97.648438    Top5 99.718750    LR 0.001500    Time 0.033230    
2018-10-21 07:48:57,823 - Epoch: [281][  150/  391]    Overall Loss 1.487252    Objective Loss 1.487252    Top1 97.661458    Top5 99.703125    LR 0.001500    Time 0.032842    
2018-10-21 07:48:59,426 - Epoch: [281][  200/  391]    Overall Loss 1.487301    Objective Loss 1.487301    Top1 97.660156    Top5 99.726562    LR 0.001500    Time 0.032637    
2018-10-21 07:49:00,981 - Epoch: [281][  250/  391]    Overall Loss 1.487494    Objective Loss 1.487494    Top1 97.646875    Top5 99.728125    LR 0.001500    Time 0.032322    
2018-10-21 07:49:02,525 - Epoch: [281][  300/  391]    Overall Loss 1.487192    Objective Loss 1.487192    Top1 97.664062    Top5 99.716146    LR 0.001500    Time 0.032073    
2018-10-21 07:49:04,086 - Epoch: [281][  350/  391]    Overall Loss 1.487106    Objective Loss 1.487106    Top1 97.680804    Top5 99.714286    LR 0.001500    Time 0.031945    
2018-10-21 07:49:05,505 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21866 | -0.00082 |    0.14512 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07726 | -0.00323 |    0.04517 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07543 |  0.00089 |    0.05127 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06517 | -0.00624 |    0.04428 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06231 | -0.00234 |    0.04090 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07671 | -0.00964 |    0.05361 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06733 | -0.00653 |    0.04737 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07830 | -0.00275 |    0.05854 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06739 | -0.00340 |    0.05127 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16100 |  0.00001 |    0.09903 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06130 | -0.00212 |    0.04629 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05427 | -0.00658 |    0.04274 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06545 | -0.00617 |    0.05013 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05240 | -0.00369 |    0.04104 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 | -0.00459 |    0.04930 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05808 | -0.00303 |    0.04606 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07513 | -0.00425 |    0.05736 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05595 | -0.00672 |    0.04434 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03949 | -0.00318 |    0.03062 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03468 | -0.00681 |    0.02722 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01999 | -0.00002 |    0.01374 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39918 | -0.00001 |    0.28195 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:49:05,506 - Total sparsity: 0.00

2018-10-21 07:49:05,506 - --- validate (epoch=281)-----------
2018-10-21 07:49:05,506 - 10000 samples (128 per mini-batch)
2018-10-21 07:49:06,682 - Epoch: [281][   50/   78]    Loss 1.551206    Top1 91.140625    Top5 99.625000    
2018-10-21 07:49:07,332 - ==> Top1: 91.290    Top5: 99.610    Loss: 1.550

2018-10-21 07:49:07,333 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:49:07,333 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:49:07,346 - 

2018-10-21 07:49:07,346 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:49:09,125 - Epoch: [282][   50/  391]    Overall Loss 1.488021    Objective Loss 1.488021    Top1 97.609375    Top5 99.640625    LR 0.001500    Time 0.035516    
2018-10-21 07:49:10,729 - Epoch: [282][  100/  391]    Overall Loss 1.488356    Objective Loss 1.488356    Top1 97.625000    Top5 99.703125    LR 0.001500    Time 0.033771    
2018-10-21 07:49:12,362 - Epoch: [282][  150/  391]    Overall Loss 1.486711    Objective Loss 1.486711    Top1 97.802083    Top5 99.718750    LR 0.001500    Time 0.033385    
2018-10-21 07:49:13,978 - Epoch: [282][  200/  391]    Overall Loss 1.487522    Objective Loss 1.487522    Top1 97.707031    Top5 99.742188    LR 0.001500    Time 0.033104    
2018-10-21 07:49:15,572 - Epoch: [282][  250/  391]    Overall Loss 1.487610    Objective Loss 1.487610    Top1 97.696875    Top5 99.743750    LR 0.001500    Time 0.032852    
2018-10-21 07:49:17,206 - Epoch: [282][  300/  391]    Overall Loss 1.487384    Objective Loss 1.487384    Top1 97.721354    Top5 99.750000    LR 0.001500    Time 0.032818    
2018-10-21 07:49:18,802 - Epoch: [282][  350/  391]    Overall Loss 1.487355    Objective Loss 1.487355    Top1 97.723214    Top5 99.734375    LR 0.001500    Time 0.032682    
2018-10-21 07:49:20,288 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21853 | -0.00057 |    0.14497 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07722 | -0.00321 |    0.04515 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07538 |  0.00090 |    0.05124 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06513 | -0.00622 |    0.04425 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06228 | -0.00232 |    0.04088 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07667 | -0.00966 |    0.05359 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06730 | -0.00651 |    0.04733 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07826 | -0.00272 |    0.05851 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06735 | -0.00341 |    0.05124 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16091 |  0.00001 |    0.09895 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06127 | -0.00211 |    0.04626 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05424 | -0.00658 |    0.04271 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06541 | -0.00617 |    0.05010 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05237 | -0.00370 |    0.04102 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06231 | -0.00458 |    0.04927 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05804 | -0.00302 |    0.04603 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07508 | -0.00424 |    0.05732 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05592 | -0.00672 |    0.04432 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03947 | -0.00317 |    0.03061 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03466 | -0.00681 |    0.02720 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01998 | -0.00002 |    0.01374 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39913 | -0.00001 |    0.28192 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:49:20,288 - Total sparsity: 0.00

2018-10-21 07:49:20,288 - --- validate (epoch=282)-----------
2018-10-21 07:49:20,289 - 10000 samples (128 per mini-batch)
2018-10-21 07:49:21,520 - Epoch: [282][   50/   78]    Loss 1.551154    Top1 91.171875    Top5 99.687500    
2018-10-21 07:49:22,181 - ==> Top1: 91.210    Top5: 99.680    Loss: 1.550

2018-10-21 07:49:22,183 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:49:22,183 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:49:22,196 - 

2018-10-21 07:49:22,196 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:49:23,997 - Epoch: [283][   50/  391]    Overall Loss 1.484754    Objective Loss 1.484754    Top1 97.984375    Top5 99.750000    LR 0.001500    Time 0.035952    
2018-10-21 07:49:25,631 - Epoch: [283][  100/  391]    Overall Loss 1.484927    Objective Loss 1.484927    Top1 97.960938    Top5 99.734375    LR 0.001500    Time 0.034300    
2018-10-21 07:49:27,278 - Epoch: [283][  150/  391]    Overall Loss 1.484729    Objective Loss 1.484729    Top1 97.973958    Top5 99.744792    LR 0.001500    Time 0.033828    
2018-10-21 07:49:28,817 - Epoch: [283][  200/  391]    Overall Loss 1.485375    Objective Loss 1.485375    Top1 97.894531    Top5 99.718750    LR 0.001500    Time 0.033055    
2018-10-21 07:49:30,419 - Epoch: [283][  250/  391]    Overall Loss 1.485666    Objective Loss 1.485666    Top1 97.871875    Top5 99.715625    LR 0.001500    Time 0.032843    
2018-10-21 07:49:31,979 - Epoch: [283][  300/  391]    Overall Loss 1.486152    Objective Loss 1.486152    Top1 97.807292    Top5 99.716146    LR 0.001500    Time 0.032562    
2018-10-21 07:49:33,505 - Epoch: [283][  350/  391]    Overall Loss 1.486480    Objective Loss 1.486480    Top1 97.776786    Top5 99.732143    LR 0.001500    Time 0.032264    
2018-10-21 07:49:34,904 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21841 | -0.00062 |    0.14487 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07717 | -0.00320 |    0.04512 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07534 |  0.00089 |    0.05122 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06509 | -0.00623 |    0.04423 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06224 | -0.00235 |    0.04087 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07662 | -0.00964 |    0.05355 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06726 | -0.00654 |    0.04731 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07821 | -0.00271 |    0.05848 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06731 | -0.00344 |    0.05121 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16082 |  0.00000 |    0.09891 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06123 | -0.00210 |    0.04624 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05421 | -0.00659 |    0.04268 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06537 | -0.00616 |    0.05008 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05234 | -0.00371 |    0.04099 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06227 | -0.00459 |    0.04924 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05801 | -0.00303 |    0.04600 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07504 | -0.00423 |    0.05729 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05589 | -0.00671 |    0.04429 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03944 | -0.00318 |    0.03059 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03464 | -0.00681 |    0.02719 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01996 | -0.00002 |    0.01373 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39909 | -0.00001 |    0.28189 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:49:34,904 - Total sparsity: 0.00

2018-10-21 07:49:34,904 - --- validate (epoch=283)-----------
2018-10-21 07:49:34,905 - 10000 samples (128 per mini-batch)
2018-10-21 07:49:36,190 - Epoch: [283][   50/   78]    Loss 1.551453    Top1 91.125000    Top5 99.625000    
2018-10-21 07:49:36,902 - ==> Top1: 91.200    Top5: 99.610    Loss: 1.550

2018-10-21 07:49:36,904 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:49:36,904 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:49:36,916 - 

2018-10-21 07:49:36,917 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:49:38,646 - Epoch: [284][   50/  391]    Overall Loss 1.486824    Objective Loss 1.486824    Top1 97.781250    Top5 99.718750    LR 0.001500    Time 0.034530    
2018-10-21 07:49:40,326 - Epoch: [284][  100/  391]    Overall Loss 1.486828    Objective Loss 1.486828    Top1 97.789062    Top5 99.710938    LR 0.001500    Time 0.034038    
2018-10-21 07:49:41,965 - Epoch: [284][  150/  391]    Overall Loss 1.486150    Objective Loss 1.486150    Top1 97.838542    Top5 99.713542    LR 0.001500    Time 0.033605    
2018-10-21 07:49:43,631 - Epoch: [284][  200/  391]    Overall Loss 1.486478    Objective Loss 1.486478    Top1 97.796875    Top5 99.738281    LR 0.001500    Time 0.033523    
2018-10-21 07:49:45,471 - Epoch: [284][  250/  391]    Overall Loss 1.486264    Objective Loss 1.486264    Top1 97.815625    Top5 99.725000    LR 0.001500    Time 0.034171    
2018-10-21 07:49:47,320 - Epoch: [284][  300/  391]    Overall Loss 1.486509    Objective Loss 1.486509    Top1 97.781250    Top5 99.705729    LR 0.001500    Time 0.034631    
2018-10-21 07:49:49,093 - Epoch: [284][  350/  391]    Overall Loss 1.485897    Objective Loss 1.485897    Top1 97.848214    Top5 99.712054    LR 0.001500    Time 0.034743    
2018-10-21 07:49:50,514 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21828 | -0.00090 |    0.14484 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07713 | -0.00319 |    0.04511 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07530 |  0.00089 |    0.05119 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06506 | -0.00618 |    0.04420 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06221 | -0.00236 |    0.04084 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07658 | -0.00964 |    0.05352 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06722 | -0.00651 |    0.04729 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07817 | -0.00269 |    0.05844 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06727 | -0.00341 |    0.05118 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16073 | -0.00001 |    0.09884 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06120 | -0.00208 |    0.04621 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05418 | -0.00658 |    0.04266 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06534 | -0.00616 |    0.05004 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05231 | -0.00370 |    0.04096 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06224 | -0.00458 |    0.04921 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05798 | -0.00304 |    0.04598 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07500 | -0.00423 |    0.05726 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05586 | -0.00670 |    0.04427 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03942 | -0.00318 |    0.03057 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03462 | -0.00680 |    0.02717 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01995 | -0.00003 |    0.01372 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39905 | -0.00001 |    0.28187 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:49:50,514 - Total sparsity: 0.00

2018-10-21 07:49:50,514 - --- validate (epoch=284)-----------
2018-10-21 07:49:50,514 - 10000 samples (128 per mini-batch)
2018-10-21 07:49:51,797 - Epoch: [284][   50/   78]    Loss 1.550656    Top1 91.171875    Top5 99.625000    
2018-10-21 07:49:52,476 - ==> Top1: 91.270    Top5: 99.610    Loss: 1.549

2018-10-21 07:49:52,478 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:49:52,478 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:49:52,491 - 

2018-10-21 07:49:52,491 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:49:54,229 - Epoch: [285][   50/  391]    Overall Loss 1.487934    Objective Loss 1.487934    Top1 97.640625    Top5 99.703125    LR 0.001500    Time 0.034703    
2018-10-21 07:49:55,823 - Epoch: [285][  100/  391]    Overall Loss 1.486898    Objective Loss 1.486898    Top1 97.773438    Top5 99.687500    LR 0.001500    Time 0.033268    
2018-10-21 07:49:57,409 - Epoch: [285][  150/  391]    Overall Loss 1.486656    Objective Loss 1.486656    Top1 97.755208    Top5 99.729167    LR 0.001500    Time 0.032738    
2018-10-21 07:49:58,957 - Epoch: [285][  200/  391]    Overall Loss 1.487300    Objective Loss 1.487300    Top1 97.667969    Top5 99.714844    LR 0.001500    Time 0.032281    
2018-10-21 07:50:00,485 - Epoch: [285][  250/  391]    Overall Loss 1.487008    Objective Loss 1.487008    Top1 97.693750    Top5 99.715625    LR 0.001500    Time 0.031929    
2018-10-21 07:50:02,034 - Epoch: [285][  300/  391]    Overall Loss 1.486737    Objective Loss 1.486737    Top1 97.713542    Top5 99.713542    LR 0.001500    Time 0.031763    
2018-10-21 07:50:03,565 - Epoch: [285][  350/  391]    Overall Loss 1.486197    Objective Loss 1.486197    Top1 97.781250    Top5 99.727679    LR 0.001500    Time 0.031594    
2018-10-21 07:50:04,949 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21816 | -0.00077 |    0.14475 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07709 | -0.00318 |    0.04507 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07525 |  0.00087 |    0.05115 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06503 | -0.00619 |    0.04417 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06217 | -0.00238 |    0.04082 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07653 | -0.00966 |    0.05349 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06718 | -0.00653 |    0.04727 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07812 | -0.00270 |    0.05840 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06724 | -0.00340 |    0.05116 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16063 | -0.00002 |    0.09875 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06116 | -0.00208 |    0.04619 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05415 | -0.00656 |    0.04264 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06530 | -0.00616 |    0.05002 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05228 | -0.00368 |    0.04094 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06220 | -0.00457 |    0.04918 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05794 | -0.00305 |    0.04595 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07495 | -0.00424 |    0.05722 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05583 | -0.00670 |    0.04425 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03940 | -0.00318 |    0.03056 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03460 | -0.00680 |    0.02716 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01994 | -0.00003 |    0.01372 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39901 | -0.00001 |    0.28184 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:50:04,949 - Total sparsity: 0.00

2018-10-21 07:50:04,949 - --- validate (epoch=285)-----------
2018-10-21 07:50:04,949 - 10000 samples (128 per mini-batch)
2018-10-21 07:50:06,209 - Epoch: [285][   50/   78]    Loss 1.550604    Top1 91.234375    Top5 99.671875    
2018-10-21 07:50:06,868 - ==> Top1: 91.220    Top5: 99.660    Loss: 1.550

2018-10-21 07:50:06,870 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:50:06,870 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:50:06,883 - 

2018-10-21 07:50:06,883 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:50:08,530 - Epoch: [286][   50/  391]    Overall Loss 1.483483    Objective Loss 1.483483    Top1 98.062500    Top5 99.687500    LR 0.001500    Time 0.032866    
2018-10-21 07:50:10,127 - Epoch: [286][  100/  391]    Overall Loss 1.485719    Objective Loss 1.485719    Top1 97.867188    Top5 99.695312    LR 0.001500    Time 0.032382    
2018-10-21 07:50:11,726 - Epoch: [286][  150/  391]    Overall Loss 1.485366    Objective Loss 1.485366    Top1 97.916667    Top5 99.661458    LR 0.001500    Time 0.032236    
2018-10-21 07:50:13,313 - Epoch: [286][  200/  391]    Overall Loss 1.485436    Objective Loss 1.485436    Top1 97.933594    Top5 99.691406    LR 0.001500    Time 0.032095    
2018-10-21 07:50:14,912 - Epoch: [286][  250/  391]    Overall Loss 1.485688    Objective Loss 1.485688    Top1 97.906250    Top5 99.715625    LR 0.001500    Time 0.032065    
2018-10-21 07:50:16,478 - Epoch: [286][  300/  391]    Overall Loss 1.485832    Objective Loss 1.485832    Top1 97.861979    Top5 99.723958    LR 0.001500    Time 0.031933    
2018-10-21 07:50:18,069 - Epoch: [286][  350/  391]    Overall Loss 1.486105    Objective Loss 1.486105    Top1 97.850446    Top5 99.727679    LR 0.001500    Time 0.031909    
2018-10-21 07:50:19,504 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21804 | -0.00091 |    0.14469 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07704 | -0.00318 |    0.04505 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07521 |  0.00084 |    0.05112 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06499 | -0.00617 |    0.04414 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06214 | -0.00234 |    0.04080 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07649 | -0.00965 |    0.05346 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06715 | -0.00647 |    0.04724 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07808 | -0.00269 |    0.05836 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06720 | -0.00339 |    0.05113 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16054 |  0.00002 |    0.09867 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06113 | -0.00209 |    0.04616 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05412 | -0.00657 |    0.04261 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06526 | -0.00616 |    0.04999 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05225 | -0.00368 |    0.04091 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06216 | -0.00458 |    0.04915 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05791 | -0.00302 |    0.04593 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07491 | -0.00424 |    0.05718 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05579 | -0.00670 |    0.04422 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03938 | -0.00319 |    0.03054 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03458 | -0.00680 |    0.02714 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01993 | -0.00003 |    0.01371 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39897 | -0.00001 |    0.28181 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:50:19,504 - Total sparsity: 0.00

2018-10-21 07:50:19,504 - --- validate (epoch=286)-----------
2018-10-21 07:50:19,505 - 10000 samples (128 per mini-batch)
2018-10-21 07:50:20,724 - Epoch: [286][   50/   78]    Loss 1.550214    Top1 91.312500    Top5 99.593750    
2018-10-21 07:50:21,380 - ==> Top1: 91.340    Top5: 99.620    Loss: 1.549

2018-10-21 07:50:21,381 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:50:21,382 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:50:21,394 - 

2018-10-21 07:50:21,395 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:50:23,129 - Epoch: [287][   50/  391]    Overall Loss 1.483687    Objective Loss 1.483687    Top1 98.000000    Top5 99.750000    LR 0.001500    Time 0.034612    
2018-10-21 07:50:24,750 - Epoch: [287][  100/  391]    Overall Loss 1.486141    Objective Loss 1.486141    Top1 97.757812    Top5 99.757812    LR 0.001500    Time 0.033499    
2018-10-21 07:50:26,385 - Epoch: [287][  150/  391]    Overall Loss 1.486230    Objective Loss 1.486230    Top1 97.760417    Top5 99.723958    LR 0.001500    Time 0.033217    
2018-10-21 07:50:28,090 - Epoch: [287][  200/  391]    Overall Loss 1.486696    Objective Loss 1.486696    Top1 97.710938    Top5 99.734375    LR 0.001500    Time 0.033423    
2018-10-21 07:50:29,658 - Epoch: [287][  250/  391]    Overall Loss 1.486613    Objective Loss 1.486613    Top1 97.712500    Top5 99.746875    LR 0.001500    Time 0.033005    
2018-10-21 07:50:31,212 - Epoch: [287][  300/  391]    Overall Loss 1.486930    Objective Loss 1.486930    Top1 97.682292    Top5 99.744792    LR 0.001500    Time 0.032676    
2018-10-21 07:50:32,791 - Epoch: [287][  350/  391]    Overall Loss 1.486880    Objective Loss 1.486880    Top1 97.703125    Top5 99.729911    LR 0.001500    Time 0.032513    
2018-10-21 07:50:34,248 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21791 | -0.00090 |    0.14463 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07700 | -0.00315 |    0.04502 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07517 |  0.00086 |    0.05109 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06495 | -0.00617 |    0.04412 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06210 | -0.00233 |    0.04077 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07645 | -0.00965 |    0.05342 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06711 | -0.00647 |    0.04721 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07804 | -0.00268 |    0.05833 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06716 | -0.00338 |    0.05109 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16045 |  0.00002 |    0.09865 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06109 | -0.00207 |    0.04614 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05409 | -0.00656 |    0.04259 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06523 | -0.00616 |    0.04996 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05222 | -0.00368 |    0.04089 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06213 | -0.00458 |    0.04912 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05788 | -0.00302 |    0.04590 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07487 | -0.00423 |    0.05716 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05576 | -0.00670 |    0.04420 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03936 | -0.00318 |    0.03052 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03456 | -0.00680 |    0.02713 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01992 | -0.00003 |    0.01370 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39892 | -0.00001 |    0.28178 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:50:34,248 - Total sparsity: 0.00

2018-10-21 07:50:34,248 - --- validate (epoch=287)-----------
2018-10-21 07:50:34,249 - 10000 samples (128 per mini-batch)
2018-10-21 07:50:35,450 - Epoch: [287][   50/   78]    Loss 1.549454    Top1 91.203125    Top5 99.671875    
2018-10-21 07:50:36,120 - ==> Top1: 91.320    Top5: 99.660    Loss: 1.549

2018-10-21 07:50:36,122 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:50:36,122 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:50:36,135 - 

2018-10-21 07:50:36,135 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:50:37,909 - Epoch: [288][   50/  391]    Overall Loss 1.483531    Objective Loss 1.483531    Top1 98.046875    Top5 99.906250    LR 0.001500    Time 0.035421    
2018-10-21 07:50:39,573 - Epoch: [288][  100/  391]    Overall Loss 1.485295    Objective Loss 1.485295    Top1 97.867188    Top5 99.867188    LR 0.001500    Time 0.034326    
2018-10-21 07:50:41,214 - Epoch: [288][  150/  391]    Overall Loss 1.486390    Objective Loss 1.486390    Top1 97.781250    Top5 99.781250    LR 0.001500    Time 0.033810    
2018-10-21 07:50:42,843 - Epoch: [288][  200/  391]    Overall Loss 1.486061    Objective Loss 1.486061    Top1 97.808594    Top5 99.753906    LR 0.001500    Time 0.033488    
2018-10-21 07:50:44,461 - Epoch: [288][  250/  391]    Overall Loss 1.486426    Objective Loss 1.486426    Top1 97.775000    Top5 99.737500    LR 0.001500    Time 0.033255    
2018-10-21 07:50:46,049 - Epoch: [288][  300/  391]    Overall Loss 1.486123    Objective Loss 1.486123    Top1 97.807292    Top5 99.760417    LR 0.001500    Time 0.032999    
2018-10-21 07:50:47,624 - Epoch: [288][  350/  391]    Overall Loss 1.486218    Objective Loss 1.486218    Top1 97.801339    Top5 99.758929    LR 0.001500    Time 0.032778    
2018-10-21 07:50:49,048 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21779 | -0.00089 |    0.14451 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07696 | -0.00316 |    0.04499 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07513 |  0.00085 |    0.05107 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06492 | -0.00615 |    0.04410 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06207 | -0.00232 |    0.04075 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07640 | -0.00965 |    0.05340 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06707 | -0.00648 |    0.04719 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07799 | -0.00269 |    0.05829 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06712 | -0.00338 |    0.05106 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16036 |  0.00000 |    0.09857 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06106 | -0.00208 |    0.04611 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05405 | -0.00658 |    0.04257 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06519 | -0.00617 |    0.04994 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05219 | -0.00369 |    0.04086 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06209 | -0.00457 |    0.04910 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05785 | -0.00302 |    0.04587 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07483 | -0.00422 |    0.05713 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05573 | -0.00669 |    0.04418 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03933 | -0.00318 |    0.03051 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03454 | -0.00680 |    0.02711 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01991 | -0.00003 |    0.01369 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39888 | -0.00001 |    0.28176 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:50:49,048 - Total sparsity: 0.00

2018-10-21 07:50:49,049 - --- validate (epoch=288)-----------
2018-10-21 07:50:49,049 - 10000 samples (128 per mini-batch)
2018-10-21 07:50:50,241 - Epoch: [288][   50/   78]    Loss 1.549691    Top1 91.296875    Top5 99.578125    
2018-10-21 07:50:50,889 - ==> Top1: 91.340    Top5: 99.590    Loss: 1.549

2018-10-21 07:50:50,890 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:50:50,891 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:50:50,904 - 

2018-10-21 07:50:50,904 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:50:52,714 - Epoch: [289][   50/  391]    Overall Loss 1.484912    Objective Loss 1.484912    Top1 97.875000    Top5 99.718750    LR 0.001500    Time 0.036140    
2018-10-21 07:50:54,271 - Epoch: [289][  100/  391]    Overall Loss 1.487529    Objective Loss 1.487529    Top1 97.679688    Top5 99.679688    LR 0.001500    Time 0.033617    
2018-10-21 07:50:55,823 - Epoch: [289][  150/  391]    Overall Loss 1.485998    Objective Loss 1.485998    Top1 97.833333    Top5 99.697917    LR 0.001500    Time 0.032739    
2018-10-21 07:50:57,441 - Epoch: [289][  200/  391]    Overall Loss 1.485998    Objective Loss 1.485998    Top1 97.835938    Top5 99.718750    LR 0.001500    Time 0.032633    
2018-10-21 07:50:59,053 - Epoch: [289][  250/  391]    Overall Loss 1.485899    Objective Loss 1.485899    Top1 97.853125    Top5 99.728125    LR 0.001500    Time 0.032546    
2018-10-21 07:51:00,599 - Epoch: [289][  300/  391]    Overall Loss 1.485729    Objective Loss 1.485729    Top1 97.864583    Top5 99.726562    LR 0.001500    Time 0.032269    
2018-10-21 07:51:02,159 - Epoch: [289][  350/  391]    Overall Loss 1.485511    Objective Loss 1.485511    Top1 97.888393    Top5 99.732143    LR 0.001500    Time 0.032111    
2018-10-21 07:51:03,553 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21767 | -0.00073 |    0.14444 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07691 | -0.00316 |    0.04497 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07509 |  0.00083 |    0.05104 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06488 | -0.00616 |    0.04408 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06203 | -0.00230 |    0.04072 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07636 | -0.00964 |    0.05337 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06703 | -0.00648 |    0.04716 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07795 | -0.00270 |    0.05826 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06708 | -0.00339 |    0.05103 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16027 |  0.00000 |    0.09852 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06103 | -0.00208 |    0.04609 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05402 | -0.00658 |    0.04255 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06515 | -0.00615 |    0.04991 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05217 | -0.00368 |    0.04084 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06206 | -0.00457 |    0.04907 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05781 | -0.00301 |    0.04585 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07478 | -0.00421 |    0.05710 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05570 | -0.00670 |    0.04415 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03931 | -0.00318 |    0.03049 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03452 | -0.00679 |    0.02710 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01990 | -0.00003 |    0.01369 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39884 | -0.00001 |    0.28173 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:51:03,553 - Total sparsity: 0.00

2018-10-21 07:51:03,553 - --- validate (epoch=289)-----------
2018-10-21 07:51:03,553 - 10000 samples (128 per mini-batch)
2018-10-21 07:51:04,738 - Epoch: [289][   50/   78]    Loss 1.549059    Top1 91.453125    Top5 99.609375    
2018-10-21 07:51:05,417 - ==> Top1: 91.400    Top5: 99.600    Loss: 1.548

2018-10-21 07:51:05,418 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:51:05,419 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:51:05,431 - 

2018-10-21 07:51:05,431 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:51:07,185 - Epoch: [290][   50/  391]    Overall Loss 1.487251    Objective Loss 1.487251    Top1 97.734375    Top5 99.734375    LR 0.001500    Time 0.035012    
2018-10-21 07:51:08,710 - Epoch: [290][  100/  391]    Overall Loss 1.487631    Objective Loss 1.487631    Top1 97.703125    Top5 99.757812    LR 0.001500    Time 0.032736    
2018-10-21 07:51:10,269 - Epoch: [290][  150/  391]    Overall Loss 1.487687    Objective Loss 1.487687    Top1 97.677083    Top5 99.718750    LR 0.001500    Time 0.032197    
2018-10-21 07:51:11,842 - Epoch: [290][  200/  391]    Overall Loss 1.486048    Objective Loss 1.486048    Top1 97.863281    Top5 99.730469    LR 0.001500    Time 0.032005    
2018-10-21 07:51:13,406 - Epoch: [290][  250/  391]    Overall Loss 1.486116    Objective Loss 1.486116    Top1 97.850000    Top5 99.759375    LR 0.001500    Time 0.031849    
2018-10-21 07:51:14,955 - Epoch: [290][  300/  391]    Overall Loss 1.486014    Objective Loss 1.486014    Top1 97.861979    Top5 99.760417    LR 0.001500    Time 0.031697    
2018-10-21 07:51:16,515 - Epoch: [290][  350/  391]    Overall Loss 1.486306    Objective Loss 1.486306    Top1 97.832589    Top5 99.747768    LR 0.001500    Time 0.031621    
2018-10-21 07:51:17,944 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21754 | -0.00104 |    0.14431 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07687 | -0.00315 |    0.04494 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07504 |  0.00082 |    0.05101 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06484 | -0.00616 |    0.04406 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06200 | -0.00232 |    0.04069 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07632 | -0.00963 |    0.05333 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06699 | -0.00647 |    0.04713 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07791 | -0.00262 |    0.05822 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06705 | -0.00338 |    0.05100 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16018 |  0.00000 |    0.09849 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06099 | -0.00207 |    0.04606 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05399 | -0.00657 |    0.04253 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06512 | -0.00615 |    0.04987 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05214 | -0.00367 |    0.04082 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06202 | -0.00458 |    0.04904 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05778 | -0.00300 |    0.04582 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07474 | -0.00421 |    0.05706 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05567 | -0.00669 |    0.04413 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03929 | -0.00318 |    0.03047 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03450 | -0.00679 |    0.02708 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01989 | -0.00003 |    0.01368 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39880 | -0.00001 |    0.28171 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:51:17,944 - Total sparsity: 0.00

2018-10-21 07:51:17,944 - --- validate (epoch=290)-----------
2018-10-21 07:51:17,944 - 10000 samples (128 per mini-batch)
2018-10-21 07:51:19,191 - Epoch: [290][   50/   78]    Loss 1.549495    Top1 91.406250    Top5 99.656250    
2018-10-21 07:51:19,825 - ==> Top1: 91.370    Top5: 99.640    Loss: 1.549

2018-10-21 07:51:19,826 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:51:19,827 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:51:19,839 - 

2018-10-21 07:51:19,840 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:51:21,584 - Epoch: [291][   50/  391]    Overall Loss 1.485584    Objective Loss 1.485584    Top1 97.843750    Top5 99.718750    LR 0.001500    Time 0.034818    
2018-10-21 07:51:23,188 - Epoch: [291][  100/  391]    Overall Loss 1.484980    Objective Loss 1.484980    Top1 97.937500    Top5 99.710938    LR 0.001500    Time 0.033423    
2018-10-21 07:51:24,789 - Epoch: [291][  150/  391]    Overall Loss 1.484972    Objective Loss 1.484972    Top1 97.942708    Top5 99.708333    LR 0.001500    Time 0.032941    
2018-10-21 07:51:26,404 - Epoch: [291][  200/  391]    Overall Loss 1.486321    Objective Loss 1.486321    Top1 97.792969    Top5 99.707031    LR 0.001500    Time 0.032769    
2018-10-21 07:51:28,026 - Epoch: [291][  250/  391]    Overall Loss 1.485678    Objective Loss 1.485678    Top1 97.853125    Top5 99.718750    LR 0.001500    Time 0.032695    
2018-10-21 07:51:29,622 - Epoch: [291][  300/  391]    Overall Loss 1.485879    Objective Loss 1.485879    Top1 97.830729    Top5 99.710938    LR 0.001500    Time 0.032558    
2018-10-21 07:51:31,237 - Epoch: [291][  350/  391]    Overall Loss 1.485941    Objective Loss 1.485941    Top1 97.828125    Top5 99.727679    LR 0.001500    Time 0.032516    
2018-10-21 07:51:32,673 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21742 | -0.00097 |    0.14421 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07683 | -0.00314 |    0.04492 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07500 |  0.00084 |    0.05099 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06481 | -0.00616 |    0.04404 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06196 | -0.00233 |    0.04068 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07628 | -0.00961 |    0.05330 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06696 | -0.00644 |    0.04709 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07786 | -0.00262 |    0.05818 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06701 | -0.00339 |    0.05097 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16009 |  0.00001 |    0.09843 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06096 | -0.00207 |    0.04603 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05396 | -0.00656 |    0.04251 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06508 | -0.00615 |    0.04985 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05211 | -0.00367 |    0.04079 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06199 | -0.00457 |    0.04901 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05775 | -0.00299 |    0.04580 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07470 | -0.00420 |    0.05702 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05564 | -0.00669 |    0.04410 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03927 | -0.00319 |    0.03046 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03448 | -0.00679 |    0.02707 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01987 | -0.00003 |    0.01367 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39876 | -0.00001 |    0.28168 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:51:32,673 - Total sparsity: 0.00

2018-10-21 07:51:32,674 - --- validate (epoch=291)-----------
2018-10-21 07:51:32,674 - 10000 samples (128 per mini-batch)
2018-10-21 07:51:33,982 - Epoch: [291][   50/   78]    Loss 1.548913    Top1 91.406250    Top5 99.593750    
2018-10-21 07:51:34,632 - ==> Top1: 91.400    Top5: 99.600    Loss: 1.549

2018-10-21 07:51:34,634 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:51:34,634 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:51:34,646 - 

2018-10-21 07:51:34,647 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:51:36,422 - Epoch: [292][   50/  391]    Overall Loss 1.485203    Objective Loss 1.485203    Top1 97.890625    Top5 99.703125    LR 0.001500    Time 0.035449    
2018-10-21 07:51:38,061 - Epoch: [292][  100/  391]    Overall Loss 1.486582    Objective Loss 1.486582    Top1 97.781250    Top5 99.710938    LR 0.001500    Time 0.034093    
2018-10-21 07:51:39,673 - Epoch: [292][  150/  391]    Overall Loss 1.486394    Objective Loss 1.486394    Top1 97.765625    Top5 99.744792    LR 0.001500    Time 0.033457    
2018-10-21 07:51:41,261 - Epoch: [292][  200/  391]    Overall Loss 1.486659    Objective Loss 1.486659    Top1 97.722656    Top5 99.746094    LR 0.001500    Time 0.033024    
2018-10-21 07:51:42,820 - Epoch: [292][  250/  391]    Overall Loss 1.486145    Objective Loss 1.486145    Top1 97.759375    Top5 99.737500    LR 0.001500    Time 0.032645    
2018-10-21 07:51:44,382 - Epoch: [292][  300/  391]    Overall Loss 1.486548    Objective Loss 1.486548    Top1 97.721354    Top5 99.721354    LR 0.001500    Time 0.032404    
2018-10-21 07:51:45,973 - Epoch: [292][  350/  391]    Overall Loss 1.486673    Objective Loss 1.486673    Top1 97.723214    Top5 99.720982    LR 0.001500    Time 0.032314    
2018-10-21 07:51:47,409 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21730 | -0.00066 |    0.14416 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07678 | -0.00312 |    0.04489 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07496 |  0.00088 |    0.05096 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06477 | -0.00616 |    0.04401 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06193 | -0.00232 |    0.04066 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07623 | -0.00960 |    0.05328 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06692 | -0.00645 |    0.04707 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07782 | -0.00258 |    0.05814 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06697 | -0.00337 |    0.05094 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16000 |  0.00001 |    0.09835 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06092 | -0.00207 |    0.04601 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05393 | -0.00657 |    0.04248 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06504 | -0.00615 |    0.04982 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05208 | -0.00365 |    0.04077 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06195 | -0.00457 |    0.04898 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05772 | -0.00299 |    0.04577 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07466 | -0.00421 |    0.05699 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05561 | -0.00668 |    0.04408 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03924 | -0.00319 |    0.03044 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03446 | -0.00679 |    0.02705 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01986 | -0.00004 |    0.01367 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39871 | -0.00001 |    0.28165 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:51:47,410 - Total sparsity: 0.00

2018-10-21 07:51:47,410 - --- validate (epoch=292)-----------
2018-10-21 07:51:47,410 - 10000 samples (128 per mini-batch)
2018-10-21 07:51:48,632 - Epoch: [292][   50/   78]    Loss 1.549201    Top1 91.343750    Top5 99.609375    
2018-10-21 07:51:49,293 - ==> Top1: 91.350    Top5: 99.610    Loss: 1.548

2018-10-21 07:51:49,294 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:51:49,294 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:51:49,307 - 

2018-10-21 07:51:49,308 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:51:51,061 - Epoch: [293][   50/  391]    Overall Loss 1.484603    Objective Loss 1.484603    Top1 98.046875    Top5 99.781250    LR 0.001500    Time 0.035013    
2018-10-21 07:51:52,643 - Epoch: [293][  100/  391]    Overall Loss 1.485506    Objective Loss 1.485506    Top1 97.945312    Top5 99.726562    LR 0.001500    Time 0.033296    
2018-10-21 07:51:54,242 - Epoch: [293][  150/  391]    Overall Loss 1.485874    Objective Loss 1.485874    Top1 97.895833    Top5 99.723958    LR 0.001500    Time 0.032846    
2018-10-21 07:51:55,830 - Epoch: [293][  200/  391]    Overall Loss 1.485848    Objective Loss 1.485848    Top1 97.898438    Top5 99.730469    LR 0.001500    Time 0.032565    
2018-10-21 07:51:57,337 - Epoch: [293][  250/  391]    Overall Loss 1.486217    Objective Loss 1.486217    Top1 97.853125    Top5 99.737500    LR 0.001500    Time 0.032069    
2018-10-21 07:51:58,871 - Epoch: [293][  300/  391]    Overall Loss 1.486184    Objective Loss 1.486184    Top1 97.861979    Top5 99.731771    LR 0.001500    Time 0.031830    
2018-10-21 07:52:00,421 - Epoch: [293][  350/  391]    Overall Loss 1.485810    Objective Loss 1.485810    Top1 97.886161    Top5 99.741071    LR 0.001500    Time 0.031705    
2018-10-21 07:52:01,822 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21717 | -0.00080 |    0.14404 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07674 | -0.00312 |    0.04487 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07492 |  0.00086 |    0.05094 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06473 | -0.00618 |    0.04399 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06189 | -0.00230 |    0.04062 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07619 | -0.00962 |    0.05325 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06688 | -0.00642 |    0.04706 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07777 | -0.00259 |    0.05811 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06693 | -0.00338 |    0.05091 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15990 |  0.00002 |    0.09831 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06089 | -0.00206 |    0.04598 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05390 | -0.00656 |    0.04246 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06501 | -0.00614 |    0.04978 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05205 | -0.00366 |    0.04075 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06192 | -0.00456 |    0.04895 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05769 | -0.00298 |    0.04575 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07461 | -0.00420 |    0.05696 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05557 | -0.00669 |    0.04406 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03922 | -0.00320 |    0.03043 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03444 | -0.00678 |    0.02704 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01985 | -0.00004 |    0.01366 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39868 | -0.00001 |    0.28163 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:52:01,823 - Total sparsity: 0.00

2018-10-21 07:52:01,823 - --- validate (epoch=293)-----------
2018-10-21 07:52:01,823 - 10000 samples (128 per mini-batch)
2018-10-21 07:52:03,057 - Epoch: [293][   50/   78]    Loss 1.549535    Top1 91.281250    Top5 99.640625    
2018-10-21 07:52:03,721 - ==> Top1: 91.290    Top5: 99.630    Loss: 1.549

2018-10-21 07:52:03,722 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:52:03,722 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:52:03,735 - 

2018-10-21 07:52:03,735 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:52:05,487 - Epoch: [294][   50/  391]    Overall Loss 1.490106    Objective Loss 1.490106    Top1 97.500000    Top5 99.750000    LR 0.001500    Time 0.034989    
2018-10-21 07:52:07,066 - Epoch: [294][  100/  391]    Overall Loss 1.487577    Objective Loss 1.487577    Top1 97.671875    Top5 99.718750    LR 0.001500    Time 0.033253    
2018-10-21 07:52:08,653 - Epoch: [294][  150/  391]    Overall Loss 1.487513    Objective Loss 1.487513    Top1 97.645833    Top5 99.692708    LR 0.001500    Time 0.032734    
2018-10-21 07:52:10,201 - Epoch: [294][  200/  391]    Overall Loss 1.487105    Objective Loss 1.487105    Top1 97.703125    Top5 99.687500    LR 0.001500    Time 0.032281    
2018-10-21 07:52:11,754 - Epoch: [294][  250/  391]    Overall Loss 1.486993    Objective Loss 1.486993    Top1 97.737500    Top5 99.709375    LR 0.001500    Time 0.032025    
2018-10-21 07:52:13,323 - Epoch: [294][  300/  391]    Overall Loss 1.486338    Objective Loss 1.486338    Top1 97.799479    Top5 99.718750    LR 0.001500    Time 0.031911    
2018-10-21 07:52:14,870 - Epoch: [294][  350/  391]    Overall Loss 1.486391    Objective Loss 1.486391    Top1 97.803571    Top5 99.720982    LR 0.001500    Time 0.031767    
2018-10-21 07:52:16,270 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21705 | -0.00087 |    0.14397 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07670 | -0.00312 |    0.04485 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07487 |  0.00084 |    0.05092 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06469 | -0.00617 |    0.04397 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06186 | -0.00229 |    0.04060 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07615 | -0.00961 |    0.05322 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06684 | -0.00645 |    0.04702 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07773 | -0.00260 |    0.05808 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06689 | -0.00338 |    0.05088 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15981 |  0.00001 |    0.09822 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06086 | -0.00205 |    0.04596 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05387 | -0.00657 |    0.04244 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06497 | -0.00613 |    0.04976 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05202 | -0.00366 |    0.04073 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06188 | -0.00457 |    0.04892 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05765 | -0.00298 |    0.04572 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07457 | -0.00421 |    0.05693 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05554 | -0.00668 |    0.04403 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03920 | -0.00320 |    0.03041 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03442 | -0.00677 |    0.02702 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01984 | -0.00004 |    0.01365 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39864 | -0.00001 |    0.28161 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:52:16,270 - Total sparsity: 0.00

2018-10-21 07:52:16,270 - --- validate (epoch=294)-----------
2018-10-21 07:52:16,270 - 10000 samples (128 per mini-batch)
2018-10-21 07:52:17,488 - Epoch: [294][   50/   78]    Loss 1.550359    Top1 91.140625    Top5 99.625000    
2018-10-21 07:52:18,128 - ==> Top1: 91.180    Top5: 99.610    Loss: 1.550

2018-10-21 07:52:18,130 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:52:18,130 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:52:18,143 - 

2018-10-21 07:52:18,143 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:52:19,862 - Epoch: [295][   50/  391]    Overall Loss 1.485509    Objective Loss 1.485509    Top1 97.953125    Top5 99.671875    LR 0.001500    Time 0.034315    
2018-10-21 07:52:21,425 - Epoch: [295][  100/  391]    Overall Loss 1.485752    Objective Loss 1.485752    Top1 97.898438    Top5 99.679688    LR 0.001500    Time 0.032766    
2018-10-21 07:52:22,978 - Epoch: [295][  150/  391]    Overall Loss 1.485022    Objective Loss 1.485022    Top1 97.979167    Top5 99.687500    LR 0.001500    Time 0.032178    
2018-10-21 07:52:24,517 - Epoch: [295][  200/  391]    Overall Loss 1.484726    Objective Loss 1.484726    Top1 97.980469    Top5 99.699219    LR 0.001500    Time 0.031818    
2018-10-21 07:52:26,093 - Epoch: [295][  250/  391]    Overall Loss 1.484891    Objective Loss 1.484891    Top1 97.971875    Top5 99.700000    LR 0.001500    Time 0.031748    
2018-10-21 07:52:27,633 - Epoch: [295][  300/  391]    Overall Loss 1.485291    Objective Loss 1.485291    Top1 97.914062    Top5 99.705729    LR 0.001500    Time 0.031583    
2018-10-21 07:52:29,201 - Epoch: [295][  350/  391]    Overall Loss 1.485510    Objective Loss 1.485510    Top1 97.901786    Top5 99.703125    LR 0.001500    Time 0.031543    
2018-10-21 07:52:30,621 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21693 | -0.00084 |    0.14395 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07665 | -0.00310 |    0.04482 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07483 |  0.00081 |    0.05089 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06466 | -0.00618 |    0.04394 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06182 | -0.00230 |    0.04057 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07610 | -0.00962 |    0.05319 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06681 | -0.00642 |    0.04699 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07769 | -0.00258 |    0.05804 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06686 | -0.00337 |    0.05085 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15972 | -0.00000 |    0.09817 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06082 | -0.00204 |    0.04594 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05384 | -0.00656 |    0.04241 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06493 | -0.00613 |    0.04974 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05199 | -0.00367 |    0.04071 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06185 | -0.00458 |    0.04890 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05762 | -0.00298 |    0.04569 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07453 | -0.00419 |    0.05690 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05551 | -0.00668 |    0.04401 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03918 | -0.00319 |    0.03039 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03440 | -0.00678 |    0.02700 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01983 | -0.00004 |    0.01365 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39860 | -0.00001 |    0.28158 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:52:30,621 - Total sparsity: 0.00

2018-10-21 07:52:30,621 - --- validate (epoch=295)-----------
2018-10-21 07:52:30,621 - 10000 samples (128 per mini-batch)
2018-10-21 07:52:31,805 - Epoch: [295][   50/   78]    Loss 1.549274    Top1 91.312500    Top5 99.578125    
2018-10-21 07:52:32,436 - ==> Top1: 91.410    Top5: 99.590    Loss: 1.549

2018-10-21 07:52:32,437 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:52:32,437 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:52:32,450 - 

2018-10-21 07:52:32,450 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:52:34,225 - Epoch: [296][   50/  391]    Overall Loss 1.484712    Objective Loss 1.484712    Top1 97.906250    Top5 99.656250    LR 0.001500    Time 0.035432    
2018-10-21 07:52:35,833 - Epoch: [296][  100/  391]    Overall Loss 1.484481    Objective Loss 1.484481    Top1 97.937500    Top5 99.718750    LR 0.001500    Time 0.033777    
2018-10-21 07:52:37,433 - Epoch: [296][  150/  391]    Overall Loss 1.485039    Objective Loss 1.485039    Top1 97.859375    Top5 99.718750    LR 0.001500    Time 0.033166    
2018-10-21 07:52:39,017 - Epoch: [296][  200/  391]    Overall Loss 1.485356    Objective Loss 1.485356    Top1 97.839844    Top5 99.703125    LR 0.001500    Time 0.032786    
2018-10-21 07:52:40,596 - Epoch: [296][  250/  391]    Overall Loss 1.485097    Objective Loss 1.485097    Top1 97.887500    Top5 99.718750    LR 0.001500    Time 0.032537    
2018-10-21 07:52:42,210 - Epoch: [296][  300/  391]    Overall Loss 1.484987    Objective Loss 1.484987    Top1 97.906250    Top5 99.723958    LR 0.001500    Time 0.032487    
2018-10-21 07:52:43,832 - Epoch: [296][  350/  391]    Overall Loss 1.485357    Objective Loss 1.485357    Top1 97.881696    Top5 99.714286    LR 0.001500    Time 0.032472    
2018-10-21 07:52:45,306 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21680 | -0.00099 |    0.14381 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07661 | -0.00309 |    0.04480 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07479 |  0.00082 |    0.05087 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06462 | -0.00616 |    0.04392 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06179 | -0.00231 |    0.04055 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07606 | -0.00957 |    0.05316 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06677 | -0.00645 |    0.04697 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07764 | -0.00258 |    0.05801 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06682 | -0.00337 |    0.05082 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15963 | -0.00002 |    0.09812 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06079 | -0.00206 |    0.04591 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05381 | -0.00655 |    0.04239 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06490 | -0.00613 |    0.04971 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05196 | -0.00367 |    0.04068 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06181 | -0.00457 |    0.04887 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05759 | -0.00298 |    0.04567 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07449 | -0.00420 |    0.05687 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05548 | -0.00668 |    0.04398 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03916 | -0.00319 |    0.03038 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03439 | -0.00677 |    0.02699 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01982 | -0.00003 |    0.01364 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39856 | -0.00001 |    0.28155 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:52:45,307 - Total sparsity: 0.00

2018-10-21 07:52:45,307 - --- validate (epoch=296)-----------
2018-10-21 07:52:45,307 - 10000 samples (128 per mini-batch)
2018-10-21 07:52:46,628 - Epoch: [296][   50/   78]    Loss 1.547899    Top1 91.609375    Top5 99.625000    
2018-10-21 07:52:47,294 - ==> Top1: 91.460    Top5: 99.610    Loss: 1.548

2018-10-21 07:52:47,295 - ==> Best Top1: 91.480   On Epoch: 238

2018-10-21 07:52:47,295 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:52:47,308 - 

2018-10-21 07:52:47,309 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:52:48,990 - Epoch: [297][   50/  391]    Overall Loss 1.485156    Objective Loss 1.485156    Top1 97.859375    Top5 99.765625    LR 0.001500    Time 0.033569    
2018-10-21 07:52:50,538 - Epoch: [297][  100/  391]    Overall Loss 1.486696    Objective Loss 1.486696    Top1 97.664062    Top5 99.726562    LR 0.001500    Time 0.032241    
2018-10-21 07:52:52,104 - Epoch: [297][  150/  391]    Overall Loss 1.486543    Objective Loss 1.486543    Top1 97.713542    Top5 99.739583    LR 0.001500    Time 0.031916    
2018-10-21 07:52:53,670 - Epoch: [297][  200/  391]    Overall Loss 1.485812    Objective Loss 1.485812    Top1 97.812500    Top5 99.761719    LR 0.001500    Time 0.031757    
2018-10-21 07:52:55,247 - Epoch: [297][  250/  391]    Overall Loss 1.485804    Objective Loss 1.485804    Top1 97.806250    Top5 99.768750    LR 0.001500    Time 0.031706    
2018-10-21 07:52:56,807 - Epoch: [297][  300/  391]    Overall Loss 1.485854    Objective Loss 1.485854    Top1 97.804688    Top5 99.773438    LR 0.001500    Time 0.031616    
2018-10-21 07:52:58,358 - Epoch: [297][  350/  391]    Overall Loss 1.485814    Objective Loss 1.485814    Top1 97.808036    Top5 99.756696    LR 0.001500    Time 0.031524    
2018-10-21 07:52:59,762 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21668 | -0.00105 |    0.14365 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07657 | -0.00310 |    0.04478 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07475 |  0.00083 |    0.05084 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06459 | -0.00614 |    0.04390 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06175 | -0.00230 |    0.04053 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07602 | -0.00958 |    0.05313 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06673 | -0.00642 |    0.04694 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07760 | -0.00259 |    0.05798 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06678 | -0.00336 |    0.05079 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15954 |  0.00001 |    0.09801 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06075 | -0.00206 |    0.04588 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05378 | -0.00654 |    0.04236 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06486 | -0.00613 |    0.04968 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05193 | -0.00365 |    0.04066 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06178 | -0.00456 |    0.04884 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05756 | -0.00297 |    0.04564 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07444 | -0.00420 |    0.05685 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05545 | -0.00668 |    0.04396 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03914 | -0.00319 |    0.03036 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03437 | -0.00677 |    0.02698 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01981 | -0.00003 |    0.01363 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39851 | -0.00001 |    0.28152 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:52:59,762 - Total sparsity: 0.00

2018-10-21 07:52:59,762 - --- validate (epoch=297)-----------
2018-10-21 07:52:59,762 - 10000 samples (128 per mini-batch)
2018-10-21 07:53:00,985 - Epoch: [297][   50/   78]    Loss 1.548548    Top1 91.546875    Top5 99.593750    
2018-10-21 07:53:01,652 - ==> Top1: 91.510    Top5: 99.600    Loss: 1.548

2018-10-21 07:53:01,654 - ==> Best Top1: 91.510   On Epoch: 297

2018-10-21 07:53:01,654 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:53:01,670 - 

2018-10-21 07:53:01,670 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:53:03,401 - Epoch: [298][   50/  391]    Overall Loss 1.486404    Objective Loss 1.486404    Top1 97.812500    Top5 99.718750    LR 0.001500    Time 0.034563    
2018-10-21 07:53:05,002 - Epoch: [298][  100/  391]    Overall Loss 1.485519    Objective Loss 1.485519    Top1 97.914062    Top5 99.718750    LR 0.001500    Time 0.033264    
2018-10-21 07:53:06,574 - Epoch: [298][  150/  391]    Overall Loss 1.485161    Objective Loss 1.485161    Top1 97.947917    Top5 99.734375    LR 0.001500    Time 0.032640    
2018-10-21 07:53:08,175 - Epoch: [298][  200/  391]    Overall Loss 1.485426    Objective Loss 1.485426    Top1 97.902344    Top5 99.753906    LR 0.001500    Time 0.032476    
2018-10-21 07:53:09,872 - Epoch: [298][  250/  391]    Overall Loss 1.485049    Objective Loss 1.485049    Top1 97.934375    Top5 99.765625    LR 0.001500    Time 0.032759    
2018-10-21 07:53:11,461 - Epoch: [298][  300/  391]    Overall Loss 1.484901    Objective Loss 1.484901    Top1 97.940104    Top5 99.765625    LR 0.001500    Time 0.032588    
2018-10-21 07:53:13,039 - Epoch: [298][  350/  391]    Overall Loss 1.484927    Objective Loss 1.484927    Top1 97.933036    Top5 99.765625    LR 0.001500    Time 0.032437    
2018-10-21 07:53:14,464 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21656 | -0.00082 |    0.14364 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07652 | -0.00313 |    0.04475 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07470 |  0.00081 |    0.05082 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06455 | -0.00615 |    0.04387 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06172 | -0.00228 |    0.04051 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07597 | -0.00958 |    0.05310 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06670 | -0.00639 |    0.04691 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07755 | -0.00258 |    0.05794 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06674 | -0.00336 |    0.05076 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15945 |  0.00006 |    0.09794 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06072 | -0.00205 |    0.04586 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05375 | -0.00654 |    0.04234 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06483 | -0.00612 |    0.04966 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05190 | -0.00365 |    0.04064 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06174 | -0.00456 |    0.04881 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05752 | -0.00297 |    0.04561 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07440 | -0.00420 |    0.05681 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05542 | -0.00667 |    0.04393 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03911 | -0.00319 |    0.03034 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03435 | -0.00677 |    0.02696 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01980 | -0.00003 |    0.01362 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39847 | -0.00001 |    0.28149 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:53:14,465 - Total sparsity: 0.00

2018-10-21 07:53:14,465 - --- validate (epoch=298)-----------
2018-10-21 07:53:14,465 - 10000 samples (128 per mini-batch)
2018-10-21 07:53:15,699 - Epoch: [298][   50/   78]    Loss 1.548222    Top1 91.531250    Top5 99.609375    
2018-10-21 07:53:16,342 - ==> Top1: 91.480    Top5: 99.610    Loss: 1.548

2018-10-21 07:53:16,343 - ==> Best Top1: 91.510   On Epoch: 297

2018-10-21 07:53:16,343 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:53:16,356 - 

2018-10-21 07:53:16,356 - Training epoch: 50000 samples (128 per mini-batch)
2018-10-21 07:53:18,124 - Epoch: [299][   50/  391]    Overall Loss 1.485799    Objective Loss 1.485799    Top1 97.750000    Top5 99.687500    LR 0.001500    Time 0.035285    
2018-10-21 07:53:19,701 - Epoch: [299][  100/  391]    Overall Loss 1.485577    Objective Loss 1.485577    Top1 97.812500    Top5 99.703125    LR 0.001500    Time 0.033393    
2018-10-21 07:53:21,262 - Epoch: [299][  150/  391]    Overall Loss 1.485507    Objective Loss 1.485507    Top1 97.828125    Top5 99.713542    LR 0.001500    Time 0.032659    
2018-10-21 07:53:22,817 - Epoch: [299][  200/  391]    Overall Loss 1.485587    Objective Loss 1.485587    Top1 97.824219    Top5 99.746094    LR 0.001500    Time 0.032256    
2018-10-21 07:53:24,394 - Epoch: [299][  250/  391]    Overall Loss 1.485617    Objective Loss 1.485617    Top1 97.821875    Top5 99.728125    LR 0.001500    Time 0.032105    
2018-10-21 07:53:25,933 - Epoch: [299][  300/  391]    Overall Loss 1.485706    Objective Loss 1.485706    Top1 97.815104    Top5 99.739583    LR 0.001500    Time 0.031877    
2018-10-21 07:53:27,448 - Epoch: [299][  350/  391]    Overall Loss 1.485634    Objective Loss 1.485634    Top1 97.814732    Top5 99.754464    LR 0.001500    Time 0.031644    
2018-10-21 07:53:28,834 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21644 | -0.00101 |    0.14352 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07648 | -0.00313 |    0.04473 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07466 |  0.00082 |    0.05079 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06451 | -0.00615 |    0.04385 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06168 | -0.00228 |    0.04048 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07594 | -0.00953 |    0.05307 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06665 | -0.00645 |    0.04689 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07751 | -0.00258 |    0.05791 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06670 | -0.00337 |    0.05074 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15936 |  0.00005 |    0.09787 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06068 | -0.00207 |    0.04584 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05372 | -0.00654 |    0.04231 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06479 | -0.00612 |    0.04963 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05188 | -0.00365 |    0.04062 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06171 | -0.00455 |    0.04878 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05749 | -0.00298 |    0.04559 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07436 | -0.00420 |    0.05678 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05539 | -0.00666 |    0.04391 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03909 | -0.00319 |    0.03033 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.03433 | -0.00677 |    0.02695 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.01979 | -0.00003 |    0.01362 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39841 | -0.00001 |    0.28145 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-10-21 07:53:28,835 - Total sparsity: 0.00

2018-10-21 07:53:28,835 - --- validate (epoch=299)-----------
2018-10-21 07:53:28,835 - 10000 samples (128 per mini-batch)
2018-10-21 07:53:30,123 - Epoch: [299][   50/   78]    Loss 1.548156    Top1 91.593750    Top5 99.656250    
2018-10-21 07:53:30,784 - ==> Top1: 91.530    Top5: 99.640    Loss: 1.548

2018-10-21 07:53:30,785 - ==> Best Top1: 91.530   On Epoch: 299

2018-10-21 07:53:30,786 - Saving checkpoint to: logs/baseline/2018.10.21-064007/checkpoint.pth.tar
2018-10-21 07:53:30,801 - --- test ---------------------
2018-10-21 07:53:30,802 - 10000 samples (128 per mini-batch)
2018-10-21 07:53:32,078 - Test: [   50/   78]    Loss 1.548156    Top1 91.593750    Top5 99.656250    
2018-10-21 07:53:32,716 - ==> Top1: 91.530    Top5: 99.640    Loss: 1.548

2018-10-21 07:53:32,723 - 
2018-10-21 07:53:32,724 - Log file for this run: /home/dllab/distiller/examples/classifier_compression/logs/baseline/2018.10.21-064007/2018.10.21-064007.log
