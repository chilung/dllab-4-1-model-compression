2018-11-01 10:46:01,506 - Log file for this run: /home/ccma/Chilung/1022/distiller/examples/classifier_compression/logs/2018.11.01-104601/2018.11.01-104601.log
2018-11-01 10:46:01,506 - Number of CPUs: 8
2018-11-01 10:46:01,543 - Number of GPUs: 1
2018-11-01 10:46:01,543 - CUDA version: 8.0.61
2018-11-01 10:46:01,543 - CUDNN version: 7102
2018-11-01 10:46:01,543 - Kernel: 4.13.0-38-generic
2018-11-01 10:46:01,543 - Python: 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
2018-11-01 10:46:01,543 - PyTorch: 0.4.0
2018-11-01 10:46:01,543 - Numpy: 1.14.3
2018-11-01 10:46:01,562 - Git is dirty
2018-11-01 10:46:01,563 - Active Git branch: master
2018-11-01 10:46:01,566 - Git commit: 8bf95d12172fb6e82a00ce40007953e23d9648c7
2018-11-01 10:46:01,566 - App args: ['compress_classifier.py', '--resume=../../../resnet20_cifar_baseline/checkpoint.pth.tar', '-a', 'resnet20_cifar', '../../../data.cifar10', '-j', '12', '--sense=filter']
2018-11-01 10:46:01,567 - ==> using cifar10 dataset
2018-11-01 10:46:01,567 - => creating resnet20_cifar model for CIFAR10
2018-11-01 10:46:04,469 - => loading checkpoint ../../../resnet20_cifar_baseline/checkpoint.pth.tar
2018-11-01 10:46:04,613 - Checkpoint keys:
arch
	state_dict
	optimizer
	best_top1
	compression_sched
	epoch
2018-11-01 10:46:04,614 -    best top@1: 91.530
2018-11-01 10:46:04,614 - Loaded compression schedule from checkpoint (epoch 299)
2018-11-01 10:46:04,614 - => loaded checkpoint '../../../resnet20_cifar_baseline/checkpoint.pth.tar' (epoch 299)
2018-11-01 10:46:04,618 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2018-11-01 10:46:04,618 - Optimizer Args: {'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False, 'dampening': 0, 'lr': 0.1}
2018-11-01 10:46:06,058 - Dataset sizes:
	training=45000
	validation=5000
	test=10000
2018-11-01 10:46:06,058 - Running sensitivity tests
2018-11-01 10:46:06,066 - Testing sensitivity of module.conv1.weight [0.0% sparsity]
2018-11-01 10:46:06,067 - --- test ---------------------
2018-11-01 10:46:06,068 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:06,507 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:06,612 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:06,710 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:06,811 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:06,836 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:06,836 - Testing sensitivity of module.conv1.weight [5.0% sparsity]
2018-11-01 10:46:06,839 - Too few filters - can't prune 5.0% filters
2018-11-01 10:46:06,840 - --- test ---------------------
2018-11-01 10:46:06,841 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:07,237 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:07,338 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:07,436 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:07,527 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:07,552 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:07,553 - Testing sensitivity of module.conv1.weight [10.0% sparsity]
2018-11-01 10:46:07,561 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 10:46:07,562 - --- test ---------------------
2018-11-01 10:46:07,562 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:07,955 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:08,057 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:08,155 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:08,245 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:08,270 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:08,271 - Testing sensitivity of module.conv1.weight [15.0% sparsity]
2018-11-01 10:46:08,273 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 10:46:08,275 - --- test ---------------------
2018-11-01 10:46:08,275 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:08,691 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:08,791 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:08,889 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:08,980 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:09,007 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:09,008 - Testing sensitivity of module.conv1.weight [20.0% sparsity]
2018-11-01 10:46:09,011 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 10:46:09,012 - --- test ---------------------
2018-11-01 10:46:09,012 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:09,412 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:09,512 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:09,611 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:09,702 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:09,726 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:09,727 - Testing sensitivity of module.conv1.weight [25.0% sparsity]
2018-11-01 10:46:09,734 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 10:46:09,735 - --- test ---------------------
2018-11-01 10:46:09,736 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:10,146 - Test: [   10/   39]    Loss 0.553210    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:10,246 - Test: [   20/   39]    Loss 0.554081    Top1 91.523438    Top5 99.570312    
2018-11-01 10:46:10,345 - Test: [   30/   39]    Loss 0.547180    Top1 91.510417    Top5 99.661458    
2018-11-01 10:46:10,435 - Test: [   40/   39]    Loss 0.541902    Top1 91.510000    Top5 99.640000    
2018-11-01 10:46:10,460 - ==> Top1: 91.510    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:10,461 - Testing sensitivity of module.conv1.weight [30.0% sparsity]
2018-11-01 10:46:10,464 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 10:46:10,465 - --- test ---------------------
2018-11-01 10:46:10,465 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:10,878 - Test: [   10/   39]    Loss 0.553210    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:10,979 - Test: [   20/   39]    Loss 0.554081    Top1 91.523438    Top5 99.570312    
2018-11-01 10:46:11,077 - Test: [   30/   39]    Loss 0.547180    Top1 91.510417    Top5 99.661458    
2018-11-01 10:46:11,168 - Test: [   40/   39]    Loss 0.541902    Top1 91.510000    Top5 99.640000    
2018-11-01 10:46:11,193 - ==> Top1: 91.510    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:11,193 - Testing sensitivity of module.conv1.weight [35.0% sparsity]
2018-11-01 10:46:11,196 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 10:46:11,197 - --- test ---------------------
2018-11-01 10:46:11,197 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:11,620 - Test: [   10/   39]    Loss 0.557399    Top1 91.328125    Top5 99.648438    
2018-11-01 10:46:11,721 - Test: [   20/   39]    Loss 0.557219    Top1 91.425781    Top5 99.550781    
2018-11-01 10:46:11,820 - Test: [   30/   39]    Loss 0.549529    Top1 91.419271    Top5 99.648438    
2018-11-01 10:46:11,910 - Test: [   40/   39]    Loss 0.545218    Top1 91.470000    Top5 99.630000    
2018-11-01 10:46:11,936 - ==> Top1: 91.470    Top5: 99.630    Loss: 0.545

2018-11-01 10:46:11,937 - Testing sensitivity of module.conv1.weight [40.0% sparsity]
2018-11-01 10:46:11,939 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 10:46:11,941 - --- test ---------------------
2018-11-01 10:46:11,941 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:12,357 - Test: [   10/   39]    Loss 0.574705    Top1 91.250000    Top5 99.648438    
2018-11-01 10:46:12,460 - Test: [   20/   39]    Loss 0.570070    Top1 91.347656    Top5 99.550781    
2018-11-01 10:46:12,558 - Test: [   30/   39]    Loss 0.560069    Top1 91.289062    Top5 99.635417    
2018-11-01 10:46:12,648 - Test: [   40/   39]    Loss 0.556566    Top1 91.400000    Top5 99.640000    
2018-11-01 10:46:12,674 - ==> Top1: 91.400    Top5: 99.640    Loss: 0.557

2018-11-01 10:46:12,675 - Testing sensitivity of module.conv1.weight [45.0% sparsity]
2018-11-01 10:46:12,677 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 10:46:12,678 - --- test ---------------------
2018-11-01 10:46:12,678 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:13,088 - Test: [   10/   39]    Loss 0.628789    Top1 90.273438    Top5 99.492188    
2018-11-01 10:46:13,189 - Test: [   20/   39]    Loss 0.606020    Top1 90.781250    Top5 99.453125    
2018-11-01 10:46:13,288 - Test: [   30/   39]    Loss 0.596363    Top1 90.781250    Top5 99.531250    
2018-11-01 10:46:13,378 - Test: [   40/   39]    Loss 0.593528    Top1 90.750000    Top5 99.530000    
2018-11-01 10:46:13,402 - ==> Top1: 90.750    Top5: 99.530    Loss: 0.594

2018-11-01 10:46:13,403 - Testing sensitivity of module.conv1.weight [50.0% sparsity]
2018-11-01 10:46:13,406 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 10:46:13,408 - --- test ---------------------
2018-11-01 10:46:13,408 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:13,818 - Test: [   10/   39]    Loss 0.709033    Top1 88.632812    Top5 99.531250    
2018-11-01 10:46:13,919 - Test: [   20/   39]    Loss 0.692784    Top1 89.277344    Top5 99.531250    
2018-11-01 10:46:14,017 - Test: [   30/   39]    Loss 0.671351    Top1 89.518229    Top5 99.596354    
2018-11-01 10:46:14,107 - Test: [   40/   39]    Loss 0.660100    Top1 89.610000    Top5 99.590000    
2018-11-01 10:46:14,132 - ==> Top1: 89.610    Top5: 99.590    Loss: 0.660

2018-11-01 10:46:14,133 - Testing sensitivity of module.conv1.weight [55.0% sparsity]
2018-11-01 10:46:14,136 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 10:46:14,138 - --- test ---------------------
2018-11-01 10:46:14,138 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:14,546 - Test: [   10/   39]    Loss 0.709033    Top1 88.632812    Top5 99.531250    
2018-11-01 10:46:14,648 - Test: [   20/   39]    Loss 0.692784    Top1 89.277344    Top5 99.531250    
2018-11-01 10:46:14,746 - Test: [   30/   39]    Loss 0.671351    Top1 89.518229    Top5 99.596354    
2018-11-01 10:46:14,836 - Test: [   40/   39]    Loss 0.660100    Top1 89.610000    Top5 99.590000    
2018-11-01 10:46:14,861 - ==> Top1: 89.610    Top5: 99.590    Loss: 0.660

2018-11-01 10:46:14,862 - Testing sensitivity of module.conv1.weight [60.0% sparsity]
2018-11-01 10:46:14,866 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 10:46:14,868 - --- test ---------------------
2018-11-01 10:46:14,868 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:15,290 - Test: [   10/   39]    Loss 0.900785    Top1 87.148438    Top5 99.570312    
2018-11-01 10:46:15,391 - Test: [   20/   39]    Loss 0.884680    Top1 87.324219    Top5 99.355469    
2018-11-01 10:46:15,489 - Test: [   30/   39]    Loss 0.859937    Top1 87.421875    Top5 99.492188    
2018-11-01 10:46:15,580 - Test: [   40/   39]    Loss 0.849026    Top1 87.340000    Top5 99.430000    
2018-11-01 10:46:15,605 - ==> Top1: 87.340    Top5: 99.430    Loss: 0.849

2018-11-01 10:46:15,606 - Testing sensitivity of module.conv1.weight [65.0% sparsity]
2018-11-01 10:46:15,609 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 10:46:15,610 - --- test ---------------------
2018-11-01 10:46:15,611 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:16,017 - Test: [   10/   39]    Loss 1.150513    Top1 82.617188    Top5 98.984375    
2018-11-01 10:46:16,117 - Test: [   20/   39]    Loss 1.148123    Top1 82.656250    Top5 98.828125    
2018-11-01 10:46:16,215 - Test: [   30/   39]    Loss 1.138178    Top1 82.916667    Top5 98.880208    
2018-11-01 10:46:16,306 - Test: [   40/   39]    Loss 1.134984    Top1 82.790000    Top5 98.870000    
2018-11-01 10:46:16,330 - ==> Top1: 82.790    Top5: 98.870    Loss: 1.135

2018-11-01 10:46:16,333 - Testing sensitivity of module.conv1.weight [70.0% sparsity]
2018-11-01 10:46:16,339 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 10:46:16,341 - --- test ---------------------
2018-11-01 10:46:16,341 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:16,752 - Test: [   10/   39]    Loss 1.579029    Top1 76.953125    Top5 97.734375    
2018-11-01 10:46:16,853 - Test: [   20/   39]    Loss 1.583341    Top1 76.699219    Top5 97.695312    
2018-11-01 10:46:16,952 - Test: [   30/   39]    Loss 1.592832    Top1 76.575521    Top5 97.799479    
2018-11-01 10:46:17,043 - Test: [   40/   39]    Loss 1.616549    Top1 76.450000    Top5 97.780000    
2018-11-01 10:46:17,069 - ==> Top1: 76.450    Top5: 97.780    Loss: 1.617

2018-11-01 10:46:17,070 - Testing sensitivity of module.conv1.weight [75.0% sparsity]
2018-11-01 10:46:17,072 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 10:46:17,073 - --- test ---------------------
2018-11-01 10:46:17,073 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:17,483 - Test: [   10/   39]    Loss 6.763968    Top1 23.476562    Top5 73.945312    
2018-11-01 10:46:17,584 - Test: [   20/   39]    Loss 6.791566    Top1 23.964844    Top5 73.886719    
2018-11-01 10:46:17,684 - Test: [   30/   39]    Loss 6.765779    Top1 24.127604    Top5 73.736979    
2018-11-01 10:46:17,774 - Test: [   40/   39]    Loss 6.727220    Top1 24.020000    Top5 73.340000    
2018-11-01 10:46:17,799 - ==> Top1: 24.020    Top5: 73.340    Loss: 6.727

2018-11-01 10:46:17,800 - Testing sensitivity of module.conv1.weight [80.0% sparsity]
2018-11-01 10:46:17,803 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 10:46:17,805 - --- test ---------------------
2018-11-01 10:46:17,805 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:18,214 - Test: [   10/   39]    Loss 6.763968    Top1 23.476562    Top5 73.945312    
2018-11-01 10:46:18,315 - Test: [   20/   39]    Loss 6.791566    Top1 23.964844    Top5 73.886719    
2018-11-01 10:46:18,415 - Test: [   30/   39]    Loss 6.765779    Top1 24.127604    Top5 73.736979    
2018-11-01 10:46:18,511 - Test: [   40/   39]    Loss 6.727220    Top1 24.020000    Top5 73.340000    
2018-11-01 10:46:18,537 - ==> Top1: 24.020    Top5: 73.340    Loss: 6.727

2018-11-01 10:46:18,539 - Testing sensitivity of module.conv1.weight [85.0% sparsity]
2018-11-01 10:46:18,544 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 10:46:18,546 - --- test ---------------------
2018-11-01 10:46:18,546 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:18,982 - Test: [   10/   39]    Loss 6.069811    Top1 14.843750    Top5 56.406250    
2018-11-01 10:46:19,083 - Test: [   20/   39]    Loss 6.052525    Top1 15.546875    Top5 56.035156    
2018-11-01 10:46:19,182 - Test: [   30/   39]    Loss 6.034514    Top1 15.481771    Top5 56.380208    
2018-11-01 10:46:19,275 - Test: [   40/   39]    Loss 5.975016    Top1 15.490000    Top5 56.280000    
2018-11-01 10:46:19,299 - ==> Top1: 15.490    Top5: 56.280    Loss: 5.975

2018-11-01 10:46:19,300 - Testing sensitivity of module.conv1.weight [90.0% sparsity]
2018-11-01 10:46:19,305 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 10:46:19,306 - --- test ---------------------
2018-11-01 10:46:19,306 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:19,714 - Test: [   10/   39]    Loss 6.218327    Top1 14.140625    Top5 55.507812    
2018-11-01 10:46:19,820 - Test: [   20/   39]    Loss 6.223041    Top1 14.785156    Top5 55.253906    
2018-11-01 10:46:19,920 - Test: [   30/   39]    Loss 6.187841    Top1 14.960938    Top5 55.807292    
2018-11-01 10:46:20,012 - Test: [   40/   39]    Loss 6.138495    Top1 15.060000    Top5 55.900000    
2018-11-01 10:46:20,036 - ==> Top1: 15.060    Top5: 55.900    Loss: 6.138

2018-11-01 10:46:20,049 - Testing sensitivity of module.layer1.0.conv1.weight [0.0% sparsity]
2018-11-01 10:46:20,052 - --- test ---------------------
2018-11-01 10:46:20,052 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:20,469 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:20,571 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:20,671 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:20,763 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:20,787 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:20,788 - Testing sensitivity of module.layer1.0.conv1.weight [5.0% sparsity]
2018-11-01 10:46:20,790 - Too few filters - can't prune 5.0% filters
2018-11-01 10:46:20,791 - --- test ---------------------
2018-11-01 10:46:20,791 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:21,236 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:21,345 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:21,449 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:21,546 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:21,584 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:21,585 - Testing sensitivity of module.layer1.0.conv1.weight [10.0% sparsity]
2018-11-01 10:46:21,588 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 10:46:21,589 - --- test ---------------------
2018-11-01 10:46:21,589 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:22,036 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:22,141 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:22,243 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:22,333 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:22,359 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:22,359 - Testing sensitivity of module.layer1.0.conv1.weight [15.0% sparsity]
2018-11-01 10:46:22,362 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 10:46:22,363 - --- test ---------------------
2018-11-01 10:46:22,364 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:22,774 - Test: [   10/   39]    Loss 0.558231    Top1 91.054688    Top5 99.648438    
2018-11-01 10:46:22,875 - Test: [   20/   39]    Loss 0.557259    Top1 91.269531    Top5 99.589844    
2018-11-01 10:46:22,973 - Test: [   30/   39]    Loss 0.551720    Top1 91.250000    Top5 99.674479    
2018-11-01 10:46:23,064 - Test: [   40/   39]    Loss 0.545333    Top1 91.380000    Top5 99.650000    
2018-11-01 10:46:23,088 - ==> Top1: 91.380    Top5: 99.650    Loss: 0.545

2018-11-01 10:46:23,089 - Testing sensitivity of module.layer1.0.conv1.weight [20.0% sparsity]
2018-11-01 10:46:23,092 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 10:46:23,094 - --- test ---------------------
2018-11-01 10:46:23,094 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:23,540 - Test: [   10/   39]    Loss 0.567060    Top1 90.781250    Top5 99.687500    
2018-11-01 10:46:23,647 - Test: [   20/   39]    Loss 0.559415    Top1 91.191406    Top5 99.589844    
2018-11-01 10:46:23,751 - Test: [   30/   39]    Loss 0.557139    Top1 91.106771    Top5 99.648438    
2018-11-01 10:46:23,847 - Test: [   40/   39]    Loss 0.551646    Top1 91.210000    Top5 99.630000    
2018-11-01 10:46:23,876 - ==> Top1: 91.210    Top5: 99.630    Loss: 0.552

2018-11-01 10:46:23,877 - Testing sensitivity of module.layer1.0.conv1.weight [25.0% sparsity]
2018-11-01 10:46:23,880 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 10:46:23,881 - --- test ---------------------
2018-11-01 10:46:23,881 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:24,322 - Test: [   10/   39]    Loss 0.565543    Top1 90.976562    Top5 99.687500    
2018-11-01 10:46:24,423 - Test: [   20/   39]    Loss 0.560538    Top1 91.250000    Top5 99.609375    
2018-11-01 10:46:24,520 - Test: [   30/   39]    Loss 0.557591    Top1 91.223958    Top5 99.661458    
2018-11-01 10:46:24,610 - Test: [   40/   39]    Loss 0.551899    Top1 91.320000    Top5 99.640000    
2018-11-01 10:46:24,634 - ==> Top1: 91.320    Top5: 99.640    Loss: 0.552

2018-11-01 10:46:24,635 - Testing sensitivity of module.layer1.0.conv1.weight [30.0% sparsity]
2018-11-01 10:46:24,639 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 10:46:24,640 - --- test ---------------------
2018-11-01 10:46:24,640 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:25,048 - Test: [   10/   39]    Loss 0.565543    Top1 90.976562    Top5 99.687500    
2018-11-01 10:46:25,149 - Test: [   20/   39]    Loss 0.560538    Top1 91.250000    Top5 99.609375    
2018-11-01 10:46:25,247 - Test: [   30/   39]    Loss 0.557591    Top1 91.223958    Top5 99.661458    
2018-11-01 10:46:25,338 - Test: [   40/   39]    Loss 0.551899    Top1 91.320000    Top5 99.640000    
2018-11-01 10:46:25,363 - ==> Top1: 91.320    Top5: 99.640    Loss: 0.552

2018-11-01 10:46:25,365 - Testing sensitivity of module.layer1.0.conv1.weight [35.0% sparsity]
2018-11-01 10:46:25,370 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 10:46:25,371 - --- test ---------------------
2018-11-01 10:46:25,371 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:25,772 - Test: [   10/   39]    Loss 0.579409    Top1 90.781250    Top5 99.687500    
2018-11-01 10:46:25,876 - Test: [   20/   39]    Loss 0.571488    Top1 91.191406    Top5 99.589844    
2018-11-01 10:46:25,974 - Test: [   30/   39]    Loss 0.567101    Top1 91.093750    Top5 99.661458    
2018-11-01 10:46:26,064 - Test: [   40/   39]    Loss 0.561226    Top1 91.170000    Top5 99.640000    
2018-11-01 10:46:26,089 - ==> Top1: 91.170    Top5: 99.640    Loss: 0.561

2018-11-01 10:46:26,091 - Testing sensitivity of module.layer1.0.conv1.weight [40.0% sparsity]
2018-11-01 10:46:26,094 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 10:46:26,096 - --- test ---------------------
2018-11-01 10:46:26,096 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:26,502 - Test: [   10/   39]    Loss 0.585311    Top1 90.742188    Top5 99.570312    
2018-11-01 10:46:26,604 - Test: [   20/   39]    Loss 0.579880    Top1 91.113281    Top5 99.531250    
2018-11-01 10:46:26,703 - Test: [   30/   39]    Loss 0.577128    Top1 91.028646    Top5 99.622396    
2018-11-01 10:46:26,793 - Test: [   40/   39]    Loss 0.568444    Top1 91.180000    Top5 99.610000    
2018-11-01 10:46:26,818 - ==> Top1: 91.180    Top5: 99.610    Loss: 0.568

2018-11-01 10:46:26,818 - Testing sensitivity of module.layer1.0.conv1.weight [45.0% sparsity]
2018-11-01 10:46:26,821 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 10:46:26,822 - --- test ---------------------
2018-11-01 10:46:26,823 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:27,253 - Test: [   10/   39]    Loss 0.588099    Top1 90.781250    Top5 99.531250    
2018-11-01 10:46:27,354 - Test: [   20/   39]    Loss 0.584238    Top1 90.957031    Top5 99.472656    
2018-11-01 10:46:27,452 - Test: [   30/   39]    Loss 0.581553    Top1 90.872396    Top5 99.583333    
2018-11-01 10:46:27,542 - Test: [   40/   39]    Loss 0.574539    Top1 90.970000    Top5 99.590000    
2018-11-01 10:46:27,568 - ==> Top1: 90.970    Top5: 99.590    Loss: 0.575

2018-11-01 10:46:27,569 - Testing sensitivity of module.layer1.0.conv1.weight [50.0% sparsity]
2018-11-01 10:46:27,571 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 10:46:27,573 - --- test ---------------------
2018-11-01 10:46:27,573 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:27,978 - Test: [   10/   39]    Loss 0.584390    Top1 90.625000    Top5 99.531250    
2018-11-01 10:46:28,078 - Test: [   20/   39]    Loss 0.580650    Top1 90.917969    Top5 99.492188    
2018-11-01 10:46:28,177 - Test: [   30/   39]    Loss 0.580110    Top1 90.833333    Top5 99.596354    
2018-11-01 10:46:28,267 - Test: [   40/   39]    Loss 0.573413    Top1 90.890000    Top5 99.580000    
2018-11-01 10:46:28,292 - ==> Top1: 90.890    Top5: 99.580    Loss: 0.573

2018-11-01 10:46:28,292 - Testing sensitivity of module.layer1.0.conv1.weight [55.0% sparsity]
2018-11-01 10:46:28,295 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 10:46:28,296 - --- test ---------------------
2018-11-01 10:46:28,296 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:28,702 - Test: [   10/   39]    Loss 0.584390    Top1 90.625000    Top5 99.531250    
2018-11-01 10:46:28,803 - Test: [   20/   39]    Loss 0.580650    Top1 90.917969    Top5 99.492188    
2018-11-01 10:46:28,901 - Test: [   30/   39]    Loss 0.580110    Top1 90.833333    Top5 99.596354    
2018-11-01 10:46:28,991 - Test: [   40/   39]    Loss 0.573413    Top1 90.890000    Top5 99.580000    
2018-11-01 10:46:29,016 - ==> Top1: 90.890    Top5: 99.580    Loss: 0.573

2018-11-01 10:46:29,017 - Testing sensitivity of module.layer1.0.conv1.weight [60.0% sparsity]
2018-11-01 10:46:29,020 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 10:46:29,021 - --- test ---------------------
2018-11-01 10:46:29,022 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:29,421 - Test: [   10/   39]    Loss 0.587477    Top1 90.351562    Top5 99.492188    
2018-11-01 10:46:29,523 - Test: [   20/   39]    Loss 0.586835    Top1 90.761719    Top5 99.472656    
2018-11-01 10:46:29,621 - Test: [   30/   39]    Loss 0.582287    Top1 90.638021    Top5 99.583333    
2018-11-01 10:46:29,711 - Test: [   40/   39]    Loss 0.578931    Top1 90.760000    Top5 99.570000    
2018-11-01 10:46:29,737 - ==> Top1: 90.760    Top5: 99.570    Loss: 0.579

2018-11-01 10:46:29,738 - Testing sensitivity of module.layer1.0.conv1.weight [65.0% sparsity]
2018-11-01 10:46:29,740 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 10:46:29,742 - --- test ---------------------
2018-11-01 10:46:29,742 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:30,149 - Test: [   10/   39]    Loss 0.607606    Top1 90.195312    Top5 99.531250    
2018-11-01 10:46:30,252 - Test: [   20/   39]    Loss 0.597614    Top1 90.351562    Top5 99.492188    
2018-11-01 10:46:30,350 - Test: [   30/   39]    Loss 0.594558    Top1 90.416667    Top5 99.583333    
2018-11-01 10:46:30,441 - Test: [   40/   39]    Loss 0.591612    Top1 90.580000    Top5 99.560000    
2018-11-01 10:46:30,466 - ==> Top1: 90.580    Top5: 99.560    Loss: 0.592

2018-11-01 10:46:30,467 - Testing sensitivity of module.layer1.0.conv1.weight [70.0% sparsity]
2018-11-01 10:46:30,470 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 10:46:30,472 - --- test ---------------------
2018-11-01 10:46:30,472 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:30,886 - Test: [   10/   39]    Loss 0.670059    Top1 89.375000    Top5 99.570312    
2018-11-01 10:46:30,986 - Test: [   20/   39]    Loss 0.650726    Top1 89.531250    Top5 99.511719    
2018-11-01 10:46:31,085 - Test: [   30/   39]    Loss 0.650679    Top1 89.557292    Top5 99.531250    
2018-11-01 10:46:31,175 - Test: [   40/   39]    Loss 0.647670    Top1 89.700000    Top5 99.530000    
2018-11-01 10:46:31,201 - ==> Top1: 89.700    Top5: 99.530    Loss: 0.648

2018-11-01 10:46:31,201 - Testing sensitivity of module.layer1.0.conv1.weight [75.0% sparsity]
2018-11-01 10:46:31,204 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 10:46:31,205 - --- test ---------------------
2018-11-01 10:46:31,205 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:31,615 - Test: [   10/   39]    Loss 0.838446    Top1 86.484375    Top5 99.492188    
2018-11-01 10:46:31,715 - Test: [   20/   39]    Loss 0.823195    Top1 86.679688    Top5 99.375000    
2018-11-01 10:46:31,814 - Test: [   30/   39]    Loss 0.836014    Top1 86.471354    Top5 99.361979    
2018-11-01 10:46:31,905 - Test: [   40/   39]    Loss 0.840521    Top1 86.450000    Top5 99.370000    
2018-11-01 10:46:31,930 - ==> Top1: 86.450    Top5: 99.370    Loss: 0.841

2018-11-01 10:46:31,931 - Testing sensitivity of module.layer1.0.conv1.weight [80.0% sparsity]
2018-11-01 10:46:31,933 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 10:46:31,934 - --- test ---------------------
2018-11-01 10:46:31,934 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:32,345 - Test: [   10/   39]    Loss 0.838446    Top1 86.484375    Top5 99.492188    
2018-11-01 10:46:32,447 - Test: [   20/   39]    Loss 0.823195    Top1 86.679688    Top5 99.375000    
2018-11-01 10:46:32,546 - Test: [   30/   39]    Loss 0.836014    Top1 86.471354    Top5 99.361979    
2018-11-01 10:46:32,636 - Test: [   40/   39]    Loss 0.840521    Top1 86.450000    Top5 99.370000    
2018-11-01 10:46:32,662 - ==> Top1: 86.450    Top5: 99.370    Loss: 0.841

2018-11-01 10:46:32,663 - Testing sensitivity of module.layer1.0.conv1.weight [85.0% sparsity]
2018-11-01 10:46:32,666 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 10:46:32,667 - --- test ---------------------
2018-11-01 10:46:32,667 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:33,070 - Test: [   10/   39]    Loss 1.222264    Top1 79.921875    Top5 99.023438    
2018-11-01 10:46:33,173 - Test: [   20/   39]    Loss 1.237161    Top1 80.273438    Top5 98.925781    
2018-11-01 10:46:33,272 - Test: [   30/   39]    Loss 1.233756    Top1 80.195312    Top5 98.828125    
2018-11-01 10:46:33,363 - Test: [   40/   39]    Loss 1.237230    Top1 80.210000    Top5 98.750000    
2018-11-01 10:46:33,388 - ==> Top1: 80.210    Top5: 98.750    Loss: 1.237

2018-11-01 10:46:33,389 - Testing sensitivity of module.layer1.0.conv1.weight [90.0% sparsity]
2018-11-01 10:46:33,392 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 10:46:33,393 - --- test ---------------------
2018-11-01 10:46:33,393 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:33,802 - Test: [   10/   39]    Loss 1.439480    Top1 75.781250    Top5 98.281250    
2018-11-01 10:46:33,904 - Test: [   20/   39]    Loss 1.446240    Top1 76.816406    Top5 98.007812    
2018-11-01 10:46:34,002 - Test: [   30/   39]    Loss 1.435505    Top1 76.679688    Top5 97.994792    
2018-11-01 10:46:34,093 - Test: [   40/   39]    Loss 1.439091    Top1 76.690000    Top5 97.970000    
2018-11-01 10:46:34,118 - ==> Top1: 76.690    Top5: 97.970    Loss: 1.439

2018-11-01 10:46:34,132 - Testing sensitivity of module.layer1.0.conv2.weight [0.0% sparsity]
2018-11-01 10:46:34,136 - --- test ---------------------
2018-11-01 10:46:34,137 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:34,509 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:34,611 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:34,709 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:34,800 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:34,825 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:34,826 - Testing sensitivity of module.layer1.0.conv2.weight [5.0% sparsity]
2018-11-01 10:46:34,828 - Too few filters - can't prune 5.0% filters
2018-11-01 10:46:34,829 - --- test ---------------------
2018-11-01 10:46:34,829 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:35,238 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:35,340 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:35,439 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:35,529 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:35,554 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:35,555 - Testing sensitivity of module.layer1.0.conv2.weight [10.0% sparsity]
2018-11-01 10:46:35,557 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 10:46:35,559 - --- test ---------------------
2018-11-01 10:46:35,559 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:35,961 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:36,063 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:36,162 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:36,252 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:36,278 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:36,279 - Testing sensitivity of module.layer1.0.conv2.weight [15.0% sparsity]
2018-11-01 10:46:36,282 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 10:46:36,283 - --- test ---------------------
2018-11-01 10:46:36,283 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:36,694 - Test: [   10/   39]    Loss 0.552677    Top1 91.210938    Top5 99.687500    
2018-11-01 10:46:36,795 - Test: [   20/   39]    Loss 0.553835    Top1 91.406250    Top5 99.550781    
2018-11-01 10:46:36,894 - Test: [   30/   39]    Loss 0.549180    Top1 91.471354    Top5 99.648438    
2018-11-01 10:46:36,985 - Test: [   40/   39]    Loss 0.545574    Top1 91.500000    Top5 99.630000    
2018-11-01 10:46:37,010 - ==> Top1: 91.500    Top5: 99.630    Loss: 0.546

2018-11-01 10:46:37,011 - Testing sensitivity of module.layer1.0.conv2.weight [20.0% sparsity]
2018-11-01 10:46:37,013 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 10:46:37,014 - --- test ---------------------
2018-11-01 10:46:37,014 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:37,419 - Test: [   10/   39]    Loss 0.555309    Top1 91.210938    Top5 99.687500    
2018-11-01 10:46:37,520 - Test: [   20/   39]    Loss 0.555969    Top1 91.328125    Top5 99.570312    
2018-11-01 10:46:37,618 - Test: [   30/   39]    Loss 0.551401    Top1 91.393229    Top5 99.661458    
2018-11-01 10:46:37,709 - Test: [   40/   39]    Loss 0.547227    Top1 91.450000    Top5 99.640000    
2018-11-01 10:46:37,734 - ==> Top1: 91.450    Top5: 99.640    Loss: 0.547

2018-11-01 10:46:37,745 - Testing sensitivity of module.layer1.0.conv2.weight [25.0% sparsity]
2018-11-01 10:46:37,748 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 10:46:37,749 - --- test ---------------------
2018-11-01 10:46:37,750 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:38,159 - Test: [   10/   39]    Loss 0.562841    Top1 91.328125    Top5 99.609375    
2018-11-01 10:46:38,260 - Test: [   20/   39]    Loss 0.568573    Top1 91.328125    Top5 99.550781    
2018-11-01 10:46:38,359 - Test: [   30/   39]    Loss 0.561467    Top1 91.341146    Top5 99.648438    
2018-11-01 10:46:38,450 - Test: [   40/   39]    Loss 0.555657    Top1 91.450000    Top5 99.640000    
2018-11-01 10:46:38,475 - ==> Top1: 91.450    Top5: 99.640    Loss: 0.556

2018-11-01 10:46:38,476 - Testing sensitivity of module.layer1.0.conv2.weight [30.0% sparsity]
2018-11-01 10:46:38,479 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 10:46:38,480 - --- test ---------------------
2018-11-01 10:46:38,481 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:38,888 - Test: [   10/   39]    Loss 0.562841    Top1 91.328125    Top5 99.609375    
2018-11-01 10:46:38,989 - Test: [   20/   39]    Loss 0.568573    Top1 91.328125    Top5 99.550781    
2018-11-01 10:46:39,088 - Test: [   30/   39]    Loss 0.561467    Top1 91.341146    Top5 99.648438    
2018-11-01 10:46:39,178 - Test: [   40/   39]    Loss 0.555657    Top1 91.450000    Top5 99.640000    
2018-11-01 10:46:39,204 - ==> Top1: 91.450    Top5: 99.640    Loss: 0.556

2018-11-01 10:46:39,205 - Testing sensitivity of module.layer1.0.conv2.weight [35.0% sparsity]
2018-11-01 10:46:39,206 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 10:46:39,208 - --- test ---------------------
2018-11-01 10:46:39,208 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:39,622 - Test: [   10/   39]    Loss 0.567023    Top1 90.703125    Top5 99.492188    
2018-11-01 10:46:39,724 - Test: [   20/   39]    Loss 0.567401    Top1 90.976562    Top5 99.453125    
2018-11-01 10:46:39,822 - Test: [   30/   39]    Loss 0.565342    Top1 91.028646    Top5 99.557292    
2018-11-01 10:46:39,913 - Test: [   40/   39]    Loss 0.556451    Top1 91.170000    Top5 99.560000    
2018-11-01 10:46:39,928 - ==> Top1: 91.170    Top5: 99.560    Loss: 0.556

2018-11-01 10:46:39,940 - Testing sensitivity of module.layer1.0.conv2.weight [40.0% sparsity]
2018-11-01 10:46:39,943 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 10:46:39,944 - --- test ---------------------
2018-11-01 10:46:39,944 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:40,355 - Test: [   10/   39]    Loss 0.564041    Top1 91.171875    Top5 99.531250    
2018-11-01 10:46:40,457 - Test: [   20/   39]    Loss 0.567189    Top1 91.171875    Top5 99.472656    
2018-11-01 10:46:40,555 - Test: [   30/   39]    Loss 0.567383    Top1 91.106771    Top5 99.570312    
2018-11-01 10:46:40,646 - Test: [   40/   39]    Loss 0.559821    Top1 91.200000    Top5 99.560000    
2018-11-01 10:46:40,669 - ==> Top1: 91.200    Top5: 99.560    Loss: 0.560

2018-11-01 10:46:40,670 - Testing sensitivity of module.layer1.0.conv2.weight [45.0% sparsity]
2018-11-01 10:46:40,672 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 10:46:40,674 - --- test ---------------------
2018-11-01 10:46:40,674 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:41,088 - Test: [   10/   39]    Loss 0.580277    Top1 90.742188    Top5 99.531250    
2018-11-01 10:46:41,190 - Test: [   20/   39]    Loss 0.584991    Top1 90.937500    Top5 99.531250    
2018-11-01 10:46:41,288 - Test: [   30/   39]    Loss 0.583290    Top1 90.807292    Top5 99.596354    
2018-11-01 10:46:41,379 - Test: [   40/   39]    Loss 0.573661    Top1 90.990000    Top5 99.580000    
2018-11-01 10:46:41,402 - ==> Top1: 90.990    Top5: 99.580    Loss: 0.574

2018-11-01 10:46:41,405 - Testing sensitivity of module.layer1.0.conv2.weight [50.0% sparsity]
2018-11-01 10:46:41,408 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 10:46:41,409 - --- test ---------------------
2018-11-01 10:46:41,410 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:41,851 - Test: [   10/   39]    Loss 0.646079    Top1 89.570312    Top5 99.531250    
2018-11-01 10:46:41,953 - Test: [   20/   39]    Loss 0.636035    Top1 90.000000    Top5 99.511719    
2018-11-01 10:46:42,052 - Test: [   30/   39]    Loss 0.628829    Top1 90.000000    Top5 99.557292    
2018-11-01 10:46:42,142 - Test: [   40/   39]    Loss 0.618306    Top1 90.160000    Top5 99.540000    
2018-11-01 10:46:42,168 - ==> Top1: 90.160    Top5: 99.540    Loss: 0.618

2018-11-01 10:46:42,169 - Testing sensitivity of module.layer1.0.conv2.weight [55.0% sparsity]
2018-11-01 10:46:42,171 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 10:46:42,173 - --- test ---------------------
2018-11-01 10:46:42,173 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:42,586 - Test: [   10/   39]    Loss 0.646079    Top1 89.570312    Top5 99.531250    
2018-11-01 10:46:42,689 - Test: [   20/   39]    Loss 0.636035    Top1 90.000000    Top5 99.511719    
2018-11-01 10:46:42,788 - Test: [   30/   39]    Loss 0.628829    Top1 90.000000    Top5 99.557292    
2018-11-01 10:46:42,878 - Test: [   40/   39]    Loss 0.618306    Top1 90.160000    Top5 99.540000    
2018-11-01 10:46:42,904 - ==> Top1: 90.160    Top5: 99.540    Loss: 0.618

2018-11-01 10:46:42,905 - Testing sensitivity of module.layer1.0.conv2.weight [60.0% sparsity]
2018-11-01 10:46:42,908 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 10:46:42,909 - --- test ---------------------
2018-11-01 10:46:42,909 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:43,318 - Test: [   10/   39]    Loss 0.677117    Top1 89.335938    Top5 99.453125    
2018-11-01 10:46:43,420 - Test: [   20/   39]    Loss 0.660042    Top1 89.765625    Top5 99.472656    
2018-11-01 10:46:43,518 - Test: [   30/   39]    Loss 0.651028    Top1 89.700521    Top5 99.557292    
2018-11-01 10:46:43,609 - Test: [   40/   39]    Loss 0.637346    Top1 89.840000    Top5 99.560000    
2018-11-01 10:46:43,634 - ==> Top1: 89.840    Top5: 99.560    Loss: 0.637

2018-11-01 10:46:43,634 - Testing sensitivity of module.layer1.0.conv2.weight [65.0% sparsity]
2018-11-01 10:46:43,637 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 10:46:43,638 - --- test ---------------------
2018-11-01 10:46:43,639 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:44,044 - Test: [   10/   39]    Loss 0.813831    Top1 87.382812    Top5 99.609375    
2018-11-01 10:46:44,146 - Test: [   20/   39]    Loss 0.789278    Top1 87.988281    Top5 99.550781    
2018-11-01 10:46:44,244 - Test: [   30/   39]    Loss 0.780284    Top1 87.890625    Top5 99.596354    
2018-11-01 10:46:44,335 - Test: [   40/   39]    Loss 0.754211    Top1 88.040000    Top5 99.570000    
2018-11-01 10:46:44,361 - ==> Top1: 88.040    Top5: 99.570    Loss: 0.754

2018-11-01 10:46:44,362 - Testing sensitivity of module.layer1.0.conv2.weight [70.0% sparsity]
2018-11-01 10:46:44,363 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 10:46:44,364 - --- test ---------------------
2018-11-01 10:46:44,364 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:44,768 - Test: [   10/   39]    Loss 0.834074    Top1 87.187500    Top5 99.375000    
2018-11-01 10:46:44,870 - Test: [   20/   39]    Loss 0.800732    Top1 87.656250    Top5 99.394531    
2018-11-01 10:46:44,968 - Test: [   30/   39]    Loss 0.796017    Top1 87.682292    Top5 99.492188    
2018-11-01 10:46:45,059 - Test: [   40/   39]    Loss 0.773348    Top1 87.740000    Top5 99.460000    
2018-11-01 10:46:45,084 - ==> Top1: 87.740    Top5: 99.460    Loss: 0.773

2018-11-01 10:46:45,085 - Testing sensitivity of module.layer1.0.conv2.weight [75.0% sparsity]
2018-11-01 10:46:45,087 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 10:46:45,089 - --- test ---------------------
2018-11-01 10:46:45,089 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:45,498 - Test: [   10/   39]    Loss 0.839600    Top1 87.304688    Top5 99.414062    
2018-11-01 10:46:45,599 - Test: [   20/   39]    Loss 0.825223    Top1 87.304688    Top5 99.355469    
2018-11-01 10:46:45,697 - Test: [   30/   39]    Loss 0.822135    Top1 87.291667    Top5 99.427083    
2018-11-01 10:46:45,788 - Test: [   40/   39]    Loss 0.799355    Top1 87.510000    Top5 99.410000    
2018-11-01 10:46:45,812 - ==> Top1: 87.510    Top5: 99.410    Loss: 0.799

2018-11-01 10:46:45,813 - Testing sensitivity of module.layer1.0.conv2.weight [80.0% sparsity]
2018-11-01 10:46:45,816 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 10:46:45,816 - --- test ---------------------
2018-11-01 10:46:45,817 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:46,223 - Test: [   10/   39]    Loss 0.839600    Top1 87.304688    Top5 99.414062    
2018-11-01 10:46:46,324 - Test: [   20/   39]    Loss 0.825223    Top1 87.304688    Top5 99.355469    
2018-11-01 10:46:46,422 - Test: [   30/   39]    Loss 0.822135    Top1 87.291667    Top5 99.427083    
2018-11-01 10:46:46,513 - Test: [   40/   39]    Loss 0.799355    Top1 87.510000    Top5 99.410000    
2018-11-01 10:46:46,549 - ==> Top1: 87.510    Top5: 99.410    Loss: 0.799

2018-11-01 10:46:46,550 - Testing sensitivity of module.layer1.0.conv2.weight [85.0% sparsity]
2018-11-01 10:46:46,552 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 10:46:46,552 - --- test ---------------------
2018-11-01 10:46:46,553 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:46,951 - Test: [   10/   39]    Loss 0.833533    Top1 86.640625    Top5 99.492188    
2018-11-01 10:46:47,052 - Test: [   20/   39]    Loss 0.821023    Top1 87.031250    Top5 99.394531    
2018-11-01 10:46:47,151 - Test: [   30/   39]    Loss 0.826071    Top1 86.966146    Top5 99.414062    
2018-11-01 10:46:47,241 - Test: [   40/   39]    Loss 0.803412    Top1 87.150000    Top5 99.400000    
2018-11-01 10:46:47,266 - ==> Top1: 87.150    Top5: 99.400    Loss: 0.803

2018-11-01 10:46:47,267 - Testing sensitivity of module.layer1.0.conv2.weight [90.0% sparsity]
2018-11-01 10:46:47,269 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 10:46:47,270 - --- test ---------------------
2018-11-01 10:46:47,270 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:47,698 - Test: [   10/   39]    Loss 1.163673    Top1 82.148438    Top5 98.945312    
2018-11-01 10:46:47,800 - Test: [   20/   39]    Loss 1.134391    Top1 82.519531    Top5 98.925781    
2018-11-01 10:46:47,899 - Test: [   30/   39]    Loss 1.142452    Top1 82.695312    Top5 98.945312    
2018-11-01 10:46:47,990 - Test: [   40/   39]    Loss 1.112481    Top1 82.990000    Top5 99.020000    
2018-11-01 10:46:48,014 - ==> Top1: 82.990    Top5: 99.020    Loss: 1.112

2018-11-01 10:46:48,029 - Testing sensitivity of module.layer1.1.conv1.weight [0.0% sparsity]
2018-11-01 10:46:48,033 - --- test ---------------------
2018-11-01 10:46:48,033 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:48,410 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:48,513 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:48,612 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:48,702 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:48,728 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:48,729 - Testing sensitivity of module.layer1.1.conv1.weight [5.0% sparsity]
2018-11-01 10:46:48,731 - Too few filters - can't prune 5.0% filters
2018-11-01 10:46:48,732 - --- test ---------------------
2018-11-01 10:46:48,733 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:49,153 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:49,254 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:49,354 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:49,444 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:49,468 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:49,469 - Testing sensitivity of module.layer1.1.conv1.weight [10.0% sparsity]
2018-11-01 10:46:49,472 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 10:46:49,474 - --- test ---------------------
2018-11-01 10:46:49,474 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:49,880 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:46:49,981 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:46:50,080 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:46:50,171 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:46:50,195 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:46:50,195 - Testing sensitivity of module.layer1.1.conv1.weight [15.0% sparsity]
2018-11-01 10:46:50,198 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 10:46:50,199 - --- test ---------------------
2018-11-01 10:46:50,199 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:50,608 - Test: [   10/   39]    Loss 0.550954    Top1 91.210938    Top5 99.687500    
2018-11-01 10:46:50,710 - Test: [   20/   39]    Loss 0.552876    Top1 91.464844    Top5 99.589844    
2018-11-01 10:46:50,809 - Test: [   30/   39]    Loss 0.546596    Top1 91.484375    Top5 99.674479    
2018-11-01 10:46:50,900 - Test: [   40/   39]    Loss 0.541798    Top1 91.490000    Top5 99.650000    
2018-11-01 10:46:50,925 - ==> Top1: 91.490    Top5: 99.650    Loss: 0.542

2018-11-01 10:46:50,926 - Testing sensitivity of module.layer1.1.conv1.weight [20.0% sparsity]
2018-11-01 10:46:50,929 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 10:46:50,930 - --- test ---------------------
2018-11-01 10:46:50,930 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:51,335 - Test: [   10/   39]    Loss 0.545483    Top1 91.210938    Top5 99.648438    
2018-11-01 10:46:51,436 - Test: [   20/   39]    Loss 0.551176    Top1 91.484375    Top5 99.570312    
2018-11-01 10:46:51,535 - Test: [   30/   39]    Loss 0.547567    Top1 91.510417    Top5 99.661458    
2018-11-01 10:46:51,626 - Test: [   40/   39]    Loss 0.542039    Top1 91.500000    Top5 99.650000    
2018-11-01 10:46:51,651 - ==> Top1: 91.500    Top5: 99.650    Loss: 0.542

2018-11-01 10:46:51,652 - Testing sensitivity of module.layer1.1.conv1.weight [25.0% sparsity]
2018-11-01 10:46:51,655 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 10:46:51,656 - --- test ---------------------
2018-11-01 10:46:51,657 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:52,063 - Test: [   10/   39]    Loss 0.550394    Top1 91.054688    Top5 99.648438    
2018-11-01 10:46:52,164 - Test: [   20/   39]    Loss 0.553760    Top1 91.367188    Top5 99.570312    
2018-11-01 10:46:52,264 - Test: [   30/   39]    Loss 0.546530    Top1 91.328125    Top5 99.661458    
2018-11-01 10:46:52,355 - Test: [   40/   39]    Loss 0.543430    Top1 91.390000    Top5 99.650000    
2018-11-01 10:46:52,380 - ==> Top1: 91.390    Top5: 99.650    Loss: 0.543

2018-11-01 10:46:52,381 - Testing sensitivity of module.layer1.1.conv1.weight [30.0% sparsity]
2018-11-01 10:46:52,384 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 10:46:52,385 - --- test ---------------------
2018-11-01 10:46:52,385 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:52,792 - Test: [   10/   39]    Loss 0.550394    Top1 91.054688    Top5 99.648438    
2018-11-01 10:46:52,893 - Test: [   20/   39]    Loss 0.553760    Top1 91.367188    Top5 99.570312    
2018-11-01 10:46:52,991 - Test: [   30/   39]    Loss 0.546530    Top1 91.328125    Top5 99.661458    
2018-11-01 10:46:53,082 - Test: [   40/   39]    Loss 0.543430    Top1 91.390000    Top5 99.650000    
2018-11-01 10:46:53,105 - ==> Top1: 91.390    Top5: 99.650    Loss: 0.543

2018-11-01 10:46:53,106 - Testing sensitivity of module.layer1.1.conv1.weight [35.0% sparsity]
2018-11-01 10:46:53,108 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 10:46:53,109 - --- test ---------------------
2018-11-01 10:46:53,109 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:53,506 - Test: [   10/   39]    Loss 0.592039    Top1 90.898438    Top5 99.687500    
2018-11-01 10:46:53,608 - Test: [   20/   39]    Loss 0.580213    Top1 91.152344    Top5 99.609375    
2018-11-01 10:46:53,707 - Test: [   30/   39]    Loss 0.568893    Top1 91.054688    Top5 99.687500    
2018-11-01 10:46:53,798 - Test: [   40/   39]    Loss 0.562768    Top1 91.080000    Top5 99.690000    
2018-11-01 10:46:53,823 - ==> Top1: 91.080    Top5: 99.690    Loss: 0.563

2018-11-01 10:46:53,824 - Testing sensitivity of module.layer1.1.conv1.weight [40.0% sparsity]
2018-11-01 10:46:53,827 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 10:46:53,828 - --- test ---------------------
2018-11-01 10:46:53,828 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:54,238 - Test: [   10/   39]    Loss 0.921969    Top1 85.937500    Top5 99.414062    
2018-11-01 10:46:54,341 - Test: [   20/   39]    Loss 0.902314    Top1 86.191406    Top5 99.394531    
2018-11-01 10:46:54,441 - Test: [   30/   39]    Loss 0.887267    Top1 86.432292    Top5 99.440104    
2018-11-01 10:46:54,533 - Test: [   40/   39]    Loss 0.862493    Top1 86.610000    Top5 99.440000    
2018-11-01 10:46:54,557 - ==> Top1: 86.610    Top5: 99.440    Loss: 0.862

2018-11-01 10:46:54,558 - Testing sensitivity of module.layer1.1.conv1.weight [45.0% sparsity]
2018-11-01 10:46:54,560 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 10:46:54,561 - --- test ---------------------
2018-11-01 10:46:54,561 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:54,973 - Test: [   10/   39]    Loss 0.944233    Top1 85.820312    Top5 99.453125    
2018-11-01 10:46:55,074 - Test: [   20/   39]    Loss 0.925010    Top1 85.996094    Top5 99.453125    
2018-11-01 10:46:55,173 - Test: [   30/   39]    Loss 0.904177    Top1 86.236979    Top5 99.466146    
2018-11-01 10:46:55,263 - Test: [   40/   39]    Loss 0.876593    Top1 86.390000    Top5 99.470000    
2018-11-01 10:46:55,288 - ==> Top1: 86.390    Top5: 99.470    Loss: 0.877

2018-11-01 10:46:55,289 - Testing sensitivity of module.layer1.1.conv1.weight [50.0% sparsity]
2018-11-01 10:46:55,292 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 10:46:55,293 - --- test ---------------------
2018-11-01 10:46:55,293 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:55,709 - Test: [   10/   39]    Loss 1.012174    Top1 85.351562    Top5 99.375000    
2018-11-01 10:46:55,810 - Test: [   20/   39]    Loss 0.988166    Top1 85.214844    Top5 99.394531    
2018-11-01 10:46:55,909 - Test: [   30/   39]    Loss 0.966070    Top1 85.507812    Top5 99.440104    
2018-11-01 10:46:56,000 - Test: [   40/   39]    Loss 0.936240    Top1 85.680000    Top5 99.430000    
2018-11-01 10:46:56,026 - ==> Top1: 85.680    Top5: 99.430    Loss: 0.936

2018-11-01 10:46:56,027 - Testing sensitivity of module.layer1.1.conv1.weight [55.0% sparsity]
2018-11-01 10:46:56,030 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 10:46:56,031 - --- test ---------------------
2018-11-01 10:46:56,031 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:56,437 - Test: [   10/   39]    Loss 1.012174    Top1 85.351562    Top5 99.375000    
2018-11-01 10:46:56,537 - Test: [   20/   39]    Loss 0.988166    Top1 85.214844    Top5 99.394531    
2018-11-01 10:46:56,636 - Test: [   30/   39]    Loss 0.966070    Top1 85.507812    Top5 99.440104    
2018-11-01 10:46:56,727 - Test: [   40/   39]    Loss 0.936240    Top1 85.680000    Top5 99.430000    
2018-11-01 10:46:56,752 - ==> Top1: 85.680    Top5: 99.430    Loss: 0.936

2018-11-01 10:46:56,753 - Testing sensitivity of module.layer1.1.conv1.weight [60.0% sparsity]
2018-11-01 10:46:56,756 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 10:46:56,757 - --- test ---------------------
2018-11-01 10:46:56,757 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:57,173 - Test: [   10/   39]    Loss 1.804650    Top1 76.562500    Top5 98.710938    
2018-11-01 10:46:57,277 - Test: [   20/   39]    Loss 1.730895    Top1 77.324219    Top5 98.808594    
2018-11-01 10:46:57,376 - Test: [   30/   39]    Loss 1.706076    Top1 77.278646    Top5 98.945312    
2018-11-01 10:46:57,467 - Test: [   40/   39]    Loss 1.690617    Top1 77.260000    Top5 98.930000    
2018-11-01 10:46:57,492 - ==> Top1: 77.260    Top5: 98.930    Loss: 1.691

2018-11-01 10:46:57,493 - Testing sensitivity of module.layer1.1.conv1.weight [65.0% sparsity]
2018-11-01 10:46:57,495 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 10:46:57,497 - --- test ---------------------
2018-11-01 10:46:57,497 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:57,905 - Test: [   10/   39]    Loss 0.993520    Top1 85.234375    Top5 98.945312    
2018-11-01 10:46:58,007 - Test: [   20/   39]    Loss 0.929326    Top1 85.625000    Top5 99.179688    
2018-11-01 10:46:58,106 - Test: [   30/   39]    Loss 0.904516    Top1 85.703125    Top5 99.166667    
2018-11-01 10:46:58,197 - Test: [   40/   39]    Loss 0.885397    Top1 85.950000    Top5 99.210000    
2018-11-01 10:46:58,221 - ==> Top1: 85.950    Top5: 99.210    Loss: 0.885

2018-11-01 10:46:58,221 - Testing sensitivity of module.layer1.1.conv1.weight [70.0% sparsity]
2018-11-01 10:46:58,224 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 10:46:58,225 - --- test ---------------------
2018-11-01 10:46:58,225 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:58,638 - Test: [   10/   39]    Loss 1.228875    Top1 81.054688    Top5 98.984375    
2018-11-01 10:46:58,740 - Test: [   20/   39]    Loss 1.180907    Top1 82.089844    Top5 99.003906    
2018-11-01 10:46:58,839 - Test: [   30/   39]    Loss 1.157580    Top1 82.252604    Top5 98.958333    
2018-11-01 10:46:58,930 - Test: [   40/   39]    Loss 1.159635    Top1 82.310000    Top5 99.030000    
2018-11-01 10:46:58,968 - ==> Top1: 82.310    Top5: 99.030    Loss: 1.160

2018-11-01 10:46:58,969 - Testing sensitivity of module.layer1.1.conv1.weight [75.0% sparsity]
2018-11-01 10:46:58,971 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 10:46:58,972 - --- test ---------------------
2018-11-01 10:46:58,972 - 10000 samples (256 per mini-batch)
2018-11-01 10:46:59,390 - Test: [   10/   39]    Loss 1.232232    Top1 81.132812    Top5 99.023438    
2018-11-01 10:46:59,492 - Test: [   20/   39]    Loss 1.181293    Top1 82.050781    Top5 99.023438    
2018-11-01 10:46:59,590 - Test: [   30/   39]    Loss 1.156989    Top1 82.174479    Top5 98.971354    
2018-11-01 10:46:59,681 - Test: [   40/   39]    Loss 1.157670    Top1 82.300000    Top5 99.040000    
2018-11-01 10:46:59,706 - ==> Top1: 82.300    Top5: 99.040    Loss: 1.158

2018-11-01 10:46:59,707 - Testing sensitivity of module.layer1.1.conv1.weight [80.0% sparsity]
2018-11-01 10:46:59,710 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 10:46:59,711 - --- test ---------------------
2018-11-01 10:46:59,711 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:00,137 - Test: [   10/   39]    Loss 1.232232    Top1 81.132812    Top5 99.023438    
2018-11-01 10:47:00,240 - Test: [   20/   39]    Loss 1.181293    Top1 82.050781    Top5 99.023438    
2018-11-01 10:47:00,339 - Test: [   30/   39]    Loss 1.156989    Top1 82.174479    Top5 98.971354    
2018-11-01 10:47:00,430 - Test: [   40/   39]    Loss 1.157670    Top1 82.300000    Top5 99.040000    
2018-11-01 10:47:00,455 - ==> Top1: 82.300    Top5: 99.040    Loss: 1.158

2018-11-01 10:47:00,457 - Testing sensitivity of module.layer1.1.conv1.weight [85.0% sparsity]
2018-11-01 10:47:00,459 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 10:47:00,460 - --- test ---------------------
2018-11-01 10:47:00,460 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:00,885 - Test: [   10/   39]    Loss 1.509714    Top1 77.031250    Top5 98.164062    
2018-11-01 10:47:00,986 - Test: [   20/   39]    Loss 1.468957    Top1 77.402344    Top5 98.105469    
2018-11-01 10:47:01,086 - Test: [   30/   39]    Loss 1.461861    Top1 77.434896    Top5 98.098958    
2018-11-01 10:47:01,176 - Test: [   40/   39]    Loss 1.458256    Top1 77.420000    Top5 98.120000    
2018-11-01 10:47:01,202 - ==> Top1: 77.420    Top5: 98.120    Loss: 1.458

2018-11-01 10:47:01,203 - Testing sensitivity of module.layer1.1.conv1.weight [90.0% sparsity]
2018-11-01 10:47:01,205 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 10:47:01,207 - --- test ---------------------
2018-11-01 10:47:01,207 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:01,611 - Test: [   10/   39]    Loss 1.764102    Top1 71.875000    Top5 97.617188    
2018-11-01 10:47:01,712 - Test: [   20/   39]    Loss 1.763544    Top1 72.656250    Top5 97.460938    
2018-11-01 10:47:01,811 - Test: [   30/   39]    Loss 1.754154    Top1 72.369792    Top5 97.682292    
2018-11-01 10:47:01,902 - Test: [   40/   39]    Loss 1.739825    Top1 72.390000    Top5 97.750000    
2018-11-01 10:47:01,927 - ==> Top1: 72.390    Top5: 97.750    Loss: 1.740

2018-11-01 10:47:01,939 - Testing sensitivity of module.layer1.1.conv2.weight [0.0% sparsity]
2018-11-01 10:47:01,942 - --- test ---------------------
2018-11-01 10:47:01,942 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:02,352 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:02,455 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:02,556 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:02,647 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:02,672 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:02,673 - Testing sensitivity of module.layer1.1.conv2.weight [5.0% sparsity]
2018-11-01 10:47:02,675 - Too few filters - can't prune 5.0% filters
2018-11-01 10:47:02,676 - --- test ---------------------
2018-11-01 10:47:02,676 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:03,112 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:03,221 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:03,329 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:03,426 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:03,451 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:03,451 - Testing sensitivity of module.layer1.1.conv2.weight [10.0% sparsity]
2018-11-01 10:47:03,454 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 10:47:03,455 - --- test ---------------------
2018-11-01 10:47:03,456 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:03,866 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:03,968 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:04,066 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:04,157 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:04,182 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:04,184 - Testing sensitivity of module.layer1.1.conv2.weight [15.0% sparsity]
2018-11-01 10:47:04,188 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 10:47:04,189 - --- test ---------------------
2018-11-01 10:47:04,189 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:04,595 - Test: [   10/   39]    Loss 0.548762    Top1 91.250000    Top5 99.687500    
2018-11-01 10:47:04,699 - Test: [   20/   39]    Loss 0.549556    Top1 91.523438    Top5 99.589844    
2018-11-01 10:47:04,805 - Test: [   30/   39]    Loss 0.543106    Top1 91.575521    Top5 99.674479    
2018-11-01 10:47:04,904 - Test: [   40/   39]    Loss 0.538385    Top1 91.590000    Top5 99.650000    
2018-11-01 10:47:04,948 - ==> Top1: 91.590    Top5: 99.650    Loss: 0.538

2018-11-01 10:47:04,949 - Testing sensitivity of module.layer1.1.conv2.weight [20.0% sparsity]
2018-11-01 10:47:04,953 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 10:47:04,954 - --- test ---------------------
2018-11-01 10:47:04,955 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:05,397 - Test: [   10/   39]    Loss 0.548487    Top1 91.250000    Top5 99.687500    
2018-11-01 10:47:05,499 - Test: [   20/   39]    Loss 0.549322    Top1 91.523438    Top5 99.589844    
2018-11-01 10:47:05,598 - Test: [   30/   39]    Loss 0.543006    Top1 91.575521    Top5 99.674479    
2018-11-01 10:47:05,696 - Test: [   40/   39]    Loss 0.538255    Top1 91.580000    Top5 99.650000    
2018-11-01 10:47:05,722 - ==> Top1: 91.580    Top5: 99.650    Loss: 0.538

2018-11-01 10:47:05,723 - Testing sensitivity of module.layer1.1.conv2.weight [25.0% sparsity]
2018-11-01 10:47:05,727 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 10:47:05,728 - --- test ---------------------
2018-11-01 10:47:05,728 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:06,192 - Test: [   10/   39]    Loss 0.548589    Top1 91.132812    Top5 99.687500    
2018-11-01 10:47:06,301 - Test: [   20/   39]    Loss 0.549418    Top1 91.484375    Top5 99.570312    
2018-11-01 10:47:06,408 - Test: [   30/   39]    Loss 0.542960    Top1 91.562500    Top5 99.661458    
2018-11-01 10:47:06,506 - Test: [   40/   39]    Loss 0.538187    Top1 91.580000    Top5 99.640000    
2018-11-01 10:47:06,507 - ==> Top1: 91.580    Top5: 99.640    Loss: 0.538

2018-11-01 10:47:06,510 - Testing sensitivity of module.layer1.1.conv2.weight [30.0% sparsity]
2018-11-01 10:47:06,513 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 10:47:06,514 - --- test ---------------------
2018-11-01 10:47:06,514 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:06,995 - Test: [   10/   39]    Loss 0.548589    Top1 91.132812    Top5 99.687500    
2018-11-01 10:47:07,106 - Test: [   20/   39]    Loss 0.549418    Top1 91.484375    Top5 99.570312    
2018-11-01 10:47:07,213 - Test: [   30/   39]    Loss 0.542960    Top1 91.562500    Top5 99.661458    
2018-11-01 10:47:07,311 - Test: [   40/   39]    Loss 0.538187    Top1 91.580000    Top5 99.640000    
2018-11-01 10:47:07,336 - ==> Top1: 91.580    Top5: 99.640    Loss: 0.538

2018-11-01 10:47:07,337 - Testing sensitivity of module.layer1.1.conv2.weight [35.0% sparsity]
2018-11-01 10:47:07,340 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 10:47:07,341 - --- test ---------------------
2018-11-01 10:47:07,341 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:07,799 - Test: [   10/   39]    Loss 0.551861    Top1 91.210938    Top5 99.687500    
2018-11-01 10:47:07,908 - Test: [   20/   39]    Loss 0.552436    Top1 91.367188    Top5 99.589844    
2018-11-01 10:47:08,014 - Test: [   30/   39]    Loss 0.547070    Top1 91.419271    Top5 99.674479    
2018-11-01 10:47:08,112 - Test: [   40/   39]    Loss 0.544264    Top1 91.470000    Top5 99.650000    
2018-11-01 10:47:08,137 - ==> Top1: 91.470    Top5: 99.650    Loss: 0.544

2018-11-01 10:47:08,138 - Testing sensitivity of module.layer1.1.conv2.weight [40.0% sparsity]
2018-11-01 10:47:08,141 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 10:47:08,143 - --- test ---------------------
2018-11-01 10:47:08,143 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:08,558 - Test: [   10/   39]    Loss 0.554345    Top1 91.367188    Top5 99.648438    
2018-11-01 10:47:08,661 - Test: [   20/   39]    Loss 0.554111    Top1 91.562500    Top5 99.570312    
2018-11-01 10:47:08,759 - Test: [   30/   39]    Loss 0.548634    Top1 91.562500    Top5 99.661458    
2018-11-01 10:47:08,850 - Test: [   40/   39]    Loss 0.545601    Top1 91.560000    Top5 99.650000    
2018-11-01 10:47:08,875 - ==> Top1: 91.560    Top5: 99.650    Loss: 0.546

2018-11-01 10:47:08,876 - Testing sensitivity of module.layer1.1.conv2.weight [45.0% sparsity]
2018-11-01 10:47:08,879 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 10:47:08,880 - --- test ---------------------
2018-11-01 10:47:08,880 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:09,281 - Test: [   10/   39]    Loss 0.559671    Top1 91.093750    Top5 99.609375    
2018-11-01 10:47:09,383 - Test: [   20/   39]    Loss 0.558656    Top1 91.308594    Top5 99.550781    
2018-11-01 10:47:09,482 - Test: [   30/   39]    Loss 0.553625    Top1 91.315104    Top5 99.648438    
2018-11-01 10:47:09,573 - Test: [   40/   39]    Loss 0.551691    Top1 91.330000    Top5 99.640000    
2018-11-01 10:47:09,603 - ==> Top1: 91.330    Top5: 99.640    Loss: 0.552

2018-11-01 10:47:09,604 - Testing sensitivity of module.layer1.1.conv2.weight [50.0% sparsity]
2018-11-01 10:47:09,607 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 10:47:09,608 - --- test ---------------------
2018-11-01 10:47:09,609 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:10,017 - Test: [   10/   39]    Loss 0.568500    Top1 90.898438    Top5 99.609375    
2018-11-01 10:47:10,118 - Test: [   20/   39]    Loss 0.566802    Top1 91.230469    Top5 99.550781    
2018-11-01 10:47:10,217 - Test: [   30/   39]    Loss 0.560108    Top1 91.132812    Top5 99.622396    
2018-11-01 10:47:10,308 - Test: [   40/   39]    Loss 0.558489    Top1 91.200000    Top5 99.630000    
2018-11-01 10:47:10,332 - ==> Top1: 91.200    Top5: 99.630    Loss: 0.558

2018-11-01 10:47:10,333 - Testing sensitivity of module.layer1.1.conv2.weight [55.0% sparsity]
2018-11-01 10:47:10,336 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 10:47:10,337 - --- test ---------------------
2018-11-01 10:47:10,338 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:10,749 - Test: [   10/   39]    Loss 0.568500    Top1 90.898438    Top5 99.609375    
2018-11-01 10:47:10,851 - Test: [   20/   39]    Loss 0.566802    Top1 91.230469    Top5 99.550781    
2018-11-01 10:47:10,950 - Test: [   30/   39]    Loss 0.560108    Top1 91.132812    Top5 99.622396    
2018-11-01 10:47:11,041 - Test: [   40/   39]    Loss 0.558489    Top1 91.200000    Top5 99.630000    
2018-11-01 10:47:11,065 - ==> Top1: 91.200    Top5: 99.630    Loss: 0.558

2018-11-01 10:47:11,066 - Testing sensitivity of module.layer1.1.conv2.weight [60.0% sparsity]
2018-11-01 10:47:11,069 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 10:47:11,070 - --- test ---------------------
2018-11-01 10:47:11,071 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:11,480 - Test: [   10/   39]    Loss 0.592767    Top1 90.664062    Top5 99.531250    
2018-11-01 10:47:11,583 - Test: [   20/   39]    Loss 0.592041    Top1 90.878906    Top5 99.531250    
2018-11-01 10:47:11,681 - Test: [   30/   39]    Loss 0.581928    Top1 90.781250    Top5 99.622396    
2018-11-01 10:47:11,772 - Test: [   40/   39]    Loss 0.580074    Top1 90.850000    Top5 99.630000    
2018-11-01 10:47:11,797 - ==> Top1: 90.850    Top5: 99.630    Loss: 0.580

2018-11-01 10:47:11,798 - Testing sensitivity of module.layer1.1.conv2.weight [65.0% sparsity]
2018-11-01 10:47:11,801 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 10:47:11,802 - --- test ---------------------
2018-11-01 10:47:11,802 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:12,260 - Test: [   10/   39]    Loss 0.618639    Top1 90.273438    Top5 99.570312    
2018-11-01 10:47:12,367 - Test: [   20/   39]    Loss 0.623154    Top1 90.410156    Top5 99.492188    
2018-11-01 10:47:12,472 - Test: [   30/   39]    Loss 0.613550    Top1 90.286458    Top5 99.583333    
2018-11-01 10:47:12,569 - Test: [   40/   39]    Loss 0.611478    Top1 90.290000    Top5 99.590000    
2018-11-01 10:47:12,594 - ==> Top1: 90.290    Top5: 99.590    Loss: 0.611

2018-11-01 10:47:12,596 - Testing sensitivity of module.layer1.1.conv2.weight [70.0% sparsity]
2018-11-01 10:47:12,599 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 10:47:12,600 - --- test ---------------------
2018-11-01 10:47:12,600 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:13,048 - Test: [   10/   39]    Loss 0.627863    Top1 90.000000    Top5 99.570312    
2018-11-01 10:47:13,150 - Test: [   20/   39]    Loss 0.627912    Top1 90.292969    Top5 99.492188    
2018-11-01 10:47:13,249 - Test: [   30/   39]    Loss 0.616434    Top1 90.234375    Top5 99.596354    
2018-11-01 10:47:13,340 - Test: [   40/   39]    Loss 0.608397    Top1 90.290000    Top5 99.600000    
2018-11-01 10:47:13,365 - ==> Top1: 90.290    Top5: 99.600    Loss: 0.608

2018-11-01 10:47:13,366 - Testing sensitivity of module.layer1.1.conv2.weight [75.0% sparsity]
2018-11-01 10:47:13,368 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 10:47:13,369 - --- test ---------------------
2018-11-01 10:47:13,369 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:13,777 - Test: [   10/   39]    Loss 0.648668    Top1 89.882812    Top5 99.765625    
2018-11-01 10:47:13,880 - Test: [   20/   39]    Loss 0.644815    Top1 90.117188    Top5 99.609375    
2018-11-01 10:47:13,979 - Test: [   30/   39]    Loss 0.638136    Top1 89.921875    Top5 99.648438    
2018-11-01 10:47:14,070 - Test: [   40/   39]    Loss 0.632887    Top1 89.960000    Top5 99.640000    
2018-11-01 10:47:14,095 - ==> Top1: 89.960    Top5: 99.640    Loss: 0.633

2018-11-01 10:47:14,096 - Testing sensitivity of module.layer1.1.conv2.weight [80.0% sparsity]
2018-11-01 10:47:14,098 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 10:47:14,099 - --- test ---------------------
2018-11-01 10:47:14,099 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:14,502 - Test: [   10/   39]    Loss 0.648668    Top1 89.882812    Top5 99.765625    
2018-11-01 10:47:14,604 - Test: [   20/   39]    Loss 0.644815    Top1 90.117188    Top5 99.609375    
2018-11-01 10:47:14,702 - Test: [   30/   39]    Loss 0.638136    Top1 89.921875    Top5 99.648438    
2018-11-01 10:47:14,793 - Test: [   40/   39]    Loss 0.632887    Top1 89.960000    Top5 99.640000    
2018-11-01 10:47:14,818 - ==> Top1: 89.960    Top5: 99.640    Loss: 0.633

2018-11-01 10:47:14,819 - Testing sensitivity of module.layer1.1.conv2.weight [85.0% sparsity]
2018-11-01 10:47:14,822 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 10:47:14,823 - --- test ---------------------
2018-11-01 10:47:14,823 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:15,237 - Test: [   10/   39]    Loss 0.774998    Top1 88.164062    Top5 99.648438    
2018-11-01 10:47:15,338 - Test: [   20/   39]    Loss 0.757807    Top1 88.437500    Top5 99.511719    
2018-11-01 10:47:15,437 - Test: [   30/   39]    Loss 0.742259    Top1 88.619792    Top5 99.570312    
2018-11-01 10:47:15,528 - Test: [   40/   39]    Loss 0.746111    Top1 88.700000    Top5 99.580000    
2018-11-01 10:47:15,553 - ==> Top1: 88.700    Top5: 99.580    Loss: 0.746

2018-11-01 10:47:15,553 - Testing sensitivity of module.layer1.1.conv2.weight [90.0% sparsity]
2018-11-01 10:47:15,556 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 10:47:15,556 - --- test ---------------------
2018-11-01 10:47:15,557 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:15,975 - Test: [   10/   39]    Loss 0.829447    Top1 87.109375    Top5 99.648438    
2018-11-01 10:47:16,077 - Test: [   20/   39]    Loss 0.800121    Top1 87.773438    Top5 99.511719    
2018-11-01 10:47:16,176 - Test: [   30/   39]    Loss 0.794036    Top1 87.955729    Top5 99.505208    
2018-11-01 10:47:16,267 - Test: [   40/   39]    Loss 0.791344    Top1 88.080000    Top5 99.520000    
2018-11-01 10:47:16,291 - ==> Top1: 88.080    Top5: 99.520    Loss: 0.791

2018-11-01 10:47:16,305 - Testing sensitivity of module.layer1.2.conv1.weight [0.0% sparsity]
2018-11-01 10:47:16,308 - --- test ---------------------
2018-11-01 10:47:16,309 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:16,723 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:16,826 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:16,925 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:17,016 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:17,043 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:17,044 - Testing sensitivity of module.layer1.2.conv1.weight [5.0% sparsity]
2018-11-01 10:47:17,047 - Too few filters - can't prune 5.0% filters
2018-11-01 10:47:17,048 - --- test ---------------------
2018-11-01 10:47:17,048 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:17,465 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:17,566 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:17,665 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:17,756 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:17,781 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:17,782 - Testing sensitivity of module.layer1.2.conv1.weight [10.0% sparsity]
2018-11-01 10:47:17,785 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 10:47:17,787 - --- test ---------------------
2018-11-01 10:47:17,787 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:18,205 - Test: [   10/   39]    Loss 0.555135    Top1 91.328125    Top5 99.609375    
2018-11-01 10:47:18,307 - Test: [   20/   39]    Loss 0.555799    Top1 91.503906    Top5 99.531250    
2018-11-01 10:47:18,408 - Test: [   30/   39]    Loss 0.550050    Top1 91.432292    Top5 99.635417    
2018-11-01 10:47:18,505 - Test: [   40/   39]    Loss 0.541964    Top1 91.440000    Top5 99.640000    
2018-11-01 10:47:18,543 - ==> Top1: 91.440    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:18,543 - Testing sensitivity of module.layer1.2.conv1.weight [15.0% sparsity]
2018-11-01 10:47:18,546 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 10:47:18,547 - --- test ---------------------
2018-11-01 10:47:18,547 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:19,003 - Test: [   10/   39]    Loss 3.153981    Top1 64.531250    Top5 97.382812    
2018-11-01 10:47:19,109 - Test: [   20/   39]    Loss 3.119490    Top1 65.585938    Top5 97.382812    
2018-11-01 10:47:19,215 - Test: [   30/   39]    Loss 3.099405    Top1 65.468750    Top5 97.513021    
2018-11-01 10:47:19,313 - Test: [   40/   39]    Loss 3.031393    Top1 65.250000    Top5 97.570000    
2018-11-01 10:47:19,342 - ==> Top1: 65.250    Top5: 97.570    Loss: 3.031

2018-11-01 10:47:19,342 - Testing sensitivity of module.layer1.2.conv1.weight [20.0% sparsity]
2018-11-01 10:47:19,345 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 10:47:19,346 - --- test ---------------------
2018-11-01 10:47:19,347 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:19,759 - Test: [   10/   39]    Loss 3.352137    Top1 62.773437    Top5 97.226562    
2018-11-01 10:47:19,860 - Test: [   20/   39]    Loss 3.324262    Top1 64.062500    Top5 97.167969    
2018-11-01 10:47:19,959 - Test: [   30/   39]    Loss 3.298804    Top1 64.010417    Top5 97.356771    
2018-11-01 10:47:20,050 - Test: [   40/   39]    Loss 3.234562    Top1 63.720000    Top5 97.380000    
2018-11-01 10:47:20,075 - ==> Top1: 63.720    Top5: 97.380    Loss: 3.235

2018-11-01 10:47:20,077 - Testing sensitivity of module.layer1.2.conv1.weight [25.0% sparsity]
2018-11-01 10:47:20,080 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 10:47:20,081 - --- test ---------------------
2018-11-01 10:47:20,081 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:20,494 - Test: [   10/   39]    Loss 3.017801    Top1 65.976562    Top5 97.578125    
2018-11-01 10:47:20,595 - Test: [   20/   39]    Loss 3.011159    Top1 66.816406    Top5 97.597656    
2018-11-01 10:47:20,694 - Test: [   30/   39]    Loss 2.987074    Top1 66.432292    Top5 97.682292    
2018-11-01 10:47:20,785 - Test: [   40/   39]    Loss 2.926190    Top1 66.180000    Top5 97.770000    
2018-11-01 10:47:20,810 - ==> Top1: 66.180    Top5: 97.770    Loss: 2.926

2018-11-01 10:47:20,811 - Testing sensitivity of module.layer1.2.conv1.weight [30.0% sparsity]
2018-11-01 10:47:20,813 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 10:47:20,814 - --- test ---------------------
2018-11-01 10:47:20,814 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:21,230 - Test: [   10/   39]    Loss 3.017801    Top1 65.976562    Top5 97.578125    
2018-11-01 10:47:21,333 - Test: [   20/   39]    Loss 3.011159    Top1 66.816406    Top5 97.597656    
2018-11-01 10:47:21,432 - Test: [   30/   39]    Loss 2.987074    Top1 66.432292    Top5 97.682292    
2018-11-01 10:47:21,523 - Test: [   40/   39]    Loss 2.926190    Top1 66.180000    Top5 97.770000    
2018-11-01 10:47:21,548 - ==> Top1: 66.180    Top5: 97.770    Loss: 2.926

2018-11-01 10:47:21,550 - Testing sensitivity of module.layer1.2.conv1.weight [35.0% sparsity]
2018-11-01 10:47:21,553 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 10:47:21,554 - --- test ---------------------
2018-11-01 10:47:21,554 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:21,968 - Test: [   10/   39]    Loss 2.915782    Top1 66.835938    Top5 97.695312    
2018-11-01 10:47:22,070 - Test: [   20/   39]    Loss 2.912158    Top1 67.519531    Top5 97.812500    
2018-11-01 10:47:22,169 - Test: [   30/   39]    Loss 2.892032    Top1 67.213542    Top5 97.799479    
2018-11-01 10:47:22,261 - Test: [   40/   39]    Loss 2.834192    Top1 66.890000    Top5 97.880000    
2018-11-01 10:47:22,285 - ==> Top1: 66.890    Top5: 97.880    Loss: 2.834

2018-11-01 10:47:22,286 - Testing sensitivity of module.layer1.2.conv1.weight [40.0% sparsity]
2018-11-01 10:47:22,289 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 10:47:22,290 - --- test ---------------------
2018-11-01 10:47:22,290 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:22,701 - Test: [   10/   39]    Loss 3.165278    Top1 65.078125    Top5 97.382812    
2018-11-01 10:47:22,803 - Test: [   20/   39]    Loss 3.157792    Top1 65.683594    Top5 97.402344    
2018-11-01 10:47:22,902 - Test: [   30/   39]    Loss 3.127536    Top1 65.468750    Top5 97.591146    
2018-11-01 10:47:22,993 - Test: [   40/   39]    Loss 3.075815    Top1 65.070000    Top5 97.610000    
2018-11-01 10:47:23,004 - ==> Top1: 65.070    Top5: 97.610    Loss: 3.076

2018-11-01 10:47:23,024 - Testing sensitivity of module.layer1.2.conv1.weight [45.0% sparsity]
2018-11-01 10:47:23,028 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 10:47:23,029 - --- test ---------------------
2018-11-01 10:47:23,030 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:23,475 - Test: [   10/   39]    Loss 3.730216    Top1 59.609375    Top5 96.406250    
2018-11-01 10:47:23,581 - Test: [   20/   39]    Loss 3.731064    Top1 60.722656    Top5 96.328125    
2018-11-01 10:47:23,686 - Test: [   30/   39]    Loss 3.690515    Top1 60.377604    Top5 96.432292    
2018-11-01 10:47:23,783 - Test: [   40/   39]    Loss 3.652502    Top1 59.910000    Top5 96.450000    
2018-11-01 10:47:23,808 - ==> Top1: 59.910    Top5: 96.450    Loss: 3.653

2018-11-01 10:47:23,809 - Testing sensitivity of module.layer1.2.conv1.weight [50.0% sparsity]
2018-11-01 10:47:23,812 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 10:47:23,813 - --- test ---------------------
2018-11-01 10:47:23,813 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:24,262 - Test: [   10/   39]    Loss 4.109321    Top1 57.578125    Top5 95.820312    
2018-11-01 10:47:24,370 - Test: [   20/   39]    Loss 4.102451    Top1 58.300781    Top5 95.859375    
2018-11-01 10:47:24,476 - Test: [   30/   39]    Loss 4.054774    Top1 57.825521    Top5 96.184896    
2018-11-01 10:47:24,573 - Test: [   40/   39]    Loss 4.035542    Top1 57.570000    Top5 96.220000    
2018-11-01 10:47:24,599 - ==> Top1: 57.570    Top5: 96.220    Loss: 4.036

2018-11-01 10:47:24,600 - Testing sensitivity of module.layer1.2.conv1.weight [55.0% sparsity]
2018-11-01 10:47:24,602 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 10:47:24,604 - --- test ---------------------
2018-11-01 10:47:24,604 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:25,035 - Test: [   10/   39]    Loss 4.109321    Top1 57.578125    Top5 95.820312    
2018-11-01 10:47:25,137 - Test: [   20/   39]    Loss 4.102451    Top1 58.300781    Top5 95.859375    
2018-11-01 10:47:25,235 - Test: [   30/   39]    Loss 4.054774    Top1 57.825521    Top5 96.184896    
2018-11-01 10:47:25,326 - Test: [   40/   39]    Loss 4.035542    Top1 57.570000    Top5 96.220000    
2018-11-01 10:47:25,350 - ==> Top1: 57.570    Top5: 96.220    Loss: 4.036

2018-11-01 10:47:25,351 - Testing sensitivity of module.layer1.2.conv1.weight [60.0% sparsity]
2018-11-01 10:47:25,353 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 10:47:25,354 - --- test ---------------------
2018-11-01 10:47:25,354 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:25,761 - Test: [   10/   39]    Loss 4.678684    Top1 55.429688    Top5 96.054688    
2018-11-01 10:47:25,863 - Test: [   20/   39]    Loss 4.673912    Top1 56.445312    Top5 95.703125    
2018-11-01 10:47:25,962 - Test: [   30/   39]    Loss 4.667108    Top1 55.898438    Top5 95.898438    
2018-11-01 10:47:26,053 - Test: [   40/   39]    Loss 4.662773    Top1 55.370000    Top5 95.930000    
2018-11-01 10:47:26,082 - ==> Top1: 55.370    Top5: 95.930    Loss: 4.663

2018-11-01 10:47:26,082 - Testing sensitivity of module.layer1.2.conv1.weight [65.0% sparsity]
2018-11-01 10:47:26,086 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 10:47:26,087 - --- test ---------------------
2018-11-01 10:47:26,087 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:26,548 - Test: [   10/   39]    Loss 4.370702    Top1 55.937500    Top5 95.390625    
2018-11-01 10:47:26,655 - Test: [   20/   39]    Loss 4.402131    Top1 56.425781    Top5 95.351562    
2018-11-01 10:47:26,761 - Test: [   30/   39]    Loss 4.442170    Top1 56.002604    Top5 95.585938    
2018-11-01 10:47:26,859 - Test: [   40/   39]    Loss 4.480815    Top1 55.650000    Top5 95.730000    
2018-11-01 10:47:26,860 - ==> Top1: 55.650    Top5: 95.730    Loss: 4.481

2018-11-01 10:47:26,863 - Testing sensitivity of module.layer1.2.conv1.weight [70.0% sparsity]
2018-11-01 10:47:26,866 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 10:47:26,867 - --- test ---------------------
2018-11-01 10:47:26,868 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:27,321 - Test: [   10/   39]    Loss 5.678392    Top1 48.398438    Top5 93.281250    
2018-11-01 10:47:27,423 - Test: [   20/   39]    Loss 5.649397    Top1 49.042969    Top5 92.968750    
2018-11-01 10:47:27,521 - Test: [   30/   39]    Loss 5.720738    Top1 47.968750    Top5 93.203125    
2018-11-01 10:47:27,612 - Test: [   40/   39]    Loss 5.782204    Top1 47.500000    Top5 93.120000    
2018-11-01 10:47:27,638 - ==> Top1: 47.500    Top5: 93.120    Loss: 5.782

2018-11-01 10:47:27,639 - Testing sensitivity of module.layer1.2.conv1.weight [75.0% sparsity]
2018-11-01 10:47:27,642 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 10:47:27,643 - --- test ---------------------
2018-11-01 10:47:27,643 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:28,061 - Test: [   10/   39]    Loss 4.824542    Top1 50.703125    Top5 94.414062    
2018-11-01 10:47:28,163 - Test: [   20/   39]    Loss 4.827679    Top1 51.542969    Top5 94.257812    
2018-11-01 10:47:28,262 - Test: [   30/   39]    Loss 4.835093    Top1 51.119792    Top5 94.557292    
2018-11-01 10:47:28,353 - Test: [   40/   39]    Loss 4.879466    Top1 50.790000    Top5 94.420000    
2018-11-01 10:47:28,377 - ==> Top1: 50.790    Top5: 94.420    Loss: 4.879

2018-11-01 10:47:28,378 - Testing sensitivity of module.layer1.2.conv1.weight [80.0% sparsity]
2018-11-01 10:47:28,381 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 10:47:28,382 - --- test ---------------------
2018-11-01 10:47:28,383 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:28,813 - Test: [   10/   39]    Loss 4.824542    Top1 50.703125    Top5 94.414062    
2018-11-01 10:47:28,920 - Test: [   20/   39]    Loss 4.827679    Top1 51.542969    Top5 94.257812    
2018-11-01 10:47:29,026 - Test: [   30/   39]    Loss 4.835093    Top1 51.119792    Top5 94.557292    
2018-11-01 10:47:29,122 - Test: [   40/   39]    Loss 4.879466    Top1 50.790000    Top5 94.420000    
2018-11-01 10:47:29,149 - ==> Top1: 50.790    Top5: 94.420    Loss: 4.879

2018-11-01 10:47:29,150 - Testing sensitivity of module.layer1.2.conv1.weight [85.0% sparsity]
2018-11-01 10:47:29,154 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 10:47:29,156 - --- test ---------------------
2018-11-01 10:47:29,156 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:29,618 - Test: [   10/   39]    Loss 6.388870    Top1 40.507812    Top5 90.273438    
2018-11-01 10:47:29,725 - Test: [   20/   39]    Loss 6.396517    Top1 41.328125    Top5 90.390625    
2018-11-01 10:47:29,831 - Test: [   30/   39]    Loss 6.457817    Top1 40.664062    Top5 90.690104    
2018-11-01 10:47:29,928 - Test: [   40/   39]    Loss 6.493794    Top1 40.040000    Top5 90.520000    
2018-11-01 10:47:29,953 - ==> Top1: 40.040    Top5: 90.520    Loss: 6.494

2018-11-01 10:47:29,953 - Testing sensitivity of module.layer1.2.conv1.weight [90.0% sparsity]
2018-11-01 10:47:29,956 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 10:47:29,957 - --- test ---------------------
2018-11-01 10:47:29,957 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:30,381 - Test: [   10/   39]    Loss 8.090513    Top1 35.351562    Top5 89.023438    
2018-11-01 10:47:30,482 - Test: [   20/   39]    Loss 8.075939    Top1 35.820312    Top5 88.847656    
2018-11-01 10:47:30,581 - Test: [   30/   39]    Loss 8.155878    Top1 35.182292    Top5 89.010417    
2018-11-01 10:47:30,671 - Test: [   40/   39]    Loss 8.227444    Top1 34.650000    Top5 88.820000    
2018-11-01 10:47:30,697 - ==> Top1: 34.650    Top5: 88.820    Loss: 8.227

2018-11-01 10:47:30,708 - Testing sensitivity of module.layer1.2.conv2.weight [0.0% sparsity]
2018-11-01 10:47:30,711 - --- test ---------------------
2018-11-01 10:47:30,711 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:31,118 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:31,228 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:31,333 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:31,431 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:31,459 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:31,460 - Testing sensitivity of module.layer1.2.conv2.weight [5.0% sparsity]
2018-11-01 10:47:31,462 - Too few filters - can't prune 5.0% filters
2018-11-01 10:47:31,463 - --- test ---------------------
2018-11-01 10:47:31,463 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:31,915 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:32,023 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:32,128 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:32,226 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:32,264 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:32,265 - Testing sensitivity of module.layer1.2.conv2.weight [10.0% sparsity]
2018-11-01 10:47:32,267 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 10:47:32,268 - --- test ---------------------
2018-11-01 10:47:32,269 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:32,725 - Test: [   10/   39]    Loss 0.551738    Top1 91.328125    Top5 99.687500    
2018-11-01 10:47:32,832 - Test: [   20/   39]    Loss 0.553006    Top1 91.503906    Top5 99.570312    
2018-11-01 10:47:32,937 - Test: [   30/   39]    Loss 0.546293    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:33,028 - Test: [   40/   39]    Loss 0.541529    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:33,052 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:33,052 - Testing sensitivity of module.layer1.2.conv2.weight [15.0% sparsity]
2018-11-01 10:47:33,056 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 10:47:33,057 - --- test ---------------------
2018-11-01 10:47:33,057 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:33,466 - Test: [   10/   39]    Loss 0.551993    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:33,567 - Test: [   20/   39]    Loss 0.553096    Top1 91.523438    Top5 99.570312    
2018-11-01 10:47:33,666 - Test: [   30/   39]    Loss 0.546500    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:33,757 - Test: [   40/   39]    Loss 0.542004    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:33,781 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:33,782 - Testing sensitivity of module.layer1.2.conv2.weight [20.0% sparsity]
2018-11-01 10:47:33,785 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 10:47:33,787 - --- test ---------------------
2018-11-01 10:47:33,787 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:34,199 - Test: [   10/   39]    Loss 0.551919    Top1 91.328125    Top5 99.687500    
2018-11-01 10:47:34,308 - Test: [   20/   39]    Loss 0.552580    Top1 91.562500    Top5 99.570312    
2018-11-01 10:47:34,414 - Test: [   30/   39]    Loss 0.546292    Top1 91.562500    Top5 99.661458    
2018-11-01 10:47:34,512 - Test: [   40/   39]    Loss 0.541991    Top1 91.540000    Top5 99.640000    
2018-11-01 10:47:34,552 - ==> Top1: 91.540    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:34,552 - Testing sensitivity of module.layer1.2.conv2.weight [25.0% sparsity]
2018-11-01 10:47:34,554 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 10:47:34,555 - --- test ---------------------
2018-11-01 10:47:34,555 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:35,012 - Test: [   10/   39]    Loss 0.551431    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:35,118 - Test: [   20/   39]    Loss 0.552159    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:35,220 - Test: [   30/   39]    Loss 0.545960    Top1 91.562500    Top5 99.661458    
2018-11-01 10:47:35,312 - Test: [   40/   39]    Loss 0.541649    Top1 91.550000    Top5 99.640000    
2018-11-01 10:47:35,337 - ==> Top1: 91.550    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:35,338 - Testing sensitivity of module.layer1.2.conv2.weight [30.0% sparsity]
2018-11-01 10:47:35,341 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 10:47:35,343 - --- test ---------------------
2018-11-01 10:47:35,343 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:35,745 - Test: [   10/   39]    Loss 0.551431    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:35,847 - Test: [   20/   39]    Loss 0.552159    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:35,946 - Test: [   30/   39]    Loss 0.545960    Top1 91.562500    Top5 99.661458    
2018-11-01 10:47:36,037 - Test: [   40/   39]    Loss 0.541649    Top1 91.550000    Top5 99.640000    
2018-11-01 10:47:36,063 - ==> Top1: 91.550    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:36,063 - Testing sensitivity of module.layer1.2.conv2.weight [35.0% sparsity]
2018-11-01 10:47:36,066 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 10:47:36,067 - --- test ---------------------
2018-11-01 10:47:36,067 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:36,472 - Test: [   10/   39]    Loss 0.551435    Top1 91.328125    Top5 99.687500    
2018-11-01 10:47:36,574 - Test: [   20/   39]    Loss 0.552200    Top1 91.582031    Top5 99.570312    
2018-11-01 10:47:36,673 - Test: [   30/   39]    Loss 0.546003    Top1 91.575521    Top5 99.661458    
2018-11-01 10:47:36,763 - Test: [   40/   39]    Loss 0.541691    Top1 91.560000    Top5 99.640000    
2018-11-01 10:47:36,789 - ==> Top1: 91.560    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:36,790 - Testing sensitivity of module.layer1.2.conv2.weight [40.0% sparsity]
2018-11-01 10:47:36,793 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 10:47:36,794 - --- test ---------------------
2018-11-01 10:47:36,794 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:37,206 - Test: [   10/   39]    Loss 0.573553    Top1 91.054688    Top5 99.609375    
2018-11-01 10:47:37,308 - Test: [   20/   39]    Loss 0.567451    Top1 91.250000    Top5 99.531250    
2018-11-01 10:47:37,407 - Test: [   30/   39]    Loss 0.560721    Top1 91.106771    Top5 99.622396    
2018-11-01 10:47:37,498 - Test: [   40/   39]    Loss 0.557485    Top1 91.210000    Top5 99.630000    
2018-11-01 10:47:37,523 - ==> Top1: 91.210    Top5: 99.630    Loss: 0.557

2018-11-01 10:47:37,523 - Testing sensitivity of module.layer1.2.conv2.weight [45.0% sparsity]
2018-11-01 10:47:37,526 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 10:47:37,527 - --- test ---------------------
2018-11-01 10:47:37,527 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:37,939 - Test: [   10/   39]    Loss 0.613039    Top1 90.507812    Top5 99.492188    
2018-11-01 10:47:38,043 - Test: [   20/   39]    Loss 0.604801    Top1 90.839844    Top5 99.492188    
2018-11-01 10:47:38,141 - Test: [   30/   39]    Loss 0.601425    Top1 90.729167    Top5 99.570312    
2018-11-01 10:47:38,232 - Test: [   40/   39]    Loss 0.597763    Top1 90.790000    Top5 99.580000    
2018-11-01 10:47:38,257 - ==> Top1: 90.790    Top5: 99.580    Loss: 0.598

2018-11-01 10:47:38,258 - Testing sensitivity of module.layer1.2.conv2.weight [50.0% sparsity]
2018-11-01 10:47:38,262 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 10:47:38,263 - --- test ---------------------
2018-11-01 10:47:38,263 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:38,671 - Test: [   10/   39]    Loss 0.635181    Top1 90.312500    Top5 99.453125    
2018-11-01 10:47:38,773 - Test: [   20/   39]    Loss 0.623764    Top1 90.722656    Top5 99.492188    
2018-11-01 10:47:38,872 - Test: [   30/   39]    Loss 0.625552    Top1 90.494792    Top5 99.544271    
2018-11-01 10:47:38,963 - Test: [   40/   39]    Loss 0.617276    Top1 90.630000    Top5 99.540000    
2018-11-01 10:47:38,989 - ==> Top1: 90.630    Top5: 99.540    Loss: 0.617

2018-11-01 10:47:38,990 - Testing sensitivity of module.layer1.2.conv2.weight [55.0% sparsity]
2018-11-01 10:47:38,992 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 10:47:38,994 - --- test ---------------------
2018-11-01 10:47:38,994 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:39,401 - Test: [   10/   39]    Loss 0.635181    Top1 90.312500    Top5 99.453125    
2018-11-01 10:47:39,504 - Test: [   20/   39]    Loss 0.623764    Top1 90.722656    Top5 99.492188    
2018-11-01 10:47:39,603 - Test: [   30/   39]    Loss 0.625552    Top1 90.494792    Top5 99.544271    
2018-11-01 10:47:39,694 - Test: [   40/   39]    Loss 0.617276    Top1 90.630000    Top5 99.540000    
2018-11-01 10:47:39,720 - ==> Top1: 90.630    Top5: 99.540    Loss: 0.617

2018-11-01 10:47:39,721 - Testing sensitivity of module.layer1.2.conv2.weight [60.0% sparsity]
2018-11-01 10:47:39,724 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 10:47:39,725 - --- test ---------------------
2018-11-01 10:47:39,726 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:40,133 - Test: [   10/   39]    Loss 0.638617    Top1 89.921875    Top5 99.414062    
2018-11-01 10:47:40,235 - Test: [   20/   39]    Loss 0.628696    Top1 90.371094    Top5 99.433594    
2018-11-01 10:47:40,333 - Test: [   30/   39]    Loss 0.634247    Top1 90.273438    Top5 99.453125    
2018-11-01 10:47:40,424 - Test: [   40/   39]    Loss 0.624181    Top1 90.360000    Top5 99.460000    
2018-11-01 10:47:40,440 - ==> Top1: 90.360    Top5: 99.460    Loss: 0.624

2018-11-01 10:47:40,454 - Testing sensitivity of module.layer1.2.conv2.weight [65.0% sparsity]
2018-11-01 10:47:40,456 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 10:47:40,457 - --- test ---------------------
2018-11-01 10:47:40,457 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:40,858 - Test: [   10/   39]    Loss 0.726991    Top1 88.476562    Top5 99.335938    
2018-11-01 10:47:40,960 - Test: [   20/   39]    Loss 0.706391    Top1 89.042969    Top5 99.433594    
2018-11-01 10:47:41,059 - Test: [   30/   39]    Loss 0.703311    Top1 89.010417    Top5 99.492188    
2018-11-01 10:47:41,150 - Test: [   40/   39]    Loss 0.688343    Top1 89.050000    Top5 99.490000    
2018-11-01 10:47:41,176 - ==> Top1: 89.050    Top5: 99.490    Loss: 0.688

2018-11-01 10:47:41,176 - Testing sensitivity of module.layer1.2.conv2.weight [70.0% sparsity]
2018-11-01 10:47:41,180 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 10:47:41,181 - --- test ---------------------
2018-11-01 10:47:41,182 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:41,581 - Test: [   10/   39]    Loss 0.744470    Top1 88.203125    Top5 99.296875    
2018-11-01 10:47:41,682 - Test: [   20/   39]    Loss 0.724236    Top1 88.847656    Top5 99.375000    
2018-11-01 10:47:41,781 - Test: [   30/   39]    Loss 0.714999    Top1 89.049479    Top5 99.401042    
2018-11-01 10:47:41,872 - Test: [   40/   39]    Loss 0.702811    Top1 89.000000    Top5 99.420000    
2018-11-01 10:47:41,896 - ==> Top1: 89.000    Top5: 99.420    Loss: 0.703

2018-11-01 10:47:41,897 - Testing sensitivity of module.layer1.2.conv2.weight [75.0% sparsity]
2018-11-01 10:47:41,899 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 10:47:41,900 - --- test ---------------------
2018-11-01 10:47:41,900 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:42,313 - Test: [   10/   39]    Loss 0.738595    Top1 88.867188    Top5 99.335938    
2018-11-01 10:47:42,419 - Test: [   20/   39]    Loss 0.705971    Top1 89.062500    Top5 99.394531    
2018-11-01 10:47:42,518 - Test: [   30/   39]    Loss 0.703214    Top1 89.088542    Top5 99.414062    
2018-11-01 10:47:42,609 - Test: [   40/   39]    Loss 0.691896    Top1 89.000000    Top5 99.430000    
2018-11-01 10:47:42,636 - ==> Top1: 89.000    Top5: 99.430    Loss: 0.692

2018-11-01 10:47:42,636 - Testing sensitivity of module.layer1.2.conv2.weight [80.0% sparsity]
2018-11-01 10:47:42,640 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 10:47:42,641 - --- test ---------------------
2018-11-01 10:47:42,642 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:43,062 - Test: [   10/   39]    Loss 0.738595    Top1 88.867188    Top5 99.335938    
2018-11-01 10:47:43,164 - Test: [   20/   39]    Loss 0.705971    Top1 89.062500    Top5 99.394531    
2018-11-01 10:47:43,263 - Test: [   30/   39]    Loss 0.703214    Top1 89.088542    Top5 99.414062    
2018-11-01 10:47:43,354 - Test: [   40/   39]    Loss 0.691896    Top1 89.000000    Top5 99.430000    
2018-11-01 10:47:43,386 - ==> Top1: 89.000    Top5: 99.430    Loss: 0.692

2018-11-01 10:47:43,386 - Testing sensitivity of module.layer1.2.conv2.weight [85.0% sparsity]
2018-11-01 10:47:43,389 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 10:47:43,390 - --- test ---------------------
2018-11-01 10:47:43,390 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:43,794 - Test: [   10/   39]    Loss 0.799377    Top1 87.539062    Top5 99.101562    
2018-11-01 10:47:43,896 - Test: [   20/   39]    Loss 0.780949    Top1 88.027344    Top5 99.257812    
2018-11-01 10:47:43,995 - Test: [   30/   39]    Loss 0.768745    Top1 88.151042    Top5 99.309896    
2018-11-01 10:47:44,086 - Test: [   40/   39]    Loss 0.757084    Top1 88.240000    Top5 99.330000    
2018-11-01 10:47:44,120 - ==> Top1: 88.240    Top5: 99.330    Loss: 0.757

2018-11-01 10:47:44,121 - Testing sensitivity of module.layer1.2.conv2.weight [90.0% sparsity]
2018-11-01 10:47:44,124 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 10:47:44,125 - --- test ---------------------
2018-11-01 10:47:44,125 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:44,534 - Test: [   10/   39]    Loss 3.335048    Top1 60.312500    Top5 93.945312    
2018-11-01 10:47:44,642 - Test: [   20/   39]    Loss 3.183331    Top1 61.679688    Top5 94.453125    
2018-11-01 10:47:44,747 - Test: [   30/   39]    Loss 3.171951    Top1 61.497396    Top5 94.283854    
2018-11-01 10:47:44,844 - Test: [   40/   39]    Loss 3.181467    Top1 61.120000    Top5 94.370000    
2018-11-01 10:47:44,869 - ==> Top1: 61.120    Top5: 94.370    Loss: 3.181

2018-11-01 10:47:44,885 - Testing sensitivity of module.layer2.0.conv1.weight [0.0% sparsity]
2018-11-01 10:47:44,889 - --- test ---------------------
2018-11-01 10:47:44,889 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:45,313 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:45,423 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:45,523 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:47:45,614 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:47:45,648 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:47:45,648 - Testing sensitivity of module.layer2.0.conv1.weight [5.0% sparsity]
2018-11-01 10:47:45,651 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 10:47:45,653 - --- test ---------------------
2018-11-01 10:47:45,653 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:46,060 - Test: [   10/   39]    Loss 0.560013    Top1 91.093750    Top5 99.648438    
2018-11-01 10:47:46,165 - Test: [   20/   39]    Loss 0.555176    Top1 91.347656    Top5 99.531250    
2018-11-01 10:47:46,272 - Test: [   30/   39]    Loss 0.550250    Top1 91.367188    Top5 99.635417    
2018-11-01 10:47:46,370 - Test: [   40/   39]    Loss 0.547216    Top1 91.330000    Top5 99.630000    
2018-11-01 10:47:46,408 - ==> Top1: 91.330    Top5: 99.630    Loss: 0.547

2018-11-01 10:47:46,409 - Testing sensitivity of module.layer2.0.conv1.weight [10.0% sparsity]
2018-11-01 10:47:46,412 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 10:47:46,412 - --- test ---------------------
2018-11-01 10:47:46,413 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:46,880 - Test: [   10/   39]    Loss 0.590406    Top1 90.468750    Top5 99.531250    
2018-11-01 10:47:46,989 - Test: [   20/   39]    Loss 0.593745    Top1 90.625000    Top5 99.375000    
2018-11-01 10:47:47,096 - Test: [   30/   39]    Loss 0.593241    Top1 90.546875    Top5 99.505208    
2018-11-01 10:47:47,193 - Test: [   40/   39]    Loss 0.577225    Top1 90.590000    Top5 99.550000    
2018-11-01 10:47:47,194 - ==> Top1: 90.590    Top5: 99.550    Loss: 0.577

2018-11-01 10:47:47,222 - Testing sensitivity of module.layer2.0.conv1.weight [15.0% sparsity]
2018-11-01 10:47:47,226 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 10:47:47,228 - --- test ---------------------
2018-11-01 10:47:47,228 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:47,664 - Test: [   10/   39]    Loss 0.599244    Top1 90.273438    Top5 99.648438    
2018-11-01 10:47:47,773 - Test: [   20/   39]    Loss 0.600748    Top1 90.585938    Top5 99.550781    
2018-11-01 10:47:47,880 - Test: [   30/   39]    Loss 0.600709    Top1 90.494792    Top5 99.609375    
2018-11-01 10:47:47,977 - Test: [   40/   39]    Loss 0.588355    Top1 90.470000    Top5 99.600000    
2018-11-01 10:47:48,002 - ==> Top1: 90.470    Top5: 99.600    Loss: 0.588

2018-11-01 10:47:48,003 - Testing sensitivity of module.layer2.0.conv1.weight [20.0% sparsity]
2018-11-01 10:47:48,006 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 10:47:48,007 - --- test ---------------------
2018-11-01 10:47:48,007 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:48,420 - Test: [   10/   39]    Loss 0.618182    Top1 89.960938    Top5 99.687500    
2018-11-01 10:47:48,522 - Test: [   20/   39]    Loss 0.612530    Top1 90.234375    Top5 99.531250    
2018-11-01 10:47:48,621 - Test: [   30/   39]    Loss 0.611525    Top1 90.091146    Top5 99.609375    
2018-11-01 10:47:48,712 - Test: [   40/   39]    Loss 0.604173    Top1 90.200000    Top5 99.570000    
2018-11-01 10:47:48,737 - ==> Top1: 90.200    Top5: 99.570    Loss: 0.604

2018-11-01 10:47:48,737 - Testing sensitivity of module.layer2.0.conv1.weight [25.0% sparsity]
2018-11-01 10:47:48,741 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 10:47:48,742 - --- test ---------------------
2018-11-01 10:47:48,742 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:49,154 - Test: [   10/   39]    Loss 0.909219    Top1 85.781250    Top5 99.140625    
2018-11-01 10:47:49,257 - Test: [   20/   39]    Loss 0.896795    Top1 85.937500    Top5 99.140625    
2018-11-01 10:47:49,356 - Test: [   30/   39]    Loss 0.895426    Top1 85.742188    Top5 99.231771    
2018-11-01 10:47:49,447 - Test: [   40/   39]    Loss 0.887979    Top1 85.680000    Top5 99.240000    
2018-11-01 10:47:49,473 - ==> Top1: 85.680    Top5: 99.240    Loss: 0.888

2018-11-01 10:47:49,474 - Testing sensitivity of module.layer2.0.conv1.weight [30.0% sparsity]
2018-11-01 10:47:49,477 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 10:47:49,478 - --- test ---------------------
2018-11-01 10:47:49,479 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:49,898 - Test: [   10/   39]    Loss 1.071578    Top1 83.359375    Top5 99.140625    
2018-11-01 10:47:50,000 - Test: [   20/   39]    Loss 1.057793    Top1 83.964844    Top5 99.042969    
2018-11-01 10:47:50,099 - Test: [   30/   39]    Loss 1.063916    Top1 83.828125    Top5 99.101562    
2018-11-01 10:47:50,195 - Test: [   40/   39]    Loss 1.048027    Top1 83.870000    Top5 99.130000    
2018-11-01 10:47:50,229 - ==> Top1: 83.870    Top5: 99.130    Loss: 1.048

2018-11-01 10:47:50,230 - Testing sensitivity of module.layer2.0.conv1.weight [35.0% sparsity]
2018-11-01 10:47:50,233 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 10:47:50,235 - --- test ---------------------
2018-11-01 10:47:50,235 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:50,685 - Test: [   10/   39]    Loss 1.105077    Top1 82.656250    Top5 98.984375    
2018-11-01 10:47:50,790 - Test: [   20/   39]    Loss 1.092871    Top1 83.125000    Top5 98.984375    
2018-11-01 10:47:50,895 - Test: [   30/   39]    Loss 1.111781    Top1 82.890625    Top5 99.036458    
2018-11-01 10:47:50,992 - Test: [   40/   39]    Loss 1.089086    Top1 82.940000    Top5 99.080000    
2018-11-01 10:47:51,020 - ==> Top1: 82.940    Top5: 99.080    Loss: 1.089

2018-11-01 10:47:51,021 - Testing sensitivity of module.layer2.0.conv1.weight [40.0% sparsity]
2018-11-01 10:47:51,025 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 10:47:51,026 - --- test ---------------------
2018-11-01 10:47:51,026 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:51,455 - Test: [   10/   39]    Loss 2.087394    Top1 70.898438    Top5 96.992188    
2018-11-01 10:47:51,556 - Test: [   20/   39]    Loss 2.030280    Top1 70.800781    Top5 97.285156    
2018-11-01 10:47:51,655 - Test: [   30/   39]    Loss 2.046899    Top1 70.846354    Top5 97.434896    
2018-11-01 10:47:51,746 - Test: [   40/   39]    Loss 2.024435    Top1 70.690000    Top5 97.400000    
2018-11-01 10:47:51,770 - ==> Top1: 70.690    Top5: 97.400    Loss: 2.024

2018-11-01 10:47:51,771 - Testing sensitivity of module.layer2.0.conv1.weight [45.0% sparsity]
2018-11-01 10:47:51,774 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 10:47:51,775 - --- test ---------------------
2018-11-01 10:47:51,776 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:52,188 - Test: [   10/   39]    Loss 2.767678    Top1 62.578125    Top5 95.703125    
2018-11-01 10:47:52,290 - Test: [   20/   39]    Loss 2.736658    Top1 62.539062    Top5 95.898438    
2018-11-01 10:47:52,389 - Test: [   30/   39]    Loss 2.743306    Top1 62.825521    Top5 96.067708    
2018-11-01 10:47:52,479 - Test: [   40/   39]    Loss 2.730689    Top1 62.830000    Top5 95.980000    
2018-11-01 10:47:52,504 - ==> Top1: 62.830    Top5: 95.980    Loss: 2.731

2018-11-01 10:47:52,504 - Testing sensitivity of module.layer2.0.conv1.weight [50.0% sparsity]
2018-11-01 10:47:52,507 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 10:47:52,509 - --- test ---------------------
2018-11-01 10:47:52,509 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:52,926 - Test: [   10/   39]    Loss 3.184790    Top1 58.710938    Top5 94.765625    
2018-11-01 10:47:53,028 - Test: [   20/   39]    Loss 3.156408    Top1 58.496094    Top5 94.960938    
2018-11-01 10:47:53,126 - Test: [   30/   39]    Loss 3.150774    Top1 59.010417    Top5 94.960938    
2018-11-01 10:47:53,217 - Test: [   40/   39]    Loss 3.159555    Top1 58.990000    Top5 95.100000    
2018-11-01 10:47:53,242 - ==> Top1: 58.990    Top5: 95.100    Loss: 3.160

2018-11-01 10:47:53,243 - Testing sensitivity of module.layer2.0.conv1.weight [55.0% sparsity]
2018-11-01 10:47:53,246 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 10:47:53,247 - --- test ---------------------
2018-11-01 10:47:53,248 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:53,660 - Test: [   10/   39]    Loss 3.555169    Top1 55.664062    Top5 94.140625    
2018-11-01 10:47:53,762 - Test: [   20/   39]    Loss 3.544898    Top1 55.410156    Top5 94.414062    
2018-11-01 10:47:53,861 - Test: [   30/   39]    Loss 3.533645    Top1 55.768229    Top5 94.322917    
2018-11-01 10:47:53,953 - Test: [   40/   39]    Loss 3.540623    Top1 55.820000    Top5 94.370000    
2018-11-01 10:47:53,978 - ==> Top1: 55.820    Top5: 94.370    Loss: 3.541

2018-11-01 10:47:53,979 - Testing sensitivity of module.layer2.0.conv1.weight [60.0% sparsity]
2018-11-01 10:47:53,982 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 10:47:53,983 - --- test ---------------------
2018-11-01 10:47:53,983 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:54,392 - Test: [   10/   39]    Loss 4.279372    Top1 49.843750    Top5 90.664062    
2018-11-01 10:47:54,494 - Test: [   20/   39]    Loss 4.293921    Top1 49.433594    Top5 90.859375    
2018-11-01 10:47:54,593 - Test: [   30/   39]    Loss 4.266676    Top1 49.908854    Top5 90.677083    
2018-11-01 10:47:54,687 - Test: [   40/   39]    Loss 4.280272    Top1 49.690000    Top5 90.890000    
2018-11-01 10:47:54,711 - ==> Top1: 49.690    Top5: 90.890    Loss: 4.280

2018-11-01 10:47:54,712 - Testing sensitivity of module.layer2.0.conv1.weight [65.0% sparsity]
2018-11-01 10:47:54,715 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 10:47:54,716 - --- test ---------------------
2018-11-01 10:47:54,716 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:55,157 - Test: [   10/   39]    Loss 4.738343    Top1 46.875000    Top5 88.437500    
2018-11-01 10:47:55,266 - Test: [   20/   39]    Loss 4.764965    Top1 45.722656    Top5 88.535156    
2018-11-01 10:47:55,375 - Test: [   30/   39]    Loss 4.728212    Top1 46.393229    Top5 88.697917    
2018-11-01 10:47:55,475 - Test: [   40/   39]    Loss 4.752353    Top1 46.220000    Top5 88.880000    
2018-11-01 10:47:55,501 - ==> Top1: 46.220    Top5: 88.880    Loss: 4.752

2018-11-01 10:47:55,501 - Testing sensitivity of module.layer2.0.conv1.weight [70.0% sparsity]
2018-11-01 10:47:55,504 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 10:47:55,505 - --- test ---------------------
2018-11-01 10:47:55,505 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:55,941 - Test: [   10/   39]    Loss 5.458069    Top1 40.468750    Top5 83.867188    
2018-11-01 10:47:56,043 - Test: [   20/   39]    Loss 5.482318    Top1 40.546875    Top5 84.375000    
2018-11-01 10:47:56,142 - Test: [   30/   39]    Loss 5.405774    Top1 41.588542    Top5 84.414062    
2018-11-01 10:47:56,236 - Test: [   40/   39]    Loss 5.446808    Top1 41.530000    Top5 84.380000    
2018-11-01 10:47:56,261 - ==> Top1: 41.530    Top5: 84.380    Loss: 5.447

2018-11-01 10:47:56,262 - Testing sensitivity of module.layer2.0.conv1.weight [75.0% sparsity]
2018-11-01 10:47:56,265 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 10:47:56,265 - --- test ---------------------
2018-11-01 10:47:56,265 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:56,693 - Test: [   10/   39]    Loss 5.818884    Top1 40.117187    Top5 84.101562    
2018-11-01 10:47:56,799 - Test: [   20/   39]    Loss 5.887047    Top1 39.218750    Top5 84.687500    
2018-11-01 10:47:56,903 - Test: [   30/   39]    Loss 5.825050    Top1 39.583333    Top5 84.752604    
2018-11-01 10:47:57,000 - Test: [   40/   39]    Loss 5.848544    Top1 39.520000    Top5 84.640000    
2018-11-01 10:47:57,024 - ==> Top1: 39.520    Top5: 84.640    Loss: 5.849

2018-11-01 10:47:57,025 - Testing sensitivity of module.layer2.0.conv1.weight [80.0% sparsity]
2018-11-01 10:47:57,028 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 10:47:57,029 - --- test ---------------------
2018-11-01 10:47:57,030 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:57,444 - Test: [   10/   39]    Loss 5.960520    Top1 38.437500    Top5 82.734375    
2018-11-01 10:47:57,546 - Test: [   20/   39]    Loss 6.037391    Top1 37.636719    Top5 83.183594    
2018-11-01 10:47:57,646 - Test: [   30/   39]    Loss 5.967104    Top1 38.203125    Top5 83.059896    
2018-11-01 10:47:57,739 - Test: [   40/   39]    Loss 5.988928    Top1 38.150000    Top5 82.900000    
2018-11-01 10:47:57,765 - ==> Top1: 38.150    Top5: 82.900    Loss: 5.989

2018-11-01 10:47:57,765 - Testing sensitivity of module.layer2.0.conv1.weight [85.0% sparsity]
2018-11-01 10:47:57,768 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 10:47:57,770 - --- test ---------------------
2018-11-01 10:47:57,770 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:58,182 - Test: [   10/   39]    Loss 8.870732    Top1 27.500000    Top5 70.898438    
2018-11-01 10:47:58,288 - Test: [   20/   39]    Loss 8.930933    Top1 27.246094    Top5 70.664062    
2018-11-01 10:47:58,392 - Test: [   30/   39]    Loss 8.788548    Top1 27.929688    Top5 71.302083    
2018-11-01 10:47:58,487 - Test: [   40/   39]    Loss 8.821252    Top1 27.760000    Top5 71.040000    
2018-11-01 10:47:58,513 - ==> Top1: 27.760    Top5: 71.040    Loss: 8.821

2018-11-01 10:47:58,514 - Testing sensitivity of module.layer2.0.conv1.weight [90.0% sparsity]
2018-11-01 10:47:58,517 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 10:47:58,518 - --- test ---------------------
2018-11-01 10:47:58,519 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:58,952 - Test: [   10/   39]    Loss 8.877059    Top1 26.640625    Top5 68.828125    
2018-11-01 10:47:59,059 - Test: [   20/   39]    Loss 8.945457    Top1 26.523438    Top5 68.593750    
2018-11-01 10:47:59,162 - Test: [   30/   39]    Loss 8.792910    Top1 27.382812    Top5 69.205729    
2018-11-01 10:47:59,255 - Test: [   40/   39]    Loss 8.827349    Top1 27.560000    Top5 69.070000    
2018-11-01 10:47:59,279 - ==> Top1: 27.560    Top5: 69.070    Loss: 8.827

2018-11-01 10:47:59,289 - Testing sensitivity of module.layer2.0.conv2.weight [0.0% sparsity]
2018-11-01 10:47:59,292 - --- test ---------------------
2018-11-01 10:47:59,293 - 10000 samples (256 per mini-batch)
2018-11-01 10:47:59,710 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:47:59,813 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:47:59,913 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:48:00,005 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:48:00,030 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:48:00,031 - Testing sensitivity of module.layer2.0.conv2.weight [5.0% sparsity]
2018-11-01 10:48:00,033 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 10:48:00,034 - --- test ---------------------
2018-11-01 10:48:00,034 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:00,451 - Test: [   10/   39]    Loss 0.560991    Top1 91.210938    Top5 99.609375    
2018-11-01 10:48:00,554 - Test: [   20/   39]    Loss 0.560651    Top1 91.503906    Top5 99.570312    
2018-11-01 10:48:00,655 - Test: [   30/   39]    Loss 0.555799    Top1 91.432292    Top5 99.648438    
2018-11-01 10:48:00,748 - Test: [   40/   39]    Loss 0.552777    Top1 91.400000    Top5 99.640000    
2018-11-01 10:48:00,773 - ==> Top1: 91.400    Top5: 99.640    Loss: 0.553

2018-11-01 10:48:00,774 - Testing sensitivity of module.layer2.0.conv2.weight [10.0% sparsity]
2018-11-01 10:48:00,777 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 10:48:00,779 - --- test ---------------------
2018-11-01 10:48:00,779 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:01,200 - Test: [   10/   39]    Loss 0.572234    Top1 90.898438    Top5 99.531250    
2018-11-01 10:48:01,303 - Test: [   20/   39]    Loss 0.571973    Top1 91.093750    Top5 99.531250    
2018-11-01 10:48:01,402 - Test: [   30/   39]    Loss 0.559260    Top1 91.145833    Top5 99.622396    
2018-11-01 10:48:01,493 - Test: [   40/   39]    Loss 0.555308    Top1 91.120000    Top5 99.630000    
2018-11-01 10:48:01,518 - ==> Top1: 91.120    Top5: 99.630    Loss: 0.555

2018-11-01 10:48:01,520 - Testing sensitivity of module.layer2.0.conv2.weight [15.0% sparsity]
2018-11-01 10:48:01,524 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 10:48:01,525 - --- test ---------------------
2018-11-01 10:48:01,526 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:01,941 - Test: [   10/   39]    Loss 0.575554    Top1 90.703125    Top5 99.531250    
2018-11-01 10:48:02,044 - Test: [   20/   39]    Loss 0.571719    Top1 91.074219    Top5 99.511719    
2018-11-01 10:48:02,143 - Test: [   30/   39]    Loss 0.558939    Top1 91.119792    Top5 99.609375    
2018-11-01 10:48:02,235 - Test: [   40/   39]    Loss 0.556242    Top1 91.180000    Top5 99.620000    
2018-11-01 10:48:02,260 - ==> Top1: 91.180    Top5: 99.620    Loss: 0.556

2018-11-01 10:48:02,261 - Testing sensitivity of module.layer2.0.conv2.weight [20.0% sparsity]
2018-11-01 10:48:02,263 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 10:48:02,265 - --- test ---------------------
2018-11-01 10:48:02,265 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:02,683 - Test: [   10/   39]    Loss 0.586571    Top1 90.703125    Top5 99.453125    
2018-11-01 10:48:02,786 - Test: [   20/   39]    Loss 0.584131    Top1 90.937500    Top5 99.433594    
2018-11-01 10:48:02,886 - Test: [   30/   39]    Loss 0.574104    Top1 90.950521    Top5 99.544271    
2018-11-01 10:48:02,978 - Test: [   40/   39]    Loss 0.572077    Top1 90.960000    Top5 99.560000    
2018-11-01 10:48:03,003 - ==> Top1: 90.960    Top5: 99.560    Loss: 0.572

2018-11-01 10:48:03,004 - Testing sensitivity of module.layer2.0.conv2.weight [25.0% sparsity]
2018-11-01 10:48:03,007 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 10:48:03,008 - --- test ---------------------
2018-11-01 10:48:03,009 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:03,427 - Test: [   10/   39]    Loss 0.643063    Top1 90.000000    Top5 99.531250    
2018-11-01 10:48:03,530 - Test: [   20/   39]    Loss 0.664672    Top1 89.746094    Top5 99.453125    
2018-11-01 10:48:03,629 - Test: [   30/   39]    Loss 0.652556    Top1 89.583333    Top5 99.531250    
2018-11-01 10:48:03,721 - Test: [   40/   39]    Loss 0.653836    Top1 89.700000    Top5 99.580000    
2018-11-01 10:48:03,745 - ==> Top1: 89.700    Top5: 99.580    Loss: 0.654

2018-11-01 10:48:03,746 - Testing sensitivity of module.layer2.0.conv2.weight [30.0% sparsity]
2018-11-01 10:48:03,749 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 10:48:03,750 - --- test ---------------------
2018-11-01 10:48:03,750 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:04,176 - Test: [   10/   39]    Loss 0.766213    Top1 88.320312    Top5 99.531250    
2018-11-01 10:48:04,277 - Test: [   20/   39]    Loss 0.787622    Top1 88.222656    Top5 99.433594    
2018-11-01 10:48:04,376 - Test: [   30/   39]    Loss 0.776512    Top1 88.164062    Top5 99.531250    
2018-11-01 10:48:04,468 - Test: [   40/   39]    Loss 0.774834    Top1 88.090000    Top5 99.540000    
2018-11-01 10:48:04,492 - ==> Top1: 88.090    Top5: 99.540    Loss: 0.775

2018-11-01 10:48:04,493 - Testing sensitivity of module.layer2.0.conv2.weight [35.0% sparsity]
2018-11-01 10:48:04,496 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 10:48:04,497 - --- test ---------------------
2018-11-01 10:48:04,497 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:04,911 - Test: [   10/   39]    Loss 1.056984    Top1 84.296875    Top5 99.335938    
2018-11-01 10:48:05,012 - Test: [   20/   39]    Loss 1.095973    Top1 84.023438    Top5 99.257812    
2018-11-01 10:48:05,113 - Test: [   30/   39]    Loss 1.091699    Top1 83.919271    Top5 99.309896    
2018-11-01 10:48:05,205 - Test: [   40/   39]    Loss 1.084293    Top1 83.790000    Top5 99.370000    
2018-11-01 10:48:05,230 - ==> Top1: 83.790    Top5: 99.370    Loss: 1.084

2018-11-01 10:48:05,232 - Testing sensitivity of module.layer2.0.conv2.weight [40.0% sparsity]
2018-11-01 10:48:05,235 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 10:48:05,236 - --- test ---------------------
2018-11-01 10:48:05,237 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:05,649 - Test: [   10/   39]    Loss 1.117898    Top1 82.929688    Top5 99.218750    
2018-11-01 10:48:05,751 - Test: [   20/   39]    Loss 1.162502    Top1 82.832031    Top5 99.179688    
2018-11-01 10:48:05,850 - Test: [   30/   39]    Loss 1.170501    Top1 82.851562    Top5 99.244792    
2018-11-01 10:48:05,942 - Test: [   40/   39]    Loss 1.151963    Top1 82.850000    Top5 99.290000    
2018-11-01 10:48:05,967 - ==> Top1: 82.850    Top5: 99.290    Loss: 1.152

2018-11-01 10:48:05,968 - Testing sensitivity of module.layer2.0.conv2.weight [45.0% sparsity]
2018-11-01 10:48:05,970 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 10:48:05,972 - --- test ---------------------
2018-11-01 10:48:05,973 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:06,393 - Test: [   10/   39]    Loss 1.659917    Top1 77.539062    Top5 99.062500    
2018-11-01 10:48:06,496 - Test: [   20/   39]    Loss 1.666840    Top1 77.636719    Top5 98.964844    
2018-11-01 10:48:06,595 - Test: [   30/   39]    Loss 1.676975    Top1 77.148438    Top5 99.062500    
2018-11-01 10:48:06,687 - Test: [   40/   39]    Loss 1.648883    Top1 77.100000    Top5 99.100000    
2018-11-01 10:48:06,713 - ==> Top1: 77.100    Top5: 99.100    Loss: 1.649

2018-11-01 10:48:06,713 - Testing sensitivity of module.layer2.0.conv2.weight [50.0% sparsity]
2018-11-01 10:48:06,718 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 10:48:06,719 - --- test ---------------------
2018-11-01 10:48:06,719 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:07,131 - Test: [   10/   39]    Loss 1.718759    Top1 76.367188    Top5 98.828125    
2018-11-01 10:48:07,232 - Test: [   20/   39]    Loss 1.716293    Top1 76.738281    Top5 98.769531    
2018-11-01 10:48:07,331 - Test: [   30/   39]    Loss 1.729713    Top1 76.145833    Top5 98.880208    
2018-11-01 10:48:07,423 - Test: [   40/   39]    Loss 1.699323    Top1 76.080000    Top5 98.920000    
2018-11-01 10:48:07,449 - ==> Top1: 76.080    Top5: 98.920    Loss: 1.699

2018-11-01 10:48:07,450 - Testing sensitivity of module.layer2.0.conv2.weight [55.0% sparsity]
2018-11-01 10:48:07,453 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 10:48:07,454 - --- test ---------------------
2018-11-01 10:48:07,455 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:07,860 - Test: [   10/   39]    Loss 2.713416    Top1 69.023438    Top5 97.070312    
2018-11-01 10:48:07,961 - Test: [   20/   39]    Loss 2.674058    Top1 69.179688    Top5 97.187500    
2018-11-01 10:48:08,060 - Test: [   30/   39]    Loss 2.738818    Top1 68.515625    Top5 97.135417    
2018-11-01 10:48:08,151 - Test: [   40/   39]    Loss 2.746701    Top1 68.370000    Top5 97.280000    
2018-11-01 10:48:08,152 - ==> Top1: 68.370    Top5: 97.280    Loss: 2.747

2018-11-01 10:48:08,155 - Testing sensitivity of module.layer2.0.conv2.weight [60.0% sparsity]
2018-11-01 10:48:08,158 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 10:48:08,159 - --- test ---------------------
2018-11-01 10:48:08,159 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:08,597 - Test: [   10/   39]    Loss 3.197620    Top1 64.882812    Top5 95.820312    
2018-11-01 10:48:08,699 - Test: [   20/   39]    Loss 3.182179    Top1 64.843750    Top5 96.152344    
2018-11-01 10:48:08,798 - Test: [   30/   39]    Loss 3.272383    Top1 64.257812    Top5 96.171875    
2018-11-01 10:48:08,889 - Test: [   40/   39]    Loss 3.256143    Top1 64.200000    Top5 96.190000    
2018-11-01 10:48:08,914 - ==> Top1: 64.200    Top5: 96.190    Loss: 3.256

2018-11-01 10:48:08,915 - Testing sensitivity of module.layer2.0.conv2.weight [65.0% sparsity]
2018-11-01 10:48:08,918 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 10:48:08,919 - --- test ---------------------
2018-11-01 10:48:08,920 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:09,339 - Test: [   10/   39]    Loss 3.512044    Top1 61.250000    Top5 95.898438    
2018-11-01 10:48:09,442 - Test: [   20/   39]    Loss 3.514655    Top1 61.425781    Top5 95.859375    
2018-11-01 10:48:09,542 - Test: [   30/   39]    Loss 3.617761    Top1 60.585938    Top5 95.729167    
2018-11-01 10:48:09,634 - Test: [   40/   39]    Loss 3.591138    Top1 60.760000    Top5 95.790000    
2018-11-01 10:48:09,660 - ==> Top1: 60.760    Top5: 95.790    Loss: 3.591

2018-11-01 10:48:09,661 - Testing sensitivity of module.layer2.0.conv2.weight [70.0% sparsity]
2018-11-01 10:48:09,664 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 10:48:09,666 - --- test ---------------------
2018-11-01 10:48:09,666 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:10,089 - Test: [   10/   39]    Loss 3.790302    Top1 58.945312    Top5 94.296875    
2018-11-01 10:48:10,197 - Test: [   20/   39]    Loss 3.838877    Top1 58.339844    Top5 94.453125    
2018-11-01 10:48:10,300 - Test: [   30/   39]    Loss 3.959978    Top1 57.604167    Top5 94.140625    
2018-11-01 10:48:10,395 - Test: [   40/   39]    Loss 3.922188    Top1 57.670000    Top5 94.270000    
2018-11-01 10:48:10,420 - ==> Top1: 57.670    Top5: 94.270    Loss: 3.922

2018-11-01 10:48:10,423 - Testing sensitivity of module.layer2.0.conv2.weight [75.0% sparsity]
2018-11-01 10:48:10,425 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 10:48:10,426 - --- test ---------------------
2018-11-01 10:48:10,426 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:10,859 - Test: [   10/   39]    Loss 5.816267    Top1 43.398438    Top5 90.039062    
2018-11-01 10:48:10,965 - Test: [   20/   39]    Loss 5.802522    Top1 42.871094    Top5 89.570312    
2018-11-01 10:48:11,066 - Test: [   30/   39]    Loss 5.900255    Top1 42.226562    Top5 89.505208    
2018-11-01 10:48:11,157 - Test: [   40/   39]    Loss 5.895324    Top1 42.070000    Top5 89.640000    
2018-11-01 10:48:11,184 - ==> Top1: 42.070    Top5: 89.640    Loss: 5.895

2018-11-01 10:48:11,185 - Testing sensitivity of module.layer2.0.conv2.weight [80.0% sparsity]
2018-11-01 10:48:11,188 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 10:48:11,189 - --- test ---------------------
2018-11-01 10:48:11,190 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:11,605 - Test: [   10/   39]    Loss 5.631944    Top1 42.929688    Top5 89.531250    
2018-11-01 10:48:11,706 - Test: [   20/   39]    Loss 5.612194    Top1 42.089844    Top5 88.925781    
2018-11-01 10:48:11,805 - Test: [   30/   39]    Loss 5.699136    Top1 41.406250    Top5 88.906250    
2018-11-01 10:48:11,896 - Test: [   40/   39]    Loss 5.699116    Top1 41.260000    Top5 88.980000    
2018-11-01 10:48:11,921 - ==> Top1: 41.260    Top5: 88.980    Loss: 5.699

2018-11-01 10:48:11,922 - Testing sensitivity of module.layer2.0.conv2.weight [85.0% sparsity]
2018-11-01 10:48:11,925 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 10:48:11,926 - --- test ---------------------
2018-11-01 10:48:11,927 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:12,349 - Test: [   10/   39]    Loss 6.292958    Top1 30.351562    Top5 79.570312    
2018-11-01 10:48:12,454 - Test: [   20/   39]    Loss 6.327913    Top1 30.117187    Top5 78.750000    
2018-11-01 10:48:12,558 - Test: [   30/   39]    Loss 6.359813    Top1 29.635417    Top5 78.945312    
2018-11-01 10:48:12,654 - Test: [   40/   39]    Loss 6.373210    Top1 29.470000    Top5 78.870000    
2018-11-01 10:48:12,680 - ==> Top1: 29.470    Top5: 78.870    Loss: 6.373

2018-11-01 10:48:12,681 - Testing sensitivity of module.layer2.0.conv2.weight [90.0% sparsity]
2018-11-01 10:48:12,684 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 10:48:12,685 - --- test ---------------------
2018-11-01 10:48:12,685 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:13,113 - Test: [   10/   39]    Loss 6.929299    Top1 26.835937    Top5 77.539062    
2018-11-01 10:48:13,215 - Test: [   20/   39]    Loss 6.968873    Top1 26.503906    Top5 76.835938    
2018-11-01 10:48:13,314 - Test: [   30/   39]    Loss 7.000005    Top1 26.015625    Top5 77.057292    
2018-11-01 10:48:13,405 - Test: [   40/   39]    Loss 7.046378    Top1 25.980000    Top5 76.990000    
2018-11-01 10:48:13,430 - ==> Top1: 25.980    Top5: 76.990    Loss: 7.046

2018-11-01 10:48:13,441 - Testing sensitivity of module.layer2.0.downsample.0.weight [0.0% sparsity]
2018-11-01 10:48:13,444 - --- test ---------------------
2018-11-01 10:48:13,444 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:13,851 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:48:13,954 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:48:14,053 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:48:14,144 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:48:14,168 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:48:14,169 - Testing sensitivity of module.layer2.0.downsample.0.weight [5.0% sparsity]
2018-11-01 10:48:14,173 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 10:48:14,174 - --- test ---------------------
2018-11-01 10:48:14,174 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:14,595 - Test: [   10/   39]    Loss 0.553076    Top1 91.210938    Top5 99.687500    
2018-11-01 10:48:14,697 - Test: [   20/   39]    Loss 0.553377    Top1 91.503906    Top5 99.570312    
2018-11-01 10:48:14,796 - Test: [   30/   39]    Loss 0.546839    Top1 91.523438    Top5 99.661458    
2018-11-01 10:48:14,887 - Test: [   40/   39]    Loss 0.541161    Top1 91.560000    Top5 99.640000    
2018-11-01 10:48:14,912 - ==> Top1: 91.560    Top5: 99.640    Loss: 0.541

2018-11-01 10:48:14,913 - Testing sensitivity of module.layer2.0.downsample.0.weight [10.0% sparsity]
2018-11-01 10:48:14,915 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 10:48:14,916 - --- test ---------------------
2018-11-01 10:48:14,916 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:15,337 - Test: [   10/   39]    Loss 0.551312    Top1 91.250000    Top5 99.687500    
2018-11-01 10:48:15,439 - Test: [   20/   39]    Loss 0.553100    Top1 91.542969    Top5 99.570312    
2018-11-01 10:48:15,538 - Test: [   30/   39]    Loss 0.547033    Top1 91.523438    Top5 99.661458    
2018-11-01 10:48:15,629 - Test: [   40/   39]    Loss 0.541896    Top1 91.540000    Top5 99.640000    
2018-11-01 10:48:15,654 - ==> Top1: 91.540    Top5: 99.640    Loss: 0.542

2018-11-01 10:48:15,655 - Testing sensitivity of module.layer2.0.downsample.0.weight [15.0% sparsity]
2018-11-01 10:48:15,657 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 10:48:15,658 - --- test ---------------------
2018-11-01 10:48:15,658 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:16,061 - Test: [   10/   39]    Loss 0.557536    Top1 91.250000    Top5 99.648438    
2018-11-01 10:48:16,163 - Test: [   20/   39]    Loss 0.556735    Top1 91.289062    Top5 99.570312    
2018-11-01 10:48:16,262 - Test: [   30/   39]    Loss 0.551969    Top1 91.197917    Top5 99.661458    
2018-11-01 10:48:16,353 - Test: [   40/   39]    Loss 0.547008    Top1 91.290000    Top5 99.640000    
2018-11-01 10:48:16,381 - ==> Top1: 91.290    Top5: 99.640    Loss: 0.547

2018-11-01 10:48:16,381 - Testing sensitivity of module.layer2.0.downsample.0.weight [20.0% sparsity]
2018-11-01 10:48:16,384 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 10:48:16,386 - --- test ---------------------
2018-11-01 10:48:16,386 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:16,793 - Test: [   10/   39]    Loss 0.555198    Top1 91.093750    Top5 99.687500    
2018-11-01 10:48:16,895 - Test: [   20/   39]    Loss 0.556137    Top1 91.210938    Top5 99.531250    
2018-11-01 10:48:16,995 - Test: [   30/   39]    Loss 0.553879    Top1 91.145833    Top5 99.635417    
2018-11-01 10:48:17,086 - Test: [   40/   39]    Loss 0.547436    Top1 91.260000    Top5 99.630000    
2018-11-01 10:48:17,111 - ==> Top1: 91.260    Top5: 99.630    Loss: 0.547

2018-11-01 10:48:17,113 - Testing sensitivity of module.layer2.0.downsample.0.weight [25.0% sparsity]
2018-11-01 10:48:17,117 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 10:48:17,118 - --- test ---------------------
2018-11-01 10:48:17,118 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:17,516 - Test: [   10/   39]    Loss 0.548013    Top1 90.859375    Top5 99.687500    
2018-11-01 10:48:17,619 - Test: [   20/   39]    Loss 0.554336    Top1 91.054688    Top5 99.511719    
2018-11-01 10:48:17,718 - Test: [   30/   39]    Loss 0.553082    Top1 91.106771    Top5 99.609375    
2018-11-01 10:48:17,809 - Test: [   40/   39]    Loss 0.544777    Top1 91.170000    Top5 99.600000    
2018-11-01 10:48:17,835 - ==> Top1: 91.170    Top5: 99.600    Loss: 0.545

2018-11-01 10:48:17,836 - Testing sensitivity of module.layer2.0.downsample.0.weight [30.0% sparsity]
2018-11-01 10:48:17,838 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 10:48:17,839 - --- test ---------------------
2018-11-01 10:48:17,839 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:18,250 - Test: [   10/   39]    Loss 0.553272    Top1 90.898438    Top5 99.648438    
2018-11-01 10:48:18,353 - Test: [   20/   39]    Loss 0.557813    Top1 91.113281    Top5 99.492188    
2018-11-01 10:48:18,452 - Test: [   30/   39]    Loss 0.558574    Top1 91.132812    Top5 99.570312    
2018-11-01 10:48:18,543 - Test: [   40/   39]    Loss 0.550114    Top1 91.170000    Top5 99.570000    
2018-11-01 10:48:18,569 - ==> Top1: 91.170    Top5: 99.570    Loss: 0.550

2018-11-01 10:48:18,570 - Testing sensitivity of module.layer2.0.downsample.0.weight [35.0% sparsity]
2018-11-01 10:48:18,572 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 10:48:18,573 - --- test ---------------------
2018-11-01 10:48:18,573 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:18,985 - Test: [   10/   39]    Loss 0.603617    Top1 90.312500    Top5 99.609375    
2018-11-01 10:48:19,087 - Test: [   20/   39]    Loss 0.595548    Top1 90.644531    Top5 99.511719    
2018-11-01 10:48:19,186 - Test: [   30/   39]    Loss 0.593295    Top1 90.664062    Top5 99.570312    
2018-11-01 10:48:19,277 - Test: [   40/   39]    Loss 0.584751    Top1 90.770000    Top5 99.590000    
2018-11-01 10:48:19,304 - ==> Top1: 90.770    Top5: 99.590    Loss: 0.585

2018-11-01 10:48:19,305 - Testing sensitivity of module.layer2.0.downsample.0.weight [40.0% sparsity]
2018-11-01 10:48:19,308 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 10:48:19,309 - --- test ---------------------
2018-11-01 10:48:19,310 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:19,720 - Test: [   10/   39]    Loss 0.605855    Top1 90.234375    Top5 99.687500    
2018-11-01 10:48:19,823 - Test: [   20/   39]    Loss 0.599629    Top1 90.488281    Top5 99.550781    
2018-11-01 10:48:19,922 - Test: [   30/   39]    Loss 0.597202    Top1 90.481771    Top5 99.596354    
2018-11-01 10:48:20,013 - Test: [   40/   39]    Loss 0.587754    Top1 90.670000    Top5 99.610000    
2018-11-01 10:48:20,039 - ==> Top1: 90.670    Top5: 99.610    Loss: 0.588

2018-11-01 10:48:20,040 - Testing sensitivity of module.layer2.0.downsample.0.weight [45.0% sparsity]
2018-11-01 10:48:20,044 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 10:48:20,045 - --- test ---------------------
2018-11-01 10:48:20,045 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:20,455 - Test: [   10/   39]    Loss 0.599087    Top1 90.117188    Top5 99.570312    
2018-11-01 10:48:20,558 - Test: [   20/   39]    Loss 0.599000    Top1 90.449219    Top5 99.433594    
2018-11-01 10:48:20,657 - Test: [   30/   39]    Loss 0.598732    Top1 90.442708    Top5 99.492188    
2018-11-01 10:48:20,748 - Test: [   40/   39]    Loss 0.589421    Top1 90.620000    Top5 99.540000    
2018-11-01 10:48:20,773 - ==> Top1: 90.620    Top5: 99.540    Loss: 0.589

2018-11-01 10:48:20,774 - Testing sensitivity of module.layer2.0.downsample.0.weight [50.0% sparsity]
2018-11-01 10:48:20,777 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 10:48:20,778 - --- test ---------------------
2018-11-01 10:48:20,779 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:21,185 - Test: [   10/   39]    Loss 0.598537    Top1 90.312500    Top5 99.570312    
2018-11-01 10:48:21,287 - Test: [   20/   39]    Loss 0.598760    Top1 90.722656    Top5 99.433594    
2018-11-01 10:48:21,386 - Test: [   30/   39]    Loss 0.597518    Top1 90.572917    Top5 99.518229    
2018-11-01 10:48:21,477 - Test: [   40/   39]    Loss 0.587492    Top1 90.670000    Top5 99.570000    
2018-11-01 10:48:21,502 - ==> Top1: 90.670    Top5: 99.570    Loss: 0.587

2018-11-01 10:48:21,503 - Testing sensitivity of module.layer2.0.downsample.0.weight [55.0% sparsity]
2018-11-01 10:48:21,507 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 10:48:21,508 - --- test ---------------------
2018-11-01 10:48:21,508 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:21,933 - Test: [   10/   39]    Loss 0.598947    Top1 90.078125    Top5 99.609375    
2018-11-01 10:48:22,036 - Test: [   20/   39]    Loss 0.599063    Top1 90.410156    Top5 99.453125    
2018-11-01 10:48:22,135 - Test: [   30/   39]    Loss 0.597347    Top1 90.377604    Top5 99.518229    
2018-11-01 10:48:22,226 - Test: [   40/   39]    Loss 0.584956    Top1 90.520000    Top5 99.570000    
2018-11-01 10:48:22,252 - ==> Top1: 90.520    Top5: 99.570    Loss: 0.585

2018-11-01 10:48:22,253 - Testing sensitivity of module.layer2.0.downsample.0.weight [60.0% sparsity]
2018-11-01 10:48:22,256 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 10:48:22,257 - --- test ---------------------
2018-11-01 10:48:22,258 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:22,677 - Test: [   10/   39]    Loss 0.644614    Top1 89.882812    Top5 99.453125    
2018-11-01 10:48:22,779 - Test: [   20/   39]    Loss 0.653576    Top1 89.863281    Top5 99.355469    
2018-11-01 10:48:22,878 - Test: [   30/   39]    Loss 0.653551    Top1 89.648438    Top5 99.414062    
2018-11-01 10:48:22,969 - Test: [   40/   39]    Loss 0.636041    Top1 89.810000    Top5 99.470000    
2018-11-01 10:48:22,995 - ==> Top1: 89.810    Top5: 99.470    Loss: 0.636

2018-11-01 10:48:22,995 - Testing sensitivity of module.layer2.0.downsample.0.weight [65.0% sparsity]
2018-11-01 10:48:22,999 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 10:48:23,001 - --- test ---------------------
2018-11-01 10:48:23,001 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:23,416 - Test: [   10/   39]    Loss 0.746607    Top1 88.437500    Top5 99.257812    
2018-11-01 10:48:23,518 - Test: [   20/   39]    Loss 0.748451    Top1 88.515625    Top5 99.218750    
2018-11-01 10:48:23,617 - Test: [   30/   39]    Loss 0.741081    Top1 88.489583    Top5 99.244792    
2018-11-01 10:48:23,709 - Test: [   40/   39]    Loss 0.717621    Top1 88.720000    Top5 99.300000    
2018-11-01 10:48:23,733 - ==> Top1: 88.720    Top5: 99.300    Loss: 0.718

2018-11-01 10:48:23,735 - Testing sensitivity of module.layer2.0.downsample.0.weight [70.0% sparsity]
2018-11-01 10:48:23,738 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 10:48:23,740 - --- test ---------------------
2018-11-01 10:48:23,740 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:24,151 - Test: [   10/   39]    Loss 0.975528    Top1 85.156250    Top5 99.062500    
2018-11-01 10:48:24,253 - Test: [   20/   39]    Loss 0.969717    Top1 85.429688    Top5 98.906250    
2018-11-01 10:48:24,352 - Test: [   30/   39]    Loss 0.984803    Top1 85.442708    Top5 98.997396    
2018-11-01 10:48:24,443 - Test: [   40/   39]    Loss 0.971165    Top1 85.520000    Top5 99.040000    
2018-11-01 10:48:24,471 - ==> Top1: 85.520    Top5: 99.040    Loss: 0.971

2018-11-01 10:48:24,471 - Testing sensitivity of module.layer2.0.downsample.0.weight [75.0% sparsity]
2018-11-01 10:48:24,476 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 10:48:24,478 - --- test ---------------------
2018-11-01 10:48:24,478 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:24,889 - Test: [   10/   39]    Loss 1.162548    Top1 82.851562    Top5 98.906250    
2018-11-01 10:48:24,992 - Test: [   20/   39]    Loss 1.142073    Top1 83.476562    Top5 98.730469    
2018-11-01 10:48:25,095 - Test: [   30/   39]    Loss 1.153226    Top1 83.502604    Top5 98.893229    
2018-11-01 10:48:25,192 - Test: [   40/   39]    Loss 1.145224    Top1 83.520000    Top5 98.950000    
2018-11-01 10:48:25,217 - ==> Top1: 83.520    Top5: 98.950    Loss: 1.145

2018-11-01 10:48:25,218 - Testing sensitivity of module.layer2.0.downsample.0.weight [80.0% sparsity]
2018-11-01 10:48:25,221 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 10:48:25,222 - --- test ---------------------
2018-11-01 10:48:25,223 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:25,648 - Test: [   10/   39]    Loss 1.366372    Top1 80.898438    Top5 98.789062    
2018-11-01 10:48:25,750 - Test: [   20/   39]    Loss 1.343349    Top1 81.386719    Top5 98.554688    
2018-11-01 10:48:25,855 - Test: [   30/   39]    Loss 1.356343    Top1 81.614583    Top5 98.645833    
2018-11-01 10:48:25,952 - Test: [   40/   39]    Loss 1.342800    Top1 81.690000    Top5 98.720000    
2018-11-01 10:48:25,978 - ==> Top1: 81.690    Top5: 98.720    Loss: 1.343

2018-11-01 10:48:25,979 - Testing sensitivity of module.layer2.0.downsample.0.weight [85.0% sparsity]
2018-11-01 10:48:25,982 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 10:48:25,983 - --- test ---------------------
2018-11-01 10:48:25,984 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:26,405 - Test: [   10/   39]    Loss 2.664456    Top1 70.507812    Top5 97.656250    
2018-11-01 10:48:26,512 - Test: [   20/   39]    Loss 2.641158    Top1 70.253906    Top5 97.714844    
2018-11-01 10:48:26,620 - Test: [   30/   39]    Loss 2.665518    Top1 70.065104    Top5 97.851562    
2018-11-01 10:48:26,718 - Test: [   40/   39]    Loss 2.634324    Top1 70.050000    Top5 97.840000    
2018-11-01 10:48:26,743 - ==> Top1: 70.050    Top5: 97.840    Loss: 2.634

2018-11-01 10:48:26,744 - Testing sensitivity of module.layer2.0.downsample.0.weight [90.0% sparsity]
2018-11-01 10:48:26,747 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 10:48:26,748 - --- test ---------------------
2018-11-01 10:48:26,748 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:27,154 - Test: [   10/   39]    Loss 3.074269    Top1 66.875000    Top5 96.484375    
2018-11-01 10:48:27,256 - Test: [   20/   39]    Loss 3.133870    Top1 66.484375    Top5 96.054688    
2018-11-01 10:48:27,355 - Test: [   30/   39]    Loss 3.176921    Top1 66.145833    Top5 96.263021    
2018-11-01 10:48:27,446 - Test: [   40/   39]    Loss 3.151698    Top1 66.070000    Top5 96.150000    
2018-11-01 10:48:27,472 - ==> Top1: 66.070    Top5: 96.150    Loss: 3.152

2018-11-01 10:48:27,487 - Testing sensitivity of module.layer2.1.conv1.weight [0.0% sparsity]
2018-11-01 10:48:27,491 - --- test ---------------------
2018-11-01 10:48:27,492 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:27,898 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:48:28,001 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:48:28,100 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:48:28,192 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:48:28,217 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:48:28,218 - Testing sensitivity of module.layer2.1.conv1.weight [5.0% sparsity]
2018-11-01 10:48:28,221 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 10:48:28,222 - --- test ---------------------
2018-11-01 10:48:28,223 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:28,639 - Test: [   10/   39]    Loss 0.558742    Top1 91.054688    Top5 99.687500    
2018-11-01 10:48:28,741 - Test: [   20/   39]    Loss 0.557620    Top1 91.347656    Top5 99.609375    
2018-11-01 10:48:28,840 - Test: [   30/   39]    Loss 0.551794    Top1 91.341146    Top5 99.687500    
2018-11-01 10:48:28,931 - Test: [   40/   39]    Loss 0.546260    Top1 91.380000    Top5 99.670000    
2018-11-01 10:48:28,957 - ==> Top1: 91.380    Top5: 99.670    Loss: 0.546

2018-11-01 10:48:28,958 - Testing sensitivity of module.layer2.1.conv1.weight [10.0% sparsity]
2018-11-01 10:48:28,961 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 10:48:28,962 - --- test ---------------------
2018-11-01 10:48:28,962 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:29,387 - Test: [   10/   39]    Loss 0.574110    Top1 90.781250    Top5 99.609375    
2018-11-01 10:48:29,494 - Test: [   20/   39]    Loss 0.574758    Top1 91.113281    Top5 99.550781    
2018-11-01 10:48:29,598 - Test: [   30/   39]    Loss 0.569808    Top1 91.158854    Top5 99.635417    
2018-11-01 10:48:29,694 - Test: [   40/   39]    Loss 0.565123    Top1 91.180000    Top5 99.630000    
2018-11-01 10:48:29,718 - ==> Top1: 91.180    Top5: 99.630    Loss: 0.565

2018-11-01 10:48:29,719 - Testing sensitivity of module.layer2.1.conv1.weight [15.0% sparsity]
2018-11-01 10:48:29,722 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 10:48:29,723 - --- test ---------------------
2018-11-01 10:48:29,723 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:30,149 - Test: [   10/   39]    Loss 0.585592    Top1 90.625000    Top5 99.570312    
2018-11-01 10:48:30,250 - Test: [   20/   39]    Loss 0.591124    Top1 90.917969    Top5 99.550781    
2018-11-01 10:48:30,353 - Test: [   30/   39]    Loss 0.589474    Top1 90.898438    Top5 99.648438    
2018-11-01 10:48:30,449 - Test: [   40/   39]    Loss 0.582935    Top1 91.030000    Top5 99.640000    
2018-11-01 10:48:30,476 - ==> Top1: 91.030    Top5: 99.640    Loss: 0.583

2018-11-01 10:48:30,476 - Testing sensitivity of module.layer2.1.conv1.weight [20.0% sparsity]
2018-11-01 10:48:30,480 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 10:48:30,482 - --- test ---------------------
2018-11-01 10:48:30,482 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:30,928 - Test: [   10/   39]    Loss 0.582717    Top1 90.703125    Top5 99.531250    
2018-11-01 10:48:31,035 - Test: [   20/   39]    Loss 0.581759    Top1 90.859375    Top5 99.453125    
2018-11-01 10:48:31,134 - Test: [   30/   39]    Loss 0.581057    Top1 90.846354    Top5 99.557292    
2018-11-01 10:48:31,225 - Test: [   40/   39]    Loss 0.572799    Top1 91.010000    Top5 99.560000    
2018-11-01 10:48:31,251 - ==> Top1: 91.010    Top5: 99.560    Loss: 0.573

2018-11-01 10:48:31,251 - Testing sensitivity of module.layer2.1.conv1.weight [25.0% sparsity]
2018-11-01 10:48:31,254 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 10:48:31,255 - --- test ---------------------
2018-11-01 10:48:31,256 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:31,661 - Test: [   10/   39]    Loss 0.605957    Top1 90.078125    Top5 99.648438    
2018-11-01 10:48:31,764 - Test: [   20/   39]    Loss 0.601169    Top1 90.527344    Top5 99.492188    
2018-11-01 10:48:31,863 - Test: [   30/   39]    Loss 0.598533    Top1 90.481771    Top5 99.596354    
2018-11-01 10:48:31,954 - Test: [   40/   39]    Loss 0.587484    Top1 90.700000    Top5 99.600000    
2018-11-01 10:48:31,979 - ==> Top1: 90.700    Top5: 99.600    Loss: 0.587

2018-11-01 10:48:31,980 - Testing sensitivity of module.layer2.1.conv1.weight [30.0% sparsity]
2018-11-01 10:48:31,983 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 10:48:31,985 - --- test ---------------------
2018-11-01 10:48:31,985 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:32,397 - Test: [   10/   39]    Loss 0.621935    Top1 89.882812    Top5 99.609375    
2018-11-01 10:48:32,500 - Test: [   20/   39]    Loss 0.615427    Top1 90.351562    Top5 99.472656    
2018-11-01 10:48:32,599 - Test: [   30/   39]    Loss 0.617661    Top1 90.182292    Top5 99.583333    
2018-11-01 10:48:32,690 - Test: [   40/   39]    Loss 0.605041    Top1 90.350000    Top5 99.600000    
2018-11-01 10:48:32,715 - ==> Top1: 90.350    Top5: 99.600    Loss: 0.605

2018-11-01 10:48:32,717 - Testing sensitivity of module.layer2.1.conv1.weight [35.0% sparsity]
2018-11-01 10:48:32,720 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 10:48:32,721 - --- test ---------------------
2018-11-01 10:48:32,721 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:33,132 - Test: [   10/   39]    Loss 0.646229    Top1 89.648438    Top5 99.570312    
2018-11-01 10:48:33,238 - Test: [   20/   39]    Loss 0.645236    Top1 90.039062    Top5 99.433594    
2018-11-01 10:48:33,342 - Test: [   30/   39]    Loss 0.650009    Top1 89.908854    Top5 99.544271    
2018-11-01 10:48:33,437 - Test: [   40/   39]    Loss 0.634936    Top1 90.050000    Top5 99.540000    
2018-11-01 10:48:33,461 - ==> Top1: 90.050    Top5: 99.540    Loss: 0.635

2018-11-01 10:48:33,462 - Testing sensitivity of module.layer2.1.conv1.weight [40.0% sparsity]
2018-11-01 10:48:33,464 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 10:48:33,465 - --- test ---------------------
2018-11-01 10:48:33,465 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:33,881 - Test: [   10/   39]    Loss 0.646872    Top1 89.492188    Top5 99.492188    
2018-11-01 10:48:33,986 - Test: [   20/   39]    Loss 0.651286    Top1 89.765625    Top5 99.414062    
2018-11-01 10:48:34,085 - Test: [   30/   39]    Loss 0.652988    Top1 89.726562    Top5 99.544271    
2018-11-01 10:48:34,176 - Test: [   40/   39]    Loss 0.639587    Top1 89.860000    Top5 99.540000    
2018-11-01 10:48:34,201 - ==> Top1: 89.860    Top5: 99.540    Loss: 0.640

2018-11-01 10:48:34,202 - Testing sensitivity of module.layer2.1.conv1.weight [45.0% sparsity]
2018-11-01 10:48:34,205 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 10:48:34,206 - --- test ---------------------
2018-11-01 10:48:34,206 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:34,629 - Test: [   10/   39]    Loss 0.647368    Top1 88.984375    Top5 99.453125    
2018-11-01 10:48:34,730 - Test: [   20/   39]    Loss 0.654171    Top1 89.140625    Top5 99.335938    
2018-11-01 10:48:34,829 - Test: [   30/   39]    Loss 0.655481    Top1 89.231771    Top5 99.453125    
2018-11-01 10:48:34,921 - Test: [   40/   39]    Loss 0.646008    Top1 89.500000    Top5 99.450000    
2018-11-01 10:48:34,945 - ==> Top1: 89.500    Top5: 99.450    Loss: 0.646

2018-11-01 10:48:34,946 - Testing sensitivity of module.layer2.1.conv1.weight [50.0% sparsity]
2018-11-01 10:48:34,949 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 10:48:34,950 - --- test ---------------------
2018-11-01 10:48:34,951 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:35,372 - Test: [   10/   39]    Loss 0.657484    Top1 88.906250    Top5 99.570312    
2018-11-01 10:48:35,478 - Test: [   20/   39]    Loss 0.662999    Top1 89.121094    Top5 99.394531    
2018-11-01 10:48:35,582 - Test: [   30/   39]    Loss 0.668763    Top1 89.127604    Top5 99.505208    
2018-11-01 10:48:35,678 - Test: [   40/   39]    Loss 0.659830    Top1 89.430000    Top5 99.440000    
2018-11-01 10:48:35,703 - ==> Top1: 89.430    Top5: 99.440    Loss: 0.660

2018-11-01 10:48:35,704 - Testing sensitivity of module.layer2.1.conv1.weight [55.0% sparsity]
2018-11-01 10:48:35,706 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 10:48:35,707 - --- test ---------------------
2018-11-01 10:48:35,707 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:36,119 - Test: [   10/   39]    Loss 0.667995    Top1 89.453125    Top5 99.414062    
2018-11-01 10:48:36,226 - Test: [   20/   39]    Loss 0.673734    Top1 89.355469    Top5 99.316406    
2018-11-01 10:48:36,330 - Test: [   30/   39]    Loss 0.675684    Top1 89.309896    Top5 99.453125    
2018-11-01 10:48:36,421 - Test: [   40/   39]    Loss 0.665706    Top1 89.550000    Top5 99.420000    
2018-11-01 10:48:36,445 - ==> Top1: 89.550    Top5: 99.420    Loss: 0.666

2018-11-01 10:48:36,446 - Testing sensitivity of module.layer2.1.conv1.weight [60.0% sparsity]
2018-11-01 10:48:36,449 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 10:48:36,450 - --- test ---------------------
2018-11-01 10:48:36,450 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:36,856 - Test: [   10/   39]    Loss 0.707731    Top1 89.101562    Top5 99.375000    
2018-11-01 10:48:36,959 - Test: [   20/   39]    Loss 0.707542    Top1 88.984375    Top5 99.316406    
2018-11-01 10:48:37,058 - Test: [   30/   39]    Loss 0.698794    Top1 89.101562    Top5 99.401042    
2018-11-01 10:48:37,149 - Test: [   40/   39]    Loss 0.690116    Top1 89.300000    Top5 99.330000    
2018-11-01 10:48:37,175 - ==> Top1: 89.300    Top5: 99.330    Loss: 0.690

2018-11-01 10:48:37,176 - Testing sensitivity of module.layer2.1.conv1.weight [65.0% sparsity]
2018-11-01 10:48:37,179 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 10:48:37,180 - --- test ---------------------
2018-11-01 10:48:37,180 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:37,591 - Test: [   10/   39]    Loss 0.739185    Top1 88.398438    Top5 99.296875    
2018-11-01 10:48:37,693 - Test: [   20/   39]    Loss 0.740900    Top1 88.300781    Top5 99.277344    
2018-11-01 10:48:37,792 - Test: [   30/   39]    Loss 0.729936    Top1 88.554688    Top5 99.375000    
2018-11-01 10:48:37,886 - Test: [   40/   39]    Loss 0.717568    Top1 88.750000    Top5 99.310000    
2018-11-01 10:48:37,913 - ==> Top1: 88.750    Top5: 99.310    Loss: 0.718

2018-11-01 10:48:37,914 - Testing sensitivity of module.layer2.1.conv1.weight [70.0% sparsity]
2018-11-01 10:48:37,918 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 10:48:37,920 - --- test ---------------------
2018-11-01 10:48:37,920 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:38,357 - Test: [   10/   39]    Loss 0.766705    Top1 87.890625    Top5 99.179688    
2018-11-01 10:48:38,464 - Test: [   20/   39]    Loss 0.765750    Top1 88.046875    Top5 99.140625    
2018-11-01 10:48:38,567 - Test: [   30/   39]    Loss 0.757735    Top1 88.229167    Top5 99.283854    
2018-11-01 10:48:38,662 - Test: [   40/   39]    Loss 0.736200    Top1 88.510000    Top5 99.260000    
2018-11-01 10:48:38,688 - ==> Top1: 88.510    Top5: 99.260    Loss: 0.736

2018-11-01 10:48:38,689 - Testing sensitivity of module.layer2.1.conv1.weight [75.0% sparsity]
2018-11-01 10:48:38,692 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 10:48:38,693 - --- test ---------------------
2018-11-01 10:48:38,693 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:39,114 - Test: [   10/   39]    Loss 0.854025    Top1 86.796875    Top5 99.140625    
2018-11-01 10:48:39,217 - Test: [   20/   39]    Loss 0.844206    Top1 86.738281    Top5 99.121094    
2018-11-01 10:48:39,316 - Test: [   30/   39]    Loss 0.840959    Top1 86.848958    Top5 99.179688    
2018-11-01 10:48:39,407 - Test: [   40/   39]    Loss 0.817771    Top1 87.250000    Top5 99.170000    
2018-11-01 10:48:39,432 - ==> Top1: 87.250    Top5: 99.170    Loss: 0.818

2018-11-01 10:48:39,433 - Testing sensitivity of module.layer2.1.conv1.weight [80.0% sparsity]
2018-11-01 10:48:39,436 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 10:48:39,437 - --- test ---------------------
2018-11-01 10:48:39,437 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:39,840 - Test: [   10/   39]    Loss 0.887391    Top1 86.562500    Top5 99.140625    
2018-11-01 10:48:39,943 - Test: [   20/   39]    Loss 0.878512    Top1 86.347656    Top5 99.101562    
2018-11-01 10:48:40,041 - Test: [   30/   39]    Loss 0.875382    Top1 86.263021    Top5 99.218750    
2018-11-01 10:48:40,133 - Test: [   40/   39]    Loss 0.848470    Top1 86.670000    Top5 99.200000    
2018-11-01 10:48:40,158 - ==> Top1: 86.670    Top5: 99.200    Loss: 0.848

2018-11-01 10:48:40,159 - Testing sensitivity of module.layer2.1.conv1.weight [85.0% sparsity]
2018-11-01 10:48:40,162 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 10:48:40,164 - --- test ---------------------
2018-11-01 10:48:40,164 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:40,572 - Test: [   10/   39]    Loss 0.919223    Top1 85.429688    Top5 99.140625    
2018-11-01 10:48:40,674 - Test: [   20/   39]    Loss 0.934991    Top1 85.371094    Top5 98.964844    
2018-11-01 10:48:40,773 - Test: [   30/   39]    Loss 0.945123    Top1 85.559896    Top5 99.023438    
2018-11-01 10:48:40,865 - Test: [   40/   39]    Loss 0.925678    Top1 85.620000    Top5 99.040000    
2018-11-01 10:48:40,891 - ==> Top1: 85.620    Top5: 99.040    Loss: 0.926

2018-11-01 10:48:40,891 - Testing sensitivity of module.layer2.1.conv1.weight [90.0% sparsity]
2018-11-01 10:48:40,894 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 10:48:40,896 - --- test ---------------------
2018-11-01 10:48:40,896 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:41,306 - Test: [   10/   39]    Loss 0.940161    Top1 84.765625    Top5 99.023438    
2018-11-01 10:48:41,408 - Test: [   20/   39]    Loss 0.952630    Top1 84.726562    Top5 98.886719    
2018-11-01 10:48:41,507 - Test: [   30/   39]    Loss 0.970009    Top1 84.778646    Top5 98.945312    
2018-11-01 10:48:41,598 - Test: [   40/   39]    Loss 0.949107    Top1 84.960000    Top5 98.970000    
2018-11-01 10:48:41,623 - ==> Top1: 84.960    Top5: 98.970    Loss: 0.949

2018-11-01 10:48:41,636 - Testing sensitivity of module.layer2.1.conv2.weight [0.0% sparsity]
2018-11-01 10:48:41,639 - --- test ---------------------
2018-11-01 10:48:41,639 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:42,048 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:48:42,150 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:48:42,249 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:48:42,340 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:48:42,365 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:48:42,366 - Testing sensitivity of module.layer2.1.conv2.weight [5.0% sparsity]
2018-11-01 10:48:42,369 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 10:48:42,370 - --- test ---------------------
2018-11-01 10:48:42,370 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:42,763 - Test: [   10/   39]    Loss 0.549199    Top1 91.015625    Top5 99.570312    
2018-11-01 10:48:42,866 - Test: [   20/   39]    Loss 0.555716    Top1 91.289062    Top5 99.531250    
2018-11-01 10:48:42,969 - Test: [   30/   39]    Loss 0.550060    Top1 91.276042    Top5 99.609375    
2018-11-01 10:48:43,065 - Test: [   40/   39]    Loss 0.548026    Top1 91.340000    Top5 99.610000    
2018-11-01 10:48:43,090 - ==> Top1: 91.340    Top5: 99.610    Loss: 0.548

2018-11-01 10:48:43,090 - Testing sensitivity of module.layer2.1.conv2.weight [10.0% sparsity]
2018-11-01 10:48:43,093 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 10:48:43,094 - --- test ---------------------
2018-11-01 10:48:43,095 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:43,626 - Test: [   10/   39]    Loss 0.556685    Top1 90.898438    Top5 99.648438    
2018-11-01 10:48:43,731 - Test: [   20/   39]    Loss 0.563770    Top1 91.113281    Top5 99.589844    
2018-11-01 10:48:43,834 - Test: [   30/   39]    Loss 0.555415    Top1 91.106771    Top5 99.661458    
2018-11-01 10:48:43,927 - Test: [   40/   39]    Loss 0.553615    Top1 91.130000    Top5 99.650000    
2018-11-01 10:48:43,955 - ==> Top1: 91.130    Top5: 99.650    Loss: 0.554

2018-11-01 10:48:43,956 - Testing sensitivity of module.layer2.1.conv2.weight [15.0% sparsity]
2018-11-01 10:48:43,959 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 10:48:43,960 - --- test ---------------------
2018-11-01 10:48:43,960 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:44,473 - Test: [   10/   39]    Loss 0.552504    Top1 91.015625    Top5 99.648438    
2018-11-01 10:48:44,574 - Test: [   20/   39]    Loss 0.562462    Top1 91.113281    Top5 99.589844    
2018-11-01 10:48:44,673 - Test: [   30/   39]    Loss 0.555194    Top1 91.002604    Top5 99.648438    
2018-11-01 10:48:44,764 - Test: [   40/   39]    Loss 0.554590    Top1 91.010000    Top5 99.650000    
2018-11-01 10:48:44,792 - ==> Top1: 91.010    Top5: 99.650    Loss: 0.555

2018-11-01 10:48:44,792 - Testing sensitivity of module.layer2.1.conv2.weight [20.0% sparsity]
2018-11-01 10:48:44,795 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 10:48:44,795 - --- test ---------------------
2018-11-01 10:48:44,796 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:45,210 - Test: [   10/   39]    Loss 0.553008    Top1 91.132812    Top5 99.609375    
2018-11-01 10:48:45,313 - Test: [   20/   39]    Loss 0.566242    Top1 91.132812    Top5 99.531250    
2018-11-01 10:48:45,412 - Test: [   30/   39]    Loss 0.560007    Top1 91.106771    Top5 99.596354    
2018-11-01 10:48:45,503 - Test: [   40/   39]    Loss 0.560677    Top1 91.090000    Top5 99.570000    
2018-11-01 10:48:45,529 - ==> Top1: 91.090    Top5: 99.570    Loss: 0.561

2018-11-01 10:48:45,529 - Testing sensitivity of module.layer2.1.conv2.weight [25.0% sparsity]
2018-11-01 10:48:45,533 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 10:48:45,534 - --- test ---------------------
2018-11-01 10:48:45,534 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:45,944 - Test: [   10/   39]    Loss 0.565503    Top1 90.742188    Top5 99.648438    
2018-11-01 10:48:46,047 - Test: [   20/   39]    Loss 0.576371    Top1 90.644531    Top5 99.531250    
2018-11-01 10:48:46,146 - Test: [   30/   39]    Loss 0.571224    Top1 90.638021    Top5 99.583333    
2018-11-01 10:48:46,237 - Test: [   40/   39]    Loss 0.578133    Top1 90.730000    Top5 99.580000    
2018-11-01 10:48:46,263 - ==> Top1: 90.730    Top5: 99.580    Loss: 0.578

2018-11-01 10:48:46,264 - Testing sensitivity of module.layer2.1.conv2.weight [30.0% sparsity]
2018-11-01 10:48:46,267 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 10:48:46,268 - --- test ---------------------
2018-11-01 10:48:46,268 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:46,679 - Test: [   10/   39]    Loss 0.561993    Top1 90.664062    Top5 99.609375    
2018-11-01 10:48:46,781 - Test: [   20/   39]    Loss 0.567029    Top1 90.898438    Top5 99.492188    
2018-11-01 10:48:46,881 - Test: [   30/   39]    Loss 0.564004    Top1 90.755208    Top5 99.544271    
2018-11-01 10:48:46,972 - Test: [   40/   39]    Loss 0.569731    Top1 90.810000    Top5 99.550000    
2018-11-01 10:48:46,997 - ==> Top1: 90.810    Top5: 99.550    Loss: 0.570

2018-11-01 10:48:46,998 - Testing sensitivity of module.layer2.1.conv2.weight [35.0% sparsity]
2018-11-01 10:48:47,000 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 10:48:47,001 - --- test ---------------------
2018-11-01 10:48:47,001 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:47,414 - Test: [   10/   39]    Loss 0.588981    Top1 90.546875    Top5 99.492188    
2018-11-01 10:48:47,517 - Test: [   20/   39]    Loss 0.591285    Top1 90.488281    Top5 99.375000    
2018-11-01 10:48:47,616 - Test: [   30/   39]    Loss 0.588054    Top1 90.416667    Top5 99.440104    
2018-11-01 10:48:47,708 - Test: [   40/   39]    Loss 0.589714    Top1 90.570000    Top5 99.460000    
2018-11-01 10:48:47,732 - ==> Top1: 90.570    Top5: 99.460    Loss: 0.590

2018-11-01 10:48:47,733 - Testing sensitivity of module.layer2.1.conv2.weight [40.0% sparsity]
2018-11-01 10:48:47,736 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 10:48:47,737 - --- test ---------------------
2018-11-01 10:48:47,737 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:48,162 - Test: [   10/   39]    Loss 0.590236    Top1 90.312500    Top5 99.453125    
2018-11-01 10:48:48,264 - Test: [   20/   39]    Loss 0.594294    Top1 90.292969    Top5 99.355469    
2018-11-01 10:48:48,363 - Test: [   30/   39]    Loss 0.594014    Top1 90.364583    Top5 99.440104    
2018-11-01 10:48:48,454 - Test: [   40/   39]    Loss 0.593772    Top1 90.520000    Top5 99.460000    
2018-11-01 10:48:48,479 - ==> Top1: 90.520    Top5: 99.460    Loss: 0.594

2018-11-01 10:48:48,480 - Testing sensitivity of module.layer2.1.conv2.weight [45.0% sparsity]
2018-11-01 10:48:48,483 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 10:48:48,484 - --- test ---------------------
2018-11-01 10:48:48,484 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:48,892 - Test: [   10/   39]    Loss 0.618405    Top1 89.414062    Top5 99.414062    
2018-11-01 10:48:48,995 - Test: [   20/   39]    Loss 0.624410    Top1 89.785156    Top5 99.414062    
2018-11-01 10:48:49,093 - Test: [   30/   39]    Loss 0.626403    Top1 89.830729    Top5 99.492188    
2018-11-01 10:48:49,185 - Test: [   40/   39]    Loss 0.619466    Top1 90.040000    Top5 99.510000    
2018-11-01 10:48:49,210 - ==> Top1: 90.040    Top5: 99.510    Loss: 0.619

2018-11-01 10:48:49,211 - Testing sensitivity of module.layer2.1.conv2.weight [50.0% sparsity]
2018-11-01 10:48:49,213 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 10:48:49,214 - --- test ---------------------
2018-11-01 10:48:49,214 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:49,621 - Test: [   10/   39]    Loss 0.623910    Top1 89.804688    Top5 99.414062    
2018-11-01 10:48:49,723 - Test: [   20/   39]    Loss 0.630116    Top1 89.746094    Top5 99.453125    
2018-11-01 10:48:49,822 - Test: [   30/   39]    Loss 0.635524    Top1 89.726562    Top5 99.466146    
2018-11-01 10:48:49,915 - Test: [   40/   39]    Loss 0.630721    Top1 89.890000    Top5 99.470000    
2018-11-01 10:48:49,940 - ==> Top1: 89.890    Top5: 99.470    Loss: 0.631

2018-11-01 10:48:49,941 - Testing sensitivity of module.layer2.1.conv2.weight [55.0% sparsity]
2018-11-01 10:48:49,944 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 10:48:49,946 - --- test ---------------------
2018-11-01 10:48:49,946 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:50,370 - Test: [   10/   39]    Loss 0.643878    Top1 89.531250    Top5 99.335938    
2018-11-01 10:48:50,475 - Test: [   20/   39]    Loss 0.650108    Top1 89.667969    Top5 99.414062    
2018-11-01 10:48:50,579 - Test: [   30/   39]    Loss 0.650953    Top1 89.648438    Top5 99.479167    
2018-11-01 10:48:50,673 - Test: [   40/   39]    Loss 0.646724    Top1 89.820000    Top5 99.480000    
2018-11-01 10:48:50,699 - ==> Top1: 89.820    Top5: 99.480    Loss: 0.647

2018-11-01 10:48:50,700 - Testing sensitivity of module.layer2.1.conv2.weight [60.0% sparsity]
2018-11-01 10:48:50,702 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 10:48:50,702 - --- test ---------------------
2018-11-01 10:48:50,703 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:51,130 - Test: [   10/   39]    Loss 0.762075    Top1 87.968750    Top5 99.062500    
2018-11-01 10:48:51,237 - Test: [   20/   39]    Loss 0.754456    Top1 88.300781    Top5 99.101562    
2018-11-01 10:48:51,338 - Test: [   30/   39]    Loss 0.749485    Top1 88.411458    Top5 99.270833    
2018-11-01 10:48:51,429 - Test: [   40/   39]    Loss 0.734432    Top1 88.580000    Top5 99.230000    
2018-11-01 10:48:51,453 - ==> Top1: 88.580    Top5: 99.230    Loss: 0.734

2018-11-01 10:48:51,456 - Testing sensitivity of module.layer2.1.conv2.weight [65.0% sparsity]
2018-11-01 10:48:51,460 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 10:48:51,461 - --- test ---------------------
2018-11-01 10:48:51,461 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:51,883 - Test: [   10/   39]    Loss 0.778768    Top1 87.890625    Top5 99.023438    
2018-11-01 10:48:51,989 - Test: [   20/   39]    Loss 0.764023    Top1 88.125000    Top5 99.062500    
2018-11-01 10:48:52,095 - Test: [   30/   39]    Loss 0.761045    Top1 88.138021    Top5 99.218750    
2018-11-01 10:48:52,192 - Test: [   40/   39]    Loss 0.746037    Top1 88.330000    Top5 99.190000    
2018-11-01 10:48:52,217 - ==> Top1: 88.330    Top5: 99.190    Loss: 0.746

2018-11-01 10:48:52,218 - Testing sensitivity of module.layer2.1.conv2.weight [70.0% sparsity]
2018-11-01 10:48:52,222 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 10:48:52,224 - --- test ---------------------
2018-11-01 10:48:52,224 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:52,635 - Test: [   10/   39]    Loss 0.815879    Top1 86.953125    Top5 99.140625    
2018-11-01 10:48:52,736 - Test: [   20/   39]    Loss 0.800904    Top1 87.597656    Top5 99.179688    
2018-11-01 10:48:52,835 - Test: [   30/   39]    Loss 0.792020    Top1 87.591146    Top5 99.231771    
2018-11-01 10:48:52,925 - Test: [   40/   39]    Loss 0.782846    Top1 87.750000    Top5 99.220000    
2018-11-01 10:48:52,951 - ==> Top1: 87.750    Top5: 99.220    Loss: 0.783

2018-11-01 10:48:52,952 - Testing sensitivity of module.layer2.1.conv2.weight [75.0% sparsity]
2018-11-01 10:48:52,955 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 10:48:52,956 - --- test ---------------------
2018-11-01 10:48:52,956 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:53,364 - Test: [   10/   39]    Loss 0.954346    Top1 85.390625    Top5 99.296875    
2018-11-01 10:48:53,466 - Test: [   20/   39]    Loss 0.920286    Top1 86.015625    Top5 99.238281    
2018-11-01 10:48:53,565 - Test: [   30/   39]    Loss 0.939012    Top1 85.611979    Top5 99.244792    
2018-11-01 10:48:53,656 - Test: [   40/   39]    Loss 0.928119    Top1 85.870000    Top5 99.240000    
2018-11-01 10:48:53,682 - ==> Top1: 85.870    Top5: 99.240    Loss: 0.928

2018-11-01 10:48:53,683 - Testing sensitivity of module.layer2.1.conv2.weight [80.0% sparsity]
2018-11-01 10:48:53,685 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 10:48:53,686 - --- test ---------------------
2018-11-01 10:48:53,686 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:54,096 - Test: [   10/   39]    Loss 0.980280    Top1 85.273438    Top5 99.296875    
2018-11-01 10:48:54,198 - Test: [   20/   39]    Loss 0.940387    Top1 85.742188    Top5 99.218750    
2018-11-01 10:48:54,298 - Test: [   30/   39]    Loss 0.961367    Top1 85.338542    Top5 99.257812    
2018-11-01 10:48:54,389 - Test: [   40/   39]    Loss 0.951266    Top1 85.580000    Top5 99.230000    
2018-11-01 10:48:54,415 - ==> Top1: 85.580    Top5: 99.230    Loss: 0.951

2018-11-01 10:48:54,415 - Testing sensitivity of module.layer2.1.conv2.weight [85.0% sparsity]
2018-11-01 10:48:54,418 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 10:48:54,419 - --- test ---------------------
2018-11-01 10:48:54,419 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:54,832 - Test: [   10/   39]    Loss 1.001341    Top1 84.414062    Top5 99.062500    
2018-11-01 10:48:54,938 - Test: [   20/   39]    Loss 0.972804    Top1 84.511719    Top5 98.984375    
2018-11-01 10:48:55,043 - Test: [   30/   39]    Loss 0.990579    Top1 84.375000    Top5 99.023438    
2018-11-01 10:48:55,138 - Test: [   40/   39]    Loss 0.982297    Top1 84.820000    Top5 99.030000    
2018-11-01 10:48:55,164 - ==> Top1: 84.820    Top5: 99.030    Loss: 0.982

2018-11-01 10:48:55,164 - Testing sensitivity of module.layer2.1.conv2.weight [90.0% sparsity]
2018-11-01 10:48:55,167 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 10:48:55,167 - --- test ---------------------
2018-11-01 10:48:55,167 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:55,580 - Test: [   10/   39]    Loss 1.270277    Top1 82.578125    Top5 98.437500    
2018-11-01 10:48:55,683 - Test: [   20/   39]    Loss 1.243412    Top1 82.109375    Top5 98.398438    
2018-11-01 10:48:55,782 - Test: [   30/   39]    Loss 1.256036    Top1 81.861979    Top5 98.489583    
2018-11-01 10:48:55,874 - Test: [   40/   39]    Loss 1.234021    Top1 82.030000    Top5 98.580000    
2018-11-01 10:48:55,899 - ==> Top1: 82.030    Top5: 98.580    Loss: 1.234

2018-11-01 10:48:55,913 - Testing sensitivity of module.layer2.2.conv1.weight [0.0% sparsity]
2018-11-01 10:48:55,918 - --- test ---------------------
2018-11-01 10:48:55,918 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:56,286 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:48:56,388 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:48:56,487 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:48:56,578 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:48:56,603 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:48:56,604 - Testing sensitivity of module.layer2.2.conv1.weight [5.0% sparsity]
2018-11-01 10:48:56,607 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 10:48:56,608 - --- test ---------------------
2018-11-01 10:48:56,608 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:57,026 - Test: [   10/   39]    Loss 0.565350    Top1 91.054688    Top5 99.648438    
2018-11-01 10:48:57,128 - Test: [   20/   39]    Loss 0.563250    Top1 91.367188    Top5 99.570312    
2018-11-01 10:48:57,227 - Test: [   30/   39]    Loss 0.556386    Top1 91.289062    Top5 99.661458    
2018-11-01 10:48:57,318 - Test: [   40/   39]    Loss 0.548743    Top1 91.350000    Top5 99.630000    
2018-11-01 10:48:57,344 - ==> Top1: 91.350    Top5: 99.630    Loss: 0.549

2018-11-01 10:48:57,345 - Testing sensitivity of module.layer2.2.conv1.weight [10.0% sparsity]
2018-11-01 10:48:57,348 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 10:48:57,349 - --- test ---------------------
2018-11-01 10:48:57,350 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:57,768 - Test: [   10/   39]    Loss 0.580148    Top1 90.546875    Top5 99.531250    
2018-11-01 10:48:57,871 - Test: [   20/   39]    Loss 0.576325    Top1 90.859375    Top5 99.550781    
2018-11-01 10:48:57,970 - Test: [   30/   39]    Loss 0.572550    Top1 90.638021    Top5 99.622396    
2018-11-01 10:48:58,061 - Test: [   40/   39]    Loss 0.569871    Top1 90.680000    Top5 99.590000    
2018-11-01 10:48:58,088 - ==> Top1: 90.680    Top5: 99.590    Loss: 0.570

2018-11-01 10:48:58,089 - Testing sensitivity of module.layer2.2.conv1.weight [15.0% sparsity]
2018-11-01 10:48:58,093 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 10:48:58,094 - --- test ---------------------
2018-11-01 10:48:58,094 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:58,505 - Test: [   10/   39]    Loss 0.580991    Top1 90.429688    Top5 99.570312    
2018-11-01 10:48:58,607 - Test: [   20/   39]    Loss 0.576518    Top1 90.859375    Top5 99.550781    
2018-11-01 10:48:58,706 - Test: [   30/   39]    Loss 0.573651    Top1 90.677083    Top5 99.609375    
2018-11-01 10:48:58,797 - Test: [   40/   39]    Loss 0.570803    Top1 90.730000    Top5 99.560000    
2018-11-01 10:48:58,824 - ==> Top1: 90.730    Top5: 99.560    Loss: 0.571

2018-11-01 10:48:58,825 - Testing sensitivity of module.layer2.2.conv1.weight [20.0% sparsity]
2018-11-01 10:48:58,828 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 10:48:58,829 - --- test ---------------------
2018-11-01 10:48:58,829 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:59,233 - Test: [   10/   39]    Loss 0.602314    Top1 89.726562    Top5 99.492188    
2018-11-01 10:48:59,335 - Test: [   20/   39]    Loss 0.604324    Top1 90.195312    Top5 99.453125    
2018-11-01 10:48:59,434 - Test: [   30/   39]    Loss 0.600186    Top1 90.078125    Top5 99.518229    
2018-11-01 10:48:59,525 - Test: [   40/   39]    Loss 0.596816    Top1 90.160000    Top5 99.520000    
2018-11-01 10:48:59,550 - ==> Top1: 90.160    Top5: 99.520    Loss: 0.597

2018-11-01 10:48:59,551 - Testing sensitivity of module.layer2.2.conv1.weight [25.0% sparsity]
2018-11-01 10:48:59,554 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 10:48:59,555 - --- test ---------------------
2018-11-01 10:48:59,556 - 10000 samples (256 per mini-batch)
2018-11-01 10:48:59,960 - Test: [   10/   39]    Loss 0.692765    Top1 87.851562    Top5 99.296875    
2018-11-01 10:49:00,062 - Test: [   20/   39]    Loss 0.677476    Top1 88.281250    Top5 99.160156    
2018-11-01 10:49:00,162 - Test: [   30/   39]    Loss 0.669444    Top1 88.007812    Top5 99.166667    
2018-11-01 10:49:00,253 - Test: [   40/   39]    Loss 0.666674    Top1 88.040000    Top5 99.130000    
2018-11-01 10:49:00,278 - ==> Top1: 88.040    Top5: 99.130    Loss: 0.667

2018-11-01 10:49:00,279 - Testing sensitivity of module.layer2.2.conv1.weight [30.0% sparsity]
2018-11-01 10:49:00,282 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 10:49:00,283 - --- test ---------------------
2018-11-01 10:49:00,283 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:00,692 - Test: [   10/   39]    Loss 0.697242    Top1 87.382812    Top5 99.257812    
2018-11-01 10:49:00,795 - Test: [   20/   39]    Loss 0.680780    Top1 88.007812    Top5 99.179688    
2018-11-01 10:49:00,895 - Test: [   30/   39]    Loss 0.674115    Top1 87.812500    Top5 99.192708    
2018-11-01 10:49:00,987 - Test: [   40/   39]    Loss 0.671197    Top1 87.850000    Top5 99.150000    
2018-11-01 10:49:01,012 - ==> Top1: 87.850    Top5: 99.150    Loss: 0.671

2018-11-01 10:49:01,013 - Testing sensitivity of module.layer2.2.conv1.weight [35.0% sparsity]
2018-11-01 10:49:01,016 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 10:49:01,017 - --- test ---------------------
2018-11-01 10:49:01,017 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:01,431 - Test: [   10/   39]    Loss 0.733100    Top1 86.796875    Top5 99.023438    
2018-11-01 10:49:01,533 - Test: [   20/   39]    Loss 0.707505    Top1 87.343750    Top5 98.964844    
2018-11-01 10:49:01,632 - Test: [   30/   39]    Loss 0.700071    Top1 87.265625    Top5 98.984375    
2018-11-01 10:49:01,723 - Test: [   40/   39]    Loss 0.700097    Top1 87.290000    Top5 98.990000    
2018-11-01 10:49:01,750 - ==> Top1: 87.290    Top5: 98.990    Loss: 0.700

2018-11-01 10:49:01,750 - Testing sensitivity of module.layer2.2.conv1.weight [40.0% sparsity]
2018-11-01 10:49:01,754 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 10:49:01,755 - --- test ---------------------
2018-11-01 10:49:01,755 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:02,174 - Test: [   10/   39]    Loss 0.744420    Top1 86.289062    Top5 99.023438    
2018-11-01 10:49:02,276 - Test: [   20/   39]    Loss 0.723221    Top1 86.953125    Top5 98.945312    
2018-11-01 10:49:02,376 - Test: [   30/   39]    Loss 0.715662    Top1 86.822917    Top5 98.971354    
2018-11-01 10:49:02,467 - Test: [   40/   39]    Loss 0.714545    Top1 86.820000    Top5 98.980000    
2018-11-01 10:49:02,493 - ==> Top1: 86.820    Top5: 98.980    Loss: 0.715

2018-11-01 10:49:02,493 - Testing sensitivity of module.layer2.2.conv1.weight [45.0% sparsity]
2018-11-01 10:49:02,496 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 10:49:02,497 - --- test ---------------------
2018-11-01 10:49:02,497 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:02,908 - Test: [   10/   39]    Loss 0.723983    Top1 86.718750    Top5 99.179688    
2018-11-01 10:49:03,009 - Test: [   20/   39]    Loss 0.711459    Top1 87.089844    Top5 99.140625    
2018-11-01 10:49:03,108 - Test: [   30/   39]    Loss 0.707039    Top1 86.927083    Top5 99.140625    
2018-11-01 10:49:03,199 - Test: [   40/   39]    Loss 0.705748    Top1 86.950000    Top5 99.170000    
2018-11-01 10:49:03,228 - ==> Top1: 86.950    Top5: 99.170    Loss: 0.706

2018-11-01 10:49:03,229 - Testing sensitivity of module.layer2.2.conv1.weight [50.0% sparsity]
2018-11-01 10:49:03,231 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 10:49:03,232 - --- test ---------------------
2018-11-01 10:49:03,232 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:03,642 - Test: [   10/   39]    Loss 1.110544    Top1 82.656250    Top5 98.515625    
2018-11-01 10:49:03,745 - Test: [   20/   39]    Loss 1.086159    Top1 82.988281    Top5 98.417969    
2018-11-01 10:49:03,845 - Test: [   30/   39]    Loss 1.067209    Top1 82.903646    Top5 98.385417    
2018-11-01 10:49:03,936 - Test: [   40/   39]    Loss 1.064480    Top1 82.930000    Top5 98.400000    
2018-11-01 10:49:03,960 - ==> Top1: 82.930    Top5: 98.400    Loss: 1.064

2018-11-01 10:49:03,961 - Testing sensitivity of module.layer2.2.conv1.weight [55.0% sparsity]
2018-11-01 10:49:03,964 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 10:49:03,965 - --- test ---------------------
2018-11-01 10:49:03,966 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:04,379 - Test: [   10/   39]    Loss 1.149111    Top1 81.640625    Top5 98.046875    
2018-11-01 10:49:04,481 - Test: [   20/   39]    Loss 1.125226    Top1 82.089844    Top5 98.144531    
2018-11-01 10:49:04,580 - Test: [   30/   39]    Loss 1.109450    Top1 82.161458    Top5 98.203125    
2018-11-01 10:49:04,671 - Test: [   40/   39]    Loss 1.108342    Top1 82.130000    Top5 98.210000    
2018-11-01 10:49:04,697 - ==> Top1: 82.130    Top5: 98.210    Loss: 1.108

2018-11-01 10:49:04,698 - Testing sensitivity of module.layer2.2.conv1.weight [60.0% sparsity]
2018-11-01 10:49:04,702 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 10:49:04,703 - --- test ---------------------
2018-11-01 10:49:04,703 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:05,122 - Test: [   10/   39]    Loss 1.377101    Top1 78.281250    Top5 97.382812    
2018-11-01 10:49:05,225 - Test: [   20/   39]    Loss 1.353666    Top1 78.730469    Top5 97.304688    
2018-11-01 10:49:05,324 - Test: [   30/   39]    Loss 1.331291    Top1 78.997396    Top5 97.460938    
2018-11-01 10:49:05,415 - Test: [   40/   39]    Loss 1.332836    Top1 79.060000    Top5 97.540000    
2018-11-01 10:49:05,448 - ==> Top1: 79.060    Top5: 97.540    Loss: 1.333

2018-11-01 10:49:05,448 - Testing sensitivity of module.layer2.2.conv1.weight [65.0% sparsity]
2018-11-01 10:49:05,451 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 10:49:05,452 - --- test ---------------------
2018-11-01 10:49:05,452 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:05,855 - Test: [   10/   39]    Loss 1.412030    Top1 77.539062    Top5 97.421875    
2018-11-01 10:49:05,958 - Test: [   20/   39]    Loss 1.384337    Top1 78.242188    Top5 97.207031    
2018-11-01 10:49:06,057 - Test: [   30/   39]    Loss 1.367293    Top1 78.320312    Top5 97.317708    
2018-11-01 10:49:06,148 - Test: [   40/   39]    Loss 1.368538    Top1 78.370000    Top5 97.360000    
2018-11-01 10:49:06,175 - ==> Top1: 78.370    Top5: 97.360    Loss: 1.369

2018-11-01 10:49:06,176 - Testing sensitivity of module.layer2.2.conv1.weight [70.0% sparsity]
2018-11-01 10:49:06,179 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 10:49:06,180 - --- test ---------------------
2018-11-01 10:49:06,181 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:06,599 - Test: [   10/   39]    Loss 1.538544    Top1 75.585938    Top5 96.953125    
2018-11-01 10:49:06,702 - Test: [   20/   39]    Loss 1.510698    Top1 75.664062    Top5 96.777344    
2018-11-01 10:49:06,801 - Test: [   30/   39]    Loss 1.504115    Top1 75.559896    Top5 96.835938    
2018-11-01 10:49:06,892 - Test: [   40/   39]    Loss 1.508004    Top1 75.670000    Top5 96.890000    
2018-11-01 10:49:06,917 - ==> Top1: 75.670    Top5: 96.890    Loss: 1.508

2018-11-01 10:49:06,918 - Testing sensitivity of module.layer2.2.conv1.weight [75.0% sparsity]
2018-11-01 10:49:06,921 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 10:49:06,922 - --- test ---------------------
2018-11-01 10:49:06,922 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:07,334 - Test: [   10/   39]    Loss 2.196901    Top1 68.085938    Top5 93.632812    
2018-11-01 10:49:07,436 - Test: [   20/   39]    Loss 2.165608    Top1 68.417969    Top5 94.199219    
2018-11-01 10:49:07,535 - Test: [   30/   39]    Loss 2.148831    Top1 68.424479    Top5 94.270833    
2018-11-01 10:49:07,626 - Test: [   40/   39]    Loss 2.082801    Top1 68.800000    Top5 94.450000    
2018-11-01 10:49:07,651 - ==> Top1: 68.800    Top5: 94.450    Loss: 2.083

2018-11-01 10:49:07,652 - Testing sensitivity of module.layer2.2.conv1.weight [80.0% sparsity]
2018-11-01 10:49:07,655 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 10:49:07,656 - --- test ---------------------
2018-11-01 10:49:07,657 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:08,075 - Test: [   10/   39]    Loss 2.208033    Top1 68.710938    Top5 93.671875    
2018-11-01 10:49:08,176 - Test: [   20/   39]    Loss 2.190963    Top1 68.632812    Top5 94.179688    
2018-11-01 10:49:08,275 - Test: [   30/   39]    Loss 2.183430    Top1 68.593750    Top5 94.140625    
2018-11-01 10:49:08,367 - Test: [   40/   39]    Loss 2.123240    Top1 68.840000    Top5 94.410000    
2018-11-01 10:49:08,392 - ==> Top1: 68.840    Top5: 94.410    Loss: 2.123

2018-11-01 10:49:08,392 - Testing sensitivity of module.layer2.2.conv1.weight [85.0% sparsity]
2018-11-01 10:49:08,396 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 10:49:08,397 - --- test ---------------------
2018-11-01 10:49:08,397 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:08,811 - Test: [   10/   39]    Loss 4.432996    Top1 52.812500    Top5 88.671875    
2018-11-01 10:49:08,917 - Test: [   20/   39]    Loss 4.344583    Top1 53.789062    Top5 89.199219    
2018-11-01 10:49:09,021 - Test: [   30/   39]    Loss 4.368555    Top1 53.242188    Top5 89.062500    
2018-11-01 10:49:09,117 - Test: [   40/   39]    Loss 4.326426    Top1 53.400000    Top5 89.360000    
2018-11-01 10:49:09,143 - ==> Top1: 53.400    Top5: 89.360    Loss: 4.326

2018-11-01 10:49:09,144 - Testing sensitivity of module.layer2.2.conv1.weight [90.0% sparsity]
2018-11-01 10:49:09,146 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 10:49:09,147 - --- test ---------------------
2018-11-01 10:49:09,147 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:09,568 - Test: [   10/   39]    Loss 7.587868    Top1 37.812500    Top5 83.945312    
2018-11-01 10:49:09,670 - Test: [   20/   39]    Loss 7.325475    Top1 38.925781    Top5 84.335938    
2018-11-01 10:49:09,769 - Test: [   30/   39]    Loss 7.405726    Top1 38.658854    Top5 84.127604    
2018-11-01 10:49:09,860 - Test: [   40/   39]    Loss 7.407818    Top1 38.850000    Top5 84.370000    
2018-11-01 10:49:09,887 - ==> Top1: 38.850    Top5: 84.370    Loss: 7.408

2018-11-01 10:49:09,898 - Testing sensitivity of module.layer2.2.conv2.weight [0.0% sparsity]
2018-11-01 10:49:09,901 - --- test ---------------------
2018-11-01 10:49:09,902 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:10,311 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:49:10,417 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:49:10,521 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:49:10,616 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:49:10,641 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:49:10,642 - Testing sensitivity of module.layer2.2.conv2.weight [5.0% sparsity]
2018-11-01 10:49:10,644 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 10:49:10,645 - --- test ---------------------
2018-11-01 10:49:10,645 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:11,057 - Test: [   10/   39]    Loss 0.555572    Top1 91.171875    Top5 99.648438    
2018-11-01 10:49:11,159 - Test: [   20/   39]    Loss 0.557812    Top1 91.386719    Top5 99.570312    
2018-11-01 10:49:11,258 - Test: [   30/   39]    Loss 0.549352    Top1 91.432292    Top5 99.661458    
2018-11-01 10:49:11,349 - Test: [   40/   39]    Loss 0.545048    Top1 91.460000    Top5 99.650000    
2018-11-01 10:49:11,375 - ==> Top1: 91.460    Top5: 99.650    Loss: 0.545

2018-11-01 10:49:11,376 - Testing sensitivity of module.layer2.2.conv2.weight [10.0% sparsity]
2018-11-01 10:49:11,380 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 10:49:11,381 - --- test ---------------------
2018-11-01 10:49:11,381 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:11,792 - Test: [   10/   39]    Loss 0.552858    Top1 90.820312    Top5 99.492188    
2018-11-01 10:49:11,893 - Test: [   20/   39]    Loss 0.563434    Top1 91.152344    Top5 99.492188    
2018-11-01 10:49:11,993 - Test: [   30/   39]    Loss 0.559423    Top1 91.236979    Top5 99.583333    
2018-11-01 10:49:12,088 - Test: [   40/   39]    Loss 0.562288    Top1 91.230000    Top5 99.600000    
2018-11-01 10:49:12,121 - ==> Top1: 91.230    Top5: 99.600    Loss: 0.562

2018-11-01 10:49:12,121 - Testing sensitivity of module.layer2.2.conv2.weight [15.0% sparsity]
2018-11-01 10:49:12,124 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 10:49:12,125 - --- test ---------------------
2018-11-01 10:49:12,126 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:12,542 - Test: [   10/   39]    Loss 0.554048    Top1 90.976562    Top5 99.492188    
2018-11-01 10:49:12,650 - Test: [   20/   39]    Loss 0.563762    Top1 91.093750    Top5 99.492188    
2018-11-01 10:49:12,755 - Test: [   30/   39]    Loss 0.559722    Top1 91.093750    Top5 99.583333    
2018-11-01 10:49:12,851 - Test: [   40/   39]    Loss 0.562192    Top1 91.120000    Top5 99.600000    
2018-11-01 10:49:12,876 - ==> Top1: 91.120    Top5: 99.600    Loss: 0.562

2018-11-01 10:49:12,877 - Testing sensitivity of module.layer2.2.conv2.weight [20.0% sparsity]
2018-11-01 10:49:12,880 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 10:49:12,881 - --- test ---------------------
2018-11-01 10:49:12,882 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:13,307 - Test: [   10/   39]    Loss 0.551529    Top1 90.976562    Top5 99.531250    
2018-11-01 10:49:13,413 - Test: [   20/   39]    Loss 0.563222    Top1 91.171875    Top5 99.511719    
2018-11-01 10:49:13,517 - Test: [   30/   39]    Loss 0.559662    Top1 91.223958    Top5 99.583333    
2018-11-01 10:49:13,609 - Test: [   40/   39]    Loss 0.562539    Top1 91.190000    Top5 99.600000    
2018-11-01 10:49:13,634 - ==> Top1: 91.190    Top5: 99.600    Loss: 0.563

2018-11-01 10:49:13,635 - Testing sensitivity of module.layer2.2.conv2.weight [25.0% sparsity]
2018-11-01 10:49:13,638 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 10:49:13,639 - --- test ---------------------
2018-11-01 10:49:13,640 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:14,049 - Test: [   10/   39]    Loss 0.565883    Top1 90.742188    Top5 99.531250    
2018-11-01 10:49:14,151 - Test: [   20/   39]    Loss 0.576057    Top1 91.035156    Top5 99.492188    
2018-11-01 10:49:14,250 - Test: [   30/   39]    Loss 0.572176    Top1 91.119792    Top5 99.557292    
2018-11-01 10:49:14,341 - Test: [   40/   39]    Loss 0.570601    Top1 91.090000    Top5 99.550000    
2018-11-01 10:49:14,366 - ==> Top1: 91.090    Top5: 99.550    Loss: 0.571

2018-11-01 10:49:14,367 - Testing sensitivity of module.layer2.2.conv2.weight [30.0% sparsity]
2018-11-01 10:49:14,371 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 10:49:14,372 - --- test ---------------------
2018-11-01 10:49:14,373 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:14,788 - Test: [   10/   39]    Loss 0.576762    Top1 90.664062    Top5 99.492188    
2018-11-01 10:49:14,890 - Test: [   20/   39]    Loss 0.588165    Top1 90.839844    Top5 99.472656    
2018-11-01 10:49:14,989 - Test: [   30/   39]    Loss 0.581918    Top1 90.976562    Top5 99.531250    
2018-11-01 10:49:15,086 - Test: [   40/   39]    Loss 0.582052    Top1 91.040000    Top5 99.530000    
2018-11-01 10:49:15,109 - ==> Top1: 91.040    Top5: 99.530    Loss: 0.582

2018-11-01 10:49:15,110 - Testing sensitivity of module.layer2.2.conv2.weight [35.0% sparsity]
2018-11-01 10:49:15,113 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 10:49:15,114 - --- test ---------------------
2018-11-01 10:49:15,114 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:15,528 - Test: [   10/   39]    Loss 0.573105    Top1 90.820312    Top5 99.531250    
2018-11-01 10:49:15,633 - Test: [   20/   39]    Loss 0.579422    Top1 90.878906    Top5 99.433594    
2018-11-01 10:49:15,737 - Test: [   30/   39]    Loss 0.577987    Top1 90.885417    Top5 99.492188    
2018-11-01 10:49:15,832 - Test: [   40/   39]    Loss 0.576448    Top1 90.870000    Top5 99.500000    
2018-11-01 10:49:15,868 - ==> Top1: 90.870    Top5: 99.500    Loss: 0.576

2018-11-01 10:49:15,869 - Testing sensitivity of module.layer2.2.conv2.weight [40.0% sparsity]
2018-11-01 10:49:15,872 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 10:49:15,873 - --- test ---------------------
2018-11-01 10:49:15,874 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:16,289 - Test: [   10/   39]    Loss 0.578691    Top1 90.664062    Top5 99.492188    
2018-11-01 10:49:16,391 - Test: [   20/   39]    Loss 0.583676    Top1 90.664062    Top5 99.433594    
2018-11-01 10:49:16,490 - Test: [   30/   39]    Loss 0.583551    Top1 90.703125    Top5 99.505208    
2018-11-01 10:49:16,582 - Test: [   40/   39]    Loss 0.580191    Top1 90.760000    Top5 99.510000    
2018-11-01 10:49:16,607 - ==> Top1: 90.760    Top5: 99.510    Loss: 0.580

2018-11-01 10:49:16,608 - Testing sensitivity of module.layer2.2.conv2.weight [45.0% sparsity]
2018-11-01 10:49:16,611 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 10:49:16,612 - --- test ---------------------
2018-11-01 10:49:16,613 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:17,030 - Test: [   10/   39]    Loss 0.600440    Top1 89.960938    Top5 99.453125    
2018-11-01 10:49:17,132 - Test: [   20/   39]    Loss 0.602806    Top1 90.312500    Top5 99.316406    
2018-11-01 10:49:17,232 - Test: [   30/   39]    Loss 0.603695    Top1 90.312500    Top5 99.401042    
2018-11-01 10:49:17,323 - Test: [   40/   39]    Loss 0.597753    Top1 90.480000    Top5 99.440000    
2018-11-01 10:49:17,348 - ==> Top1: 90.480    Top5: 99.440    Loss: 0.598

2018-11-01 10:49:17,348 - Testing sensitivity of module.layer2.2.conv2.weight [50.0% sparsity]
2018-11-01 10:49:17,351 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 10:49:17,353 - --- test ---------------------
2018-11-01 10:49:17,353 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:17,756 - Test: [   10/   39]    Loss 0.652045    Top1 89.414062    Top5 99.296875    
2018-11-01 10:49:17,858 - Test: [   20/   39]    Loss 0.655703    Top1 89.843750    Top5 99.199219    
2018-11-01 10:49:17,957 - Test: [   30/   39]    Loss 0.665471    Top1 89.570312    Top5 99.375000    
2018-11-01 10:49:18,048 - Test: [   40/   39]    Loss 0.655061    Top1 89.660000    Top5 99.410000    
2018-11-01 10:49:18,073 - ==> Top1: 89.660    Top5: 99.410    Loss: 0.655

2018-11-01 10:49:18,074 - Testing sensitivity of module.layer2.2.conv2.weight [55.0% sparsity]
2018-11-01 10:49:18,078 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 10:49:18,078 - --- test ---------------------
2018-11-01 10:49:18,079 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:18,485 - Test: [   10/   39]    Loss 0.667584    Top1 89.335938    Top5 99.296875    
2018-11-01 10:49:18,587 - Test: [   20/   39]    Loss 0.666969    Top1 89.726562    Top5 99.257812    
2018-11-01 10:49:18,686 - Test: [   30/   39]    Loss 0.673831    Top1 89.335938    Top5 99.388021    
2018-11-01 10:49:18,777 - Test: [   40/   39]    Loss 0.657866    Top1 89.450000    Top5 99.420000    
2018-11-01 10:49:18,802 - ==> Top1: 89.450    Top5: 99.420    Loss: 0.658

2018-11-01 10:49:18,803 - Testing sensitivity of module.layer2.2.conv2.weight [60.0% sparsity]
2018-11-01 10:49:18,807 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 10:49:18,808 - --- test ---------------------
2018-11-01 10:49:18,808 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:19,219 - Test: [   10/   39]    Loss 0.698435    Top1 88.750000    Top5 99.257812    
2018-11-01 10:49:19,321 - Test: [   20/   39]    Loss 0.691659    Top1 89.199219    Top5 99.218750    
2018-11-01 10:49:19,421 - Test: [   30/   39]    Loss 0.701699    Top1 88.971354    Top5 99.335938    
2018-11-01 10:49:19,518 - Test: [   40/   39]    Loss 0.691649    Top1 89.170000    Top5 99.370000    
2018-11-01 10:49:19,547 - ==> Top1: 89.170    Top5: 99.370    Loss: 0.692

2018-11-01 10:49:19,547 - Testing sensitivity of module.layer2.2.conv2.weight [65.0% sparsity]
2018-11-01 10:49:19,551 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 10:49:19,552 - --- test ---------------------
2018-11-01 10:49:19,553 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:19,994 - Test: [   10/   39]    Loss 0.687586    Top1 88.632812    Top5 99.257812    
2018-11-01 10:49:20,101 - Test: [   20/   39]    Loss 0.676642    Top1 89.140625    Top5 99.218750    
2018-11-01 10:49:20,206 - Test: [   30/   39]    Loss 0.686860    Top1 89.036458    Top5 99.296875    
2018-11-01 10:49:20,302 - Test: [   40/   39]    Loss 0.683635    Top1 89.260000    Top5 99.340000    
2018-11-01 10:49:20,327 - ==> Top1: 89.260    Top5: 99.340    Loss: 0.684

2018-11-01 10:49:20,328 - Testing sensitivity of module.layer2.2.conv2.weight [70.0% sparsity]
2018-11-01 10:49:20,331 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 10:49:20,332 - --- test ---------------------
2018-11-01 10:49:20,332 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:20,746 - Test: [   10/   39]    Loss 0.782126    Top1 87.500000    Top5 99.179688    
2018-11-01 10:49:20,848 - Test: [   20/   39]    Loss 0.768059    Top1 87.929688    Top5 99.101562    
2018-11-01 10:49:20,947 - Test: [   30/   39]    Loss 0.776968    Top1 87.695312    Top5 99.192708    
2018-11-01 10:49:21,038 - Test: [   40/   39]    Loss 0.761488    Top1 87.810000    Top5 99.210000    
2018-11-01 10:49:21,063 - ==> Top1: 87.810    Top5: 99.210    Loss: 0.761

2018-11-01 10:49:21,065 - Testing sensitivity of module.layer2.2.conv2.weight [75.0% sparsity]
2018-11-01 10:49:21,068 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 10:49:21,070 - --- test ---------------------
2018-11-01 10:49:21,070 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:21,469 - Test: [   10/   39]    Loss 0.813279    Top1 86.835938    Top5 99.296875    
2018-11-01 10:49:21,571 - Test: [   20/   39]    Loss 0.807073    Top1 87.226562    Top5 99.179688    
2018-11-01 10:49:21,670 - Test: [   30/   39]    Loss 0.819537    Top1 86.953125    Top5 99.244792    
2018-11-01 10:49:21,761 - Test: [   40/   39]    Loss 0.810586    Top1 87.080000    Top5 99.260000    
2018-11-01 10:49:21,785 - ==> Top1: 87.080    Top5: 99.260    Loss: 0.811

2018-11-01 10:49:21,786 - Testing sensitivity of module.layer2.2.conv2.weight [80.0% sparsity]
2018-11-01 10:49:21,789 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 10:49:21,790 - --- test ---------------------
2018-11-01 10:49:21,790 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:22,194 - Test: [   10/   39]    Loss 0.957536    Top1 84.101562    Top5 99.062500    
2018-11-01 10:49:22,296 - Test: [   20/   39]    Loss 0.965294    Top1 84.589844    Top5 98.906250    
2018-11-01 10:49:22,395 - Test: [   30/   39]    Loss 0.966605    Top1 84.661458    Top5 99.010417    
2018-11-01 10:49:22,486 - Test: [   40/   39]    Loss 0.959394    Top1 84.730000    Top5 99.000000    
2018-11-01 10:49:22,510 - ==> Top1: 84.730    Top5: 99.000    Loss: 0.959

2018-11-01 10:49:22,511 - Testing sensitivity of module.layer2.2.conv2.weight [85.0% sparsity]
2018-11-01 10:49:22,515 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 10:49:22,516 - --- test ---------------------
2018-11-01 10:49:22,516 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:22,938 - Test: [   10/   39]    Loss 1.050116    Top1 82.890625    Top5 99.062500    
2018-11-01 10:49:23,045 - Test: [   20/   39]    Loss 1.052546    Top1 83.496094    Top5 98.867188    
2018-11-01 10:49:23,150 - Test: [   30/   39]    Loss 1.058761    Top1 83.385417    Top5 98.958333    
2018-11-01 10:49:23,245 - Test: [   40/   39]    Loss 1.051373    Top1 83.500000    Top5 98.930000    
2018-11-01 10:49:23,270 - ==> Top1: 83.500    Top5: 98.930    Loss: 1.051

2018-11-01 10:49:23,270 - Testing sensitivity of module.layer2.2.conv2.weight [90.0% sparsity]
2018-11-01 10:49:23,274 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 10:49:23,275 - --- test ---------------------
2018-11-01 10:49:23,275 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:23,690 - Test: [   10/   39]    Loss 1.196599    Top1 81.523438    Top5 99.062500    
2018-11-01 10:49:23,797 - Test: [   20/   39]    Loss 1.205201    Top1 81.582031    Top5 98.710938    
2018-11-01 10:49:23,902 - Test: [   30/   39]    Loss 1.204470    Top1 81.601562    Top5 98.802083    
2018-11-01 10:49:23,997 - Test: [   40/   39]    Loss 1.213410    Top1 81.520000    Top5 98.810000    
2018-11-01 10:49:24,016 - ==> Top1: 81.520    Top5: 98.810    Loss: 1.213

2018-11-01 10:49:24,039 - Testing sensitivity of module.layer3.0.conv1.weight [0.0% sparsity]
2018-11-01 10:49:24,041 - --- test ---------------------
2018-11-01 10:49:24,041 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:24,437 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:49:24,539 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:49:24,638 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:49:24,730 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:49:24,755 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:49:24,756 - Testing sensitivity of module.layer3.0.conv1.weight [5.0% sparsity]
2018-11-01 10:49:24,758 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 10:49:24,759 - --- test ---------------------
2018-11-01 10:49:24,759 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:25,164 - Test: [   10/   39]    Loss 0.717403    Top1 88.164062    Top5 99.296875    
2018-11-01 10:49:25,266 - Test: [   20/   39]    Loss 0.725431    Top1 88.105469    Top5 99.179688    
2018-11-01 10:49:25,365 - Test: [   30/   39]    Loss 0.697623    Top1 88.359375    Top5 99.244792    
2018-11-01 10:49:25,456 - Test: [   40/   39]    Loss 0.693287    Top1 88.400000    Top5 99.250000    
2018-11-01 10:49:25,482 - ==> Top1: 88.400    Top5: 99.250    Loss: 0.693

2018-11-01 10:49:25,482 - Testing sensitivity of module.layer3.0.conv1.weight [10.0% sparsity]
2018-11-01 10:49:25,485 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 10:49:25,486 - --- test ---------------------
2018-11-01 10:49:25,486 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:25,904 - Test: [   10/   39]    Loss 0.789880    Top1 86.992188    Top5 99.335938    
2018-11-01 10:49:26,007 - Test: [   20/   39]    Loss 0.795758    Top1 87.148438    Top5 99.179688    
2018-11-01 10:49:26,106 - Test: [   30/   39]    Loss 0.768547    Top1 87.096354    Top5 99.270833    
2018-11-01 10:49:26,197 - Test: [   40/   39]    Loss 0.765283    Top1 87.110000    Top5 99.270000    
2018-11-01 10:49:26,222 - ==> Top1: 87.110    Top5: 99.270    Loss: 0.765

2018-11-01 10:49:26,223 - Testing sensitivity of module.layer3.0.conv1.weight [15.0% sparsity]
2018-11-01 10:49:26,226 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 10:49:26,227 - --- test ---------------------
2018-11-01 10:49:26,227 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:26,642 - Test: [   10/   39]    Loss 1.028857    Top1 82.695312    Top5 98.828125    
2018-11-01 10:49:26,745 - Test: [   20/   39]    Loss 1.016467    Top1 83.222656    Top5 98.613281    
2018-11-01 10:49:26,844 - Test: [   30/   39]    Loss 0.995640    Top1 83.268229    Top5 98.567708    
2018-11-01 10:49:26,935 - Test: [   40/   39]    Loss 1.004977    Top1 83.020000    Top5 98.610000    
2018-11-01 10:49:26,960 - ==> Top1: 83.020    Top5: 98.610    Loss: 1.005

2018-11-01 10:49:26,960 - Testing sensitivity of module.layer3.0.conv1.weight [20.0% sparsity]
2018-11-01 10:49:26,964 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 10:49:26,965 - --- test ---------------------
2018-11-01 10:49:26,965 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:27,380 - Test: [   10/   39]    Loss 1.356978    Top1 77.226562    Top5 97.656250    
2018-11-01 10:49:27,484 - Test: [   20/   39]    Loss 1.341944    Top1 77.285156    Top5 97.597656    
2018-11-01 10:49:27,583 - Test: [   30/   39]    Loss 1.314165    Top1 77.539062    Top5 97.552083    
2018-11-01 10:49:27,674 - Test: [   40/   39]    Loss 1.322797    Top1 77.330000    Top5 97.670000    
2018-11-01 10:49:27,697 - ==> Top1: 77.330    Top5: 97.670    Loss: 1.323

2018-11-01 10:49:27,698 - Testing sensitivity of module.layer3.0.conv1.weight [25.0% sparsity]
2018-11-01 10:49:27,702 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 10:49:27,703 - --- test ---------------------
2018-11-01 10:49:27,703 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:28,128 - Test: [   10/   39]    Loss 1.774207    Top1 71.757812    Top5 97.382812    
2018-11-01 10:49:28,231 - Test: [   20/   39]    Loss 1.755896    Top1 71.992188    Top5 97.285156    
2018-11-01 10:49:28,330 - Test: [   30/   39]    Loss 1.739009    Top1 72.174479    Top5 97.330729    
2018-11-01 10:49:28,422 - Test: [   40/   39]    Loss 1.739434    Top1 72.160000    Top5 97.410000    
2018-11-01 10:49:28,447 - ==> Top1: 72.160    Top5: 97.410    Loss: 1.739

2018-11-01 10:49:28,447 - Testing sensitivity of module.layer3.0.conv1.weight [30.0% sparsity]
2018-11-01 10:49:28,451 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 10:49:28,452 - --- test ---------------------
2018-11-01 10:49:28,452 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:28,860 - Test: [   10/   39]    Loss 2.198338    Top1 66.718750    Top5 96.875000    
2018-11-01 10:49:28,962 - Test: [   20/   39]    Loss 2.177939    Top1 66.445312    Top5 96.757812    
2018-11-01 10:49:29,061 - Test: [   30/   39]    Loss 2.155145    Top1 66.119792    Top5 96.888021    
2018-11-01 10:49:29,152 - Test: [   40/   39]    Loss 2.155074    Top1 66.090000    Top5 96.900000    
2018-11-01 10:49:29,177 - ==> Top1: 66.090    Top5: 96.900    Loss: 2.155

2018-11-01 10:49:29,178 - Testing sensitivity of module.layer3.0.conv1.weight [35.0% sparsity]
2018-11-01 10:49:29,182 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 10:49:29,183 - --- test ---------------------
2018-11-01 10:49:29,183 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:29,589 - Test: [   10/   39]    Loss 2.735826    Top1 60.078125    Top5 95.703125    
2018-11-01 10:49:29,691 - Test: [   20/   39]    Loss 2.708296    Top1 60.429687    Top5 95.937500    
2018-11-01 10:49:29,789 - Test: [   30/   39]    Loss 2.701768    Top1 60.130208    Top5 96.080729    
2018-11-01 10:49:29,880 - Test: [   40/   39]    Loss 2.697151    Top1 60.040000    Top5 95.970000    
2018-11-01 10:49:29,906 - ==> Top1: 60.040    Top5: 95.970    Loss: 2.697

2018-11-01 10:49:29,906 - Testing sensitivity of module.layer3.0.conv1.weight [40.0% sparsity]
2018-11-01 10:49:29,910 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 10:49:29,911 - --- test ---------------------
2018-11-01 10:49:29,911 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:30,314 - Test: [   10/   39]    Loss 3.007436    Top1 57.343750    Top5 94.140625    
2018-11-01 10:49:30,416 - Test: [   20/   39]    Loss 2.983703    Top1 58.554688    Top5 94.042969    
2018-11-01 10:49:30,515 - Test: [   30/   39]    Loss 2.979739    Top1 58.111979    Top5 94.283854    
2018-11-01 10:49:30,606 - Test: [   40/   39]    Loss 2.963085    Top1 58.210000    Top5 94.250000    
2018-11-01 10:49:30,631 - ==> Top1: 58.210    Top5: 94.250    Loss: 2.963

2018-11-01 10:49:30,632 - Testing sensitivity of module.layer3.0.conv1.weight [45.0% sparsity]
2018-11-01 10:49:30,636 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 10:49:30,637 - --- test ---------------------
2018-11-01 10:49:30,637 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:31,051 - Test: [   10/   39]    Loss 3.883748    Top1 49.609375    Top5 93.632812    
2018-11-01 10:49:31,154 - Test: [   20/   39]    Loss 3.884255    Top1 50.312500    Top5 93.730469    
2018-11-01 10:49:31,253 - Test: [   30/   39]    Loss 3.864105    Top1 49.687500    Top5 94.010417    
2018-11-01 10:49:31,344 - Test: [   40/   39]    Loss 3.839666    Top1 49.730000    Top5 93.950000    
2018-11-01 10:49:31,360 - ==> Top1: 49.730    Top5: 93.950    Loss: 3.840

2018-11-01 10:49:31,372 - Testing sensitivity of module.layer3.0.conv1.weight [50.0% sparsity]
2018-11-01 10:49:31,376 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 10:49:31,377 - --- test ---------------------
2018-11-01 10:49:31,378 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:31,782 - Test: [   10/   39]    Loss 4.298121    Top1 43.671875    Top5 92.929688    
2018-11-01 10:49:31,884 - Test: [   20/   39]    Loss 4.289835    Top1 44.746094    Top5 92.734375    
2018-11-01 10:49:31,982 - Test: [   30/   39]    Loss 4.272934    Top1 44.388021    Top5 92.864583    
2018-11-01 10:49:32,073 - Test: [   40/   39]    Loss 4.248398    Top1 44.140000    Top5 92.960000    
2018-11-01 10:49:32,098 - ==> Top1: 44.140    Top5: 92.960    Loss: 4.248

2018-11-01 10:49:32,100 - Testing sensitivity of module.layer3.0.conv1.weight [55.0% sparsity]
2018-11-01 10:49:32,103 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 10:49:32,104 - --- test ---------------------
2018-11-01 10:49:32,105 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:32,503 - Test: [   10/   39]    Loss 5.357036    Top1 33.320313    Top5 91.250000    
2018-11-01 10:49:32,605 - Test: [   20/   39]    Loss 5.385003    Top1 33.750000    Top5 90.820312    
2018-11-01 10:49:32,704 - Test: [   30/   39]    Loss 5.342175    Top1 33.789062    Top5 90.846354    
2018-11-01 10:49:32,794 - Test: [   40/   39]    Loss 5.311285    Top1 33.820000    Top5 90.880000    
2018-11-01 10:49:32,829 - ==> Top1: 33.820    Top5: 90.880    Loss: 5.311

2018-11-01 10:49:32,830 - Testing sensitivity of module.layer3.0.conv1.weight [60.0% sparsity]
2018-11-01 10:49:32,832 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 10:49:32,832 - --- test ---------------------
2018-11-01 10:49:32,833 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:33,238 - Test: [   10/   39]    Loss 4.886244    Top1 32.773438    Top5 88.242188    
2018-11-01 10:49:33,340 - Test: [   20/   39]    Loss 4.901619    Top1 32.910156    Top5 87.910156    
2018-11-01 10:49:33,439 - Test: [   30/   39]    Loss 4.870664    Top1 32.838542    Top5 88.111979    
2018-11-01 10:49:33,530 - Test: [   40/   39]    Loss 4.844815    Top1 32.710000    Top5 88.300000    
2018-11-01 10:49:33,554 - ==> Top1: 32.710    Top5: 88.300    Loss: 4.845

2018-11-01 10:49:33,556 - Testing sensitivity of module.layer3.0.conv1.weight [65.0% sparsity]
2018-11-01 10:49:33,559 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 10:49:33,560 - --- test ---------------------
2018-11-01 10:49:33,560 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:33,960 - Test: [   10/   39]    Loss 5.249247    Top1 29.960937    Top5 87.968750    
2018-11-01 10:49:34,062 - Test: [   20/   39]    Loss 5.264399    Top1 29.941406    Top5 87.558594    
2018-11-01 10:49:34,161 - Test: [   30/   39]    Loss 5.219768    Top1 30.000000    Top5 87.591146    
2018-11-01 10:49:34,252 - Test: [   40/   39]    Loss 5.172825    Top1 29.790000    Top5 87.730000    
2018-11-01 10:49:34,278 - ==> Top1: 29.790    Top5: 87.730    Loss: 5.173

2018-11-01 10:49:34,279 - Testing sensitivity of module.layer3.0.conv1.weight [70.0% sparsity]
2018-11-01 10:49:34,283 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 10:49:34,284 - --- test ---------------------
2018-11-01 10:49:34,284 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:34,693 - Test: [   10/   39]    Loss 6.714642    Top1 20.312500    Top5 80.234375    
2018-11-01 10:49:34,795 - Test: [   20/   39]    Loss 6.762224    Top1 20.410156    Top5 79.765625    
2018-11-01 10:49:34,894 - Test: [   30/   39]    Loss 6.754300    Top1 20.182292    Top5 79.622396    
2018-11-01 10:49:34,985 - Test: [   40/   39]    Loss 6.711700    Top1 20.490000    Top5 79.550000    
2018-11-01 10:49:35,011 - ==> Top1: 20.490    Top5: 79.550    Loss: 6.712

2018-11-01 10:49:35,012 - Testing sensitivity of module.layer3.0.conv1.weight [75.0% sparsity]
2018-11-01 10:49:35,014 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 10:49:35,015 - --- test ---------------------
2018-11-01 10:49:35,015 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:35,422 - Test: [   10/   39]    Loss 8.110081    Top1 18.593750    Top5 71.796875    
2018-11-01 10:49:35,524 - Test: [   20/   39]    Loss 8.090984    Top1 18.339844    Top5 71.660156    
2018-11-01 10:49:35,623 - Test: [   30/   39]    Loss 8.102156    Top1 18.098958    Top5 71.927083    
2018-11-01 10:49:35,714 - Test: [   40/   39]    Loss 8.009439    Top1 18.380000    Top5 71.990000    
2018-11-01 10:49:35,740 - ==> Top1: 18.380    Top5: 71.990    Loss: 8.009

2018-11-01 10:49:35,740 - Testing sensitivity of module.layer3.0.conv1.weight [80.0% sparsity]
2018-11-01 10:49:35,744 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 10:49:35,746 - --- test ---------------------
2018-11-01 10:49:35,746 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:36,150 - Test: [   10/   39]    Loss 10.306623    Top1 15.781250    Top5 67.968750    
2018-11-01 10:49:36,252 - Test: [   20/   39]    Loss 10.262776    Top1 15.742188    Top5 68.457031    
2018-11-01 10:49:36,351 - Test: [   30/   39]    Loss 10.266058    Top1 15.494792    Top5 67.968750    
2018-11-01 10:49:36,442 - Test: [   40/   39]    Loss 10.179641    Top1 15.790000    Top5 67.870000    
2018-11-01 10:49:36,467 - ==> Top1: 15.790    Top5: 67.870    Loss: 10.180

2018-11-01 10:49:36,468 - Testing sensitivity of module.layer3.0.conv1.weight [85.0% sparsity]
2018-11-01 10:49:36,470 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 10:49:36,471 - --- test ---------------------
2018-11-01 10:49:36,472 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:36,881 - Test: [   10/   39]    Loss 14.579949    Top1 11.367187    Top5 58.632812    
2018-11-01 10:49:36,984 - Test: [   20/   39]    Loss 14.649286    Top1 10.605469    Top5 58.574219    
2018-11-01 10:49:37,082 - Test: [   30/   39]    Loss 14.674935    Top1 10.351562    Top5 58.528646    
2018-11-01 10:49:37,173 - Test: [   40/   39]    Loss 14.569701    Top1 10.600000    Top5 58.680000    
2018-11-01 10:49:37,200 - ==> Top1: 10.600    Top5: 58.680    Loss: 14.570

2018-11-01 10:49:37,201 - Testing sensitivity of module.layer3.0.conv1.weight [90.0% sparsity]
2018-11-01 10:49:37,204 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 10:49:37,205 - --- test ---------------------
2018-11-01 10:49:37,205 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:37,611 - Test: [   10/   39]    Loss 18.659673    Top1 10.820312    Top5 57.421875    
2018-11-01 10:49:37,713 - Test: [   20/   39]    Loss 18.753666    Top1 10.058594    Top5 57.500000    
2018-11-01 10:49:37,812 - Test: [   30/   39]    Loss 18.799800    Top1 9.804687    Top5 57.083333    
2018-11-01 10:49:37,903 - Test: [   40/   39]    Loss 18.675469    Top1 10.030000    Top5 57.020000    
2018-11-01 10:49:37,932 - ==> Top1: 10.030    Top5: 57.020    Loss: 18.675

2018-11-01 10:49:37,947 - Testing sensitivity of module.layer3.0.conv2.weight [0.0% sparsity]
2018-11-01 10:49:37,951 - --- test ---------------------
2018-11-01 10:49:37,951 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:38,356 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:49:38,459 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:49:38,558 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:49:38,649 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:49:38,675 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:49:38,676 - Testing sensitivity of module.layer3.0.conv2.weight [5.0% sparsity]
2018-11-01 10:49:38,679 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 10:49:38,680 - --- test ---------------------
2018-11-01 10:49:38,680 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:39,089 - Test: [   10/   39]    Loss 0.585166    Top1 90.625000    Top5 99.531250    
2018-11-01 10:49:39,191 - Test: [   20/   39]    Loss 0.591098    Top1 90.820312    Top5 99.492188    
2018-11-01 10:49:39,290 - Test: [   30/   39]    Loss 0.587323    Top1 90.807292    Top5 99.557292    
2018-11-01 10:49:39,382 - Test: [   40/   39]    Loss 0.578441    Top1 90.940000    Top5 99.570000    
2018-11-01 10:49:39,407 - ==> Top1: 90.940    Top5: 99.570    Loss: 0.578

2018-11-01 10:49:39,407 - Testing sensitivity of module.layer3.0.conv2.weight [10.0% sparsity]
2018-11-01 10:49:39,412 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 10:49:39,413 - --- test ---------------------
2018-11-01 10:49:39,413 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:39,821 - Test: [   10/   39]    Loss 0.590779    Top1 90.156250    Top5 99.609375    
2018-11-01 10:49:39,923 - Test: [   20/   39]    Loss 0.602861    Top1 90.390625    Top5 99.550781    
2018-11-01 10:49:40,022 - Test: [   30/   39]    Loss 0.603376    Top1 90.377604    Top5 99.596354    
2018-11-01 10:49:40,114 - Test: [   40/   39]    Loss 0.595590    Top1 90.530000    Top5 99.610000    
2018-11-01 10:49:40,140 - ==> Top1: 90.530    Top5: 99.610    Loss: 0.596

2018-11-01 10:49:40,140 - Testing sensitivity of module.layer3.0.conv2.weight [15.0% sparsity]
2018-11-01 10:49:40,144 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 10:49:40,145 - --- test ---------------------
2018-11-01 10:49:40,146 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:40,554 - Test: [   10/   39]    Loss 0.607732    Top1 89.296875    Top5 99.492188    
2018-11-01 10:49:40,656 - Test: [   20/   39]    Loss 0.622962    Top1 89.550781    Top5 99.492188    
2018-11-01 10:49:40,755 - Test: [   30/   39]    Loss 0.623294    Top1 89.466146    Top5 99.518229    
2018-11-01 10:49:40,846 - Test: [   40/   39]    Loss 0.622287    Top1 89.460000    Top5 99.540000    
2018-11-01 10:49:40,872 - ==> Top1: 89.460    Top5: 99.540    Loss: 0.622

2018-11-01 10:49:40,873 - Testing sensitivity of module.layer3.0.conv2.weight [20.0% sparsity]
2018-11-01 10:49:40,876 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 10:49:40,877 - --- test ---------------------
2018-11-01 10:49:40,877 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:41,293 - Test: [   10/   39]    Loss 0.667108    Top1 87.929688    Top5 99.453125    
2018-11-01 10:49:41,396 - Test: [   20/   39]    Loss 0.662701    Top1 88.281250    Top5 99.375000    
2018-11-01 10:49:41,496 - Test: [   30/   39]    Loss 0.657682    Top1 88.359375    Top5 99.388021    
2018-11-01 10:49:41,587 - Test: [   40/   39]    Loss 0.666507    Top1 88.280000    Top5 99.360000    
2018-11-01 10:49:41,612 - ==> Top1: 88.280    Top5: 99.360    Loss: 0.667

2018-11-01 10:49:41,613 - Testing sensitivity of module.layer3.0.conv2.weight [25.0% sparsity]
2018-11-01 10:49:41,617 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 10:49:41,618 - --- test ---------------------
2018-11-01 10:49:41,618 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:42,030 - Test: [   10/   39]    Loss 0.765093    Top1 86.914062    Top5 99.140625    
2018-11-01 10:49:42,133 - Test: [   20/   39]    Loss 0.756523    Top1 87.148438    Top5 99.121094    
2018-11-01 10:49:42,232 - Test: [   30/   39]    Loss 0.764778    Top1 87.083333    Top5 99.036458    
2018-11-01 10:49:42,324 - Test: [   40/   39]    Loss 0.775019    Top1 87.120000    Top5 99.010000    
2018-11-01 10:49:42,348 - ==> Top1: 87.120    Top5: 99.010    Loss: 0.775

2018-11-01 10:49:42,349 - Testing sensitivity of module.layer3.0.conv2.weight [30.0% sparsity]
2018-11-01 10:49:42,353 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 10:49:42,354 - --- test ---------------------
2018-11-01 10:49:42,354 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:42,772 - Test: [   10/   39]    Loss 0.789888    Top1 85.976562    Top5 98.945312    
2018-11-01 10:49:42,875 - Test: [   20/   39]    Loss 0.787801    Top1 86.191406    Top5 98.906250    
2018-11-01 10:49:42,974 - Test: [   30/   39]    Loss 0.799668    Top1 86.132812    Top5 98.932292    
2018-11-01 10:49:43,066 - Test: [   40/   39]    Loss 0.808229    Top1 86.220000    Top5 98.910000    
2018-11-01 10:49:43,091 - ==> Top1: 86.220    Top5: 98.910    Loss: 0.808

2018-11-01 10:49:43,092 - Testing sensitivity of module.layer3.0.conv2.weight [35.0% sparsity]
2018-11-01 10:49:43,096 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 10:49:43,097 - --- test ---------------------
2018-11-01 10:49:43,097 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:43,505 - Test: [   10/   39]    Loss 1.066234    Top1 80.585938    Top5 98.007812    
2018-11-01 10:49:43,606 - Test: [   20/   39]    Loss 1.075070    Top1 81.074219    Top5 98.164062    
2018-11-01 10:49:43,706 - Test: [   30/   39]    Loss 1.086792    Top1 81.093750    Top5 98.385417    
2018-11-01 10:49:43,797 - Test: [   40/   39]    Loss 1.085282    Top1 81.140000    Top5 98.340000    
2018-11-01 10:49:43,825 - ==> Top1: 81.140    Top5: 98.340    Loss: 1.085

2018-11-01 10:49:43,825 - Testing sensitivity of module.layer3.0.conv2.weight [40.0% sparsity]
2018-11-01 10:49:43,828 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 10:49:43,829 - --- test ---------------------
2018-11-01 10:49:43,830 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:44,236 - Test: [   10/   39]    Loss 1.532493    Top1 73.671875    Top5 97.734375    
2018-11-01 10:49:44,338 - Test: [   20/   39]    Loss 1.531590    Top1 73.906250    Top5 97.636719    
2018-11-01 10:49:44,437 - Test: [   30/   39]    Loss 1.543526    Top1 73.984375    Top5 97.812500    
2018-11-01 10:49:44,529 - Test: [   40/   39]    Loss 1.551531    Top1 73.830000    Top5 97.630000    
2018-11-01 10:49:44,556 - ==> Top1: 73.830    Top5: 97.630    Loss: 1.552

2018-11-01 10:49:44,556 - Testing sensitivity of module.layer3.0.conv2.weight [45.0% sparsity]
2018-11-01 10:49:44,560 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 10:49:44,561 - --- test ---------------------
2018-11-01 10:49:44,561 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:44,977 - Test: [   10/   39]    Loss 1.799002    Top1 69.179688    Top5 96.796875    
2018-11-01 10:49:45,080 - Test: [   20/   39]    Loss 1.817244    Top1 68.925781    Top5 96.367188    
2018-11-01 10:49:45,180 - Test: [   30/   39]    Loss 1.822762    Top1 68.854167    Top5 96.627604    
2018-11-01 10:49:45,271 - Test: [   40/   39]    Loss 1.838676    Top1 68.580000    Top5 96.580000    
2018-11-01 10:49:45,297 - ==> Top1: 68.580    Top5: 96.580    Loss: 1.839

2018-11-01 10:49:45,298 - Testing sensitivity of module.layer3.0.conv2.weight [50.0% sparsity]
2018-11-01 10:49:45,302 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 10:49:45,303 - --- test ---------------------
2018-11-01 10:49:45,304 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:45,724 - Test: [   10/   39]    Loss 2.110419    Top1 67.539062    Top5 94.960938    
2018-11-01 10:49:45,831 - Test: [   20/   39]    Loss 2.134368    Top1 67.285156    Top5 94.335938    
2018-11-01 10:49:45,930 - Test: [   30/   39]    Loss 2.115364    Top1 67.656250    Top5 94.348958    
2018-11-01 10:49:46,021 - Test: [   40/   39]    Loss 2.128492    Top1 67.250000    Top5 94.240000    
2018-11-01 10:49:46,047 - ==> Top1: 67.250    Top5: 94.240    Loss: 2.128

2018-11-01 10:49:46,048 - Testing sensitivity of module.layer3.0.conv2.weight [55.0% sparsity]
2018-11-01 10:49:46,052 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 10:49:46,053 - --- test ---------------------
2018-11-01 10:49:46,053 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:46,457 - Test: [   10/   39]    Loss 2.177522    Top1 65.664062    Top5 95.039062    
2018-11-01 10:49:46,560 - Test: [   20/   39]    Loss 2.155024    Top1 65.917969    Top5 94.726562    
2018-11-01 10:49:46,660 - Test: [   30/   39]    Loss 2.153005    Top1 65.989583    Top5 94.661458    
2018-11-01 10:49:46,752 - Test: [   40/   39]    Loss 2.157219    Top1 65.910000    Top5 94.460000    
2018-11-01 10:49:46,760 - ==> Top1: 65.910    Top5: 94.460    Loss: 2.157

2018-11-01 10:49:46,770 - Testing sensitivity of module.layer3.0.conv2.weight [60.0% sparsity]
2018-11-01 10:49:46,774 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 10:49:46,778 - --- test ---------------------
2018-11-01 10:49:46,779 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:47,194 - Test: [   10/   39]    Loss 2.580851    Top1 62.031250    Top5 91.289062    
2018-11-01 10:49:47,296 - Test: [   20/   39]    Loss 2.560589    Top1 62.148438    Top5 91.230469    
2018-11-01 10:49:47,395 - Test: [   30/   39]    Loss 2.542385    Top1 62.161458    Top5 91.289062    
2018-11-01 10:49:47,487 - Test: [   40/   39]    Loss 2.537098    Top1 61.990000    Top5 91.180000    
2018-11-01 10:49:47,512 - ==> Top1: 61.990    Top5: 91.180    Loss: 2.537

2018-11-01 10:49:47,513 - Testing sensitivity of module.layer3.0.conv2.weight [65.0% sparsity]
2018-11-01 10:49:47,517 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 10:49:47,518 - --- test ---------------------
2018-11-01 10:49:47,518 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:47,927 - Test: [   10/   39]    Loss 3.164720    Top1 57.148438    Top5 82.812500    
2018-11-01 10:49:48,030 - Test: [   20/   39]    Loss 3.166944    Top1 57.343750    Top5 82.421875    
2018-11-01 10:49:48,129 - Test: [   30/   39]    Loss 3.125006    Top1 57.695312    Top5 82.838542    
2018-11-01 10:49:48,221 - Test: [   40/   39]    Loss 3.115672    Top1 57.570000    Top5 82.480000    
2018-11-01 10:49:48,246 - ==> Top1: 57.570    Top5: 82.480    Loss: 3.116

2018-11-01 10:49:48,247 - Testing sensitivity of module.layer3.0.conv2.weight [70.0% sparsity]
2018-11-01 10:49:48,251 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 10:49:48,252 - --- test ---------------------
2018-11-01 10:49:48,252 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:48,652 - Test: [   10/   39]    Loss 3.199066    Top1 52.968750    Top5 77.070312    
2018-11-01 10:49:48,758 - Test: [   20/   39]    Loss 3.210853    Top1 53.710938    Top5 76.992188    
2018-11-01 10:49:48,857 - Test: [   30/   39]    Loss 3.178855    Top1 54.036458    Top5 77.539062    
2018-11-01 10:49:48,948 - Test: [   40/   39]    Loss 3.163204    Top1 53.770000    Top5 77.090000    
2018-11-01 10:49:48,974 - ==> Top1: 53.770    Top5: 77.090    Loss: 3.163

2018-11-01 10:49:48,974 - Testing sensitivity of module.layer3.0.conv2.weight [75.0% sparsity]
2018-11-01 10:49:48,978 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 10:49:48,979 - --- test ---------------------
2018-11-01 10:49:48,979 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:49,387 - Test: [   10/   39]    Loss 3.923713    Top1 45.117188    Top5 76.953125    
2018-11-01 10:49:49,489 - Test: [   20/   39]    Loss 3.902284    Top1 45.605469    Top5 76.992188    
2018-11-01 10:49:49,588 - Test: [   30/   39]    Loss 3.868403    Top1 46.041667    Top5 77.278646    
2018-11-01 10:49:49,680 - Test: [   40/   39]    Loss 3.856530    Top1 46.020000    Top5 76.980000    
2018-11-01 10:49:49,706 - ==> Top1: 46.020    Top5: 76.980    Loss: 3.857

2018-11-01 10:49:49,707 - Testing sensitivity of module.layer3.0.conv2.weight [80.0% sparsity]
2018-11-01 10:49:49,710 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 10:49:49,711 - --- test ---------------------
2018-11-01 10:49:49,712 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:50,124 - Test: [   10/   39]    Loss 2.600518    Top1 41.054688    Top5 79.765625    
2018-11-01 10:49:50,227 - Test: [   20/   39]    Loss 2.555579    Top1 42.636719    Top5 79.375000    
2018-11-01 10:49:50,326 - Test: [   30/   39]    Loss 2.523559    Top1 42.747396    Top5 79.908854    
2018-11-01 10:49:50,417 - Test: [   40/   39]    Loss 2.529647    Top1 42.610000    Top5 79.610000    
2018-11-01 10:49:50,442 - ==> Top1: 42.610    Top5: 79.610    Loss: 2.530

2018-11-01 10:49:50,443 - Testing sensitivity of module.layer3.0.conv2.weight [85.0% sparsity]
2018-11-01 10:49:50,446 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 10:49:50,447 - --- test ---------------------
2018-11-01 10:49:50,448 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:50,869 - Test: [   10/   39]    Loss 2.536207    Top1 35.195312    Top5 76.601562    
2018-11-01 10:49:50,972 - Test: [   20/   39]    Loss 2.514962    Top1 35.566406    Top5 76.523438    
2018-11-01 10:49:51,071 - Test: [   30/   39]    Loss 2.492521    Top1 35.260417    Top5 77.005208    
2018-11-01 10:49:51,164 - Test: [   40/   39]    Loss 2.507489    Top1 35.090000    Top5 76.800000    
2018-11-01 10:49:51,190 - ==> Top1: 35.090    Top5: 76.800    Loss: 2.507

2018-11-01 10:49:51,191 - Testing sensitivity of module.layer3.0.conv2.weight [90.0% sparsity]
2018-11-01 10:49:51,194 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 10:49:51,195 - --- test ---------------------
2018-11-01 10:49:51,196 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:51,620 - Test: [   10/   39]    Loss 3.877337    Top1 22.812500    Top5 76.953125    
2018-11-01 10:49:51,723 - Test: [   20/   39]    Loss 3.870780    Top1 23.222656    Top5 76.816406    
2018-11-01 10:49:51,822 - Test: [   30/   39]    Loss 3.882640    Top1 22.552083    Top5 77.057292    
2018-11-01 10:49:51,914 - Test: [   40/   39]    Loss 3.922844    Top1 22.140000    Top5 76.920000    
2018-11-01 10:49:51,928 - ==> Top1: 22.140    Top5: 76.920    Loss: 3.923

2018-11-01 10:49:51,957 - Testing sensitivity of module.layer3.0.downsample.0.weight [0.0% sparsity]
2018-11-01 10:49:51,960 - --- test ---------------------
2018-11-01 10:49:51,960 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:52,345 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:49:52,447 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:49:52,546 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:49:52,637 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:49:52,662 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:49:52,662 - Testing sensitivity of module.layer3.0.downsample.0.weight [5.0% sparsity]
2018-11-01 10:49:52,666 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 10:49:52,667 - --- test ---------------------
2018-11-01 10:49:52,667 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:53,074 - Test: [   10/   39]    Loss 0.551975    Top1 91.250000    Top5 99.687500    
2018-11-01 10:49:53,178 - Test: [   20/   39]    Loss 0.552888    Top1 91.484375    Top5 99.570312    
2018-11-01 10:49:53,277 - Test: [   30/   39]    Loss 0.546285    Top1 91.523438    Top5 99.661458    
2018-11-01 10:49:53,368 - Test: [   40/   39]    Loss 0.541358    Top1 91.520000    Top5 99.640000    
2018-11-01 10:49:53,394 - ==> Top1: 91.520    Top5: 99.640    Loss: 0.541

2018-11-01 10:49:53,394 - Testing sensitivity of module.layer3.0.downsample.0.weight [10.0% sparsity]
2018-11-01 10:49:53,398 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 10:49:53,399 - --- test ---------------------
2018-11-01 10:49:53,399 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:53,813 - Test: [   10/   39]    Loss 0.559196    Top1 91.328125    Top5 99.687500    
2018-11-01 10:49:53,916 - Test: [   20/   39]    Loss 0.560782    Top1 91.445312    Top5 99.589844    
2018-11-01 10:49:54,015 - Test: [   30/   39]    Loss 0.554029    Top1 91.393229    Top5 99.674479    
2018-11-01 10:49:54,106 - Test: [   40/   39]    Loss 0.548808    Top1 91.400000    Top5 99.650000    
2018-11-01 10:49:54,130 - ==> Top1: 91.400    Top5: 99.650    Loss: 0.549

2018-11-01 10:49:54,131 - Testing sensitivity of module.layer3.0.downsample.0.weight [15.0% sparsity]
2018-11-01 10:49:54,135 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 10:49:54,136 - --- test ---------------------
2018-11-01 10:49:54,137 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:54,544 - Test: [   10/   39]    Loss 0.561902    Top1 91.289062    Top5 99.687500    
2018-11-01 10:49:54,645 - Test: [   20/   39]    Loss 0.562817    Top1 91.308594    Top5 99.589844    
2018-11-01 10:49:54,744 - Test: [   30/   39]    Loss 0.555301    Top1 91.315104    Top5 99.674479    
2018-11-01 10:49:54,835 - Test: [   40/   39]    Loss 0.550084    Top1 91.330000    Top5 99.640000    
2018-11-01 10:49:54,860 - ==> Top1: 91.330    Top5: 99.640    Loss: 0.550

2018-11-01 10:49:54,861 - Testing sensitivity of module.layer3.0.downsample.0.weight [20.0% sparsity]
2018-11-01 10:49:54,865 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 10:49:54,866 - --- test ---------------------
2018-11-01 10:49:54,866 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:55,277 - Test: [   10/   39]    Loss 0.561396    Top1 91.367188    Top5 99.687500    
2018-11-01 10:49:55,379 - Test: [   20/   39]    Loss 0.563440    Top1 91.210938    Top5 99.609375    
2018-11-01 10:49:55,478 - Test: [   30/   39]    Loss 0.555869    Top1 91.197917    Top5 99.687500    
2018-11-01 10:49:55,569 - Test: [   40/   39]    Loss 0.549897    Top1 91.230000    Top5 99.660000    
2018-11-01 10:49:55,570 - ==> Top1: 91.230    Top5: 99.660    Loss: 0.550

2018-11-01 10:49:55,573 - Testing sensitivity of module.layer3.0.downsample.0.weight [25.0% sparsity]
2018-11-01 10:49:55,577 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 10:49:55,578 - --- test ---------------------
2018-11-01 10:49:55,578 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:56,011 - Test: [   10/   39]    Loss 0.571015    Top1 91.328125    Top5 99.648438    
2018-11-01 10:49:56,113 - Test: [   20/   39]    Loss 0.575992    Top1 91.230469    Top5 99.570312    
2018-11-01 10:49:56,212 - Test: [   30/   39]    Loss 0.567432    Top1 91.184896    Top5 99.661458    
2018-11-01 10:49:56,303 - Test: [   40/   39]    Loss 0.561924    Top1 91.240000    Top5 99.630000    
2018-11-01 10:49:56,329 - ==> Top1: 91.240    Top5: 99.630    Loss: 0.562

2018-11-01 10:49:56,331 - Testing sensitivity of module.layer3.0.downsample.0.weight [30.0% sparsity]
2018-11-01 10:49:56,333 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 10:49:56,334 - --- test ---------------------
2018-11-01 10:49:56,334 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:56,755 - Test: [   10/   39]    Loss 0.571929    Top1 91.250000    Top5 99.648438    
2018-11-01 10:49:56,864 - Test: [   20/   39]    Loss 0.578584    Top1 91.210938    Top5 99.550781    
2018-11-01 10:49:56,972 - Test: [   30/   39]    Loss 0.570053    Top1 91.197917    Top5 99.648438    
2018-11-01 10:49:57,069 - Test: [   40/   39]    Loss 0.565607    Top1 91.270000    Top5 99.630000    
2018-11-01 10:49:57,100 - ==> Top1: 91.270    Top5: 99.630    Loss: 0.566

2018-11-01 10:49:57,101 - Testing sensitivity of module.layer3.0.downsample.0.weight [35.0% sparsity]
2018-11-01 10:49:57,105 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 10:49:57,106 - --- test ---------------------
2018-11-01 10:49:57,106 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:57,544 - Test: [   10/   39]    Loss 0.574258    Top1 91.015625    Top5 99.609375    
2018-11-01 10:49:57,646 - Test: [   20/   39]    Loss 0.582852    Top1 91.015625    Top5 99.570312    
2018-11-01 10:49:57,745 - Test: [   30/   39]    Loss 0.572151    Top1 91.093750    Top5 99.635417    
2018-11-01 10:49:57,836 - Test: [   40/   39]    Loss 0.567147    Top1 91.180000    Top5 99.620000    
2018-11-01 10:49:57,860 - ==> Top1: 91.180    Top5: 99.620    Loss: 0.567

2018-11-01 10:49:57,861 - Testing sensitivity of module.layer3.0.downsample.0.weight [40.0% sparsity]
2018-11-01 10:49:57,864 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 10:49:57,865 - --- test ---------------------
2018-11-01 10:49:57,865 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:58,276 - Test: [   10/   39]    Loss 0.569300    Top1 90.976562    Top5 99.609375    
2018-11-01 10:49:58,379 - Test: [   20/   39]    Loss 0.579413    Top1 90.937500    Top5 99.550781    
2018-11-01 10:49:58,478 - Test: [   30/   39]    Loss 0.569158    Top1 91.041667    Top5 99.596354    
2018-11-01 10:49:58,569 - Test: [   40/   39]    Loss 0.562483    Top1 91.100000    Top5 99.590000    
2018-11-01 10:49:58,595 - ==> Top1: 91.100    Top5: 99.590    Loss: 0.562

2018-11-01 10:49:58,595 - Testing sensitivity of module.layer3.0.downsample.0.weight [45.0% sparsity]
2018-11-01 10:49:58,599 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 10:49:58,601 - --- test ---------------------
2018-11-01 10:49:58,601 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:59,009 - Test: [   10/   39]    Loss 0.574499    Top1 90.742188    Top5 99.609375    
2018-11-01 10:49:59,111 - Test: [   20/   39]    Loss 0.587116    Top1 90.742188    Top5 99.589844    
2018-11-01 10:49:59,210 - Test: [   30/   39]    Loss 0.575610    Top1 90.859375    Top5 99.622396    
2018-11-01 10:49:59,301 - Test: [   40/   39]    Loss 0.569912    Top1 90.970000    Top5 99.600000    
2018-11-01 10:49:59,326 - ==> Top1: 90.970    Top5: 99.600    Loss: 0.570

2018-11-01 10:49:59,327 - Testing sensitivity of module.layer3.0.downsample.0.weight [50.0% sparsity]
2018-11-01 10:49:59,330 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 10:49:59,332 - --- test ---------------------
2018-11-01 10:49:59,332 - 10000 samples (256 per mini-batch)
2018-11-01 10:49:59,742 - Test: [   10/   39]    Loss 0.568781    Top1 90.742188    Top5 99.609375    
2018-11-01 10:49:59,848 - Test: [   20/   39]    Loss 0.578331    Top1 90.898438    Top5 99.589844    
2018-11-01 10:49:59,952 - Test: [   30/   39]    Loss 0.569030    Top1 90.911458    Top5 99.622396    
2018-11-01 10:50:00,049 - Test: [   40/   39]    Loss 0.563193    Top1 90.970000    Top5 99.600000    
2018-11-01 10:50:00,075 - ==> Top1: 90.970    Top5: 99.600    Loss: 0.563

2018-11-01 10:50:00,075 - Testing sensitivity of module.layer3.0.downsample.0.weight [55.0% sparsity]
2018-11-01 10:50:00,078 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 10:50:00,079 - --- test ---------------------
2018-11-01 10:50:00,079 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:00,498 - Test: [   10/   39]    Loss 0.573673    Top1 90.742188    Top5 99.531250    
2018-11-01 10:50:00,611 - Test: [   20/   39]    Loss 0.590484    Top1 90.664062    Top5 99.550781    
2018-11-01 10:50:00,716 - Test: [   30/   39]    Loss 0.580799    Top1 90.625000    Top5 99.609375    
2018-11-01 10:50:00,808 - Test: [   40/   39]    Loss 0.577576    Top1 90.710000    Top5 99.600000    
2018-11-01 10:50:00,833 - ==> Top1: 90.710    Top5: 99.600    Loss: 0.578

2018-11-01 10:50:00,834 - Testing sensitivity of module.layer3.0.downsample.0.weight [60.0% sparsity]
2018-11-01 10:50:00,839 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 10:50:00,840 - --- test ---------------------
2018-11-01 10:50:00,840 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:01,258 - Test: [   10/   39]    Loss 0.596866    Top1 90.312500    Top5 99.453125    
2018-11-01 10:50:01,361 - Test: [   20/   39]    Loss 0.600218    Top1 90.507812    Top5 99.511719    
2018-11-01 10:50:01,460 - Test: [   30/   39]    Loss 0.587752    Top1 90.546875    Top5 99.570312    
2018-11-01 10:50:01,552 - Test: [   40/   39]    Loss 0.584111    Top1 90.630000    Top5 99.570000    
2018-11-01 10:50:01,577 - ==> Top1: 90.630    Top5: 99.570    Loss: 0.584

2018-11-01 10:50:01,578 - Testing sensitivity of module.layer3.0.downsample.0.weight [65.0% sparsity]
2018-11-01 10:50:01,582 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 10:50:01,583 - --- test ---------------------
2018-11-01 10:50:01,583 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:01,995 - Test: [   10/   39]    Loss 0.610572    Top1 90.078125    Top5 99.492188    
2018-11-01 10:50:02,097 - Test: [   20/   39]    Loss 0.610321    Top1 90.390625    Top5 99.531250    
2018-11-01 10:50:02,196 - Test: [   30/   39]    Loss 0.594661    Top1 90.481771    Top5 99.583333    
2018-11-01 10:50:02,287 - Test: [   40/   39]    Loss 0.592828    Top1 90.590000    Top5 99.560000    
2018-11-01 10:50:02,312 - ==> Top1: 90.590    Top5: 99.560    Loss: 0.593

2018-11-01 10:50:02,313 - Testing sensitivity of module.layer3.0.downsample.0.weight [70.0% sparsity]
2018-11-01 10:50:02,316 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 10:50:02,317 - --- test ---------------------
2018-11-01 10:50:02,317 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:02,741 - Test: [   10/   39]    Loss 0.621120    Top1 90.273438    Top5 99.531250    
2018-11-01 10:50:02,843 - Test: [   20/   39]    Loss 0.620748    Top1 90.332031    Top5 99.550781    
2018-11-01 10:50:02,942 - Test: [   30/   39]    Loss 0.606172    Top1 90.299479    Top5 99.596354    
2018-11-01 10:50:03,034 - Test: [   40/   39]    Loss 0.605497    Top1 90.380000    Top5 99.550000    
2018-11-01 10:50:03,059 - ==> Top1: 90.380    Top5: 99.550    Loss: 0.605

2018-11-01 10:50:03,060 - Testing sensitivity of module.layer3.0.downsample.0.weight [75.0% sparsity]
2018-11-01 10:50:03,062 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 10:50:03,063 - --- test ---------------------
2018-11-01 10:50:03,063 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:03,469 - Test: [   10/   39]    Loss 0.624350    Top1 89.921875    Top5 99.453125    
2018-11-01 10:50:03,571 - Test: [   20/   39]    Loss 0.622731    Top1 90.214844    Top5 99.492188    
2018-11-01 10:50:03,670 - Test: [   30/   39]    Loss 0.607972    Top1 90.221354    Top5 99.557292    
2018-11-01 10:50:03,762 - Test: [   40/   39]    Loss 0.607684    Top1 90.260000    Top5 99.520000    
2018-11-01 10:50:03,789 - ==> Top1: 90.260    Top5: 99.520    Loss: 0.608

2018-11-01 10:50:03,789 - Testing sensitivity of module.layer3.0.downsample.0.weight [80.0% sparsity]
2018-11-01 10:50:03,794 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 10:50:03,795 - --- test ---------------------
2018-11-01 10:50:03,795 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:04,208 - Test: [   10/   39]    Loss 0.626142    Top1 89.687500    Top5 99.492188    
2018-11-01 10:50:04,310 - Test: [   20/   39]    Loss 0.625919    Top1 90.000000    Top5 99.511719    
2018-11-01 10:50:04,409 - Test: [   30/   39]    Loss 0.611857    Top1 90.013021    Top5 99.570312    
2018-11-01 10:50:04,500 - Test: [   40/   39]    Loss 0.609973    Top1 90.070000    Top5 99.530000    
2018-11-01 10:50:04,540 - ==> Top1: 90.070    Top5: 99.530    Loss: 0.610

2018-11-01 10:50:04,540 - Testing sensitivity of module.layer3.0.downsample.0.weight [85.0% sparsity]
2018-11-01 10:50:04,543 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 10:50:04,543 - --- test ---------------------
2018-11-01 10:50:04,544 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:04,964 - Test: [   10/   39]    Loss 0.629374    Top1 90.078125    Top5 99.531250    
2018-11-01 10:50:05,066 - Test: [   20/   39]    Loss 0.632015    Top1 90.175781    Top5 99.589844    
2018-11-01 10:50:05,165 - Test: [   30/   39]    Loss 0.617056    Top1 90.208333    Top5 99.635417    
2018-11-01 10:50:05,256 - Test: [   40/   39]    Loss 0.613613    Top1 90.260000    Top5 99.580000    
2018-11-01 10:50:05,281 - ==> Top1: 90.260    Top5: 99.580    Loss: 0.614

2018-11-01 10:50:05,282 - Testing sensitivity of module.layer3.0.downsample.0.weight [90.0% sparsity]
2018-11-01 10:50:05,286 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 10:50:05,287 - --- test ---------------------
2018-11-01 10:50:05,287 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:05,699 - Test: [   10/   39]    Loss 0.647628    Top1 90.000000    Top5 99.531250    
2018-11-01 10:50:05,801 - Test: [   20/   39]    Loss 0.654070    Top1 89.824219    Top5 99.550781    
2018-11-01 10:50:05,900 - Test: [   30/   39]    Loss 0.634925    Top1 89.908854    Top5 99.609375    
2018-11-01 10:50:05,991 - Test: [   40/   39]    Loss 0.635164    Top1 89.890000    Top5 99.530000    
2018-11-01 10:50:06,017 - ==> Top1: 89.890    Top5: 99.530    Loss: 0.635

2018-11-01 10:50:06,032 - Testing sensitivity of module.layer3.1.conv1.weight [0.0% sparsity]
2018-11-01 10:50:06,036 - --- test ---------------------
2018-11-01 10:50:06,036 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:06,414 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:50:06,516 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:50:06,615 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:50:06,706 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:50:06,732 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:50:06,733 - Testing sensitivity of module.layer3.1.conv1.weight [5.0% sparsity]
2018-11-01 10:50:06,735 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 10:50:06,736 - --- test ---------------------
2018-11-01 10:50:06,736 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:07,147 - Test: [   10/   39]    Loss 1.211170    Top1 71.328125    Top5 97.539062    
2018-11-01 10:50:07,249 - Test: [   20/   39]    Loss 1.216702    Top1 71.347656    Top5 97.539062    
2018-11-01 10:50:07,348 - Test: [   30/   39]    Loss 1.237343    Top1 70.481771    Top5 97.591146    
2018-11-01 10:50:07,439 - Test: [   40/   39]    Loss 1.228197    Top1 70.560000    Top5 97.700000    
2018-11-01 10:50:07,465 - ==> Top1: 70.560    Top5: 97.700    Loss: 1.228

2018-11-01 10:50:07,465 - Testing sensitivity of module.layer3.1.conv1.weight [10.0% sparsity]
2018-11-01 10:50:07,469 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 10:50:07,470 - --- test ---------------------
2018-11-01 10:50:07,470 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:07,881 - Test: [   10/   39]    Loss 1.035351    Top1 65.429688    Top5 97.460938    
2018-11-01 10:50:07,984 - Test: [   20/   39]    Loss 1.035084    Top1 65.019531    Top5 97.343750    
2018-11-01 10:50:08,083 - Test: [   30/   39]    Loss 1.058320    Top1 64.270833    Top5 97.265625    
2018-11-01 10:50:08,174 - Test: [   40/   39]    Loss 1.051145    Top1 64.300000    Top5 97.250000    
2018-11-01 10:50:08,199 - ==> Top1: 64.300    Top5: 97.250    Loss: 1.051

2018-11-01 10:50:08,199 - Testing sensitivity of module.layer3.1.conv1.weight [15.0% sparsity]
2018-11-01 10:50:08,203 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 10:50:08,204 - --- test ---------------------
2018-11-01 10:50:08,204 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:08,614 - Test: [   10/   39]    Loss 1.832829    Top1 39.335937    Top5 87.304688    
2018-11-01 10:50:08,716 - Test: [   20/   39]    Loss 1.812720    Top1 40.039062    Top5 87.832031    
2018-11-01 10:50:08,815 - Test: [   30/   39]    Loss 1.833983    Top1 39.427083    Top5 87.356771    
2018-11-01 10:50:08,906 - Test: [   40/   39]    Loss 1.835869    Top1 39.240000    Top5 87.360000    
2018-11-01 10:50:08,932 - ==> Top1: 39.240    Top5: 87.360    Loss: 1.836

2018-11-01 10:50:08,932 - Testing sensitivity of module.layer3.1.conv1.weight [20.0% sparsity]
2018-11-01 10:50:08,936 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 10:50:08,936 - --- test ---------------------
2018-11-01 10:50:08,937 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:09,344 - Test: [   10/   39]    Loss 1.915931    Top1 39.453125    Top5 85.234375    
2018-11-01 10:50:09,447 - Test: [   20/   39]    Loss 1.887404    Top1 40.097656    Top5 86.132812    
2018-11-01 10:50:09,546 - Test: [   30/   39]    Loss 1.907417    Top1 39.440104    Top5 85.846354    
2018-11-01 10:50:09,637 - Test: [   40/   39]    Loss 1.908529    Top1 39.260000    Top5 85.920000    
2018-11-01 10:50:09,662 - ==> Top1: 39.260    Top5: 85.920    Loss: 1.909

2018-11-01 10:50:09,663 - Testing sensitivity of module.layer3.1.conv1.weight [25.0% sparsity]
2018-11-01 10:50:09,667 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 10:50:09,668 - --- test ---------------------
2018-11-01 10:50:09,668 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:10,086 - Test: [   10/   39]    Loss 2.476662    Top1 26.093750    Top5 79.531250    
2018-11-01 10:50:10,187 - Test: [   20/   39]    Loss 2.436933    Top1 26.875000    Top5 80.859375    
2018-11-01 10:50:10,287 - Test: [   30/   39]    Loss 2.443194    Top1 26.406250    Top5 81.236979    
2018-11-01 10:50:10,378 - Test: [   40/   39]    Loss 2.456489    Top1 26.180000    Top5 80.640000    
2018-11-01 10:50:10,402 - ==> Top1: 26.180    Top5: 80.640    Loss: 2.456

2018-11-01 10:50:10,403 - Testing sensitivity of module.layer3.1.conv1.weight [30.0% sparsity]
2018-11-01 10:50:10,406 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 10:50:10,407 - --- test ---------------------
2018-11-01 10:50:10,407 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:10,822 - Test: [   10/   39]    Loss 2.363049    Top1 25.351563    Top5 75.820312    
2018-11-01 10:50:10,923 - Test: [   20/   39]    Loss 2.330763    Top1 25.507813    Top5 76.816406    
2018-11-01 10:50:11,022 - Test: [   30/   39]    Loss 2.335383    Top1 24.986979    Top5 77.122396    
2018-11-01 10:50:11,113 - Test: [   40/   39]    Loss 2.348691    Top1 24.780000    Top5 76.360000    
2018-11-01 10:50:11,138 - ==> Top1: 24.780    Top5: 76.360    Loss: 2.349

2018-11-01 10:50:11,139 - Testing sensitivity of module.layer3.1.conv1.weight [35.0% sparsity]
2018-11-01 10:50:11,143 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 10:50:11,144 - --- test ---------------------
2018-11-01 10:50:11,145 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:11,553 - Test: [   10/   39]    Loss 2.342821    Top1 23.750000    Top5 73.476562    
2018-11-01 10:50:11,655 - Test: [   20/   39]    Loss 2.316577    Top1 24.121094    Top5 74.375000    
2018-11-01 10:50:11,754 - Test: [   30/   39]    Loss 2.315118    Top1 23.854167    Top5 74.739583    
2018-11-01 10:50:11,844 - Test: [   40/   39]    Loss 2.327175    Top1 23.900000    Top5 74.190000    
2018-11-01 10:50:11,870 - ==> Top1: 23.900    Top5: 74.190    Loss: 2.327

2018-11-01 10:50:11,871 - Testing sensitivity of module.layer3.1.conv1.weight [40.0% sparsity]
2018-11-01 10:50:11,873 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 10:50:11,874 - --- test ---------------------
2018-11-01 10:50:11,874 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:12,292 - Test: [   10/   39]    Loss 2.389274    Top1 22.929687    Top5 74.687500    
2018-11-01 10:50:12,394 - Test: [   20/   39]    Loss 2.366767    Top1 23.222656    Top5 75.410156    
2018-11-01 10:50:12,493 - Test: [   30/   39]    Loss 2.366701    Top1 23.020833    Top5 75.598958    
2018-11-01 10:50:12,584 - Test: [   40/   39]    Loss 2.379920    Top1 22.890000    Top5 75.090000    
2018-11-01 10:50:12,610 - ==> Top1: 22.890    Top5: 75.090    Loss: 2.380

2018-11-01 10:50:12,611 - Testing sensitivity of module.layer3.1.conv1.weight [45.0% sparsity]
2018-11-01 10:50:12,613 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 10:50:12,614 - --- test ---------------------
2018-11-01 10:50:12,614 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:13,027 - Test: [   10/   39]    Loss 2.443137    Top1 22.578125    Top5 71.289062    
2018-11-01 10:50:13,128 - Test: [   20/   39]    Loss 2.416771    Top1 22.792969    Top5 72.441406    
2018-11-01 10:50:13,227 - Test: [   30/   39]    Loss 2.416013    Top1 22.682292    Top5 72.773438    
2018-11-01 10:50:13,318 - Test: [   40/   39]    Loss 2.427379    Top1 22.520000    Top5 72.340000    
2018-11-01 10:50:13,343 - ==> Top1: 22.520    Top5: 72.340    Loss: 2.427

2018-11-01 10:50:13,344 - Testing sensitivity of module.layer3.1.conv1.weight [50.0% sparsity]
2018-11-01 10:50:13,347 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 10:50:13,347 - --- test ---------------------
2018-11-01 10:50:13,348 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:13,756 - Test: [   10/   39]    Loss 2.574129    Top1 21.015625    Top5 68.359375    
2018-11-01 10:50:13,861 - Test: [   20/   39]    Loss 2.549578    Top1 21.269531    Top5 69.375000    
2018-11-01 10:50:13,960 - Test: [   30/   39]    Loss 2.547965    Top1 21.145833    Top5 69.661458    
2018-11-01 10:50:14,051 - Test: [   40/   39]    Loss 2.558958    Top1 20.990000    Top5 69.240000    
2018-11-01 10:50:14,076 - ==> Top1: 20.990    Top5: 69.240    Loss: 2.559

2018-11-01 10:50:14,076 - Testing sensitivity of module.layer3.1.conv1.weight [55.0% sparsity]
2018-11-01 10:50:14,080 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 10:50:14,081 - --- test ---------------------
2018-11-01 10:50:14,081 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:14,495 - Test: [   10/   39]    Loss 2.673382    Top1 19.218750    Top5 63.945312    
2018-11-01 10:50:14,597 - Test: [   20/   39]    Loss 2.649225    Top1 19.335938    Top5 65.234375    
2018-11-01 10:50:14,696 - Test: [   30/   39]    Loss 2.646670    Top1 19.270833    Top5 65.442708    
2018-11-01 10:50:14,787 - Test: [   40/   39]    Loss 2.656681    Top1 19.090000    Top5 65.130000    
2018-11-01 10:50:14,822 - ==> Top1: 19.090    Top5: 65.130    Loss: 2.657

2018-11-01 10:50:14,822 - Testing sensitivity of module.layer3.1.conv1.weight [60.0% sparsity]
2018-11-01 10:50:14,826 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 10:50:14,827 - --- test ---------------------
2018-11-01 10:50:14,827 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:15,233 - Test: [   10/   39]    Loss 2.676428    Top1 19.218750    Top5 64.296875    
2018-11-01 10:50:15,334 - Test: [   20/   39]    Loss 2.660686    Top1 19.453125    Top5 64.472656    
2018-11-01 10:50:15,433 - Test: [   30/   39]    Loss 2.660316    Top1 19.518229    Top5 64.544271    
2018-11-01 10:50:15,524 - Test: [   40/   39]    Loss 2.664286    Top1 19.390000    Top5 64.530000    
2018-11-01 10:50:15,549 - ==> Top1: 19.390    Top5: 64.530    Loss: 2.664

2018-11-01 10:50:15,549 - Testing sensitivity of module.layer3.1.conv1.weight [65.0% sparsity]
2018-11-01 10:50:15,553 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 10:50:15,554 - --- test ---------------------
2018-11-01 10:50:15,554 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:15,972 - Test: [   10/   39]    Loss 2.699785    Top1 18.906250    Top5 64.296875    
2018-11-01 10:50:16,073 - Test: [   20/   39]    Loss 2.682506    Top1 19.218750    Top5 64.550781    
2018-11-01 10:50:16,172 - Test: [   30/   39]    Loss 2.682599    Top1 19.257813    Top5 64.440104    
2018-11-01 10:50:16,263 - Test: [   40/   39]    Loss 2.688220    Top1 19.100000    Top5 64.360000    
2018-11-01 10:50:16,288 - ==> Top1: 19.100    Top5: 64.360    Loss: 2.688

2018-11-01 10:50:16,289 - Testing sensitivity of module.layer3.1.conv1.weight [70.0% sparsity]
2018-11-01 10:50:16,293 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 10:50:16,295 - --- test ---------------------
2018-11-01 10:50:16,295 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:16,709 - Test: [   10/   39]    Loss 2.554751    Top1 20.585937    Top5 68.632812    
2018-11-01 10:50:16,811 - Test: [   20/   39]    Loss 2.547362    Top1 21.191406    Top5 68.203125    
2018-11-01 10:50:16,910 - Test: [   30/   39]    Loss 2.550414    Top1 21.093750    Top5 67.890625    
2018-11-01 10:50:17,001 - Test: [   40/   39]    Loss 2.555164    Top1 21.070000    Top5 67.660000    
2018-11-01 10:50:17,026 - ==> Top1: 21.070    Top5: 67.660    Loss: 2.555

2018-11-01 10:50:17,027 - Testing sensitivity of module.layer3.1.conv1.weight [75.0% sparsity]
2018-11-01 10:50:17,030 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 10:50:17,031 - --- test ---------------------
2018-11-01 10:50:17,031 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:17,441 - Test: [   10/   39]    Loss 2.721637    Top1 21.171875    Top5 63.320312    
2018-11-01 10:50:17,542 - Test: [   20/   39]    Loss 2.700855    Top1 21.582031    Top5 63.652344    
2018-11-01 10:50:17,641 - Test: [   30/   39]    Loss 2.692867    Top1 21.458333    Top5 63.945312    
2018-11-01 10:50:17,732 - Test: [   40/   39]    Loss 2.701735    Top1 21.430000    Top5 63.750000    
2018-11-01 10:50:17,774 - ==> Top1: 21.430    Top5: 63.750    Loss: 2.702

2018-11-01 10:50:17,775 - Testing sensitivity of module.layer3.1.conv1.weight [80.0% sparsity]
2018-11-01 10:50:17,778 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 10:50:17,779 - --- test ---------------------
2018-11-01 10:50:17,779 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:18,186 - Test: [   10/   39]    Loss 2.809519    Top1 20.039063    Top5 60.000000    
2018-11-01 10:50:18,288 - Test: [   20/   39]    Loss 2.783350    Top1 20.039063    Top5 60.410156    
2018-11-01 10:50:18,386 - Test: [   30/   39]    Loss 2.776830    Top1 19.440104    Top5 60.716146    
2018-11-01 10:50:18,477 - Test: [   40/   39]    Loss 2.787779    Top1 19.180000    Top5 60.440000    
2018-11-01 10:50:18,502 - ==> Top1: 19.180    Top5: 60.440    Loss: 2.788

2018-11-01 10:50:18,503 - Testing sensitivity of module.layer3.1.conv1.weight [85.0% sparsity]
2018-11-01 10:50:18,507 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 10:50:18,508 - --- test ---------------------
2018-11-01 10:50:18,509 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:18,917 - Test: [   10/   39]    Loss 2.810695    Top1 20.820313    Top5 60.585938    
2018-11-01 10:50:19,019 - Test: [   20/   39]    Loss 2.785273    Top1 20.878906    Top5 60.937500    
2018-11-01 10:50:19,118 - Test: [   30/   39]    Loss 2.777406    Top1 20.351562    Top5 61.328125    
2018-11-01 10:50:19,209 - Test: [   40/   39]    Loss 2.788535    Top1 20.190000    Top5 61.020000    
2018-11-01 10:50:19,233 - ==> Top1: 20.190    Top5: 61.020    Loss: 2.789

2018-11-01 10:50:19,234 - Testing sensitivity of module.layer3.1.conv1.weight [90.0% sparsity]
2018-11-01 10:50:19,237 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 10:50:19,238 - --- test ---------------------
2018-11-01 10:50:19,238 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:19,653 - Test: [   10/   39]    Loss 2.869325    Top1 13.750000    Top5 63.164062    
2018-11-01 10:50:19,756 - Test: [   20/   39]    Loss 2.838667    Top1 13.769531    Top5 63.964844    
2018-11-01 10:50:19,855 - Test: [   30/   39]    Loss 2.827094    Top1 13.463542    Top5 64.622396    
2018-11-01 10:50:19,945 - Test: [   40/   39]    Loss 2.844186    Top1 13.300000    Top5 64.160000    
2018-11-01 10:50:19,971 - ==> Top1: 13.300    Top5: 64.160    Loss: 2.844

2018-11-01 10:50:19,986 - Testing sensitivity of module.layer3.1.conv2.weight [0.0% sparsity]
2018-11-01 10:50:19,990 - --- test ---------------------
2018-11-01 10:50:19,991 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:20,375 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:50:20,476 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:50:20,575 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:50:20,666 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:50:20,691 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:50:20,692 - Testing sensitivity of module.layer3.1.conv2.weight [5.0% sparsity]
2018-11-01 10:50:20,696 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 10:50:20,697 - --- test ---------------------
2018-11-01 10:50:20,697 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:21,105 - Test: [   10/   39]    Loss 0.582990    Top1 90.742188    Top5 99.570312    
2018-11-01 10:50:21,208 - Test: [   20/   39]    Loss 0.580950    Top1 91.113281    Top5 99.472656    
2018-11-01 10:50:21,307 - Test: [   30/   39]    Loss 0.573389    Top1 90.976562    Top5 99.557292    
2018-11-01 10:50:21,398 - Test: [   40/   39]    Loss 0.568493    Top1 90.990000    Top5 99.540000    
2018-11-01 10:50:21,423 - ==> Top1: 90.990    Top5: 99.540    Loss: 0.568

2018-11-01 10:50:21,423 - Testing sensitivity of module.layer3.1.conv2.weight [10.0% sparsity]
2018-11-01 10:50:21,427 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 10:50:21,428 - --- test ---------------------
2018-11-01 10:50:21,429 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:21,840 - Test: [   10/   39]    Loss 0.728663    Top1 89.179688    Top5 99.414062    
2018-11-01 10:50:21,943 - Test: [   20/   39]    Loss 0.730438    Top1 89.882812    Top5 99.218750    
2018-11-01 10:50:22,042 - Test: [   30/   39]    Loss 0.720693    Top1 89.700521    Top5 99.270833    
2018-11-01 10:50:22,133 - Test: [   40/   39]    Loss 0.712325    Top1 89.880000    Top5 99.250000    
2018-11-01 10:50:22,158 - ==> Top1: 89.880    Top5: 99.250    Loss: 0.712

2018-11-01 10:50:22,159 - Testing sensitivity of module.layer3.1.conv2.weight [15.0% sparsity]
2018-11-01 10:50:22,163 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 10:50:22,164 - --- test ---------------------
2018-11-01 10:50:22,165 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:22,588 - Test: [   10/   39]    Loss 0.758950    Top1 89.062500    Top5 99.335938    
2018-11-01 10:50:22,691 - Test: [   20/   39]    Loss 0.756604    Top1 89.667969    Top5 99.062500    
2018-11-01 10:50:22,789 - Test: [   30/   39]    Loss 0.750049    Top1 89.388021    Top5 99.153646    
2018-11-01 10:50:22,881 - Test: [   40/   39]    Loss 0.735485    Top1 89.540000    Top5 99.190000    
2018-11-01 10:50:22,905 - ==> Top1: 89.540    Top5: 99.190    Loss: 0.735

2018-11-01 10:50:22,906 - Testing sensitivity of module.layer3.1.conv2.weight [20.0% sparsity]
2018-11-01 10:50:22,909 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 10:50:22,910 - --- test ---------------------
2018-11-01 10:50:22,911 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:23,316 - Test: [   10/   39]    Loss 0.797038    Top1 89.218750    Top5 99.179688    
2018-11-01 10:50:23,418 - Test: [   20/   39]    Loss 0.796737    Top1 89.609375    Top5 99.082031    
2018-11-01 10:50:23,517 - Test: [   30/   39]    Loss 0.793192    Top1 89.335938    Top5 99.179688    
2018-11-01 10:50:23,609 - Test: [   40/   39]    Loss 0.772930    Top1 89.510000    Top5 99.230000    
2018-11-01 10:50:23,633 - ==> Top1: 89.510    Top5: 99.230    Loss: 0.773

2018-11-01 10:50:23,634 - Testing sensitivity of module.layer3.1.conv2.weight [25.0% sparsity]
2018-11-01 10:50:23,638 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 10:50:23,638 - --- test ---------------------
2018-11-01 10:50:23,639 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:24,047 - Test: [   10/   39]    Loss 0.949691    Top1 87.148438    Top5 99.257812    
2018-11-01 10:50:24,149 - Test: [   20/   39]    Loss 0.949268    Top1 87.558594    Top5 99.121094    
2018-11-01 10:50:24,248 - Test: [   30/   39]    Loss 0.944463    Top1 87.395833    Top5 99.205729    
2018-11-01 10:50:24,339 - Test: [   40/   39]    Loss 0.907793    Top1 87.460000    Top5 99.240000    
2018-11-01 10:50:24,365 - ==> Top1: 87.460    Top5: 99.240    Loss: 0.908

2018-11-01 10:50:24,365 - Testing sensitivity of module.layer3.1.conv2.weight [30.0% sparsity]
2018-11-01 10:50:24,369 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 10:50:24,370 - --- test ---------------------
2018-11-01 10:50:24,370 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:24,786 - Test: [   10/   39]    Loss 1.034575    Top1 86.132812    Top5 99.218750    
2018-11-01 10:50:24,888 - Test: [   20/   39]    Loss 1.039186    Top1 86.562500    Top5 98.964844    
2018-11-01 10:50:24,987 - Test: [   30/   39]    Loss 1.043141    Top1 86.289062    Top5 99.049479    
2018-11-01 10:50:25,079 - Test: [   40/   39]    Loss 0.997139    Top1 86.500000    Top5 99.070000    
2018-11-01 10:50:25,103 - ==> Top1: 86.500    Top5: 99.070    Loss: 0.997

2018-11-01 10:50:25,104 - Testing sensitivity of module.layer3.1.conv2.weight [35.0% sparsity]
2018-11-01 10:50:25,107 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 10:50:25,109 - --- test ---------------------
2018-11-01 10:50:25,109 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:25,522 - Test: [   10/   39]    Loss 1.092171    Top1 84.648438    Top5 98.671875    
2018-11-01 10:50:25,623 - Test: [   20/   39]    Loss 1.083686    Top1 85.273438    Top5 98.574219    
2018-11-01 10:50:25,723 - Test: [   30/   39]    Loss 1.086575    Top1 85.104167    Top5 98.632812    
2018-11-01 10:50:25,814 - Test: [   40/   39]    Loss 1.041582    Top1 85.310000    Top5 98.690000    
2018-11-01 10:50:25,838 - ==> Top1: 85.310    Top5: 98.690    Loss: 1.042

2018-11-01 10:50:25,839 - Testing sensitivity of module.layer3.1.conv2.weight [40.0% sparsity]
2018-11-01 10:50:25,842 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 10:50:25,843 - --- test ---------------------
2018-11-01 10:50:25,843 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:26,254 - Test: [   10/   39]    Loss 1.080067    Top1 84.296875    Top5 98.359375    
2018-11-01 10:50:26,356 - Test: [   20/   39]    Loss 1.079897    Top1 84.570312    Top5 98.281250    
2018-11-01 10:50:26,455 - Test: [   30/   39]    Loss 1.095630    Top1 84.466146    Top5 98.346354    
2018-11-01 10:50:26,547 - Test: [   40/   39]    Loss 1.039581    Top1 84.720000    Top5 98.420000    
2018-11-01 10:50:26,572 - ==> Top1: 84.720    Top5: 98.420    Loss: 1.040

2018-11-01 10:50:26,573 - Testing sensitivity of module.layer3.1.conv2.weight [45.0% sparsity]
2018-11-01 10:50:26,576 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 10:50:26,576 - --- test ---------------------
2018-11-01 10:50:26,577 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:27,000 - Test: [   10/   39]    Loss 1.692220    Top1 77.851562    Top5 97.187500    
2018-11-01 10:50:27,105 - Test: [   20/   39]    Loss 1.707772    Top1 77.968750    Top5 97.128906    
2018-11-01 10:50:27,204 - Test: [   30/   39]    Loss 1.744939    Top1 77.721354    Top5 97.109375    
2018-11-01 10:50:27,295 - Test: [   40/   39]    Loss 1.692255    Top1 77.930000    Top5 97.180000    
2018-11-01 10:50:27,320 - ==> Top1: 77.930    Top5: 97.180    Loss: 1.692

2018-11-01 10:50:27,322 - Testing sensitivity of module.layer3.1.conv2.weight [50.0% sparsity]
2018-11-01 10:50:27,326 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 10:50:27,327 - --- test ---------------------
2018-11-01 10:50:27,327 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:27,740 - Test: [   10/   39]    Loss 1.954253    Top1 73.632812    Top5 97.187500    
2018-11-01 10:50:27,843 - Test: [   20/   39]    Loss 1.988766    Top1 74.121094    Top5 96.992188    
2018-11-01 10:50:27,942 - Test: [   30/   39]    Loss 2.022441    Top1 74.192708    Top5 96.966146    
2018-11-01 10:50:28,033 - Test: [   40/   39]    Loss 1.965406    Top1 74.470000    Top5 97.010000    
2018-11-01 10:50:28,058 - ==> Top1: 74.470    Top5: 97.010    Loss: 1.965

2018-11-01 10:50:28,059 - Testing sensitivity of module.layer3.1.conv2.weight [55.0% sparsity]
2018-11-01 10:50:28,063 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 10:50:28,064 - --- test ---------------------
2018-11-01 10:50:28,064 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:28,479 - Test: [   10/   39]    Loss 1.858781    Top1 74.062500    Top5 97.304688    
2018-11-01 10:50:28,581 - Test: [   20/   39]    Loss 1.894024    Top1 74.570312    Top5 96.992188    
2018-11-01 10:50:28,680 - Test: [   30/   39]    Loss 1.921311    Top1 74.388021    Top5 96.979167    
2018-11-01 10:50:28,772 - Test: [   40/   39]    Loss 1.872690    Top1 74.630000    Top5 97.030000    
2018-11-01 10:50:28,798 - ==> Top1: 74.630    Top5: 97.030    Loss: 1.873

2018-11-01 10:50:28,798 - Testing sensitivity of module.layer3.1.conv2.weight [60.0% sparsity]
2018-11-01 10:50:28,802 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 10:50:28,804 - --- test ---------------------
2018-11-01 10:50:28,804 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:29,223 - Test: [   10/   39]    Loss 2.511686    Top1 69.062500    Top5 97.539062    
2018-11-01 10:50:29,325 - Test: [   20/   39]    Loss 2.531343    Top1 69.394531    Top5 97.109375    
2018-11-01 10:50:29,424 - Test: [   30/   39]    Loss 2.546232    Top1 69.335938    Top5 97.278646    
2018-11-01 10:50:29,515 - Test: [   40/   39]    Loss 2.492456    Top1 69.640000    Top5 97.270000    
2018-11-01 10:50:29,541 - ==> Top1: 69.640    Top5: 97.270    Loss: 2.492

2018-11-01 10:50:29,542 - Testing sensitivity of module.layer3.1.conv2.weight [65.0% sparsity]
2018-11-01 10:50:29,545 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 10:50:29,546 - --- test ---------------------
2018-11-01 10:50:29,546 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:29,969 - Test: [   10/   39]    Loss 2.280894    Top1 71.835938    Top5 97.734375    
2018-11-01 10:50:30,071 - Test: [   20/   39]    Loss 2.303930    Top1 71.992188    Top5 97.421875    
2018-11-01 10:50:30,170 - Test: [   30/   39]    Loss 2.326440    Top1 71.848958    Top5 97.617188    
2018-11-01 10:50:30,261 - Test: [   40/   39]    Loss 2.294502    Top1 72.240000    Top5 97.520000    
2018-11-01 10:50:30,286 - ==> Top1: 72.240    Top5: 97.520    Loss: 2.295

2018-11-01 10:50:30,287 - Testing sensitivity of module.layer3.1.conv2.weight [70.0% sparsity]
2018-11-01 10:50:30,292 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 10:50:30,292 - --- test ---------------------
2018-11-01 10:50:30,293 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:30,701 - Test: [   10/   39]    Loss 2.659955    Top1 68.437500    Top5 97.304688    
2018-11-01 10:50:30,803 - Test: [   20/   39]    Loss 2.654425    Top1 69.101562    Top5 97.109375    
2018-11-01 10:50:30,902 - Test: [   30/   39]    Loss 2.653614    Top1 68.932292    Top5 97.421875    
2018-11-01 10:50:30,993 - Test: [   40/   39]    Loss 2.620966    Top1 69.120000    Top5 97.350000    
2018-11-01 10:50:31,016 - ==> Top1: 69.120    Top5: 97.350    Loss: 2.621

2018-11-01 10:50:31,020 - Testing sensitivity of module.layer3.1.conv2.weight [75.0% sparsity]
2018-11-01 10:50:31,024 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 10:50:31,026 - --- test ---------------------
2018-11-01 10:50:31,026 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:31,438 - Test: [   10/   39]    Loss 3.056916    Top1 64.257812    Top5 97.265625    
2018-11-01 10:50:31,540 - Test: [   20/   39]    Loss 3.088402    Top1 65.214844    Top5 97.128906    
2018-11-01 10:50:31,639 - Test: [   30/   39]    Loss 3.119193    Top1 65.117188    Top5 97.486979    
2018-11-01 10:50:31,730 - Test: [   40/   39]    Loss 3.065445    Top1 65.450000    Top5 97.340000    
2018-11-01 10:50:31,755 - ==> Top1: 65.450    Top5: 97.340    Loss: 3.065

2018-11-01 10:50:31,756 - Testing sensitivity of module.layer3.1.conv2.weight [80.0% sparsity]
2018-11-01 10:50:31,760 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 10:50:31,761 - --- test ---------------------
2018-11-01 10:50:31,761 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:32,165 - Test: [   10/   39]    Loss 2.592851    Top1 68.085938    Top5 97.929688    
2018-11-01 10:50:32,268 - Test: [   20/   39]    Loss 2.628842    Top1 68.906250    Top5 97.714844    
2018-11-01 10:50:32,367 - Test: [   30/   39]    Loss 2.663619    Top1 68.450521    Top5 97.851562    
2018-11-01 10:50:32,458 - Test: [   40/   39]    Loss 2.618236    Top1 68.420000    Top5 97.780000    
2018-11-01 10:50:32,485 - ==> Top1: 68.420    Top5: 97.780    Loss: 2.618

2018-11-01 10:50:32,485 - Testing sensitivity of module.layer3.1.conv2.weight [85.0% sparsity]
2018-11-01 10:50:32,489 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 10:50:32,490 - --- test ---------------------
2018-11-01 10:50:32,491 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:32,905 - Test: [   10/   39]    Loss 2.887443    Top1 65.312500    Top5 97.187500    
2018-11-01 10:50:33,007 - Test: [   20/   39]    Loss 2.941854    Top1 65.488281    Top5 97.148438    
2018-11-01 10:50:33,106 - Test: [   30/   39]    Loss 2.985311    Top1 64.609375    Top5 97.252604    
2018-11-01 10:50:33,197 - Test: [   40/   39]    Loss 2.950839    Top1 64.380000    Top5 97.150000    
2018-11-01 10:50:33,221 - ==> Top1: 64.380    Top5: 97.150    Loss: 2.951

2018-11-01 10:50:33,222 - Testing sensitivity of module.layer3.1.conv2.weight [90.0% sparsity]
2018-11-01 10:50:33,225 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 10:50:33,226 - --- test ---------------------
2018-11-01 10:50:33,226 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:33,633 - Test: [   10/   39]    Loss 5.109533    Top1 51.289063    Top5 90.781250    
2018-11-01 10:50:33,735 - Test: [   20/   39]    Loss 5.044211    Top1 52.070313    Top5 90.625000    
2018-11-01 10:50:33,834 - Test: [   30/   39]    Loss 5.057171    Top1 52.174479    Top5 90.729167    
2018-11-01 10:50:33,925 - Test: [   40/   39]    Loss 5.083632    Top1 51.560000    Top5 90.630000    
2018-11-01 10:50:33,950 - ==> Top1: 51.560    Top5: 90.630    Loss: 5.084

2018-11-01 10:50:33,965 - Testing sensitivity of module.layer3.2.conv1.weight [0.0% sparsity]
2018-11-01 10:50:33,967 - --- test ---------------------
2018-11-01 10:50:33,968 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:34,384 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:50:34,486 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:50:34,586 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:50:34,677 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:50:34,713 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:50:34,713 - Testing sensitivity of module.layer3.2.conv1.weight [5.0% sparsity]
2018-11-01 10:50:34,716 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 10:50:34,717 - --- test ---------------------
2018-11-01 10:50:34,717 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:35,119 - Test: [   10/   39]    Loss 0.550807    Top1 91.132812    Top5 99.609375    
2018-11-01 10:50:35,221 - Test: [   20/   39]    Loss 0.553137    Top1 91.308594    Top5 99.531250    
2018-11-01 10:50:35,320 - Test: [   30/   39]    Loss 0.545616    Top1 91.289062    Top5 99.635417    
2018-11-01 10:50:35,412 - Test: [   40/   39]    Loss 0.543650    Top1 91.370000    Top5 99.610000    
2018-11-01 10:50:35,437 - ==> Top1: 91.370    Top5: 99.610    Loss: 0.544

2018-11-01 10:50:35,438 - Testing sensitivity of module.layer3.2.conv1.weight [10.0% sparsity]
2018-11-01 10:50:35,442 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 10:50:35,443 - --- test ---------------------
2018-11-01 10:50:35,444 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:35,853 - Test: [   10/   39]    Loss 0.553556    Top1 90.976562    Top5 99.531250    
2018-11-01 10:50:35,955 - Test: [   20/   39]    Loss 0.557689    Top1 91.250000    Top5 99.531250    
2018-11-01 10:50:36,054 - Test: [   30/   39]    Loss 0.548557    Top1 91.236979    Top5 99.635417    
2018-11-01 10:50:36,145 - Test: [   40/   39]    Loss 0.548079    Top1 91.280000    Top5 99.600000    
2018-11-01 10:50:36,171 - ==> Top1: 91.280    Top5: 99.600    Loss: 0.548

2018-11-01 10:50:36,171 - Testing sensitivity of module.layer3.2.conv1.weight [15.0% sparsity]
2018-11-01 10:50:36,175 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 10:50:36,176 - --- test ---------------------
2018-11-01 10:50:36,177 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:36,582 - Test: [   10/   39]    Loss 0.652546    Top1 87.578125    Top5 98.281250    
2018-11-01 10:50:36,683 - Test: [   20/   39]    Loss 0.640425    Top1 87.343750    Top5 98.242188    
2018-11-01 10:50:36,782 - Test: [   30/   39]    Loss 0.650846    Top1 87.291667    Top5 98.411458    
2018-11-01 10:50:36,873 - Test: [   40/   39]    Loss 0.628585    Top1 87.540000    Top5 98.470000    
2018-11-01 10:50:36,899 - ==> Top1: 87.540    Top5: 98.470    Loss: 0.629

2018-11-01 10:50:36,900 - Testing sensitivity of module.layer3.2.conv1.weight [20.0% sparsity]
2018-11-01 10:50:36,902 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 10:50:36,903 - --- test ---------------------
2018-11-01 10:50:36,904 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:37,337 - Test: [   10/   39]    Loss 0.781281    Top1 84.960938    Top5 97.929688    
2018-11-01 10:50:37,439 - Test: [   20/   39]    Loss 0.770585    Top1 85.234375    Top5 97.773438    
2018-11-01 10:50:37,538 - Test: [   30/   39]    Loss 0.773640    Top1 85.169271    Top5 97.929688    
2018-11-01 10:50:37,629 - Test: [   40/   39]    Loss 0.760189    Top1 85.300000    Top5 98.000000    
2018-11-01 10:50:37,655 - ==> Top1: 85.300    Top5: 98.000    Loss: 0.760

2018-11-01 10:50:37,656 - Testing sensitivity of module.layer3.2.conv1.weight [25.0% sparsity]
2018-11-01 10:50:37,661 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 10:50:37,662 - --- test ---------------------
2018-11-01 10:50:37,662 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:38,089 - Test: [   10/   39]    Loss 1.041357    Top1 80.625000    Top5 96.562500    
2018-11-01 10:50:38,190 - Test: [   20/   39]    Loss 1.038507    Top1 81.054688    Top5 96.582031    
2018-11-01 10:50:38,289 - Test: [   30/   39]    Loss 1.031509    Top1 81.302083    Top5 96.601562    
2018-11-01 10:50:38,380 - Test: [   40/   39]    Loss 1.027244    Top1 81.450000    Top5 96.660000    
2018-11-01 10:50:38,406 - ==> Top1: 81.450    Top5: 96.660    Loss: 1.027

2018-11-01 10:50:38,407 - Testing sensitivity of module.layer3.2.conv1.weight [30.0% sparsity]
2018-11-01 10:50:38,411 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 10:50:38,412 - --- test ---------------------
2018-11-01 10:50:38,412 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:38,836 - Test: [   10/   39]    Loss 2.012679    Top1 65.117188    Top5 96.367188    
2018-11-01 10:50:38,939 - Test: [   20/   39]    Loss 1.986117    Top1 65.468750    Top5 96.210938    
2018-11-01 10:50:39,038 - Test: [   30/   39]    Loss 1.976151    Top1 65.403646    Top5 96.080729    
2018-11-01 10:50:39,129 - Test: [   40/   39]    Loss 1.979478    Top1 65.260000    Top5 96.140000    
2018-11-01 10:50:39,154 - ==> Top1: 65.260    Top5: 96.140    Loss: 1.979

2018-11-01 10:50:39,155 - Testing sensitivity of module.layer3.2.conv1.weight [35.0% sparsity]
2018-11-01 10:50:39,159 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 10:50:39,160 - --- test ---------------------
2018-11-01 10:50:39,160 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:39,566 - Test: [   10/   39]    Loss 3.573738    Top1 49.218750    Top5 92.734375    
2018-11-01 10:50:39,669 - Test: [   20/   39]    Loss 3.538839    Top1 49.765625    Top5 92.578125    
2018-11-01 10:50:39,768 - Test: [   30/   39]    Loss 3.536803    Top1 49.765625    Top5 92.669271    
2018-11-01 10:50:39,859 - Test: [   40/   39]    Loss 3.546524    Top1 49.520000    Top5 92.800000    
2018-11-01 10:50:39,883 - ==> Top1: 49.520    Top5: 92.800    Loss: 3.547

2018-11-01 10:50:39,884 - Testing sensitivity of module.layer3.2.conv1.weight [40.0% sparsity]
2018-11-01 10:50:39,887 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 10:50:39,888 - --- test ---------------------
2018-11-01 10:50:39,888 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:40,297 - Test: [   10/   39]    Loss 10.069141    Top1 22.226563    Top5 90.234375    
2018-11-01 10:50:40,399 - Test: [   20/   39]    Loss 10.046195    Top1 22.441406    Top5 90.058594    
2018-11-01 10:50:40,498 - Test: [   30/   39]    Loss 10.037587    Top1 22.578125    Top5 89.882812    
2018-11-01 10:50:40,589 - Test: [   40/   39]    Loss 10.044239    Top1 22.520000    Top5 90.090000    
2018-11-01 10:50:40,614 - ==> Top1: 22.520    Top5: 90.090    Loss: 10.044

2018-11-01 10:50:40,614 - Testing sensitivity of module.layer3.2.conv1.weight [45.0% sparsity]
2018-11-01 10:50:40,617 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 10:50:40,618 - --- test ---------------------
2018-11-01 10:50:40,618 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:41,043 - Test: [   10/   39]    Loss 15.054230    Top1 12.578125    Top5 89.375000    
2018-11-01 10:50:41,146 - Test: [   20/   39]    Loss 15.030560    Top1 13.007813    Top5 89.121094    
2018-11-01 10:50:41,245 - Test: [   30/   39]    Loss 15.026025    Top1 12.890625    Top5 88.841146    
2018-11-01 10:50:41,336 - Test: [   40/   39]    Loss 14.984263    Top1 12.880000    Top5 89.220000    
2018-11-01 10:50:41,363 - ==> Top1: 12.880    Top5: 89.220    Loss: 14.984

2018-11-01 10:50:41,364 - Testing sensitivity of module.layer3.2.conv1.weight [50.0% sparsity]
2018-11-01 10:50:41,368 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 10:50:41,369 - --- test ---------------------
2018-11-01 10:50:41,369 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:41,784 - Test: [   10/   39]    Loss 5.003936    Top1 42.382812    Top5 85.312500    
2018-11-01 10:50:41,886 - Test: [   20/   39]    Loss 5.000520    Top1 43.066406    Top5 85.371094    
2018-11-01 10:50:41,985 - Test: [   30/   39]    Loss 4.965697    Top1 43.151042    Top5 85.833333    
2018-11-01 10:50:42,076 - Test: [   40/   39]    Loss 4.936333    Top1 43.050000    Top5 85.770000    
2018-11-01 10:50:42,102 - ==> Top1: 43.050    Top5: 85.770    Loss: 4.936

2018-11-01 10:50:42,103 - Testing sensitivity of module.layer3.2.conv1.weight [55.0% sparsity]
2018-11-01 10:50:42,107 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 10:50:42,108 - --- test ---------------------
2018-11-01 10:50:42,108 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:42,522 - Test: [   10/   39]    Loss 4.975899    Top1 39.257812    Top5 90.976562    
2018-11-01 10:50:42,623 - Test: [   20/   39]    Loss 5.033565    Top1 38.105469    Top5 90.312500    
2018-11-01 10:50:42,722 - Test: [   30/   39]    Loss 5.033202    Top1 37.682292    Top5 90.247396    
2018-11-01 10:50:42,814 - Test: [   40/   39]    Loss 5.022640    Top1 37.760000    Top5 90.360000    
2018-11-01 10:50:42,840 - ==> Top1: 37.760    Top5: 90.360    Loss: 5.023

2018-11-01 10:50:42,841 - Testing sensitivity of module.layer3.2.conv1.weight [60.0% sparsity]
2018-11-01 10:50:42,844 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 10:50:42,845 - --- test ---------------------
2018-11-01 10:50:42,845 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:43,249 - Test: [   10/   39]    Loss 5.657541    Top1 28.750000    Top5 82.460938    
2018-11-01 10:50:43,352 - Test: [   20/   39]    Loss 5.724592    Top1 28.476563    Top5 82.148438    
2018-11-01 10:50:43,451 - Test: [   30/   39]    Loss 5.725095    Top1 28.619792    Top5 82.395833    
2018-11-01 10:50:43,542 - Test: [   40/   39]    Loss 5.721915    Top1 28.660000    Top5 82.490000    
2018-11-01 10:50:43,568 - ==> Top1: 28.660    Top5: 82.490    Loss: 5.722

2018-11-01 10:50:43,569 - Testing sensitivity of module.layer3.2.conv1.weight [65.0% sparsity]
2018-11-01 10:50:43,573 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 10:50:43,574 - --- test ---------------------
2018-11-01 10:50:43,574 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:43,988 - Test: [   10/   39]    Loss 5.760033    Top1 36.796875    Top5 75.703125    
2018-11-01 10:50:44,089 - Test: [   20/   39]    Loss 5.787159    Top1 36.796875    Top5 75.761719    
2018-11-01 10:50:44,188 - Test: [   30/   39]    Loss 5.736939    Top1 36.888021    Top5 76.315104    
2018-11-01 10:50:44,279 - Test: [   40/   39]    Loss 5.771107    Top1 36.460000    Top5 76.240000    
2018-11-01 10:50:44,304 - ==> Top1: 36.460    Top5: 76.240    Loss: 5.771

2018-11-01 10:50:44,306 - Testing sensitivity of module.layer3.2.conv1.weight [70.0% sparsity]
2018-11-01 10:50:44,310 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 10:50:44,311 - --- test ---------------------
2018-11-01 10:50:44,311 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:44,735 - Test: [   10/   39]    Loss 6.966092    Top1 28.593750    Top5 77.148438    
2018-11-01 10:50:44,837 - Test: [   20/   39]    Loss 6.934566    Top1 28.925781    Top5 77.343750    
2018-11-01 10:50:44,936 - Test: [   30/   39]    Loss 6.885913    Top1 29.166667    Top5 77.721354    
2018-11-01 10:50:45,026 - Test: [   40/   39]    Loss 6.913382    Top1 28.930000    Top5 77.640000    
2018-11-01 10:50:45,050 - ==> Top1: 28.930    Top5: 77.640    Loss: 6.913

2018-11-01 10:50:45,051 - Testing sensitivity of module.layer3.2.conv1.weight [75.0% sparsity]
2018-11-01 10:50:45,055 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 10:50:45,056 - --- test ---------------------
2018-11-01 10:50:45,057 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:45,479 - Test: [   10/   39]    Loss 5.848892    Top1 27.304688    Top5 81.367188    
2018-11-01 10:50:45,587 - Test: [   20/   39]    Loss 5.757179    Top1 28.554687    Top5 81.093750    
2018-11-01 10:50:45,691 - Test: [   30/   39]    Loss 5.697652    Top1 28.841146    Top5 81.627604    
2018-11-01 10:50:45,787 - Test: [   40/   39]    Loss 5.704192    Top1 28.850000    Top5 81.530000    
2018-11-01 10:50:45,813 - ==> Top1: 28.850    Top5: 81.530    Loss: 5.704

2018-11-01 10:50:45,813 - Testing sensitivity of module.layer3.2.conv1.weight [80.0% sparsity]
2018-11-01 10:50:45,816 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 10:50:45,816 - --- test ---------------------
2018-11-01 10:50:45,817 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:46,247 - Test: [   10/   39]    Loss 6.067382    Top1 23.828125    Top5 75.234375    
2018-11-01 10:50:46,356 - Test: [   20/   39]    Loss 5.965443    Top1 25.136719    Top5 75.761719    
2018-11-01 10:50:46,462 - Test: [   30/   39]    Loss 5.920779    Top1 24.973958    Top5 76.328125    
2018-11-01 10:50:46,560 - Test: [   40/   39]    Loss 5.949475    Top1 24.900000    Top5 75.860000    
2018-11-01 10:50:46,587 - ==> Top1: 24.900    Top5: 75.860    Loss: 5.949

2018-11-01 10:50:46,588 - Testing sensitivity of module.layer3.2.conv1.weight [85.0% sparsity]
2018-11-01 10:50:46,591 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 10:50:46,592 - --- test ---------------------
2018-11-01 10:50:46,592 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:47,009 - Test: [   10/   39]    Loss 8.127165    Top1 26.718750    Top5 52.773438    
2018-11-01 10:50:47,117 - Test: [   20/   39]    Loss 8.011205    Top1 27.636719    Top5 53.964844    
2018-11-01 10:50:47,223 - Test: [   30/   39]    Loss 7.905559    Top1 28.242188    Top5 54.557292    
2018-11-01 10:50:47,322 - Test: [   40/   39]    Loss 7.944966    Top1 27.780000    Top5 54.290000    
2018-11-01 10:50:47,356 - ==> Top1: 27.780    Top5: 54.290    Loss: 7.945

2018-11-01 10:50:47,357 - Testing sensitivity of module.layer3.2.conv1.weight [90.0% sparsity]
2018-11-01 10:50:47,360 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 10:50:47,361 - --- test ---------------------
2018-11-01 10:50:47,361 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:47,769 - Test: [   10/   39]    Loss 8.101437    Top1 21.718750    Top5 58.710938    
2018-11-01 10:50:47,878 - Test: [   20/   39]    Loss 8.020851    Top1 22.304687    Top5 59.726562    
2018-11-01 10:50:47,977 - Test: [   30/   39]    Loss 7.936189    Top1 22.578125    Top5 60.598958    
2018-11-01 10:50:48,068 - Test: [   40/   39]    Loss 7.978707    Top1 22.080000    Top5 60.400000    
2018-11-01 10:50:48,094 - ==> Top1: 22.080    Top5: 60.400    Loss: 7.979

2018-11-01 10:50:48,109 - Testing sensitivity of module.layer3.2.conv2.weight [0.0% sparsity]
2018-11-01 10:50:48,113 - --- test ---------------------
2018-11-01 10:50:48,114 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:48,519 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 10:50:48,622 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 10:50:48,721 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 10:50:48,812 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 10:50:48,837 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 10:50:48,838 - Testing sensitivity of module.layer3.2.conv2.weight [5.0% sparsity]
2018-11-01 10:50:48,842 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 10:50:48,843 - --- test ---------------------
2018-11-01 10:50:48,843 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:49,257 - Test: [   10/   39]    Loss 0.547515    Top1 91.289062    Top5 99.687500    
2018-11-01 10:50:49,360 - Test: [   20/   39]    Loss 0.548254    Top1 91.503906    Top5 99.570312    
2018-11-01 10:50:49,459 - Test: [   30/   39]    Loss 0.541132    Top1 91.484375    Top5 99.661458    
2018-11-01 10:50:49,550 - Test: [   40/   39]    Loss 0.536767    Top1 91.500000    Top5 99.640000    
2018-11-01 10:50:49,575 - ==> Top1: 91.500    Top5: 99.640    Loss: 0.537

2018-11-01 10:50:49,576 - Testing sensitivity of module.layer3.2.conv2.weight [10.0% sparsity]
2018-11-01 10:50:49,579 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 10:50:49,580 - --- test ---------------------
2018-11-01 10:50:49,581 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:49,996 - Test: [   10/   39]    Loss 0.540229    Top1 91.210938    Top5 99.687500    
2018-11-01 10:50:50,097 - Test: [   20/   39]    Loss 0.541160    Top1 91.484375    Top5 99.570312    
2018-11-01 10:50:50,201 - Test: [   30/   39]    Loss 0.534249    Top1 91.484375    Top5 99.661458    
2018-11-01 10:50:50,297 - Test: [   40/   39]    Loss 0.530007    Top1 91.510000    Top5 99.640000    
2018-11-01 10:50:50,324 - ==> Top1: 91.510    Top5: 99.640    Loss: 0.530

2018-11-01 10:50:50,325 - Testing sensitivity of module.layer3.2.conv2.weight [15.0% sparsity]
2018-11-01 10:50:50,329 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 10:50:50,330 - --- test ---------------------
2018-11-01 10:50:50,330 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:50,757 - Test: [   10/   39]    Loss 0.529288    Top1 91.289062    Top5 99.687500    
2018-11-01 10:50:50,864 - Test: [   20/   39]    Loss 0.529706    Top1 91.542969    Top5 99.570312    
2018-11-01 10:50:50,968 - Test: [   30/   39]    Loss 0.523005    Top1 91.497396    Top5 99.661458    
2018-11-01 10:50:51,064 - Test: [   40/   39]    Loss 0.517782    Top1 91.560000    Top5 99.640000    
2018-11-01 10:50:51,101 - ==> Top1: 91.560    Top5: 99.640    Loss: 0.518

2018-11-01 10:50:51,101 - Testing sensitivity of module.layer3.2.conv2.weight [20.0% sparsity]
2018-11-01 10:50:51,104 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 10:50:51,104 - --- test ---------------------
2018-11-01 10:50:51,105 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:51,528 - Test: [   10/   39]    Loss 0.519147    Top1 91.445312    Top5 99.687500    
2018-11-01 10:50:51,631 - Test: [   20/   39]    Loss 0.518458    Top1 91.621094    Top5 99.570312    
2018-11-01 10:50:51,730 - Test: [   30/   39]    Loss 0.513011    Top1 91.549479    Top5 99.661458    
2018-11-01 10:50:51,821 - Test: [   40/   39]    Loss 0.506846    Top1 91.600000    Top5 99.640000    
2018-11-01 10:50:51,846 - ==> Top1: 91.600    Top5: 99.640    Loss: 0.507

2018-11-01 10:50:51,847 - Testing sensitivity of module.layer3.2.conv2.weight [25.0% sparsity]
2018-11-01 10:50:51,850 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 10:50:51,851 - --- test ---------------------
2018-11-01 10:50:51,851 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:52,263 - Test: [   10/   39]    Loss 0.507227    Top1 91.406250    Top5 99.687500    
2018-11-01 10:50:52,366 - Test: [   20/   39]    Loss 0.508139    Top1 91.503906    Top5 99.609375    
2018-11-01 10:50:52,465 - Test: [   30/   39]    Loss 0.502824    Top1 91.445312    Top5 99.687500    
2018-11-01 10:50:52,556 - Test: [   40/   39]    Loss 0.497342    Top1 91.520000    Top5 99.660000    
2018-11-01 10:50:52,582 - ==> Top1: 91.520    Top5: 99.660    Loss: 0.497

2018-11-01 10:50:52,583 - Testing sensitivity of module.layer3.2.conv2.weight [30.0% sparsity]
2018-11-01 10:50:52,586 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 10:50:52,587 - --- test ---------------------
2018-11-01 10:50:52,587 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:53,002 - Test: [   10/   39]    Loss 0.493257    Top1 91.445312    Top5 99.726562    
2018-11-01 10:50:53,104 - Test: [   20/   39]    Loss 0.494994    Top1 91.503906    Top5 99.648438    
2018-11-01 10:50:53,203 - Test: [   30/   39]    Loss 0.490755    Top1 91.510417    Top5 99.713542    
2018-11-01 10:50:53,294 - Test: [   40/   39]    Loss 0.484799    Top1 91.590000    Top5 99.670000    
2018-11-01 10:50:53,321 - ==> Top1: 91.590    Top5: 99.670    Loss: 0.485

2018-11-01 10:50:53,322 - Testing sensitivity of module.layer3.2.conv2.weight [35.0% sparsity]
2018-11-01 10:50:53,326 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 10:50:53,327 - --- test ---------------------
2018-11-01 10:50:53,327 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:53,752 - Test: [   10/   39]    Loss 0.488266    Top1 91.328125    Top5 99.726562    
2018-11-01 10:50:53,854 - Test: [   20/   39]    Loss 0.487508    Top1 91.582031    Top5 99.648438    
2018-11-01 10:50:53,952 - Test: [   30/   39]    Loss 0.482341    Top1 91.523438    Top5 99.700521    
2018-11-01 10:50:54,044 - Test: [   40/   39]    Loss 0.477112    Top1 91.560000    Top5 99.650000    
2018-11-01 10:50:54,069 - ==> Top1: 91.560    Top5: 99.650    Loss: 0.477

2018-11-01 10:50:54,070 - Testing sensitivity of module.layer3.2.conv2.weight [40.0% sparsity]
2018-11-01 10:50:54,072 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 10:50:54,073 - --- test ---------------------
2018-11-01 10:50:54,074 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:54,480 - Test: [   10/   39]    Loss 0.473027    Top1 91.445312    Top5 99.687500    
2018-11-01 10:50:54,582 - Test: [   20/   39]    Loss 0.473224    Top1 91.601562    Top5 99.628906    
2018-11-01 10:50:54,682 - Test: [   30/   39]    Loss 0.468245    Top1 91.536458    Top5 99.687500    
2018-11-01 10:50:54,773 - Test: [   40/   39]    Loss 0.463816    Top1 91.520000    Top5 99.640000    
2018-11-01 10:50:54,798 - ==> Top1: 91.520    Top5: 99.640    Loss: 0.464

2018-11-01 10:50:54,799 - Testing sensitivity of module.layer3.2.conv2.weight [45.0% sparsity]
2018-11-01 10:50:54,803 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 10:50:54,804 - --- test ---------------------
2018-11-01 10:50:54,804 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:55,225 - Test: [   10/   39]    Loss 0.464333    Top1 91.484375    Top5 99.570312    
2018-11-01 10:50:55,331 - Test: [   20/   39]    Loss 0.466979    Top1 91.503906    Top5 99.531250    
2018-11-01 10:50:55,435 - Test: [   30/   39]    Loss 0.462940    Top1 91.471354    Top5 99.609375    
2018-11-01 10:50:55,530 - Test: [   40/   39]    Loss 0.458847    Top1 91.480000    Top5 99.580000    
2018-11-01 10:50:55,556 - ==> Top1: 91.480    Top5: 99.580    Loss: 0.459

2018-11-01 10:50:55,557 - Testing sensitivity of module.layer3.2.conv2.weight [50.0% sparsity]
2018-11-01 10:50:55,560 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 10:50:55,561 - --- test ---------------------
2018-11-01 10:50:55,561 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:55,989 - Test: [   10/   39]    Loss 0.447351    Top1 91.289062    Top5 99.531250    
2018-11-01 10:50:56,094 - Test: [   20/   39]    Loss 0.454195    Top1 91.328125    Top5 99.453125    
2018-11-01 10:50:56,197 - Test: [   30/   39]    Loss 0.449622    Top1 91.210938    Top5 99.557292    
2018-11-01 10:50:56,293 - Test: [   40/   39]    Loss 0.446821    Top1 91.180000    Top5 99.550000    
2018-11-01 10:50:56,320 - ==> Top1: 91.180    Top5: 99.550    Loss: 0.447

2018-11-01 10:50:56,321 - Testing sensitivity of module.layer3.2.conv2.weight [55.0% sparsity]
2018-11-01 10:50:56,324 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 10:50:56,325 - --- test ---------------------
2018-11-01 10:50:56,326 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:56,746 - Test: [   10/   39]    Loss 0.461211    Top1 90.625000    Top5 99.492188    
2018-11-01 10:50:56,849 - Test: [   20/   39]    Loss 0.471166    Top1 90.703125    Top5 99.453125    
2018-11-01 10:50:56,949 - Test: [   30/   39]    Loss 0.465197    Top1 90.494792    Top5 99.557292    
2018-11-01 10:50:57,040 - Test: [   40/   39]    Loss 0.463569    Top1 90.450000    Top5 99.540000    
2018-11-01 10:50:57,065 - ==> Top1: 90.450    Top5: 99.540    Loss: 0.464

2018-11-01 10:50:57,066 - Testing sensitivity of module.layer3.2.conv2.weight [60.0% sparsity]
2018-11-01 10:50:57,071 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 10:50:57,072 - --- test ---------------------
2018-11-01 10:50:57,072 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:57,483 - Test: [   10/   39]    Loss 0.490352    Top1 89.492188    Top5 99.570312    
2018-11-01 10:50:57,585 - Test: [   20/   39]    Loss 0.501505    Top1 89.628906    Top5 99.453125    
2018-11-01 10:50:57,684 - Test: [   30/   39]    Loss 0.493135    Top1 89.348958    Top5 99.544271    
2018-11-01 10:50:57,775 - Test: [   40/   39]    Loss 0.492347    Top1 89.310000    Top5 99.520000    
2018-11-01 10:50:57,800 - ==> Top1: 89.310    Top5: 99.520    Loss: 0.492

2018-11-01 10:50:57,801 - Testing sensitivity of module.layer3.2.conv2.weight [65.0% sparsity]
2018-11-01 10:50:57,805 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 10:50:57,806 - --- test ---------------------
2018-11-01 10:50:57,806 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:58,232 - Test: [   10/   39]    Loss 0.506620    Top1 88.632812    Top5 99.570312    
2018-11-01 10:50:58,339 - Test: [   20/   39]    Loss 0.516859    Top1 88.750000    Top5 99.394531    
2018-11-01 10:50:58,445 - Test: [   30/   39]    Loss 0.511171    Top1 88.450521    Top5 99.453125    
2018-11-01 10:50:58,544 - Test: [   40/   39]    Loss 0.511539    Top1 88.410000    Top5 99.420000    
2018-11-01 10:50:58,570 - ==> Top1: 88.410    Top5: 99.420    Loss: 0.512

2018-11-01 10:50:58,570 - Testing sensitivity of module.layer3.2.conv2.weight [70.0% sparsity]
2018-11-01 10:50:58,574 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 10:50:58,575 - --- test ---------------------
2018-11-01 10:50:58,575 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:59,019 - Test: [   10/   39]    Loss 0.733783    Top1 80.976562    Top5 97.812500    
2018-11-01 10:50:59,126 - Test: [   20/   39]    Loss 0.748271    Top1 81.367188    Top5 97.714844    
2018-11-01 10:50:59,229 - Test: [   30/   39]    Loss 0.739704    Top1 81.302083    Top5 97.825521    
2018-11-01 10:50:59,320 - Test: [   40/   39]    Loss 0.740822    Top1 81.240000    Top5 97.760000    
2018-11-01 10:50:59,346 - ==> Top1: 81.240    Top5: 97.760    Loss: 0.741

2018-11-01 10:50:59,346 - Testing sensitivity of module.layer3.2.conv2.weight [75.0% sparsity]
2018-11-01 10:50:59,349 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 10:50:59,350 - --- test ---------------------
2018-11-01 10:50:59,350 - 10000 samples (256 per mini-batch)
2018-11-01 10:50:59,764 - Test: [   10/   39]    Loss 0.742642    Top1 79.921875    Top5 97.031250    
2018-11-01 10:50:59,866 - Test: [   20/   39]    Loss 0.752040    Top1 79.902344    Top5 97.128906    
2018-11-01 10:50:59,965 - Test: [   30/   39]    Loss 0.746109    Top1 79.856771    Top5 97.343750    
2018-11-01 10:51:00,056 - Test: [   40/   39]    Loss 0.745218    Top1 79.890000    Top5 97.290000    
2018-11-01 10:51:00,083 - ==> Top1: 79.890    Top5: 97.290    Loss: 0.745

2018-11-01 10:51:00,084 - Testing sensitivity of module.layer3.2.conv2.weight [80.0% sparsity]
2018-11-01 10:51:00,088 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 10:51:00,089 - --- test ---------------------
2018-11-01 10:51:00,089 - 10000 samples (256 per mini-batch)
2018-11-01 10:51:00,497 - Test: [   10/   39]    Loss 0.986756    Top1 74.570312    Top5 91.406250    
2018-11-01 10:51:00,600 - Test: [   20/   39]    Loss 0.999473    Top1 74.355469    Top5 91.132812    
2018-11-01 10:51:00,699 - Test: [   30/   39]    Loss 0.989578    Top1 74.700521    Top5 91.276042    
2018-11-01 10:51:00,789 - Test: [   40/   39]    Loss 0.994658    Top1 74.510000    Top5 91.190000    
2018-11-01 10:51:00,815 - ==> Top1: 74.510    Top5: 91.190    Loss: 0.995

2018-11-01 10:51:00,815 - Testing sensitivity of module.layer3.2.conv2.weight [85.0% sparsity]
2018-11-01 10:51:00,819 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 10:51:00,820 - --- test ---------------------
2018-11-01 10:51:00,820 - 10000 samples (256 per mini-batch)
2018-11-01 10:51:01,238 - Test: [   10/   39]    Loss 0.940453    Top1 74.257812    Top5 90.976562    
2018-11-01 10:51:01,341 - Test: [   20/   39]    Loss 0.951708    Top1 74.570312    Top5 90.644531    
2018-11-01 10:51:01,440 - Test: [   30/   39]    Loss 0.942157    Top1 75.039062    Top5 90.833333    
2018-11-01 10:51:01,531 - Test: [   40/   39]    Loss 0.949596    Top1 74.750000    Top5 90.750000    
2018-11-01 10:51:01,556 - ==> Top1: 74.750    Top5: 90.750    Loss: 0.950

2018-11-01 10:51:01,557 - Testing sensitivity of module.layer3.2.conv2.weight [90.0% sparsity]
2018-11-01 10:51:01,560 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 10:51:01,561 - --- test ---------------------
2018-11-01 10:51:01,561 - 10000 samples (256 per mini-batch)
2018-11-01 10:51:01,968 - Test: [   10/   39]    Loss 1.315647    Top1 62.734375    Top5 84.375000    
2018-11-01 10:51:02,071 - Test: [   20/   39]    Loss 1.311665    Top1 63.281250    Top5 84.414062    
2018-11-01 10:51:02,170 - Test: [   30/   39]    Loss 1.292194    Top1 64.244792    Top5 84.700521    
2018-11-01 10:51:02,261 - Test: [   40/   39]    Loss 1.308838    Top1 63.690000    Top5 84.470000    
2018-11-01 10:51:02,287 - ==> Top1: 63.690    Top5: 84.470    Loss: 1.309

2018-11-01 10:51:02,301 - Testing sensitivity of module.fc.weight [0.0% sparsity]
2018-11-01 10:51:02,301 - Testing sensitivity of module.fc.weight [5.0% sparsity]
2018-11-01 10:51:02,301 - Testing sensitivity of module.fc.weight [10.0% sparsity]
2018-11-01 10:51:02,302 - Testing sensitivity of module.fc.weight [15.0% sparsity]
2018-11-01 10:51:02,302 - Testing sensitivity of module.fc.weight [20.0% sparsity]
2018-11-01 10:51:02,302 - Testing sensitivity of module.fc.weight [25.0% sparsity]
2018-11-01 10:51:02,302 - Testing sensitivity of module.fc.weight [30.0% sparsity]
2018-11-01 10:51:02,303 - Testing sensitivity of module.fc.weight [35.0% sparsity]
2018-11-01 10:51:02,303 - Testing sensitivity of module.fc.weight [40.0% sparsity]
2018-11-01 10:51:02,303 - Testing sensitivity of module.fc.weight [45.0% sparsity]
2018-11-01 10:51:02,304 - Testing sensitivity of module.fc.weight [50.0% sparsity]
2018-11-01 10:51:02,304 - Testing sensitivity of module.fc.weight [55.0% sparsity]
2018-11-01 10:51:02,304 - Testing sensitivity of module.fc.weight [60.0% sparsity]
2018-11-01 10:51:02,304 - Testing sensitivity of module.fc.weight [65.0% sparsity]
2018-11-01 10:51:02,305 - Testing sensitivity of module.fc.weight [70.0% sparsity]
2018-11-01 10:51:02,305 - Testing sensitivity of module.fc.weight [75.0% sparsity]
2018-11-01 10:51:02,305 - Testing sensitivity of module.fc.weight [80.0% sparsity]
2018-11-01 10:51:02,305 - Testing sensitivity of module.fc.weight [85.0% sparsity]
2018-11-01 10:51:02,306 - Testing sensitivity of module.fc.weight [90.0% sparsity]
2018-11-01 10:51:02,441 - Generating sensitivity graph
2018-11-01 10:51:02,676 - 
2018-11-01 10:51:02,676 - Log file for this run: /home/ccma/Chilung/1022/distiller/examples/classifier_compression/logs/2018.11.01-104601/2018.11.01-104601.log
