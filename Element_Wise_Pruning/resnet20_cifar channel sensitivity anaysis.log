2018-11-01 11:18:10,734 - Log file for this run: /home/ccma/Chilung/1022/distiller/examples/classifier_compression/logs/2018.11.01-111810/2018.11.01-111810.log
2018-11-01 11:18:10,734 - Number of CPUs: 8
2018-11-01 11:18:10,759 - Number of GPUs: 1
2018-11-01 11:18:10,760 - CUDA version: 8.0.61
2018-11-01 11:18:10,760 - CUDNN version: 7102
2018-11-01 11:18:10,760 - Kernel: 4.13.0-38-generic
2018-11-01 11:18:10,760 - Python: 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
2018-11-01 11:18:10,760 - PyTorch: 0.4.0
2018-11-01 11:18:10,760 - Numpy: 1.14.3
2018-11-01 11:18:10,768 - Git is dirty
2018-11-01 11:18:10,769 - Active Git branch: master
2018-11-01 11:18:10,772 - Git commit: 8bf95d12172fb6e82a00ce40007953e23d9648c7
2018-11-01 11:18:10,772 - App args: ['compress_classifier.py', '--resume=../../../resnet20_cifar_baseline/checkpoint.pth.tar', '-a', 'resnet20_cifar', '../../../data.cifar10', '-j', '12', '--sense=channel']
2018-11-01 11:18:10,773 - ==> using cifar10 dataset
2018-11-01 11:18:10,773 - => creating resnet20_cifar model for CIFAR10
2018-11-01 11:18:13,155 - => loading checkpoint ../../../resnet20_cifar_baseline/checkpoint.pth.tar
2018-11-01 11:18:13,253 - Checkpoint keys:
compression_sched
	epoch
	optimizer
	state_dict
	best_top1
	arch
2018-11-01 11:18:13,253 -    best top@1: 91.530
2018-11-01 11:18:13,254 - Loaded compression schedule from checkpoint (epoch 299)
2018-11-01 11:18:13,254 - => loaded checkpoint '../../../resnet20_cifar_baseline/checkpoint.pth.tar' (epoch 299)
2018-11-01 11:18:13,257 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2018-11-01 11:18:13,257 - Optimizer Args: {'lr': 0.1, 'nesterov': False, 'momentum': 0.9, 'weight_decay': 0.0001, 'dampening': 0}
2018-11-01 11:18:14,484 - Dataset sizes:
	training=45000
	validation=5000
	test=10000
2018-11-01 11:18:14,484 - Running sensitivity tests
2018-11-01 11:18:14,492 - Testing sensitivity of module.conv1.weight [0.0% sparsity]
2018-11-01 11:18:14,494 - --- test ---------------------
2018-11-01 11:18:14,494 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:14,939 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:15,044 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:15,148 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:15,249 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:15,273 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:15,274 - Testing sensitivity of module.conv1.weight [5.0% sparsity]
2018-11-01 11:18:15,276 - Too few channels (3)- can't prune 5.0% channels
2018-11-01 11:18:15,278 - --- test ---------------------
2018-11-01 11:18:15,278 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:15,691 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:15,794 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:15,893 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:15,985 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:16,009 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:16,010 - Testing sensitivity of module.conv1.weight [10.0% sparsity]
2018-11-01 11:18:16,012 - Too few channels (3)- can't prune 10.0% channels
2018-11-01 11:18:16,013 - --- test ---------------------
2018-11-01 11:18:16,013 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:16,420 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:16,522 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:16,624 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:16,716 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:16,741 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:16,741 - Testing sensitivity of module.conv1.weight [15.0% sparsity]
2018-11-01 11:18:16,743 - Too few channels (3)- can't prune 15.0% channels
2018-11-01 11:18:16,743 - --- test ---------------------
2018-11-01 11:18:16,744 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:17,160 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:17,262 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:17,361 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:17,452 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:17,477 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:17,478 - Testing sensitivity of module.conv1.weight [20.0% sparsity]
2018-11-01 11:18:17,480 - Too few channels (3)- can't prune 20.0% channels
2018-11-01 11:18:17,481 - --- test ---------------------
2018-11-01 11:18:17,481 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:17,913 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:18,016 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:18,115 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:18,207 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:18,232 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:18,232 - Testing sensitivity of module.conv1.weight [25.0% sparsity]
2018-11-01 11:18:18,234 - Too few channels (3)- can't prune 25.0% channels
2018-11-01 11:18:18,235 - --- test ---------------------
2018-11-01 11:18:18,235 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:18,676 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:18,786 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:18,893 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:18,989 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:19,013 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:19,014 - Testing sensitivity of module.conv1.weight [30.0% sparsity]
2018-11-01 11:18:19,016 - Too few channels (3)- can't prune 30.0% channels
2018-11-01 11:18:19,018 - --- test ---------------------
2018-11-01 11:18:19,018 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:19,485 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:19,587 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:19,685 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:19,776 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:19,802 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:19,803 - Testing sensitivity of module.conv1.weight [35.0% sparsity]
2018-11-01 11:18:19,811 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.333 goal=0.350 (1/3)
2018-11-01 11:18:19,812 - --- test ---------------------
2018-11-01 11:18:19,812 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:20,282 - Test: [   10/   39]    Loss 1.802675    Top1 73.945312    Top5 95.585938    
2018-11-01 11:18:20,391 - Test: [   20/   39]    Loss 1.775311    Top1 74.667969    Top5 95.800781    
2018-11-01 11:18:20,497 - Test: [   30/   39]    Loss 1.801709    Top1 74.114583    Top5 95.898438    
2018-11-01 11:18:20,595 - Test: [   40/   39]    Loss 1.798657    Top1 74.370000    Top5 96.100000    
2018-11-01 11:18:20,620 - ==> Top1: 74.370    Top5: 96.100    Loss: 1.799

2018-11-01 11:18:20,620 - Testing sensitivity of module.conv1.weight [40.0% sparsity]
2018-11-01 11:18:20,623 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.333 goal=0.400 (1/3)
2018-11-01 11:18:20,624 - --- test ---------------------
2018-11-01 11:18:20,625 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:21,074 - Test: [   10/   39]    Loss 1.802675    Top1 73.945312    Top5 95.585938    
2018-11-01 11:18:21,181 - Test: [   20/   39]    Loss 1.775311    Top1 74.667969    Top5 95.800781    
2018-11-01 11:18:21,288 - Test: [   30/   39]    Loss 1.801709    Top1 74.114583    Top5 95.898438    
2018-11-01 11:18:21,385 - Test: [   40/   39]    Loss 1.798657    Top1 74.370000    Top5 96.100000    
2018-11-01 11:18:21,418 - ==> Top1: 74.370    Top5: 96.100    Loss: 1.799

2018-11-01 11:18:21,418 - Testing sensitivity of module.conv1.weight [45.0% sparsity]
2018-11-01 11:18:21,421 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.333 goal=0.450 (1/3)
2018-11-01 11:18:21,422 - --- test ---------------------
2018-11-01 11:18:21,423 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:21,889 - Test: [   10/   39]    Loss 1.802675    Top1 73.945312    Top5 95.585938    
2018-11-01 11:18:21,998 - Test: [   20/   39]    Loss 1.775311    Top1 74.667969    Top5 95.800781    
2018-11-01 11:18:22,104 - Test: [   30/   39]    Loss 1.801709    Top1 74.114583    Top5 95.898438    
2018-11-01 11:18:22,202 - Test: [   40/   39]    Loss 1.798657    Top1 74.370000    Top5 96.100000    
2018-11-01 11:18:22,228 - ==> Top1: 74.370    Top5: 96.100    Loss: 1.799

2018-11-01 11:18:22,228 - Testing sensitivity of module.conv1.weight [50.0% sparsity]
2018-11-01 11:18:22,231 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.333 goal=0.500 (1/3)
2018-11-01 11:18:22,232 - --- test ---------------------
2018-11-01 11:18:22,233 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:22,640 - Test: [   10/   39]    Loss 1.802675    Top1 73.945312    Top5 95.585938    
2018-11-01 11:18:22,742 - Test: [   20/   39]    Loss 1.775311    Top1 74.667969    Top5 95.800781    
2018-11-01 11:18:22,841 - Test: [   30/   39]    Loss 1.801709    Top1 74.114583    Top5 95.898438    
2018-11-01 11:18:22,932 - Test: [   40/   39]    Loss 1.798657    Top1 74.370000    Top5 96.100000    
2018-11-01 11:18:22,956 - ==> Top1: 74.370    Top5: 96.100    Loss: 1.799

2018-11-01 11:18:22,957 - Testing sensitivity of module.conv1.weight [55.0% sparsity]
2018-11-01 11:18:22,963 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.333 goal=0.550 (1/3)
2018-11-01 11:18:22,964 - --- test ---------------------
2018-11-01 11:18:22,964 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:23,371 - Test: [   10/   39]    Loss 1.802675    Top1 73.945312    Top5 95.585938    
2018-11-01 11:18:23,473 - Test: [   20/   39]    Loss 1.775311    Top1 74.667969    Top5 95.800781    
2018-11-01 11:18:23,579 - Test: [   30/   39]    Loss 1.801709    Top1 74.114583    Top5 95.898438    
2018-11-01 11:18:23,677 - Test: [   40/   39]    Loss 1.798657    Top1 74.370000    Top5 96.100000    
2018-11-01 11:18:23,718 - ==> Top1: 74.370    Top5: 96.100    Loss: 1.799

2018-11-01 11:18:23,719 - Testing sensitivity of module.conv1.weight [60.0% sparsity]
2018-11-01 11:18:23,721 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.333 goal=0.600 (1/3)
2018-11-01 11:18:23,723 - --- test ---------------------
2018-11-01 11:18:23,723 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:24,132 - Test: [   10/   39]    Loss 1.802675    Top1 73.945312    Top5 95.585938    
2018-11-01 11:18:24,234 - Test: [   20/   39]    Loss 1.775311    Top1 74.667969    Top5 95.800781    
2018-11-01 11:18:24,333 - Test: [   30/   39]    Loss 1.801709    Top1 74.114583    Top5 95.898438    
2018-11-01 11:18:24,424 - Test: [   40/   39]    Loss 1.798657    Top1 74.370000    Top5 96.100000    
2018-11-01 11:18:24,448 - ==> Top1: 74.370    Top5: 96.100    Loss: 1.799

2018-11-01 11:18:24,449 - Testing sensitivity of module.conv1.weight [65.0% sparsity]
2018-11-01 11:18:24,451 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.333 goal=0.650 (1/3)
2018-11-01 11:18:24,453 - --- test ---------------------
2018-11-01 11:18:24,453 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:24,901 - Test: [   10/   39]    Loss 1.802675    Top1 73.945312    Top5 95.585938    
2018-11-01 11:18:25,010 - Test: [   20/   39]    Loss 1.775311    Top1 74.667969    Top5 95.800781    
2018-11-01 11:18:25,117 - Test: [   30/   39]    Loss 1.801709    Top1 74.114583    Top5 95.898438    
2018-11-01 11:18:25,214 - Test: [   40/   39]    Loss 1.798657    Top1 74.370000    Top5 96.100000    
2018-11-01 11:18:25,241 - ==> Top1: 74.370    Top5: 96.100    Loss: 1.799

2018-11-01 11:18:25,241 - Testing sensitivity of module.conv1.weight [70.0% sparsity]
2018-11-01 11:18:25,244 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.667 goal=0.700 (2/3)
2018-11-01 11:18:25,245 - --- test ---------------------
2018-11-01 11:18:25,245 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:25,648 - Test: [   10/   39]    Loss 3.931518    Top1 48.164063    Top5 88.867188    
2018-11-01 11:18:25,751 - Test: [   20/   39]    Loss 3.777846    Top1 48.945313    Top5 89.355469    
2018-11-01 11:18:25,850 - Test: [   30/   39]    Loss 3.748958    Top1 48.867188    Top5 89.609375    
2018-11-01 11:18:25,941 - Test: [   40/   39]    Loss 3.778685    Top1 48.490000    Top5 89.790000    
2018-11-01 11:18:25,941 - ==> Top1: 48.490    Top5: 89.790    Loss: 3.779

2018-11-01 11:18:25,945 - Testing sensitivity of module.conv1.weight [75.0% sparsity]
2018-11-01 11:18:25,947 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.667 goal=0.750 (2/3)
2018-11-01 11:18:25,948 - --- test ---------------------
2018-11-01 11:18:25,948 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:26,384 - Test: [   10/   39]    Loss 3.931518    Top1 48.164063    Top5 88.867188    
2018-11-01 11:18:26,490 - Test: [   20/   39]    Loss 3.777846    Top1 48.945313    Top5 89.355469    
2018-11-01 11:18:26,589 - Test: [   30/   39]    Loss 3.748958    Top1 48.867188    Top5 89.609375    
2018-11-01 11:18:26,683 - Test: [   40/   39]    Loss 3.778685    Top1 48.490000    Top5 89.790000    
2018-11-01 11:18:26,711 - ==> Top1: 48.490    Top5: 89.790    Loss: 3.779

2018-11-01 11:18:26,713 - Testing sensitivity of module.conv1.weight [80.0% sparsity]
2018-11-01 11:18:26,715 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.667 goal=0.800 (2/3)
2018-11-01 11:18:26,716 - --- test ---------------------
2018-11-01 11:18:26,718 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:27,154 - Test: [   10/   39]    Loss 3.931518    Top1 48.164063    Top5 88.867188    
2018-11-01 11:18:27,256 - Test: [   20/   39]    Loss 3.777846    Top1 48.945313    Top5 89.355469    
2018-11-01 11:18:27,360 - Test: [   30/   39]    Loss 3.748958    Top1 48.867188    Top5 89.609375    
2018-11-01 11:18:27,455 - Test: [   40/   39]    Loss 3.778685    Top1 48.490000    Top5 89.790000    
2018-11-01 11:18:27,480 - ==> Top1: 48.490    Top5: 89.790    Loss: 3.779

2018-11-01 11:18:27,480 - Testing sensitivity of module.conv1.weight [85.0% sparsity]
2018-11-01 11:18:27,483 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.667 goal=0.850 (2/3)
2018-11-01 11:18:27,484 - --- test ---------------------
2018-11-01 11:18:27,484 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:27,945 - Test: [   10/   39]    Loss 3.931518    Top1 48.164063    Top5 88.867188    
2018-11-01 11:18:28,052 - Test: [   20/   39]    Loss 3.777846    Top1 48.945313    Top5 89.355469    
2018-11-01 11:18:28,152 - Test: [   30/   39]    Loss 3.748958    Top1 48.867188    Top5 89.609375    
2018-11-01 11:18:28,245 - Test: [   40/   39]    Loss 3.778685    Top1 48.490000    Top5 89.790000    
2018-11-01 11:18:28,272 - ==> Top1: 48.490    Top5: 89.790    Loss: 3.779

2018-11-01 11:18:28,273 - Testing sensitivity of module.conv1.weight [90.0% sparsity]
2018-11-01 11:18:28,275 - L1RankedStructureParameterPruner - param: module.conv1.weight pruned=0.667 goal=0.900 (2/3)
2018-11-01 11:18:28,277 - --- test ---------------------
2018-11-01 11:18:28,277 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:28,696 - Test: [   10/   39]    Loss 3.931518    Top1 48.164063    Top5 88.867188    
2018-11-01 11:18:28,799 - Test: [   20/   39]    Loss 3.777846    Top1 48.945313    Top5 89.355469    
2018-11-01 11:18:28,898 - Test: [   30/   39]    Loss 3.748958    Top1 48.867188    Top5 89.609375    
2018-11-01 11:18:28,989 - Test: [   40/   39]    Loss 3.778685    Top1 48.490000    Top5 89.790000    
2018-11-01 11:18:29,014 - ==> Top1: 48.490    Top5: 89.790    Loss: 3.779

2018-11-01 11:18:29,025 - Testing sensitivity of module.layer1.0.conv1.weight [0.0% sparsity]
2018-11-01 11:18:29,028 - --- test ---------------------
2018-11-01 11:18:29,028 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:29,440 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:29,541 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:29,640 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:29,731 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:29,756 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:29,758 - Testing sensitivity of module.layer1.0.conv1.weight [5.0% sparsity]
2018-11-01 11:18:29,759 - Too few channels (16)- can't prune 5.0% channels
2018-11-01 11:18:29,760 - --- test ---------------------
2018-11-01 11:18:29,761 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:30,164 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:30,266 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:30,365 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:30,456 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:30,481 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:30,482 - Testing sensitivity of module.layer1.0.conv1.weight [10.0% sparsity]
2018-11-01 11:18:30,485 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 11:18:30,486 - --- test ---------------------
2018-11-01 11:18:30,487 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:30,962 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:31,073 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:31,180 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:31,277 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:31,305 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:31,305 - Testing sensitivity of module.layer1.0.conv1.weight [15.0% sparsity]
2018-11-01 11:18:31,308 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 11:18:31,310 - --- test ---------------------
2018-11-01 11:18:31,310 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:31,728 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:31,830 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:31,937 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:32,035 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:32,071 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:32,073 - Testing sensitivity of module.layer1.0.conv1.weight [20.0% sparsity]
2018-11-01 11:18:32,076 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 11:18:32,078 - --- test ---------------------
2018-11-01 11:18:32,078 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:32,529 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:32,634 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:32,733 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:32,824 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:32,849 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:32,849 - Testing sensitivity of module.layer1.0.conv1.weight [25.0% sparsity]
2018-11-01 11:18:32,852 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 11:18:32,853 - --- test ---------------------
2018-11-01 11:18:32,853 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:33,291 - Test: [   10/   39]    Loss 0.552114    Top1 91.367188    Top5 99.687500    
2018-11-01 11:18:33,395 - Test: [   20/   39]    Loss 0.553444    Top1 91.562500    Top5 99.570312    
2018-11-01 11:18:33,494 - Test: [   30/   39]    Loss 0.546768    Top1 91.536458    Top5 99.661458    
2018-11-01 11:18:33,585 - Test: [   40/   39]    Loss 0.541587    Top1 91.520000    Top5 99.640000    
2018-11-01 11:18:33,611 - ==> Top1: 91.520    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:33,611 - Testing sensitivity of module.layer1.0.conv1.weight [30.0% sparsity]
2018-11-01 11:18:33,615 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 11:18:33,616 - --- test ---------------------
2018-11-01 11:18:33,617 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:34,099 - Test: [   10/   39]    Loss 0.552114    Top1 91.367188    Top5 99.687500    
2018-11-01 11:18:34,202 - Test: [   20/   39]    Loss 0.553444    Top1 91.562500    Top5 99.570312    
2018-11-01 11:18:34,302 - Test: [   30/   39]    Loss 0.546768    Top1 91.536458    Top5 99.661458    
2018-11-01 11:18:34,399 - Test: [   40/   39]    Loss 0.541587    Top1 91.520000    Top5 99.640000    
2018-11-01 11:18:34,424 - ==> Top1: 91.520    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:34,425 - Testing sensitivity of module.layer1.0.conv1.weight [35.0% sparsity]
2018-11-01 11:18:34,427 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 11:18:34,428 - --- test ---------------------
2018-11-01 11:18:34,429 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:34,856 - Test: [   10/   39]    Loss 0.554327    Top1 91.250000    Top5 99.648438    
2018-11-01 11:18:34,962 - Test: [   20/   39]    Loss 0.553118    Top1 91.484375    Top5 99.550781    
2018-11-01 11:18:35,068 - Test: [   30/   39]    Loss 0.546716    Top1 91.406250    Top5 99.648438    
2018-11-01 11:18:35,162 - Test: [   40/   39]    Loss 0.542741    Top1 91.420000    Top5 99.630000    
2018-11-01 11:18:35,186 - ==> Top1: 91.420    Top5: 99.630    Loss: 0.543

2018-11-01 11:18:35,187 - Testing sensitivity of module.layer1.0.conv1.weight [40.0% sparsity]
2018-11-01 11:18:35,190 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 11:18:35,191 - --- test ---------------------
2018-11-01 11:18:35,192 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:35,619 - Test: [   10/   39]    Loss 0.557010    Top1 91.132812    Top5 99.648438    
2018-11-01 11:18:35,721 - Test: [   20/   39]    Loss 0.553718    Top1 91.308594    Top5 99.550781    
2018-11-01 11:18:35,819 - Test: [   30/   39]    Loss 0.547533    Top1 91.302083    Top5 99.648438    
2018-11-01 11:18:35,911 - Test: [   40/   39]    Loss 0.544258    Top1 91.300000    Top5 99.630000    
2018-11-01 11:18:35,937 - ==> Top1: 91.300    Top5: 99.630    Loss: 0.544

2018-11-01 11:18:35,938 - Testing sensitivity of module.layer1.0.conv1.weight [45.0% sparsity]
2018-11-01 11:18:35,941 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 11:18:35,943 - --- test ---------------------
2018-11-01 11:18:35,943 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:36,353 - Test: [   10/   39]    Loss 0.571790    Top1 90.859375    Top5 99.609375    
2018-11-01 11:18:36,458 - Test: [   20/   39]    Loss 0.564866    Top1 91.054688    Top5 99.531250    
2018-11-01 11:18:36,557 - Test: [   30/   39]    Loss 0.556541    Top1 91.067708    Top5 99.622396    
2018-11-01 11:18:36,648 - Test: [   40/   39]    Loss 0.552144    Top1 91.120000    Top5 99.620000    
2018-11-01 11:18:36,674 - ==> Top1: 91.120    Top5: 99.620    Loss: 0.552

2018-11-01 11:18:36,675 - Testing sensitivity of module.layer1.0.conv1.weight [50.0% sparsity]
2018-11-01 11:18:36,677 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 11:18:36,679 - --- test ---------------------
2018-11-01 11:18:36,679 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:37,096 - Test: [   10/   39]    Loss 0.573076    Top1 90.703125    Top5 99.531250    
2018-11-01 11:18:37,197 - Test: [   20/   39]    Loss 0.567984    Top1 91.015625    Top5 99.414062    
2018-11-01 11:18:37,296 - Test: [   30/   39]    Loss 0.565006    Top1 90.976562    Top5 99.518229    
2018-11-01 11:18:37,388 - Test: [   40/   39]    Loss 0.556909    Top1 91.060000    Top5 99.510000    
2018-11-01 11:18:37,412 - ==> Top1: 91.060    Top5: 99.510    Loss: 0.557

2018-11-01 11:18:37,414 - Testing sensitivity of module.layer1.0.conv1.weight [55.0% sparsity]
2018-11-01 11:18:37,417 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 11:18:37,418 - --- test ---------------------
2018-11-01 11:18:37,418 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:37,828 - Test: [   10/   39]    Loss 0.573076    Top1 90.703125    Top5 99.531250    
2018-11-01 11:18:37,931 - Test: [   20/   39]    Loss 0.567984    Top1 91.015625    Top5 99.414062    
2018-11-01 11:18:38,030 - Test: [   30/   39]    Loss 0.565006    Top1 90.976562    Top5 99.518229    
2018-11-01 11:18:38,121 - Test: [   40/   39]    Loss 0.556909    Top1 91.060000    Top5 99.510000    
2018-11-01 11:18:38,145 - ==> Top1: 91.060    Top5: 99.510    Loss: 0.557

2018-11-01 11:18:38,146 - Testing sensitivity of module.layer1.0.conv1.weight [60.0% sparsity]
2018-11-01 11:18:38,149 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 11:18:38,150 - --- test ---------------------
2018-11-01 11:18:38,150 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:38,568 - Test: [   10/   39]    Loss 0.591519    Top1 90.820312    Top5 99.531250    
2018-11-01 11:18:38,670 - Test: [   20/   39]    Loss 0.590608    Top1 90.859375    Top5 99.433594    
2018-11-01 11:18:38,769 - Test: [   30/   39]    Loss 0.589443    Top1 90.716146    Top5 99.518229    
2018-11-01 11:18:38,860 - Test: [   40/   39]    Loss 0.583379    Top1 90.710000    Top5 99.520000    
2018-11-01 11:18:38,885 - ==> Top1: 90.710    Top5: 99.520    Loss: 0.583

2018-11-01 11:18:38,886 - Testing sensitivity of module.layer1.0.conv1.weight [65.0% sparsity]
2018-11-01 11:18:38,888 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 11:18:38,889 - --- test ---------------------
2018-11-01 11:18:38,889 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:39,299 - Test: [   10/   39]    Loss 0.597669    Top1 90.351562    Top5 99.531250    
2018-11-01 11:18:39,401 - Test: [   20/   39]    Loss 0.598069    Top1 90.585938    Top5 99.375000    
2018-11-01 11:18:39,500 - Test: [   30/   39]    Loss 0.604395    Top1 90.377604    Top5 99.479167    
2018-11-01 11:18:39,591 - Test: [   40/   39]    Loss 0.600957    Top1 90.430000    Top5 99.510000    
2018-11-01 11:18:39,615 - ==> Top1: 90.430    Top5: 99.510    Loss: 0.601

2018-11-01 11:18:39,616 - Testing sensitivity of module.layer1.0.conv1.weight [70.0% sparsity]
2018-11-01 11:18:39,619 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 11:18:39,620 - --- test ---------------------
2018-11-01 11:18:39,621 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:40,040 - Test: [   10/   39]    Loss 0.618022    Top1 90.156250    Top5 99.570312    
2018-11-01 11:18:40,143 - Test: [   20/   39]    Loss 0.618887    Top1 90.468750    Top5 99.355469    
2018-11-01 11:18:40,242 - Test: [   30/   39]    Loss 0.620128    Top1 90.325521    Top5 99.414062    
2018-11-01 11:18:40,334 - Test: [   40/   39]    Loss 0.615341    Top1 90.270000    Top5 99.430000    
2018-11-01 11:18:40,359 - ==> Top1: 90.270    Top5: 99.430    Loss: 0.615

2018-11-01 11:18:40,360 - Testing sensitivity of module.layer1.0.conv1.weight [75.0% sparsity]
2018-11-01 11:18:40,363 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 11:18:40,364 - --- test ---------------------
2018-11-01 11:18:40,365 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:40,777 - Test: [   10/   39]    Loss 0.728042    Top1 88.710938    Top5 99.570312    
2018-11-01 11:18:40,880 - Test: [   20/   39]    Loss 0.720683    Top1 88.847656    Top5 99.355469    
2018-11-01 11:18:40,979 - Test: [   30/   39]    Loss 0.727225    Top1 88.645833    Top5 99.414062    
2018-11-01 11:18:41,070 - Test: [   40/   39]    Loss 0.730381    Top1 88.530000    Top5 99.380000    
2018-11-01 11:18:41,095 - ==> Top1: 88.530    Top5: 99.380    Loss: 0.730

2018-11-01 11:18:41,095 - Testing sensitivity of module.layer1.0.conv1.weight [80.0% sparsity]
2018-11-01 11:18:41,098 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 11:18:41,098 - --- test ---------------------
2018-11-01 11:18:41,099 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:41,523 - Test: [   10/   39]    Loss 0.728042    Top1 88.710938    Top5 99.570312    
2018-11-01 11:18:41,624 - Test: [   20/   39]    Loss 0.720683    Top1 88.847656    Top5 99.355469    
2018-11-01 11:18:41,724 - Test: [   30/   39]    Loss 0.727225    Top1 88.645833    Top5 99.414062    
2018-11-01 11:18:41,815 - Test: [   40/   39]    Loss 0.730381    Top1 88.530000    Top5 99.380000    
2018-11-01 11:18:41,840 - ==> Top1: 88.530    Top5: 99.380    Loss: 0.730

2018-11-01 11:18:41,841 - Testing sensitivity of module.layer1.0.conv1.weight [85.0% sparsity]
2018-11-01 11:18:41,843 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 11:18:41,845 - --- test ---------------------
2018-11-01 11:18:41,845 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:42,308 - Test: [   10/   39]    Loss 0.751121    Top1 88.320312    Top5 99.531250    
2018-11-01 11:18:42,412 - Test: [   20/   39]    Loss 0.748849    Top1 88.515625    Top5 99.296875    
2018-11-01 11:18:42,513 - Test: [   30/   39]    Loss 0.757309    Top1 88.203125    Top5 99.401042    
2018-11-01 11:18:42,605 - Test: [   40/   39]    Loss 0.754294    Top1 88.160000    Top5 99.370000    
2018-11-01 11:18:42,631 - ==> Top1: 88.160    Top5: 99.370    Loss: 0.754

2018-11-01 11:18:42,631 - Testing sensitivity of module.layer1.0.conv1.weight [90.0% sparsity]
2018-11-01 11:18:42,634 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 11:18:42,635 - --- test ---------------------
2018-11-01 11:18:42,635 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:43,068 - Test: [   10/   39]    Loss 0.785734    Top1 87.226562    Top5 99.335938    
2018-11-01 11:18:43,170 - Test: [   20/   39]    Loss 0.796883    Top1 87.500000    Top5 99.160156    
2018-11-01 11:18:43,269 - Test: [   30/   39]    Loss 0.804259    Top1 87.330729    Top5 99.309896    
2018-11-01 11:18:43,361 - Test: [   40/   39]    Loss 0.812400    Top1 87.370000    Top5 99.310000    
2018-11-01 11:18:43,386 - ==> Top1: 87.370    Top5: 99.310    Loss: 0.812

2018-11-01 11:18:43,402 - Testing sensitivity of module.layer1.0.conv2.weight [0.0% sparsity]
2018-11-01 11:18:43,406 - --- test ---------------------
2018-11-01 11:18:43,406 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:43,800 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:43,903 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:44,005 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:44,103 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:44,138 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:44,139 - Testing sensitivity of module.layer1.0.conv2.weight [5.0% sparsity]
2018-11-01 11:18:44,141 - Too few channels (16)- can't prune 5.0% channels
2018-11-01 11:18:44,142 - --- test ---------------------
2018-11-01 11:18:44,143 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:44,575 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:44,681 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:44,780 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:44,873 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:44,898 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:44,899 - Testing sensitivity of module.layer1.0.conv2.weight [10.0% sparsity]
2018-11-01 11:18:44,901 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 11:18:44,903 - --- test ---------------------
2018-11-01 11:18:44,903 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:45,353 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:45,463 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:45,563 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:45,655 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:45,681 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:45,682 - Testing sensitivity of module.layer1.0.conv2.weight [15.0% sparsity]
2018-11-01 11:18:45,685 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 11:18:45,686 - --- test ---------------------
2018-11-01 11:18:45,686 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:46,128 - Test: [   10/   39]    Loss 0.559678    Top1 91.171875    Top5 99.648438    
2018-11-01 11:18:46,231 - Test: [   20/   39]    Loss 0.556906    Top1 91.386719    Top5 99.570312    
2018-11-01 11:18:46,331 - Test: [   30/   39]    Loss 0.551454    Top1 91.328125    Top5 99.635417    
2018-11-01 11:18:46,424 - Test: [   40/   39]    Loss 0.546219    Top1 91.410000    Top5 99.620000    
2018-11-01 11:18:46,424 - ==> Top1: 91.410    Top5: 99.620    Loss: 0.546

2018-11-01 11:18:46,428 - Testing sensitivity of module.layer1.0.conv2.weight [20.0% sparsity]
2018-11-01 11:18:46,431 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 11:18:46,432 - --- test ---------------------
2018-11-01 11:18:46,432 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:46,849 - Test: [   10/   39]    Loss 0.558566    Top1 91.171875    Top5 99.687500    
2018-11-01 11:18:46,953 - Test: [   20/   39]    Loss 0.558900    Top1 91.406250    Top5 99.589844    
2018-11-01 11:18:47,053 - Test: [   30/   39]    Loss 0.553933    Top1 91.354167    Top5 99.648438    
2018-11-01 11:18:47,145 - Test: [   40/   39]    Loss 0.547832    Top1 91.410000    Top5 99.630000    
2018-11-01 11:18:47,171 - ==> Top1: 91.410    Top5: 99.630    Loss: 0.548

2018-11-01 11:18:47,172 - Testing sensitivity of module.layer1.0.conv2.weight [25.0% sparsity]
2018-11-01 11:18:47,174 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 11:18:47,175 - --- test ---------------------
2018-11-01 11:18:47,175 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:47,624 - Test: [   10/   39]    Loss 0.566231    Top1 91.015625    Top5 99.609375    
2018-11-01 11:18:47,733 - Test: [   20/   39]    Loss 0.568219    Top1 91.210938    Top5 99.531250    
2018-11-01 11:18:47,836 - Test: [   30/   39]    Loss 0.565298    Top1 91.145833    Top5 99.609375    
2018-11-01 11:18:47,928 - Test: [   40/   39]    Loss 0.559645    Top1 91.190000    Top5 99.600000    
2018-11-01 11:18:47,957 - ==> Top1: 91.190    Top5: 99.600    Loss: 0.560

2018-11-01 11:18:47,961 - Testing sensitivity of module.layer1.0.conv2.weight [30.0% sparsity]
2018-11-01 11:18:47,963 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 11:18:47,965 - --- test ---------------------
2018-11-01 11:18:47,965 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:48,385 - Test: [   10/   39]    Loss 0.566231    Top1 91.015625    Top5 99.609375    
2018-11-01 11:18:48,490 - Test: [   20/   39]    Loss 0.568219    Top1 91.210938    Top5 99.531250    
2018-11-01 11:18:48,590 - Test: [   30/   39]    Loss 0.565298    Top1 91.145833    Top5 99.609375    
2018-11-01 11:18:48,688 - Test: [   40/   39]    Loss 0.559645    Top1 91.190000    Top5 99.600000    
2018-11-01 11:18:48,713 - ==> Top1: 91.190    Top5: 99.600    Loss: 0.560

2018-11-01 11:18:48,715 - Testing sensitivity of module.layer1.0.conv2.weight [35.0% sparsity]
2018-11-01 11:18:48,718 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 11:18:48,719 - --- test ---------------------
2018-11-01 11:18:48,720 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:49,148 - Test: [   10/   39]    Loss 0.568769    Top1 90.664062    Top5 99.687500    
2018-11-01 11:18:49,251 - Test: [   20/   39]    Loss 0.569608    Top1 91.015625    Top5 99.589844    
2018-11-01 11:18:49,350 - Test: [   30/   39]    Loss 0.568148    Top1 90.950521    Top5 99.648438    
2018-11-01 11:18:49,441 - Test: [   40/   39]    Loss 0.562734    Top1 90.960000    Top5 99.630000    
2018-11-01 11:18:49,466 - ==> Top1: 90.960    Top5: 99.630    Loss: 0.563

2018-11-01 11:18:49,467 - Testing sensitivity of module.layer1.0.conv2.weight [40.0% sparsity]
2018-11-01 11:18:49,470 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 11:18:49,471 - --- test ---------------------
2018-11-01 11:18:49,471 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:49,884 - Test: [   10/   39]    Loss 0.578353    Top1 90.585938    Top5 99.609375    
2018-11-01 11:18:49,986 - Test: [   20/   39]    Loss 0.580124    Top1 90.781250    Top5 99.550781    
2018-11-01 11:18:50,085 - Test: [   30/   39]    Loss 0.572843    Top1 90.820312    Top5 99.596354    
2018-11-01 11:18:50,177 - Test: [   40/   39]    Loss 0.570157    Top1 90.780000    Top5 99.580000    
2018-11-01 11:18:50,201 - ==> Top1: 90.780    Top5: 99.580    Loss: 0.570

2018-11-01 11:18:50,202 - Testing sensitivity of module.layer1.0.conv2.weight [45.0% sparsity]
2018-11-01 11:18:50,205 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 11:18:50,206 - --- test ---------------------
2018-11-01 11:18:50,207 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:50,619 - Test: [   10/   39]    Loss 0.584965    Top1 90.468750    Top5 99.570312    
2018-11-01 11:18:50,722 - Test: [   20/   39]    Loss 0.585061    Top1 90.703125    Top5 99.550781    
2018-11-01 11:18:50,821 - Test: [   30/   39]    Loss 0.578637    Top1 90.768229    Top5 99.609375    
2018-11-01 11:18:50,913 - Test: [   40/   39]    Loss 0.573900    Top1 90.770000    Top5 99.590000    
2018-11-01 11:18:50,937 - ==> Top1: 90.770    Top5: 99.590    Loss: 0.574

2018-11-01 11:18:50,938 - Testing sensitivity of module.layer1.0.conv2.weight [50.0% sparsity]
2018-11-01 11:18:50,940 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 11:18:50,941 - --- test ---------------------
2018-11-01 11:18:50,941 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:51,347 - Test: [   10/   39]    Loss 0.592563    Top1 90.390625    Top5 99.570312    
2018-11-01 11:18:51,451 - Test: [   20/   39]    Loss 0.591840    Top1 90.644531    Top5 99.492188    
2018-11-01 11:18:51,550 - Test: [   30/   39]    Loss 0.583765    Top1 90.690104    Top5 99.570312    
2018-11-01 11:18:51,642 - Test: [   40/   39]    Loss 0.580270    Top1 90.710000    Top5 99.560000    
2018-11-01 11:18:51,667 - ==> Top1: 90.710    Top5: 99.560    Loss: 0.580

2018-11-01 11:18:51,668 - Testing sensitivity of module.layer1.0.conv2.weight [55.0% sparsity]
2018-11-01 11:18:51,671 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 11:18:51,672 - --- test ---------------------
2018-11-01 11:18:51,672 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:52,082 - Test: [   10/   39]    Loss 0.592563    Top1 90.390625    Top5 99.570312    
2018-11-01 11:18:52,185 - Test: [   20/   39]    Loss 0.591840    Top1 90.644531    Top5 99.492188    
2018-11-01 11:18:52,284 - Test: [   30/   39]    Loss 0.583765    Top1 90.690104    Top5 99.570312    
2018-11-01 11:18:52,375 - Test: [   40/   39]    Loss 0.580270    Top1 90.710000    Top5 99.560000    
2018-11-01 11:18:52,400 - ==> Top1: 90.710    Top5: 99.560    Loss: 0.580

2018-11-01 11:18:52,400 - Testing sensitivity of module.layer1.0.conv2.weight [60.0% sparsity]
2018-11-01 11:18:52,402 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 11:18:52,403 - --- test ---------------------
2018-11-01 11:18:52,403 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:52,811 - Test: [   10/   39]    Loss 0.603156    Top1 90.507812    Top5 99.492188    
2018-11-01 11:18:52,916 - Test: [   20/   39]    Loss 0.601819    Top1 90.644531    Top5 99.472656    
2018-11-01 11:18:53,019 - Test: [   30/   39]    Loss 0.594012    Top1 90.703125    Top5 99.557292    
2018-11-01 11:18:53,112 - Test: [   40/   39]    Loss 0.588821    Top1 90.720000    Top5 99.550000    
2018-11-01 11:18:53,137 - ==> Top1: 90.720    Top5: 99.550    Loss: 0.589

2018-11-01 11:18:53,137 - Testing sensitivity of module.layer1.0.conv2.weight [65.0% sparsity]
2018-11-01 11:18:53,140 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 11:18:53,141 - --- test ---------------------
2018-11-01 11:18:53,141 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:53,558 - Test: [   10/   39]    Loss 0.612963    Top1 89.765625    Top5 99.570312    
2018-11-01 11:18:53,661 - Test: [   20/   39]    Loss 0.609848    Top1 90.117188    Top5 99.511719    
2018-11-01 11:18:53,761 - Test: [   30/   39]    Loss 0.607250    Top1 90.169271    Top5 99.557292    
2018-11-01 11:18:53,852 - Test: [   40/   39]    Loss 0.600315    Top1 90.250000    Top5 99.540000    
2018-11-01 11:18:53,876 - ==> Top1: 90.250    Top5: 99.540    Loss: 0.600

2018-11-01 11:18:53,877 - Testing sensitivity of module.layer1.0.conv2.weight [70.0% sparsity]
2018-11-01 11:18:53,880 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 11:18:53,880 - --- test ---------------------
2018-11-01 11:18:53,881 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:54,290 - Test: [   10/   39]    Loss 0.675641    Top1 89.179688    Top5 99.453125    
2018-11-01 11:18:54,394 - Test: [   20/   39]    Loss 0.659283    Top1 89.414062    Top5 99.394531    
2018-11-01 11:18:54,493 - Test: [   30/   39]    Loss 0.659479    Top1 89.375000    Top5 99.427083    
2018-11-01 11:18:54,584 - Test: [   40/   39]    Loss 0.645475    Top1 89.520000    Top5 99.390000    
2018-11-01 11:18:54,609 - ==> Top1: 89.520    Top5: 99.390    Loss: 0.645

2018-11-01 11:18:54,610 - Testing sensitivity of module.layer1.0.conv2.weight [75.0% sparsity]
2018-11-01 11:18:54,614 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 11:18:54,615 - --- test ---------------------
2018-11-01 11:18:54,615 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:55,033 - Test: [   10/   39]    Loss 0.719400    Top1 88.437500    Top5 99.453125    
2018-11-01 11:18:55,136 - Test: [   20/   39]    Loss 0.698976    Top1 88.476562    Top5 99.453125    
2018-11-01 11:18:55,235 - Test: [   30/   39]    Loss 0.706307    Top1 88.489583    Top5 99.466146    
2018-11-01 11:18:55,328 - Test: [   40/   39]    Loss 0.692004    Top1 88.710000    Top5 99.480000    
2018-11-01 11:18:55,353 - ==> Top1: 88.710    Top5: 99.480    Loss: 0.692

2018-11-01 11:18:55,354 - Testing sensitivity of module.layer1.0.conv2.weight [80.0% sparsity]
2018-11-01 11:18:55,357 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 11:18:55,359 - --- test ---------------------
2018-11-01 11:18:55,359 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:55,761 - Test: [   10/   39]    Loss 0.719400    Top1 88.437500    Top5 99.453125    
2018-11-01 11:18:55,870 - Test: [   20/   39]    Loss 0.698976    Top1 88.476562    Top5 99.453125    
2018-11-01 11:18:55,970 - Test: [   30/   39]    Loss 0.706307    Top1 88.489583    Top5 99.466146    
2018-11-01 11:18:56,063 - Test: [   40/   39]    Loss 0.692004    Top1 88.710000    Top5 99.480000    
2018-11-01 11:18:56,091 - ==> Top1: 88.710    Top5: 99.480    Loss: 0.692

2018-11-01 11:18:56,092 - Testing sensitivity of module.layer1.0.conv2.weight [85.0% sparsity]
2018-11-01 11:18:56,094 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 11:18:56,096 - --- test ---------------------
2018-11-01 11:18:56,096 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:56,510 - Test: [   10/   39]    Loss 0.756989    Top1 87.929688    Top5 99.531250    
2018-11-01 11:18:56,613 - Test: [   20/   39]    Loss 0.739423    Top1 88.339844    Top5 99.531250    
2018-11-01 11:18:56,712 - Test: [   30/   39]    Loss 0.744190    Top1 88.320312    Top5 99.557292    
2018-11-01 11:18:56,804 - Test: [   40/   39]    Loss 0.727282    Top1 88.480000    Top5 99.570000    
2018-11-01 11:18:56,829 - ==> Top1: 88.480    Top5: 99.570    Loss: 0.727

2018-11-01 11:18:56,830 - Testing sensitivity of module.layer1.0.conv2.weight [90.0% sparsity]
2018-11-01 11:18:56,833 - L1RankedStructureParameterPruner - param: module.layer1.0.conv2.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 11:18:56,834 - --- test ---------------------
2018-11-01 11:18:56,835 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:57,248 - Test: [   10/   39]    Loss 0.872603    Top1 86.601562    Top5 99.453125    
2018-11-01 11:18:57,350 - Test: [   20/   39]    Loss 0.847950    Top1 87.011719    Top5 99.375000    
2018-11-01 11:18:57,449 - Test: [   30/   39]    Loss 0.852738    Top1 87.122396    Top5 99.414062    
2018-11-01 11:18:57,540 - Test: [   40/   39]    Loss 0.834831    Top1 87.170000    Top5 99.430000    
2018-11-01 11:18:57,576 - ==> Top1: 87.170    Top5: 99.430    Loss: 0.835

2018-11-01 11:18:57,590 - Testing sensitivity of module.layer1.1.conv1.weight [0.0% sparsity]
2018-11-01 11:18:57,594 - --- test ---------------------
2018-11-01 11:18:57,594 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:57,978 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:58,080 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:58,180 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:58,272 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:58,297 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:58,298 - Testing sensitivity of module.layer1.1.conv1.weight [5.0% sparsity]
2018-11-01 11:18:58,300 - Too few channels (16)- can't prune 5.0% channels
2018-11-01 11:18:58,301 - --- test ---------------------
2018-11-01 11:18:58,302 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:58,709 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:58,812 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:58,911 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:59,002 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:59,027 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:59,028 - Testing sensitivity of module.layer1.1.conv1.weight [10.0% sparsity]
2018-11-01 11:18:59,031 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 11:18:59,032 - --- test ---------------------
2018-11-01 11:18:59,032 - 10000 samples (256 per mini-batch)
2018-11-01 11:18:59,451 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:18:59,553 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:18:59,652 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:18:59,743 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:18:59,767 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:18:59,768 - Testing sensitivity of module.layer1.1.conv1.weight [15.0% sparsity]
2018-11-01 11:18:59,770 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 11:18:59,771 - --- test ---------------------
2018-11-01 11:18:59,772 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:00,196 - Test: [   10/   39]    Loss 0.549375    Top1 91.484375    Top5 99.648438    
2018-11-01 11:19:00,302 - Test: [   20/   39]    Loss 0.550927    Top1 91.621094    Top5 99.550781    
2018-11-01 11:19:00,405 - Test: [   30/   39]    Loss 0.545716    Top1 91.575521    Top5 99.648438    
2018-11-01 11:19:00,500 - Test: [   40/   39]    Loss 0.540103    Top1 91.570000    Top5 99.640000    
2018-11-01 11:19:00,526 - ==> Top1: 91.570    Top5: 99.640    Loss: 0.540

2018-11-01 11:19:00,527 - Testing sensitivity of module.layer1.1.conv1.weight [20.0% sparsity]
2018-11-01 11:19:00,530 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 11:19:00,531 - --- test ---------------------
2018-11-01 11:19:00,532 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:00,958 - Test: [   10/   39]    Loss 0.550288    Top1 91.328125    Top5 99.648438    
2018-11-01 11:19:01,063 - Test: [   20/   39]    Loss 0.551785    Top1 91.425781    Top5 99.589844    
2018-11-01 11:19:01,166 - Test: [   30/   39]    Loss 0.544730    Top1 91.458333    Top5 99.674479    
2018-11-01 11:19:01,262 - Test: [   40/   39]    Loss 0.540342    Top1 91.450000    Top5 99.650000    
2018-11-01 11:19:01,288 - ==> Top1: 91.450    Top5: 99.650    Loss: 0.540

2018-11-01 11:19:01,288 - Testing sensitivity of module.layer1.1.conv1.weight [25.0% sparsity]
2018-11-01 11:19:01,292 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 11:19:01,294 - --- test ---------------------
2018-11-01 11:19:01,295 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:01,794 - Test: [   10/   39]    Loss 0.551470    Top1 91.484375    Top5 99.648438    
2018-11-01 11:19:01,905 - Test: [   20/   39]    Loss 0.553116    Top1 91.523438    Top5 99.570312    
2018-11-01 11:19:02,013 - Test: [   30/   39]    Loss 0.546015    Top1 91.575521    Top5 99.661458    
2018-11-01 11:19:02,113 - Test: [   40/   39]    Loss 0.541949    Top1 91.550000    Top5 99.640000    
2018-11-01 11:19:02,147 - ==> Top1: 91.550    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:02,148 - Testing sensitivity of module.layer1.1.conv1.weight [30.0% sparsity]
2018-11-01 11:19:02,151 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 11:19:02,152 - --- test ---------------------
2018-11-01 11:19:02,153 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:02,608 - Test: [   10/   39]    Loss 0.551470    Top1 91.484375    Top5 99.648438    
2018-11-01 11:19:02,715 - Test: [   20/   39]    Loss 0.553116    Top1 91.523438    Top5 99.570312    
2018-11-01 11:19:02,822 - Test: [   30/   39]    Loss 0.546015    Top1 91.575521    Top5 99.661458    
2018-11-01 11:19:02,920 - Test: [   40/   39]    Loss 0.541949    Top1 91.550000    Top5 99.640000    
2018-11-01 11:19:02,959 - ==> Top1: 91.550    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:02,959 - Testing sensitivity of module.layer1.1.conv1.weight [35.0% sparsity]
2018-11-01 11:19:02,961 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 11:19:02,962 - --- test ---------------------
2018-11-01 11:19:02,962 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:03,396 - Test: [   10/   39]    Loss 0.558059    Top1 91.093750    Top5 99.570312    
2018-11-01 11:19:03,503 - Test: [   20/   39]    Loss 0.556033    Top1 91.269531    Top5 99.550781    
2018-11-01 11:19:03,607 - Test: [   30/   39]    Loss 0.549020    Top1 91.250000    Top5 99.648438    
2018-11-01 11:19:03,703 - Test: [   40/   39]    Loss 0.542594    Top1 91.320000    Top5 99.620000    
2018-11-01 11:19:03,728 - ==> Top1: 91.320    Top5: 99.620    Loss: 0.543

2018-11-01 11:19:03,729 - Testing sensitivity of module.layer1.1.conv1.weight [40.0% sparsity]
2018-11-01 11:19:03,731 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 11:19:03,733 - --- test ---------------------
2018-11-01 11:19:03,733 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:04,171 - Test: [   10/   39]    Loss 0.552743    Top1 91.054688    Top5 99.648438    
2018-11-01 11:19:04,281 - Test: [   20/   39]    Loss 0.556546    Top1 91.191406    Top5 99.589844    
2018-11-01 11:19:04,385 - Test: [   30/   39]    Loss 0.550463    Top1 91.106771    Top5 99.674479    
2018-11-01 11:19:04,482 - Test: [   40/   39]    Loss 0.544054    Top1 91.140000    Top5 99.660000    
2018-11-01 11:19:04,508 - ==> Top1: 91.140    Top5: 99.660    Loss: 0.544

2018-11-01 11:19:04,509 - Testing sensitivity of module.layer1.1.conv1.weight [45.0% sparsity]
2018-11-01 11:19:04,511 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 11:19:04,512 - --- test ---------------------
2018-11-01 11:19:04,512 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:04,961 - Test: [   10/   39]    Loss 0.550657    Top1 91.054688    Top5 99.609375    
2018-11-01 11:19:05,066 - Test: [   20/   39]    Loss 0.558103    Top1 91.132812    Top5 99.570312    
2018-11-01 11:19:05,171 - Test: [   30/   39]    Loss 0.551079    Top1 91.093750    Top5 99.661458    
2018-11-01 11:19:05,267 - Test: [   40/   39]    Loss 0.544751    Top1 91.160000    Top5 99.640000    
2018-11-01 11:19:05,303 - ==> Top1: 91.160    Top5: 99.640    Loss: 0.545

2018-11-01 11:19:05,304 - Testing sensitivity of module.layer1.1.conv1.weight [50.0% sparsity]
2018-11-01 11:19:05,307 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 11:19:05,307 - --- test ---------------------
2018-11-01 11:19:05,307 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:05,752 - Test: [   10/   39]    Loss 0.561049    Top1 90.976562    Top5 99.648438    
2018-11-01 11:19:05,858 - Test: [   20/   39]    Loss 0.564141    Top1 91.015625    Top5 99.609375    
2018-11-01 11:19:05,962 - Test: [   30/   39]    Loss 0.555063    Top1 90.989583    Top5 99.687500    
2018-11-01 11:19:06,059 - Test: [   40/   39]    Loss 0.548268    Top1 91.090000    Top5 99.660000    
2018-11-01 11:19:06,088 - ==> Top1: 91.090    Top5: 99.660    Loss: 0.548

2018-11-01 11:19:06,089 - Testing sensitivity of module.layer1.1.conv1.weight [55.0% sparsity]
2018-11-01 11:19:06,091 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 11:19:06,093 - --- test ---------------------
2018-11-01 11:19:06,093 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:06,541 - Test: [   10/   39]    Loss 0.561049    Top1 90.976562    Top5 99.648438    
2018-11-01 11:19:06,651 - Test: [   20/   39]    Loss 0.564141    Top1 91.015625    Top5 99.609375    
2018-11-01 11:19:06,755 - Test: [   30/   39]    Loss 0.555063    Top1 90.989583    Top5 99.687500    
2018-11-01 11:19:06,852 - Test: [   40/   39]    Loss 0.548268    Top1 91.090000    Top5 99.660000    
2018-11-01 11:19:06,877 - ==> Top1: 91.090    Top5: 99.660    Loss: 0.548

2018-11-01 11:19:06,878 - Testing sensitivity of module.layer1.1.conv1.weight [60.0% sparsity]
2018-11-01 11:19:06,880 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 11:19:06,881 - --- test ---------------------
2018-11-01 11:19:06,882 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:07,327 - Test: [   10/   39]    Loss 0.561166    Top1 90.898438    Top5 99.570312    
2018-11-01 11:19:07,433 - Test: [   20/   39]    Loss 0.564364    Top1 90.976562    Top5 99.570312    
2018-11-01 11:19:07,536 - Test: [   30/   39]    Loss 0.555376    Top1 90.950521    Top5 99.661458    
2018-11-01 11:19:07,632 - Test: [   40/   39]    Loss 0.548151    Top1 91.050000    Top5 99.650000    
2018-11-01 11:19:07,663 - ==> Top1: 91.050    Top5: 99.650    Loss: 0.548

2018-11-01 11:19:07,664 - Testing sensitivity of module.layer1.1.conv1.weight [65.0% sparsity]
2018-11-01 11:19:07,667 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 11:19:07,668 - --- test ---------------------
2018-11-01 11:19:07,669 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:08,114 - Test: [   10/   39]    Loss 0.619501    Top1 89.960938    Top5 99.648438    
2018-11-01 11:19:08,221 - Test: [   20/   39]    Loss 0.608761    Top1 90.390625    Top5 99.609375    
2018-11-01 11:19:08,325 - Test: [   30/   39]    Loss 0.595377    Top1 90.260417    Top5 99.687500    
2018-11-01 11:19:08,421 - Test: [   40/   39]    Loss 0.579289    Top1 90.440000    Top5 99.670000    
2018-11-01 11:19:08,451 - ==> Top1: 90.440    Top5: 99.670    Loss: 0.579

2018-11-01 11:19:08,451 - Testing sensitivity of module.layer1.1.conv1.weight [70.0% sparsity]
2018-11-01 11:19:08,456 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 11:19:08,457 - --- test ---------------------
2018-11-01 11:19:08,458 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:08,894 - Test: [   10/   39]    Loss 0.653789    Top1 89.375000    Top5 99.687500    
2018-11-01 11:19:09,001 - Test: [   20/   39]    Loss 0.633340    Top1 89.824219    Top5 99.628906    
2018-11-01 11:19:09,106 - Test: [   30/   39]    Loss 0.616403    Top1 89.765625    Top5 99.700521    
2018-11-01 11:19:09,202 - Test: [   40/   39]    Loss 0.601146    Top1 89.970000    Top5 99.670000    
2018-11-01 11:19:09,227 - ==> Top1: 89.970    Top5: 99.670    Loss: 0.601

2018-11-01 11:19:09,228 - Testing sensitivity of module.layer1.1.conv1.weight [75.0% sparsity]
2018-11-01 11:19:09,231 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 11:19:09,233 - --- test ---------------------
2018-11-01 11:19:09,233 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:09,667 - Test: [   10/   39]    Loss 0.670809    Top1 88.984375    Top5 99.609375    
2018-11-01 11:19:09,774 - Test: [   20/   39]    Loss 0.646282    Top1 89.550781    Top5 99.609375    
2018-11-01 11:19:09,879 - Test: [   30/   39]    Loss 0.628881    Top1 89.570312    Top5 99.687500    
2018-11-01 11:19:09,976 - Test: [   40/   39]    Loss 0.613574    Top1 89.860000    Top5 99.650000    
2018-11-01 11:19:10,002 - ==> Top1: 89.860    Top5: 99.650    Loss: 0.614

2018-11-01 11:19:10,002 - Testing sensitivity of module.layer1.1.conv1.weight [80.0% sparsity]
2018-11-01 11:19:10,005 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 11:19:10,007 - --- test ---------------------
2018-11-01 11:19:10,007 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:10,447 - Test: [   10/   39]    Loss 0.670809    Top1 88.984375    Top5 99.609375    
2018-11-01 11:19:10,555 - Test: [   20/   39]    Loss 0.646282    Top1 89.550781    Top5 99.609375    
2018-11-01 11:19:10,660 - Test: [   30/   39]    Loss 0.628881    Top1 89.570312    Top5 99.687500    
2018-11-01 11:19:10,756 - Test: [   40/   39]    Loss 0.613574    Top1 89.860000    Top5 99.650000    
2018-11-01 11:19:10,780 - ==> Top1: 89.860    Top5: 99.650    Loss: 0.614

2018-11-01 11:19:10,782 - Testing sensitivity of module.layer1.1.conv1.weight [85.0% sparsity]
2018-11-01 11:19:10,785 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 11:19:10,786 - --- test ---------------------
2018-11-01 11:19:10,786 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:11,222 - Test: [   10/   39]    Loss 0.688547    Top1 89.023438    Top5 99.453125    
2018-11-01 11:19:11,328 - Test: [   20/   39]    Loss 0.676945    Top1 89.453125    Top5 99.453125    
2018-11-01 11:19:11,432 - Test: [   30/   39]    Loss 0.668799    Top1 89.388021    Top5 99.557292    
2018-11-01 11:19:11,528 - Test: [   40/   39]    Loss 0.647856    Top1 89.430000    Top5 99.540000    
2018-11-01 11:19:11,568 - ==> Top1: 89.430    Top5: 99.540    Loss: 0.648

2018-11-01 11:19:11,569 - Testing sensitivity of module.layer1.1.conv1.weight [90.0% sparsity]
2018-11-01 11:19:11,571 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 11:19:11,572 - --- test ---------------------
2018-11-01 11:19:11,572 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:12,005 - Test: [   10/   39]    Loss 0.843922    Top1 86.679688    Top5 99.101562    
2018-11-01 11:19:12,112 - Test: [   20/   39]    Loss 0.807419    Top1 87.363281    Top5 99.179688    
2018-11-01 11:19:12,216 - Test: [   30/   39]    Loss 0.810563    Top1 86.796875    Top5 99.244792    
2018-11-01 11:19:12,312 - Test: [   40/   39]    Loss 0.784243    Top1 86.940000    Top5 99.240000    
2018-11-01 11:19:12,337 - ==> Top1: 86.940    Top5: 99.240    Loss: 0.784

2018-11-01 11:19:12,348 - Testing sensitivity of module.layer1.1.conv2.weight [0.0% sparsity]
2018-11-01 11:19:12,351 - --- test ---------------------
2018-11-01 11:19:12,351 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:12,773 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:12,882 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:12,987 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:13,084 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:13,109 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:13,109 - Testing sensitivity of module.layer1.1.conv2.weight [5.0% sparsity]
2018-11-01 11:19:13,112 - Too few channels (16)- can't prune 5.0% channels
2018-11-01 11:19:13,113 - --- test ---------------------
2018-11-01 11:19:13,113 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:13,547 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:13,655 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:13,759 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:13,855 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:13,884 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:13,884 - Testing sensitivity of module.layer1.1.conv2.weight [10.0% sparsity]
2018-11-01 11:19:13,887 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 11:19:13,888 - --- test ---------------------
2018-11-01 11:19:13,888 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:14,320 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:14,428 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:14,533 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:14,628 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:14,654 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:14,657 - Testing sensitivity of module.layer1.1.conv2.weight [15.0% sparsity]
2018-11-01 11:19:14,660 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 11:19:14,663 - --- test ---------------------
2018-11-01 11:19:14,663 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:15,080 - Test: [   10/   39]    Loss 0.551573    Top1 91.289062    Top5 99.570312    
2018-11-01 11:19:15,188 - Test: [   20/   39]    Loss 0.555817    Top1 91.425781    Top5 99.472656    
2018-11-01 11:19:15,292 - Test: [   30/   39]    Loss 0.548238    Top1 91.497396    Top5 99.583333    
2018-11-01 11:19:15,388 - Test: [   40/   39]    Loss 0.545380    Top1 91.490000    Top5 99.590000    
2018-11-01 11:19:15,413 - ==> Top1: 91.490    Top5: 99.590    Loss: 0.545

2018-11-01 11:19:15,414 - Testing sensitivity of module.layer1.1.conv2.weight [20.0% sparsity]
2018-11-01 11:19:15,417 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 11:19:15,418 - --- test ---------------------
2018-11-01 11:19:15,418 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:15,871 - Test: [   10/   39]    Loss 0.549978    Top1 91.250000    Top5 99.609375    
2018-11-01 11:19:15,981 - Test: [   20/   39]    Loss 0.554864    Top1 91.367188    Top5 99.511719    
2018-11-01 11:19:16,086 - Test: [   30/   39]    Loss 0.547917    Top1 91.497396    Top5 99.609375    
2018-11-01 11:19:16,183 - Test: [   40/   39]    Loss 0.545077    Top1 91.480000    Top5 99.590000    
2018-11-01 11:19:16,208 - ==> Top1: 91.480    Top5: 99.590    Loss: 0.545

2018-11-01 11:19:16,209 - Testing sensitivity of module.layer1.1.conv2.weight [25.0% sparsity]
2018-11-01 11:19:16,211 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 11:19:16,213 - --- test ---------------------
2018-11-01 11:19:16,213 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:16,657 - Test: [   10/   39]    Loss 0.564236    Top1 90.546875    Top5 99.609375    
2018-11-01 11:19:16,763 - Test: [   20/   39]    Loss 0.568497    Top1 90.898438    Top5 99.570312    
2018-11-01 11:19:16,867 - Test: [   30/   39]    Loss 0.558435    Top1 91.015625    Top5 99.661458    
2018-11-01 11:19:16,962 - Test: [   40/   39]    Loss 0.553454    Top1 91.100000    Top5 99.650000    
2018-11-01 11:19:16,987 - ==> Top1: 91.100    Top5: 99.650    Loss: 0.553

2018-11-01 11:19:16,989 - Testing sensitivity of module.layer1.1.conv2.weight [30.0% sparsity]
2018-11-01 11:19:16,991 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 11:19:16,992 - --- test ---------------------
2018-11-01 11:19:16,992 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:17,422 - Test: [   10/   39]    Loss 0.564236    Top1 90.546875    Top5 99.609375    
2018-11-01 11:19:17,529 - Test: [   20/   39]    Loss 0.568497    Top1 90.898438    Top5 99.570312    
2018-11-01 11:19:17,632 - Test: [   30/   39]    Loss 0.558435    Top1 91.015625    Top5 99.661458    
2018-11-01 11:19:17,727 - Test: [   40/   39]    Loss 0.553454    Top1 91.100000    Top5 99.650000    
2018-11-01 11:19:17,752 - ==> Top1: 91.100    Top5: 99.650    Loss: 0.553

2018-11-01 11:19:17,753 - Testing sensitivity of module.layer1.1.conv2.weight [35.0% sparsity]
2018-11-01 11:19:17,755 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 11:19:17,757 - --- test ---------------------
2018-11-01 11:19:17,757 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:18,193 - Test: [   10/   39]    Loss 0.651714    Top1 89.609375    Top5 99.648438    
2018-11-01 11:19:18,299 - Test: [   20/   39]    Loss 0.629677    Top1 90.175781    Top5 99.589844    
2018-11-01 11:19:18,406 - Test: [   30/   39]    Loss 0.604682    Top1 90.390625    Top5 99.661458    
2018-11-01 11:19:18,503 - Test: [   40/   39]    Loss 0.594059    Top1 90.340000    Top5 99.690000    
2018-11-01 11:19:18,528 - ==> Top1: 90.340    Top5: 99.690    Loss: 0.594

2018-11-01 11:19:18,529 - Testing sensitivity of module.layer1.1.conv2.weight [40.0% sparsity]
2018-11-01 11:19:18,531 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 11:19:18,532 - --- test ---------------------
2018-11-01 11:19:18,532 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:18,972 - Test: [   10/   39]    Loss 0.649311    Top1 89.765625    Top5 99.726562    
2018-11-01 11:19:19,084 - Test: [   20/   39]    Loss 0.628565    Top1 90.156250    Top5 99.628906    
2018-11-01 11:19:19,190 - Test: [   30/   39]    Loss 0.604861    Top1 90.325521    Top5 99.687500    
2018-11-01 11:19:19,290 - Test: [   40/   39]    Loss 0.594123    Top1 90.350000    Top5 99.710000    
2018-11-01 11:19:19,318 - ==> Top1: 90.350    Top5: 99.710    Loss: 0.594

2018-11-01 11:19:19,319 - Testing sensitivity of module.layer1.1.conv2.weight [45.0% sparsity]
2018-11-01 11:19:19,323 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 11:19:19,324 - --- test ---------------------
2018-11-01 11:19:19,324 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:19,760 - Test: [   10/   39]    Loss 0.623735    Top1 89.843750    Top5 99.687500    
2018-11-01 11:19:19,868 - Test: [   20/   39]    Loss 0.609112    Top1 90.253906    Top5 99.609375    
2018-11-01 11:19:19,973 - Test: [   30/   39]    Loss 0.587725    Top1 90.481771    Top5 99.661458    
2018-11-01 11:19:20,071 - Test: [   40/   39]    Loss 0.579948    Top1 90.460000    Top5 99.670000    
2018-11-01 11:19:20,096 - ==> Top1: 90.460    Top5: 99.670    Loss: 0.580

2018-11-01 11:19:20,097 - Testing sensitivity of module.layer1.1.conv2.weight [50.0% sparsity]
2018-11-01 11:19:20,099 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 11:19:20,100 - --- test ---------------------
2018-11-01 11:19:20,100 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:20,552 - Test: [   10/   39]    Loss 0.620234    Top1 89.765625    Top5 99.687500    
2018-11-01 11:19:20,658 - Test: [   20/   39]    Loss 0.610510    Top1 90.058594    Top5 99.570312    
2018-11-01 11:19:20,762 - Test: [   30/   39]    Loss 0.588224    Top1 90.286458    Top5 99.609375    
2018-11-01 11:19:20,857 - Test: [   40/   39]    Loss 0.580402    Top1 90.320000    Top5 99.630000    
2018-11-01 11:19:20,881 - ==> Top1: 90.320    Top5: 99.630    Loss: 0.580

2018-11-01 11:19:20,884 - Testing sensitivity of module.layer1.1.conv2.weight [55.0% sparsity]
2018-11-01 11:19:20,886 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 11:19:20,887 - --- test ---------------------
2018-11-01 11:19:20,888 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:21,318 - Test: [   10/   39]    Loss 0.620234    Top1 89.765625    Top5 99.687500    
2018-11-01 11:19:21,428 - Test: [   20/   39]    Loss 0.610510    Top1 90.058594    Top5 99.570312    
2018-11-01 11:19:21,534 - Test: [   30/   39]    Loss 0.588224    Top1 90.286458    Top5 99.609375    
2018-11-01 11:19:21,632 - Test: [   40/   39]    Loss 0.580402    Top1 90.320000    Top5 99.630000    
2018-11-01 11:19:21,689 - ==> Top1: 90.320    Top5: 99.630    Loss: 0.580

2018-11-01 11:19:21,690 - Testing sensitivity of module.layer1.1.conv2.weight [60.0% sparsity]
2018-11-01 11:19:21,698 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 11:19:21,699 - --- test ---------------------
2018-11-01 11:19:21,700 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:22,134 - Test: [   10/   39]    Loss 0.632652    Top1 89.726562    Top5 99.687500    
2018-11-01 11:19:22,241 - Test: [   20/   39]    Loss 0.621446    Top1 89.902344    Top5 99.589844    
2018-11-01 11:19:22,346 - Test: [   30/   39]    Loss 0.596815    Top1 90.156250    Top5 99.622396    
2018-11-01 11:19:22,443 - Test: [   40/   39]    Loss 0.586935    Top1 90.240000    Top5 99.620000    
2018-11-01 11:19:22,473 - ==> Top1: 90.240    Top5: 99.620    Loss: 0.587

2018-11-01 11:19:22,473 - Testing sensitivity of module.layer1.1.conv2.weight [65.0% sparsity]
2018-11-01 11:19:22,478 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 11:19:22,479 - --- test ---------------------
2018-11-01 11:19:22,479 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:22,948 - Test: [   10/   39]    Loss 0.632148    Top1 89.726562    Top5 99.609375    
2018-11-01 11:19:23,058 - Test: [   20/   39]    Loss 0.623205    Top1 89.882812    Top5 99.570312    
2018-11-01 11:19:23,166 - Test: [   30/   39]    Loss 0.597776    Top1 90.156250    Top5 99.596354    
2018-11-01 11:19:23,264 - Test: [   40/   39]    Loss 0.590612    Top1 90.200000    Top5 99.620000    
2018-11-01 11:19:23,305 - ==> Top1: 90.200    Top5: 99.620    Loss: 0.591

2018-11-01 11:19:23,305 - Testing sensitivity of module.layer1.1.conv2.weight [70.0% sparsity]
2018-11-01 11:19:23,308 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 11:19:23,310 - --- test ---------------------
2018-11-01 11:19:23,310 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:23,795 - Test: [   10/   39]    Loss 0.632861    Top1 89.570312    Top5 99.609375    
2018-11-01 11:19:23,905 - Test: [   20/   39]    Loss 0.621660    Top1 89.785156    Top5 99.589844    
2018-11-01 11:19:24,011 - Test: [   30/   39]    Loss 0.596037    Top1 90.065104    Top5 99.609375    
2018-11-01 11:19:24,110 - Test: [   40/   39]    Loss 0.589106    Top1 90.080000    Top5 99.620000    
2018-11-01 11:19:24,144 - ==> Top1: 90.080    Top5: 99.620    Loss: 0.589

2018-11-01 11:19:24,145 - Testing sensitivity of module.layer1.1.conv2.weight [75.0% sparsity]
2018-11-01 11:19:24,148 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 11:19:24,149 - --- test ---------------------
2018-11-01 11:19:24,150 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:24,607 - Test: [   10/   39]    Loss 0.631063    Top1 89.687500    Top5 99.609375    
2018-11-01 11:19:24,714 - Test: [   20/   39]    Loss 0.621291    Top1 89.902344    Top5 99.589844    
2018-11-01 11:19:24,817 - Test: [   30/   39]    Loss 0.597935    Top1 90.104167    Top5 99.609375    
2018-11-01 11:19:24,915 - Test: [   40/   39]    Loss 0.589921    Top1 90.110000    Top5 99.620000    
2018-11-01 11:19:24,944 - ==> Top1: 90.110    Top5: 99.620    Loss: 0.590

2018-11-01 11:19:24,944 - Testing sensitivity of module.layer1.1.conv2.weight [80.0% sparsity]
2018-11-01 11:19:24,948 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 11:19:24,949 - --- test ---------------------
2018-11-01 11:19:24,950 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:25,426 - Test: [   10/   39]    Loss 0.631063    Top1 89.687500    Top5 99.609375    
2018-11-01 11:19:25,537 - Test: [   20/   39]    Loss 0.621291    Top1 89.902344    Top5 99.589844    
2018-11-01 11:19:25,644 - Test: [   30/   39]    Loss 0.597935    Top1 90.104167    Top5 99.609375    
2018-11-01 11:19:25,742 - Test: [   40/   39]    Loss 0.589921    Top1 90.110000    Top5 99.620000    
2018-11-01 11:19:25,780 - ==> Top1: 90.110    Top5: 99.620    Loss: 0.590

2018-11-01 11:19:25,781 - Testing sensitivity of module.layer1.1.conv2.weight [85.0% sparsity]
2018-11-01 11:19:25,783 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 11:19:25,785 - --- test ---------------------
2018-11-01 11:19:25,785 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:26,244 - Test: [   10/   39]    Loss 0.712852    Top1 88.476562    Top5 99.609375    
2018-11-01 11:19:26,356 - Test: [   20/   39]    Loss 0.696397    Top1 88.984375    Top5 99.511719    
2018-11-01 11:19:26,463 - Test: [   30/   39]    Loss 0.679156    Top1 89.010417    Top5 99.518229    
2018-11-01 11:19:26,561 - Test: [   40/   39]    Loss 0.669252    Top1 89.050000    Top5 99.550000    
2018-11-01 11:19:26,600 - ==> Top1: 89.050    Top5: 99.550    Loss: 0.669

2018-11-01 11:19:26,601 - Testing sensitivity of module.layer1.1.conv2.weight [90.0% sparsity]
2018-11-01 11:19:26,605 - L1RankedStructureParameterPruner - param: module.layer1.1.conv2.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 11:19:26,606 - --- test ---------------------
2018-11-01 11:19:26,607 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:27,081 - Test: [   10/   39]    Loss 0.797429    Top1 87.226562    Top5 99.375000    
2018-11-01 11:19:27,190 - Test: [   20/   39]    Loss 0.791517    Top1 87.226562    Top5 99.355469    
2018-11-01 11:19:27,298 - Test: [   30/   39]    Loss 0.788012    Top1 87.213542    Top5 99.257812    
2018-11-01 11:19:27,396 - Test: [   40/   39]    Loss 0.783081    Top1 87.320000    Top5 99.300000    
2018-11-01 11:19:27,434 - ==> Top1: 87.320    Top5: 99.300    Loss: 0.783

2018-11-01 11:19:27,453 - Testing sensitivity of module.layer1.2.conv1.weight [0.0% sparsity]
2018-11-01 11:19:27,456 - --- test ---------------------
2018-11-01 11:19:27,456 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:27,857 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:27,967 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:28,074 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:28,172 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:28,205 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:28,206 - Testing sensitivity of module.layer1.2.conv1.weight [5.0% sparsity]
2018-11-01 11:19:28,209 - Too few channels (16)- can't prune 5.0% channels
2018-11-01 11:19:28,210 - --- test ---------------------
2018-11-01 11:19:28,210 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:28,706 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:28,816 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:28,924 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:29,023 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:29,067 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:29,068 - Testing sensitivity of module.layer1.2.conv1.weight [10.0% sparsity]
2018-11-01 11:19:29,071 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 11:19:29,072 - --- test ---------------------
2018-11-01 11:19:29,072 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:29,528 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:29,638 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:29,742 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:29,837 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:29,862 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:29,862 - Testing sensitivity of module.layer1.2.conv1.weight [15.0% sparsity]
2018-11-01 11:19:29,865 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 11:19:29,866 - --- test ---------------------
2018-11-01 11:19:29,866 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:30,314 - Test: [   10/   39]    Loss 0.553020    Top1 91.250000    Top5 99.648438    
2018-11-01 11:19:30,425 - Test: [   20/   39]    Loss 0.551085    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:30,532 - Test: [   30/   39]    Loss 0.545359    Top1 91.432292    Top5 99.661458    
2018-11-01 11:19:30,630 - Test: [   40/   39]    Loss 0.540656    Top1 91.460000    Top5 99.650000    
2018-11-01 11:19:30,663 - ==> Top1: 91.460    Top5: 99.650    Loss: 0.541

2018-11-01 11:19:30,663 - Testing sensitivity of module.layer1.2.conv1.weight [20.0% sparsity]
2018-11-01 11:19:30,666 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 11:19:30,667 - --- test ---------------------
2018-11-01 11:19:30,668 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:31,132 - Test: [   10/   39]    Loss 0.553412    Top1 91.328125    Top5 99.609375    
2018-11-01 11:19:31,241 - Test: [   20/   39]    Loss 0.556216    Top1 91.425781    Top5 99.531250    
2018-11-01 11:19:31,348 - Test: [   30/   39]    Loss 0.551825    Top1 91.302083    Top5 99.635417    
2018-11-01 11:19:31,447 - Test: [   40/   39]    Loss 0.544255    Top1 91.340000    Top5 99.640000    
2018-11-01 11:19:31,481 - ==> Top1: 91.340    Top5: 99.640    Loss: 0.544

2018-11-01 11:19:31,481 - Testing sensitivity of module.layer1.2.conv1.weight [25.0% sparsity]
2018-11-01 11:19:31,484 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 11:19:31,486 - --- test ---------------------
2018-11-01 11:19:31,486 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:31,933 - Test: [   10/   39]    Loss 0.554679    Top1 91.132812    Top5 99.570312    
2018-11-01 11:19:32,044 - Test: [   20/   39]    Loss 0.553179    Top1 91.308594    Top5 99.511719    
2018-11-01 11:19:32,153 - Test: [   30/   39]    Loss 0.551067    Top1 91.184896    Top5 99.622396    
2018-11-01 11:19:32,251 - Test: [   40/   39]    Loss 0.545245    Top1 91.240000    Top5 99.600000    
2018-11-01 11:19:32,286 - ==> Top1: 91.240    Top5: 99.600    Loss: 0.545

2018-11-01 11:19:32,286 - Testing sensitivity of module.layer1.2.conv1.weight [30.0% sparsity]
2018-11-01 11:19:32,289 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 11:19:32,290 - --- test ---------------------
2018-11-01 11:19:32,290 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:32,717 - Test: [   10/   39]    Loss 0.554679    Top1 91.132812    Top5 99.570312    
2018-11-01 11:19:32,824 - Test: [   20/   39]    Loss 0.553179    Top1 91.308594    Top5 99.511719    
2018-11-01 11:19:32,927 - Test: [   30/   39]    Loss 0.551067    Top1 91.184896    Top5 99.622396    
2018-11-01 11:19:33,021 - Test: [   40/   39]    Loss 0.545245    Top1 91.240000    Top5 99.600000    
2018-11-01 11:19:33,047 - ==> Top1: 91.240    Top5: 99.600    Loss: 0.545

2018-11-01 11:19:33,048 - Testing sensitivity of module.layer1.2.conv1.weight [35.0% sparsity]
2018-11-01 11:19:33,051 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 11:19:33,052 - --- test ---------------------
2018-11-01 11:19:33,053 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:33,469 - Test: [   10/   39]    Loss 0.559582    Top1 90.937500    Top5 99.531250    
2018-11-01 11:19:33,574 - Test: [   20/   39]    Loss 0.556590    Top1 91.093750    Top5 99.472656    
2018-11-01 11:19:33,677 - Test: [   30/   39]    Loss 0.552974    Top1 90.976562    Top5 99.596354    
2018-11-01 11:19:33,771 - Test: [   40/   39]    Loss 0.547435    Top1 91.050000    Top5 99.590000    
2018-11-01 11:19:33,798 - ==> Top1: 91.050    Top5: 99.590    Loss: 0.547

2018-11-01 11:19:33,800 - Testing sensitivity of module.layer1.2.conv1.weight [40.0% sparsity]
2018-11-01 11:19:33,803 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 11:19:33,804 - --- test ---------------------
2018-11-01 11:19:33,804 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:34,223 - Test: [   10/   39]    Loss 0.569541    Top1 90.664062    Top5 99.531250    
2018-11-01 11:19:34,330 - Test: [   20/   39]    Loss 0.564446    Top1 90.917969    Top5 99.511719    
2018-11-01 11:19:34,432 - Test: [   30/   39]    Loss 0.560113    Top1 90.703125    Top5 99.609375    
2018-11-01 11:19:34,528 - Test: [   40/   39]    Loss 0.552844    Top1 90.790000    Top5 99.580000    
2018-11-01 11:19:34,553 - ==> Top1: 90.790    Top5: 99.580    Loss: 0.553

2018-11-01 11:19:34,554 - Testing sensitivity of module.layer1.2.conv1.weight [45.0% sparsity]
2018-11-01 11:19:34,556 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 11:19:34,557 - --- test ---------------------
2018-11-01 11:19:34,557 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:34,995 - Test: [   10/   39]    Loss 0.574212    Top1 90.820312    Top5 99.531250    
2018-11-01 11:19:35,102 - Test: [   20/   39]    Loss 0.571291    Top1 90.976562    Top5 99.511719    
2018-11-01 11:19:35,207 - Test: [   30/   39]    Loss 0.569274    Top1 90.781250    Top5 99.596354    
2018-11-01 11:19:35,303 - Test: [   40/   39]    Loss 0.563128    Top1 90.810000    Top5 99.600000    
2018-11-01 11:19:35,332 - ==> Top1: 90.810    Top5: 99.600    Loss: 0.563

2018-11-01 11:19:35,333 - Testing sensitivity of module.layer1.2.conv1.weight [50.0% sparsity]
2018-11-01 11:19:35,336 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 11:19:35,337 - --- test ---------------------
2018-11-01 11:19:35,337 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:35,763 - Test: [   10/   39]    Loss 0.572018    Top1 90.703125    Top5 99.531250    
2018-11-01 11:19:35,871 - Test: [   20/   39]    Loss 0.572175    Top1 90.976562    Top5 99.511719    
2018-11-01 11:19:35,975 - Test: [   30/   39]    Loss 0.569026    Top1 90.846354    Top5 99.609375    
2018-11-01 11:19:36,072 - Test: [   40/   39]    Loss 0.562049    Top1 90.870000    Top5 99.620000    
2018-11-01 11:19:36,104 - ==> Top1: 90.870    Top5: 99.620    Loss: 0.562

2018-11-01 11:19:36,105 - Testing sensitivity of module.layer1.2.conv1.weight [55.0% sparsity]
2018-11-01 11:19:36,107 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 11:19:36,107 - --- test ---------------------
2018-11-01 11:19:36,108 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:36,552 - Test: [   10/   39]    Loss 0.572018    Top1 90.703125    Top5 99.531250    
2018-11-01 11:19:36,658 - Test: [   20/   39]    Loss 0.572175    Top1 90.976562    Top5 99.511719    
2018-11-01 11:19:36,763 - Test: [   30/   39]    Loss 0.569026    Top1 90.846354    Top5 99.609375    
2018-11-01 11:19:36,859 - Test: [   40/   39]    Loss 0.562049    Top1 90.870000    Top5 99.620000    
2018-11-01 11:19:36,892 - ==> Top1: 90.870    Top5: 99.620    Loss: 0.562

2018-11-01 11:19:36,893 - Testing sensitivity of module.layer1.2.conv1.weight [60.0% sparsity]
2018-11-01 11:19:36,897 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 11:19:36,897 - --- test ---------------------
2018-11-01 11:19:36,898 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:37,327 - Test: [   10/   39]    Loss 0.592957    Top1 90.390625    Top5 99.453125    
2018-11-01 11:19:37,434 - Test: [   20/   39]    Loss 0.595319    Top1 90.625000    Top5 99.414062    
2018-11-01 11:19:37,537 - Test: [   30/   39]    Loss 0.592039    Top1 90.546875    Top5 99.531250    
2018-11-01 11:19:37,632 - Test: [   40/   39]    Loss 0.581599    Top1 90.570000    Top5 99.550000    
2018-11-01 11:19:37,656 - ==> Top1: 90.570    Top5: 99.550    Loss: 0.582

2018-11-01 11:19:37,657 - Testing sensitivity of module.layer1.2.conv1.weight [65.0% sparsity]
2018-11-01 11:19:37,660 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 11:19:37,661 - --- test ---------------------
2018-11-01 11:19:37,661 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:38,102 - Test: [   10/   39]    Loss 0.644838    Top1 89.570312    Top5 99.375000    
2018-11-01 11:19:38,208 - Test: [   20/   39]    Loss 0.640991    Top1 89.511719    Top5 99.375000    
2018-11-01 11:19:38,313 - Test: [   30/   39]    Loss 0.637935    Top1 89.531250    Top5 99.518229    
2018-11-01 11:19:38,408 - Test: [   40/   39]    Loss 0.631194    Top1 89.740000    Top5 99.530000    
2018-11-01 11:19:38,433 - ==> Top1: 89.740    Top5: 99.530    Loss: 0.631

2018-11-01 11:19:38,433 - Testing sensitivity of module.layer1.2.conv1.weight [70.0% sparsity]
2018-11-01 11:19:38,436 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 11:19:38,437 - --- test ---------------------
2018-11-01 11:19:38,437 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:38,870 - Test: [   10/   39]    Loss 0.834739    Top1 86.562500    Top5 99.062500    
2018-11-01 11:19:38,976 - Test: [   20/   39]    Loss 0.825474    Top1 86.796875    Top5 99.062500    
2018-11-01 11:19:39,079 - Test: [   30/   39]    Loss 0.825738    Top1 86.953125    Top5 99.114583    
2018-11-01 11:19:39,175 - Test: [   40/   39]    Loss 0.810698    Top1 87.260000    Top5 99.140000    
2018-11-01 11:19:39,199 - ==> Top1: 87.260    Top5: 99.140    Loss: 0.811

2018-11-01 11:19:39,201 - Testing sensitivity of module.layer1.2.conv1.weight [75.0% sparsity]
2018-11-01 11:19:39,203 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 11:19:39,204 - --- test ---------------------
2018-11-01 11:19:39,204 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:39,627 - Test: [   10/   39]    Loss 1.121948    Top1 83.750000    Top5 98.593750    
2018-11-01 11:19:39,732 - Test: [   20/   39]    Loss 1.119384    Top1 83.574219    Top5 98.652344    
2018-11-01 11:19:39,836 - Test: [   30/   39]    Loss 1.109502    Top1 83.567708    Top5 98.723958    
2018-11-01 11:19:39,931 - Test: [   40/   39]    Loss 1.083866    Top1 83.750000    Top5 98.760000    
2018-11-01 11:19:39,956 - ==> Top1: 83.750    Top5: 98.760    Loss: 1.084

2018-11-01 11:19:39,957 - Testing sensitivity of module.layer1.2.conv1.weight [80.0% sparsity]
2018-11-01 11:19:39,960 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 11:19:39,961 - --- test ---------------------
2018-11-01 11:19:39,961 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:40,374 - Test: [   10/   39]    Loss 1.121948    Top1 83.750000    Top5 98.593750    
2018-11-01 11:19:40,481 - Test: [   20/   39]    Loss 1.119384    Top1 83.574219    Top5 98.652344    
2018-11-01 11:19:40,585 - Test: [   30/   39]    Loss 1.109502    Top1 83.567708    Top5 98.723958    
2018-11-01 11:19:40,682 - Test: [   40/   39]    Loss 1.083866    Top1 83.750000    Top5 98.760000    
2018-11-01 11:19:40,708 - ==> Top1: 83.750    Top5: 98.760    Loss: 1.084

2018-11-01 11:19:40,708 - Testing sensitivity of module.layer1.2.conv1.weight [85.0% sparsity]
2018-11-01 11:19:40,711 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 11:19:40,713 - --- test ---------------------
2018-11-01 11:19:40,713 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:41,137 - Test: [   10/   39]    Loss 4.098663    Top1 60.156250    Top5 95.585938    
2018-11-01 11:19:41,244 - Test: [   20/   39]    Loss 4.107667    Top1 60.527344    Top5 95.156250    
2018-11-01 11:19:41,348 - Test: [   30/   39]    Loss 4.124873    Top1 59.921875    Top5 95.234375    
2018-11-01 11:19:41,444 - Test: [   40/   39]    Loss 4.139820    Top1 59.800000    Top5 95.210000    
2018-11-01 11:19:41,469 - ==> Top1: 59.800    Top5: 95.210    Loss: 4.140

2018-11-01 11:19:41,470 - Testing sensitivity of module.layer1.2.conv1.weight [90.0% sparsity]
2018-11-01 11:19:41,472 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 11:19:41,473 - --- test ---------------------
2018-11-01 11:19:41,474 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:41,896 - Test: [   10/   39]    Loss 5.758274    Top1 48.007812    Top5 88.945312    
2018-11-01 11:19:42,002 - Test: [   20/   39]    Loss 5.741071    Top1 48.496094    Top5 88.867188    
2018-11-01 11:19:42,106 - Test: [   30/   39]    Loss 5.816861    Top1 47.656250    Top5 88.710938    
2018-11-01 11:19:42,202 - Test: [   40/   39]    Loss 5.874624    Top1 47.370000    Top5 88.440000    
2018-11-01 11:19:42,226 - ==> Top1: 47.370    Top5: 88.440    Loss: 5.875

2018-11-01 11:19:42,239 - Testing sensitivity of module.layer1.2.conv2.weight [0.0% sparsity]
2018-11-01 11:19:42,242 - --- test ---------------------
2018-11-01 11:19:42,242 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:42,657 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:42,764 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:42,868 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:42,963 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:42,994 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:42,995 - Testing sensitivity of module.layer1.2.conv2.weight [5.0% sparsity]
2018-11-01 11:19:42,997 - Too few channels (16)- can't prune 5.0% channels
2018-11-01 11:19:42,998 - --- test ---------------------
2018-11-01 11:19:42,998 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:43,421 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:43,526 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:43,629 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:43,724 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:43,749 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:43,750 - Testing sensitivity of module.layer1.2.conv2.weight [10.0% sparsity]
2018-11-01 11:19:43,753 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 11:19:43,754 - --- test ---------------------
2018-11-01 11:19:43,754 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:44,179 - Test: [   10/   39]    Loss 0.559945    Top1 91.250000    Top5 99.609375    
2018-11-01 11:19:44,286 - Test: [   20/   39]    Loss 0.558986    Top1 91.308594    Top5 99.511719    
2018-11-01 11:19:44,392 - Test: [   30/   39]    Loss 0.552274    Top1 91.276042    Top5 99.609375    
2018-11-01 11:19:44,490 - Test: [   40/   39]    Loss 0.547333    Top1 91.320000    Top5 99.600000    
2018-11-01 11:19:44,515 - ==> Top1: 91.320    Top5: 99.600    Loss: 0.547

2018-11-01 11:19:44,515 - Testing sensitivity of module.layer1.2.conv2.weight [15.0% sparsity]
2018-11-01 11:19:44,518 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 11:19:44,519 - --- test ---------------------
2018-11-01 11:19:44,519 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:44,958 - Test: [   10/   39]    Loss 0.563728    Top1 91.015625    Top5 99.648438    
2018-11-01 11:19:45,064 - Test: [   20/   39]    Loss 0.560586    Top1 91.210938    Top5 99.570312    
2018-11-01 11:19:45,166 - Test: [   30/   39]    Loss 0.553046    Top1 91.276042    Top5 99.622396    
2018-11-01 11:19:45,261 - Test: [   40/   39]    Loss 0.547982    Top1 91.220000    Top5 99.610000    
2018-11-01 11:19:45,288 - ==> Top1: 91.220    Top5: 99.610    Loss: 0.548

2018-11-01 11:19:45,289 - Testing sensitivity of module.layer1.2.conv2.weight [20.0% sparsity]
2018-11-01 11:19:45,291 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 11:19:45,293 - --- test ---------------------
2018-11-01 11:19:45,293 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:45,719 - Test: [   10/   39]    Loss 0.582445    Top1 90.703125    Top5 99.531250    
2018-11-01 11:19:45,825 - Test: [   20/   39]    Loss 0.578806    Top1 90.917969    Top5 99.433594    
2018-11-01 11:19:45,928 - Test: [   30/   39]    Loss 0.575804    Top1 90.820312    Top5 99.531250    
2018-11-01 11:19:46,022 - Test: [   40/   39]    Loss 0.569694    Top1 90.810000    Top5 99.530000    
2018-11-01 11:19:46,046 - ==> Top1: 90.810    Top5: 99.530    Loss: 0.570

2018-11-01 11:19:46,047 - Testing sensitivity of module.layer1.2.conv2.weight [25.0% sparsity]
2018-11-01 11:19:46,051 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 11:19:46,052 - --- test ---------------------
2018-11-01 11:19:46,052 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:46,484 - Test: [   10/   39]    Loss 0.591182    Top1 90.234375    Top5 99.570312    
2018-11-01 11:19:46,590 - Test: [   20/   39]    Loss 0.587874    Top1 90.546875    Top5 99.453125    
2018-11-01 11:19:46,695 - Test: [   30/   39]    Loss 0.584516    Top1 90.520833    Top5 99.518229    
2018-11-01 11:19:46,790 - Test: [   40/   39]    Loss 0.579223    Top1 90.530000    Top5 99.510000    
2018-11-01 11:19:46,814 - ==> Top1: 90.530    Top5: 99.510    Loss: 0.579

2018-11-01 11:19:46,817 - Testing sensitivity of module.layer1.2.conv2.weight [30.0% sparsity]
2018-11-01 11:19:46,819 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 11:19:46,821 - --- test ---------------------
2018-11-01 11:19:46,821 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:47,247 - Test: [   10/   39]    Loss 0.591182    Top1 90.234375    Top5 99.570312    
2018-11-01 11:19:47,352 - Test: [   20/   39]    Loss 0.587874    Top1 90.546875    Top5 99.453125    
2018-11-01 11:19:47,455 - Test: [   30/   39]    Loss 0.584516    Top1 90.520833    Top5 99.518229    
2018-11-01 11:19:47,550 - Test: [   40/   39]    Loss 0.579223    Top1 90.530000    Top5 99.510000    
2018-11-01 11:19:47,576 - ==> Top1: 90.530    Top5: 99.510    Loss: 0.579

2018-11-01 11:19:47,577 - Testing sensitivity of module.layer1.2.conv2.weight [35.0% sparsity]
2018-11-01 11:19:47,580 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 11:19:47,581 - --- test ---------------------
2018-11-01 11:19:47,582 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:48,006 - Test: [   10/   39]    Loss 0.592372    Top1 89.882812    Top5 99.609375    
2018-11-01 11:19:48,114 - Test: [   20/   39]    Loss 0.586338    Top1 90.488281    Top5 99.472656    
2018-11-01 11:19:48,217 - Test: [   30/   39]    Loss 0.588812    Top1 90.390625    Top5 99.557292    
2018-11-01 11:19:48,312 - Test: [   40/   39]    Loss 0.578827    Top1 90.430000    Top5 99.540000    
2018-11-01 11:19:48,336 - ==> Top1: 90.430    Top5: 99.540    Loss: 0.579

2018-11-01 11:19:48,337 - Testing sensitivity of module.layer1.2.conv2.weight [40.0% sparsity]
2018-11-01 11:19:48,340 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 11:19:48,341 - --- test ---------------------
2018-11-01 11:19:48,341 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:48,765 - Test: [   10/   39]    Loss 0.598062    Top1 90.312500    Top5 99.453125    
2018-11-01 11:19:48,870 - Test: [   20/   39]    Loss 0.592316    Top1 90.546875    Top5 99.394531    
2018-11-01 11:19:48,973 - Test: [   30/   39]    Loss 0.595154    Top1 90.455729    Top5 99.453125    
2018-11-01 11:19:49,068 - Test: [   40/   39]    Loss 0.585691    Top1 90.550000    Top5 99.470000    
2018-11-01 11:19:49,093 - ==> Top1: 90.550    Top5: 99.470    Loss: 0.586

2018-11-01 11:19:49,094 - Testing sensitivity of module.layer1.2.conv2.weight [45.0% sparsity]
2018-11-01 11:19:49,096 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 11:19:49,098 - --- test ---------------------
2018-11-01 11:19:49,098 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:49,531 - Test: [   10/   39]    Loss 0.641164    Top1 89.101562    Top5 99.453125    
2018-11-01 11:19:49,637 - Test: [   20/   39]    Loss 0.625431    Top1 89.785156    Top5 99.375000    
2018-11-01 11:19:49,743 - Test: [   30/   39]    Loss 0.632023    Top1 89.752604    Top5 99.466146    
2018-11-01 11:19:49,840 - Test: [   40/   39]    Loss 0.619491    Top1 89.850000    Top5 99.440000    
2018-11-01 11:19:49,866 - ==> Top1: 89.850    Top5: 99.440    Loss: 0.619

2018-11-01 11:19:49,867 - Testing sensitivity of module.layer1.2.conv2.weight [50.0% sparsity]
2018-11-01 11:19:49,869 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 11:19:49,870 - --- test ---------------------
2018-11-01 11:19:49,871 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:50,307 - Test: [   10/   39]    Loss 0.740387    Top1 87.578125    Top5 99.570312    
2018-11-01 11:19:50,416 - Test: [   20/   39]    Loss 0.723739    Top1 88.417969    Top5 99.433594    
2018-11-01 11:19:50,520 - Test: [   30/   39]    Loss 0.733083    Top1 88.255208    Top5 99.479167    
2018-11-01 11:19:50,616 - Test: [   40/   39]    Loss 0.718577    Top1 88.470000    Top5 99.440000    
2018-11-01 11:19:50,642 - ==> Top1: 88.470    Top5: 99.440    Loss: 0.719

2018-11-01 11:19:50,643 - Testing sensitivity of module.layer1.2.conv2.weight [55.0% sparsity]
2018-11-01 11:19:50,646 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 11:19:50,647 - --- test ---------------------
2018-11-01 11:19:50,648 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:51,086 - Test: [   10/   39]    Loss 0.740387    Top1 87.578125    Top5 99.570312    
2018-11-01 11:19:51,192 - Test: [   20/   39]    Loss 0.723739    Top1 88.417969    Top5 99.433594    
2018-11-01 11:19:51,295 - Test: [   30/   39]    Loss 0.733083    Top1 88.255208    Top5 99.479167    
2018-11-01 11:19:51,389 - Test: [   40/   39]    Loss 0.718577    Top1 88.470000    Top5 99.440000    
2018-11-01 11:19:51,414 - ==> Top1: 88.470    Top5: 99.440    Loss: 0.719

2018-11-01 11:19:51,416 - Testing sensitivity of module.layer1.2.conv2.weight [60.0% sparsity]
2018-11-01 11:19:51,418 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 11:19:51,419 - --- test ---------------------
2018-11-01 11:19:51,420 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:51,845 - Test: [   10/   39]    Loss 0.845469    Top1 85.859375    Top5 99.140625    
2018-11-01 11:19:51,952 - Test: [   20/   39]    Loss 0.830949    Top1 86.464844    Top5 98.964844    
2018-11-01 11:19:52,054 - Test: [   30/   39]    Loss 0.846008    Top1 86.354167    Top5 99.036458    
2018-11-01 11:19:52,151 - Test: [   40/   39]    Loss 0.833829    Top1 86.480000    Top5 99.060000    
2018-11-01 11:19:52,184 - ==> Top1: 86.480    Top5: 99.060    Loss: 0.834

2018-11-01 11:19:52,185 - Testing sensitivity of module.layer1.2.conv2.weight [65.0% sparsity]
2018-11-01 11:19:52,188 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 11:19:52,188 - --- test ---------------------
2018-11-01 11:19:52,189 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:52,635 - Test: [   10/   39]    Loss 0.748991    Top1 87.304688    Top5 99.296875    
2018-11-01 11:19:52,744 - Test: [   20/   39]    Loss 0.760538    Top1 87.851562    Top5 99.296875    
2018-11-01 11:19:52,850 - Test: [   30/   39]    Loss 0.769634    Top1 87.682292    Top5 99.309896    
2018-11-01 11:19:52,945 - Test: [   40/   39]    Loss 0.753698    Top1 87.920000    Top5 99.280000    
2018-11-01 11:19:52,973 - ==> Top1: 87.920    Top5: 99.280    Loss: 0.754

2018-11-01 11:19:52,973 - Testing sensitivity of module.layer1.2.conv2.weight [70.0% sparsity]
2018-11-01 11:19:52,976 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 11:19:52,977 - --- test ---------------------
2018-11-01 11:19:52,977 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:53,405 - Test: [   10/   39]    Loss 0.877297    Top1 85.781250    Top5 99.023438    
2018-11-01 11:19:53,511 - Test: [   20/   39]    Loss 0.882349    Top1 86.132812    Top5 98.964844    
2018-11-01 11:19:53,615 - Test: [   30/   39]    Loss 0.897411    Top1 85.807292    Top5 99.023438    
2018-11-01 11:19:53,710 - Test: [   40/   39]    Loss 0.887067    Top1 85.860000    Top5 99.070000    
2018-11-01 11:19:53,735 - ==> Top1: 85.860    Top5: 99.070    Loss: 0.887

2018-11-01 11:19:53,736 - Testing sensitivity of module.layer1.2.conv2.weight [75.0% sparsity]
2018-11-01 11:19:53,739 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 11:19:53,740 - --- test ---------------------
2018-11-01 11:19:53,740 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:54,173 - Test: [   10/   39]    Loss 1.614833    Top1 76.640625    Top5 96.562500    
2018-11-01 11:19:54,279 - Test: [   20/   39]    Loss 1.592337    Top1 77.421875    Top5 96.679688    
2018-11-01 11:19:54,383 - Test: [   30/   39]    Loss 1.621643    Top1 76.940104    Top5 96.458333    
2018-11-01 11:19:54,477 - Test: [   40/   39]    Loss 1.655209    Top1 76.790000    Top5 96.460000    
2018-11-01 11:19:54,501 - ==> Top1: 76.790    Top5: 96.460    Loss: 1.655

2018-11-01 11:19:54,502 - Testing sensitivity of module.layer1.2.conv2.weight [80.0% sparsity]
2018-11-01 11:19:54,505 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 11:19:54,505 - --- test ---------------------
2018-11-01 11:19:54,506 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:54,930 - Test: [   10/   39]    Loss 1.614833    Top1 76.640625    Top5 96.562500    
2018-11-01 11:19:55,038 - Test: [   20/   39]    Loss 1.592337    Top1 77.421875    Top5 96.679688    
2018-11-01 11:19:55,143 - Test: [   30/   39]    Loss 1.621643    Top1 76.940104    Top5 96.458333    
2018-11-01 11:19:55,240 - Test: [   40/   39]    Loss 1.655209    Top1 76.790000    Top5 96.460000    
2018-11-01 11:19:55,264 - ==> Top1: 76.790    Top5: 96.460    Loss: 1.655

2018-11-01 11:19:55,265 - Testing sensitivity of module.layer1.2.conv2.weight [85.0% sparsity]
2018-11-01 11:19:55,268 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 11:19:55,269 - --- test ---------------------
2018-11-01 11:19:55,269 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:55,696 - Test: [   10/   39]    Loss 1.137137    Top1 81.679688    Top5 98.828125    
2018-11-01 11:19:55,802 - Test: [   20/   39]    Loss 1.128439    Top1 82.675781    Top5 98.710938    
2018-11-01 11:19:55,906 - Test: [   30/   39]    Loss 1.142944    Top1 82.304688    Top5 98.710938    
2018-11-01 11:19:56,002 - Test: [   40/   39]    Loss 1.149439    Top1 82.340000    Top5 98.730000    
2018-11-01 11:19:56,027 - ==> Top1: 82.340    Top5: 98.730    Loss: 1.149

2018-11-01 11:19:56,029 - Testing sensitivity of module.layer1.2.conv2.weight [90.0% sparsity]
2018-11-01 11:19:56,032 - L1RankedStructureParameterPruner - param: module.layer1.2.conv2.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 11:19:56,032 - --- test ---------------------
2018-11-01 11:19:56,033 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:56,437 - Test: [   10/   39]    Loss 1.851078    Top1 72.656250    Top5 96.171875    
2018-11-01 11:19:56,543 - Test: [   20/   39]    Loss 1.831766    Top1 73.222656    Top5 96.347656    
2018-11-01 11:19:56,646 - Test: [   30/   39]    Loss 1.861566    Top1 72.604167    Top5 96.276042    
2018-11-01 11:19:56,741 - Test: [   40/   39]    Loss 1.881326    Top1 72.600000    Top5 96.320000    
2018-11-01 11:19:56,767 - ==> Top1: 72.600    Top5: 96.320    Loss: 1.881

2018-11-01 11:19:56,779 - Testing sensitivity of module.layer2.0.conv1.weight [0.0% sparsity]
2018-11-01 11:19:56,782 - --- test ---------------------
2018-11-01 11:19:56,782 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:57,192 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:57,299 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:57,403 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:57,498 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:57,523 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:57,524 - Testing sensitivity of module.layer2.0.conv1.weight [5.0% sparsity]
2018-11-01 11:19:57,527 - Too few channels (16)- can't prune 5.0% channels
2018-11-01 11:19:57,528 - --- test ---------------------
2018-11-01 11:19:57,528 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:57,947 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:19:58,054 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:19:58,158 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:19:58,254 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:19:58,279 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:19:58,280 - Testing sensitivity of module.layer2.0.conv1.weight [10.0% sparsity]
2018-11-01 11:19:58,282 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 11:19:58,283 - --- test ---------------------
2018-11-01 11:19:58,283 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:58,704 - Test: [   10/   39]    Loss 0.560249    Top1 90.976562    Top5 99.687500    
2018-11-01 11:19:58,811 - Test: [   20/   39]    Loss 0.557418    Top1 91.230469    Top5 99.609375    
2018-11-01 11:19:58,914 - Test: [   30/   39]    Loss 0.554926    Top1 91.250000    Top5 99.687500    
2018-11-01 11:19:59,009 - Test: [   40/   39]    Loss 0.548717    Top1 91.210000    Top5 99.690000    
2018-11-01 11:19:59,036 - ==> Top1: 91.210    Top5: 99.690    Loss: 0.549

2018-11-01 11:19:59,036 - Testing sensitivity of module.layer2.0.conv1.weight [15.0% sparsity]
2018-11-01 11:19:59,039 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 11:19:59,040 - --- test ---------------------
2018-11-01 11:19:59,040 - 10000 samples (256 per mini-batch)
2018-11-01 11:19:59,474 - Test: [   10/   39]    Loss 0.607038    Top1 90.351562    Top5 99.609375    
2018-11-01 11:19:59,580 - Test: [   20/   39]    Loss 0.597272    Top1 90.292969    Top5 99.511719    
2018-11-01 11:19:59,685 - Test: [   30/   39]    Loss 0.591076    Top1 90.325521    Top5 99.583333    
2018-11-01 11:19:59,780 - Test: [   40/   39]    Loss 0.590402    Top1 90.370000    Top5 99.610000    
2018-11-01 11:19:59,811 - ==> Top1: 90.370    Top5: 99.610    Loss: 0.590

2018-11-01 11:19:59,811 - Testing sensitivity of module.layer2.0.conv1.weight [20.0% sparsity]
2018-11-01 11:19:59,815 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 11:19:59,816 - --- test ---------------------
2018-11-01 11:19:59,817 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:00,238 - Test: [   10/   39]    Loss 0.634110    Top1 89.648438    Top5 99.375000    
2018-11-01 11:20:00,345 - Test: [   20/   39]    Loss 0.630910    Top1 89.726562    Top5 99.394531    
2018-11-01 11:20:00,450 - Test: [   30/   39]    Loss 0.623308    Top1 89.791667    Top5 99.453125    
2018-11-01 11:20:00,548 - Test: [   40/   39]    Loss 0.623228    Top1 89.850000    Top5 99.460000    
2018-11-01 11:20:00,574 - ==> Top1: 89.850    Top5: 99.460    Loss: 0.623

2018-11-01 11:20:00,574 - Testing sensitivity of module.layer2.0.conv1.weight [25.0% sparsity]
2018-11-01 11:20:00,577 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 11:20:00,578 - --- test ---------------------
2018-11-01 11:20:00,578 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:01,027 - Test: [   10/   39]    Loss 0.795081    Top1 87.890625    Top5 99.296875    
2018-11-01 11:20:01,132 - Test: [   20/   39]    Loss 0.769476    Top1 87.968750    Top5 99.277344    
2018-11-01 11:20:01,237 - Test: [   30/   39]    Loss 0.749754    Top1 88.164062    Top5 99.361979    
2018-11-01 11:20:01,332 - Test: [   40/   39]    Loss 0.746012    Top1 88.200000    Top5 99.400000    
2018-11-01 11:20:01,357 - ==> Top1: 88.200    Top5: 99.400    Loss: 0.746

2018-11-01 11:20:01,358 - Testing sensitivity of module.layer2.0.conv1.weight [30.0% sparsity]
2018-11-01 11:20:01,361 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 11:20:01,362 - --- test ---------------------
2018-11-01 11:20:01,362 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:01,805 - Test: [   10/   39]    Loss 0.795081    Top1 87.890625    Top5 99.296875    
2018-11-01 11:20:01,915 - Test: [   20/   39]    Loss 0.769476    Top1 87.968750    Top5 99.277344    
2018-11-01 11:20:02,019 - Test: [   30/   39]    Loss 0.749754    Top1 88.164062    Top5 99.361979    
2018-11-01 11:20:02,115 - Test: [   40/   39]    Loss 0.746012    Top1 88.200000    Top5 99.400000    
2018-11-01 11:20:02,156 - ==> Top1: 88.200    Top5: 99.400    Loss: 0.746

2018-11-01 11:20:02,157 - Testing sensitivity of module.layer2.0.conv1.weight [35.0% sparsity]
2018-11-01 11:20:02,159 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 11:20:02,160 - --- test ---------------------
2018-11-01 11:20:02,160 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:02,585 - Test: [   10/   39]    Loss 0.889975    Top1 86.601562    Top5 99.335938    
2018-11-01 11:20:02,693 - Test: [   20/   39]    Loss 0.843526    Top1 87.128906    Top5 99.277344    
2018-11-01 11:20:02,797 - Test: [   30/   39]    Loss 0.815950    Top1 87.356771    Top5 99.348958    
2018-11-01 11:20:02,894 - Test: [   40/   39]    Loss 0.808160    Top1 87.310000    Top5 99.390000    
2018-11-01 11:20:02,918 - ==> Top1: 87.310    Top5: 99.390    Loss: 0.808

2018-11-01 11:20:02,918 - Testing sensitivity of module.layer2.0.conv1.weight [40.0% sparsity]
2018-11-01 11:20:02,921 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 11:20:02,922 - --- test ---------------------
2018-11-01 11:20:02,922 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:03,370 - Test: [   10/   39]    Loss 1.036769    Top1 84.882812    Top5 99.296875    
2018-11-01 11:20:03,478 - Test: [   20/   39]    Loss 0.979124    Top1 85.703125    Top5 99.062500    
2018-11-01 11:20:03,582 - Test: [   30/   39]    Loss 0.937614    Top1 85.898438    Top5 99.179688    
2018-11-01 11:20:03,678 - Test: [   40/   39]    Loss 0.930783    Top1 85.830000    Top5 99.210000    
2018-11-01 11:20:03,703 - ==> Top1: 85.830    Top5: 99.210    Loss: 0.931

2018-11-01 11:20:03,704 - Testing sensitivity of module.layer2.0.conv1.weight [45.0% sparsity]
2018-11-01 11:20:03,706 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 11:20:03,707 - --- test ---------------------
2018-11-01 11:20:03,707 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:04,145 - Test: [   10/   39]    Loss 1.626848    Top1 78.632812    Top5 98.710938    
2018-11-01 11:20:04,255 - Test: [   20/   39]    Loss 1.551664    Top1 79.160156    Top5 98.554688    
2018-11-01 11:20:04,358 - Test: [   30/   39]    Loss 1.517811    Top1 78.984375    Top5 98.697917    
2018-11-01 11:20:04,454 - Test: [   40/   39]    Loss 1.507298    Top1 78.830000    Top5 98.660000    
2018-11-01 11:20:04,479 - ==> Top1: 78.830    Top5: 98.660    Loss: 1.507

2018-11-01 11:20:04,480 - Testing sensitivity of module.layer2.0.conv1.weight [50.0% sparsity]
2018-11-01 11:20:04,483 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 11:20:04,484 - --- test ---------------------
2018-11-01 11:20:04,485 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:04,929 - Test: [   10/   39]    Loss 4.860492    Top1 53.164062    Top5 93.125000    
2018-11-01 11:20:05,035 - Test: [   20/   39]    Loss 4.619775    Top1 54.277344    Top5 93.242188    
2018-11-01 11:20:05,143 - Test: [   30/   39]    Loss 4.582506    Top1 54.335938    Top5 93.385417    
2018-11-01 11:20:05,243 - Test: [   40/   39]    Loss 4.559061    Top1 54.340000    Top5 93.210000    
2018-11-01 11:20:05,272 - ==> Top1: 54.340    Top5: 93.210    Loss: 4.559

2018-11-01 11:20:05,273 - Testing sensitivity of module.layer2.0.conv1.weight [55.0% sparsity]
2018-11-01 11:20:05,275 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 11:20:05,275 - --- test ---------------------
2018-11-01 11:20:05,275 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:05,705 - Test: [   10/   39]    Loss 4.860492    Top1 53.164062    Top5 93.125000    
2018-11-01 11:20:05,814 - Test: [   20/   39]    Loss 4.619775    Top1 54.277344    Top5 93.242188    
2018-11-01 11:20:05,919 - Test: [   30/   39]    Loss 4.582506    Top1 54.335938    Top5 93.385417    
2018-11-01 11:20:06,014 - Test: [   40/   39]    Loss 4.559061    Top1 54.340000    Top5 93.210000    
2018-11-01 11:20:06,040 - ==> Top1: 54.340    Top5: 93.210    Loss: 4.559

2018-11-01 11:20:06,040 - Testing sensitivity of module.layer2.0.conv1.weight [60.0% sparsity]
2018-11-01 11:20:06,042 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 11:20:06,044 - --- test ---------------------
2018-11-01 11:20:06,044 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:06,469 - Test: [   10/   39]    Loss 6.980509    Top1 42.109375    Top5 90.000000    
2018-11-01 11:20:06,576 - Test: [   20/   39]    Loss 6.732577    Top1 43.574219    Top5 90.683594    
2018-11-01 11:20:06,680 - Test: [   30/   39]    Loss 6.704952    Top1 43.450521    Top5 90.963542    
2018-11-01 11:20:06,779 - Test: [   40/   39]    Loss 6.684232    Top1 43.110000    Top5 90.990000    
2018-11-01 11:20:06,779 - ==> Top1: 43.110    Top5: 90.990    Loss: 6.684

2018-11-01 11:20:06,807 - Testing sensitivity of module.layer2.0.conv1.weight [65.0% sparsity]
2018-11-01 11:20:06,810 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 11:20:06,811 - --- test ---------------------
2018-11-01 11:20:06,811 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:07,240 - Test: [   10/   39]    Loss 7.460191    Top1 37.929688    Top5 82.968750    
2018-11-01 11:20:07,346 - Test: [   20/   39]    Loss 7.300248    Top1 38.281250    Top5 83.789062    
2018-11-01 11:20:07,450 - Test: [   30/   39]    Loss 7.239645    Top1 38.372396    Top5 84.518229    
2018-11-01 11:20:07,546 - Test: [   40/   39]    Loss 7.209424    Top1 38.520000    Top5 84.350000    
2018-11-01 11:20:07,570 - ==> Top1: 38.520    Top5: 84.350    Loss: 7.209

2018-11-01 11:20:07,571 - Testing sensitivity of module.layer2.0.conv1.weight [70.0% sparsity]
2018-11-01 11:20:07,574 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 11:20:07,575 - --- test ---------------------
2018-11-01 11:20:07,575 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:08,004 - Test: [   10/   39]    Loss 10.718091    Top1 26.718750    Top5 82.812500    
2018-11-01 11:20:08,110 - Test: [   20/   39]    Loss 10.678826    Top1 27.285156    Top5 82.617188    
2018-11-01 11:20:08,214 - Test: [   30/   39]    Loss 10.545194    Top1 27.552083    Top5 83.138021    
2018-11-01 11:20:08,310 - Test: [   40/   39]    Loss 10.536074    Top1 27.230000    Top5 83.110000    
2018-11-01 11:20:08,335 - ==> Top1: 27.230    Top5: 83.110    Loss: 10.536

2018-11-01 11:20:08,335 - Testing sensitivity of module.layer2.0.conv1.weight [75.0% sparsity]
2018-11-01 11:20:08,338 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 11:20:08,339 - --- test ---------------------
2018-11-01 11:20:08,339 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:08,761 - Test: [   10/   39]    Loss 10.839931    Top1 26.835937    Top5 79.453125    
2018-11-01 11:20:08,867 - Test: [   20/   39]    Loss 10.827556    Top1 27.246094    Top5 80.078125    
2018-11-01 11:20:08,972 - Test: [   30/   39]    Loss 10.663284    Top1 27.552083    Top5 80.377604    
2018-11-01 11:20:09,068 - Test: [   40/   39]    Loss 10.652234    Top1 27.300000    Top5 80.250000    
2018-11-01 11:20:09,093 - ==> Top1: 27.300    Top5: 80.250    Loss: 10.652

2018-11-01 11:20:09,094 - Testing sensitivity of module.layer2.0.conv1.weight [80.0% sparsity]
2018-11-01 11:20:09,096 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 11:20:09,097 - --- test ---------------------
2018-11-01 11:20:09,097 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:09,560 - Test: [   10/   39]    Loss 10.839931    Top1 26.835937    Top5 79.453125    
2018-11-01 11:20:09,670 - Test: [   20/   39]    Loss 10.827556    Top1 27.246094    Top5 80.078125    
2018-11-01 11:20:09,777 - Test: [   30/   39]    Loss 10.663284    Top1 27.552083    Top5 80.377604    
2018-11-01 11:20:09,875 - Test: [   40/   39]    Loss 10.652234    Top1 27.300000    Top5 80.250000    
2018-11-01 11:20:09,903 - ==> Top1: 27.300    Top5: 80.250    Loss: 10.652

2018-11-01 11:20:09,904 - Testing sensitivity of module.layer2.0.conv1.weight [85.0% sparsity]
2018-11-01 11:20:09,907 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 11:20:09,909 - --- test ---------------------
2018-11-01 11:20:09,909 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:10,354 - Test: [   10/   39]    Loss 12.084325    Top1 23.437500    Top5 74.062500    
2018-11-01 11:20:10,465 - Test: [   20/   39]    Loss 12.042481    Top1 23.691406    Top5 74.355469    
2018-11-01 11:20:10,572 - Test: [   30/   39]    Loss 11.876320    Top1 23.867187    Top5 74.778646    
2018-11-01 11:20:10,670 - Test: [   40/   39]    Loss 11.851099    Top1 23.720000    Top5 74.310000    
2018-11-01 11:20:10,712 - ==> Top1: 23.720    Top5: 74.310    Loss: 11.851

2018-11-01 11:20:10,713 - Testing sensitivity of module.layer2.0.conv1.weight [90.0% sparsity]
2018-11-01 11:20:10,716 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 11:20:10,717 - --- test ---------------------
2018-11-01 11:20:10,717 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:11,152 - Test: [   10/   39]    Loss 9.875837    Top1 25.273437    Top5 66.640625    
2018-11-01 11:20:11,262 - Test: [   20/   39]    Loss 9.799666    Top1 25.468750    Top5 67.324219    
2018-11-01 11:20:11,370 - Test: [   30/   39]    Loss 9.714990    Top1 25.442708    Top5 68.007812    
2018-11-01 11:20:11,468 - Test: [   40/   39]    Loss 9.703122    Top1 25.220000    Top5 67.550000    
2018-11-01 11:20:11,505 - ==> Top1: 25.220    Top5: 67.550    Loss: 9.703

2018-11-01 11:20:11,519 - Testing sensitivity of module.layer2.0.conv2.weight [0.0% sparsity]
2018-11-01 11:20:11,521 - --- test ---------------------
2018-11-01 11:20:11,522 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:11,898 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:20:12,004 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:20:12,107 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:20:12,201 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:20:12,226 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:20:12,228 - Testing sensitivity of module.layer2.0.conv2.weight [5.0% sparsity]
2018-11-01 11:20:12,231 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 11:20:12,232 - --- test ---------------------
2018-11-01 11:20:12,232 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:12,674 - Test: [   10/   39]    Loss 0.560013    Top1 91.093750    Top5 99.648438    
2018-11-01 11:20:12,783 - Test: [   20/   39]    Loss 0.555176    Top1 91.347656    Top5 99.531250    
2018-11-01 11:20:12,886 - Test: [   30/   39]    Loss 0.550250    Top1 91.367188    Top5 99.635417    
2018-11-01 11:20:12,980 - Test: [   40/   39]    Loss 0.547216    Top1 91.330000    Top5 99.630000    
2018-11-01 11:20:13,020 - ==> Top1: 91.330    Top5: 99.630    Loss: 0.547

2018-11-01 11:20:13,020 - Testing sensitivity of module.layer2.0.conv2.weight [10.0% sparsity]
2018-11-01 11:20:13,022 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 11:20:13,023 - --- test ---------------------
2018-11-01 11:20:13,023 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:13,456 - Test: [   10/   39]    Loss 0.563131    Top1 90.820312    Top5 99.414062    
2018-11-01 11:20:13,562 - Test: [   20/   39]    Loss 0.564599    Top1 90.878906    Top5 99.394531    
2018-11-01 11:20:13,669 - Test: [   30/   39]    Loss 0.564891    Top1 90.742188    Top5 99.531250    
2018-11-01 11:20:13,769 - Test: [   40/   39]    Loss 0.553417    Top1 90.960000    Top5 99.530000    
2018-11-01 11:20:13,812 - ==> Top1: 90.960    Top5: 99.530    Loss: 0.553

2018-11-01 11:20:13,813 - Testing sensitivity of module.layer2.0.conv2.weight [15.0% sparsity]
2018-11-01 11:20:13,815 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 11:20:13,815 - --- test ---------------------
2018-11-01 11:20:13,815 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:14,245 - Test: [   10/   39]    Loss 0.598402    Top1 90.312500    Top5 99.492188    
2018-11-01 11:20:14,350 - Test: [   20/   39]    Loss 0.592861    Top1 90.527344    Top5 99.492188    
2018-11-01 11:20:14,457 - Test: [   30/   39]    Loss 0.588946    Top1 90.481771    Top5 99.570312    
2018-11-01 11:20:14,555 - Test: [   40/   39]    Loss 0.578033    Top1 90.640000    Top5 99.560000    
2018-11-01 11:20:14,580 - ==> Top1: 90.640    Top5: 99.560    Loss: 0.578

2018-11-01 11:20:14,581 - Testing sensitivity of module.layer2.0.conv2.weight [20.0% sparsity]
2018-11-01 11:20:14,584 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 11:20:14,585 - --- test ---------------------
2018-11-01 11:20:14,585 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:15,019 - Test: [   10/   39]    Loss 0.638345    Top1 89.296875    Top5 99.375000    
2018-11-01 11:20:15,125 - Test: [   20/   39]    Loss 0.633637    Top1 89.648438    Top5 99.414062    
2018-11-01 11:20:15,230 - Test: [   30/   39]    Loss 0.625972    Top1 89.648438    Top5 99.414062    
2018-11-01 11:20:15,327 - Test: [   40/   39]    Loss 0.616861    Top1 89.970000    Top5 99.400000    
2018-11-01 11:20:15,353 - ==> Top1: 89.970    Top5: 99.400    Loss: 0.617

2018-11-01 11:20:15,354 - Testing sensitivity of module.layer2.0.conv2.weight [25.0% sparsity]
2018-11-01 11:20:15,356 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 11:20:15,357 - --- test ---------------------
2018-11-01 11:20:15,358 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:15,779 - Test: [   10/   39]    Loss 0.755797    Top1 87.695312    Top5 99.375000    
2018-11-01 11:20:15,886 - Test: [   20/   39]    Loss 0.733016    Top1 88.007812    Top5 99.433594    
2018-11-01 11:20:15,989 - Test: [   30/   39]    Loss 0.707262    Top1 88.502604    Top5 99.440104    
2018-11-01 11:20:16,084 - Test: [   40/   39]    Loss 0.697738    Top1 88.810000    Top5 99.420000    
2018-11-01 11:20:16,111 - ==> Top1: 88.810    Top5: 99.420    Loss: 0.698

2018-11-01 11:20:16,111 - Testing sensitivity of module.layer2.0.conv2.weight [30.0% sparsity]
2018-11-01 11:20:16,114 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 11:20:16,116 - --- test ---------------------
2018-11-01 11:20:16,116 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:16,545 - Test: [   10/   39]    Loss 0.807685    Top1 86.914062    Top5 99.218750    
2018-11-01 11:20:16,651 - Test: [   20/   39]    Loss 0.789242    Top1 87.226562    Top5 99.296875    
2018-11-01 11:20:16,756 - Test: [   30/   39]    Loss 0.761154    Top1 87.591146    Top5 99.322917    
2018-11-01 11:20:16,854 - Test: [   40/   39]    Loss 0.750603    Top1 87.890000    Top5 99.310000    
2018-11-01 11:20:16,880 - ==> Top1: 87.890    Top5: 99.310    Loss: 0.751

2018-11-01 11:20:16,880 - Testing sensitivity of module.layer2.0.conv2.weight [35.0% sparsity]
2018-11-01 11:20:16,884 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 11:20:16,885 - --- test ---------------------
2018-11-01 11:20:16,885 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:17,317 - Test: [   10/   39]    Loss 0.900645    Top1 86.289062    Top5 99.531250    
2018-11-01 11:20:17,421 - Test: [   20/   39]    Loss 0.883861    Top1 86.523438    Top5 99.296875    
2018-11-01 11:20:17,524 - Test: [   30/   39]    Loss 0.854012    Top1 86.614583    Top5 99.427083    
2018-11-01 11:20:17,619 - Test: [   40/   39]    Loss 0.835085    Top1 86.780000    Top5 99.420000    
2018-11-01 11:20:17,643 - ==> Top1: 86.780    Top5: 99.420    Loss: 0.835

2018-11-01 11:20:17,644 - Testing sensitivity of module.layer2.0.conv2.weight [40.0% sparsity]
2018-11-01 11:20:17,647 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 11:20:17,648 - --- test ---------------------
2018-11-01 11:20:17,648 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:18,076 - Test: [   10/   39]    Loss 0.988844    Top1 84.804688    Top5 99.296875    
2018-11-01 11:20:18,182 - Test: [   20/   39]    Loss 0.956125    Top1 85.566406    Top5 99.218750    
2018-11-01 11:20:18,288 - Test: [   30/   39]    Loss 0.925603    Top1 85.742188    Top5 99.322917    
2018-11-01 11:20:18,384 - Test: [   40/   39]    Loss 0.897938    Top1 85.890000    Top5 99.290000    
2018-11-01 11:20:18,409 - ==> Top1: 85.890    Top5: 99.290    Loss: 0.898

2018-11-01 11:20:18,410 - Testing sensitivity of module.layer2.0.conv2.weight [45.0% sparsity]
2018-11-01 11:20:18,413 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 11:20:18,413 - --- test ---------------------
2018-11-01 11:20:18,413 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:18,833 - Test: [   10/   39]    Loss 1.295775    Top1 81.835938    Top5 98.828125    
2018-11-01 11:20:18,938 - Test: [   20/   39]    Loss 1.268875    Top1 82.343750    Top5 98.867188    
2018-11-01 11:20:19,041 - Test: [   30/   39]    Loss 1.256184    Top1 82.096354    Top5 99.049479    
2018-11-01 11:20:19,135 - Test: [   40/   39]    Loss 1.221837    Top1 82.140000    Top5 99.090000    
2018-11-01 11:20:19,159 - ==> Top1: 82.140    Top5: 99.090    Loss: 1.222

2018-11-01 11:20:19,160 - Testing sensitivity of module.layer2.0.conv2.weight [50.0% sparsity]
2018-11-01 11:20:19,163 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 11:20:19,163 - --- test ---------------------
2018-11-01 11:20:19,164 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:19,582 - Test: [   10/   39]    Loss 1.469270    Top1 79.765625    Top5 98.750000    
2018-11-01 11:20:19,688 - Test: [   20/   39]    Loss 1.452596    Top1 80.410156    Top5 98.769531    
2018-11-01 11:20:19,792 - Test: [   30/   39]    Loss 1.450815    Top1 79.856771    Top5 98.932292    
2018-11-01 11:20:19,886 - Test: [   40/   39]    Loss 1.415794    Top1 79.790000    Top5 98.990000    
2018-11-01 11:20:19,911 - ==> Top1: 79.790    Top5: 98.990    Loss: 1.416

2018-11-01 11:20:19,913 - Testing sensitivity of module.layer2.0.conv2.weight [55.0% sparsity]
2018-11-01 11:20:19,916 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 11:20:19,917 - --- test ---------------------
2018-11-01 11:20:19,917 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:20,336 - Test: [   10/   39]    Loss 1.657633    Top1 77.656250    Top5 98.750000    
2018-11-01 11:20:20,442 - Test: [   20/   39]    Loss 1.641668    Top1 78.007812    Top5 98.710938    
2018-11-01 11:20:20,544 - Test: [   30/   39]    Loss 1.647954    Top1 77.734375    Top5 98.893229    
2018-11-01 11:20:20,638 - Test: [   40/   39]    Loss 1.615880    Top1 77.760000    Top5 98.910000    
2018-11-01 11:20:20,665 - ==> Top1: 77.760    Top5: 98.910    Loss: 1.616

2018-11-01 11:20:20,665 - Testing sensitivity of module.layer2.0.conv2.weight [60.0% sparsity]
2018-11-01 11:20:20,668 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 11:20:20,670 - --- test ---------------------
2018-11-01 11:20:20,670 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:21,111 - Test: [   10/   39]    Loss 1.591929    Top1 76.445312    Top5 98.632812    
2018-11-01 11:20:21,218 - Test: [   20/   39]    Loss 1.584630    Top1 76.503906    Top5 98.515625    
2018-11-01 11:20:21,328 - Test: [   30/   39]    Loss 1.610001    Top1 76.132812    Top5 98.593750    
2018-11-01 11:20:21,423 - Test: [   40/   39]    Loss 1.587671    Top1 76.410000    Top5 98.660000    
2018-11-01 11:20:21,447 - ==> Top1: 76.410    Top5: 98.660    Loss: 1.588

2018-11-01 11:20:21,448 - Testing sensitivity of module.layer2.0.conv2.weight [65.0% sparsity]
2018-11-01 11:20:21,451 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 11:20:21,452 - --- test ---------------------
2018-11-01 11:20:21,452 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:21,878 - Test: [   10/   39]    Loss 1.965241    Top1 72.578125    Top5 98.085938    
2018-11-01 11:20:21,983 - Test: [   20/   39]    Loss 1.968546    Top1 72.402344    Top5 98.027344    
2018-11-01 11:20:22,090 - Test: [   30/   39]    Loss 2.002717    Top1 71.848958    Top5 98.164062    
2018-11-01 11:20:22,186 - Test: [   40/   39]    Loss 1.980605    Top1 71.800000    Top5 98.140000    
2018-11-01 11:20:22,211 - ==> Top1: 71.800    Top5: 98.140    Loss: 1.981

2018-11-01 11:20:22,213 - Testing sensitivity of module.layer2.0.conv2.weight [70.0% sparsity]
2018-11-01 11:20:22,216 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 11:20:22,217 - --- test ---------------------
2018-11-01 11:20:22,218 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:22,636 - Test: [   10/   39]    Loss 2.851042    Top1 62.812500    Top5 96.250000    
2018-11-01 11:20:22,742 - Test: [   20/   39]    Loss 2.811466    Top1 63.007813    Top5 96.074219    
2018-11-01 11:20:22,846 - Test: [   30/   39]    Loss 2.838267    Top1 62.109375    Top5 96.106771    
2018-11-01 11:20:22,944 - Test: [   40/   39]    Loss 2.858445    Top1 62.040000    Top5 96.020000    
2018-11-01 11:20:22,969 - ==> Top1: 62.040    Top5: 96.020    Loss: 2.858

2018-11-01 11:20:22,970 - Testing sensitivity of module.layer2.0.conv2.weight [75.0% sparsity]
2018-11-01 11:20:22,973 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 11:20:22,974 - --- test ---------------------
2018-11-01 11:20:22,974 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:23,397 - Test: [   10/   39]    Loss 3.687612    Top1 53.203125    Top5 93.554688    
2018-11-01 11:20:23,504 - Test: [   20/   39]    Loss 3.627113    Top1 54.355469    Top5 93.632812    
2018-11-01 11:20:23,607 - Test: [   30/   39]    Loss 3.658331    Top1 53.880208    Top5 93.945312    
2018-11-01 11:20:23,702 - Test: [   40/   39]    Loss 3.657772    Top1 53.780000    Top5 93.790000    
2018-11-01 11:20:23,726 - ==> Top1: 53.780    Top5: 93.790    Loss: 3.658

2018-11-01 11:20:23,728 - Testing sensitivity of module.layer2.0.conv2.weight [80.0% sparsity]
2018-11-01 11:20:23,732 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 11:20:23,733 - --- test ---------------------
2018-11-01 11:20:23,733 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:24,179 - Test: [   10/   39]    Loss 4.357907    Top1 46.914062    Top5 90.703125    
2018-11-01 11:20:24,285 - Test: [   20/   39]    Loss 4.275159    Top1 47.519531    Top5 90.878906    
2018-11-01 11:20:24,389 - Test: [   30/   39]    Loss 4.309254    Top1 46.770833    Top5 91.328125    
2018-11-01 11:20:24,484 - Test: [   40/   39]    Loss 4.318257    Top1 46.500000    Top5 91.110000    
2018-11-01 11:20:24,509 - ==> Top1: 46.500    Top5: 91.110    Loss: 4.318

2018-11-01 11:20:24,511 - Testing sensitivity of module.layer2.0.conv2.weight [85.0% sparsity]
2018-11-01 11:20:24,515 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 11:20:24,516 - --- test ---------------------
2018-11-01 11:20:24,516 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:24,947 - Test: [   10/   39]    Loss 5.526010    Top1 36.992187    Top5 87.578125    
2018-11-01 11:20:25,061 - Test: [   20/   39]    Loss 5.450006    Top1 37.324219    Top5 87.519531    
2018-11-01 11:20:25,168 - Test: [   30/   39]    Loss 5.499946    Top1 36.445313    Top5 87.695312    
2018-11-01 11:20:25,265 - Test: [   40/   39]    Loss 5.500631    Top1 36.310000    Top5 87.470000    
2018-11-01 11:20:25,292 - ==> Top1: 36.310    Top5: 87.470    Loss: 5.501

2018-11-01 11:20:25,292 - Testing sensitivity of module.layer2.0.conv2.weight [90.0% sparsity]
2018-11-01 11:20:25,295 - L1RankedStructureParameterPruner - param: module.layer2.0.conv2.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 11:20:25,297 - --- test ---------------------
2018-11-01 11:20:25,297 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:25,725 - Test: [   10/   39]    Loss 5.315428    Top1 34.804688    Top5 85.703125    
2018-11-01 11:20:25,830 - Test: [   20/   39]    Loss 5.267579    Top1 35.058594    Top5 85.527344    
2018-11-01 11:20:25,933 - Test: [   30/   39]    Loss 5.328810    Top1 34.153646    Top5 85.651042    
2018-11-01 11:20:26,029 - Test: [   40/   39]    Loss 5.348487    Top1 34.080000    Top5 85.710000    
2018-11-01 11:20:26,055 - ==> Top1: 34.080    Top5: 85.710    Loss: 5.348

2018-11-01 11:20:26,071 - Testing sensitivity of module.layer2.0.downsample.0.weight [0.0% sparsity]
2018-11-01 11:20:26,075 - --- test ---------------------
2018-11-01 11:20:26,075 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:26,467 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:20:26,574 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:20:26,681 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:20:26,775 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:20:26,802 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:20:26,803 - Testing sensitivity of module.layer2.0.downsample.0.weight [5.0% sparsity]
2018-11-01 11:20:26,806 - Too few channels (16)- can't prune 5.0% channels
2018-11-01 11:20:26,807 - --- test ---------------------
2018-11-01 11:20:26,808 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:27,227 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:20:27,344 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:20:27,451 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:20:27,551 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:20:27,584 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:20:27,585 - Testing sensitivity of module.layer2.0.downsample.0.weight [10.0% sparsity]
2018-11-01 11:20:27,588 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.062 goal=0.100 (1/16)
2018-11-01 11:20:27,589 - --- test ---------------------
2018-11-01 11:20:27,589 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:28,054 - Test: [   10/   39]    Loss 0.546673    Top1 91.445312    Top5 99.531250    
2018-11-01 11:20:28,161 - Test: [   20/   39]    Loss 0.560476    Top1 91.328125    Top5 99.472656    
2018-11-01 11:20:28,265 - Test: [   30/   39]    Loss 0.555009    Top1 91.380208    Top5 99.596354    
2018-11-01 11:20:28,360 - Test: [   40/   39]    Loss 0.550359    Top1 91.370000    Top5 99.590000    
2018-11-01 11:20:28,385 - ==> Top1: 91.370    Top5: 99.590    Loss: 0.550

2018-11-01 11:20:28,386 - Testing sensitivity of module.layer2.0.downsample.0.weight [15.0% sparsity]
2018-11-01 11:20:28,388 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.125 goal=0.150 (2/16)
2018-11-01 11:20:28,389 - --- test ---------------------
2018-11-01 11:20:28,389 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:28,812 - Test: [   10/   39]    Loss 0.543575    Top1 91.250000    Top5 99.531250    
2018-11-01 11:20:28,917 - Test: [   20/   39]    Loss 0.558117    Top1 91.367188    Top5 99.492188    
2018-11-01 11:20:29,022 - Test: [   30/   39]    Loss 0.553383    Top1 91.341146    Top5 99.609375    
2018-11-01 11:20:29,117 - Test: [   40/   39]    Loss 0.551201    Top1 91.300000    Top5 99.600000    
2018-11-01 11:20:29,141 - ==> Top1: 91.300    Top5: 99.600    Loss: 0.551

2018-11-01 11:20:29,142 - Testing sensitivity of module.layer2.0.downsample.0.weight [20.0% sparsity]
2018-11-01 11:20:29,145 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.188 goal=0.200 (3/16)
2018-11-01 11:20:29,146 - --- test ---------------------
2018-11-01 11:20:29,146 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:29,574 - Test: [   10/   39]    Loss 0.548340    Top1 90.859375    Top5 99.531250    
2018-11-01 11:20:29,681 - Test: [   20/   39]    Loss 0.564629    Top1 91.054688    Top5 99.511719    
2018-11-01 11:20:29,785 - Test: [   30/   39]    Loss 0.561460    Top1 90.989583    Top5 99.609375    
2018-11-01 11:20:29,881 - Test: [   40/   39]    Loss 0.561726    Top1 90.980000    Top5 99.600000    
2018-11-01 11:20:29,907 - ==> Top1: 90.980    Top5: 99.600    Loss: 0.562

2018-11-01 11:20:29,908 - Testing sensitivity of module.layer2.0.downsample.0.weight [25.0% sparsity]
2018-11-01 11:20:29,910 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.250 goal=0.250 (4/16)
2018-11-01 11:20:29,910 - --- test ---------------------
2018-11-01 11:20:29,910 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:30,326 - Test: [   10/   39]    Loss 0.570317    Top1 90.820312    Top5 99.531250    
2018-11-01 11:20:30,432 - Test: [   20/   39]    Loss 0.588937    Top1 90.937500    Top5 99.492188    
2018-11-01 11:20:30,535 - Test: [   30/   39]    Loss 0.583843    Top1 90.872396    Top5 99.544271    
2018-11-01 11:20:30,630 - Test: [   40/   39]    Loss 0.584924    Top1 90.870000    Top5 99.550000    
2018-11-01 11:20:30,654 - ==> Top1: 90.870    Top5: 99.550    Loss: 0.585

2018-11-01 11:20:30,655 - Testing sensitivity of module.layer2.0.downsample.0.weight [30.0% sparsity]
2018-11-01 11:20:30,658 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.250 goal=0.300 (4/16)
2018-11-01 11:20:30,659 - --- test ---------------------
2018-11-01 11:20:30,659 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:31,095 - Test: [   10/   39]    Loss 0.570317    Top1 90.820312    Top5 99.531250    
2018-11-01 11:20:31,202 - Test: [   20/   39]    Loss 0.588937    Top1 90.937500    Top5 99.492188    
2018-11-01 11:20:31,307 - Test: [   30/   39]    Loss 0.583843    Top1 90.872396    Top5 99.544271    
2018-11-01 11:20:31,403 - Test: [   40/   39]    Loss 0.584924    Top1 90.870000    Top5 99.550000    
2018-11-01 11:20:31,428 - ==> Top1: 90.870    Top5: 99.550    Loss: 0.585

2018-11-01 11:20:31,428 - Testing sensitivity of module.layer2.0.downsample.0.weight [35.0% sparsity]
2018-11-01 11:20:31,431 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.312 goal=0.350 (5/16)
2018-11-01 11:20:31,432 - --- test ---------------------
2018-11-01 11:20:31,432 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:31,858 - Test: [   10/   39]    Loss 0.579892    Top1 90.585938    Top5 99.453125    
2018-11-01 11:20:31,964 - Test: [   20/   39]    Loss 0.602212    Top1 90.839844    Top5 99.472656    
2018-11-01 11:20:32,068 - Test: [   30/   39]    Loss 0.602004    Top1 90.690104    Top5 99.505208    
2018-11-01 11:20:32,163 - Test: [   40/   39]    Loss 0.597505    Top1 90.660000    Top5 99.520000    
2018-11-01 11:20:32,188 - ==> Top1: 90.660    Top5: 99.520    Loss: 0.598

2018-11-01 11:20:32,189 - Testing sensitivity of module.layer2.0.downsample.0.weight [40.0% sparsity]
2018-11-01 11:20:32,191 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.375 goal=0.400 (6/16)
2018-11-01 11:20:32,192 - --- test ---------------------
2018-11-01 11:20:32,192 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:32,613 - Test: [   10/   39]    Loss 0.648691    Top1 89.921875    Top5 99.492188    
2018-11-01 11:20:32,719 - Test: [   20/   39]    Loss 0.664219    Top1 89.960938    Top5 99.472656    
2018-11-01 11:20:32,823 - Test: [   30/   39]    Loss 0.660789    Top1 89.830729    Top5 99.505208    
2018-11-01 11:20:32,919 - Test: [   40/   39]    Loss 0.658838    Top1 89.720000    Top5 99.540000    
2018-11-01 11:20:32,919 - ==> Top1: 89.720    Top5: 99.540    Loss: 0.659

2018-11-01 11:20:32,923 - Testing sensitivity of module.layer2.0.downsample.0.weight [45.0% sparsity]
2018-11-01 11:20:32,925 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.438 goal=0.450 (7/16)
2018-11-01 11:20:32,926 - --- test ---------------------
2018-11-01 11:20:32,927 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:33,370 - Test: [   10/   39]    Loss 0.745051    Top1 88.242188    Top5 99.179688    
2018-11-01 11:20:33,484 - Test: [   20/   39]    Loss 0.792505    Top1 88.261719    Top5 99.023438    
2018-11-01 11:20:33,590 - Test: [   30/   39]    Loss 0.792446    Top1 88.190104    Top5 99.075521    
2018-11-01 11:20:33,685 - Test: [   40/   39]    Loss 0.772472    Top1 88.370000    Top5 99.130000    
2018-11-01 11:20:33,709 - ==> Top1: 88.370    Top5: 99.130    Loss: 0.772

2018-11-01 11:20:33,710 - Testing sensitivity of module.layer2.0.downsample.0.weight [50.0% sparsity]
2018-11-01 11:20:33,713 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.500 goal=0.500 (8/16)
2018-11-01 11:20:33,714 - --- test ---------------------
2018-11-01 11:20:33,715 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:34,132 - Test: [   10/   39]    Loss 0.827817    Top1 87.070312    Top5 98.945312    
2018-11-01 11:20:34,238 - Test: [   20/   39]    Loss 0.863786    Top1 87.031250    Top5 98.984375    
2018-11-01 11:20:34,342 - Test: [   30/   39]    Loss 0.868806    Top1 86.888021    Top5 99.075521    
2018-11-01 11:20:34,437 - Test: [   40/   39]    Loss 0.845905    Top1 87.080000    Top5 99.110000    
2018-11-01 11:20:34,462 - ==> Top1: 87.080    Top5: 99.110    Loss: 0.846

2018-11-01 11:20:34,463 - Testing sensitivity of module.layer2.0.downsample.0.weight [55.0% sparsity]
2018-11-01 11:20:34,466 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.500 goal=0.550 (8/16)
2018-11-01 11:20:34,467 - --- test ---------------------
2018-11-01 11:20:34,468 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:34,870 - Test: [   10/   39]    Loss 0.827817    Top1 87.070312    Top5 98.945312    
2018-11-01 11:20:34,975 - Test: [   20/   39]    Loss 0.863786    Top1 87.031250    Top5 98.984375    
2018-11-01 11:20:35,078 - Test: [   30/   39]    Loss 0.868806    Top1 86.888021    Top5 99.075521    
2018-11-01 11:20:35,174 - Test: [   40/   39]    Loss 0.845905    Top1 87.080000    Top5 99.110000    
2018-11-01 11:20:35,198 - ==> Top1: 87.080    Top5: 99.110    Loss: 0.846

2018-11-01 11:20:35,199 - Testing sensitivity of module.layer2.0.downsample.0.weight [60.0% sparsity]
2018-11-01 11:20:35,202 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.562 goal=0.600 (9/16)
2018-11-01 11:20:35,203 - --- test ---------------------
2018-11-01 11:20:35,204 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:35,628 - Test: [   10/   39]    Loss 1.034702    Top1 84.960938    Top5 98.515625    
2018-11-01 11:20:35,734 - Test: [   20/   39]    Loss 1.068785    Top1 84.453125    Top5 98.398438    
2018-11-01 11:20:35,838 - Test: [   30/   39]    Loss 1.064490    Top1 84.375000    Top5 98.502604    
2018-11-01 11:20:35,933 - Test: [   40/   39]    Loss 1.045128    Top1 84.720000    Top5 98.590000    
2018-11-01 11:20:35,959 - ==> Top1: 84.720    Top5: 98.590    Loss: 1.045

2018-11-01 11:20:35,959 - Testing sensitivity of module.layer2.0.downsample.0.weight [65.0% sparsity]
2018-11-01 11:20:35,961 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.625 goal=0.650 (10/16)
2018-11-01 11:20:35,962 - --- test ---------------------
2018-11-01 11:20:35,962 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:36,371 - Test: [   10/   39]    Loss 1.273226    Top1 82.148438    Top5 98.554688    
2018-11-01 11:20:36,476 - Test: [   20/   39]    Loss 1.301509    Top1 81.796875    Top5 98.359375    
2018-11-01 11:20:36,579 - Test: [   30/   39]    Loss 1.314852    Top1 81.979167    Top5 98.398438    
2018-11-01 11:20:36,673 - Test: [   40/   39]    Loss 1.300654    Top1 82.040000    Top5 98.430000    
2018-11-01 11:20:36,708 - ==> Top1: 82.040    Top5: 98.430    Loss: 1.301

2018-11-01 11:20:36,709 - Testing sensitivity of module.layer2.0.downsample.0.weight [70.0% sparsity]
2018-11-01 11:20:36,711 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.688 goal=0.700 (11/16)
2018-11-01 11:20:36,712 - --- test ---------------------
2018-11-01 11:20:36,712 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:37,135 - Test: [   10/   39]    Loss 1.586098    Top1 78.476562    Top5 97.812500    
2018-11-01 11:20:37,241 - Test: [   20/   39]    Loss 1.614617    Top1 78.457031    Top5 97.753906    
2018-11-01 11:20:37,345 - Test: [   30/   39]    Loss 1.652500    Top1 78.059896    Top5 97.773438    
2018-11-01 11:20:37,439 - Test: [   40/   39]    Loss 1.626892    Top1 78.290000    Top5 97.900000    
2018-11-01 11:20:37,464 - ==> Top1: 78.290    Top5: 97.900    Loss: 1.627

2018-11-01 11:20:37,466 - Testing sensitivity of module.layer2.0.downsample.0.weight [75.0% sparsity]
2018-11-01 11:20:37,469 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.750 goal=0.750 (12/16)
2018-11-01 11:20:37,470 - --- test ---------------------
2018-11-01 11:20:37,470 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:37,893 - Test: [   10/   39]    Loss 2.469356    Top1 69.140625    Top5 96.289062    
2018-11-01 11:20:38,003 - Test: [   20/   39]    Loss 2.512231    Top1 69.433594    Top5 95.820312    
2018-11-01 11:20:38,105 - Test: [   30/   39]    Loss 2.599068    Top1 68.932292    Top5 95.885417    
2018-11-01 11:20:38,200 - Test: [   40/   39]    Loss 2.589518    Top1 69.020000    Top5 95.870000    
2018-11-01 11:20:38,225 - ==> Top1: 69.020    Top5: 95.870    Loss: 2.590

2018-11-01 11:20:38,226 - Testing sensitivity of module.layer2.0.downsample.0.weight [80.0% sparsity]
2018-11-01 11:20:38,228 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.750 goal=0.800 (12/16)
2018-11-01 11:20:38,229 - --- test ---------------------
2018-11-01 11:20:38,230 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:38,658 - Test: [   10/   39]    Loss 2.469356    Top1 69.140625    Top5 96.289062    
2018-11-01 11:20:38,764 - Test: [   20/   39]    Loss 2.512231    Top1 69.433594    Top5 95.820312    
2018-11-01 11:20:38,867 - Test: [   30/   39]    Loss 2.599068    Top1 68.932292    Top5 95.885417    
2018-11-01 11:20:38,962 - Test: [   40/   39]    Loss 2.589518    Top1 69.020000    Top5 95.870000    
2018-11-01 11:20:38,987 - ==> Top1: 69.020    Top5: 95.870    Loss: 2.590

2018-11-01 11:20:38,987 - Testing sensitivity of module.layer2.0.downsample.0.weight [85.0% sparsity]
2018-11-01 11:20:38,990 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.812 goal=0.850 (13/16)
2018-11-01 11:20:38,991 - --- test ---------------------
2018-11-01 11:20:38,991 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:39,420 - Test: [   10/   39]    Loss 3.061718    Top1 64.296875    Top5 95.625000    
2018-11-01 11:20:39,525 - Test: [   20/   39]    Loss 3.077981    Top1 64.824219    Top5 95.019531    
2018-11-01 11:20:39,628 - Test: [   30/   39]    Loss 3.168706    Top1 64.492188    Top5 94.973958    
2018-11-01 11:20:39,724 - Test: [   40/   39]    Loss 3.166217    Top1 64.360000    Top5 94.780000    
2018-11-01 11:20:39,750 - ==> Top1: 64.360    Top5: 94.780    Loss: 3.166

2018-11-01 11:20:39,751 - Testing sensitivity of module.layer2.0.downsample.0.weight [90.0% sparsity]
2018-11-01 11:20:39,754 - L1RankedStructureParameterPruner - param: module.layer2.0.downsample.0.weight pruned=0.875 goal=0.900 (14/16)
2018-11-01 11:20:39,755 - --- test ---------------------
2018-11-01 11:20:39,756 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:40,177 - Test: [   10/   39]    Loss 9.195816    Top1 30.039063    Top5 72.929688    
2018-11-01 11:20:40,282 - Test: [   20/   39]    Loss 9.100804    Top1 30.078125    Top5 73.515625    
2018-11-01 11:20:40,386 - Test: [   30/   39]    Loss 9.181816    Top1 29.765625    Top5 73.684896    
2018-11-01 11:20:40,480 - Test: [   40/   39]    Loss 9.253113    Top1 29.520000    Top5 73.480000    
2018-11-01 11:20:40,504 - ==> Top1: 29.520    Top5: 73.480    Loss: 9.253

2018-11-01 11:20:40,519 - Testing sensitivity of module.layer2.1.conv1.weight [0.0% sparsity]
2018-11-01 11:20:40,523 - --- test ---------------------
2018-11-01 11:20:40,524 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:40,909 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:20:41,016 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:20:41,120 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:20:41,215 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:20:41,239 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:20:41,240 - Testing sensitivity of module.layer2.1.conv1.weight [5.0% sparsity]
2018-11-01 11:20:41,243 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 11:20:41,244 - --- test ---------------------
2018-11-01 11:20:41,244 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:41,662 - Test: [   10/   39]    Loss 0.555600    Top1 91.210938    Top5 99.687500    
2018-11-01 11:20:41,768 - Test: [   20/   39]    Loss 0.555956    Top1 91.523438    Top5 99.589844    
2018-11-01 11:20:41,871 - Test: [   30/   39]    Loss 0.548280    Top1 91.484375    Top5 99.674479    
2018-11-01 11:20:41,966 - Test: [   40/   39]    Loss 0.543650    Top1 91.500000    Top5 99.650000    
2018-11-01 11:20:41,990 - ==> Top1: 91.500    Top5: 99.650    Loss: 0.544

2018-11-01 11:20:41,991 - Testing sensitivity of module.layer2.1.conv1.weight [10.0% sparsity]
2018-11-01 11:20:41,994 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 11:20:41,995 - --- test ---------------------
2018-11-01 11:20:41,996 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:42,423 - Test: [   10/   39]    Loss 0.558747    Top1 90.937500    Top5 99.648438    
2018-11-01 11:20:42,529 - Test: [   20/   39]    Loss 0.561142    Top1 91.308594    Top5 99.550781    
2018-11-01 11:20:42,633 - Test: [   30/   39]    Loss 0.556906    Top1 91.197917    Top5 99.648438    
2018-11-01 11:20:42,728 - Test: [   40/   39]    Loss 0.550395    Top1 91.300000    Top5 99.630000    
2018-11-01 11:20:42,754 - ==> Top1: 91.300    Top5: 99.630    Loss: 0.550

2018-11-01 11:20:42,755 - Testing sensitivity of module.layer2.1.conv1.weight [15.0% sparsity]
2018-11-01 11:20:42,758 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 11:20:42,759 - --- test ---------------------
2018-11-01 11:20:42,759 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:43,198 - Test: [   10/   39]    Loss 0.559967    Top1 90.937500    Top5 99.648438    
2018-11-01 11:20:43,303 - Test: [   20/   39]    Loss 0.560565    Top1 91.250000    Top5 99.570312    
2018-11-01 11:20:43,407 - Test: [   30/   39]    Loss 0.557735    Top1 91.184896    Top5 99.648438    
2018-11-01 11:20:43,503 - Test: [   40/   39]    Loss 0.551764    Top1 91.220000    Top5 99.630000    
2018-11-01 11:20:43,528 - ==> Top1: 91.220    Top5: 99.630    Loss: 0.552

2018-11-01 11:20:43,529 - Testing sensitivity of module.layer2.1.conv1.weight [20.0% sparsity]
2018-11-01 11:20:43,533 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 11:20:43,534 - --- test ---------------------
2018-11-01 11:20:43,534 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:43,960 - Test: [   10/   39]    Loss 0.565288    Top1 90.742188    Top5 99.609375    
2018-11-01 11:20:44,067 - Test: [   20/   39]    Loss 0.567196    Top1 91.132812    Top5 99.589844    
2018-11-01 11:20:44,174 - Test: [   30/   39]    Loss 0.565958    Top1 91.067708    Top5 99.674479    
2018-11-01 11:20:44,271 - Test: [   40/   39]    Loss 0.559879    Top1 91.160000    Top5 99.640000    
2018-11-01 11:20:44,298 - ==> Top1: 91.160    Top5: 99.640    Loss: 0.560

2018-11-01 11:20:44,298 - Testing sensitivity of module.layer2.1.conv1.weight [25.0% sparsity]
2018-11-01 11:20:44,301 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 11:20:44,302 - --- test ---------------------
2018-11-01 11:20:44,302 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:44,727 - Test: [   10/   39]    Loss 0.581007    Top1 90.312500    Top5 99.570312    
2018-11-01 11:20:44,834 - Test: [   20/   39]    Loss 0.578112    Top1 90.761719    Top5 99.550781    
2018-11-01 11:20:44,937 - Test: [   30/   39]    Loss 0.578115    Top1 90.677083    Top5 99.635417    
2018-11-01 11:20:45,033 - Test: [   40/   39]    Loss 0.572585    Top1 90.810000    Top5 99.630000    
2018-11-01 11:20:45,058 - ==> Top1: 90.810    Top5: 99.630    Loss: 0.573

2018-11-01 11:20:45,059 - Testing sensitivity of module.layer2.1.conv1.weight [30.0% sparsity]
2018-11-01 11:20:45,062 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 11:20:45,063 - --- test ---------------------
2018-11-01 11:20:45,063 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:45,481 - Test: [   10/   39]    Loss 0.599789    Top1 89.882812    Top5 99.609375    
2018-11-01 11:20:45,588 - Test: [   20/   39]    Loss 0.602573    Top1 90.312500    Top5 99.550781    
2018-11-01 11:20:45,692 - Test: [   30/   39]    Loss 0.606383    Top1 90.260417    Top5 99.622396    
2018-11-01 11:20:45,787 - Test: [   40/   39]    Loss 0.599019    Top1 90.300000    Top5 99.630000    
2018-11-01 11:20:45,812 - ==> Top1: 90.300    Top5: 99.630    Loss: 0.599

2018-11-01 11:20:45,813 - Testing sensitivity of module.layer2.1.conv1.weight [35.0% sparsity]
2018-11-01 11:20:45,816 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 11:20:45,817 - --- test ---------------------
2018-11-01 11:20:45,817 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:46,244 - Test: [   10/   39]    Loss 0.615831    Top1 89.609375    Top5 99.648438    
2018-11-01 11:20:46,350 - Test: [   20/   39]    Loss 0.625482    Top1 89.941406    Top5 99.550781    
2018-11-01 11:20:46,454 - Test: [   30/   39]    Loss 0.627430    Top1 89.765625    Top5 99.609375    
2018-11-01 11:20:46,549 - Test: [   40/   39]    Loss 0.619231    Top1 89.960000    Top5 99.590000    
2018-11-01 11:20:46,574 - ==> Top1: 89.960    Top5: 99.590    Loss: 0.619

2018-11-01 11:20:46,575 - Testing sensitivity of module.layer2.1.conv1.weight [40.0% sparsity]
2018-11-01 11:20:46,578 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 11:20:46,579 - --- test ---------------------
2018-11-01 11:20:46,579 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:47,005 - Test: [   10/   39]    Loss 0.623974    Top1 89.648438    Top5 99.648438    
2018-11-01 11:20:47,111 - Test: [   20/   39]    Loss 0.639056    Top1 89.765625    Top5 99.492188    
2018-11-01 11:20:47,215 - Test: [   30/   39]    Loss 0.642016    Top1 89.518229    Top5 99.583333    
2018-11-01 11:20:47,311 - Test: [   40/   39]    Loss 0.632894    Top1 89.620000    Top5 99.570000    
2018-11-01 11:20:47,336 - ==> Top1: 89.620    Top5: 99.570    Loss: 0.633

2018-11-01 11:20:47,337 - Testing sensitivity of module.layer2.1.conv1.weight [45.0% sparsity]
2018-11-01 11:20:47,340 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 11:20:47,341 - --- test ---------------------
2018-11-01 11:20:47,341 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:47,763 - Test: [   10/   39]    Loss 0.637001    Top1 89.414062    Top5 99.453125    
2018-11-01 11:20:47,868 - Test: [   20/   39]    Loss 0.653415    Top1 89.472656    Top5 99.375000    
2018-11-01 11:20:47,971 - Test: [   30/   39]    Loss 0.663442    Top1 89.309896    Top5 99.479167    
2018-11-01 11:20:48,065 - Test: [   40/   39]    Loss 0.654281    Top1 89.400000    Top5 99.480000    
2018-11-01 11:20:48,090 - ==> Top1: 89.400    Top5: 99.480    Loss: 0.654

2018-11-01 11:20:48,090 - Testing sensitivity of module.layer2.1.conv1.weight [50.0% sparsity]
2018-11-01 11:20:48,092 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 11:20:48,093 - --- test ---------------------
2018-11-01 11:20:48,093 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:48,517 - Test: [   10/   39]    Loss 0.698099    Top1 88.164062    Top5 99.375000    
2018-11-01 11:20:48,622 - Test: [   20/   39]    Loss 0.715857    Top1 88.457031    Top5 99.218750    
2018-11-01 11:20:48,726 - Test: [   30/   39]    Loss 0.726171    Top1 88.437500    Top5 99.322917    
2018-11-01 11:20:48,821 - Test: [   40/   39]    Loss 0.717641    Top1 88.450000    Top5 99.320000    
2018-11-01 11:20:48,846 - ==> Top1: 88.450    Top5: 99.320    Loss: 0.718

2018-11-01 11:20:48,847 - Testing sensitivity of module.layer2.1.conv1.weight [55.0% sparsity]
2018-11-01 11:20:48,850 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 11:20:48,852 - --- test ---------------------
2018-11-01 11:20:48,852 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:49,271 - Test: [   10/   39]    Loss 0.701463    Top1 88.437500    Top5 99.531250    
2018-11-01 11:20:49,377 - Test: [   20/   39]    Loss 0.705393    Top1 88.476562    Top5 99.375000    
2018-11-01 11:20:49,480 - Test: [   30/   39]    Loss 0.712946    Top1 88.320312    Top5 99.427083    
2018-11-01 11:20:49,575 - Test: [   40/   39]    Loss 0.707932    Top1 88.360000    Top5 99.400000    
2018-11-01 11:20:49,600 - ==> Top1: 88.360    Top5: 99.400    Loss: 0.708

2018-11-01 11:20:49,601 - Testing sensitivity of module.layer2.1.conv1.weight [60.0% sparsity]
2018-11-01 11:20:49,604 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 11:20:49,605 - --- test ---------------------
2018-11-01 11:20:49,605 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:50,026 - Test: [   10/   39]    Loss 0.791010    Top1 87.187500    Top5 99.375000    
2018-11-01 11:20:50,132 - Test: [   20/   39]    Loss 0.796660    Top1 87.363281    Top5 99.179688    
2018-11-01 11:20:50,236 - Test: [   30/   39]    Loss 0.802803    Top1 87.148438    Top5 99.296875    
2018-11-01 11:20:50,332 - Test: [   40/   39]    Loss 0.791611    Top1 87.150000    Top5 99.260000    
2018-11-01 11:20:50,357 - ==> Top1: 87.150    Top5: 99.260    Loss: 0.792

2018-11-01 11:20:50,359 - Testing sensitivity of module.layer2.1.conv1.weight [65.0% sparsity]
2018-11-01 11:20:50,361 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 11:20:50,362 - --- test ---------------------
2018-11-01 11:20:50,363 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:50,786 - Test: [   10/   39]    Loss 0.844729    Top1 86.367188    Top5 99.257812    
2018-11-01 11:20:50,893 - Test: [   20/   39]    Loss 0.857563    Top1 86.347656    Top5 99.042969    
2018-11-01 11:20:50,996 - Test: [   30/   39]    Loss 0.873163    Top1 86.119792    Top5 99.166667    
2018-11-01 11:20:51,091 - Test: [   40/   39]    Loss 0.860964    Top1 86.160000    Top5 99.170000    
2018-11-01 11:20:51,117 - ==> Top1: 86.160    Top5: 99.170    Loss: 0.861

2018-11-01 11:20:51,117 - Testing sensitivity of module.layer2.1.conv1.weight [70.0% sparsity]
2018-11-01 11:20:51,120 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 11:20:51,121 - --- test ---------------------
2018-11-01 11:20:51,122 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:51,541 - Test: [   10/   39]    Loss 0.940821    Top1 85.273438    Top5 99.257812    
2018-11-01 11:20:51,646 - Test: [   20/   39]    Loss 0.958115    Top1 85.117188    Top5 98.964844    
2018-11-01 11:20:51,748 - Test: [   30/   39]    Loss 0.986559    Top1 84.726562    Top5 99.036458    
2018-11-01 11:20:51,843 - Test: [   40/   39]    Loss 0.970489    Top1 84.680000    Top5 99.030000    
2018-11-01 11:20:51,867 - ==> Top1: 84.680    Top5: 99.030    Loss: 0.970

2018-11-01 11:20:51,868 - Testing sensitivity of module.layer2.1.conv1.weight [75.0% sparsity]
2018-11-01 11:20:51,870 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 11:20:51,871 - --- test ---------------------
2018-11-01 11:20:51,871 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:52,298 - Test: [   10/   39]    Loss 1.346210    Top1 80.781250    Top5 98.828125    
2018-11-01 11:20:52,404 - Test: [   20/   39]    Loss 1.337656    Top1 80.449219    Top5 98.574219    
2018-11-01 11:20:52,507 - Test: [   30/   39]    Loss 1.378419    Top1 80.000000    Top5 98.554688    
2018-11-01 11:20:52,603 - Test: [   40/   39]    Loss 1.372927    Top1 79.830000    Top5 98.510000    
2018-11-01 11:20:52,628 - ==> Top1: 79.830    Top5: 98.510    Loss: 1.373

2018-11-01 11:20:52,629 - Testing sensitivity of module.layer2.1.conv1.weight [80.0% sparsity]
2018-11-01 11:20:52,632 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 11:20:52,633 - --- test ---------------------
2018-11-01 11:20:52,633 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:53,061 - Test: [   10/   39]    Loss 1.441652    Top1 79.882812    Top5 98.515625    
2018-11-01 11:20:53,167 - Test: [   20/   39]    Loss 1.442356    Top1 79.082031    Top5 98.261719    
2018-11-01 11:20:53,271 - Test: [   30/   39]    Loss 1.483412    Top1 78.619792    Top5 98.229167    
2018-11-01 11:20:53,366 - Test: [   40/   39]    Loss 1.473539    Top1 78.410000    Top5 98.270000    
2018-11-01 11:20:53,391 - ==> Top1: 78.410    Top5: 98.270    Loss: 1.474

2018-11-01 11:20:53,393 - Testing sensitivity of module.layer2.1.conv1.weight [85.0% sparsity]
2018-11-01 11:20:53,395 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 11:20:53,397 - --- test ---------------------
2018-11-01 11:20:53,397 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:53,825 - Test: [   10/   39]    Loss 1.977913    Top1 72.929688    Top5 97.226562    
2018-11-01 11:20:53,932 - Test: [   20/   39]    Loss 2.036443    Top1 71.250000    Top5 96.914062    
2018-11-01 11:20:54,039 - Test: [   30/   39]    Loss 2.100066    Top1 70.781250    Top5 96.901042    
2018-11-01 11:20:54,137 - Test: [   40/   39]    Loss 2.102351    Top1 70.800000    Top5 97.000000    
2018-11-01 11:20:54,161 - ==> Top1: 70.800    Top5: 97.000    Loss: 2.102

2018-11-01 11:20:54,162 - Testing sensitivity of module.layer2.1.conv1.weight [90.0% sparsity]
2018-11-01 11:20:54,165 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 11:20:54,166 - --- test ---------------------
2018-11-01 11:20:54,167 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:54,608 - Test: [   10/   39]    Loss 2.364219    Top1 69.218750    Top5 96.406250    
2018-11-01 11:20:54,715 - Test: [   20/   39]    Loss 2.459575    Top1 67.734375    Top5 96.250000    
2018-11-01 11:20:54,819 - Test: [   30/   39]    Loss 2.526374    Top1 67.161458    Top5 96.002604    
2018-11-01 11:20:54,914 - Test: [   40/   39]    Loss 2.547695    Top1 67.180000    Top5 96.130000    
2018-11-01 11:20:54,939 - ==> Top1: 67.180    Top5: 96.130    Loss: 2.548

2018-11-01 11:20:54,955 - Testing sensitivity of module.layer2.1.conv2.weight [0.0% sparsity]
2018-11-01 11:20:54,959 - --- test ---------------------
2018-11-01 11:20:54,960 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:55,376 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:20:55,483 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:20:55,587 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:20:55,685 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:20:55,685 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:20:55,712 - Testing sensitivity of module.layer2.1.conv2.weight [5.0% sparsity]
2018-11-01 11:20:55,715 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 11:20:55,716 - --- test ---------------------
2018-11-01 11:20:55,717 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:56,155 - Test: [   10/   39]    Loss 0.560201    Top1 91.171875    Top5 99.726562    
2018-11-01 11:20:56,263 - Test: [   20/   39]    Loss 0.557955    Top1 91.386719    Top5 99.609375    
2018-11-01 11:20:56,366 - Test: [   30/   39]    Loss 0.553242    Top1 91.302083    Top5 99.674479    
2018-11-01 11:20:56,462 - Test: [   40/   39]    Loss 0.549742    Top1 91.320000    Top5 99.660000    
2018-11-01 11:20:56,488 - ==> Top1: 91.320    Top5: 99.660    Loss: 0.550

2018-11-01 11:20:56,488 - Testing sensitivity of module.layer2.1.conv2.weight [10.0% sparsity]
2018-11-01 11:20:56,491 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 11:20:56,492 - --- test ---------------------
2018-11-01 11:20:56,492 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:57,035 - Test: [   10/   39]    Loss 0.565679    Top1 91.132812    Top5 99.609375    
2018-11-01 11:20:57,142 - Test: [   20/   39]    Loss 0.570091    Top1 91.171875    Top5 99.570312    
2018-11-01 11:20:57,246 - Test: [   30/   39]    Loss 0.567081    Top1 91.015625    Top5 99.635417    
2018-11-01 11:20:57,342 - Test: [   40/   39]    Loss 0.563450    Top1 91.010000    Top5 99.630000    
2018-11-01 11:20:57,370 - ==> Top1: 91.010    Top5: 99.630    Loss: 0.563

2018-11-01 11:20:57,370 - Testing sensitivity of module.layer2.1.conv2.weight [15.0% sparsity]
2018-11-01 11:20:57,373 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 11:20:57,374 - --- test ---------------------
2018-11-01 11:20:57,374 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:57,912 - Test: [   10/   39]    Loss 0.563084    Top1 91.015625    Top5 99.570312    
2018-11-01 11:20:58,021 - Test: [   20/   39]    Loss 0.565629    Top1 91.152344    Top5 99.531250    
2018-11-01 11:20:58,126 - Test: [   30/   39]    Loss 0.564809    Top1 90.989583    Top5 99.609375    
2018-11-01 11:20:58,221 - Test: [   40/   39]    Loss 0.563686    Top1 90.970000    Top5 99.610000    
2018-11-01 11:20:58,252 - ==> Top1: 90.970    Top5: 99.610    Loss: 0.564

2018-11-01 11:20:58,253 - Testing sensitivity of module.layer2.1.conv2.weight [20.0% sparsity]
2018-11-01 11:20:58,255 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 11:20:58,256 - --- test ---------------------
2018-11-01 11:20:58,257 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:58,704 - Test: [   10/   39]    Loss 0.581524    Top1 90.703125    Top5 99.570312    
2018-11-01 11:20:58,811 - Test: [   20/   39]    Loss 0.582395    Top1 90.937500    Top5 99.511719    
2018-11-01 11:20:58,916 - Test: [   30/   39]    Loss 0.582090    Top1 90.781250    Top5 99.596354    
2018-11-01 11:20:59,013 - Test: [   40/   39]    Loss 0.578748    Top1 90.800000    Top5 99.590000    
2018-11-01 11:20:59,037 - ==> Top1: 90.800    Top5: 99.590    Loss: 0.579

2018-11-01 11:20:59,037 - Testing sensitivity of module.layer2.1.conv2.weight [25.0% sparsity]
2018-11-01 11:20:59,041 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 11:20:59,042 - --- test ---------------------
2018-11-01 11:20:59,042 - 10000 samples (256 per mini-batch)
2018-11-01 11:20:59,475 - Test: [   10/   39]    Loss 0.616312    Top1 89.765625    Top5 99.414062    
2018-11-01 11:20:59,582 - Test: [   20/   39]    Loss 0.618842    Top1 90.000000    Top5 99.394531    
2018-11-01 11:20:59,685 - Test: [   30/   39]    Loss 0.622378    Top1 89.817708    Top5 99.505208    
2018-11-01 11:20:59,782 - Test: [   40/   39]    Loss 0.613163    Top1 90.020000    Top5 99.490000    
2018-11-01 11:20:59,807 - ==> Top1: 90.020    Top5: 99.490    Loss: 0.613

2018-11-01 11:20:59,807 - Testing sensitivity of module.layer2.1.conv2.weight [30.0% sparsity]
2018-11-01 11:20:59,811 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 11:20:59,813 - --- test ---------------------
2018-11-01 11:20:59,813 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:00,244 - Test: [   10/   39]    Loss 0.634730    Top1 89.609375    Top5 99.375000    
2018-11-01 11:21:00,350 - Test: [   20/   39]    Loss 0.629443    Top1 89.863281    Top5 99.394531    
2018-11-01 11:21:00,457 - Test: [   30/   39]    Loss 0.628197    Top1 89.830729    Top5 99.492188    
2018-11-01 11:21:00,554 - Test: [   40/   39]    Loss 0.619655    Top1 90.030000    Top5 99.470000    
2018-11-01 11:21:00,579 - ==> Top1: 90.030    Top5: 99.470    Loss: 0.620

2018-11-01 11:21:00,580 - Testing sensitivity of module.layer2.1.conv2.weight [35.0% sparsity]
2018-11-01 11:21:00,583 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 11:21:00,585 - --- test ---------------------
2018-11-01 11:21:00,585 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:01,008 - Test: [   10/   39]    Loss 0.665197    Top1 89.179688    Top5 99.492188    
2018-11-01 11:21:01,115 - Test: [   20/   39]    Loss 0.658351    Top1 89.511719    Top5 99.492188    
2018-11-01 11:21:01,219 - Test: [   30/   39]    Loss 0.656374    Top1 89.375000    Top5 99.544271    
2018-11-01 11:21:01,318 - Test: [   40/   39]    Loss 0.643146    Top1 89.530000    Top5 99.560000    
2018-11-01 11:21:01,343 - ==> Top1: 89.530    Top5: 99.560    Loss: 0.643

2018-11-01 11:21:01,344 - Testing sensitivity of module.layer2.1.conv2.weight [40.0% sparsity]
2018-11-01 11:21:01,346 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 11:21:01,346 - --- test ---------------------
2018-11-01 11:21:01,347 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:01,765 - Test: [   10/   39]    Loss 0.719533    Top1 88.554688    Top5 99.492188    
2018-11-01 11:21:01,870 - Test: [   20/   39]    Loss 0.710133    Top1 88.710938    Top5 99.453125    
2018-11-01 11:21:01,975 - Test: [   30/   39]    Loss 0.703351    Top1 88.684896    Top5 99.505208    
2018-11-01 11:21:02,070 - Test: [   40/   39]    Loss 0.683895    Top1 88.830000    Top5 99.480000    
2018-11-01 11:21:02,103 - ==> Top1: 88.830    Top5: 99.480    Loss: 0.684

2018-11-01 11:21:02,104 - Testing sensitivity of module.layer2.1.conv2.weight [45.0% sparsity]
2018-11-01 11:21:02,106 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 11:21:02,107 - --- test ---------------------
2018-11-01 11:21:02,108 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:02,539 - Test: [   10/   39]    Loss 0.760676    Top1 87.734375    Top5 99.375000    
2018-11-01 11:21:02,648 - Test: [   20/   39]    Loss 0.750984    Top1 88.046875    Top5 99.238281    
2018-11-01 11:21:02,752 - Test: [   30/   39]    Loss 0.743043    Top1 87.903646    Top5 99.335938    
2018-11-01 11:21:02,849 - Test: [   40/   39]    Loss 0.722542    Top1 88.120000    Top5 99.330000    
2018-11-01 11:21:02,875 - ==> Top1: 88.120    Top5: 99.330    Loss: 0.723

2018-11-01 11:21:02,875 - Testing sensitivity of module.layer2.1.conv2.weight [50.0% sparsity]
2018-11-01 11:21:02,878 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 11:21:02,879 - --- test ---------------------
2018-11-01 11:21:02,879 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:03,314 - Test: [   10/   39]    Loss 0.856172    Top1 86.289062    Top5 99.218750    
2018-11-01 11:21:03,421 - Test: [   20/   39]    Loss 0.849330    Top1 86.523438    Top5 99.121094    
2018-11-01 11:21:03,525 - Test: [   30/   39]    Loss 0.841250    Top1 86.627604    Top5 99.166667    
2018-11-01 11:21:03,621 - Test: [   40/   39]    Loss 0.812498    Top1 86.840000    Top5 99.170000    
2018-11-01 11:21:03,646 - ==> Top1: 86.840    Top5: 99.170    Loss: 0.812

2018-11-01 11:21:03,647 - Testing sensitivity of module.layer2.1.conv2.weight [55.0% sparsity]
2018-11-01 11:21:03,650 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 11:21:03,651 - --- test ---------------------
2018-11-01 11:21:03,651 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:04,083 - Test: [   10/   39]    Loss 0.879372    Top1 85.898438    Top5 99.218750    
2018-11-01 11:21:04,188 - Test: [   20/   39]    Loss 0.869326    Top1 86.308594    Top5 99.101562    
2018-11-01 11:21:04,291 - Test: [   30/   39]    Loss 0.861823    Top1 86.210938    Top5 99.153646    
2018-11-01 11:21:04,385 - Test: [   40/   39]    Loss 0.838306    Top1 86.510000    Top5 99.170000    
2018-11-01 11:21:04,410 - ==> Top1: 86.510    Top5: 99.170    Loss: 0.838

2018-11-01 11:21:04,411 - Testing sensitivity of module.layer2.1.conv2.weight [60.0% sparsity]
2018-11-01 11:21:04,413 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 11:21:04,414 - --- test ---------------------
2018-11-01 11:21:04,414 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:04,836 - Test: [   10/   39]    Loss 0.927367    Top1 85.585938    Top5 99.179688    
2018-11-01 11:21:04,945 - Test: [   20/   39]    Loss 0.920593    Top1 85.703125    Top5 99.042969    
2018-11-01 11:21:05,050 - Test: [   30/   39]    Loss 0.922496    Top1 85.546875    Top5 99.114583    
2018-11-01 11:21:05,145 - Test: [   40/   39]    Loss 0.898147    Top1 85.720000    Top5 99.050000    
2018-11-01 11:21:05,171 - ==> Top1: 85.720    Top5: 99.050    Loss: 0.898

2018-11-01 11:21:05,172 - Testing sensitivity of module.layer2.1.conv2.weight [65.0% sparsity]
2018-11-01 11:21:05,175 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 11:21:05,177 - --- test ---------------------
2018-11-01 11:21:05,177 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:05,623 - Test: [   10/   39]    Loss 0.932293    Top1 85.429688    Top5 99.140625    
2018-11-01 11:21:05,729 - Test: [   20/   39]    Loss 0.919243    Top1 85.664062    Top5 99.023438    
2018-11-01 11:21:05,833 - Test: [   30/   39]    Loss 0.925638    Top1 85.364583    Top5 99.114583    
2018-11-01 11:21:05,929 - Test: [   40/   39]    Loss 0.900378    Top1 85.680000    Top5 99.070000    
2018-11-01 11:21:05,955 - ==> Top1: 85.680    Top5: 99.070    Loss: 0.900

2018-11-01 11:21:05,955 - Testing sensitivity of module.layer2.1.conv2.weight [70.0% sparsity]
2018-11-01 11:21:05,958 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 11:21:05,959 - --- test ---------------------
2018-11-01 11:21:05,959 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:06,402 - Test: [   10/   39]    Loss 1.108729    Top1 82.929688    Top5 98.515625    
2018-11-01 11:21:06,510 - Test: [   20/   39]    Loss 1.113160    Top1 82.910156    Top5 98.496094    
2018-11-01 11:21:06,615 - Test: [   30/   39]    Loss 1.137339    Top1 82.539062    Top5 98.567708    
2018-11-01 11:21:06,712 - Test: [   40/   39]    Loss 1.109944    Top1 82.550000    Top5 98.550000    
2018-11-01 11:21:06,736 - ==> Top1: 82.550    Top5: 98.550    Loss: 1.110

2018-11-01 11:21:06,737 - Testing sensitivity of module.layer2.1.conv2.weight [75.0% sparsity]
2018-11-01 11:21:06,740 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 11:21:06,741 - --- test ---------------------
2018-11-01 11:21:06,741 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:07,185 - Test: [   10/   39]    Loss 1.211624    Top1 81.640625    Top5 98.281250    
2018-11-01 11:21:07,291 - Test: [   20/   39]    Loss 1.218013    Top1 81.386719    Top5 98.222656    
2018-11-01 11:21:07,397 - Test: [   30/   39]    Loss 1.238770    Top1 80.963542    Top5 98.372396    
2018-11-01 11:21:07,493 - Test: [   40/   39]    Loss 1.210357    Top1 81.040000    Top5 98.410000    
2018-11-01 11:21:07,519 - ==> Top1: 81.040    Top5: 98.410    Loss: 1.210

2018-11-01 11:21:07,519 - Testing sensitivity of module.layer2.1.conv2.weight [80.0% sparsity]
2018-11-01 11:21:07,522 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 11:21:07,523 - --- test ---------------------
2018-11-01 11:21:07,524 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:07,961 - Test: [   10/   39]    Loss 1.245763    Top1 80.664062    Top5 97.890625    
2018-11-01 11:21:08,067 - Test: [   20/   39]    Loss 1.253547    Top1 80.566406    Top5 97.968750    
2018-11-01 11:21:08,171 - Test: [   30/   39]    Loss 1.269123    Top1 80.403646    Top5 98.138021    
2018-11-01 11:21:08,268 - Test: [   40/   39]    Loss 1.239097    Top1 80.450000    Top5 98.200000    
2018-11-01 11:21:08,294 - ==> Top1: 80.450    Top5: 98.200    Loss: 1.239

2018-11-01 11:21:08,294 - Testing sensitivity of module.layer2.1.conv2.weight [85.0% sparsity]
2018-11-01 11:21:08,298 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 11:21:08,299 - --- test ---------------------
2018-11-01 11:21:08,299 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:08,742 - Test: [   10/   39]    Loss 1.566119    Top1 76.250000    Top5 97.382812    
2018-11-01 11:21:08,849 - Test: [   20/   39]    Loss 1.592267    Top1 75.839844    Top5 97.226562    
2018-11-01 11:21:08,952 - Test: [   30/   39]    Loss 1.599078    Top1 75.716146    Top5 97.382812    
2018-11-01 11:21:09,050 - Test: [   40/   39]    Loss 1.581855    Top1 75.730000    Top5 97.480000    
2018-11-01 11:21:09,076 - ==> Top1: 75.730    Top5: 97.480    Loss: 1.582

2018-11-01 11:21:09,077 - Testing sensitivity of module.layer2.1.conv2.weight [90.0% sparsity]
2018-11-01 11:21:09,080 - L1RankedStructureParameterPruner - param: module.layer2.1.conv2.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 11:21:09,081 - --- test ---------------------
2018-11-01 11:21:09,081 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:09,508 - Test: [   10/   39]    Loss 1.699250    Top1 74.804688    Top5 97.343750    
2018-11-01 11:21:09,614 - Test: [   20/   39]    Loss 1.734798    Top1 73.808594    Top5 96.953125    
2018-11-01 11:21:09,717 - Test: [   30/   39]    Loss 1.750643    Top1 73.437500    Top5 97.057292    
2018-11-01 11:21:09,812 - Test: [   40/   39]    Loss 1.740160    Top1 73.580000    Top5 97.220000    
2018-11-01 11:21:09,837 - ==> Top1: 73.580    Top5: 97.220    Loss: 1.740

2018-11-01 11:21:09,850 - Testing sensitivity of module.layer2.2.conv1.weight [0.0% sparsity]
2018-11-01 11:21:09,854 - --- test ---------------------
2018-11-01 11:21:09,854 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:10,284 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:21:10,390 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:21:10,493 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:21:10,589 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:21:10,614 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:21:10,616 - Testing sensitivity of module.layer2.2.conv1.weight [5.0% sparsity]
2018-11-01 11:21:10,618 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 11:21:10,619 - --- test ---------------------
2018-11-01 11:21:10,619 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:11,047 - Test: [   10/   39]    Loss 0.558811    Top1 90.820312    Top5 99.687500    
2018-11-01 11:21:11,154 - Test: [   20/   39]    Loss 0.553924    Top1 91.152344    Top5 99.589844    
2018-11-01 11:21:11,258 - Test: [   30/   39]    Loss 0.549070    Top1 91.158854    Top5 99.674479    
2018-11-01 11:21:11,354 - Test: [   40/   39]    Loss 0.544642    Top1 91.260000    Top5 99.670000    
2018-11-01 11:21:11,380 - ==> Top1: 91.260    Top5: 99.670    Loss: 0.545

2018-11-01 11:21:11,381 - Testing sensitivity of module.layer2.2.conv1.weight [10.0% sparsity]
2018-11-01 11:21:11,384 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 11:21:11,385 - --- test ---------------------
2018-11-01 11:21:11,386 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:11,814 - Test: [   10/   39]    Loss 0.577060    Top1 90.468750    Top5 99.648438    
2018-11-01 11:21:11,918 - Test: [   20/   39]    Loss 0.575316    Top1 90.761719    Top5 99.531250    
2018-11-01 11:21:12,021 - Test: [   30/   39]    Loss 0.567574    Top1 90.859375    Top5 99.622396    
2018-11-01 11:21:12,115 - Test: [   40/   39]    Loss 0.562931    Top1 91.080000    Top5 99.610000    
2018-11-01 11:21:12,140 - ==> Top1: 91.080    Top5: 99.610    Loss: 0.563

2018-11-01 11:21:12,142 - Testing sensitivity of module.layer2.2.conv1.weight [15.0% sparsity]
2018-11-01 11:21:12,147 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 11:21:12,149 - --- test ---------------------
2018-11-01 11:21:12,150 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:12,575 - Test: [   10/   39]    Loss 0.605886    Top1 90.468750    Top5 99.531250    
2018-11-01 11:21:12,681 - Test: [   20/   39]    Loss 0.603029    Top1 90.546875    Top5 99.414062    
2018-11-01 11:21:12,784 - Test: [   30/   39]    Loss 0.594154    Top1 90.703125    Top5 99.531250    
2018-11-01 11:21:12,878 - Test: [   40/   39]    Loss 0.585717    Top1 90.860000    Top5 99.540000    
2018-11-01 11:21:12,904 - ==> Top1: 90.860    Top5: 99.540    Loss: 0.586

2018-11-01 11:21:12,905 - Testing sensitivity of module.layer2.2.conv1.weight [20.0% sparsity]
2018-11-01 11:21:12,907 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 11:21:12,908 - --- test ---------------------
2018-11-01 11:21:12,909 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:13,325 - Test: [   10/   39]    Loss 0.635532    Top1 89.960938    Top5 99.375000    
2018-11-01 11:21:13,431 - Test: [   20/   39]    Loss 0.644825    Top1 90.136719    Top5 99.414062    
2018-11-01 11:21:13,535 - Test: [   30/   39]    Loss 0.636154    Top1 90.221354    Top5 99.518229    
2018-11-01 11:21:13,630 - Test: [   40/   39]    Loss 0.619312    Top1 90.320000    Top5 99.520000    
2018-11-01 11:21:13,656 - ==> Top1: 90.320    Top5: 99.520    Loss: 0.619

2018-11-01 11:21:13,656 - Testing sensitivity of module.layer2.2.conv1.weight [25.0% sparsity]
2018-11-01 11:21:13,659 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 11:21:13,660 - --- test ---------------------
2018-11-01 11:21:13,660 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:14,085 - Test: [   10/   39]    Loss 0.656880    Top1 89.687500    Top5 99.375000    
2018-11-01 11:21:14,190 - Test: [   20/   39]    Loss 0.661594    Top1 89.824219    Top5 99.414062    
2018-11-01 11:21:14,292 - Test: [   30/   39]    Loss 0.657355    Top1 89.921875    Top5 99.518229    
2018-11-01 11:21:14,387 - Test: [   40/   39]    Loss 0.638400    Top1 90.110000    Top5 99.530000    
2018-11-01 11:21:14,412 - ==> Top1: 90.110    Top5: 99.530    Loss: 0.638

2018-11-01 11:21:14,413 - Testing sensitivity of module.layer2.2.conv1.weight [30.0% sparsity]
2018-11-01 11:21:14,416 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 11:21:14,417 - --- test ---------------------
2018-11-01 11:21:14,417 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:14,835 - Test: [   10/   39]    Loss 0.688533    Top1 89.218750    Top5 99.414062    
2018-11-01 11:21:14,940 - Test: [   20/   39]    Loss 0.695465    Top1 89.492188    Top5 99.394531    
2018-11-01 11:21:15,045 - Test: [   30/   39]    Loss 0.691654    Top1 89.427083    Top5 99.505208    
2018-11-01 11:21:15,141 - Test: [   40/   39]    Loss 0.674911    Top1 89.630000    Top5 99.520000    
2018-11-01 11:21:15,165 - ==> Top1: 89.630    Top5: 99.520    Loss: 0.675

2018-11-01 11:21:15,166 - Testing sensitivity of module.layer2.2.conv1.weight [35.0% sparsity]
2018-11-01 11:21:15,169 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 11:21:15,170 - --- test ---------------------
2018-11-01 11:21:15,170 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:15,592 - Test: [   10/   39]    Loss 0.814828    Top1 87.460938    Top5 99.218750    
2018-11-01 11:21:15,699 - Test: [   20/   39]    Loss 0.811321    Top1 87.832031    Top5 99.179688    
2018-11-01 11:21:15,802 - Test: [   30/   39]    Loss 0.800362    Top1 87.851562    Top5 99.322917    
2018-11-01 11:21:15,898 - Test: [   40/   39]    Loss 0.778336    Top1 88.100000    Top5 99.370000    
2018-11-01 11:21:15,923 - ==> Top1: 88.100    Top5: 99.370    Loss: 0.778

2018-11-01 11:21:15,924 - Testing sensitivity of module.layer2.2.conv1.weight [40.0% sparsity]
2018-11-01 11:21:15,927 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 11:21:15,928 - --- test ---------------------
2018-11-01 11:21:15,928 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:16,372 - Test: [   10/   39]    Loss 0.774939    Top1 87.851562    Top5 99.257812    
2018-11-01 11:21:16,478 - Test: [   20/   39]    Loss 0.773180    Top1 88.320312    Top5 99.238281    
2018-11-01 11:21:16,583 - Test: [   30/   39]    Loss 0.763994    Top1 88.320312    Top5 99.348958    
2018-11-01 11:21:16,678 - Test: [   40/   39]    Loss 0.743249    Top1 88.500000    Top5 99.390000    
2018-11-01 11:21:16,702 - ==> Top1: 88.500    Top5: 99.390    Loss: 0.743

2018-11-01 11:21:16,704 - Testing sensitivity of module.layer2.2.conv1.weight [45.0% sparsity]
2018-11-01 11:21:16,707 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 11:21:16,708 - --- test ---------------------
2018-11-01 11:21:16,709 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:17,136 - Test: [   10/   39]    Loss 0.868058    Top1 86.835938    Top5 99.257812    
2018-11-01 11:21:17,241 - Test: [   20/   39]    Loss 0.860582    Top1 87.226562    Top5 99.160156    
2018-11-01 11:21:17,345 - Test: [   30/   39]    Loss 0.853584    Top1 87.174479    Top5 99.192708    
2018-11-01 11:21:17,441 - Test: [   40/   39]    Loss 0.838303    Top1 87.500000    Top5 99.270000    
2018-11-01 11:21:17,467 - ==> Top1: 87.500    Top5: 99.270    Loss: 0.838

2018-11-01 11:21:17,468 - Testing sensitivity of module.layer2.2.conv1.weight [50.0% sparsity]
2018-11-01 11:21:17,471 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 11:21:17,472 - --- test ---------------------
2018-11-01 11:21:17,472 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:17,889 - Test: [   10/   39]    Loss 1.070647    Top1 84.726562    Top5 99.062500    
2018-11-01 11:21:17,995 - Test: [   20/   39]    Loss 1.042084    Top1 85.332031    Top5 99.042969    
2018-11-01 11:21:18,099 - Test: [   30/   39]    Loss 1.028392    Top1 85.377604    Top5 99.114583    
2018-11-01 11:21:18,194 - Test: [   40/   39]    Loss 1.019187    Top1 85.750000    Top5 99.190000    
2018-11-01 11:21:18,219 - ==> Top1: 85.750    Top5: 99.190    Loss: 1.019

2018-11-01 11:21:18,220 - Testing sensitivity of module.layer2.2.conv1.weight [55.0% sparsity]
2018-11-01 11:21:18,222 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 11:21:18,223 - --- test ---------------------
2018-11-01 11:21:18,223 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:18,648 - Test: [   10/   39]    Loss 1.186323    Top1 83.867188    Top5 98.789062    
2018-11-01 11:21:18,754 - Test: [   20/   39]    Loss 1.157508    Top1 84.218750    Top5 98.886719    
2018-11-01 11:21:18,858 - Test: [   30/   39]    Loss 1.142288    Top1 84.114583    Top5 98.906250    
2018-11-01 11:21:18,953 - Test: [   40/   39]    Loss 1.126818    Top1 84.560000    Top5 99.000000    
2018-11-01 11:21:18,978 - ==> Top1: 84.560    Top5: 99.000    Loss: 1.127

2018-11-01 11:21:18,979 - Testing sensitivity of module.layer2.2.conv1.weight [60.0% sparsity]
2018-11-01 11:21:18,982 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 11:21:18,983 - --- test ---------------------
2018-11-01 11:21:18,984 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:19,396 - Test: [   10/   39]    Loss 1.373709    Top1 82.304688    Top5 98.671875    
2018-11-01 11:21:19,502 - Test: [   20/   39]    Loss 1.348040    Top1 82.597656    Top5 98.593750    
2018-11-01 11:21:19,605 - Test: [   30/   39]    Loss 1.330103    Top1 82.643229    Top5 98.554688    
2018-11-01 11:21:19,700 - Test: [   40/   39]    Loss 1.316808    Top1 83.000000    Top5 98.710000    
2018-11-01 11:21:19,728 - ==> Top1: 83.000    Top5: 98.710    Loss: 1.317

2018-11-01 11:21:19,729 - Testing sensitivity of module.layer2.2.conv1.weight [65.0% sparsity]
2018-11-01 11:21:19,731 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 11:21:19,732 - --- test ---------------------
2018-11-01 11:21:19,732 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:20,144 - Test: [   10/   39]    Loss 2.031142    Top1 76.835938    Top5 97.890625    
2018-11-01 11:21:20,251 - Test: [   20/   39]    Loss 1.969164    Top1 77.500000    Top5 97.929688    
2018-11-01 11:21:20,355 - Test: [   30/   39]    Loss 1.951936    Top1 77.226562    Top5 97.903646    
2018-11-01 11:21:20,450 - Test: [   40/   39]    Loss 1.952219    Top1 77.500000    Top5 98.150000    
2018-11-01 11:21:20,475 - ==> Top1: 77.500    Top5: 98.150    Loss: 1.952

2018-11-01 11:21:20,476 - Testing sensitivity of module.layer2.2.conv1.weight [70.0% sparsity]
2018-11-01 11:21:20,479 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 11:21:20,480 - --- test ---------------------
2018-11-01 11:21:20,480 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:20,905 - Test: [   10/   39]    Loss 2.882376    Top1 70.468750    Top5 96.679688    
2018-11-01 11:21:21,010 - Test: [   20/   39]    Loss 2.775072    Top1 71.035156    Top5 97.128906    
2018-11-01 11:21:21,113 - Test: [   30/   39]    Loss 2.780449    Top1 70.742188    Top5 97.135417    
2018-11-01 11:21:21,207 - Test: [   40/   39]    Loss 2.776628    Top1 70.710000    Top5 97.370000    
2018-11-01 11:21:21,232 - ==> Top1: 70.710    Top5: 97.370    Loss: 2.777

2018-11-01 11:21:21,235 - Testing sensitivity of module.layer2.2.conv1.weight [75.0% sparsity]
2018-11-01 11:21:21,238 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 11:21:21,239 - --- test ---------------------
2018-11-01 11:21:21,239 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:21,664 - Test: [   10/   39]    Loss 3.188038    Top1 67.148438    Top5 95.898438    
2018-11-01 11:21:21,770 - Test: [   20/   39]    Loss 3.075473    Top1 67.636719    Top5 96.308594    
2018-11-01 11:21:21,872 - Test: [   30/   39]    Loss 3.083699    Top1 67.382812    Top5 96.380208    
2018-11-01 11:21:21,966 - Test: [   40/   39]    Loss 3.092415    Top1 67.300000    Top5 96.530000    
2018-11-01 11:21:21,991 - ==> Top1: 67.300    Top5: 96.530    Loss: 3.092

2018-11-01 11:21:21,991 - Testing sensitivity of module.layer2.2.conv1.weight [80.0% sparsity]
2018-11-01 11:21:21,993 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 11:21:21,994 - --- test ---------------------
2018-11-01 11:21:21,994 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:22,401 - Test: [   10/   39]    Loss 4.685474    Top1 58.203125    Top5 93.867188    
2018-11-01 11:21:22,507 - Test: [   20/   39]    Loss 4.528943    Top1 59.296875    Top5 94.453125    
2018-11-01 11:21:22,610 - Test: [   30/   39]    Loss 4.557185    Top1 58.971354    Top5 94.518229    
2018-11-01 11:21:22,705 - Test: [   40/   39]    Loss 4.539606    Top1 59.010000    Top5 94.700000    
2018-11-01 11:21:22,731 - ==> Top1: 59.010    Top5: 94.700    Loss: 4.540

2018-11-01 11:21:22,731 - Testing sensitivity of module.layer2.2.conv1.weight [85.0% sparsity]
2018-11-01 11:21:22,733 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 11:21:22,734 - --- test ---------------------
2018-11-01 11:21:22,734 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:23,155 - Test: [   10/   39]    Loss 5.824657    Top1 50.820312    Top5 92.890625    
2018-11-01 11:21:23,262 - Test: [   20/   39]    Loss 5.594427    Top1 52.246094    Top5 93.417969    
2018-11-01 11:21:23,365 - Test: [   30/   39]    Loss 5.611904    Top1 52.109375    Top5 93.476562    
2018-11-01 11:21:23,461 - Test: [   40/   39]    Loss 5.589903    Top1 52.360000    Top5 93.590000    
2018-11-01 11:21:23,489 - ==> Top1: 52.360    Top5: 93.590    Loss: 5.590

2018-11-01 11:21:23,490 - Testing sensitivity of module.layer2.2.conv1.weight [90.0% sparsity]
2018-11-01 11:21:23,493 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 11:21:23,494 - --- test ---------------------
2018-11-01 11:21:23,494 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:23,930 - Test: [   10/   39]    Loss 7.130412    Top1 46.796875    Top5 91.914062    
2018-11-01 11:21:24,035 - Test: [   20/   39]    Loss 6.882670    Top1 47.265625    Top5 92.167969    
2018-11-01 11:21:24,137 - Test: [   30/   39]    Loss 6.915231    Top1 47.096354    Top5 92.135417    
2018-11-01 11:21:24,231 - Test: [   40/   39]    Loss 6.864234    Top1 47.360000    Top5 92.130000    
2018-11-01 11:21:24,256 - ==> Top1: 47.360    Top5: 92.130    Loss: 6.864

2018-11-01 11:21:24,271 - Testing sensitivity of module.layer2.2.conv2.weight [0.0% sparsity]
2018-11-01 11:21:24,276 - --- test ---------------------
2018-11-01 11:21:24,277 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:24,671 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:21:24,778 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:21:24,882 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:21:24,977 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:21:25,003 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:21:25,004 - Testing sensitivity of module.layer2.2.conv2.weight [5.0% sparsity]
2018-11-01 11:21:25,007 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 11:21:25,008 - --- test ---------------------
2018-11-01 11:21:25,008 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:25,451 - Test: [   10/   39]    Loss 0.562231    Top1 91.328125    Top5 99.609375    
2018-11-01 11:21:25,556 - Test: [   20/   39]    Loss 0.563982    Top1 91.464844    Top5 99.531250    
2018-11-01 11:21:25,659 - Test: [   30/   39]    Loss 0.558419    Top1 91.393229    Top5 99.635417    
2018-11-01 11:21:25,754 - Test: [   40/   39]    Loss 0.552602    Top1 91.410000    Top5 99.620000    
2018-11-01 11:21:25,778 - ==> Top1: 91.410    Top5: 99.620    Loss: 0.553

2018-11-01 11:21:25,780 - Testing sensitivity of module.layer2.2.conv2.weight [10.0% sparsity]
2018-11-01 11:21:25,784 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 11:21:25,785 - --- test ---------------------
2018-11-01 11:21:25,785 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:26,215 - Test: [   10/   39]    Loss 0.586157    Top1 90.937500    Top5 99.687500    
2018-11-01 11:21:26,321 - Test: [   20/   39]    Loss 0.582887    Top1 91.132812    Top5 99.589844    
2018-11-01 11:21:26,424 - Test: [   30/   39]    Loss 0.574113    Top1 91.106771    Top5 99.674479    
2018-11-01 11:21:26,520 - Test: [   40/   39]    Loss 0.565530    Top1 91.130000    Top5 99.680000    
2018-11-01 11:21:26,549 - ==> Top1: 91.130    Top5: 99.680    Loss: 0.566

2018-11-01 11:21:26,549 - Testing sensitivity of module.layer2.2.conv2.weight [15.0% sparsity]
2018-11-01 11:21:26,552 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 11:21:26,553 - --- test ---------------------
2018-11-01 11:21:26,553 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:26,962 - Test: [   10/   39]    Loss 0.591069    Top1 90.781250    Top5 99.492188    
2018-11-01 11:21:27,069 - Test: [   20/   39]    Loss 0.583952    Top1 90.859375    Top5 99.433594    
2018-11-01 11:21:27,171 - Test: [   30/   39]    Loss 0.579226    Top1 90.859375    Top5 99.570312    
2018-11-01 11:21:27,266 - Test: [   40/   39]    Loss 0.570143    Top1 90.930000    Top5 99.580000    
2018-11-01 11:21:27,291 - ==> Top1: 90.930    Top5: 99.580    Loss: 0.570

2018-11-01 11:21:27,292 - Testing sensitivity of module.layer2.2.conv2.weight [20.0% sparsity]
2018-11-01 11:21:27,295 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 11:21:27,296 - --- test ---------------------
2018-11-01 11:21:27,297 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:27,741 - Test: [   10/   39]    Loss 0.655531    Top1 89.570312    Top5 99.609375    
2018-11-01 11:21:27,846 - Test: [   20/   39]    Loss 0.654282    Top1 89.726562    Top5 99.531250    
2018-11-01 11:21:27,951 - Test: [   30/   39]    Loss 0.650918    Top1 89.609375    Top5 99.609375    
2018-11-01 11:21:28,046 - Test: [   40/   39]    Loss 0.633544    Top1 89.740000    Top5 99.610000    
2018-11-01 11:21:28,071 - ==> Top1: 89.740    Top5: 99.610    Loss: 0.634

2018-11-01 11:21:28,072 - Testing sensitivity of module.layer2.2.conv2.weight [25.0% sparsity]
2018-11-01 11:21:28,076 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 11:21:28,077 - --- test ---------------------
2018-11-01 11:21:28,077 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:28,522 - Test: [   10/   39]    Loss 0.674838    Top1 89.023438    Top5 99.570312    
2018-11-01 11:21:28,629 - Test: [   20/   39]    Loss 0.685695    Top1 89.179688    Top5 99.492188    
2018-11-01 11:21:28,734 - Test: [   30/   39]    Loss 0.684519    Top1 89.114583    Top5 99.596354    
2018-11-01 11:21:28,830 - Test: [   40/   39]    Loss 0.666724    Top1 89.280000    Top5 99.600000    
2018-11-01 11:21:28,856 - ==> Top1: 89.280    Top5: 99.600    Loss: 0.667

2018-11-01 11:21:28,856 - Testing sensitivity of module.layer2.2.conv2.weight [30.0% sparsity]
2018-11-01 11:21:28,859 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 11:21:28,861 - --- test ---------------------
2018-11-01 11:21:28,861 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:29,315 - Test: [   10/   39]    Loss 0.704097    Top1 88.593750    Top5 99.492188    
2018-11-01 11:21:29,422 - Test: [   20/   39]    Loss 0.717492    Top1 88.730469    Top5 99.414062    
2018-11-01 11:21:29,526 - Test: [   30/   39]    Loss 0.719201    Top1 88.723958    Top5 99.505208    
2018-11-01 11:21:29,621 - Test: [   40/   39]    Loss 0.699612    Top1 88.800000    Top5 99.530000    
2018-11-01 11:21:29,645 - ==> Top1: 88.800    Top5: 99.530    Loss: 0.700

2018-11-01 11:21:29,646 - Testing sensitivity of module.layer2.2.conv2.weight [35.0% sparsity]
2018-11-01 11:21:29,649 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 11:21:29,650 - --- test ---------------------
2018-11-01 11:21:29,650 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:30,096 - Test: [   10/   39]    Loss 0.727810    Top1 87.890625    Top5 99.492188    
2018-11-01 11:21:30,203 - Test: [   20/   39]    Loss 0.753390    Top1 87.929688    Top5 99.375000    
2018-11-01 11:21:30,306 - Test: [   30/   39]    Loss 0.755841    Top1 87.825521    Top5 99.479167    
2018-11-01 11:21:30,402 - Test: [   40/   39]    Loss 0.738504    Top1 87.920000    Top5 99.500000    
2018-11-01 11:21:30,428 - ==> Top1: 87.920    Top5: 99.500    Loss: 0.739

2018-11-01 11:21:30,428 - Testing sensitivity of module.layer2.2.conv2.weight [40.0% sparsity]
2018-11-01 11:21:30,431 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 11:21:30,432 - --- test ---------------------
2018-11-01 11:21:30,432 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:30,860 - Test: [   10/   39]    Loss 0.755202    Top1 87.734375    Top5 99.531250    
2018-11-01 11:21:30,967 - Test: [   20/   39]    Loss 0.781070    Top1 87.832031    Top5 99.355469    
2018-11-01 11:21:31,071 - Test: [   30/   39]    Loss 0.784310    Top1 87.617188    Top5 99.466146    
2018-11-01 11:21:31,167 - Test: [   40/   39]    Loss 0.769158    Top1 87.690000    Top5 99.450000    
2018-11-01 11:21:31,180 - ==> Top1: 87.690    Top5: 99.450    Loss: 0.769

2018-11-01 11:21:31,192 - Testing sensitivity of module.layer2.2.conv2.weight [45.0% sparsity]
2018-11-01 11:21:31,196 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 11:21:31,198 - --- test ---------------------
2018-11-01 11:21:31,198 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:31,630 - Test: [   10/   39]    Loss 0.803841    Top1 86.992188    Top5 99.375000    
2018-11-01 11:21:31,736 - Test: [   20/   39]    Loss 0.829317    Top1 87.226562    Top5 99.199219    
2018-11-01 11:21:31,840 - Test: [   30/   39]    Loss 0.837690    Top1 86.861979    Top5 99.296875    
2018-11-01 11:21:31,935 - Test: [   40/   39]    Loss 0.825435    Top1 86.940000    Top5 99.290000    
2018-11-01 11:21:31,960 - ==> Top1: 86.940    Top5: 99.290    Loss: 0.825

2018-11-01 11:21:31,961 - Testing sensitivity of module.layer2.2.conv2.weight [50.0% sparsity]
2018-11-01 11:21:31,963 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 11:21:31,964 - --- test ---------------------
2018-11-01 11:21:31,964 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:32,385 - Test: [   10/   39]    Loss 0.895254    Top1 85.351562    Top5 99.179688    
2018-11-01 11:21:32,491 - Test: [   20/   39]    Loss 0.934369    Top1 85.332031    Top5 98.945312    
2018-11-01 11:21:32,594 - Test: [   30/   39]    Loss 0.952568    Top1 85.169271    Top5 99.023438    
2018-11-01 11:21:32,691 - Test: [   40/   39]    Loss 0.949455    Top1 85.190000    Top5 99.090000    
2018-11-01 11:21:32,732 - ==> Top1: 85.190    Top5: 99.090    Loss: 0.949

2018-11-01 11:21:32,733 - Testing sensitivity of module.layer2.2.conv2.weight [55.0% sparsity]
2018-11-01 11:21:32,736 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 11:21:32,738 - --- test ---------------------
2018-11-01 11:21:32,738 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:33,166 - Test: [   10/   39]    Loss 0.917920    Top1 85.351562    Top5 99.179688    
2018-11-01 11:21:33,272 - Test: [   20/   39]    Loss 0.950395    Top1 85.449219    Top5 99.003906    
2018-11-01 11:21:33,376 - Test: [   30/   39]    Loss 0.970249    Top1 85.195312    Top5 99.101562    
2018-11-01 11:21:33,471 - Test: [   40/   39]    Loss 0.961276    Top1 85.240000    Top5 99.190000    
2018-11-01 11:21:33,495 - ==> Top1: 85.240    Top5: 99.190    Loss: 0.961

2018-11-01 11:21:33,497 - Testing sensitivity of module.layer2.2.conv2.weight [60.0% sparsity]
2018-11-01 11:21:33,500 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 11:21:33,501 - --- test ---------------------
2018-11-01 11:21:33,502 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:34,010 - Test: [   10/   39]    Loss 1.084233    Top1 83.046875    Top5 98.789062    
2018-11-01 11:21:34,121 - Test: [   20/   39]    Loss 1.113172    Top1 83.281250    Top5 98.730469    
2018-11-01 11:21:34,228 - Test: [   30/   39]    Loss 1.129407    Top1 83.111979    Top5 98.841146    
2018-11-01 11:21:34,326 - Test: [   40/   39]    Loss 1.116388    Top1 83.130000    Top5 98.910000    
2018-11-01 11:21:34,362 - ==> Top1: 83.130    Top5: 98.910    Loss: 1.116

2018-11-01 11:21:34,363 - Testing sensitivity of module.layer2.2.conv2.weight [65.0% sparsity]
2018-11-01 11:21:34,366 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 11:21:34,367 - --- test ---------------------
2018-11-01 11:21:34,367 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:34,817 - Test: [   10/   39]    Loss 1.091312    Top1 82.695312    Top5 98.789062    
2018-11-01 11:21:34,923 - Test: [   20/   39]    Loss 1.115362    Top1 83.183594    Top5 98.750000    
2018-11-01 11:21:35,028 - Test: [   30/   39]    Loss 1.132360    Top1 83.072917    Top5 98.906250    
2018-11-01 11:21:35,124 - Test: [   40/   39]    Loss 1.118706    Top1 83.160000    Top5 99.000000    
2018-11-01 11:21:35,151 - ==> Top1: 83.160    Top5: 99.000    Loss: 1.119

2018-11-01 11:21:35,151 - Testing sensitivity of module.layer2.2.conv2.weight [70.0% sparsity]
2018-11-01 11:21:35,154 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 11:21:35,155 - --- test ---------------------
2018-11-01 11:21:35,155 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:35,604 - Test: [   10/   39]    Loss 1.048325    Top1 83.437500    Top5 99.062500    
2018-11-01 11:21:35,712 - Test: [   20/   39]    Loss 1.076245    Top1 83.691406    Top5 98.925781    
2018-11-01 11:21:35,820 - Test: [   30/   39]    Loss 1.078731    Top1 83.645833    Top5 99.062500    
2018-11-01 11:21:35,918 - Test: [   40/   39]    Loss 1.069333    Top1 83.690000    Top5 99.090000    
2018-11-01 11:21:35,949 - ==> Top1: 83.690    Top5: 99.090    Loss: 1.069

2018-11-01 11:21:35,950 - Testing sensitivity of module.layer2.2.conv2.weight [75.0% sparsity]
2018-11-01 11:21:35,953 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 11:21:35,954 - --- test ---------------------
2018-11-01 11:21:35,954 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:36,406 - Test: [   10/   39]    Loss 1.121374    Top1 82.500000    Top5 98.750000    
2018-11-01 11:21:36,512 - Test: [   20/   39]    Loss 1.135478    Top1 83.046875    Top5 98.691406    
2018-11-01 11:21:36,617 - Test: [   30/   39]    Loss 1.139176    Top1 83.007812    Top5 98.919271    
2018-11-01 11:21:36,712 - Test: [   40/   39]    Loss 1.141914    Top1 82.940000    Top5 99.000000    
2018-11-01 11:21:36,738 - ==> Top1: 82.940    Top5: 99.000    Loss: 1.142

2018-11-01 11:21:36,738 - Testing sensitivity of module.layer2.2.conv2.weight [80.0% sparsity]
2018-11-01 11:21:36,741 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 11:21:36,742 - --- test ---------------------
2018-11-01 11:21:36,742 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:37,173 - Test: [   10/   39]    Loss 1.226611    Top1 81.132812    Top5 98.710938    
2018-11-01 11:21:37,279 - Test: [   20/   39]    Loss 1.222174    Top1 81.777344    Top5 98.574219    
2018-11-01 11:21:37,383 - Test: [   30/   39]    Loss 1.236038    Top1 81.679688    Top5 98.802083    
2018-11-01 11:21:37,478 - Test: [   40/   39]    Loss 1.235203    Top1 81.740000    Top5 98.900000    
2018-11-01 11:21:37,503 - ==> Top1: 81.740    Top5: 98.900    Loss: 1.235

2018-11-01 11:21:37,504 - Testing sensitivity of module.layer2.2.conv2.weight [85.0% sparsity]
2018-11-01 11:21:37,507 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 11:21:37,508 - --- test ---------------------
2018-11-01 11:21:37,508 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:37,934 - Test: [   10/   39]    Loss 1.461486    Top1 78.437500    Top5 98.359375    
2018-11-01 11:21:38,041 - Test: [   20/   39]    Loss 1.459881    Top1 78.535156    Top5 98.085938    
2018-11-01 11:21:38,145 - Test: [   30/   39]    Loss 1.465193    Top1 78.320312    Top5 98.372396    
2018-11-01 11:21:38,241 - Test: [   40/   39]    Loss 1.469917    Top1 78.140000    Top5 98.410000    
2018-11-01 11:21:38,265 - ==> Top1: 78.140    Top5: 98.410    Loss: 1.470

2018-11-01 11:21:38,266 - Testing sensitivity of module.layer2.2.conv2.weight [90.0% sparsity]
2018-11-01 11:21:38,268 - L1RankedStructureParameterPruner - param: module.layer2.2.conv2.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 11:21:38,269 - --- test ---------------------
2018-11-01 11:21:38,269 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:38,761 - Test: [   10/   39]    Loss 1.461532    Top1 78.125000    Top5 98.281250    
2018-11-01 11:21:38,872 - Test: [   20/   39]    Loss 1.473490    Top1 78.261719    Top5 97.812500    
2018-11-01 11:21:38,976 - Test: [   30/   39]    Loss 1.485350    Top1 78.111979    Top5 98.085938    
2018-11-01 11:21:39,071 - Test: [   40/   39]    Loss 1.494001    Top1 77.900000    Top5 98.170000    
2018-11-01 11:21:39,097 - ==> Top1: 77.900    Top5: 98.170    Loss: 1.494

2018-11-01 11:21:39,113 - Testing sensitivity of module.layer3.0.conv1.weight [0.0% sparsity]
2018-11-01 11:21:39,117 - --- test ---------------------
2018-11-01 11:21:39,117 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:39,522 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:21:39,628 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:21:39,732 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:21:39,827 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:21:39,851 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:21:39,852 - Testing sensitivity of module.layer3.0.conv1.weight [5.0% sparsity]
2018-11-01 11:21:39,855 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 11:21:39,856 - --- test ---------------------
2018-11-01 11:21:39,856 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:40,283 - Test: [   10/   39]    Loss 0.563452    Top1 90.156250    Top5 99.648438    
2018-11-01 11:21:40,390 - Test: [   20/   39]    Loss 0.560609    Top1 90.644531    Top5 99.570312    
2018-11-01 11:21:40,494 - Test: [   30/   39]    Loss 0.558191    Top1 90.651042    Top5 99.609375    
2018-11-01 11:21:40,589 - Test: [   40/   39]    Loss 0.554126    Top1 90.700000    Top5 99.610000    
2018-11-01 11:21:40,613 - ==> Top1: 90.700    Top5: 99.610    Loss: 0.554

2018-11-01 11:21:40,614 - Testing sensitivity of module.layer3.0.conv1.weight [10.0% sparsity]
2018-11-01 11:21:40,616 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 11:21:40,617 - --- test ---------------------
2018-11-01 11:21:40,617 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:41,048 - Test: [   10/   39]    Loss 0.723775    Top1 87.929688    Top5 99.335938    
2018-11-01 11:21:41,154 - Test: [   20/   39]    Loss 0.723494    Top1 88.222656    Top5 99.257812    
2018-11-01 11:21:41,257 - Test: [   30/   39]    Loss 0.719056    Top1 88.164062    Top5 99.401042    
2018-11-01 11:21:41,352 - Test: [   40/   39]    Loss 0.705614    Top1 88.240000    Top5 99.450000    
2018-11-01 11:21:41,378 - ==> Top1: 88.240    Top5: 99.450    Loss: 0.706

2018-11-01 11:21:41,378 - Testing sensitivity of module.layer3.0.conv1.weight [15.0% sparsity]
2018-11-01 11:21:41,381 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 11:21:41,382 - --- test ---------------------
2018-11-01 11:21:41,383 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:41,809 - Test: [   10/   39]    Loss 0.865429    Top1 85.898438    Top5 99.101562    
2018-11-01 11:21:41,916 - Test: [   20/   39]    Loss 0.864649    Top1 86.289062    Top5 99.082031    
2018-11-01 11:21:42,019 - Test: [   30/   39]    Loss 0.869812    Top1 86.106771    Top5 99.205729    
2018-11-01 11:21:42,114 - Test: [   40/   39]    Loss 0.856059    Top1 86.250000    Top5 99.240000    
2018-11-01 11:21:42,144 - ==> Top1: 86.250    Top5: 99.240    Loss: 0.856

2018-11-01 11:21:42,145 - Testing sensitivity of module.layer3.0.conv1.weight [20.0% sparsity]
2018-11-01 11:21:42,148 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 11:21:42,149 - --- test ---------------------
2018-11-01 11:21:42,149 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:42,569 - Test: [   10/   39]    Loss 1.017011    Top1 83.203125    Top5 99.023438    
2018-11-01 11:21:42,675 - Test: [   20/   39]    Loss 0.994968    Top1 83.710938    Top5 98.886719    
2018-11-01 11:21:42,779 - Test: [   30/   39]    Loss 1.007311    Top1 83.750000    Top5 98.945312    
2018-11-01 11:21:42,875 - Test: [   40/   39]    Loss 1.003523    Top1 83.780000    Top5 99.020000    
2018-11-01 11:21:42,901 - ==> Top1: 83.780    Top5: 99.020    Loss: 1.004

2018-11-01 11:21:42,902 - Testing sensitivity of module.layer3.0.conv1.weight [25.0% sparsity]
2018-11-01 11:21:42,904 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 11:21:42,905 - --- test ---------------------
2018-11-01 11:21:42,906 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:43,330 - Test: [   10/   39]    Loss 1.501919    Top1 76.953125    Top5 98.281250    
2018-11-01 11:21:43,436 - Test: [   20/   39]    Loss 1.475157    Top1 77.187500    Top5 98.183594    
2018-11-01 11:21:43,541 - Test: [   30/   39]    Loss 1.494185    Top1 77.408854    Top5 98.294271    
2018-11-01 11:21:43,637 - Test: [   40/   39]    Loss 1.499028    Top1 77.420000    Top5 98.350000    
2018-11-01 11:21:43,662 - ==> Top1: 77.420    Top5: 98.350    Loss: 1.499

2018-11-01 11:21:43,663 - Testing sensitivity of module.layer3.0.conv1.weight [30.0% sparsity]
2018-11-01 11:21:43,665 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 11:21:43,666 - --- test ---------------------
2018-11-01 11:21:43,666 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:44,081 - Test: [   10/   39]    Loss 1.604857    Top1 76.757812    Top5 98.125000    
2018-11-01 11:21:44,188 - Test: [   20/   39]    Loss 1.576331    Top1 76.699219    Top5 98.007812    
2018-11-01 11:21:44,296 - Test: [   30/   39]    Loss 1.578963    Top1 76.718750    Top5 97.981771    
2018-11-01 11:21:44,395 - Test: [   40/   39]    Loss 1.581216    Top1 76.620000    Top5 98.030000    
2018-11-01 11:21:44,420 - ==> Top1: 76.620    Top5: 98.030    Loss: 1.581

2018-11-01 11:21:44,421 - Testing sensitivity of module.layer3.0.conv1.weight [35.0% sparsity]
2018-11-01 11:21:44,424 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 11:21:44,425 - --- test ---------------------
2018-11-01 11:21:44,425 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:44,864 - Test: [   10/   39]    Loss 2.118586    Top1 71.523438    Top5 96.914062    
2018-11-01 11:21:44,970 - Test: [   20/   39]    Loss 2.085821    Top1 71.367188    Top5 97.050781    
2018-11-01 11:21:45,073 - Test: [   30/   39]    Loss 2.088719    Top1 71.523438    Top5 96.888021    
2018-11-01 11:21:45,169 - Test: [   40/   39]    Loss 2.109971    Top1 71.480000    Top5 96.930000    
2018-11-01 11:21:45,193 - ==> Top1: 71.480    Top5: 96.930    Loss: 2.110

2018-11-01 11:21:45,194 - Testing sensitivity of module.layer3.0.conv1.weight [40.0% sparsity]
2018-11-01 11:21:45,197 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 11:21:45,198 - --- test ---------------------
2018-11-01 11:21:45,198 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:45,625 - Test: [   10/   39]    Loss 2.209973    Top1 71.015625    Top5 96.445312    
2018-11-01 11:21:45,731 - Test: [   20/   39]    Loss 2.156631    Top1 70.683594    Top5 96.503906    
2018-11-01 11:21:45,834 - Test: [   30/   39]    Loss 2.162362    Top1 70.585938    Top5 96.419271    
2018-11-01 11:21:45,929 - Test: [   40/   39]    Loss 2.182045    Top1 70.710000    Top5 96.360000    
2018-11-01 11:21:45,977 - ==> Top1: 70.710    Top5: 96.360    Loss: 2.182

2018-11-01 11:21:45,978 - Testing sensitivity of module.layer3.0.conv1.weight [45.0% sparsity]
2018-11-01 11:21:45,981 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 11:21:45,982 - --- test ---------------------
2018-11-01 11:21:45,982 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:46,524 - Test: [   10/   39]    Loss 2.306094    Top1 69.257812    Top5 96.328125    
2018-11-01 11:21:46,637 - Test: [   20/   39]    Loss 2.243310    Top1 69.296875    Top5 96.171875    
2018-11-01 11:21:46,744 - Test: [   30/   39]    Loss 2.252991    Top1 68.997396    Top5 96.080729    
2018-11-01 11:21:46,843 - Test: [   40/   39]    Loss 2.274114    Top1 69.010000    Top5 96.070000    
2018-11-01 11:21:46,868 - ==> Top1: 69.010    Top5: 96.070    Loss: 2.274

2018-11-01 11:21:46,869 - Testing sensitivity of module.layer3.0.conv1.weight [50.0% sparsity]
2018-11-01 11:21:46,871 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 11:21:46,872 - --- test ---------------------
2018-11-01 11:21:46,873 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:47,313 - Test: [   10/   39]    Loss 2.116760    Top1 69.218750    Top5 95.625000    
2018-11-01 11:21:47,423 - Test: [   20/   39]    Loss 2.077817    Top1 69.746094    Top5 95.585938    
2018-11-01 11:21:47,531 - Test: [   30/   39]    Loss 2.107218    Top1 69.648438    Top5 95.520833    
2018-11-01 11:21:47,629 - Test: [   40/   39]    Loss 2.131053    Top1 69.880000    Top5 95.580000    
2018-11-01 11:21:47,688 - ==> Top1: 69.880    Top5: 95.580    Loss: 2.131

2018-11-01 11:21:47,689 - Testing sensitivity of module.layer3.0.conv1.weight [55.0% sparsity]
2018-11-01 11:21:47,693 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 11:21:47,694 - --- test ---------------------
2018-11-01 11:21:47,695 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:48,166 - Test: [   10/   39]    Loss 2.084730    Top1 69.492188    Top5 96.250000    
2018-11-01 11:21:48,271 - Test: [   20/   39]    Loss 2.056375    Top1 69.316406    Top5 96.328125    
2018-11-01 11:21:48,374 - Test: [   30/   39]    Loss 2.088138    Top1 69.179688    Top5 96.197917    
2018-11-01 11:21:48,469 - Test: [   40/   39]    Loss 2.086230    Top1 69.410000    Top5 96.280000    
2018-11-01 11:21:48,494 - ==> Top1: 69.410    Top5: 96.280    Loss: 2.086

2018-11-01 11:21:48,494 - Testing sensitivity of module.layer3.0.conv1.weight [60.0% sparsity]
2018-11-01 11:21:48,497 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 11:21:48,498 - --- test ---------------------
2018-11-01 11:21:48,498 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:48,999 - Test: [   10/   39]    Loss 2.992046    Top1 58.437500    Top5 92.500000    
2018-11-01 11:21:49,110 - Test: [   20/   39]    Loss 3.019664    Top1 58.554688    Top5 92.695312    
2018-11-01 11:21:49,217 - Test: [   30/   39]    Loss 3.033834    Top1 58.776042    Top5 92.695312    
2018-11-01 11:21:49,315 - Test: [   40/   39]    Loss 3.026512    Top1 58.860000    Top5 92.780000    
2018-11-01 11:21:49,344 - ==> Top1: 58.860    Top5: 92.780    Loss: 3.027

2018-11-01 11:21:49,344 - Testing sensitivity of module.layer3.0.conv1.weight [65.0% sparsity]
2018-11-01 11:21:49,346 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 11:21:49,347 - --- test ---------------------
2018-11-01 11:21:49,347 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:49,769 - Test: [   10/   39]    Loss 3.033169    Top1 57.031250    Top5 90.507812    
2018-11-01 11:21:49,876 - Test: [   20/   39]    Loss 3.084066    Top1 56.093750    Top5 90.410156    
2018-11-01 11:21:49,980 - Test: [   30/   39]    Loss 3.109886    Top1 56.484375    Top5 90.195312    
2018-11-01 11:21:50,077 - Test: [   40/   39]    Loss 3.104113    Top1 56.680000    Top5 90.300000    
2018-11-01 11:21:50,103 - ==> Top1: 56.680    Top5: 90.300    Loss: 3.104

2018-11-01 11:21:50,103 - Testing sensitivity of module.layer3.0.conv1.weight [70.0% sparsity]
2018-11-01 11:21:50,106 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 11:21:50,107 - --- test ---------------------
2018-11-01 11:21:50,107 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:50,585 - Test: [   10/   39]    Loss 2.653296    Top1 57.656250    Top5 91.328125    
2018-11-01 11:21:50,691 - Test: [   20/   39]    Loss 2.671625    Top1 56.914062    Top5 91.152344    
2018-11-01 11:21:50,793 - Test: [   30/   39]    Loss 2.673348    Top1 57.265625    Top5 91.132812    
2018-11-01 11:21:50,889 - Test: [   40/   39]    Loss 2.665777    Top1 57.260000    Top5 91.130000    
2018-11-01 11:21:50,917 - ==> Top1: 57.260    Top5: 91.130    Loss: 2.666

2018-11-01 11:21:50,917 - Testing sensitivity of module.layer3.0.conv1.weight [75.0% sparsity]
2018-11-01 11:21:50,920 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 11:21:50,921 - --- test ---------------------
2018-11-01 11:21:50,921 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:51,372 - Test: [   10/   39]    Loss 3.854271    Top1 47.773438    Top5 90.195312    
2018-11-01 11:21:51,478 - Test: [   20/   39]    Loss 3.872787    Top1 47.207031    Top5 90.195312    
2018-11-01 11:21:51,582 - Test: [   30/   39]    Loss 3.866790    Top1 48.007812    Top5 90.052083    
2018-11-01 11:21:51,677 - Test: [   40/   39]    Loss 3.814725    Top1 48.400000    Top5 90.250000    
2018-11-01 11:21:51,701 - ==> Top1: 48.400    Top5: 90.250    Loss: 3.815

2018-11-01 11:21:51,702 - Testing sensitivity of module.layer3.0.conv1.weight [80.0% sparsity]
2018-11-01 11:21:51,705 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 11:21:51,705 - --- test ---------------------
2018-11-01 11:21:51,706 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:52,146 - Test: [   10/   39]    Loss 5.675814    Top1 35.507812    Top5 83.359375    
2018-11-01 11:21:52,253 - Test: [   20/   39]    Loss 5.719328    Top1 34.453125    Top5 83.164062    
2018-11-01 11:21:52,357 - Test: [   30/   39]    Loss 5.702440    Top1 34.843750    Top5 83.294271    
2018-11-01 11:21:52,452 - Test: [   40/   39]    Loss 5.577116    Top1 35.150000    Top5 83.430000    
2018-11-01 11:21:52,477 - ==> Top1: 35.150    Top5: 83.430    Loss: 5.577

2018-11-01 11:21:52,478 - Testing sensitivity of module.layer3.0.conv1.weight [85.0% sparsity]
2018-11-01 11:21:52,480 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 11:21:52,481 - --- test ---------------------
2018-11-01 11:21:52,481 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:52,919 - Test: [   10/   39]    Loss 6.712798    Top1 30.000000    Top5 76.718750    
2018-11-01 11:21:53,026 - Test: [   20/   39]    Loss 6.718694    Top1 29.726562    Top5 76.250000    
2018-11-01 11:21:53,129 - Test: [   30/   39]    Loss 6.662894    Top1 29.674479    Top5 76.666667    
2018-11-01 11:21:53,226 - Test: [   40/   39]    Loss 6.562968    Top1 29.710000    Top5 76.660000    
2018-11-01 11:21:53,252 - ==> Top1: 29.710    Top5: 76.660    Loss: 6.563

2018-11-01 11:21:53,253 - Testing sensitivity of module.layer3.0.conv1.weight [90.0% sparsity]
2018-11-01 11:21:53,256 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 11:21:53,257 - --- test ---------------------
2018-11-01 11:21:53,257 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:53,681 - Test: [   10/   39]    Loss 7.718456    Top1 28.476563    Top5 70.312500    
2018-11-01 11:21:53,787 - Test: [   20/   39]    Loss 7.745807    Top1 27.773437    Top5 69.980469    
2018-11-01 11:21:53,894 - Test: [   30/   39]    Loss 7.703335    Top1 27.747396    Top5 69.947917    
2018-11-01 11:21:53,992 - Test: [   40/   39]    Loss 7.659565    Top1 27.660000    Top5 69.740000    
2018-11-01 11:21:54,032 - ==> Top1: 27.660    Top5: 69.740    Loss: 7.660

2018-11-01 11:21:54,041 - Testing sensitivity of module.layer3.0.conv2.weight [0.0% sparsity]
2018-11-01 11:21:54,044 - --- test ---------------------
2018-11-01 11:21:54,044 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:54,445 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:21:54,552 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:21:54,655 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:21:54,755 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:21:54,782 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:21:54,782 - Testing sensitivity of module.layer3.0.conv2.weight [5.0% sparsity]
2018-11-01 11:21:54,786 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 11:21:54,787 - --- test ---------------------
2018-11-01 11:21:54,787 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:55,206 - Test: [   10/   39]    Loss 0.590594    Top1 90.664062    Top5 99.609375    
2018-11-01 11:21:55,311 - Test: [   20/   39]    Loss 0.585318    Top1 90.742188    Top5 99.550781    
2018-11-01 11:21:55,415 - Test: [   30/   39]    Loss 0.578983    Top1 90.611979    Top5 99.648438    
2018-11-01 11:21:55,509 - Test: [   40/   39]    Loss 0.580242    Top1 90.720000    Top5 99.650000    
2018-11-01 11:21:55,534 - ==> Top1: 90.720    Top5: 99.650    Loss: 0.580

2018-11-01 11:21:55,535 - Testing sensitivity of module.layer3.0.conv2.weight [10.0% sparsity]
2018-11-01 11:21:55,537 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 11:21:55,538 - --- test ---------------------
2018-11-01 11:21:55,539 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:56,013 - Test: [   10/   39]    Loss 0.636255    Top1 89.804688    Top5 99.531250    
2018-11-01 11:21:56,120 - Test: [   20/   39]    Loss 0.637873    Top1 89.921875    Top5 99.433594    
2018-11-01 11:21:56,224 - Test: [   30/   39]    Loss 0.633367    Top1 89.921875    Top5 99.518229    
2018-11-01 11:21:56,321 - Test: [   40/   39]    Loss 0.638651    Top1 90.020000    Top5 99.540000    
2018-11-01 11:21:56,371 - ==> Top1: 90.020    Top5: 99.540    Loss: 0.639

2018-11-01 11:21:56,371 - Testing sensitivity of module.layer3.0.conv2.weight [15.0% sparsity]
2018-11-01 11:21:56,375 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 11:21:56,376 - --- test ---------------------
2018-11-01 11:21:56,377 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:56,820 - Test: [   10/   39]    Loss 0.695246    Top1 88.867188    Top5 99.453125    
2018-11-01 11:21:56,929 - Test: [   20/   39]    Loss 0.698931    Top1 89.316406    Top5 99.511719    
2018-11-01 11:21:57,033 - Test: [   30/   39]    Loss 0.694259    Top1 89.205729    Top5 99.531250    
2018-11-01 11:21:57,129 - Test: [   40/   39]    Loss 0.691547    Top1 89.320000    Top5 99.550000    
2018-11-01 11:21:57,153 - ==> Top1: 89.320    Top5: 99.550    Loss: 0.692

2018-11-01 11:21:57,154 - Testing sensitivity of module.layer3.0.conv2.weight [20.0% sparsity]
2018-11-01 11:21:57,157 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 11:21:57,157 - --- test ---------------------
2018-11-01 11:21:57,157 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:57,586 - Test: [   10/   39]    Loss 0.749787    Top1 88.828125    Top5 99.335938    
2018-11-01 11:21:57,692 - Test: [   20/   39]    Loss 0.750253    Top1 89.101562    Top5 99.355469    
2018-11-01 11:21:57,795 - Test: [   30/   39]    Loss 0.736228    Top1 89.127604    Top5 99.440104    
2018-11-01 11:21:57,890 - Test: [   40/   39]    Loss 0.732963    Top1 89.260000    Top5 99.470000    
2018-11-01 11:21:57,916 - ==> Top1: 89.260    Top5: 99.470    Loss: 0.733

2018-11-01 11:21:57,918 - Testing sensitivity of module.layer3.0.conv2.weight [25.0% sparsity]
2018-11-01 11:21:57,921 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 11:21:57,922 - --- test ---------------------
2018-11-01 11:21:57,923 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:58,347 - Test: [   10/   39]    Loss 0.837712    Top1 87.460938    Top5 99.296875    
2018-11-01 11:21:58,452 - Test: [   20/   39]    Loss 0.842670    Top1 87.656250    Top5 99.355469    
2018-11-01 11:21:58,555 - Test: [   30/   39]    Loss 0.824392    Top1 87.669271    Top5 99.453125    
2018-11-01 11:21:58,649 - Test: [   40/   39]    Loss 0.816889    Top1 87.820000    Top5 99.450000    
2018-11-01 11:21:58,674 - ==> Top1: 87.820    Top5: 99.450    Loss: 0.817

2018-11-01 11:21:58,675 - Testing sensitivity of module.layer3.0.conv2.weight [30.0% sparsity]
2018-11-01 11:21:58,678 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 11:21:58,679 - --- test ---------------------
2018-11-01 11:21:58,679 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:59,105 - Test: [   10/   39]    Loss 1.085822    Top1 84.531250    Top5 98.984375    
2018-11-01 11:21:59,211 - Test: [   20/   39]    Loss 1.109276    Top1 84.335938    Top5 99.121094    
2018-11-01 11:21:59,315 - Test: [   30/   39]    Loss 1.073556    Top1 84.583333    Top5 99.270833    
2018-11-01 11:21:59,413 - Test: [   40/   39]    Loss 1.068932    Top1 84.640000    Top5 99.240000    
2018-11-01 11:21:59,453 - ==> Top1: 84.640    Top5: 99.240    Loss: 1.069

2018-11-01 11:21:59,454 - Testing sensitivity of module.layer3.0.conv2.weight [35.0% sparsity]
2018-11-01 11:21:59,457 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 11:21:59,458 - --- test ---------------------
2018-11-01 11:21:59,458 - 10000 samples (256 per mini-batch)
2018-11-01 11:21:59,931 - Test: [   10/   39]    Loss 1.145638    Top1 83.046875    Top5 99.179688    
2018-11-01 11:22:00,041 - Test: [   20/   39]    Loss 1.162093    Top1 83.320312    Top5 99.023438    
2018-11-01 11:22:00,148 - Test: [   30/   39]    Loss 1.122729    Top1 83.710938    Top5 99.101562    
2018-11-01 11:22:00,247 - Test: [   40/   39]    Loss 1.106843    Top1 83.880000    Top5 99.100000    
2018-11-01 11:22:00,286 - ==> Top1: 83.880    Top5: 99.100    Loss: 1.107

2018-11-01 11:22:00,287 - Testing sensitivity of module.layer3.0.conv2.weight [40.0% sparsity]
2018-11-01 11:22:00,290 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 11:22:00,291 - --- test ---------------------
2018-11-01 11:22:00,292 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:00,782 - Test: [   10/   39]    Loss 1.402156    Top1 79.687500    Top5 98.750000    
2018-11-01 11:22:00,893 - Test: [   20/   39]    Loss 1.415631    Top1 80.332031    Top5 98.828125    
2018-11-01 11:22:01,001 - Test: [   30/   39]    Loss 1.349877    Top1 80.598958    Top5 98.697917    
2018-11-01 11:22:01,099 - Test: [   40/   39]    Loss 1.337873    Top1 80.470000    Top5 98.720000    
2018-11-01 11:22:01,137 - ==> Top1: 80.470    Top5: 98.720    Loss: 1.338

2018-11-01 11:22:01,137 - Testing sensitivity of module.layer3.0.conv2.weight [45.0% sparsity]
2018-11-01 11:22:01,142 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 11:22:01,144 - --- test ---------------------
2018-11-01 11:22:01,144 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:01,588 - Test: [   10/   39]    Loss 1.708904    Top1 75.820312    Top5 98.281250    
2018-11-01 11:22:01,694 - Test: [   20/   39]    Loss 1.695563    Top1 76.367188    Top5 98.300781    
2018-11-01 11:22:01,797 - Test: [   30/   39]    Loss 1.641691    Top1 76.770833    Top5 98.203125    
2018-11-01 11:22:01,892 - Test: [   40/   39]    Loss 1.627582    Top1 76.700000    Top5 98.230000    
2018-11-01 11:22:01,917 - ==> Top1: 76.700    Top5: 98.230    Loss: 1.628

2018-11-01 11:22:01,918 - Testing sensitivity of module.layer3.0.conv2.weight [50.0% sparsity]
2018-11-01 11:22:01,921 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 11:22:01,922 - --- test ---------------------
2018-11-01 11:22:01,923 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:02,345 - Test: [   10/   39]    Loss 1.695348    Top1 73.945312    Top5 97.656250    
2018-11-01 11:22:02,452 - Test: [   20/   39]    Loss 1.722759    Top1 74.179688    Top5 97.519531    
2018-11-01 11:22:02,556 - Test: [   30/   39]    Loss 1.673279    Top1 74.687500    Top5 97.526042    
2018-11-01 11:22:02,651 - Test: [   40/   39]    Loss 1.639260    Top1 74.630000    Top5 97.620000    
2018-11-01 11:22:02,677 - ==> Top1: 74.630    Top5: 97.620    Loss: 1.639

2018-11-01 11:22:02,678 - Testing sensitivity of module.layer3.0.conv2.weight [55.0% sparsity]
2018-11-01 11:22:02,681 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 11:22:02,682 - --- test ---------------------
2018-11-01 11:22:02,683 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:03,108 - Test: [   10/   39]    Loss 1.750354    Top1 73.750000    Top5 97.812500    
2018-11-01 11:22:03,215 - Test: [   20/   39]    Loss 1.787385    Top1 72.968750    Top5 97.460938    
2018-11-01 11:22:03,322 - Test: [   30/   39]    Loss 1.771083    Top1 72.968750    Top5 97.578125    
2018-11-01 11:22:03,418 - Test: [   40/   39]    Loss 1.722848    Top1 72.880000    Top5 97.510000    
2018-11-01 11:22:03,442 - ==> Top1: 72.880    Top5: 97.510    Loss: 1.723

2018-11-01 11:22:03,443 - Testing sensitivity of module.layer3.0.conv2.weight [60.0% sparsity]
2018-11-01 11:22:03,446 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 11:22:03,447 - --- test ---------------------
2018-11-01 11:22:03,447 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:03,869 - Test: [   10/   39]    Loss 1.746897    Top1 72.578125    Top5 97.851562    
2018-11-01 11:22:03,978 - Test: [   20/   39]    Loss 1.772700    Top1 72.148438    Top5 97.343750    
2018-11-01 11:22:04,085 - Test: [   30/   39]    Loss 1.772854    Top1 71.966146    Top5 97.460938    
2018-11-01 11:22:04,185 - Test: [   40/   39]    Loss 1.744333    Top1 72.050000    Top5 97.400000    
2018-11-01 11:22:04,220 - ==> Top1: 72.050    Top5: 97.400    Loss: 1.744

2018-11-01 11:22:04,221 - Testing sensitivity of module.layer3.0.conv2.weight [65.0% sparsity]
2018-11-01 11:22:04,224 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 11:22:04,224 - --- test ---------------------
2018-11-01 11:22:04,225 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:04,661 - Test: [   10/   39]    Loss 2.579216    Top1 62.421875    Top5 91.914062    
2018-11-01 11:22:04,773 - Test: [   20/   39]    Loss 2.568066    Top1 62.714844    Top5 91.738281    
2018-11-01 11:22:04,882 - Test: [   30/   39]    Loss 2.556383    Top1 62.539062    Top5 92.135417    
2018-11-01 11:22:04,980 - Test: [   40/   39]    Loss 2.545369    Top1 62.340000    Top5 92.090000    
2018-11-01 11:22:05,023 - ==> Top1: 62.340    Top5: 92.090    Loss: 2.545

2018-11-01 11:22:05,024 - Testing sensitivity of module.layer3.0.conv2.weight [70.0% sparsity]
2018-11-01 11:22:05,028 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 11:22:05,029 - --- test ---------------------
2018-11-01 11:22:05,029 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:05,466 - Test: [   10/   39]    Loss 2.814603    Top1 57.500000    Top5 89.414062    
2018-11-01 11:22:05,578 - Test: [   20/   39]    Loss 2.810607    Top1 57.011719    Top5 88.828125    
2018-11-01 11:22:05,685 - Test: [   30/   39]    Loss 2.808859    Top1 57.109375    Top5 88.997396    
2018-11-01 11:22:05,783 - Test: [   40/   39]    Loss 2.791079    Top1 57.100000    Top5 88.850000    
2018-11-01 11:22:05,811 - ==> Top1: 57.100    Top5: 88.850    Loss: 2.791

2018-11-01 11:22:05,812 - Testing sensitivity of module.layer3.0.conv2.weight [75.0% sparsity]
2018-11-01 11:22:05,815 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 11:22:05,816 - --- test ---------------------
2018-11-01 11:22:05,816 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:06,248 - Test: [   10/   39]    Loss 3.178976    Top1 52.031250    Top5 87.070312    
2018-11-01 11:22:06,356 - Test: [   20/   39]    Loss 3.184308    Top1 51.269531    Top5 86.640625    
2018-11-01 11:22:06,463 - Test: [   30/   39]    Loss 3.189690    Top1 51.236979    Top5 86.835938    
2018-11-01 11:22:06,564 - Test: [   40/   39]    Loss 3.172888    Top1 51.320000    Top5 86.990000    
2018-11-01 11:22:06,589 - ==> Top1: 51.320    Top5: 86.990    Loss: 3.173

2018-11-01 11:22:06,590 - Testing sensitivity of module.layer3.0.conv2.weight [80.0% sparsity]
2018-11-01 11:22:06,592 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 11:22:06,593 - --- test ---------------------
2018-11-01 11:22:06,594 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:07,115 - Test: [   10/   39]    Loss 3.921284    Top1 43.906250    Top5 79.179688    
2018-11-01 11:22:07,222 - Test: [   20/   39]    Loss 3.916590    Top1 44.472656    Top5 78.164062    
2018-11-01 11:22:07,326 - Test: [   30/   39]    Loss 3.887478    Top1 44.843750    Top5 78.372396    
2018-11-01 11:22:07,422 - Test: [   40/   39]    Loss 3.862627    Top1 45.110000    Top5 78.590000    
2018-11-01 11:22:07,453 - ==> Top1: 45.110    Top5: 78.590    Loss: 3.863

2018-11-01 11:22:07,453 - Testing sensitivity of module.layer3.0.conv2.weight [85.0% sparsity]
2018-11-01 11:22:07,456 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 11:22:07,458 - --- test ---------------------
2018-11-01 11:22:07,459 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:07,871 - Test: [   10/   39]    Loss 4.151854    Top1 38.984375    Top5 75.195312    
2018-11-01 11:22:07,978 - Test: [   20/   39]    Loss 4.155974    Top1 39.414062    Top5 74.433594    
2018-11-01 11:22:08,086 - Test: [   30/   39]    Loss 4.111157    Top1 39.752604    Top5 74.921875    
2018-11-01 11:22:08,185 - Test: [   40/   39]    Loss 4.111709    Top1 40.040000    Top5 74.910000    
2018-11-01 11:22:08,211 - ==> Top1: 40.040    Top5: 74.910    Loss: 4.112

2018-11-01 11:22:08,211 - Testing sensitivity of module.layer3.0.conv2.weight [90.0% sparsity]
2018-11-01 11:22:08,214 - L1RankedStructureParameterPruner - param: module.layer3.0.conv2.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 11:22:08,215 - --- test ---------------------
2018-11-01 11:22:08,216 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:08,758 - Test: [   10/   39]    Loss 4.371623    Top1 33.710938    Top5 72.929688    
2018-11-01 11:22:08,868 - Test: [   20/   39]    Loss 4.317039    Top1 34.746094    Top5 72.988281    
2018-11-01 11:22:08,975 - Test: [   30/   39]    Loss 4.254451    Top1 35.039062    Top5 73.242188    
2018-11-01 11:22:09,073 - Test: [   40/   39]    Loss 4.261891    Top1 35.060000    Top5 73.040000    
2018-11-01 11:22:09,101 - ==> Top1: 35.060    Top5: 73.040    Loss: 4.262

2018-11-01 11:22:09,117 - Testing sensitivity of module.layer3.0.downsample.0.weight [0.0% sparsity]
2018-11-01 11:22:09,122 - --- test ---------------------
2018-11-01 11:22:09,123 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:09,620 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:22:09,728 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:22:09,832 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:22:09,930 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:22:09,955 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:22:09,956 - Testing sensitivity of module.layer3.0.downsample.0.weight [5.0% sparsity]
2018-11-01 11:22:09,959 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.031 goal=0.050 (1/32)
2018-11-01 11:22:09,959 - --- test ---------------------
2018-11-01 11:22:09,960 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:10,384 - Test: [   10/   39]    Loss 0.550606    Top1 91.328125    Top5 99.726562    
2018-11-01 11:22:10,492 - Test: [   20/   39]    Loss 0.552552    Top1 91.484375    Top5 99.609375    
2018-11-01 11:22:10,598 - Test: [   30/   39]    Loss 0.545843    Top1 91.575521    Top5 99.687500    
2018-11-01 11:22:10,698 - Test: [   40/   39]    Loss 0.542569    Top1 91.570000    Top5 99.670000    
2018-11-01 11:22:10,722 - ==> Top1: 91.570    Top5: 99.670    Loss: 0.543

2018-11-01 11:22:10,722 - Testing sensitivity of module.layer3.0.downsample.0.weight [10.0% sparsity]
2018-11-01 11:22:10,725 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.094 goal=0.100 (3/32)
2018-11-01 11:22:10,726 - --- test ---------------------
2018-11-01 11:22:10,726 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:11,227 - Test: [   10/   39]    Loss 0.562968    Top1 91.015625    Top5 99.570312    
2018-11-01 11:22:11,338 - Test: [   20/   39]    Loss 0.560652    Top1 91.210938    Top5 99.550781    
2018-11-01 11:22:11,447 - Test: [   30/   39]    Loss 0.551681    Top1 91.276042    Top5 99.635417    
2018-11-01 11:22:11,545 - Test: [   40/   39]    Loss 0.549536    Top1 91.340000    Top5 99.630000    
2018-11-01 11:22:11,572 - ==> Top1: 91.340    Top5: 99.630    Loss: 0.550

2018-11-01 11:22:11,573 - Testing sensitivity of module.layer3.0.downsample.0.weight [15.0% sparsity]
2018-11-01 11:22:11,576 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.125 goal=0.150 (4/32)
2018-11-01 11:22:11,577 - --- test ---------------------
2018-11-01 11:22:11,578 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:12,003 - Test: [   10/   39]    Loss 0.560928    Top1 91.093750    Top5 99.609375    
2018-11-01 11:22:12,110 - Test: [   20/   39]    Loss 0.557469    Top1 91.171875    Top5 99.550781    
2018-11-01 11:22:12,215 - Test: [   30/   39]    Loss 0.550030    Top1 91.250000    Top5 99.609375    
2018-11-01 11:22:12,310 - Test: [   40/   39]    Loss 0.549150    Top1 91.310000    Top5 99.600000    
2018-11-01 11:22:12,335 - ==> Top1: 91.310    Top5: 99.600    Loss: 0.549

2018-11-01 11:22:12,335 - Testing sensitivity of module.layer3.0.downsample.0.weight [20.0% sparsity]
2018-11-01 11:22:12,338 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.188 goal=0.200 (6/32)
2018-11-01 11:22:12,339 - --- test ---------------------
2018-11-01 11:22:12,340 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:12,759 - Test: [   10/   39]    Loss 0.566584    Top1 91.015625    Top5 99.609375    
2018-11-01 11:22:12,866 - Test: [   20/   39]    Loss 0.565036    Top1 91.074219    Top5 99.531250    
2018-11-01 11:22:12,969 - Test: [   30/   39]    Loss 0.556915    Top1 91.158854    Top5 99.609375    
2018-11-01 11:22:13,064 - Test: [   40/   39]    Loss 0.554786    Top1 91.230000    Top5 99.600000    
2018-11-01 11:22:13,090 - ==> Top1: 91.230    Top5: 99.600    Loss: 0.555

2018-11-01 11:22:13,090 - Testing sensitivity of module.layer3.0.downsample.0.weight [25.0% sparsity]
2018-11-01 11:22:13,093 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.250 goal=0.250 (8/32)
2018-11-01 11:22:13,094 - --- test ---------------------
2018-11-01 11:22:13,094 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:13,542 - Test: [   10/   39]    Loss 0.568685    Top1 90.781250    Top5 99.609375    
2018-11-01 11:22:13,653 - Test: [   20/   39]    Loss 0.562057    Top1 90.957031    Top5 99.550781    
2018-11-01 11:22:13,762 - Test: [   30/   39]    Loss 0.552322    Top1 91.067708    Top5 99.622396    
2018-11-01 11:22:13,861 - Test: [   40/   39]    Loss 0.549598    Top1 91.130000    Top5 99.590000    
2018-11-01 11:22:13,913 - ==> Top1: 91.130    Top5: 99.590    Loss: 0.550

2018-11-01 11:22:13,913 - Testing sensitivity of module.layer3.0.downsample.0.weight [30.0% sparsity]
2018-11-01 11:22:13,917 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.281 goal=0.300 (9/32)
2018-11-01 11:22:13,919 - --- test ---------------------
2018-11-01 11:22:13,920 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:14,408 - Test: [   10/   39]    Loss 0.573521    Top1 90.625000    Top5 99.609375    
2018-11-01 11:22:14,515 - Test: [   20/   39]    Loss 0.565855    Top1 90.820312    Top5 99.570312    
2018-11-01 11:22:14,618 - Test: [   30/   39]    Loss 0.554879    Top1 91.002604    Top5 99.635417    
2018-11-01 11:22:14,717 - Test: [   40/   39]    Loss 0.552652    Top1 91.070000    Top5 99.600000    
2018-11-01 11:22:14,751 - ==> Top1: 91.070    Top5: 99.600    Loss: 0.553

2018-11-01 11:22:14,751 - Testing sensitivity of module.layer3.0.downsample.0.weight [35.0% sparsity]
2018-11-01 11:22:14,758 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.344 goal=0.350 (11/32)
2018-11-01 11:22:14,759 - --- test ---------------------
2018-11-01 11:22:14,760 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:15,287 - Test: [   10/   39]    Loss 0.584568    Top1 90.625000    Top5 99.609375    
2018-11-01 11:22:15,396 - Test: [   20/   39]    Loss 0.576021    Top1 90.976562    Top5 99.550781    
2018-11-01 11:22:15,500 - Test: [   30/   39]    Loss 0.564243    Top1 91.054688    Top5 99.622396    
2018-11-01 11:22:15,598 - Test: [   40/   39]    Loss 0.563991    Top1 91.080000    Top5 99.620000    
2018-11-01 11:22:15,636 - ==> Top1: 91.080    Top5: 99.620    Loss: 0.564

2018-11-01 11:22:15,636 - Testing sensitivity of module.layer3.0.downsample.0.weight [40.0% sparsity]
2018-11-01 11:22:15,641 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.375 goal=0.400 (12/32)
2018-11-01 11:22:15,642 - --- test ---------------------
2018-11-01 11:22:15,643 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:16,198 - Test: [   10/   39]    Loss 0.596994    Top1 90.507812    Top5 99.609375    
2018-11-01 11:22:16,310 - Test: [   20/   39]    Loss 0.588367    Top1 90.859375    Top5 99.570312    
2018-11-01 11:22:16,419 - Test: [   30/   39]    Loss 0.575807    Top1 90.976562    Top5 99.622396    
2018-11-01 11:22:16,519 - Test: [   40/   39]    Loss 0.576052    Top1 90.960000    Top5 99.590000    
2018-11-01 11:22:16,573 - ==> Top1: 90.960    Top5: 99.590    Loss: 0.576

2018-11-01 11:22:16,573 - Testing sensitivity of module.layer3.0.downsample.0.weight [45.0% sparsity]
2018-11-01 11:22:16,576 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.438 goal=0.450 (14/32)
2018-11-01 11:22:16,576 - --- test ---------------------
2018-11-01 11:22:16,577 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:16,988 - Test: [   10/   39]    Loss 0.588624    Top1 90.468750    Top5 99.570312    
2018-11-01 11:22:17,095 - Test: [   20/   39]    Loss 0.580535    Top1 90.800781    Top5 99.550781    
2018-11-01 11:22:17,201 - Test: [   30/   39]    Loss 0.570812    Top1 90.885417    Top5 99.609375    
2018-11-01 11:22:17,298 - Test: [   40/   39]    Loss 0.572453    Top1 90.870000    Top5 99.590000    
2018-11-01 11:22:17,327 - ==> Top1: 90.870    Top5: 99.590    Loss: 0.572

2018-11-01 11:22:17,328 - Testing sensitivity of module.layer3.0.downsample.0.weight [50.0% sparsity]
2018-11-01 11:22:17,329 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.500 goal=0.500 (16/32)
2018-11-01 11:22:17,330 - --- test ---------------------
2018-11-01 11:22:17,330 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:17,775 - Test: [   10/   39]    Loss 0.602466    Top1 90.507812    Top5 99.570312    
2018-11-01 11:22:17,882 - Test: [   20/   39]    Loss 0.593788    Top1 90.742188    Top5 99.570312    
2018-11-01 11:22:17,986 - Test: [   30/   39]    Loss 0.579775    Top1 90.768229    Top5 99.635417    
2018-11-01 11:22:18,083 - Test: [   40/   39]    Loss 0.583166    Top1 90.700000    Top5 99.610000    
2018-11-01 11:22:18,118 - ==> Top1: 90.700    Top5: 99.610    Loss: 0.583

2018-11-01 11:22:18,119 - Testing sensitivity of module.layer3.0.downsample.0.weight [55.0% sparsity]
2018-11-01 11:22:18,121 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.531 goal=0.550 (17/32)
2018-11-01 11:22:18,122 - --- test ---------------------
2018-11-01 11:22:18,122 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:18,543 - Test: [   10/   39]    Loss 0.616788    Top1 90.390625    Top5 99.531250    
2018-11-01 11:22:18,651 - Test: [   20/   39]    Loss 0.605867    Top1 90.664062    Top5 99.531250    
2018-11-01 11:22:18,755 - Test: [   30/   39]    Loss 0.590880    Top1 90.755208    Top5 99.596354    
2018-11-01 11:22:18,851 - Test: [   40/   39]    Loss 0.596091    Top1 90.750000    Top5 99.570000    
2018-11-01 11:22:18,877 - ==> Top1: 90.750    Top5: 99.570    Loss: 0.596

2018-11-01 11:22:18,878 - Testing sensitivity of module.layer3.0.downsample.0.weight [60.0% sparsity]
2018-11-01 11:22:18,881 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.594 goal=0.600 (19/32)
2018-11-01 11:22:18,882 - --- test ---------------------
2018-11-01 11:22:18,882 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:19,302 - Test: [   10/   39]    Loss 0.622973    Top1 90.390625    Top5 99.531250    
2018-11-01 11:22:19,408 - Test: [   20/   39]    Loss 0.612577    Top1 90.585938    Top5 99.492188    
2018-11-01 11:22:19,515 - Test: [   30/   39]    Loss 0.598230    Top1 90.625000    Top5 99.583333    
2018-11-01 11:22:19,613 - Test: [   40/   39]    Loss 0.605764    Top1 90.630000    Top5 99.540000    
2018-11-01 11:22:19,645 - ==> Top1: 90.630    Top5: 99.540    Loss: 0.606

2018-11-01 11:22:19,646 - Testing sensitivity of module.layer3.0.downsample.0.weight [65.0% sparsity]
2018-11-01 11:22:19,651 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.625 goal=0.650 (20/32)
2018-11-01 11:22:19,652 - --- test ---------------------
2018-11-01 11:22:19,652 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:20,080 - Test: [   10/   39]    Loss 0.605768    Top1 90.703125    Top5 99.570312    
2018-11-01 11:22:20,186 - Test: [   20/   39]    Loss 0.597619    Top1 90.703125    Top5 99.550781    
2018-11-01 11:22:20,290 - Test: [   30/   39]    Loss 0.587357    Top1 90.664062    Top5 99.596354    
2018-11-01 11:22:20,386 - Test: [   40/   39]    Loss 0.590451    Top1 90.590000    Top5 99.550000    
2018-11-01 11:22:20,411 - ==> Top1: 90.590    Top5: 99.550    Loss: 0.590

2018-11-01 11:22:20,411 - Testing sensitivity of module.layer3.0.downsample.0.weight [70.0% sparsity]
2018-11-01 11:22:20,415 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.688 goal=0.700 (22/32)
2018-11-01 11:22:20,416 - --- test ---------------------
2018-11-01 11:22:20,416 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:20,836 - Test: [   10/   39]    Loss 0.626168    Top1 90.195312    Top5 99.375000    
2018-11-01 11:22:20,948 - Test: [   20/   39]    Loss 0.629784    Top1 90.195312    Top5 99.472656    
2018-11-01 11:22:21,056 - Test: [   30/   39]    Loss 0.615545    Top1 90.156250    Top5 99.544271    
2018-11-01 11:22:21,156 - Test: [   40/   39]    Loss 0.618778    Top1 90.120000    Top5 99.510000    
2018-11-01 11:22:21,215 - ==> Top1: 90.120    Top5: 99.510    Loss: 0.619

2018-11-01 11:22:21,216 - Testing sensitivity of module.layer3.0.downsample.0.weight [75.0% sparsity]
2018-11-01 11:22:21,218 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.750 goal=0.750 (24/32)
2018-11-01 11:22:21,219 - --- test ---------------------
2018-11-01 11:22:21,219 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:21,806 - Test: [   10/   39]    Loss 0.657399    Top1 89.531250    Top5 99.492188    
2018-11-01 11:22:21,916 - Test: [   20/   39]    Loss 0.665204    Top1 89.511719    Top5 99.511719    
2018-11-01 11:22:22,024 - Test: [   30/   39]    Loss 0.649541    Top1 89.596354    Top5 99.570312    
2018-11-01 11:22:22,122 - Test: [   40/   39]    Loss 0.654366    Top1 89.680000    Top5 99.530000    
2018-11-01 11:22:22,185 - ==> Top1: 89.680    Top5: 99.530    Loss: 0.654

2018-11-01 11:22:22,187 - Testing sensitivity of module.layer3.0.downsample.0.weight [80.0% sparsity]
2018-11-01 11:22:22,192 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.781 goal=0.800 (25/32)
2018-11-01 11:22:22,193 - --- test ---------------------
2018-11-01 11:22:22,193 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:22,763 - Test: [   10/   39]    Loss 0.666431    Top1 89.218750    Top5 99.453125    
2018-11-01 11:22:22,878 - Test: [   20/   39]    Loss 0.673719    Top1 89.257812    Top5 99.531250    
2018-11-01 11:22:22,986 - Test: [   30/   39]    Loss 0.655919    Top1 89.388021    Top5 99.583333    
2018-11-01 11:22:23,084 - Test: [   40/   39]    Loss 0.664591    Top1 89.570000    Top5 99.530000    
2018-11-01 11:22:23,149 - ==> Top1: 89.570    Top5: 99.530    Loss: 0.665

2018-11-01 11:22:23,149 - Testing sensitivity of module.layer3.0.downsample.0.weight [85.0% sparsity]
2018-11-01 11:22:23,153 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.844 goal=0.850 (27/32)
2018-11-01 11:22:23,155 - --- test ---------------------
2018-11-01 11:22:23,155 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:23,598 - Test: [   10/   39]    Loss 0.690813    Top1 89.492188    Top5 99.335938    
2018-11-01 11:22:23,703 - Test: [   20/   39]    Loss 0.698383    Top1 89.550781    Top5 99.492188    
2018-11-01 11:22:23,810 - Test: [   30/   39]    Loss 0.679665    Top1 89.440104    Top5 99.544271    
2018-11-01 11:22:23,908 - Test: [   40/   39]    Loss 0.684347    Top1 89.550000    Top5 99.470000    
2018-11-01 11:22:23,932 - ==> Top1: 89.550    Top5: 99.470    Loss: 0.684

2018-11-01 11:22:23,933 - Testing sensitivity of module.layer3.0.downsample.0.weight [90.0% sparsity]
2018-11-01 11:22:23,936 - L1RankedStructureParameterPruner - param: module.layer3.0.downsample.0.weight pruned=0.875 goal=0.900 (28/32)
2018-11-01 11:22:23,937 - --- test ---------------------
2018-11-01 11:22:23,937 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:24,363 - Test: [   10/   39]    Loss 0.684243    Top1 89.765625    Top5 99.414062    
2018-11-01 11:22:24,473 - Test: [   20/   39]    Loss 0.691398    Top1 89.824219    Top5 99.492188    
2018-11-01 11:22:24,577 - Test: [   30/   39]    Loss 0.678665    Top1 89.700521    Top5 99.544271    
2018-11-01 11:22:24,673 - Test: [   40/   39]    Loss 0.670991    Top1 89.820000    Top5 99.490000    
2018-11-01 11:22:24,698 - ==> Top1: 89.820    Top5: 99.490    Loss: 0.671

2018-11-01 11:22:24,709 - Testing sensitivity of module.layer3.1.conv1.weight [0.0% sparsity]
2018-11-01 11:22:24,711 - --- test ---------------------
2018-11-01 11:22:24,712 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:25,129 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:22:25,234 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:22:25,338 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:22:25,433 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:22:25,460 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:22:25,460 - Testing sensitivity of module.layer3.1.conv1.weight [5.0% sparsity]
2018-11-01 11:22:25,463 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 11:22:25,464 - --- test ---------------------
2018-11-01 11:22:25,465 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:25,891 - Test: [   10/   39]    Loss 0.561244    Top1 90.507812    Top5 99.648438    
2018-11-01 11:22:25,996 - Test: [   20/   39]    Loss 0.562510    Top1 90.859375    Top5 99.570312    
2018-11-01 11:22:26,101 - Test: [   30/   39]    Loss 0.570315    Top1 90.690104    Top5 99.583333    
2018-11-01 11:22:26,200 - Test: [   40/   39]    Loss 0.564286    Top1 90.760000    Top5 99.590000    
2018-11-01 11:22:26,236 - ==> Top1: 90.760    Top5: 99.590    Loss: 0.564

2018-11-01 11:22:26,237 - Testing sensitivity of module.layer3.1.conv1.weight [10.0% sparsity]
2018-11-01 11:22:26,239 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 11:22:26,240 - --- test ---------------------
2018-11-01 11:22:26,241 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:26,706 - Test: [   10/   39]    Loss 0.621649    Top1 89.257812    Top5 99.453125    
2018-11-01 11:22:26,814 - Test: [   20/   39]    Loss 0.624507    Top1 89.609375    Top5 99.375000    
2018-11-01 11:22:26,919 - Test: [   30/   39]    Loss 0.630837    Top1 89.361979    Top5 99.492188    
2018-11-01 11:22:27,016 - Test: [   40/   39]    Loss 0.627017    Top1 89.430000    Top5 99.470000    
2018-11-01 11:22:27,049 - ==> Top1: 89.430    Top5: 99.470    Loss: 0.627

2018-11-01 11:22:27,050 - Testing sensitivity of module.layer3.1.conv1.weight [15.0% sparsity]
2018-11-01 11:22:27,053 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 11:22:27,053 - --- test ---------------------
2018-11-01 11:22:27,054 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:27,475 - Test: [   10/   39]    Loss 0.625629    Top1 88.828125    Top5 99.453125    
2018-11-01 11:22:27,581 - Test: [   20/   39]    Loss 0.628606    Top1 88.945312    Top5 99.355469    
2018-11-01 11:22:27,685 - Test: [   30/   39]    Loss 0.632457    Top1 88.802083    Top5 99.492188    
2018-11-01 11:22:27,782 - Test: [   40/   39]    Loss 0.627903    Top1 88.890000    Top5 99.520000    
2018-11-01 11:22:27,826 - ==> Top1: 88.890    Top5: 99.520    Loss: 0.628

2018-11-01 11:22:27,827 - Testing sensitivity of module.layer3.1.conv1.weight [20.0% sparsity]
2018-11-01 11:22:27,830 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 11:22:27,832 - --- test ---------------------
2018-11-01 11:22:27,832 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:28,398 - Test: [   10/   39]    Loss 0.670144    Top1 88.203125    Top5 99.375000    
2018-11-01 11:22:28,509 - Test: [   20/   39]    Loss 0.655800    Top1 88.300781    Top5 99.296875    
2018-11-01 11:22:28,616 - Test: [   30/   39]    Loss 0.659171    Top1 88.450521    Top5 99.414062    
2018-11-01 11:22:28,714 - Test: [   40/   39]    Loss 0.657231    Top1 88.440000    Top5 99.440000    
2018-11-01 11:22:28,760 - ==> Top1: 88.440    Top5: 99.440    Loss: 0.657

2018-11-01 11:22:28,761 - Testing sensitivity of module.layer3.1.conv1.weight [25.0% sparsity]
2018-11-01 11:22:28,764 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 11:22:28,765 - --- test ---------------------
2018-11-01 11:22:28,765 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:29,329 - Test: [   10/   39]    Loss 0.734586    Top1 87.656250    Top5 99.335938    
2018-11-01 11:22:29,435 - Test: [   20/   39]    Loss 0.705180    Top1 87.441406    Top5 99.160156    
2018-11-01 11:22:29,539 - Test: [   30/   39]    Loss 0.705544    Top1 87.539062    Top5 99.296875    
2018-11-01 11:22:29,638 - Test: [   40/   39]    Loss 0.697578    Top1 87.660000    Top5 99.320000    
2018-11-01 11:22:29,676 - ==> Top1: 87.660    Top5: 99.320    Loss: 0.698

2018-11-01 11:22:29,676 - Testing sensitivity of module.layer3.1.conv1.weight [30.0% sparsity]
2018-11-01 11:22:29,680 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 11:22:29,681 - --- test ---------------------
2018-11-01 11:22:29,683 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:30,254 - Test: [   10/   39]    Loss 0.754957    Top1 86.132812    Top5 99.335938    
2018-11-01 11:22:30,362 - Test: [   20/   39]    Loss 0.738614    Top1 86.562500    Top5 99.160156    
2018-11-01 11:22:30,470 - Test: [   30/   39]    Loss 0.742092    Top1 86.341146    Top5 99.296875    
2018-11-01 11:22:30,569 - Test: [   40/   39]    Loss 0.736643    Top1 86.490000    Top5 99.320000    
2018-11-01 11:22:30,609 - ==> Top1: 86.490    Top5: 99.320    Loss: 0.737

2018-11-01 11:22:30,624 - Testing sensitivity of module.layer3.1.conv1.weight [35.0% sparsity]
2018-11-01 11:22:30,628 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 11:22:30,629 - --- test ---------------------
2018-11-01 11:22:30,629 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:31,176 - Test: [   10/   39]    Loss 0.780292    Top1 85.195312    Top5 99.101562    
2018-11-01 11:22:31,283 - Test: [   20/   39]    Loss 0.769093    Top1 85.800781    Top5 98.984375    
2018-11-01 11:22:31,387 - Test: [   30/   39]    Loss 0.767265    Top1 85.937500    Top5 99.088542    
2018-11-01 11:22:31,482 - Test: [   40/   39]    Loss 0.770225    Top1 85.780000    Top5 99.110000    
2018-11-01 11:22:31,508 - ==> Top1: 85.780    Top5: 99.110    Loss: 0.770

2018-11-01 11:22:31,509 - Testing sensitivity of module.layer3.1.conv1.weight [40.0% sparsity]
2018-11-01 11:22:31,512 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 11:22:31,513 - --- test ---------------------
2018-11-01 11:22:31,513 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:31,952 - Test: [   10/   39]    Loss 0.798060    Top1 84.687500    Top5 99.257812    
2018-11-01 11:22:32,060 - Test: [   20/   39]    Loss 0.782719    Top1 85.332031    Top5 99.003906    
2018-11-01 11:22:32,168 - Test: [   30/   39]    Loss 0.777363    Top1 85.468750    Top5 99.075521    
2018-11-01 11:22:32,263 - Test: [   40/   39]    Loss 0.779178    Top1 85.260000    Top5 99.070000    
2018-11-01 11:22:32,289 - ==> Top1: 85.260    Top5: 99.070    Loss: 0.779

2018-11-01 11:22:32,290 - Testing sensitivity of module.layer3.1.conv1.weight [45.0% sparsity]
2018-11-01 11:22:32,293 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 11:22:32,294 - --- test ---------------------
2018-11-01 11:22:32,294 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:32,741 - Test: [   10/   39]    Loss 0.985595    Top1 81.757812    Top5 98.906250    
2018-11-01 11:22:32,847 - Test: [   20/   39]    Loss 0.951418    Top1 82.656250    Top5 98.828125    
2018-11-01 11:22:32,951 - Test: [   30/   39]    Loss 0.949698    Top1 82.721354    Top5 98.854167    
2018-11-01 11:22:33,046 - Test: [   40/   39]    Loss 0.940523    Top1 82.640000    Top5 98.880000    
2018-11-01 11:22:33,072 - ==> Top1: 82.640    Top5: 98.880    Loss: 0.941

2018-11-01 11:22:33,072 - Testing sensitivity of module.layer3.1.conv1.weight [50.0% sparsity]
2018-11-01 11:22:33,075 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 11:22:33,076 - --- test ---------------------
2018-11-01 11:22:33,076 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:33,510 - Test: [   10/   39]    Loss 1.102346    Top1 80.625000    Top5 98.554688    
2018-11-01 11:22:33,616 - Test: [   20/   39]    Loss 1.071540    Top1 80.664062    Top5 98.554688    
2018-11-01 11:22:33,719 - Test: [   30/   39]    Loss 1.059832    Top1 80.690104    Top5 98.645833    
2018-11-01 11:22:33,814 - Test: [   40/   39]    Loss 1.050411    Top1 80.650000    Top5 98.700000    
2018-11-01 11:22:33,839 - ==> Top1: 80.650    Top5: 98.700    Loss: 1.050

2018-11-01 11:22:33,840 - Testing sensitivity of module.layer3.1.conv1.weight [55.0% sparsity]
2018-11-01 11:22:33,843 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 11:22:33,844 - --- test ---------------------
2018-11-01 11:22:33,844 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:34,274 - Test: [   10/   39]    Loss 1.123472    Top1 79.218750    Top5 98.789062    
2018-11-01 11:22:34,380 - Test: [   20/   39]    Loss 1.097738    Top1 79.121094    Top5 98.671875    
2018-11-01 11:22:34,487 - Test: [   30/   39]    Loss 1.099783    Top1 79.127604    Top5 98.736979    
2018-11-01 11:22:34,586 - Test: [   40/   39]    Loss 1.095061    Top1 79.120000    Top5 98.760000    
2018-11-01 11:22:34,624 - ==> Top1: 79.120    Top5: 98.760    Loss: 1.095

2018-11-01 11:22:34,625 - Testing sensitivity of module.layer3.1.conv1.weight [60.0% sparsity]
2018-11-01 11:22:34,640 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 11:22:34,642 - --- test ---------------------
2018-11-01 11:22:34,642 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:35,211 - Test: [   10/   39]    Loss 1.019146    Top1 78.906250    Top5 98.671875    
2018-11-01 11:22:35,321 - Test: [   20/   39]    Loss 1.004034    Top1 79.238281    Top5 98.574219    
2018-11-01 11:22:35,428 - Test: [   30/   39]    Loss 1.014806    Top1 79.127604    Top5 98.671875    
2018-11-01 11:22:35,526 - Test: [   40/   39]    Loss 1.007954    Top1 79.100000    Top5 98.660000    
2018-11-01 11:22:35,587 - ==> Top1: 79.100    Top5: 98.660    Loss: 1.008

2018-11-01 11:22:35,588 - Testing sensitivity of module.layer3.1.conv1.weight [65.0% sparsity]
2018-11-01 11:22:35,591 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 11:22:35,593 - --- test ---------------------
2018-11-01 11:22:35,593 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:36,188 - Test: [   10/   39]    Loss 1.123351    Top1 75.585938    Top5 97.460938    
2018-11-01 11:22:36,297 - Test: [   20/   39]    Loss 1.090026    Top1 75.839844    Top5 97.480469    
2018-11-01 11:22:36,405 - Test: [   30/   39]    Loss 1.088789    Top1 75.442708    Top5 97.539062    
2018-11-01 11:22:36,503 - Test: [   40/   39]    Loss 1.085259    Top1 75.490000    Top5 97.600000    
2018-11-01 11:22:36,549 - ==> Top1: 75.490    Top5: 97.600    Loss: 1.085

2018-11-01 11:22:36,550 - Testing sensitivity of module.layer3.1.conv1.weight [70.0% sparsity]
2018-11-01 11:22:36,554 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 11:22:36,555 - --- test ---------------------
2018-11-01 11:22:36,556 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:37,092 - Test: [   10/   39]    Loss 1.183660    Top1 71.640625    Top5 95.937500    
2018-11-01 11:22:37,204 - Test: [   20/   39]    Loss 1.171337    Top1 72.148438    Top5 95.996094    
2018-11-01 11:22:37,311 - Test: [   30/   39]    Loss 1.173475    Top1 71.588542    Top5 96.158854    
2018-11-01 11:22:37,409 - Test: [   40/   39]    Loss 1.161882    Top1 71.560000    Top5 96.180000    
2018-11-01 11:22:37,449 - ==> Top1: 71.560    Top5: 96.180    Loss: 1.162

2018-11-01 11:22:37,449 - Testing sensitivity of module.layer3.1.conv1.weight [75.0% sparsity]
2018-11-01 11:22:37,457 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 11:22:37,459 - --- test ---------------------
2018-11-01 11:22:37,459 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:37,998 - Test: [   10/   39]    Loss 1.274445    Top1 63.476562    Top5 94.062500    
2018-11-01 11:22:38,110 - Test: [   20/   39]    Loss 1.246459    Top1 64.199219    Top5 94.082031    
2018-11-01 11:22:38,218 - Test: [   30/   39]    Loss 1.256899    Top1 63.476562    Top5 94.244792    
2018-11-01 11:22:38,318 - Test: [   40/   39]    Loss 1.260327    Top1 63.040000    Top5 94.310000    
2018-11-01 11:22:38,376 - ==> Top1: 63.040    Top5: 94.310    Loss: 1.260

2018-11-01 11:22:38,377 - Testing sensitivity of module.layer3.1.conv1.weight [80.0% sparsity]
2018-11-01 11:22:38,379 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 11:22:38,379 - --- test ---------------------
2018-11-01 11:22:38,380 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:38,864 - Test: [   10/   39]    Loss 1.717392    Top1 48.789062    Top5 91.367188    
2018-11-01 11:22:38,975 - Test: [   20/   39]    Loss 1.680986    Top1 50.253906    Top5 91.464844    
2018-11-01 11:22:39,084 - Test: [   30/   39]    Loss 1.691259    Top1 49.960938    Top5 91.770833    
2018-11-01 11:22:39,182 - Test: [   40/   39]    Loss 1.706409    Top1 49.360000    Top5 91.660000    
2018-11-01 11:22:39,242 - ==> Top1: 49.360    Top5: 91.660    Loss: 1.706

2018-11-01 11:22:39,243 - Testing sensitivity of module.layer3.1.conv1.weight [85.0% sparsity]
2018-11-01 11:22:39,246 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 11:22:39,247 - --- test ---------------------
2018-11-01 11:22:39,247 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:39,758 - Test: [   10/   39]    Loss 2.036233    Top1 38.750000    Top5 90.117188    
2018-11-01 11:22:39,864 - Test: [   20/   39]    Loss 1.991853    Top1 39.433594    Top5 90.488281    
2018-11-01 11:22:39,967 - Test: [   30/   39]    Loss 2.008811    Top1 38.841146    Top5 90.598958    
2018-11-01 11:22:40,064 - Test: [   40/   39]    Loss 2.021282    Top1 38.280000    Top5 90.430000    
2018-11-01 11:22:40,110 - ==> Top1: 38.280    Top5: 90.430    Loss: 2.021

2018-11-01 11:22:40,111 - Testing sensitivity of module.layer3.1.conv1.weight [90.0% sparsity]
2018-11-01 11:22:40,116 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 11:22:40,118 - --- test ---------------------
2018-11-01 11:22:40,119 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:40,602 - Test: [   10/   39]    Loss 2.243610    Top1 30.117187    Top5 83.906250    
2018-11-01 11:22:40,710 - Test: [   20/   39]    Loss 2.207125    Top1 30.898437    Top5 84.550781    
2018-11-01 11:22:40,815 - Test: [   30/   39]    Loss 2.226731    Top1 30.182292    Top5 84.739583    
2018-11-01 11:22:40,910 - Test: [   40/   39]    Loss 2.246328    Top1 29.740000    Top5 84.380000    
2018-11-01 11:22:40,935 - ==> Top1: 29.740    Top5: 84.380    Loss: 2.246

2018-11-01 11:22:40,947 - Testing sensitivity of module.layer3.1.conv2.weight [0.0% sparsity]
2018-11-01 11:22:40,950 - --- test ---------------------
2018-11-01 11:22:40,950 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:41,369 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:22:41,476 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:22:41,579 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:22:41,674 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:22:41,700 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:22:41,701 - Testing sensitivity of module.layer3.1.conv2.weight [5.0% sparsity]
2018-11-01 11:22:41,704 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 11:22:41,705 - --- test ---------------------
2018-11-01 11:22:41,705 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:42,136 - Test: [   10/   39]    Loss 0.617804    Top1 90.507812    Top5 99.648438    
2018-11-01 11:22:42,241 - Test: [   20/   39]    Loss 0.599881    Top1 90.781250    Top5 99.531250    
2018-11-01 11:22:42,343 - Test: [   30/   39]    Loss 0.593780    Top1 90.742188    Top5 99.648438    
2018-11-01 11:22:42,439 - Test: [   40/   39]    Loss 0.580056    Top1 90.860000    Top5 99.630000    
2018-11-01 11:22:42,464 - ==> Top1: 90.860    Top5: 99.630    Loss: 0.580

2018-11-01 11:22:42,466 - Testing sensitivity of module.layer3.1.conv2.weight [10.0% sparsity]
2018-11-01 11:22:42,469 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 11:22:42,470 - --- test ---------------------
2018-11-01 11:22:42,470 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:42,891 - Test: [   10/   39]    Loss 0.689126    Top1 89.960938    Top5 99.648438    
2018-11-01 11:22:42,997 - Test: [   20/   39]    Loss 0.670490    Top1 90.214844    Top5 99.550781    
2018-11-01 11:22:43,105 - Test: [   30/   39]    Loss 0.656396    Top1 90.221354    Top5 99.648438    
2018-11-01 11:22:43,204 - Test: [   40/   39]    Loss 0.643843    Top1 90.270000    Top5 99.640000    
2018-11-01 11:22:43,205 - ==> Top1: 90.270    Top5: 99.640    Loss: 0.644

2018-11-01 11:22:43,238 - Testing sensitivity of module.layer3.1.conv2.weight [15.0% sparsity]
2018-11-01 11:22:43,242 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 11:22:43,243 - --- test ---------------------
2018-11-01 11:22:43,244 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:43,705 - Test: [   10/   39]    Loss 0.740786    Top1 89.726562    Top5 99.570312    
2018-11-01 11:22:43,812 - Test: [   20/   39]    Loss 0.722817    Top1 89.921875    Top5 99.414062    
2018-11-01 11:22:43,916 - Test: [   30/   39]    Loss 0.717345    Top1 89.713542    Top5 99.544271    
2018-11-01 11:22:44,012 - Test: [   40/   39]    Loss 0.703616    Top1 89.670000    Top5 99.550000    
2018-11-01 11:22:44,037 - ==> Top1: 89.670    Top5: 99.550    Loss: 0.704

2018-11-01 11:22:44,038 - Testing sensitivity of module.layer3.1.conv2.weight [20.0% sparsity]
2018-11-01 11:22:44,040 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 11:22:44,041 - --- test ---------------------
2018-11-01 11:22:44,041 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:44,466 - Test: [   10/   39]    Loss 0.880151    Top1 88.320312    Top5 99.492188    
2018-11-01 11:22:44,572 - Test: [   20/   39]    Loss 0.846125    Top1 88.281250    Top5 99.375000    
2018-11-01 11:22:44,677 - Test: [   30/   39]    Loss 0.844270    Top1 88.216146    Top5 99.492188    
2018-11-01 11:22:44,775 - Test: [   40/   39]    Loss 0.832201    Top1 88.160000    Top5 99.500000    
2018-11-01 11:22:44,800 - ==> Top1: 88.160    Top5: 99.500    Loss: 0.832

2018-11-01 11:22:44,801 - Testing sensitivity of module.layer3.1.conv2.weight [25.0% sparsity]
2018-11-01 11:22:44,804 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 11:22:44,805 - --- test ---------------------
2018-11-01 11:22:44,805 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:45,256 - Test: [   10/   39]    Loss 1.075011    Top1 85.703125    Top5 99.414062    
2018-11-01 11:22:45,363 - Test: [   20/   39]    Loss 1.046485    Top1 85.957031    Top5 99.316406    
2018-11-01 11:22:45,468 - Test: [   30/   39]    Loss 1.053150    Top1 85.781250    Top5 99.335938    
2018-11-01 11:22:45,563 - Test: [   40/   39]    Loss 1.036474    Top1 85.960000    Top5 99.330000    
2018-11-01 11:22:45,589 - ==> Top1: 85.960    Top5: 99.330    Loss: 1.036

2018-11-01 11:22:45,589 - Testing sensitivity of module.layer3.1.conv2.weight [30.0% sparsity]
2018-11-01 11:22:45,592 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 11:22:45,593 - --- test ---------------------
2018-11-01 11:22:45,593 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:46,032 - Test: [   10/   39]    Loss 1.055681    Top1 85.546875    Top5 99.414062    
2018-11-01 11:22:46,140 - Test: [   20/   39]    Loss 1.041088    Top1 85.585938    Top5 99.238281    
2018-11-01 11:22:46,245 - Test: [   30/   39]    Loss 1.052324    Top1 85.481771    Top5 99.283854    
2018-11-01 11:22:46,341 - Test: [   40/   39]    Loss 1.029074    Top1 85.880000    Top5 99.300000    
2018-11-01 11:22:46,367 - ==> Top1: 85.880    Top5: 99.300    Loss: 1.029

2018-11-01 11:22:46,368 - Testing sensitivity of module.layer3.1.conv2.weight [35.0% sparsity]
2018-11-01 11:22:46,371 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 11:22:46,371 - --- test ---------------------
2018-11-01 11:22:46,372 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:46,799 - Test: [   10/   39]    Loss 1.229366    Top1 84.257812    Top5 99.296875    
2018-11-01 11:22:46,909 - Test: [   20/   39]    Loss 1.233447    Top1 84.277344    Top5 99.179688    
2018-11-01 11:22:47,014 - Test: [   30/   39]    Loss 1.251189    Top1 84.036458    Top5 99.179688    
2018-11-01 11:22:47,109 - Test: [   40/   39]    Loss 1.246426    Top1 84.160000    Top5 99.170000    
2018-11-01 11:22:47,134 - ==> Top1: 84.160    Top5: 99.170    Loss: 1.246

2018-11-01 11:22:47,135 - Testing sensitivity of module.layer3.1.conv2.weight [40.0% sparsity]
2018-11-01 11:22:47,138 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 11:22:47,139 - --- test ---------------------
2018-11-01 11:22:47,139 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:47,573 - Test: [   10/   39]    Loss 1.565236    Top1 81.289062    Top5 99.218750    
2018-11-01 11:22:47,680 - Test: [   20/   39]    Loss 1.565185    Top1 81.308594    Top5 99.003906    
2018-11-01 11:22:47,785 - Test: [   30/   39]    Loss 1.570073    Top1 81.067708    Top5 98.945312    
2018-11-01 11:22:47,882 - Test: [   40/   39]    Loss 1.551345    Top1 81.060000    Top5 99.000000    
2018-11-01 11:22:47,908 - ==> Top1: 81.060    Top5: 99.000    Loss: 1.551

2018-11-01 11:22:47,908 - Testing sensitivity of module.layer3.1.conv2.weight [45.0% sparsity]
2018-11-01 11:22:47,911 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 11:22:47,912 - --- test ---------------------
2018-11-01 11:22:47,913 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:48,360 - Test: [   10/   39]    Loss 1.702891    Top1 80.312500    Top5 99.101562    
2018-11-01 11:22:48,468 - Test: [   20/   39]    Loss 1.702352    Top1 80.683594    Top5 98.906250    
2018-11-01 11:22:48,573 - Test: [   30/   39]    Loss 1.716569    Top1 80.559896    Top5 98.906250    
2018-11-01 11:22:48,669 - Test: [   40/   39]    Loss 1.691298    Top1 80.680000    Top5 98.910000    
2018-11-01 11:22:48,704 - ==> Top1: 80.680    Top5: 98.910    Loss: 1.691

2018-11-01 11:22:48,705 - Testing sensitivity of module.layer3.1.conv2.weight [50.0% sparsity]
2018-11-01 11:22:48,707 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 11:22:48,708 - --- test ---------------------
2018-11-01 11:22:48,708 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:49,128 - Test: [   10/   39]    Loss 1.778111    Top1 79.335938    Top5 98.906250    
2018-11-01 11:22:49,234 - Test: [   20/   39]    Loss 1.786334    Top1 79.628906    Top5 98.652344    
2018-11-01 11:22:49,338 - Test: [   30/   39]    Loss 1.805226    Top1 79.335938    Top5 98.710938    
2018-11-01 11:22:49,434 - Test: [   40/   39]    Loss 1.816829    Top1 79.260000    Top5 98.670000    
2018-11-01 11:22:49,460 - ==> Top1: 79.260    Top5: 98.670    Loss: 1.817

2018-11-01 11:22:49,461 - Testing sensitivity of module.layer3.1.conv2.weight [55.0% sparsity]
2018-11-01 11:22:49,464 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 11:22:49,465 - --- test ---------------------
2018-11-01 11:22:49,465 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:49,923 - Test: [   10/   39]    Loss 2.471865    Top1 73.437500    Top5 98.554688    
2018-11-01 11:22:50,031 - Test: [   20/   39]    Loss 2.449610    Top1 73.964844    Top5 98.535156    
2018-11-01 11:22:50,136 - Test: [   30/   39]    Loss 2.492544    Top1 73.684896    Top5 98.593750    
2018-11-01 11:22:50,234 - Test: [   40/   39]    Loss 2.475909    Top1 73.620000    Top5 98.550000    
2018-11-01 11:22:50,258 - ==> Top1: 73.620    Top5: 98.550    Loss: 2.476

2018-11-01 11:22:50,259 - Testing sensitivity of module.layer3.1.conv2.weight [60.0% sparsity]
2018-11-01 11:22:50,262 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 11:22:50,263 - --- test ---------------------
2018-11-01 11:22:50,264 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:50,703 - Test: [   10/   39]    Loss 2.854368    Top1 71.484375    Top5 98.320312    
2018-11-01 11:22:50,809 - Test: [   20/   39]    Loss 2.854854    Top1 72.031250    Top5 98.242188    
2018-11-01 11:22:50,913 - Test: [   30/   39]    Loss 2.896391    Top1 71.692708    Top5 98.229167    
2018-11-01 11:22:51,009 - Test: [   40/   39]    Loss 2.860343    Top1 71.890000    Top5 98.200000    
2018-11-01 11:22:51,044 - ==> Top1: 71.890    Top5: 98.200    Loss: 2.860

2018-11-01 11:22:51,045 - Testing sensitivity of module.layer3.1.conv2.weight [65.0% sparsity]
2018-11-01 11:22:51,047 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 11:22:51,047 - --- test ---------------------
2018-11-01 11:22:51,047 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:51,470 - Test: [   10/   39]    Loss 3.127650    Top1 68.242188    Top5 97.890625    
2018-11-01 11:22:51,577 - Test: [   20/   39]    Loss 3.107970    Top1 68.613281    Top5 97.988281    
2018-11-01 11:22:51,682 - Test: [   30/   39]    Loss 3.105905    Top1 68.424479    Top5 97.955729    
2018-11-01 11:22:51,778 - Test: [   40/   39]    Loss 3.069774    Top1 68.640000    Top5 97.980000    
2018-11-01 11:22:51,805 - ==> Top1: 68.640    Top5: 97.980    Loss: 3.070

2018-11-01 11:22:51,806 - Testing sensitivity of module.layer3.1.conv2.weight [70.0% sparsity]
2018-11-01 11:22:51,809 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 11:22:51,810 - --- test ---------------------
2018-11-01 11:22:51,810 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:52,254 - Test: [   10/   39]    Loss 2.908806    Top1 68.007812    Top5 97.773438    
2018-11-01 11:22:52,362 - Test: [   20/   39]    Loss 2.900603    Top1 68.886719    Top5 97.695312    
2018-11-01 11:22:52,466 - Test: [   30/   39]    Loss 2.894699    Top1 68.893229    Top5 97.799479    
2018-11-01 11:22:52,563 - Test: [   40/   39]    Loss 2.869937    Top1 68.990000    Top5 97.840000    
2018-11-01 11:22:52,588 - ==> Top1: 68.990    Top5: 97.840    Loss: 2.870

2018-11-01 11:22:52,589 - Testing sensitivity of module.layer3.1.conv2.weight [75.0% sparsity]
2018-11-01 11:22:52,592 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 11:22:52,593 - --- test ---------------------
2018-11-01 11:22:52,594 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:53,026 - Test: [   10/   39]    Loss 3.864320    Top1 63.242188    Top5 94.648438    
2018-11-01 11:22:53,132 - Test: [   20/   39]    Loss 3.844462    Top1 63.417969    Top5 95.097656    
2018-11-01 11:22:53,235 - Test: [   30/   39]    Loss 3.841804    Top1 63.164062    Top5 95.156250    
2018-11-01 11:22:53,330 - Test: [   40/   39]    Loss 3.854387    Top1 63.100000    Top5 95.170000    
2018-11-01 11:22:53,355 - ==> Top1: 63.100    Top5: 95.170    Loss: 3.854

2018-11-01 11:22:53,358 - Testing sensitivity of module.layer3.1.conv2.weight [80.0% sparsity]
2018-11-01 11:22:53,361 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 11:22:53,362 - --- test ---------------------
2018-11-01 11:22:53,363 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:53,791 - Test: [   10/   39]    Loss 4.076587    Top1 60.273438    Top5 94.492188    
2018-11-01 11:22:53,897 - Test: [   20/   39]    Loss 4.050107    Top1 61.171875    Top5 94.843750    
2018-11-01 11:22:54,000 - Test: [   30/   39]    Loss 4.076759    Top1 60.520833    Top5 95.052083    
2018-11-01 11:22:54,094 - Test: [   40/   39]    Loss 4.082818    Top1 60.440000    Top5 94.990000    
2018-11-01 11:22:54,120 - ==> Top1: 60.440    Top5: 94.990    Loss: 4.083

2018-11-01 11:22:54,121 - Testing sensitivity of module.layer3.1.conv2.weight [85.0% sparsity]
2018-11-01 11:22:54,124 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 11:22:54,125 - --- test ---------------------
2018-11-01 11:22:54,125 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:54,559 - Test: [   10/   39]    Loss 5.817771    Top1 49.687500    Top5 94.335938    
2018-11-01 11:22:54,665 - Test: [   20/   39]    Loss 5.672066    Top1 51.015625    Top5 94.707031    
2018-11-01 11:22:54,768 - Test: [   30/   39]    Loss 5.751091    Top1 50.416667    Top5 94.830729    
2018-11-01 11:22:54,863 - Test: [   40/   39]    Loss 5.770582    Top1 50.230000    Top5 94.770000    
2018-11-01 11:22:54,889 - ==> Top1: 50.230    Top5: 94.770    Loss: 5.771

2018-11-01 11:22:54,889 - Testing sensitivity of module.layer3.1.conv2.weight [90.0% sparsity]
2018-11-01 11:22:54,891 - L1RankedStructureParameterPruner - param: module.layer3.1.conv2.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 11:22:54,892 - --- test ---------------------
2018-11-01 11:22:54,892 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:55,313 - Test: [   10/   39]    Loss 6.273677    Top1 47.226562    Top5 94.335938    
2018-11-01 11:22:55,419 - Test: [   20/   39]    Loss 6.090548    Top1 48.359375    Top5 94.531250    
2018-11-01 11:22:55,523 - Test: [   30/   39]    Loss 6.182306    Top1 47.760417    Top5 94.609375    
2018-11-01 11:22:55,620 - Test: [   40/   39]    Loss 6.184807    Top1 47.460000    Top5 94.700000    
2018-11-01 11:22:55,636 - ==> Top1: 47.460    Top5: 94.700    Loss: 6.185

2018-11-01 11:22:55,655 - Testing sensitivity of module.layer3.2.conv1.weight [0.0% sparsity]
2018-11-01 11:22:55,659 - --- test ---------------------
2018-11-01 11:22:55,659 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:56,093 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:22:56,198 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:22:56,303 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:22:56,399 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:22:56,426 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:22:56,427 - Testing sensitivity of module.layer3.2.conv1.weight [5.0% sparsity]
2018-11-01 11:22:56,430 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 11:22:56,431 - --- test ---------------------
2018-11-01 11:22:56,431 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:56,860 - Test: [   10/   39]    Loss 0.568391    Top1 90.390625    Top5 99.492188    
2018-11-01 11:22:56,967 - Test: [   20/   39]    Loss 0.567676    Top1 90.878906    Top5 99.511719    
2018-11-01 11:22:57,070 - Test: [   30/   39]    Loss 0.561002    Top1 90.716146    Top5 99.596354    
2018-11-01 11:22:57,165 - Test: [   40/   39]    Loss 0.562255    Top1 90.660000    Top5 99.590000    
2018-11-01 11:22:57,191 - ==> Top1: 90.660    Top5: 99.590    Loss: 0.562

2018-11-01 11:22:57,192 - Testing sensitivity of module.layer3.2.conv1.weight [10.0% sparsity]
2018-11-01 11:22:57,195 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 11:22:57,196 - --- test ---------------------
2018-11-01 11:22:57,196 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:57,627 - Test: [   10/   39]    Loss 0.610902    Top1 88.984375    Top5 99.335938    
2018-11-01 11:22:57,734 - Test: [   20/   39]    Loss 0.605059    Top1 89.453125    Top5 99.375000    
2018-11-01 11:22:57,837 - Test: [   30/   39]    Loss 0.582774    Top1 89.817708    Top5 99.427083    
2018-11-01 11:22:57,933 - Test: [   40/   39]    Loss 0.589720    Top1 89.870000    Top5 99.390000    
2018-11-01 11:22:57,959 - ==> Top1: 89.870    Top5: 99.390    Loss: 0.590

2018-11-01 11:22:57,960 - Testing sensitivity of module.layer3.2.conv1.weight [15.0% sparsity]
2018-11-01 11:22:57,963 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 11:22:57,964 - --- test ---------------------
2018-11-01 11:22:57,964 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:58,390 - Test: [   10/   39]    Loss 0.684736    Top1 88.125000    Top5 99.140625    
2018-11-01 11:22:58,496 - Test: [   20/   39]    Loss 0.687896    Top1 88.222656    Top5 99.199219    
2018-11-01 11:22:58,601 - Test: [   30/   39]    Loss 0.673358    Top1 88.281250    Top5 99.244792    
2018-11-01 11:22:58,697 - Test: [   40/   39]    Loss 0.680813    Top1 88.410000    Top5 99.250000    
2018-11-01 11:22:58,723 - ==> Top1: 88.410    Top5: 99.250    Loss: 0.681

2018-11-01 11:22:58,724 - Testing sensitivity of module.layer3.2.conv1.weight [20.0% sparsity]
2018-11-01 11:22:58,726 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 11:22:58,728 - --- test ---------------------
2018-11-01 11:22:58,729 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:59,175 - Test: [   10/   39]    Loss 0.795670    Top1 86.250000    Top5 98.750000    
2018-11-01 11:22:59,281 - Test: [   20/   39]    Loss 0.789793    Top1 86.542969    Top5 98.847656    
2018-11-01 11:22:59,384 - Test: [   30/   39]    Loss 0.774456    Top1 86.497396    Top5 98.958333    
2018-11-01 11:22:59,479 - Test: [   40/   39]    Loss 0.762225    Top1 86.730000    Top5 98.930000    
2018-11-01 11:22:59,505 - ==> Top1: 86.730    Top5: 98.930    Loss: 0.762

2018-11-01 11:22:59,506 - Testing sensitivity of module.layer3.2.conv1.weight [25.0% sparsity]
2018-11-01 11:22:59,510 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 11:22:59,511 - --- test ---------------------
2018-11-01 11:22:59,511 - 10000 samples (256 per mini-batch)
2018-11-01 11:22:59,955 - Test: [   10/   39]    Loss 0.900969    Top1 83.945312    Top5 98.320312    
2018-11-01 11:23:00,063 - Test: [   20/   39]    Loss 0.890310    Top1 84.414062    Top5 98.437500    
2018-11-01 11:23:00,167 - Test: [   30/   39]    Loss 0.883988    Top1 84.466146    Top5 98.554688    
2018-11-01 11:23:00,263 - Test: [   40/   39]    Loss 0.867983    Top1 84.610000    Top5 98.500000    
2018-11-01 11:23:00,291 - ==> Top1: 84.610    Top5: 98.500    Loss: 0.868

2018-11-01 11:23:00,294 - Testing sensitivity of module.layer3.2.conv1.weight [30.0% sparsity]
2018-11-01 11:23:00,298 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 11:23:00,300 - --- test ---------------------
2018-11-01 11:23:00,300 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:00,745 - Test: [   10/   39]    Loss 0.831262    Top1 84.296875    Top5 97.695312    
2018-11-01 11:23:00,853 - Test: [   20/   39]    Loss 0.818864    Top1 84.667969    Top5 97.949219    
2018-11-01 11:23:00,957 - Test: [   30/   39]    Loss 0.815404    Top1 84.322917    Top5 98.177083    
2018-11-01 11:23:01,054 - Test: [   40/   39]    Loss 0.798908    Top1 84.440000    Top5 98.180000    
2018-11-01 11:23:01,078 - ==> Top1: 84.440    Top5: 98.180    Loss: 0.799

2018-11-01 11:23:01,079 - Testing sensitivity of module.layer3.2.conv1.weight [35.0% sparsity]
2018-11-01 11:23:01,082 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 11:23:01,083 - --- test ---------------------
2018-11-01 11:23:01,083 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:01,527 - Test: [   10/   39]    Loss 1.271926    Top1 76.718750    Top5 95.976562    
2018-11-01 11:23:01,634 - Test: [   20/   39]    Loss 1.259440    Top1 76.523438    Top5 95.996094    
2018-11-01 11:23:01,738 - Test: [   30/   39]    Loss 1.273063    Top1 76.119792    Top5 96.028646    
2018-11-01 11:23:01,834 - Test: [   40/   39]    Loss 1.254919    Top1 76.260000    Top5 96.080000    
2018-11-01 11:23:01,859 - ==> Top1: 76.260    Top5: 96.080    Loss: 1.255

2018-11-01 11:23:01,860 - Testing sensitivity of module.layer3.2.conv1.weight [40.0% sparsity]
2018-11-01 11:23:01,862 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 11:23:01,863 - --- test ---------------------
2018-11-01 11:23:01,864 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:02,309 - Test: [   10/   39]    Loss 1.636735    Top1 71.210938    Top5 94.414062    
2018-11-01 11:23:02,418 - Test: [   20/   39]    Loss 1.629279    Top1 71.406250    Top5 94.550781    
2018-11-01 11:23:02,524 - Test: [   30/   39]    Loss 1.630340    Top1 71.315104    Top5 94.453125    
2018-11-01 11:23:02,620 - Test: [   40/   39]    Loss 1.624155    Top1 71.210000    Top5 94.460000    
2018-11-01 11:23:02,646 - ==> Top1: 71.210    Top5: 94.460    Loss: 1.624

2018-11-01 11:23:02,647 - Testing sensitivity of module.layer3.2.conv1.weight [45.0% sparsity]
2018-11-01 11:23:02,652 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 11:23:02,653 - --- test ---------------------
2018-11-01 11:23:02,653 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:03,100 - Test: [   10/   39]    Loss 1.773335    Top1 68.437500    Top5 95.078125    
2018-11-01 11:23:03,209 - Test: [   20/   39]    Loss 1.760531    Top1 68.593750    Top5 95.097656    
2018-11-01 11:23:03,318 - Test: [   30/   39]    Loss 1.761301    Top1 68.437500    Top5 94.921875    
2018-11-01 11:23:03,416 - Test: [   40/   39]    Loss 1.755108    Top1 68.490000    Top5 94.920000    
2018-11-01 11:23:03,447 - ==> Top1: 68.490    Top5: 94.920    Loss: 1.755

2018-11-01 11:23:03,447 - Testing sensitivity of module.layer3.2.conv1.weight [50.0% sparsity]
2018-11-01 11:23:03,450 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 11:23:03,450 - --- test ---------------------
2018-11-01 11:23:03,451 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:03,903 - Test: [   10/   39]    Loss 2.717351    Top1 55.117188    Top5 93.203125    
2018-11-01 11:23:04,009 - Test: [   20/   39]    Loss 2.741505    Top1 55.097656    Top5 93.320312    
2018-11-01 11:23:04,116 - Test: [   30/   39]    Loss 2.730224    Top1 55.221354    Top5 93.085938    
2018-11-01 11:23:04,213 - Test: [   40/   39]    Loss 2.701365    Top1 55.350000    Top5 93.050000    
2018-11-01 11:23:04,247 - ==> Top1: 55.350    Top5: 93.050    Loss: 2.701

2018-11-01 11:23:04,248 - Testing sensitivity of module.layer3.2.conv1.weight [55.0% sparsity]
2018-11-01 11:23:04,252 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 11:23:04,253 - --- test ---------------------
2018-11-01 11:23:04,253 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:04,721 - Test: [   10/   39]    Loss 2.416993    Top1 58.828125    Top5 93.632812    
2018-11-01 11:23:04,833 - Test: [   20/   39]    Loss 2.435500    Top1 58.632812    Top5 93.945312    
2018-11-01 11:23:04,941 - Test: [   30/   39]    Loss 2.434573    Top1 58.554688    Top5 93.736979    
2018-11-01 11:23:05,040 - Test: [   40/   39]    Loss 2.412013    Top1 58.440000    Top5 93.840000    
2018-11-01 11:23:05,072 - ==> Top1: 58.440    Top5: 93.840    Loss: 2.412

2018-11-01 11:23:05,072 - Testing sensitivity of module.layer3.2.conv1.weight [60.0% sparsity]
2018-11-01 11:23:05,075 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 11:23:05,076 - --- test ---------------------
2018-11-01 11:23:05,076 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:05,520 - Test: [   10/   39]    Loss 1.851377    Top1 63.593750    Top5 94.609375    
2018-11-01 11:23:05,627 - Test: [   20/   39]    Loss 1.870168    Top1 63.730469    Top5 95.039062    
2018-11-01 11:23:05,732 - Test: [   30/   39]    Loss 1.868517    Top1 63.789063    Top5 94.726562    
2018-11-01 11:23:05,828 - Test: [   40/   39]    Loss 1.853217    Top1 63.730000    Top5 94.710000    
2018-11-01 11:23:05,856 - ==> Top1: 63.730    Top5: 94.710    Loss: 1.853

2018-11-01 11:23:05,857 - Testing sensitivity of module.layer3.2.conv1.weight [65.0% sparsity]
2018-11-01 11:23:05,860 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 11:23:05,861 - --- test ---------------------
2018-11-01 11:23:05,863 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:06,331 - Test: [   10/   39]    Loss 2.018713    Top1 58.710938    Top5 95.859375    
2018-11-01 11:23:06,437 - Test: [   20/   39]    Loss 2.025396    Top1 58.808594    Top5 95.761719    
2018-11-01 11:23:06,541 - Test: [   30/   39]    Loss 2.011328    Top1 59.205729    Top5 95.416667    
2018-11-01 11:23:06,638 - Test: [   40/   39]    Loss 2.005557    Top1 59.080000    Top5 95.350000    
2018-11-01 11:23:06,663 - ==> Top1: 59.080    Top5: 95.350    Loss: 2.006

2018-11-01 11:23:06,666 - Testing sensitivity of module.layer3.2.conv1.weight [70.0% sparsity]
2018-11-01 11:23:06,669 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 11:23:06,673 - --- test ---------------------
2018-11-01 11:23:06,673 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:07,119 - Test: [   10/   39]    Loss 2.776293    Top1 54.218750    Top5 95.468750    
2018-11-01 11:23:07,226 - Test: [   20/   39]    Loss 2.800572    Top1 55.175781    Top5 95.429688    
2018-11-01 11:23:07,331 - Test: [   30/   39]    Loss 2.773717    Top1 55.104167    Top5 95.364583    
2018-11-01 11:23:07,426 - Test: [   40/   39]    Loss 2.791398    Top1 55.110000    Top5 95.290000    
2018-11-01 11:23:07,451 - ==> Top1: 55.110    Top5: 95.290    Loss: 2.791

2018-11-01 11:23:07,453 - Testing sensitivity of module.layer3.2.conv1.weight [75.0% sparsity]
2018-11-01 11:23:07,456 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 11:23:07,457 - --- test ---------------------
2018-11-01 11:23:07,457 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:07,914 - Test: [   10/   39]    Loss 3.905357    Top1 36.796875    Top5 92.031250    
2018-11-01 11:23:08,022 - Test: [   20/   39]    Loss 3.924726    Top1 36.914062    Top5 92.148438    
2018-11-01 11:23:08,127 - Test: [   30/   39]    Loss 3.897456    Top1 37.005208    Top5 91.718750    
2018-11-01 11:23:08,225 - Test: [   40/   39]    Loss 3.931642    Top1 36.800000    Top5 91.830000    
2018-11-01 11:23:08,253 - ==> Top1: 36.800    Top5: 91.830    Loss: 3.932

2018-11-01 11:23:08,254 - Testing sensitivity of module.layer3.2.conv1.weight [80.0% sparsity]
2018-11-01 11:23:08,256 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 11:23:08,257 - --- test ---------------------
2018-11-01 11:23:08,257 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:08,708 - Test: [   10/   39]    Loss 5.958960    Top1 27.656250    Top5 77.578125    
2018-11-01 11:23:08,817 - Test: [   20/   39]    Loss 5.950860    Top1 27.988281    Top5 78.125000    
2018-11-01 11:23:08,923 - Test: [   30/   39]    Loss 5.855614    Top1 28.242188    Top5 78.007812    
2018-11-01 11:23:09,019 - Test: [   40/   39]    Loss 5.928594    Top1 28.080000    Top5 77.940000    
2018-11-01 11:23:09,045 - ==> Top1: 28.080    Top5: 77.940    Loss: 5.929

2018-11-01 11:23:09,045 - Testing sensitivity of module.layer3.2.conv1.weight [85.0% sparsity]
2018-11-01 11:23:09,048 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 11:23:09,049 - --- test ---------------------
2018-11-01 11:23:09,049 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:09,490 - Test: [   10/   39]    Loss 9.333731    Top1 12.031250    Top5 70.000000    
2018-11-01 11:23:09,603 - Test: [   20/   39]    Loss 9.310368    Top1 12.441406    Top5 70.585938    
2018-11-01 11:23:09,713 - Test: [   30/   39]    Loss 9.275143    Top1 12.669271    Top5 70.638021    
2018-11-01 11:23:09,813 - Test: [   40/   39]    Loss 9.358826    Top1 12.410000    Top5 70.530000    
2018-11-01 11:23:09,839 - ==> Top1: 12.410    Top5: 70.530    Loss: 9.359

2018-11-01 11:23:09,840 - Testing sensitivity of module.layer3.2.conv1.weight [90.0% sparsity]
2018-11-01 11:23:09,843 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 11:23:09,845 - --- test ---------------------
2018-11-01 11:23:09,845 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:10,279 - Test: [   10/   39]    Loss 6.680910    Top1 21.601563    Top5 59.335938    
2018-11-01 11:23:10,386 - Test: [   20/   39]    Loss 6.628921    Top1 22.148437    Top5 59.765625    
2018-11-01 11:23:10,490 - Test: [   30/   39]    Loss 6.581170    Top1 22.486979    Top5 60.195312    
2018-11-01 11:23:10,588 - Test: [   40/   39]    Loss 6.598534    Top1 22.200000    Top5 59.820000    
2018-11-01 11:23:10,612 - ==> Top1: 22.200    Top5: 59.820    Loss: 6.599

2018-11-01 11:23:10,628 - Testing sensitivity of module.layer3.2.conv2.weight [0.0% sparsity]
2018-11-01 11:23:10,632 - --- test ---------------------
2018-11-01 11:23:10,632 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:11,141 - Test: [   10/   39]    Loss 0.551863    Top1 91.289062    Top5 99.687500    
2018-11-01 11:23:11,256 - Test: [   20/   39]    Loss 0.552944    Top1 91.542969    Top5 99.570312    
2018-11-01 11:23:11,363 - Test: [   30/   39]    Loss 0.546295    Top1 91.523438    Top5 99.661458    
2018-11-01 11:23:11,461 - Test: [   40/   39]    Loss 0.541567    Top1 91.530000    Top5 99.640000    
2018-11-01 11:23:11,516 - ==> Top1: 91.530    Top5: 99.640    Loss: 0.542

2018-11-01 11:23:11,517 - Testing sensitivity of module.layer3.2.conv2.weight [5.0% sparsity]
2018-11-01 11:23:11,520 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.047 goal=0.050 (3/64)
2018-11-01 11:23:11,521 - --- test ---------------------
2018-11-01 11:23:11,522 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:11,964 - Test: [   10/   39]    Loss 0.544914    Top1 91.250000    Top5 99.726562    
2018-11-01 11:23:12,071 - Test: [   20/   39]    Loss 0.546597    Top1 91.367188    Top5 99.609375    
2018-11-01 11:23:12,174 - Test: [   30/   39]    Loss 0.539083    Top1 91.380208    Top5 99.687500    
2018-11-01 11:23:12,269 - Test: [   40/   39]    Loss 0.534133    Top1 91.430000    Top5 99.660000    
2018-11-01 11:23:12,294 - ==> Top1: 91.430    Top5: 99.660    Loss: 0.534

2018-11-01 11:23:12,295 - Testing sensitivity of module.layer3.2.conv2.weight [10.0% sparsity]
2018-11-01 11:23:12,298 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.094 goal=0.100 (6/64)
2018-11-01 11:23:12,299 - --- test ---------------------
2018-11-01 11:23:12,300 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:12,728 - Test: [   10/   39]    Loss 0.535681    Top1 91.171875    Top5 99.726562    
2018-11-01 11:23:12,837 - Test: [   20/   39]    Loss 0.540128    Top1 91.425781    Top5 99.648438    
2018-11-01 11:23:12,945 - Test: [   30/   39]    Loss 0.532620    Top1 91.419271    Top5 99.713542    
2018-11-01 11:23:13,040 - Test: [   40/   39]    Loss 0.526543    Top1 91.420000    Top5 99.660000    
2018-11-01 11:23:13,069 - ==> Top1: 91.420    Top5: 99.660    Loss: 0.527

2018-11-01 11:23:13,073 - Testing sensitivity of module.layer3.2.conv2.weight [15.0% sparsity]
2018-11-01 11:23:13,076 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.141 goal=0.150 (9/64)
2018-11-01 11:23:13,077 - --- test ---------------------
2018-11-01 11:23:13,077 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:13,644 - Test: [   10/   39]    Loss 0.541076    Top1 91.289062    Top5 99.609375    
2018-11-01 11:23:13,755 - Test: [   20/   39]    Loss 0.548833    Top1 91.132812    Top5 99.570312    
2018-11-01 11:23:13,862 - Test: [   30/   39]    Loss 0.542013    Top1 91.171875    Top5 99.648438    
2018-11-01 11:23:13,961 - Test: [   40/   39]    Loss 0.537726    Top1 91.090000    Top5 99.630000    
2018-11-01 11:23:14,005 - ==> Top1: 91.090    Top5: 99.630    Loss: 0.538

2018-11-01 11:23:14,005 - Testing sensitivity of module.layer3.2.conv2.weight [20.0% sparsity]
2018-11-01 11:23:14,008 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.188 goal=0.200 (12/64)
2018-11-01 11:23:14,013 - --- test ---------------------
2018-11-01 11:23:14,013 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:14,541 - Test: [   10/   39]    Loss 0.534736    Top1 91.210938    Top5 99.609375    
2018-11-01 11:23:14,654 - Test: [   20/   39]    Loss 0.549795    Top1 91.113281    Top5 99.550781    
2018-11-01 11:23:14,762 - Test: [   30/   39]    Loss 0.543450    Top1 90.937500    Top5 99.596354    
2018-11-01 11:23:14,862 - Test: [   40/   39]    Loss 0.538162    Top1 90.880000    Top5 99.580000    
2018-11-01 11:23:14,902 - ==> Top1: 90.880    Top5: 99.580    Loss: 0.538

2018-11-01 11:23:14,903 - Testing sensitivity of module.layer3.2.conv2.weight [25.0% sparsity]
2018-11-01 11:23:14,906 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.250 goal=0.250 (16/64)
2018-11-01 11:23:14,908 - --- test ---------------------
2018-11-01 11:23:14,908 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:15,391 - Test: [   10/   39]    Loss 0.572967    Top1 89.531250    Top5 99.492188    
2018-11-01 11:23:15,498 - Test: [   20/   39]    Loss 0.582981    Top1 89.902344    Top5 99.414062    
2018-11-01 11:23:15,605 - Test: [   30/   39]    Loss 0.573596    Top1 89.947917    Top5 99.518229    
2018-11-01 11:23:15,704 - Test: [   40/   39]    Loss 0.582077    Top1 89.820000    Top5 99.490000    
2018-11-01 11:23:15,766 - ==> Top1: 89.820    Top5: 99.490    Loss: 0.582

2018-11-01 11:23:15,767 - Testing sensitivity of module.layer3.2.conv2.weight [30.0% sparsity]
2018-11-01 11:23:15,771 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.297 goal=0.300 (19/64)
2018-11-01 11:23:15,772 - --- test ---------------------
2018-11-01 11:23:15,772 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:16,310 - Test: [   10/   39]    Loss 0.598698    Top1 88.632812    Top5 99.609375    
2018-11-01 11:23:16,423 - Test: [   20/   39]    Loss 0.607173    Top1 89.101562    Top5 99.531250    
2018-11-01 11:23:16,530 - Test: [   30/   39]    Loss 0.598873    Top1 89.166667    Top5 99.609375    
2018-11-01 11:23:16,629 - Test: [   40/   39]    Loss 0.604929    Top1 89.000000    Top5 99.580000    
2018-11-01 11:23:16,697 - ==> Top1: 89.000    Top5: 99.580    Loss: 0.605

2018-11-01 11:23:16,697 - Testing sensitivity of module.layer3.2.conv2.weight [35.0% sparsity]
2018-11-01 11:23:16,701 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.344 goal=0.350 (22/64)
2018-11-01 11:23:16,703 - --- test ---------------------
2018-11-01 11:23:16,703 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:17,214 - Test: [   10/   39]    Loss 0.717745    Top1 86.328125    Top5 99.257812    
2018-11-01 11:23:17,325 - Test: [   20/   39]    Loss 0.726368    Top1 86.933594    Top5 99.257812    
2018-11-01 11:23:17,432 - Test: [   30/   39]    Loss 0.716691    Top1 87.148438    Top5 99.309896    
2018-11-01 11:23:17,530 - Test: [   40/   39]    Loss 0.725357    Top1 87.000000    Top5 99.310000    
2018-11-01 11:23:17,572 - ==> Top1: 87.000    Top5: 99.310    Loss: 0.725

2018-11-01 11:23:17,573 - Testing sensitivity of module.layer3.2.conv2.weight [40.0% sparsity]
2018-11-01 11:23:17,576 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.391 goal=0.400 (25/64)
2018-11-01 11:23:17,577 - --- test ---------------------
2018-11-01 11:23:17,578 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:18,018 - Test: [   10/   39]    Loss 0.986529    Top1 82.304688    Top5 98.750000    
2018-11-01 11:23:18,127 - Test: [   20/   39]    Loss 0.991194    Top1 82.324219    Top5 98.886719    
2018-11-01 11:23:18,232 - Test: [   30/   39]    Loss 0.968375    Top1 82.434896    Top5 98.945312    
2018-11-01 11:23:18,331 - Test: [   40/   39]    Loss 0.998551    Top1 81.990000    Top5 98.930000    
2018-11-01 11:23:18,355 - ==> Top1: 81.990    Top5: 98.930    Loss: 0.999

2018-11-01 11:23:18,356 - Testing sensitivity of module.layer3.2.conv2.weight [45.0% sparsity]
2018-11-01 11:23:18,359 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.438 goal=0.450 (28/64)
2018-11-01 11:23:18,360 - --- test ---------------------
2018-11-01 11:23:18,361 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:18,806 - Test: [   10/   39]    Loss 1.179599    Top1 77.890625    Top5 98.750000    
2018-11-01 11:23:18,915 - Test: [   20/   39]    Loss 1.195872    Top1 78.007812    Top5 98.789062    
2018-11-01 11:23:19,020 - Test: [   30/   39]    Loss 1.188429    Top1 77.695312    Top5 98.802083    
2018-11-01 11:23:19,119 - Test: [   40/   39]    Loss 1.207880    Top1 77.700000    Top5 98.820000    
2018-11-01 11:23:19,145 - ==> Top1: 77.700    Top5: 98.820    Loss: 1.208

2018-11-01 11:23:19,145 - Testing sensitivity of module.layer3.2.conv2.weight [50.0% sparsity]
2018-11-01 11:23:19,148 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.500 goal=0.500 (32/64)
2018-11-01 11:23:19,149 - --- test ---------------------
2018-11-01 11:23:19,149 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:19,594 - Test: [   10/   39]    Loss 1.151786    Top1 75.976562    Top5 98.789062    
2018-11-01 11:23:19,700 - Test: [   20/   39]    Loss 1.175927    Top1 76.269531    Top5 98.750000    
2018-11-01 11:23:19,808 - Test: [   30/   39]    Loss 1.170596    Top1 76.171875    Top5 98.789062    
2018-11-01 11:23:19,907 - Test: [   40/   39]    Loss 1.187893    Top1 76.020000    Top5 98.840000    
2018-11-01 11:23:19,937 - ==> Top1: 76.020    Top5: 98.840    Loss: 1.188

2018-11-01 11:23:19,938 - Testing sensitivity of module.layer3.2.conv2.weight [55.0% sparsity]
2018-11-01 11:23:19,941 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.547 goal=0.550 (35/64)
2018-11-01 11:23:19,942 - --- test ---------------------
2018-11-01 11:23:19,942 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:20,383 - Test: [   10/   39]    Loss 1.143267    Top1 75.078125    Top5 98.437500    
2018-11-01 11:23:20,490 - Test: [   20/   39]    Loss 1.176449    Top1 75.039062    Top5 98.183594    
2018-11-01 11:23:20,596 - Test: [   30/   39]    Loss 1.177897    Top1 74.934896    Top5 98.242188    
2018-11-01 11:23:20,694 - Test: [   40/   39]    Loss 1.187765    Top1 74.980000    Top5 98.270000    
2018-11-01 11:23:20,724 - ==> Top1: 74.980    Top5: 98.270    Loss: 1.188

2018-11-01 11:23:20,724 - Testing sensitivity of module.layer3.2.conv2.weight [60.0% sparsity]
2018-11-01 11:23:20,727 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.594 goal=0.600 (38/64)
2018-11-01 11:23:20,739 - --- test ---------------------
2018-11-01 11:23:20,739 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:21,361 - Test: [   10/   39]    Loss 1.349160    Top1 70.429688    Top5 98.281250    
2018-11-01 11:23:21,471 - Test: [   20/   39]    Loss 1.373755    Top1 71.015625    Top5 97.851562    
2018-11-01 11:23:21,578 - Test: [   30/   39]    Loss 1.367355    Top1 71.015625    Top5 97.877604    
2018-11-01 11:23:21,676 - Test: [   40/   39]    Loss 1.383344    Top1 71.040000    Top5 97.950000    
2018-11-01 11:23:21,744 - ==> Top1: 71.040    Top5: 97.950    Loss: 1.383

2018-11-01 11:23:21,744 - Testing sensitivity of module.layer3.2.conv2.weight [65.0% sparsity]
2018-11-01 11:23:21,747 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.641 goal=0.650 (41/64)
2018-11-01 11:23:21,749 - --- test ---------------------
2018-11-01 11:23:21,750 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:22,293 - Test: [   10/   39]    Loss 1.295438    Top1 68.398438    Top5 97.773438    
2018-11-01 11:23:22,405 - Test: [   20/   39]    Loss 1.325596    Top1 69.140625    Top5 97.304688    
2018-11-01 11:23:22,512 - Test: [   30/   39]    Loss 1.316680    Top1 69.270833    Top5 97.382812    
2018-11-01 11:23:22,610 - Test: [   40/   39]    Loss 1.326935    Top1 69.270000    Top5 97.430000    
2018-11-01 11:23:22,657 - ==> Top1: 69.270    Top5: 97.430    Loss: 1.327

2018-11-01 11:23:22,658 - Testing sensitivity of module.layer3.2.conv2.weight [70.0% sparsity]
2018-11-01 11:23:22,662 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.688 goal=0.700 (44/64)
2018-11-01 11:23:22,663 - --- test ---------------------
2018-11-01 11:23:22,664 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:23,138 - Test: [   10/   39]    Loss 1.364110    Top1 67.617188    Top5 96.796875    
2018-11-01 11:23:23,245 - Test: [   20/   39]    Loss 1.377365    Top1 68.261719    Top5 96.582031    
2018-11-01 11:23:23,351 - Test: [   30/   39]    Loss 1.380742    Top1 68.203125    Top5 96.614583    
2018-11-01 11:23:23,448 - Test: [   40/   39]    Loss 1.395883    Top1 68.360000    Top5 96.700000    
2018-11-01 11:23:23,480 - ==> Top1: 68.360    Top5: 96.700    Loss: 1.396

2018-11-01 11:23:23,481 - Testing sensitivity of module.layer3.2.conv2.weight [75.0% sparsity]
2018-11-01 11:23:23,484 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.750 goal=0.750 (48/64)
2018-11-01 11:23:23,484 - --- test ---------------------
2018-11-01 11:23:23,484 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:23,935 - Test: [   10/   39]    Loss 1.360481    Top1 63.554687    Top5 96.015625    
2018-11-01 11:23:24,045 - Test: [   20/   39]    Loss 1.389255    Top1 63.808594    Top5 95.625000    
2018-11-01 11:23:24,152 - Test: [   30/   39]    Loss 1.398399    Top1 63.697917    Top5 95.611979    
2018-11-01 11:23:24,251 - Test: [   40/   39]    Loss 1.403666    Top1 63.800000    Top5 95.590000    
2018-11-01 11:23:24,295 - ==> Top1: 63.800    Top5: 95.590    Loss: 1.404

2018-11-01 11:23:24,296 - Testing sensitivity of module.layer3.2.conv2.weight [80.0% sparsity]
2018-11-01 11:23:24,299 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.797 goal=0.800 (51/64)
2018-11-01 11:23:24,300 - --- test ---------------------
2018-11-01 11:23:24,300 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:24,839 - Test: [   10/   39]    Loss 1.602673    Top1 56.289062    Top5 96.445312    
2018-11-01 11:23:24,950 - Test: [   20/   39]    Loss 1.615427    Top1 56.640625    Top5 95.957031    
2018-11-01 11:23:25,057 - Test: [   30/   39]    Loss 1.619066    Top1 56.549479    Top5 95.885417    
2018-11-01 11:23:25,155 - Test: [   40/   39]    Loss 1.622503    Top1 56.550000    Top5 95.850000    
2018-11-01 11:23:25,198 - ==> Top1: 56.550    Top5: 95.850    Loss: 1.623

2018-11-01 11:23:25,198 - Testing sensitivity of module.layer3.2.conv2.weight [85.0% sparsity]
2018-11-01 11:23:25,202 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.844 goal=0.850 (54/64)
2018-11-01 11:23:25,203 - --- test ---------------------
2018-11-01 11:23:25,203 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:25,703 - Test: [   10/   39]    Loss 1.511155    Top1 56.601562    Top5 95.312500    
2018-11-01 11:23:25,817 - Test: [   20/   39]    Loss 1.510136    Top1 57.363281    Top5 94.902344    
2018-11-01 11:23:25,925 - Test: [   30/   39]    Loss 1.521376    Top1 57.434896    Top5 94.843750    
2018-11-01 11:23:26,024 - Test: [   40/   39]    Loss 1.533481    Top1 57.270000    Top5 94.900000    
2018-11-01 11:23:26,061 - ==> Top1: 57.270    Top5: 94.900    Loss: 1.533

2018-11-01 11:23:26,061 - Testing sensitivity of module.layer3.2.conv2.weight [90.0% sparsity]
2018-11-01 11:23:26,064 - L1RankedStructureParameterPruner - param: module.layer3.2.conv2.weight pruned=0.891 goal=0.900 (57/64)
2018-11-01 11:23:26,066 - --- test ---------------------
2018-11-01 11:23:26,066 - 10000 samples (256 per mini-batch)
2018-11-01 11:23:26,520 - Test: [   10/   39]    Loss 2.276557    Top1 41.601562    Top5 88.359375    
2018-11-01 11:23:26,626 - Test: [   20/   39]    Loss 2.247812    Top1 42.929688    Top5 87.617188    
2018-11-01 11:23:26,731 - Test: [   30/   39]    Loss 2.252170    Top1 42.903646    Top5 87.604167    
2018-11-01 11:23:26,828 - Test: [   40/   39]    Loss 2.271621    Top1 42.590000    Top5 87.590000    
2018-11-01 11:23:26,861 - ==> Top1: 42.590    Top5: 87.590    Loss: 2.272

2018-11-01 11:23:26,876 - Testing sensitivity of module.fc.weight [0.0% sparsity]
2018-11-01 11:23:26,876 - Testing sensitivity of module.fc.weight [5.0% sparsity]
2018-11-01 11:23:26,877 - Testing sensitivity of module.fc.weight [10.0% sparsity]
2018-11-01 11:23:26,877 - Testing sensitivity of module.fc.weight [15.0% sparsity]
2018-11-01 11:23:26,877 - Testing sensitivity of module.fc.weight [20.0% sparsity]
2018-11-01 11:23:26,877 - Testing sensitivity of module.fc.weight [25.0% sparsity]
2018-11-01 11:23:26,878 - Testing sensitivity of module.fc.weight [30.0% sparsity]
2018-11-01 11:23:26,878 - Testing sensitivity of module.fc.weight [35.0% sparsity]
2018-11-01 11:23:26,878 - Testing sensitivity of module.fc.weight [40.0% sparsity]
2018-11-01 11:23:26,878 - Testing sensitivity of module.fc.weight [45.0% sparsity]
2018-11-01 11:23:26,879 - Testing sensitivity of module.fc.weight [50.0% sparsity]
2018-11-01 11:23:26,879 - Testing sensitivity of module.fc.weight [55.0% sparsity]
2018-11-01 11:23:26,879 - Testing sensitivity of module.fc.weight [60.0% sparsity]
2018-11-01 11:23:26,879 - Testing sensitivity of module.fc.weight [65.0% sparsity]
2018-11-01 11:23:26,880 - Testing sensitivity of module.fc.weight [70.0% sparsity]
2018-11-01 11:23:26,880 - Testing sensitivity of module.fc.weight [75.0% sparsity]
2018-11-01 11:23:26,880 - Testing sensitivity of module.fc.weight [80.0% sparsity]
2018-11-01 11:23:26,881 - Testing sensitivity of module.fc.weight [85.0% sparsity]
2018-11-01 11:23:26,881 - Testing sensitivity of module.fc.weight [90.0% sparsity]
2018-11-01 11:23:26,999 - Generating sensitivity graph
2018-11-01 11:23:27,227 - 
2018-11-01 11:23:27,227 - Log file for this run: /home/ccma/Chilung/1022/distiller/examples/classifier_compression/logs/2018.11.01-111810/2018.11.01-111810.log
