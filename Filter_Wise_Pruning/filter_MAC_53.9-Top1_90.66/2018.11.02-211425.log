2018-11-02 21:14:25,675 - Log file for this run: /home/ccma/Chilung/1022/distiller/examples/classifier_compression/logs/2018.11.02-211425/2018.11.02-211425.log
2018-11-02 21:14:25,675 - Number of CPUs: 8
2018-11-02 21:14:25,696 - Number of GPUs: 1
2018-11-02 21:14:25,696 - CUDA version: 8.0.61
2018-11-02 21:14:25,696 - CUDNN version: 7102
2018-11-02 21:14:25,696 - Kernel: 4.13.0-38-generic
2018-11-02 21:14:25,696 - Python: 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
2018-11-02 21:14:25,696 - PyTorch: 0.4.0
2018-11-02 21:14:25,696 - Numpy: 1.14.3
2018-11-02 21:14:25,706 - Git is dirty
2018-11-02 21:14:25,706 - Active Git branch: master
2018-11-02 21:14:25,710 - Git commit: 8bf95d12172fb6e82a00ce40007953e23d9648c7
2018-11-02 21:14:25,711 - App args: ['compress_classifier.py', '--arch', 'resnet20_cifar', '--lr', '0.3', '-p', '50', '../../../data.cifar10', '-b', '128', '-j', '1', '--vs', '0', '--deterministic', '--epochs', '300', '--compress=../../../resnet20_cifar_baseline/resnet20_cifar_baseline.yaml']
2018-11-02 21:14:25,711 - ==> using cifar10 dataset
2018-11-02 21:14:25,712 - => creating resnet20_cifar model for CIFAR10
2018-11-02 21:14:28,065 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2018-11-02 21:14:28,066 - Optimizer Args: {'nesterov': False, 'lr': 0.3, 'weight_decay': 0.0001, 'momentum': 0.9, 'dampening': 0}
2018-11-02 21:14:29,265 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2018-11-02 21:14:29,265 - Reading compression schedule from: ../../../resnet20_cifar_baseline/resnet20_cifar_baseline.yaml
2018-11-02 21:14:29,306 - Schedule contents:
{
  "pruners": {
    "filter_pruner": {
      "class": "L1RankedStructureParameterPruner",
      "reg_regims": {
        "module.layer1.0.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer1.1.conv1.weight": [
          0.8,
          "3D"
        ],
        "module.layer1.2.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer2.0.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer2.1.conv1.weight": [
          0.8,
          "3D"
        ],
        "module.layer2.2.conv1.weight": [
          0.8,
          "3D"
        ],
        "module.layer3.0.conv1.weight": [
          0.4,
          "3D"
        ],
        "module.layer3.1.conv1.weight": [
          0.4,
          "3D"
        ],
        "module.layer3.2.conv1.weight": [
          0.4,
          "3D"
        ]
      }
    }
  },
  "extensions": {
    "net_thinner": {
      "class": "FilterRemover",
      "thinning_func_str": "remove_filters",
      "arch": "resnet20_cifar",
      "dataset": "cifar10"
    }
  },
  "lr_schedulers": {
    "exp_finetuning_lr": {
      "class": "ExponentialLR",
      "gamma": 0.95
    }
  },
  "policies": [
    {
      "pruner": {
        "instance_name": "filter_pruner"
      },
      "epochs": [
        120
      ]
    },
    {
      "extension": {
        "instance_name": "net_thinner"
      },
      "epochs": [
        120
      ]
    },
    {
      "lr_scheduler": {
        "instance_name": "exp_finetuning_lr"
      },
      "starting_epoch": 121,
      "ending_epoch": 300,
      "frequency": 1
    }
  ]
}
2018-11-02 21:14:29,307 - 

2018-11-02 21:14:29,307 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:14:30,495 - Epoch: [0][   50/  391]    Overall Loss 2.249211    Objective Loss 2.249211    Top1 19.015625    Top5 69.343750    LR 0.300000    Time 0.023722    
2018-11-02 21:14:31,609 - Epoch: [0][  100/  391]    Overall Loss 2.080102    Objective Loss 2.080102    Top1 22.304687    Top5 76.265625    LR 0.300000    Time 0.022991    
2018-11-02 21:14:32,731 - Epoch: [0][  150/  391]    Overall Loss 1.987033    Objective Loss 1.987033    Top1 24.859375    Top5 79.520833    LR 0.300000    Time 0.022798    
2018-11-02 21:14:33,853 - Epoch: [0][  200/  391]    Overall Loss 1.930329    Objective Loss 1.930329    Top1 26.828125    Top5 81.312500    LR 0.300000    Time 0.022704    
2018-11-02 21:14:34,977 - Epoch: [0][  250/  391]    Overall Loss 1.875432    Objective Loss 1.875432    Top1 29.021875    Top5 82.884375    LR 0.300000    Time 0.022637    
2018-11-02 21:14:36,118 - Epoch: [0][  300/  391]    Overall Loss 1.828787    Objective Loss 1.828787    Top1 30.838542    Top5 84.057292    LR 0.300000    Time 0.022664    
2018-11-02 21:14:37,241 - Epoch: [0][  350/  391]    Overall Loss 1.785466    Objective Loss 1.785466    Top1 32.598214    Top5 85.113839    LR 0.300000    Time 0.022633    
2018-11-02 21:14:38,244 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38050 | -0.00181 |    0.28428 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15096 |  0.00035 |    0.11653 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14372 |  0.00002 |    0.11309 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14422 | -0.00081 |    0.11371 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13851 | -0.00675 |    0.11000 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13119 | -0.01244 |    0.10391 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13018 |  0.00125 |    0.10249 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10461 | -0.00659 |    0.08339 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09446 | -0.00098 |    0.07512 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27383 | -0.01196 |    0.21812 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09312 | -0.00347 |    0.07331 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09104 | -0.00102 |    0.07217 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08823 | -0.00216 |    0.07018 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08739 | -0.00353 |    0.06937 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06462 |  0.00235 |    0.05133 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06203 | -0.00472 |    0.04929 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19659 | -0.01411 |    0.15634 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06312 | -0.00072 |    0.04979 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06331 | -0.00317 |    0.05004 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05683 |  0.00381 |    0.04536 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05852 | -0.01055 |    0.04742 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34955 | -0.00382 |    0.26083 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:14:38,244 - Total sparsity: 0.00

2018-11-02 21:14:38,244 - --- validate (epoch=0)-----------
2018-11-02 21:14:38,245 - 10000 samples (128 per mini-batch)
2018-11-02 21:14:38,985 - Epoch: [0][   50/   78]    Loss 1.543209    Top1 43.578125    Top5 92.062500    
2018-11-02 21:14:39,380 - ==> Top1: 43.020    Top5: 92.200    Loss: 1.540

2018-11-02 21:14:39,381 - ==> Best Top1: 43.020   On Epoch: 0

2018-11-02 21:14:39,381 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:14:39,441 - 

2018-11-02 21:14:39,442 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:14:40,596 - Epoch: [1][   50/  391]    Overall Loss 1.432155    Objective Loss 1.432155    Top1 47.703125    Top5 92.812500    LR 0.300000    Time 0.023059    
2018-11-02 21:14:41,723 - Epoch: [1][  100/  391]    Overall Loss 1.394355    Objective Loss 1.394355    Top1 49.156250    Top5 93.062500    LR 0.300000    Time 0.022782    
2018-11-02 21:14:42,849 - Epoch: [1][  150/  391]    Overall Loss 1.348181    Objective Loss 1.348181    Top1 51.166667    Top5 93.598958    LR 0.300000    Time 0.022685    
2018-11-02 21:14:43,975 - Epoch: [1][  200/  391]    Overall Loss 1.317914    Objective Loss 1.317914    Top1 52.265625    Top5 93.988281    LR 0.300000    Time 0.022636    
2018-11-02 21:14:45,103 - Epoch: [1][  250/  391]    Overall Loss 1.284584    Objective Loss 1.284584    Top1 53.546875    Top5 94.259375    LR 0.300000    Time 0.022616    
2018-11-02 21:14:46,230 - Epoch: [1][  300/  391]    Overall Loss 1.261676    Objective Loss 1.261676    Top1 54.458333    Top5 94.463542    LR 0.300000    Time 0.022599    
2018-11-02 21:14:47,358 - Epoch: [1][  350/  391]    Overall Loss 1.238257    Objective Loss 1.238257    Top1 55.245536    Top5 94.720982    LR 0.300000    Time 0.022591    
2018-11-02 21:14:48,361 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.45953 | -0.00249 |    0.33452 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15807 |  0.00165 |    0.11915 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15396 | -0.00644 |    0.11741 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16260 | -0.00514 |    0.12439 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15842 | -0.01287 |    0.12385 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14331 | -0.00897 |    0.10933 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14026 | -0.00313 |    0.10937 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13296 | -0.00761 |    0.10201 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11633 | -0.00307 |    0.09029 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31871 | -0.01197 |    0.25082 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11267 | -0.00666 |    0.08707 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10380 | -0.00370 |    0.08168 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09885 | -0.00670 |    0.07800 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09459 | -0.00215 |    0.07490 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07736 | -0.00279 |    0.06092 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06888 | -0.00481 |    0.05404 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21034 | -0.02617 |    0.16644 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07034 | -0.00181 |    0.05461 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06784 | -0.00219 |    0.05268 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05440 |  0.00458 |    0.04325 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05563 | -0.01096 |    0.04504 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44571 | -0.00339 |    0.34367 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:14:48,362 - Total sparsity: 0.00

2018-11-02 21:14:48,362 - --- validate (epoch=1)-----------
2018-11-02 21:14:48,362 - 10000 samples (128 per mini-batch)
2018-11-02 21:14:49,086 - Epoch: [1][   50/   78]    Loss 1.349763    Top1 56.953125    Top5 95.171875    
2018-11-02 21:14:49,478 - ==> Top1: 56.810    Top5: 94.970    Loss: 1.362

2018-11-02 21:14:49,478 - ==> Best Top1: 56.810   On Epoch: 1

2018-11-02 21:14:49,478 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:14:49,497 - 

2018-11-02 21:14:49,497 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:14:50,655 - Epoch: [2][   50/  391]    Overall Loss 1.051294    Objective Loss 1.051294    Top1 62.859375    Top5 96.500000    LR 0.300000    Time 0.023114    
2018-11-02 21:14:51,784 - Epoch: [2][  100/  391]    Overall Loss 1.043496    Objective Loss 1.043496    Top1 63.046875    Top5 96.367188    LR 0.300000    Time 0.022831    
2018-11-02 21:14:52,932 - Epoch: [2][  150/  391]    Overall Loss 1.023157    Objective Loss 1.023157    Top1 63.661458    Top5 96.505208    LR 0.300000    Time 0.022866    
2018-11-02 21:14:54,075 - Epoch: [2][  200/  391]    Overall Loss 0.998733    Objective Loss 0.998733    Top1 64.531250    Top5 96.582031    LR 0.300000    Time 0.022858    
2018-11-02 21:14:55,208 - Epoch: [2][  250/  391]    Overall Loss 0.988267    Objective Loss 0.988267    Top1 64.865625    Top5 96.693750    LR 0.300000    Time 0.022815    
2018-11-02 21:14:56,350 - Epoch: [2][  300/  391]    Overall Loss 0.974377    Objective Loss 0.974377    Top1 65.367188    Top5 96.822917    LR 0.300000    Time 0.022813    
2018-11-02 21:14:57,489 - Epoch: [2][  350/  391]    Overall Loss 0.960025    Objective Loss 0.960025    Top1 65.897321    Top5 96.957589    LR 0.300000    Time 0.022805    
2018-11-02 21:14:58,494 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.48925 |  0.00347 |    0.34664 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15822 | -0.00110 |    0.11574 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15771 | -0.00415 |    0.11743 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17224 | -0.00460 |    0.12850 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16983 | -0.01272 |    0.13061 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14941 | -0.01277 |    0.11263 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14410 | -0.00669 |    0.11163 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15118 | -0.00946 |    0.11387 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13155 | -0.00442 |    0.10064 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34933 | -0.01586 |    0.27146 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12528 | -0.00749 |    0.09604 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11283 | -0.00501 |    0.08812 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10745 | -0.00947 |    0.08426 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09987 | -0.00158 |    0.07889 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09207 | -0.00552 |    0.07226 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07809 | -0.00627 |    0.06074 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21872 | -0.02809 |    0.17216 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07803 | -0.00536 |    0.06029 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07200 | -0.00189 |    0.05512 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05241 |  0.00420 |    0.04153 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05279 | -0.01131 |    0.04277 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.50144 | -0.00302 |    0.39110 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:14:58,494 - Total sparsity: 0.00

2018-11-02 21:14:58,494 - --- validate (epoch=2)-----------
2018-11-02 21:14:58,494 - 10000 samples (128 per mini-batch)
2018-11-02 21:14:59,223 - Epoch: [2][   50/   78]    Loss 1.125182    Top1 62.046875    Top5 97.156250    
2018-11-02 21:14:59,633 - ==> Top1: 62.230    Top5: 97.240    Loss: 1.114

2018-11-02 21:14:59,634 - ==> Best Top1: 62.230   On Epoch: 2

2018-11-02 21:14:59,634 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:14:59,645 - 

2018-11-02 21:14:59,645 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:15:00,833 - Epoch: [3][   50/  391]    Overall Loss 0.831718    Objective Loss 0.831718    Top1 70.281250    Top5 98.046875    LR 0.300000    Time 0.023708    
2018-11-02 21:15:01,970 - Epoch: [3][  100/  391]    Overall Loss 0.830995    Objective Loss 0.830995    Top1 70.765625    Top5 97.898438    LR 0.300000    Time 0.023217    
2018-11-02 21:15:03,108 - Epoch: [3][  150/  391]    Overall Loss 0.817110    Objective Loss 0.817110    Top1 71.427083    Top5 97.901042    LR 0.300000    Time 0.023054    
2018-11-02 21:15:04,240 - Epoch: [3][  200/  391]    Overall Loss 0.815265    Objective Loss 0.815265    Top1 71.453125    Top5 97.929688    LR 0.300000    Time 0.022944    
2018-11-02 21:15:05,373 - Epoch: [3][  250/  391]    Overall Loss 0.808913    Objective Loss 0.808913    Top1 71.825000    Top5 97.965625    LR 0.300000    Time 0.022883    
2018-11-02 21:15:06,504 - Epoch: [3][  300/  391]    Overall Loss 0.803061    Objective Loss 0.803061    Top1 72.018229    Top5 98.015625    LR 0.300000    Time 0.022833    
2018-11-02 21:15:07,637 - Epoch: [3][  350/  391]    Overall Loss 0.797292    Objective Loss 0.797292    Top1 72.234375    Top5 97.997768    LR 0.300000    Time 0.022805    
2018-11-02 21:15:08,643 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.50562 |  0.00173 |    0.35189 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15849 |  0.00031 |    0.11249 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15957 | -0.00381 |    0.11719 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17691 | -0.00789 |    0.13131 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17571 | -0.00827 |    0.13356 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15612 | -0.01400 |    0.11595 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14641 | -0.00303 |    0.11179 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16203 | -0.00973 |    0.12074 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14065 | -0.00495 |    0.10751 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36660 | -0.01683 |    0.28433 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13319 | -0.00799 |    0.10182 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00570 |    0.09230 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11386 | -0.01353 |    0.08916 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10352 | -0.00141 |    0.08124 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10312 | -0.00847 |    0.08080 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08635 | -0.00804 |    0.06692 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22372 | -0.02903 |    0.17636 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08547 | -0.00700 |    0.06560 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07592 | -0.00103 |    0.05755 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05107 |  0.00399 |    0.04029 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05055 | -0.01131 |    0.04092 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53041 | -0.00268 |    0.41685 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:15:08,644 - Total sparsity: 0.00

2018-11-02 21:15:08,644 - --- validate (epoch=3)-----------
2018-11-02 21:15:08,644 - 10000 samples (128 per mini-batch)
2018-11-02 21:15:09,375 - Epoch: [3][   50/   78]    Loss 0.896211    Top1 70.171875    Top5 98.140625    
2018-11-02 21:15:09,778 - ==> Top1: 70.400    Top5: 98.080    Loss: 0.891

2018-11-02 21:15:09,778 - ==> Best Top1: 70.400   On Epoch: 3

2018-11-02 21:15:09,779 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:15:09,790 - 

2018-11-02 21:15:09,790 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:15:10,983 - Epoch: [4][   50/  391]    Overall Loss 0.717632    Objective Loss 0.717632    Top1 74.781250    Top5 98.406250    LR 0.300000    Time 0.023818    
2018-11-02 21:15:12,121 - Epoch: [4][  100/  391]    Overall Loss 0.722083    Objective Loss 0.722083    Top1 74.648438    Top5 98.390625    LR 0.300000    Time 0.023280    
2018-11-02 21:15:13,261 - Epoch: [4][  150/  391]    Overall Loss 0.715959    Objective Loss 0.715959    Top1 74.958333    Top5 98.359375    LR 0.300000    Time 0.023105    
2018-11-02 21:15:14,409 - Epoch: [4][  200/  391]    Overall Loss 0.711381    Objective Loss 0.711381    Top1 75.203125    Top5 98.375000    LR 0.300000    Time 0.023063    
2018-11-02 21:15:15,562 - Epoch: [4][  250/  391]    Overall Loss 0.709762    Objective Loss 0.709762    Top1 75.200000    Top5 98.440625    LR 0.300000    Time 0.023056    
2018-11-02 21:15:16,733 - Epoch: [4][  300/  391]    Overall Loss 0.709174    Objective Loss 0.709174    Top1 75.171875    Top5 98.442708    LR 0.300000    Time 0.023112    
2018-11-02 21:15:17,867 - Epoch: [4][  350/  391]    Overall Loss 0.705033    Objective Loss 0.705033    Top1 75.368304    Top5 98.457589    LR 0.300000    Time 0.023046    
2018-11-02 21:15:18,923 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.51703 | -0.00070 |    0.35452 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15868 | -0.00000 |    0.10973 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15907 | -0.00780 |    0.11562 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18134 | -0.00580 |    0.13273 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17905 | -0.00760 |    0.13420 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15944 | -0.01677 |    0.11722 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14661 | -0.00383 |    0.11189 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17026 | -0.00874 |    0.12548 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14739 | -0.00605 |    0.11225 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37612 | -0.01949 |    0.28724 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13879 | -0.00589 |    0.10613 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12244 | -0.00643 |    0.09475 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11809 | -0.01462 |    0.09246 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10535 | -0.00197 |    0.08223 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11155 | -0.00894 |    0.08747 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09342 | -0.00922 |    0.07198 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22533 | -0.02769 |    0.17637 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09163 | -0.00835 |    0.07045 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07882 | -0.00083 |    0.05952 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04977 |  0.00360 |    0.03909 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04840 | -0.01112 |    0.03908 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54627 | -0.00238 |    0.43049 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:15:18,924 - Total sparsity: 0.00

2018-11-02 21:15:18,924 - --- validate (epoch=4)-----------
2018-11-02 21:15:18,924 - 10000 samples (128 per mini-batch)
2018-11-02 21:15:19,669 - Epoch: [4][   50/   78]    Loss 0.925385    Top1 70.031250    Top5 97.531250    
2018-11-02 21:15:20,077 - ==> Top1: 69.730    Top5: 97.650    Loss: 0.919

2018-11-02 21:15:20,078 - ==> Best Top1: 70.400   On Epoch: 3

2018-11-02 21:15:20,078 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:15:20,086 - 

2018-11-02 21:15:20,087 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:15:21,325 - Epoch: [5][   50/  391]    Overall Loss 0.652075    Objective Loss 0.652075    Top1 77.609375    Top5 98.859375    LR 0.300000    Time 0.024727    
2018-11-02 21:15:22,464 - Epoch: [5][  100/  391]    Overall Loss 0.656179    Objective Loss 0.656179    Top1 77.101562    Top5 98.703125    LR 0.300000    Time 0.023736    
2018-11-02 21:15:23,630 - Epoch: [5][  150/  391]    Overall Loss 0.648720    Objective Loss 0.648720    Top1 77.458333    Top5 98.692708    LR 0.300000    Time 0.023590    
2018-11-02 21:15:24,764 - Epoch: [5][  200/  391]    Overall Loss 0.656688    Objective Loss 0.656688    Top1 77.132812    Top5 98.628906    LR 0.300000    Time 0.023354    
2018-11-02 21:15:25,935 - Epoch: [5][  250/  391]    Overall Loss 0.657535    Objective Loss 0.657535    Top1 77.115625    Top5 98.643750    LR 0.300000    Time 0.023364    
2018-11-02 21:15:27,095 - Epoch: [5][  300/  391]    Overall Loss 0.661805    Objective Loss 0.661805    Top1 76.908854    Top5 98.643229    LR 0.300000    Time 0.023330    
2018-11-02 21:15:28,227 - Epoch: [5][  350/  391]    Overall Loss 0.661302    Objective Loss 0.661302    Top1 76.926339    Top5 98.620536    LR 0.300000    Time 0.023219    
2018-11-02 21:15:29,242 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.52752 |  0.00136 |    0.35840 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15710 | -0.00037 |    0.10629 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15683 | -0.00999 |    0.11287 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18375 | -0.00339 |    0.13424 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18087 | -0.00526 |    0.13500 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16293 | -0.01785 |    0.11894 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14772 | -0.00573 |    0.11153 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17636 | -0.00825 |    0.12914 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15322 | -0.00586 |    0.11665 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38303 | -0.02554 |    0.28994 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14284 | -0.00821 |    0.10927 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12531 | -0.00692 |    0.09711 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12270 | -0.01619 |    0.09618 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10729 | -0.00083 |    0.08358 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11840 | -0.00941 |    0.09263 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09959 | -0.01077 |    0.07681 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22580 | -0.02774 |    0.17554 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09679 | -0.00886 |    0.07448 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08135 | -0.00087 |    0.06118 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04895 |  0.00342 |    0.03829 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04679 | -0.01100 |    0.03756 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55611 | -0.00212 |    0.43856 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:15:29,242 - Total sparsity: 0.00

2018-11-02 21:15:29,243 - --- validate (epoch=5)-----------
2018-11-02 21:15:29,243 - 10000 samples (128 per mini-batch)
2018-11-02 21:15:29,967 - Epoch: [5][   50/   78]    Loss 0.979193    Top1 69.421875    Top5 95.640625    
2018-11-02 21:15:30,361 - ==> Top1: 69.500    Top5: 95.900    Loss: 0.964

2018-11-02 21:15:30,361 - ==> Best Top1: 70.400   On Epoch: 3

2018-11-02 21:15:30,361 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:15:30,368 - 

2018-11-02 21:15:30,369 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:15:31,558 - Epoch: [6][   50/  391]    Overall Loss 0.599611    Objective Loss 0.599611    Top1 79.562500    Top5 98.593750    LR 0.300000    Time 0.023753    
2018-11-02 21:15:32,693 - Epoch: [6][  100/  391]    Overall Loss 0.612522    Objective Loss 0.612522    Top1 78.843750    Top5 98.765625    LR 0.300000    Time 0.023216    
2018-11-02 21:15:33,837 - Epoch: [6][  150/  391]    Overall Loss 0.613124    Objective Loss 0.613124    Top1 78.781250    Top5 98.697917    LR 0.300000    Time 0.023091    
2018-11-02 21:15:34,971 - Epoch: [6][  200/  391]    Overall Loss 0.612003    Objective Loss 0.612003    Top1 78.816406    Top5 98.750000    LR 0.300000    Time 0.022984    
2018-11-02 21:15:36,105 - Epoch: [6][  250/  391]    Overall Loss 0.617169    Objective Loss 0.617169    Top1 78.521875    Top5 98.743750    LR 0.300000    Time 0.022916    
2018-11-02 21:15:37,241 - Epoch: [6][  300/  391]    Overall Loss 0.615142    Objective Loss 0.615142    Top1 78.549479    Top5 98.770833    LR 0.300000    Time 0.022878    
2018-11-02 21:15:38,372 - Epoch: [6][  350/  391]    Overall Loss 0.614235    Objective Loss 0.614235    Top1 78.631696    Top5 98.772321    LR 0.300000    Time 0.022840    
2018-11-02 21:15:39,381 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53461 | -0.00222 |    0.35921 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15561 | -0.00008 |    0.10339 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15545 | -0.01118 |    0.11078 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18569 | -0.00217 |    0.13370 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18460 | -0.00473 |    0.13829 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16422 | -0.01816 |    0.11948 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14901 | -0.00161 |    0.11137 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18075 | -0.01099 |    0.13243 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15725 | -0.00596 |    0.11897 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38928 | -0.03055 |    0.29287 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14587 | -0.00880 |    0.11142 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12701 | -0.00730 |    0.09840 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12578 | -0.01581 |    0.09861 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10848 | -0.00112 |    0.08459 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12388 | -0.00973 |    0.09703 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10474 | -0.01049 |    0.08062 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22496 | -0.02549 |    0.17491 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10115 | -0.00967 |    0.07790 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08333 | -0.00038 |    0.06252 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04826 |  0.00301 |    0.03751 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04537 | -0.01056 |    0.03616 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56413 | -0.00188 |    0.44359 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:15:39,382 - Total sparsity: 0.00

2018-11-02 21:15:39,382 - --- validate (epoch=6)-----------
2018-11-02 21:15:39,382 - 10000 samples (128 per mini-batch)
2018-11-02 21:15:40,107 - Epoch: [6][   50/   78]    Loss 0.843975    Top1 72.765625    Top5 98.078125    
2018-11-02 21:15:40,493 - ==> Top1: 72.350    Top5: 98.110    Loss: 0.843

2018-11-02 21:15:40,494 - ==> Best Top1: 72.350   On Epoch: 6

2018-11-02 21:15:40,494 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:15:40,504 - 

2018-11-02 21:15:40,505 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:15:41,695 - Epoch: [7][   50/  391]    Overall Loss 0.565125    Objective Loss 0.565125    Top1 80.109375    Top5 99.125000    LR 0.300000    Time 0.023770    
2018-11-02 21:15:42,829 - Epoch: [7][  100/  391]    Overall Loss 0.569496    Objective Loss 0.569496    Top1 79.867188    Top5 99.093750    LR 0.300000    Time 0.023209    
2018-11-02 21:15:43,964 - Epoch: [7][  150/  391]    Overall Loss 0.579048    Objective Loss 0.579048    Top1 79.708333    Top5 99.026042    LR 0.300000    Time 0.023026    
2018-11-02 21:15:45,099 - Epoch: [7][  200/  391]    Overall Loss 0.580896    Objective Loss 0.580896    Top1 79.660156    Top5 98.988281    LR 0.300000    Time 0.022940    
2018-11-02 21:15:46,235 - Epoch: [7][  250/  391]    Overall Loss 0.580644    Objective Loss 0.580644    Top1 79.568750    Top5 98.987500    LR 0.300000    Time 0.022890    
2018-11-02 21:15:47,379 - Epoch: [7][  300/  391]    Overall Loss 0.582417    Objective Loss 0.582417    Top1 79.505208    Top5 98.950521    LR 0.300000    Time 0.022884    
2018-11-02 21:15:48,525 - Epoch: [7][  350/  391]    Overall Loss 0.583301    Objective Loss 0.583301    Top1 79.551339    Top5 98.979911    LR 0.300000    Time 0.022884    
2018-11-02 21:15:49,539 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53899 |  0.00684 |    0.36101 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15316 |  0.00199 |    0.10091 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15320 | -0.00827 |    0.10893 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18669 | -0.00564 |    0.13397 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18574 | -0.00774 |    0.13873 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16688 | -0.01609 |    0.12061 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15000 | -0.00361 |    0.11173 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18309 | -0.00872 |    0.13444 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15942 | -0.00481 |    0.12095 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39260 | -0.02750 |    0.29527 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14775 | -0.00885 |    0.11282 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12797 | -0.00758 |    0.09893 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12772 | -0.01764 |    0.10030 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10913 | -0.00141 |    0.08516 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12734 | -0.01076 |    0.10027 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10839 | -0.01165 |    0.08360 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22424 | -0.02595 |    0.17367 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10472 | -0.01080 |    0.08069 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08499 | -0.00087 |    0.06381 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04810 |  0.00253 |    0.03715 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04426 | -0.01061 |    0.03511 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57289 | -0.00167 |    0.45102 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:15:49,540 - Total sparsity: 0.00

2018-11-02 21:15:49,540 - --- validate (epoch=7)-----------
2018-11-02 21:15:49,540 - 10000 samples (128 per mini-batch)
2018-11-02 21:15:50,269 - Epoch: [7][   50/   78]    Loss 0.739096    Top1 75.421875    Top5 98.531250    
2018-11-02 21:15:50,671 - ==> Top1: 75.280    Top5: 98.680    Loss: 0.741

2018-11-02 21:15:50,672 - ==> Best Top1: 75.280   On Epoch: 7

2018-11-02 21:15:50,672 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:15:50,683 - 

2018-11-02 21:15:50,683 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:15:51,870 - Epoch: [8][   50/  391]    Overall Loss 0.541494    Objective Loss 0.541494    Top1 81.281250    Top5 99.031250    LR 0.300000    Time 0.023705    
2018-11-02 21:15:53,011 - Epoch: [8][  100/  391]    Overall Loss 0.558675    Objective Loss 0.558675    Top1 80.640625    Top5 99.007812    LR 0.300000    Time 0.023246    
2018-11-02 21:15:54,150 - Epoch: [8][  150/  391]    Overall Loss 0.552118    Objective Loss 0.552118    Top1 80.875000    Top5 99.067708    LR 0.300000    Time 0.023080    
2018-11-02 21:15:55,291 - Epoch: [8][  200/  391]    Overall Loss 0.559015    Objective Loss 0.559015    Top1 80.722656    Top5 99.039062    LR 0.300000    Time 0.023008    
2018-11-02 21:15:56,430 - Epoch: [8][  250/  391]    Overall Loss 0.556137    Objective Loss 0.556137    Top1 80.790625    Top5 99.015625    LR 0.300000    Time 0.022958    
2018-11-02 21:15:57,569 - Epoch: [8][  300/  391]    Overall Loss 0.557609    Objective Loss 0.557609    Top1 80.765625    Top5 99.023438    LR 0.300000    Time 0.022923    
2018-11-02 21:15:58,708 - Epoch: [8][  350/  391]    Overall Loss 0.557383    Objective Loss 0.557383    Top1 80.812500    Top5 98.995536    LR 0.300000    Time 0.022899    
2018-11-02 21:15:59,725 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54362 |  0.00929 |    0.36112 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15209 |  0.00190 |    0.09986 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15241 | -0.01214 |    0.10757 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18732 | -0.00451 |    0.13493 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18645 | -0.00826 |    0.13814 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16751 | -0.02158 |    0.12163 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15058 | -0.00257 |    0.11183 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18474 | -0.00973 |    0.13594 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16032 | -0.00417 |    0.12150 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39386 | -0.03099 |    0.29271 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14940 | -0.00935 |    0.11441 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12914 | -0.00837 |    0.09992 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12983 | -0.01798 |    0.10216 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10999 | -0.00128 |    0.08561 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13047 | -0.01157 |    0.10266 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11172 | -0.01194 |    0.08638 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22324 | -0.02450 |    0.17343 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10801 | -0.01096 |    0.08343 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08631 | -0.00016 |    0.06470 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04790 |  0.00232 |    0.03678 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04354 | -0.01013 |    0.03416 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57621 | -0.00149 |    0.45166 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:15:59,725 - Total sparsity: 0.00

2018-11-02 21:15:59,725 - --- validate (epoch=8)-----------
2018-11-02 21:15:59,725 - 10000 samples (128 per mini-batch)
2018-11-02 21:16:00,477 - Epoch: [8][   50/   78]    Loss 0.774249    Top1 75.234375    Top5 97.843750    
2018-11-02 21:16:00,871 - ==> Top1: 75.290    Top5: 98.020    Loss: 0.776

2018-11-02 21:16:00,871 - ==> Best Top1: 75.290   On Epoch: 8

2018-11-02 21:16:00,872 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:16:00,888 - 

2018-11-02 21:16:00,888 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:16:02,088 - Epoch: [9][   50/  391]    Overall Loss 0.530622    Objective Loss 0.530622    Top1 81.953125    Top5 99.140625    LR 0.300000    Time 0.023951    
2018-11-02 21:16:03,227 - Epoch: [9][  100/  391]    Overall Loss 0.531139    Objective Loss 0.531139    Top1 81.843750    Top5 99.156250    LR 0.300000    Time 0.023354    
2018-11-02 21:16:04,359 - Epoch: [9][  150/  391]    Overall Loss 0.541816    Objective Loss 0.541816    Top1 81.484375    Top5 99.140625    LR 0.300000    Time 0.023106    
2018-11-02 21:16:05,490 - Epoch: [9][  200/  391]    Overall Loss 0.546964    Objective Loss 0.546964    Top1 81.312500    Top5 99.082031    LR 0.300000    Time 0.022978    
2018-11-02 21:16:06,624 - Epoch: [9][  250/  391]    Overall Loss 0.544687    Objective Loss 0.544687    Top1 81.390625    Top5 99.078125    LR 0.300000    Time 0.022911    
2018-11-02 21:16:07,755 - Epoch: [9][  300/  391]    Overall Loss 0.542334    Objective Loss 0.542334    Top1 81.385417    Top5 99.098958    LR 0.300000    Time 0.022858    
2018-11-02 21:16:08,887 - Epoch: [9][  350/  391]    Overall Loss 0.544663    Objective Loss 0.544663    Top1 81.332589    Top5 99.060268    LR 0.300000    Time 0.022825    
2018-11-02 21:16:09,898 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54461 |  0.01107 |    0.36408 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15131 |  0.00219 |    0.09785 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15257 | -0.00885 |    0.10689 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18837 | -0.00506 |    0.13402 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18739 | -0.00769 |    0.13944 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16915 | -0.02010 |    0.12169 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15122 | -0.00378 |    0.11144 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18729 | -0.00551 |    0.13747 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16222 | -0.00541 |    0.12319 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39656 | -0.03214 |    0.29598 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15100 | -0.01007 |    0.11568 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13013 | -0.00802 |    0.10083 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13151 | -0.01972 |    0.10398 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11054 | -0.00108 |    0.08607 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13364 | -0.01213 |    0.10519 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11465 | -0.01176 |    0.08870 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22192 | -0.02064 |    0.17230 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11065 | -0.01132 |    0.08559 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08742 | -0.00074 |    0.06541 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04803 |  0.00224 |    0.03658 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04301 | -0.01017 |    0.03356 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57926 | -0.00132 |    0.45184 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:16:09,898 - Total sparsity: 0.00

2018-11-02 21:16:09,898 - --- validate (epoch=9)-----------
2018-11-02 21:16:09,898 - 10000 samples (128 per mini-batch)
2018-11-02 21:16:10,622 - Epoch: [9][   50/   78]    Loss 0.668818    Top1 77.718750    Top5 98.531250    
2018-11-02 21:16:11,013 - ==> Top1: 77.730    Top5: 98.620    Loss: 0.669

2018-11-02 21:16:11,013 - ==> Best Top1: 77.730   On Epoch: 9

2018-11-02 21:16:11,014 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:16:11,025 - 

2018-11-02 21:16:11,025 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:16:12,221 - Epoch: [10][   50/  391]    Overall Loss 0.524044    Objective Loss 0.524044    Top1 81.703125    Top5 98.890625    LR 0.300000    Time 0.023873    
2018-11-02 21:16:13,358 - Epoch: [10][  100/  391]    Overall Loss 0.516917    Objective Loss 0.516917    Top1 81.875000    Top5 99.117188    LR 0.300000    Time 0.023299    
2018-11-02 21:16:14,497 - Epoch: [10][  150/  391]    Overall Loss 0.530731    Objective Loss 0.530731    Top1 81.651042    Top5 99.104167    LR 0.300000    Time 0.023114    
2018-11-02 21:16:15,634 - Epoch: [10][  200/  391]    Overall Loss 0.529301    Objective Loss 0.529301    Top1 81.656250    Top5 99.136719    LR 0.300000    Time 0.023017    
2018-11-02 21:16:16,772 - Epoch: [10][  250/  391]    Overall Loss 0.530735    Objective Loss 0.530735    Top1 81.743750    Top5 99.137500    LR 0.300000    Time 0.022958    
2018-11-02 21:16:17,916 - Epoch: [10][  300/  391]    Overall Loss 0.529554    Objective Loss 0.529554    Top1 81.854167    Top5 99.148438    LR 0.300000    Time 0.022941    
2018-11-02 21:16:19,063 - Epoch: [10][  350/  391]    Overall Loss 0.527447    Objective Loss 0.527447    Top1 81.970982    Top5 99.122768    LR 0.300000    Time 0.022936    
2018-11-02 21:16:20,118 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54512 |  0.00430 |    0.36011 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15131 | -0.00084 |    0.09622 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15300 | -0.00928 |    0.10647 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18875 | -0.00664 |    0.13561 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18877 | -0.00903 |    0.14078 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17000 | -0.02060 |    0.12248 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15213 | -0.00262 |    0.11094 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18928 | -0.00703 |    0.13859 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16380 | -0.00419 |    0.12412 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39745 | -0.03288 |    0.29702 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15123 | -0.00921 |    0.11603 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13062 | -0.00833 |    0.10133 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13439 | -0.01959 |    0.10617 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11250 | -0.00156 |    0.08747 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.01225 |    0.10802 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11742 | -0.01173 |    0.09091 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22101 | -0.02162 |    0.17194 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11289 | -0.01155 |    0.08745 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08862 | -0.00024 |    0.06643 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04817 |  0.00193 |    0.03654 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04262 | -0.00997 |    0.03303 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58161 | -0.00118 |    0.45709 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:16:20,118 - Total sparsity: 0.00

2018-11-02 21:16:20,118 - --- validate (epoch=10)-----------
2018-11-02 21:16:20,118 - 10000 samples (128 per mini-batch)
2018-11-02 21:16:20,882 - Epoch: [10][   50/   78]    Loss 1.167046    Top1 67.875000    Top5 97.484375    
2018-11-02 21:16:21,286 - ==> Top1: 66.980    Top5: 97.570    Loss: 1.177

2018-11-02 21:16:21,291 - ==> Best Top1: 77.730   On Epoch: 9

2018-11-02 21:16:21,291 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:16:21,300 - 

2018-11-02 21:16:21,300 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:16:22,550 - Epoch: [11][   50/  391]    Overall Loss 0.500677    Objective Loss 0.500677    Top1 82.609375    Top5 99.187500    LR 0.300000    Time 0.024965    
2018-11-02 21:16:23,719 - Epoch: [11][  100/  391]    Overall Loss 0.510383    Objective Loss 0.510383    Top1 82.250000    Top5 99.109375    LR 0.300000    Time 0.024154    
2018-11-02 21:16:24,882 - Epoch: [11][  150/  391]    Overall Loss 0.510306    Objective Loss 0.510306    Top1 82.276042    Top5 99.130208    LR 0.300000    Time 0.023849    
2018-11-02 21:16:26,060 - Epoch: [11][  200/  391]    Overall Loss 0.513909    Objective Loss 0.513909    Top1 82.062500    Top5 99.101562    LR 0.300000    Time 0.023772    
2018-11-02 21:16:27,223 - Epoch: [11][  250/  391]    Overall Loss 0.512675    Objective Loss 0.512675    Top1 82.062500    Top5 99.118750    LR 0.300000    Time 0.023663    
2018-11-02 21:16:28,394 - Epoch: [11][  300/  391]    Overall Loss 0.511758    Objective Loss 0.511758    Top1 82.174479    Top5 99.135417    LR 0.300000    Time 0.023616    
2018-11-02 21:16:29,550 - Epoch: [11][  350/  391]    Overall Loss 0.510035    Objective Loss 0.510035    Top1 82.283482    Top5 99.109375    LR 0.300000    Time 0.023541    
2018-11-02 21:16:30,633 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54676 | -0.00794 |    0.35991 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15251 |  0.00188 |    0.09590 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15387 | -0.01053 |    0.10766 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18889 | -0.00735 |    0.13525 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18922 | -0.01055 |    0.14134 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17062 | -0.02271 |    0.12331 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15263 |  0.00097 |    0.11074 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19149 | -0.00762 |    0.14050 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16509 | -0.00372 |    0.12545 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39751 | -0.03186 |    0.29647 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15163 | -0.00923 |    0.11617 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13095 | -0.00837 |    0.10138 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13671 | -0.01989 |    0.10796 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11358 | -0.00057 |    0.08830 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13910 | -0.01195 |    0.11008 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11973 | -0.01200 |    0.09315 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22003 | -0.02260 |    0.17105 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11492 | -0.01183 |    0.08917 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08951 | -0.00076 |    0.06712 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04845 |  0.00149 |    0.03662 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04242 | -0.00995 |    0.03255 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58144 | -0.00104 |    0.45640 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:16:30,634 - Total sparsity: 0.00

2018-11-02 21:16:30,634 - --- validate (epoch=11)-----------
2018-11-02 21:16:30,634 - 10000 samples (128 per mini-batch)
2018-11-02 21:16:31,487 - Epoch: [11][   50/   78]    Loss 0.757607    Top1 76.187500    Top5 98.328125    
2018-11-02 21:16:31,893 - ==> Top1: 76.420    Top5: 98.440    Loss: 0.754

2018-11-02 21:16:31,894 - ==> Best Top1: 77.730   On Epoch: 9

2018-11-02 21:16:31,894 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:16:31,905 - 

2018-11-02 21:16:31,905 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:16:33,192 - Epoch: [12][   50/  391]    Overall Loss 0.486437    Objective Loss 0.486437    Top1 82.906250    Top5 99.203125    LR 0.300000    Time 0.025705    
2018-11-02 21:16:34,448 - Epoch: [12][  100/  391]    Overall Loss 0.483850    Objective Loss 0.483850    Top1 83.148438    Top5 99.242188    LR 0.300000    Time 0.025393    
2018-11-02 21:16:35,712 - Epoch: [12][  150/  391]    Overall Loss 0.498873    Objective Loss 0.498873    Top1 82.609375    Top5 99.192708    LR 0.300000    Time 0.025347    
2018-11-02 21:16:36,985 - Epoch: [12][  200/  391]    Overall Loss 0.500934    Objective Loss 0.500934    Top1 82.578125    Top5 99.140625    LR 0.300000    Time 0.025369    
2018-11-02 21:16:38,219 - Epoch: [12][  250/  391]    Overall Loss 0.498838    Objective Loss 0.498838    Top1 82.718750    Top5 99.175000    LR 0.300000    Time 0.025213    
2018-11-02 21:16:39,497 - Epoch: [12][  300/  391]    Overall Loss 0.501135    Objective Loss 0.501135    Top1 82.619792    Top5 99.184896    LR 0.300000    Time 0.025265    
2018-11-02 21:16:40,694 - Epoch: [12][  350/  391]    Overall Loss 0.501869    Objective Loss 0.501869    Top1 82.535714    Top5 99.185268    LR 0.300000    Time 0.025072    
2018-11-02 21:16:41,709 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54900 | -0.00715 |    0.36168 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15289 |  0.00305 |    0.09637 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15480 | -0.01216 |    0.10799 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19034 | -0.00767 |    0.13533 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18936 | -0.00756 |    0.14079 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17178 | -0.02004 |    0.12449 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15378 | -0.00126 |    0.11145 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19360 | -0.00453 |    0.14227 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16624 | -0.00500 |    0.12643 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39824 | -0.03599 |    0.29739 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15254 | -0.01062 |    0.11704 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13182 | -0.00761 |    0.10213 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13807 | -0.01880 |    0.10913 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11426 | -0.00091 |    0.08911 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14119 | -0.01314 |    0.11158 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12204 | -0.01224 |    0.09519 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21881 | -0.02171 |    0.16978 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11692 | -0.01137 |    0.09098 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09044 | -0.00036 |    0.06798 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04882 |  0.00130 |    0.03671 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04242 | -0.00920 |    0.03216 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58463 | -0.00093 |    0.46056 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:16:41,709 - Total sparsity: 0.00

2018-11-02 21:16:41,709 - --- validate (epoch=12)-----------
2018-11-02 21:16:41,709 - 10000 samples (128 per mini-batch)
2018-11-02 21:16:42,429 - Epoch: [12][   50/   78]    Loss 0.676923    Top1 77.796875    Top5 98.953125    
2018-11-02 21:16:42,818 - ==> Top1: 77.400    Top5: 98.860    Loss: 0.693

2018-11-02 21:16:42,819 - ==> Best Top1: 77.730   On Epoch: 9

2018-11-02 21:16:42,819 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:16:42,826 - 

2018-11-02 21:16:42,826 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:16:44,020 - Epoch: [13][   50/  391]    Overall Loss 0.481722    Objective Loss 0.481722    Top1 83.718750    Top5 99.281250    LR 0.300000    Time 0.023850    
2018-11-02 21:16:45,160 - Epoch: [13][  100/  391]    Overall Loss 0.475275    Objective Loss 0.475275    Top1 83.773438    Top5 99.289062    LR 0.300000    Time 0.023303    
2018-11-02 21:16:46,300 - Epoch: [13][  150/  391]    Overall Loss 0.481132    Objective Loss 0.481132    Top1 83.473958    Top5 99.265625    LR 0.300000    Time 0.023129    
2018-11-02 21:16:47,440 - Epoch: [13][  200/  391]    Overall Loss 0.484958    Objective Loss 0.484958    Top1 83.386719    Top5 99.292969    LR 0.300000    Time 0.023041    
2018-11-02 21:16:48,580 - Epoch: [13][  250/  391]    Overall Loss 0.482961    Objective Loss 0.482961    Top1 83.481250    Top5 99.275000    LR 0.300000    Time 0.022986    
2018-11-02 21:16:49,717 - Epoch: [13][  300/  391]    Overall Loss 0.482360    Objective Loss 0.482360    Top1 83.510417    Top5 99.276042    LR 0.300000    Time 0.022942    
2018-11-02 21:16:50,857 - Epoch: [13][  350/  391]    Overall Loss 0.485245    Objective Loss 0.485245    Top1 83.386161    Top5 99.261161    LR 0.300000    Time 0.022916    
2018-11-02 21:16:51,870 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55349 |  0.00370 |    0.36218 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15348 | -0.00110 |    0.09667 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15510 | -0.00969 |    0.10732 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19105 | -0.00944 |    0.13529 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19030 | -0.01051 |    0.14168 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17367 | -0.02263 |    0.12541 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 |  0.00269 |    0.11234 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19588 | -0.00169 |    0.14492 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16739 | -0.00591 |    0.12744 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39646 | -0.03399 |    0.29718 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15294 | -0.01054 |    0.11724 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13209 | -0.00868 |    0.10244 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13946 | -0.01909 |    0.11096 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11485 | -0.00144 |    0.08959 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14232 | -0.01461 |    0.11280 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12363 | -0.01177 |    0.09635 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21649 | -0.02162 |    0.16802 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11841 | -0.01150 |    0.09222 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09118 | -0.00056 |    0.06861 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04920 |  0.00080 |    0.03692 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04236 | -0.00933 |    0.03200 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58627 | -0.00083 |    0.46140 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:16:51,870 - Total sparsity: 0.00

2018-11-02 21:16:51,870 - --- validate (epoch=13)-----------
2018-11-02 21:16:51,870 - 10000 samples (128 per mini-batch)
2018-11-02 21:16:52,599 - Epoch: [13][   50/   78]    Loss 0.591525    Top1 79.968750    Top5 98.906250    
2018-11-02 21:16:52,993 - ==> Top1: 79.800    Top5: 98.950    Loss: 0.598

2018-11-02 21:16:52,994 - ==> Best Top1: 79.800   On Epoch: 13

2018-11-02 21:16:52,994 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:16:53,006 - 

2018-11-02 21:16:53,006 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:16:54,248 - Epoch: [14][   50/  391]    Overall Loss 0.468498    Objective Loss 0.468498    Top1 83.843750    Top5 99.296875    LR 0.300000    Time 0.024794    
2018-11-02 21:16:55,509 - Epoch: [14][  100/  391]    Overall Loss 0.478209    Objective Loss 0.478209    Top1 83.406250    Top5 99.265625    LR 0.300000    Time 0.024994    
2018-11-02 21:16:56,714 - Epoch: [14][  150/  391]    Overall Loss 0.483510    Objective Loss 0.483510    Top1 83.296875    Top5 99.260417    LR 0.300000    Time 0.024687    
2018-11-02 21:16:57,853 - Epoch: [14][  200/  391]    Overall Loss 0.475692    Objective Loss 0.475692    Top1 83.675781    Top5 99.246094    LR 0.300000    Time 0.024204    
2018-11-02 21:16:58,992 - Epoch: [14][  250/  391]    Overall Loss 0.480450    Objective Loss 0.480450    Top1 83.587500    Top5 99.246875    LR 0.300000    Time 0.023914    
2018-11-02 21:17:00,132 - Epoch: [14][  300/  391]    Overall Loss 0.481345    Objective Loss 0.481345    Top1 83.546875    Top5 99.263021    LR 0.300000    Time 0.023726    
2018-11-02 21:17:01,316 - Epoch: [14][  350/  391]    Overall Loss 0.477993    Objective Loss 0.477993    Top1 83.618304    Top5 99.276786    LR 0.300000    Time 0.023714    
2018-11-02 21:17:02,447 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55107 | -0.00209 |    0.35685 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15233 |  0.00099 |    0.09428 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15342 | -0.00934 |    0.10681 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19151 | -0.00915 |    0.13514 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19013 | -0.01015 |    0.14106 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17542 | -0.02505 |    0.12660 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15630 |  0.00112 |    0.11285 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19745 | -0.00645 |    0.14618 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16879 | -0.00550 |    0.12893 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39529 | -0.02779 |    0.29518 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15360 | -0.01021 |    0.11769 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13289 | -0.00918 |    0.10347 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14090 | -0.02001 |    0.11209 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11590 | -0.00005 |    0.09047 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14363 | -0.01465 |    0.11384 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12535 | -0.01174 |    0.09779 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21467 | -0.02250 |    0.16708 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11992 | -0.01255 |    0.09354 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09205 | -0.00036 |    0.06918 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04990 |  0.00076 |    0.03730 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04255 | -0.00954 |    0.03206 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59049 | -0.00073 |    0.46462 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:17:02,447 - Total sparsity: 0.00

2018-11-02 21:17:02,447 - --- validate (epoch=14)-----------
2018-11-02 21:17:02,447 - 10000 samples (128 per mini-batch)
2018-11-02 21:17:03,177 - Epoch: [14][   50/   78]    Loss 0.553592    Top1 81.796875    Top5 98.937500    
2018-11-02 21:17:03,587 - ==> Top1: 81.830    Top5: 98.940    Loss: 0.552

2018-11-02 21:17:03,588 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 21:17:03,588 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:17:03,600 - 

2018-11-02 21:17:03,600 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:17:04,842 - Epoch: [15][   50/  391]    Overall Loss 0.484880    Objective Loss 0.484880    Top1 83.625000    Top5 99.187500    LR 0.300000    Time 0.024792    
2018-11-02 21:17:06,004 - Epoch: [15][  100/  391]    Overall Loss 0.472924    Objective Loss 0.472924    Top1 83.953125    Top5 99.289062    LR 0.300000    Time 0.023996    
2018-11-02 21:17:07,160 - Epoch: [15][  150/  391]    Overall Loss 0.475943    Objective Loss 0.475943    Top1 83.588542    Top5 99.255208    LR 0.300000    Time 0.023693    
2018-11-02 21:17:08,329 - Epoch: [15][  200/  391]    Overall Loss 0.471260    Objective Loss 0.471260    Top1 83.691406    Top5 99.296875    LR 0.300000    Time 0.023608    
2018-11-02 21:17:09,504 - Epoch: [15][  250/  391]    Overall Loss 0.472324    Objective Loss 0.472324    Top1 83.650000    Top5 99.268750    LR 0.300000    Time 0.023581    
2018-11-02 21:17:10,701 - Epoch: [15][  300/  391]    Overall Loss 0.473911    Objective Loss 0.473911    Top1 83.598958    Top5 99.250000    LR 0.300000    Time 0.023634    
2018-11-02 21:17:11,859 - Epoch: [15][  350/  391]    Overall Loss 0.475216    Objective Loss 0.475216    Top1 83.569196    Top5 99.245536    LR 0.300000    Time 0.023562    
2018-11-02 21:17:12,934 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55279 |  0.00901 |    0.35802 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15245 |  0.00262 |    0.09606 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15349 | -0.00835 |    0.10611 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19157 | -0.00889 |    0.13533 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19060 | -0.00990 |    0.14089 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17727 | -0.02286 |    0.12708 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15769 |  0.00044 |    0.11474 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19858 | -0.00463 |    0.14704 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16968 | -0.00484 |    0.12943 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39967 | -0.02473 |    0.29574 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15352 | -0.00978 |    0.11710 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13348 | -0.00867 |    0.10355 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14240 | -0.02071 |    0.11367 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11719 | -0.00032 |    0.09135 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14469 | -0.01422 |    0.11459 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12681 | -0.01234 |    0.09931 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21507 | -0.02075 |    0.16668 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12158 | -0.01320 |    0.09510 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09278 | -0.00029 |    0.06991 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05035 |  0.00053 |    0.03760 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04266 | -0.00951 |    0.03186 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59383 | -0.00065 |    0.46829 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:17:12,934 - Total sparsity: 0.00

2018-11-02 21:17:12,934 - --- validate (epoch=15)-----------
2018-11-02 21:17:12,934 - 10000 samples (128 per mini-batch)
2018-11-02 21:17:13,698 - Epoch: [15][   50/   78]    Loss 0.644802    Top1 78.421875    Top5 98.546875    
2018-11-02 21:17:14,099 - ==> Top1: 78.460    Top5: 98.670    Loss: 0.645

2018-11-02 21:17:14,100 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 21:17:14,100 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:17:14,108 - 

2018-11-02 21:17:14,109 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:17:15,315 - Epoch: [16][   50/  391]    Overall Loss 0.462213    Objective Loss 0.462213    Top1 83.890625    Top5 99.218750    LR 0.300000    Time 0.024086    
2018-11-02 21:17:16,517 - Epoch: [16][  100/  391]    Overall Loss 0.466342    Objective Loss 0.466342    Top1 83.757812    Top5 99.226562    LR 0.300000    Time 0.024051    
2018-11-02 21:17:17,774 - Epoch: [16][  150/  391]    Overall Loss 0.455612    Objective Loss 0.455612    Top1 84.192708    Top5 99.291667    LR 0.300000    Time 0.024399    
2018-11-02 21:17:19,029 - Epoch: [16][  200/  391]    Overall Loss 0.466542    Objective Loss 0.466542    Top1 84.003906    Top5 99.226562    LR 0.300000    Time 0.024568    
2018-11-02 21:17:20,301 - Epoch: [16][  250/  391]    Overall Loss 0.465634    Objective Loss 0.465634    Top1 83.965625    Top5 99.240625    LR 0.300000    Time 0.024738    
2018-11-02 21:17:21,540 - Epoch: [16][  300/  391]    Overall Loss 0.466490    Objective Loss 0.466490    Top1 83.947917    Top5 99.247396    LR 0.300000    Time 0.024738    
2018-11-02 21:17:22,729 - Epoch: [16][  350/  391]    Overall Loss 0.467831    Objective Loss 0.467831    Top1 83.886161    Top5 99.234375    LR 0.300000    Time 0.024588    
2018-11-02 21:17:23,805 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55101 |  0.00327 |    0.36115 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15266 |  0.00318 |    0.09507 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15432 | -0.00735 |    0.10755 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19155 | -0.00953 |    0.13536 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19056 | -0.01257 |    0.14103 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17780 | -0.02604 |    0.12855 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15880 |  0.00287 |    0.11512 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19985 | -0.00590 |    0.14795 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17028 | -0.00348 |    0.12969 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39986 | -0.02810 |    0.29600 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15411 | -0.01175 |    0.11790 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13436 | -0.00894 |    0.10479 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14306 | -0.02140 |    0.11401 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11779 | -0.00083 |    0.09214 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14584 | -0.01490 |    0.11581 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12823 | -0.01221 |    0.10054 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21587 | -0.02027 |    0.16843 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12313 | -0.01251 |    0.09636 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09335 | -0.00049 |    0.07053 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05085 |  0.00070 |    0.03787 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04292 | -0.00890 |    0.03195 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59568 | -0.00058 |    0.46826 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:17:23,805 - Total sparsity: 0.00

2018-11-02 21:17:23,805 - --- validate (epoch=16)-----------
2018-11-02 21:17:23,805 - 10000 samples (128 per mini-batch)
2018-11-02 21:17:24,553 - Epoch: [16][   50/   78]    Loss 0.574556    Top1 81.484375    Top5 99.000000    
2018-11-02 21:17:24,950 - ==> Top1: 81.660    Top5: 99.080    Loss: 0.561

2018-11-02 21:17:24,951 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 21:17:24,951 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:17:24,963 - 

2018-11-02 21:17:24,963 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:17:26,163 - Epoch: [17][   50/  391]    Overall Loss 0.460725    Objective Loss 0.460725    Top1 84.093750    Top5 99.421875    LR 0.300000    Time 0.023954    
2018-11-02 21:17:27,361 - Epoch: [17][  100/  391]    Overall Loss 0.460128    Objective Loss 0.460128    Top1 84.031250    Top5 99.406250    LR 0.300000    Time 0.023943    
2018-11-02 21:17:28,626 - Epoch: [17][  150/  391]    Overall Loss 0.454301    Objective Loss 0.454301    Top1 84.328125    Top5 99.416667    LR 0.300000    Time 0.024389    
2018-11-02 21:17:29,831 - Epoch: [17][  200/  391]    Overall Loss 0.455855    Objective Loss 0.455855    Top1 84.351562    Top5 99.414062    LR 0.300000    Time 0.024309    
2018-11-02 21:17:31,019 - Epoch: [17][  250/  391]    Overall Loss 0.455916    Objective Loss 0.455916    Top1 84.356250    Top5 99.356250    LR 0.300000    Time 0.024192    
2018-11-02 21:17:32,158 - Epoch: [17][  300/  391]    Overall Loss 0.457474    Objective Loss 0.457474    Top1 84.307292    Top5 99.343750    LR 0.300000    Time 0.023953    
2018-11-02 21:17:33,300 - Epoch: [17][  350/  391]    Overall Loss 0.459062    Objective Loss 0.459062    Top1 84.261161    Top5 99.321429    LR 0.300000    Time 0.023790    
2018-11-02 21:17:34,316 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55572 | -0.00064 |    0.36143 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15227 |  0.00596 |    0.09559 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15449 | -0.00810 |    0.10693 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19289 | -0.01132 |    0.13571 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19102 | -0.00690 |    0.14063 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17986 | -0.02708 |    0.13028 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16057 |  0.00357 |    0.11589 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20074 | -0.00445 |    0.14873 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17094 | -0.00384 |    0.13036 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40238 | -0.03077 |    0.29962 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15454 | -0.01163 |    0.11845 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13487 | -0.00955 |    0.10525 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14455 | -0.02156 |    0.11508 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11892 | -0.00069 |    0.09308 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14711 | -0.01609 |    0.11685 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13006 | -0.01144 |    0.10183 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21591 | -0.02090 |    0.16874 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12486 | -0.01269 |    0.09789 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09413 |  0.00043 |    0.07106 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05155 |  0.00060 |    0.03842 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04323 | -0.00898 |    0.03212 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59700 | -0.00052 |    0.47026 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:17:34,317 - Total sparsity: 0.00

2018-11-02 21:17:34,317 - --- validate (epoch=17)-----------
2018-11-02 21:17:34,317 - 10000 samples (128 per mini-batch)
2018-11-02 21:17:35,045 - Epoch: [17][   50/   78]    Loss 0.620183    Top1 79.328125    Top5 98.984375    
2018-11-02 21:17:35,440 - ==> Top1: 79.560    Top5: 99.010    Loss: 0.625

2018-11-02 21:17:35,441 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 21:17:35,441 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:17:35,453 - 

2018-11-02 21:17:35,453 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:17:36,654 - Epoch: [18][   50/  391]    Overall Loss 0.438647    Objective Loss 0.438647    Top1 84.484375    Top5 99.343750    LR 0.300000    Time 0.023975    
2018-11-02 21:17:37,793 - Epoch: [18][  100/  391]    Overall Loss 0.438232    Objective Loss 0.438232    Top1 84.695312    Top5 99.351562    LR 0.300000    Time 0.023367    
2018-11-02 21:17:38,933 - Epoch: [18][  150/  391]    Overall Loss 0.454791    Objective Loss 0.454791    Top1 84.145833    Top5 99.322917    LR 0.300000    Time 0.023168    
2018-11-02 21:17:40,073 - Epoch: [18][  200/  391]    Overall Loss 0.452430    Objective Loss 0.452430    Top1 84.238281    Top5 99.335938    LR 0.300000    Time 0.023069    
2018-11-02 21:17:41,214 - Epoch: [18][  250/  391]    Overall Loss 0.447912    Objective Loss 0.447912    Top1 84.450000    Top5 99.318750    LR 0.300000    Time 0.023015    
2018-11-02 21:17:42,355 - Epoch: [18][  300/  391]    Overall Loss 0.447908    Objective Loss 0.447908    Top1 84.526042    Top5 99.317708    LR 0.300000    Time 0.022976    
2018-11-02 21:17:43,499 - Epoch: [18][  350/  391]    Overall Loss 0.448539    Objective Loss 0.448539    Top1 84.517857    Top5 99.321429    LR 0.300000    Time 0.022960    
2018-11-02 21:17:44,517 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55580 |  0.00262 |    0.36041 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15262 |  0.00509 |    0.09543 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15409 | -0.00986 |    0.10660 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19497 | -0.01176 |    0.13696 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19304 | -0.01037 |    0.14186 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18067 | -0.02625 |    0.13026 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16071 |  0.00356 |    0.11522 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20039 | -0.00482 |    0.14832 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17068 | -0.00398 |    0.13025 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40276 | -0.02892 |    0.29762 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15414 | -0.01250 |    0.11773 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13491 | -0.01059 |    0.10544 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14502 | -0.02207 |    0.11540 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11892 | -0.00007 |    0.09314 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14773 | -0.01515 |    0.11760 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13073 | -0.01171 |    0.10254 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21520 | -0.02302 |    0.16862 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12619 | -0.01301 |    0.09900 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09466 | -0.00025 |    0.07146 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05225 | -0.00010 |    0.03900 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04351 | -0.00904 |    0.03225 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59936 | -0.00046 |    0.47117 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:17:44,517 - Total sparsity: 0.00

2018-11-02 21:17:44,517 - --- validate (epoch=18)-----------
2018-11-02 21:17:44,517 - 10000 samples (128 per mini-batch)
2018-11-02 21:17:45,249 - Epoch: [18][   50/   78]    Loss 0.531873    Top1 82.000000    Top5 98.906250    
2018-11-02 21:17:45,644 - ==> Top1: 81.720    Top5: 99.130    Loss: 0.532

2018-11-02 21:17:45,645 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 21:17:45,645 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:17:45,654 - 

2018-11-02 21:17:45,654 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:17:46,850 - Epoch: [19][   50/  391]    Overall Loss 0.417357    Objective Loss 0.417357    Top1 85.484375    Top5 99.609375    LR 0.300000    Time 0.023891    
2018-11-02 21:17:47,992 - Epoch: [19][  100/  391]    Overall Loss 0.438285    Objective Loss 0.438285    Top1 84.820312    Top5 99.468750    LR 0.300000    Time 0.023353    
2018-11-02 21:17:49,134 - Epoch: [19][  150/  391]    Overall Loss 0.443575    Objective Loss 0.443575    Top1 84.598958    Top5 99.421875    LR 0.300000    Time 0.023172    
2018-11-02 21:17:50,275 - Epoch: [19][  200/  391]    Overall Loss 0.437444    Objective Loss 0.437444    Top1 84.855469    Top5 99.414062    LR 0.300000    Time 0.023075    
2018-11-02 21:17:51,415 - Epoch: [19][  250/  391]    Overall Loss 0.441505    Objective Loss 0.441505    Top1 84.734375    Top5 99.365625    LR 0.300000    Time 0.023017    
2018-11-02 21:17:52,555 - Epoch: [19][  300/  391]    Overall Loss 0.443858    Objective Loss 0.443858    Top1 84.614583    Top5 99.356771    LR 0.300000    Time 0.022975    
2018-11-02 21:17:53,696 - Epoch: [19][  350/  391]    Overall Loss 0.441310    Objective Loss 0.441310    Top1 84.676339    Top5 99.368304    LR 0.300000    Time 0.022949    
2018-11-02 21:17:54,712 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55798 | -0.00145 |    0.35900 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15383 |  0.00457 |    0.09586 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15540 | -0.01014 |    0.10807 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19522 | -0.00898 |    0.13797 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19228 | -0.01323 |    0.14205 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18116 | -0.02718 |    0.13117 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16121 |  0.00241 |    0.11514 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20039 | -0.00467 |    0.14725 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17052 | -0.00287 |    0.13006 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40346 | -0.02675 |    0.29713 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15451 | -0.01154 |    0.11783 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13552 | -0.00996 |    0.10596 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14561 | -0.02155 |    0.11552 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11908 | -0.00014 |    0.09329 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14815 | -0.01653 |    0.11787 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13120 | -0.01270 |    0.10309 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21536 | -0.02351 |    0.16869 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12709 | -0.01281 |    0.09946 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09504 | -0.00015 |    0.07175 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05315 | -0.00021 |    0.03959 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04389 | -0.00880 |    0.03242 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60234 | -0.00041 |    0.47271 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:17:54,712 - Total sparsity: 0.00

2018-11-02 21:17:54,712 - --- validate (epoch=19)-----------
2018-11-02 21:17:54,712 - 10000 samples (128 per mini-batch)
2018-11-02 21:17:55,440 - Epoch: [19][   50/   78]    Loss 0.561296    Top1 81.906250    Top5 98.968750    
2018-11-02 21:17:55,834 - ==> Top1: 81.390    Top5: 99.030    Loss: 0.564

2018-11-02 21:17:55,835 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 21:17:55,835 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:17:55,846 - 

2018-11-02 21:17:55,846 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:17:57,044 - Epoch: [20][   50/  391]    Overall Loss 0.411911    Objective Loss 0.411911    Top1 85.359375    Top5 99.515625    LR 0.300000    Time 0.023914    
2018-11-02 21:17:58,183 - Epoch: [20][  100/  391]    Overall Loss 0.430509    Objective Loss 0.430509    Top1 85.093750    Top5 99.429688    LR 0.300000    Time 0.023338    
2018-11-02 21:17:59,324 - Epoch: [20][  150/  391]    Overall Loss 0.436406    Objective Loss 0.436406    Top1 84.880208    Top5 99.380208    LR 0.300000    Time 0.023153    
2018-11-02 21:18:00,466 - Epoch: [20][  200/  391]    Overall Loss 0.438936    Objective Loss 0.438936    Top1 84.882812    Top5 99.402344    LR 0.300000    Time 0.023068    
2018-11-02 21:18:01,607 - Epoch: [20][  250/  391]    Overall Loss 0.439447    Objective Loss 0.439447    Top1 84.893750    Top5 99.393750    LR 0.300000    Time 0.023015    
2018-11-02 21:18:02,748 - Epoch: [20][  300/  391]    Overall Loss 0.441940    Objective Loss 0.441940    Top1 84.812500    Top5 99.388021    LR 0.300000    Time 0.022977    
2018-11-02 21:18:03,888 - Epoch: [20][  350/  391]    Overall Loss 0.441413    Objective Loss 0.441413    Top1 84.839286    Top5 99.401786    LR 0.300000    Time 0.022948    
2018-11-02 21:18:04,904 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56022 | -0.00214 |    0.36342 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15280 |  0.00103 |    0.09436 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15470 | -0.00647 |    0.10723 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19598 | -0.01220 |    0.13979 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19355 | -0.01037 |    0.14364 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18356 | -0.02717 |    0.13197 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16246 |  0.00271 |    0.11603 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20206 | -0.00662 |    0.14811 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17167 | -0.00418 |    0.13108 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40287 | -0.02322 |    0.29334 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 | -0.01232 |    0.11863 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13587 | -0.00949 |    0.10580 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14608 | -0.02394 |    0.11630 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11944 | -0.00131 |    0.09366 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14866 | -0.01503 |    0.11813 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13151 | -0.01202 |    0.10334 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21614 | -0.02249 |    0.16993 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12766 | -0.01177 |    0.10002 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09536 | -0.00037 |    0.07196 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05353 | -0.00058 |    0.03987 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04413 | -0.00830 |    0.03255 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60156 | -0.00036 |    0.47291 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:18:04,905 - Total sparsity: 0.00

2018-11-02 21:18:04,905 - --- validate (epoch=20)-----------
2018-11-02 21:18:04,905 - 10000 samples (128 per mini-batch)
2018-11-02 21:18:05,638 - Epoch: [20][   50/   78]    Loss 0.692618    Top1 78.000000    Top5 98.359375    
2018-11-02 21:18:06,040 - ==> Top1: 77.920    Top5: 98.530    Loss: 0.693

2018-11-02 21:18:06,041 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 21:18:06,041 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:18:06,049 - 

2018-11-02 21:18:06,049 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:18:07,251 - Epoch: [21][   50/  391]    Overall Loss 0.419993    Objective Loss 0.419993    Top1 85.484375    Top5 99.343750    LR 0.300000    Time 0.023990    
2018-11-02 21:18:08,390 - Epoch: [21][  100/  391]    Overall Loss 0.422242    Objective Loss 0.422242    Top1 85.585938    Top5 99.406250    LR 0.300000    Time 0.023373    
2018-11-02 21:18:09,531 - Epoch: [21][  150/  391]    Overall Loss 0.427061    Objective Loss 0.427061    Top1 85.380208    Top5 99.390625    LR 0.300000    Time 0.023180    
2018-11-02 21:18:10,671 - Epoch: [21][  200/  391]    Overall Loss 0.432874    Objective Loss 0.432874    Top1 85.035156    Top5 99.402344    LR 0.300000    Time 0.023079    
2018-11-02 21:18:11,811 - Epoch: [21][  250/  391]    Overall Loss 0.436389    Objective Loss 0.436389    Top1 84.893750    Top5 99.387500    LR 0.300000    Time 0.023017    
2018-11-02 21:18:12,950 - Epoch: [21][  300/  391]    Overall Loss 0.439647    Objective Loss 0.439647    Top1 84.830729    Top5 99.382812    LR 0.300000    Time 0.022973    
2018-11-02 21:18:14,089 - Epoch: [21][  350/  391]    Overall Loss 0.438854    Objective Loss 0.438854    Top1 84.870536    Top5 99.366071    LR 0.300000    Time 0.022932    
2018-11-02 21:18:15,103 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55944 | -0.00293 |    0.36365 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15262 |  0.00155 |    0.09379 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15445 | -0.00603 |    0.10714 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19492 | -0.01450 |    0.13869 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19318 | -0.00890 |    0.14303 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18467 | -0.02714 |    0.13353 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16321 |  0.00456 |    0.11666 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20192 | -0.00659 |    0.14906 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17162 | -0.00400 |    0.13097 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40251 | -0.01938 |    0.28975 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15558 | -0.01196 |    0.11884 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13585 | -0.00914 |    0.10622 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14723 | -0.02276 |    0.11700 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11963 | -0.00149 |    0.09374 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14913 | -0.01426 |    0.11867 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13179 | -0.01228 |    0.10375 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21532 | -0.02251 |    0.16923 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12787 | -0.01295 |    0.10020 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09554 |  0.00019 |    0.07199 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05397 | -0.00037 |    0.04020 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04458 | -0.00834 |    0.03293 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60256 | -0.00032 |    0.47432 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:18:15,104 - Total sparsity: 0.00

2018-11-02 21:18:15,104 - --- validate (epoch=21)-----------
2018-11-02 21:18:15,104 - 10000 samples (128 per mini-batch)
2018-11-02 21:18:15,831 - Epoch: [21][   50/   78]    Loss 0.538879    Top1 82.671875    Top5 99.031250    
2018-11-02 21:18:16,227 - ==> Top1: 82.470    Top5: 99.150    Loss: 0.541

2018-11-02 21:18:16,227 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 21:18:16,227 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:18:16,239 - 

2018-11-02 21:18:16,239 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:18:17,438 - Epoch: [22][   50/  391]    Overall Loss 0.431970    Objective Loss 0.431970    Top1 84.859375    Top5 99.515625    LR 0.300000    Time 0.023944    
2018-11-02 21:18:18,585 - Epoch: [22][  100/  391]    Overall Loss 0.426939    Objective Loss 0.426939    Top1 85.289062    Top5 99.437500    LR 0.300000    Time 0.023421    
2018-11-02 21:18:19,733 - Epoch: [22][  150/  391]    Overall Loss 0.435777    Objective Loss 0.435777    Top1 84.947917    Top5 99.442708    LR 0.300000    Time 0.023260    
2018-11-02 21:18:20,874 - Epoch: [22][  200/  391]    Overall Loss 0.438827    Objective Loss 0.438827    Top1 84.828125    Top5 99.425781    LR 0.300000    Time 0.023144    
2018-11-02 21:18:22,019 - Epoch: [22][  250/  391]    Overall Loss 0.436408    Objective Loss 0.436408    Top1 84.956250    Top5 99.393750    LR 0.300000    Time 0.023088    
2018-11-02 21:18:23,161 - Epoch: [22][  300/  391]    Overall Loss 0.436915    Objective Loss 0.436915    Top1 85.026042    Top5 99.406250    LR 0.300000    Time 0.023043    
2018-11-02 21:18:24,313 - Epoch: [22][  350/  391]    Overall Loss 0.435117    Objective Loss 0.435117    Top1 85.044643    Top5 99.430804    LR 0.300000    Time 0.023039    
2018-11-02 21:18:25,410 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55931 | -0.00163 |    0.36545 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15193 |  0.00148 |    0.09282 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15298 | -0.00438 |    0.10528 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19470 | -0.01341 |    0.13839 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19333 | -0.00593 |    0.14213 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18637 | -0.02705 |    0.13465 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16435 |  0.00240 |    0.11810 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20318 | -0.00653 |    0.14961 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17176 | -0.00364 |    0.13141 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40091 | -0.01273 |    0.28733 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 | -0.01138 |    0.11824 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13538 | -0.00933 |    0.10614 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14787 | -0.02446 |    0.11764 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12058 | -0.00136 |    0.09446 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14888 | -0.01484 |    0.11843 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13218 | -0.01193 |    0.10413 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21486 | -0.02405 |    0.16893 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12864 | -0.01302 |    0.10091 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09585 | -0.00016 |    0.07237 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05447 | -0.00113 |    0.04058 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04486 | -0.00821 |    0.03304 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60354 | -0.00029 |    0.47180 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:18:25,411 - Total sparsity: 0.00

2018-11-02 21:18:25,411 - --- validate (epoch=22)-----------
2018-11-02 21:18:25,411 - 10000 samples (128 per mini-batch)
2018-11-02 21:18:26,151 - Epoch: [22][   50/   78]    Loss 0.580114    Top1 81.484375    Top5 99.109375    
2018-11-02 21:18:26,553 - ==> Top1: 81.150    Top5: 99.200    Loss: 0.578

2018-11-02 21:18:26,554 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 21:18:26,554 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:18:26,562 - 

2018-11-02 21:18:26,563 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:18:27,777 - Epoch: [23][   50/  391]    Overall Loss 0.421167    Objective Loss 0.421167    Top1 85.484375    Top5 99.453125    LR 0.300000    Time 0.024255    
2018-11-02 21:18:28,932 - Epoch: [23][  100/  391]    Overall Loss 0.425054    Objective Loss 0.425054    Top1 85.359375    Top5 99.359375    LR 0.300000    Time 0.023659    
2018-11-02 21:18:30,077 - Epoch: [23][  150/  391]    Overall Loss 0.426006    Objective Loss 0.426006    Top1 85.255208    Top5 99.395833    LR 0.300000    Time 0.023402    
2018-11-02 21:18:31,219 - Epoch: [23][  200/  391]    Overall Loss 0.428340    Objective Loss 0.428340    Top1 85.250000    Top5 99.351562    LR 0.300000    Time 0.023254    
2018-11-02 21:18:32,375 - Epoch: [23][  250/  391]    Overall Loss 0.429339    Objective Loss 0.429339    Top1 85.218750    Top5 99.353125    LR 0.300000    Time 0.023222    
2018-11-02 21:18:33,522 - Epoch: [23][  300/  391]    Overall Loss 0.425796    Objective Loss 0.425796    Top1 85.341146    Top5 99.367188    LR 0.300000    Time 0.023169    
2018-11-02 21:18:34,673 - Epoch: [23][  350/  391]    Overall Loss 0.427985    Objective Loss 0.427985    Top1 85.272321    Top5 99.354911    LR 0.300000    Time 0.023144    
2018-11-02 21:18:35,694 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56331 | -0.00619 |    0.37125 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15253 |  0.00098 |    0.09314 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15285 | -0.00640 |    0.10529 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19465 | -0.01107 |    0.13852 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19218 | -0.01044 |    0.14144 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18634 | -0.02971 |    0.13458 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16573 |  0.00245 |    0.11888 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20379 | -0.00878 |    0.14929 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17207 | -0.00347 |    0.13122 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40086 | -0.01714 |    0.28688 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15466 | -0.01162 |    0.11816 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13578 | -0.00972 |    0.10664 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14931 | -0.02425 |    0.11907 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12116 | -0.00075 |    0.09539 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14902 | -0.01488 |    0.11810 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13235 | -0.01206 |    0.10414 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21460 | -0.02368 |    0.16800 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12909 | -0.01330 |    0.10127 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09596 | -0.00033 |    0.07245 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05503 | -0.00124 |    0.04108 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04516 | -0.00811 |    0.03326 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60041 | -0.00025 |    0.47228 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:18:35,694 - Total sparsity: 0.00

2018-11-02 21:18:35,694 - --- validate (epoch=23)-----------
2018-11-02 21:18:35,694 - 10000 samples (128 per mini-batch)
2018-11-02 21:18:36,427 - Epoch: [23][   50/   78]    Loss 0.629701    Top1 80.968750    Top5 98.187500    
2018-11-02 21:18:36,821 - ==> Top1: 80.420    Top5: 98.330    Loss: 0.628

2018-11-02 21:18:36,822 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 21:18:36,822 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:18:36,830 - 

2018-11-02 21:18:36,830 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:18:38,033 - Epoch: [24][   50/  391]    Overall Loss 0.440332    Objective Loss 0.440332    Top1 84.796875    Top5 99.421875    LR 0.300000    Time 0.024032    
2018-11-02 21:18:39,209 - Epoch: [24][  100/  391]    Overall Loss 0.430900    Objective Loss 0.430900    Top1 85.187500    Top5 99.429688    LR 0.300000    Time 0.023754    
2018-11-02 21:18:40,355 - Epoch: [24][  150/  391]    Overall Loss 0.427604    Objective Loss 0.427604    Top1 85.312500    Top5 99.427083    LR 0.300000    Time 0.023470    
2018-11-02 21:18:41,500 - Epoch: [24][  200/  391]    Overall Loss 0.422351    Objective Loss 0.422351    Top1 85.562500    Top5 99.402344    LR 0.300000    Time 0.023320    
2018-11-02 21:18:42,649 - Epoch: [24][  250/  391]    Overall Loss 0.425870    Objective Loss 0.425870    Top1 85.506250    Top5 99.412500    LR 0.300000    Time 0.023248    
2018-11-02 21:18:43,792 - Epoch: [24][  300/  391]    Overall Loss 0.427738    Objective Loss 0.427738    Top1 85.375000    Top5 99.403646    LR 0.300000    Time 0.023177    
2018-11-02 21:18:44,942 - Epoch: [24][  350/  391]    Overall Loss 0.426338    Objective Loss 0.426338    Top1 85.404018    Top5 99.397321    LR 0.300000    Time 0.023150    
2018-11-02 21:18:45,957 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56382 |  0.00770 |    0.36859 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15389 | -0.00019 |    0.09332 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15361 | -0.00941 |    0.10601 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19384 | -0.00951 |    0.13698 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19088 | -0.01362 |    0.14025 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18972 | -0.02612 |    0.13699 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16627 |  0.00270 |    0.12032 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20425 | -0.00600 |    0.15008 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17251 | -0.00432 |    0.13138 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40070 | -0.02117 |    0.28989 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15490 | -0.01204 |    0.11851 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13635 | -0.00940 |    0.10729 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14976 | -0.02400 |    0.11934 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12153 | -0.00262 |    0.09548 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14977 | -0.01488 |    0.11875 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13321 | -0.01226 |    0.10490 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21427 | -0.02636 |    0.16802 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13004 | -0.01319 |    0.10216 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09656 | -0.00002 |    0.07290 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05565 | -0.00100 |    0.04155 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04570 | -0.00834 |    0.03372 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60339 | -0.00023 |    0.47411 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:18:45,957 - Total sparsity: 0.00

2018-11-02 21:18:45,957 - --- validate (epoch=24)-----------
2018-11-02 21:18:45,957 - 10000 samples (128 per mini-batch)
2018-11-02 21:18:46,683 - Epoch: [24][   50/   78]    Loss 0.581916    Top1 81.265625    Top5 98.671875    
2018-11-02 21:18:47,078 - ==> Top1: 81.050    Top5: 98.860    Loss: 0.575

2018-11-02 21:18:47,079 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 21:18:47,079 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:18:47,087 - 

2018-11-02 21:18:47,087 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:18:48,282 - Epoch: [25][   50/  391]    Overall Loss 0.398186    Objective Loss 0.398186    Top1 86.500000    Top5 99.437500    LR 0.300000    Time 0.023864    
2018-11-02 21:18:49,424 - Epoch: [25][  100/  391]    Overall Loss 0.411513    Objective Loss 0.411513    Top1 86.015625    Top5 99.437500    LR 0.300000    Time 0.023330    
2018-11-02 21:18:50,564 - Epoch: [25][  150/  391]    Overall Loss 0.424587    Objective Loss 0.424587    Top1 85.463542    Top5 99.432292    LR 0.300000    Time 0.023149    
2018-11-02 21:18:51,706 - Epoch: [25][  200/  391]    Overall Loss 0.422686    Objective Loss 0.422686    Top1 85.500000    Top5 99.449219    LR 0.300000    Time 0.023061    
2018-11-02 21:18:52,849 - Epoch: [25][  250/  391]    Overall Loss 0.422980    Objective Loss 0.422980    Top1 85.393750    Top5 99.453125    LR 0.300000    Time 0.023015    
2018-11-02 21:18:53,988 - Epoch: [25][  300/  391]    Overall Loss 0.424185    Objective Loss 0.424185    Top1 85.328125    Top5 99.476562    LR 0.300000    Time 0.022963    
2018-11-02 21:18:55,130 - Epoch: [25][  350/  391]    Overall Loss 0.425829    Objective Loss 0.425829    Top1 85.292411    Top5 99.468750    LR 0.300000    Time 0.022939    
2018-11-02 21:18:56,154 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56415 | -0.00388 |    0.36911 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15422 |  0.00305 |    0.09458 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15460 | -0.00816 |    0.10570 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19308 | -0.01384 |    0.13711 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19132 | -0.01003 |    0.14029 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19025 | -0.02792 |    0.13733 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16661 |  0.00637 |    0.12014 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20484 | -0.00566 |    0.14992 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17324 | -0.00478 |    0.13239 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39848 | -0.02127 |    0.28655 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15486 | -0.01146 |    0.11870 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13642 | -0.00937 |    0.10711 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14995 | -0.02438 |    0.11934 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12166 | -0.00158 |    0.09522 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15012 | -0.01503 |    0.11927 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13388 | -0.01241 |    0.10552 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21342 | -0.02524 |    0.16806 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13051 | -0.01331 |    0.10254 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09684 |  0.00036 |    0.07302 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05624 | -0.00153 |    0.04201 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04620 | -0.00782 |    0.03403 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60467 | -0.00020 |    0.47156 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:18:56,154 - Total sparsity: 0.00

2018-11-02 21:18:56,155 - --- validate (epoch=25)-----------
2018-11-02 21:18:56,155 - 10000 samples (128 per mini-batch)
2018-11-02 21:18:56,890 - Epoch: [25][   50/   78]    Loss 0.643285    Top1 79.984375    Top5 98.531250    
2018-11-02 21:18:57,296 - ==> Top1: 79.740    Top5: 98.630    Loss: 0.646

2018-11-02 21:18:57,297 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 21:18:57,297 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:18:57,305 - 

2018-11-02 21:18:57,305 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:18:58,528 - Epoch: [26][   50/  391]    Overall Loss 0.417416    Objective Loss 0.417416    Top1 85.578125    Top5 99.500000    LR 0.300000    Time 0.024422    
2018-11-02 21:18:59,668 - Epoch: [26][  100/  391]    Overall Loss 0.417940    Objective Loss 0.417940    Top1 85.703125    Top5 99.554688    LR 0.300000    Time 0.023597    
2018-11-02 21:19:00,813 - Epoch: [26][  150/  391]    Overall Loss 0.422377    Objective Loss 0.422377    Top1 85.458333    Top5 99.489583    LR 0.300000    Time 0.023355    
2018-11-02 21:19:01,957 - Epoch: [26][  200/  391]    Overall Loss 0.416953    Objective Loss 0.416953    Top1 85.652344    Top5 99.468750    LR 0.300000    Time 0.023228    
2018-11-02 21:19:03,101 - Epoch: [26][  250/  391]    Overall Loss 0.421263    Objective Loss 0.421263    Top1 85.484375    Top5 99.443750    LR 0.300000    Time 0.023152    
2018-11-02 21:19:04,248 - Epoch: [26][  300/  391]    Overall Loss 0.421681    Objective Loss 0.421681    Top1 85.505208    Top5 99.445312    LR 0.300000    Time 0.023113    
2018-11-02 21:19:05,403 - Epoch: [26][  350/  391]    Overall Loss 0.423767    Objective Loss 0.423767    Top1 85.437500    Top5 99.424107    LR 0.300000    Time 0.023106    
2018-11-02 21:19:06,435 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56443 | -0.01236 |    0.36893 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15407 |  0.00360 |    0.09396 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15561 | -0.00711 |    0.10610 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19233 | -0.01452 |    0.13666 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19109 | -0.01156 |    0.13982 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19049 | -0.02948 |    0.13886 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16756 |  0.00284 |    0.12074 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20597 | -0.00562 |    0.15008 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17441 | -0.00668 |    0.13364 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40020 | -0.02187 |    0.28941 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15475 | -0.01132 |    0.11846 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13643 | -0.01002 |    0.10732 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15129 | -0.02395 |    0.12015 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12222 | -0.00141 |    0.09585 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15090 | -0.01494 |    0.11964 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13456 | -0.01205 |    0.10620 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21358 | -0.02265 |    0.16770 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13123 | -0.01277 |    0.10301 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09704 |  0.00043 |    0.07314 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05684 | -0.00116 |    0.04245 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04653 | -0.00781 |    0.03420 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60335 | -0.00018 |    0.47215 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:19:06,435 - Total sparsity: 0.00

2018-11-02 21:19:06,435 - --- validate (epoch=26)-----------
2018-11-02 21:19:06,435 - 10000 samples (128 per mini-batch)
2018-11-02 21:19:07,167 - Epoch: [26][   50/   78]    Loss 0.667699    Top1 78.296875    Top5 98.421875    
2018-11-02 21:19:07,565 - ==> Top1: 77.740    Top5: 98.400    Loss: 0.690

2018-11-02 21:19:07,566 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 21:19:07,566 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:19:07,575 - 

2018-11-02 21:19:07,575 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:19:08,790 - Epoch: [27][   50/  391]    Overall Loss 0.425505    Objective Loss 0.425505    Top1 85.609375    Top5 99.437500    LR 0.300000    Time 0.024267    
2018-11-02 21:19:09,935 - Epoch: [27][  100/  391]    Overall Loss 0.423597    Objective Loss 0.423597    Top1 85.609375    Top5 99.453125    LR 0.300000    Time 0.023563    
2018-11-02 21:19:11,080 - Epoch: [27][  150/  391]    Overall Loss 0.416781    Objective Loss 0.416781    Top1 85.828125    Top5 99.479167    LR 0.300000    Time 0.023337    
2018-11-02 21:19:12,234 - Epoch: [27][  200/  391]    Overall Loss 0.415437    Objective Loss 0.415437    Top1 85.722656    Top5 99.468750    LR 0.300000    Time 0.023264    
2018-11-02 21:19:13,385 - Epoch: [27][  250/  391]    Overall Loss 0.417865    Objective Loss 0.417865    Top1 85.590625    Top5 99.446875    LR 0.300000    Time 0.023210    
2018-11-02 21:19:14,529 - Epoch: [27][  300/  391]    Overall Loss 0.413472    Objective Loss 0.413472    Top1 85.765625    Top5 99.445312    LR 0.300000    Time 0.023149    
2018-11-02 21:19:15,677 - Epoch: [27][  350/  391]    Overall Loss 0.415889    Objective Loss 0.415889    Top1 85.680804    Top5 99.428571    LR 0.300000    Time 0.023117    
2018-11-02 21:19:16,694 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56756 | -0.01378 |    0.36896 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15403 |  0.00238 |    0.09327 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15596 | -0.00637 |    0.10596 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19256 | -0.01275 |    0.13708 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19143 | -0.01183 |    0.13931 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19081 | -0.03152 |    0.13948 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16832 |  0.00377 |    0.12115 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20688 | -0.00751 |    0.15132 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17535 | -0.00563 |    0.13418 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40102 | -0.01897 |    0.29237 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15496 | -0.01057 |    0.11877 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13627 | -0.01023 |    0.10757 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15175 | -0.02513 |    0.12025 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12306 | -0.00073 |    0.09639 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15139 | -0.01419 |    0.12022 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13522 | -0.01116 |    0.10675 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21448 | -0.02257 |    0.16904 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13193 | -0.01317 |    0.10372 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09723 |  0.00011 |    0.07338 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05733 | -0.00201 |    0.04292 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04692 | -0.00738 |    0.03438 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60330 | -0.00016 |    0.47040 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:19:16,694 - Total sparsity: 0.00

2018-11-02 21:19:16,694 - --- validate (epoch=27)-----------
2018-11-02 21:19:16,694 - 10000 samples (128 per mini-batch)
2018-11-02 21:19:17,414 - Epoch: [27][   50/   78]    Loss 0.628523    Top1 79.921875    Top5 98.718750    
2018-11-02 21:19:17,807 - ==> Top1: 79.560    Top5: 98.830    Loss: 0.628

2018-11-02 21:19:17,808 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 21:19:17,808 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:19:17,816 - 

2018-11-02 21:19:17,816 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:19:19,019 - Epoch: [28][   50/  391]    Overall Loss 0.407176    Objective Loss 0.407176    Top1 85.515625    Top5 99.625000    LR 0.300000    Time 0.024016    
2018-11-02 21:19:20,167 - Epoch: [28][  100/  391]    Overall Loss 0.421477    Objective Loss 0.421477    Top1 85.375000    Top5 99.492188    LR 0.300000    Time 0.023471    
2018-11-02 21:19:21,313 - Epoch: [28][  150/  391]    Overall Loss 0.415005    Objective Loss 0.415005    Top1 85.677083    Top5 99.520833    LR 0.300000    Time 0.023279    
2018-11-02 21:19:22,457 - Epoch: [28][  200/  391]    Overall Loss 0.408802    Objective Loss 0.408802    Top1 85.914062    Top5 99.500000    LR 0.300000    Time 0.023174    
2018-11-02 21:19:23,597 - Epoch: [28][  250/  391]    Overall Loss 0.416891    Objective Loss 0.416891    Top1 85.693750    Top5 99.471875    LR 0.300000    Time 0.023092    
2018-11-02 21:19:24,745 - Epoch: [28][  300/  391]    Overall Loss 0.415789    Objective Loss 0.415789    Top1 85.747396    Top5 99.466146    LR 0.300000    Time 0.023066    
2018-11-02 21:19:25,889 - Epoch: [28][  350/  391]    Overall Loss 0.414076    Objective Loss 0.414076    Top1 85.814732    Top5 99.462054    LR 0.300000    Time 0.023036    
2018-11-02 21:19:26,912 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56534 |  0.00175 |    0.36423 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15336 | -0.00013 |    0.09260 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15473 | -0.00373 |    0.10536 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19110 | -0.01358 |    0.13533 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19134 | -0.01279 |    0.14054 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19145 | -0.02944 |    0.14004 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16814 |  0.00259 |    0.12023 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20778 | -0.00798 |    0.15183 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17584 | -0.00533 |    0.13467 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39968 | -0.02168 |    0.28785 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15456 | -0.01129 |    0.11844 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13616 | -0.00848 |    0.10708 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15215 | -0.02486 |    0.12057 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12318 | -0.00092 |    0.09633 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15141 | -0.01426 |    0.12004 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13530 | -0.01229 |    0.10681 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21424 | -0.02241 |    0.16739 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13237 | -0.01299 |    0.10401 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09738 | -0.00015 |    0.07349 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05790 | -0.00159 |    0.04335 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04728 | -0.00748 |    0.03475 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60446 | -0.00014 |    0.47241 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:19:26,912 - Total sparsity: 0.00

2018-11-02 21:19:26,912 - --- validate (epoch=28)-----------
2018-11-02 21:19:26,912 - 10000 samples (128 per mini-batch)
2018-11-02 21:19:27,652 - Epoch: [28][   50/   78]    Loss 0.640717    Top1 78.468750    Top5 98.781250    
2018-11-02 21:19:28,050 - ==> Top1: 78.290    Top5: 98.820    Loss: 0.644

2018-11-02 21:19:28,051 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 21:19:28,051 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:19:28,060 - 

2018-11-02 21:19:28,060 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:19:29,270 - Epoch: [29][   50/  391]    Overall Loss 0.420074    Objective Loss 0.420074    Top1 85.515625    Top5 99.468750    LR 0.300000    Time 0.024153    
2018-11-02 21:19:30,418 - Epoch: [29][  100/  391]    Overall Loss 0.407547    Objective Loss 0.407547    Top1 85.859375    Top5 99.500000    LR 0.300000    Time 0.023550    
2018-11-02 21:19:31,566 - Epoch: [29][  150/  391]    Overall Loss 0.399170    Objective Loss 0.399170    Top1 86.218750    Top5 99.494792    LR 0.300000    Time 0.023339    
2018-11-02 21:19:32,722 - Epoch: [29][  200/  391]    Overall Loss 0.401598    Objective Loss 0.401598    Top1 86.121094    Top5 99.476562    LR 0.300000    Time 0.023281    
2018-11-02 21:19:33,874 - Epoch: [29][  250/  391]    Overall Loss 0.405417    Objective Loss 0.405417    Top1 86.034375    Top5 99.462500    LR 0.300000    Time 0.023227    
2018-11-02 21:19:35,024 - Epoch: [29][  300/  391]    Overall Loss 0.407054    Objective Loss 0.407054    Top1 85.976562    Top5 99.450521    LR 0.300000    Time 0.023184    
2018-11-02 21:19:36,171 - Epoch: [29][  350/  391]    Overall Loss 0.405368    Objective Loss 0.405368    Top1 85.955357    Top5 99.448661    LR 0.300000    Time 0.023143    
2018-11-02 21:19:37,191 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56299 | -0.00071 |    0.36565 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15466 |  0.00166 |    0.09423 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15454 | -0.00434 |    0.10587 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19180 | -0.01127 |    0.13597 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19111 | -0.01462 |    0.13930 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19227 | -0.02855 |    0.14010 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16867 |  0.00059 |    0.12142 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20857 | -0.00745 |    0.15291 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17627 | -0.00492 |    0.13544 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39798 | -0.02295 |    0.28737 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15473 | -0.01267 |    0.11860 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.00892 |    0.10703 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15212 | -0.02466 |    0.12038 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12285 | -0.00083 |    0.09638 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15138 | -0.01546 |    0.12051 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13555 | -0.01190 |    0.10688 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21331 | -0.02363 |    0.16755 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13255 | -0.01365 |    0.10429 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09732 | -0.00021 |    0.07345 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05816 | -0.00166 |    0.04355 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04740 | -0.00739 |    0.03482 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60213 | -0.00013 |    0.47056 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:19:37,191 - Total sparsity: 0.00

2018-11-02 21:19:37,191 - --- validate (epoch=29)-----------
2018-11-02 21:19:37,191 - 10000 samples (128 per mini-batch)
2018-11-02 21:19:37,923 - Epoch: [29][   50/   78]    Loss 0.514717    Top1 83.062500    Top5 99.015625    
2018-11-02 21:19:38,324 - ==> Top1: 82.480    Top5: 99.120    Loss: 0.525

2018-11-02 21:19:38,325 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 21:19:38,325 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:19:38,336 - 

2018-11-02 21:19:38,336 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:19:39,545 - Epoch: [30][   50/  391]    Overall Loss 0.381935    Objective Loss 0.381935    Top1 87.187500    Top5 99.484375    LR 0.300000    Time 0.024129    
2018-11-02 21:19:40,695 - Epoch: [30][  100/  391]    Overall Loss 0.392877    Objective Loss 0.392877    Top1 86.460938    Top5 99.460938    LR 0.300000    Time 0.023552    
2018-11-02 21:19:41,835 - Epoch: [30][  150/  391]    Overall Loss 0.397810    Objective Loss 0.397810    Top1 86.291667    Top5 99.505208    LR 0.300000    Time 0.023290    
2018-11-02 21:19:42,974 - Epoch: [30][  200/  391]    Overall Loss 0.400091    Objective Loss 0.400091    Top1 86.234375    Top5 99.527344    LR 0.300000    Time 0.023155    
2018-11-02 21:19:44,112 - Epoch: [30][  250/  391]    Overall Loss 0.403560    Objective Loss 0.403560    Top1 86.131250    Top5 99.493750    LR 0.300000    Time 0.023073    
2018-11-02 21:19:45,293 - Epoch: [30][  300/  391]    Overall Loss 0.403603    Objective Loss 0.403603    Top1 86.200521    Top5 99.473958    LR 0.300000    Time 0.023148    
2018-11-02 21:19:46,434 - Epoch: [30][  350/  391]    Overall Loss 0.406001    Objective Loss 0.406001    Top1 86.102679    Top5 99.466518    LR 0.300000    Time 0.023096    
2018-11-02 21:19:47,465 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56802 |  0.00096 |    0.36972 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15502 |  0.00082 |    0.09419 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15507 | -0.00204 |    0.10514 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19290 | -0.01663 |    0.13648 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19087 | -0.01211 |    0.13968 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19325 | -0.02811 |    0.14141 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16957 |  0.00180 |    0.12124 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20824 | -0.00736 |    0.15282 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17581 | -0.00609 |    0.13547 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39804 | -0.02685 |    0.28754 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15421 | -0.01126 |    0.11805 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13555 | -0.00803 |    0.10655 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15151 | -0.02543 |    0.12036 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12246 | -0.00040 |    0.09606 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15146 | -0.01562 |    0.12065 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13565 | -0.01184 |    0.10691 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21236 | -0.02408 |    0.16562 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13287 | -0.01336 |    0.10446 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09757 | -0.00066 |    0.07364 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05913 | -0.00205 |    0.04429 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04797 | -0.00727 |    0.03526 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60599 | -0.00011 |    0.47192 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:19:47,466 - Total sparsity: 0.00

2018-11-02 21:19:47,466 - --- validate (epoch=30)-----------
2018-11-02 21:19:47,466 - 10000 samples (128 per mini-batch)
2018-11-02 21:19:48,203 - Epoch: [30][   50/   78]    Loss 0.962153    Top1 73.031250    Top5 98.296875    
2018-11-02 21:19:48,604 - ==> Top1: 72.530    Top5: 98.200    Loss: 0.975

2018-11-02 21:19:48,604 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 21:19:48,605 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:19:48,613 - 

2018-11-02 21:19:48,613 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:19:49,814 - Epoch: [31][   50/  391]    Overall Loss 0.402150    Objective Loss 0.402150    Top1 85.593750    Top5 99.562500    LR 0.300000    Time 0.023971    
2018-11-02 21:19:50,961 - Epoch: [31][  100/  391]    Overall Loss 0.416433    Objective Loss 0.416433    Top1 85.429688    Top5 99.500000    LR 0.300000    Time 0.023444    
2018-11-02 21:19:52,101 - Epoch: [31][  150/  391]    Overall Loss 0.412316    Objective Loss 0.412316    Top1 85.536458    Top5 99.520833    LR 0.300000    Time 0.023223    
2018-11-02 21:19:53,241 - Epoch: [31][  200/  391]    Overall Loss 0.407614    Objective Loss 0.407614    Top1 85.847656    Top5 99.507812    LR 0.300000    Time 0.023110    
2018-11-02 21:19:54,384 - Epoch: [31][  250/  391]    Overall Loss 0.409778    Objective Loss 0.409778    Top1 85.734375    Top5 99.487500    LR 0.300000    Time 0.023055    
2018-11-02 21:19:55,528 - Epoch: [31][  300/  391]    Overall Loss 0.410372    Objective Loss 0.410372    Top1 85.760417    Top5 99.486979    LR 0.300000    Time 0.023019    
2018-11-02 21:19:56,677 - Epoch: [31][  350/  391]    Overall Loss 0.405058    Objective Loss 0.405058    Top1 85.984375    Top5 99.495536    LR 0.300000    Time 0.023012    
2018-11-02 21:19:57,697 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56883 | -0.00199 |    0.37146 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15442 |  0.00229 |    0.09356 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15591 | -0.00404 |    0.10635 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19401 | -0.01632 |    0.13700 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19136 | -0.01423 |    0.14094 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19421 | -0.02947 |    0.14194 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17046 |  0.00044 |    0.12188 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20782 | -0.00743 |    0.15244 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17592 | -0.00522 |    0.13529 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39851 | -0.02515 |    0.28525 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15420 | -0.01130 |    0.11824 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13573 | -0.01037 |    0.10660 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15229 | -0.02556 |    0.12095 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12275 | -0.00027 |    0.09601 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15184 | -0.01457 |    0.12064 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13611 | -0.01165 |    0.10732 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21259 | -0.02472 |    0.16531 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13328 | -0.01376 |    0.10482 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09767 | -0.00077 |    0.07373 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05960 | -0.00212 |    0.04473 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04829 | -0.00760 |    0.03552 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60139 | -0.00010 |    0.46912 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:19:57,697 - Total sparsity: 0.00

2018-11-02 21:19:57,697 - --- validate (epoch=31)-----------
2018-11-02 21:19:57,697 - 10000 samples (128 per mini-batch)
2018-11-02 21:19:58,429 - Epoch: [31][   50/   78]    Loss 0.700790    Top1 78.406250    Top5 98.921875    
2018-11-02 21:19:58,818 - ==> Top1: 78.070    Top5: 99.090    Loss: 0.697

2018-11-02 21:19:58,818 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 21:19:58,819 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:19:58,827 - 

2018-11-02 21:19:58,827 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:20:00,035 - Epoch: [32][   50/  391]    Overall Loss 0.390838    Objective Loss 0.390838    Top1 86.765625    Top5 99.484375    LR 0.300000    Time 0.024116    
2018-11-02 21:20:01,179 - Epoch: [32][  100/  391]    Overall Loss 0.398318    Objective Loss 0.398318    Top1 86.328125    Top5 99.507812    LR 0.300000    Time 0.023487    
2018-11-02 21:20:02,333 - Epoch: [32][  150/  391]    Overall Loss 0.402769    Objective Loss 0.402769    Top1 86.125000    Top5 99.463542    LR 0.300000    Time 0.023340    
2018-11-02 21:20:03,497 - Epoch: [32][  200/  391]    Overall Loss 0.409901    Objective Loss 0.409901    Top1 85.906250    Top5 99.441406    LR 0.300000    Time 0.023321    
2018-11-02 21:20:04,640 - Epoch: [32][  250/  391]    Overall Loss 0.406954    Objective Loss 0.406954    Top1 86.115625    Top5 99.478125    LR 0.300000    Time 0.023221    
2018-11-02 21:20:05,784 - Epoch: [32][  300/  391]    Overall Loss 0.405631    Objective Loss 0.405631    Top1 86.138021    Top5 99.479167    LR 0.300000    Time 0.023158    
2018-11-02 21:20:06,932 - Epoch: [32][  350/  391]    Overall Loss 0.408432    Objective Loss 0.408432    Top1 86.013393    Top5 99.479911    LR 0.300000    Time 0.023127    
2018-11-02 21:20:07,955 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57035 |  0.00419 |    0.37368 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15313 |  0.00144 |    0.09339 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15507 | -0.00346 |    0.10643 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19361 | -0.01678 |    0.13659 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19109 | -0.01378 |    0.14062 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19336 | -0.03119 |    0.14225 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17029 |  0.00236 |    0.12176 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20856 | -0.00592 |    0.15278 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17672 | -0.00363 |    0.13598 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39740 | -0.02309 |    0.28226 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15383 | -0.00943 |    0.11765 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13518 | -0.01129 |    0.10603 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15302 | -0.02401 |    0.12102 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12330 | -0.00144 |    0.09635 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15200 | -0.01456 |    0.12077 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13650 | -0.01147 |    0.10761 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21242 | -0.02465 |    0.16591 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13368 | -0.01364 |    0.10513 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09797 | -0.00052 |    0.07393 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06010 | -0.00166 |    0.04506 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04874 | -0.00752 |    0.03589 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60341 | -0.00009 |    0.47012 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:20:07,955 - Total sparsity: 0.00

2018-11-02 21:20:07,955 - --- validate (epoch=32)-----------
2018-11-02 21:20:07,955 - 10000 samples (128 per mini-batch)
2018-11-02 21:20:08,703 - Epoch: [32][   50/   78]    Loss 0.598514    Top1 81.046875    Top5 98.703125    
2018-11-02 21:20:09,111 - ==> Top1: 80.870    Top5: 98.760    Loss: 0.598

2018-11-02 21:20:09,112 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 21:20:09,112 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:20:09,123 - 

2018-11-02 21:20:09,124 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:20:10,322 - Epoch: [33][   50/  391]    Overall Loss 0.366076    Objective Loss 0.366076    Top1 87.109375    Top5 99.609375    LR 0.300000    Time 0.023929    
2018-11-02 21:20:11,466 - Epoch: [33][  100/  391]    Overall Loss 0.380934    Objective Loss 0.380934    Top1 86.687500    Top5 99.546875    LR 0.300000    Time 0.023391    
2018-11-02 21:20:12,617 - Epoch: [33][  150/  391]    Overall Loss 0.390445    Objective Loss 0.390445    Top1 86.541667    Top5 99.526042    LR 0.300000    Time 0.023257    
2018-11-02 21:20:13,787 - Epoch: [33][  200/  391]    Overall Loss 0.392527    Objective Loss 0.392527    Top1 86.488281    Top5 99.500000    LR 0.300000    Time 0.023284    
2018-11-02 21:20:14,928 - Epoch: [33][  250/  391]    Overall Loss 0.389035    Objective Loss 0.389035    Top1 86.603125    Top5 99.518750    LR 0.300000    Time 0.023185    
2018-11-02 21:20:16,076 - Epoch: [33][  300/  391]    Overall Loss 0.394350    Objective Loss 0.394350    Top1 86.377604    Top5 99.494792    LR 0.300000    Time 0.023144    
2018-11-02 21:20:17,221 - Epoch: [33][  350/  391]    Overall Loss 0.393709    Objective Loss 0.393709    Top1 86.401786    Top5 99.491071    LR 0.300000    Time 0.023103    
2018-11-02 21:20:18,241 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57201 | -0.01466 |    0.37845 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15310 |  0.00253 |    0.09360 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15397 | -0.00588 |    0.10614 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19363 | -0.01765 |    0.13763 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19121 | -0.01466 |    0.14168 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19406 | -0.02881 |    0.14153 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17147 |  0.00122 |    0.12227 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20813 | -0.00531 |    0.15270 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17628 | -0.00631 |    0.13550 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39574 | -0.02289 |    0.28436 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15354 | -0.00917 |    0.11786 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13536 | -0.01036 |    0.10637 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15278 | -0.02470 |    0.12125 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12305 | -0.00091 |    0.09595 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15207 | -0.01470 |    0.12074 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13675 | -0.01135 |    0.10773 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21151 | -0.02332 |    0.16461 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13347 | -0.01408 |    0.10508 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09782 | -0.00050 |    0.07393 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06041 | -0.00257 |    0.04535 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04879 | -0.00690 |    0.03575 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60438 | -0.00008 |    0.47149 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:20:18,242 - Total sparsity: 0.00

2018-11-02 21:20:18,242 - --- validate (epoch=33)-----------
2018-11-02 21:20:18,242 - 10000 samples (128 per mini-batch)
2018-11-02 21:20:18,969 - Epoch: [33][   50/   78]    Loss 0.703675    Top1 79.359375    Top5 98.812500    
2018-11-02 21:20:19,362 - ==> Top1: 78.780    Top5: 98.950    Loss: 0.717

2018-11-02 21:20:19,363 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 21:20:19,363 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:20:19,375 - 

2018-11-02 21:20:19,375 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:20:20,579 - Epoch: [34][   50/  391]    Overall Loss 0.382364    Objective Loss 0.382364    Top1 86.765625    Top5 99.625000    LR 0.300000    Time 0.024049    
2018-11-02 21:20:21,727 - Epoch: [34][  100/  391]    Overall Loss 0.392413    Objective Loss 0.392413    Top1 86.492188    Top5 99.421875    LR 0.300000    Time 0.023487    
2018-11-02 21:20:22,878 - Epoch: [34][  150/  391]    Overall Loss 0.393584    Objective Loss 0.393584    Top1 86.520833    Top5 99.380208    LR 0.300000    Time 0.023326    
2018-11-02 21:20:24,021 - Epoch: [34][  200/  391]    Overall Loss 0.392822    Objective Loss 0.392822    Top1 86.562500    Top5 99.421875    LR 0.300000    Time 0.023200    
2018-11-02 21:20:25,181 - Epoch: [34][  250/  391]    Overall Loss 0.394373    Objective Loss 0.394373    Top1 86.446875    Top5 99.421875    LR 0.300000    Time 0.023194    
2018-11-02 21:20:26,331 - Epoch: [34][  300/  391]    Overall Loss 0.395311    Objective Loss 0.395311    Top1 86.421875    Top5 99.421875    LR 0.300000    Time 0.023157    
2018-11-02 21:20:27,475 - Epoch: [34][  350/  391]    Overall Loss 0.394406    Objective Loss 0.394406    Top1 86.482143    Top5 99.419643    LR 0.300000    Time 0.023114    
2018-11-02 21:20:28,501 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57437 |  0.00190 |    0.37698 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15522 |  0.00137 |    0.09392 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15457 | -0.00124 |    0.10649 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19256 | -0.01482 |    0.13676 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19189 | -0.01424 |    0.14262 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19355 | -0.02655 |    0.14089 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17127 | -0.00031 |    0.12206 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20814 | -0.00504 |    0.15265 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17668 | -0.00450 |    0.13579 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39612 | -0.01742 |    0.28336 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15433 | -0.01113 |    0.11839 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13621 | -0.01051 |    0.10702 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15299 | -0.02269 |    0.12102 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12318 | -0.00128 |    0.09630 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15210 | -0.01504 |    0.12088 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13699 | -0.01127 |    0.10805 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21306 | -0.02368 |    0.16662 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13398 | -0.01376 |    0.10545 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09812 | -0.00095 |    0.07421 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06110 | -0.00198 |    0.04575 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04923 | -0.00666 |    0.03616 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60354 | -0.00007 |    0.47076 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:20:28,501 - Total sparsity: 0.00

2018-11-02 21:20:28,501 - --- validate (epoch=34)-----------
2018-11-02 21:20:28,501 - 10000 samples (128 per mini-batch)
2018-11-02 21:20:29,231 - Epoch: [34][   50/   78]    Loss 0.765296    Top1 77.546875    Top5 98.937500    
2018-11-02 21:20:29,624 - ==> Top1: 77.460    Top5: 99.030    Loss: 0.775

2018-11-02 21:20:29,624 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 21:20:29,625 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:20:29,633 - 

2018-11-02 21:20:29,633 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:20:30,837 - Epoch: [35][   50/  391]    Overall Loss 0.371675    Objective Loss 0.371675    Top1 86.921875    Top5 99.656250    LR 0.300000    Time 0.024034    
2018-11-02 21:20:31,982 - Epoch: [35][  100/  391]    Overall Loss 0.376777    Objective Loss 0.376777    Top1 86.812500    Top5 99.601562    LR 0.300000    Time 0.023450    
2018-11-02 21:20:33,130 - Epoch: [35][  150/  391]    Overall Loss 0.379723    Objective Loss 0.379723    Top1 86.656250    Top5 99.609375    LR 0.300000    Time 0.023277    
2018-11-02 21:20:34,273 - Epoch: [35][  200/  391]    Overall Loss 0.387552    Objective Loss 0.387552    Top1 86.492188    Top5 99.570312    LR 0.300000    Time 0.023166    
2018-11-02 21:20:35,420 - Epoch: [35][  250/  391]    Overall Loss 0.389706    Objective Loss 0.389706    Top1 86.431250    Top5 99.553125    LR 0.300000    Time 0.023115    
2018-11-02 21:20:36,576 - Epoch: [35][  300/  391]    Overall Loss 0.392868    Objective Loss 0.392868    Top1 86.408854    Top5 99.531250    LR 0.300000    Time 0.023112    
2018-11-02 21:20:37,725 - Epoch: [35][  350/  391]    Overall Loss 0.396108    Objective Loss 0.396108    Top1 86.314732    Top5 99.508929    LR 0.300000    Time 0.023089    
2018-11-02 21:20:38,749 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57221 | -0.01228 |    0.37818 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15586 |  0.00120 |    0.09524 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15561 | -0.00139 |    0.10756 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19364 | -0.01632 |    0.13831 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19143 | -0.01260 |    0.14146 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19368 | -0.02816 |    0.14175 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17117 |  0.00001 |    0.12170 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20815 | -0.00575 |    0.15275 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17705 | -0.00475 |    0.13596 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39603 | -0.01758 |    0.28404 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15386 | -0.01129 |    0.11806 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13581 | -0.01025 |    0.10619 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15226 | -0.02330 |    0.12019 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12301 | -0.00023 |    0.09599 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15228 | -0.01490 |    0.12081 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13731 | -0.01187 |    0.10833 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21422 | -0.02378 |    0.16770 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13456 | -0.01313 |    0.10598 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09848 | -0.00091 |    0.07431 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06160 | -0.00293 |    0.04635 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04950 | -0.00710 |    0.03643 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59911 | -0.00006 |    0.46704 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:20:38,749 - Total sparsity: 0.00

2018-11-02 21:20:38,749 - --- validate (epoch=35)-----------
2018-11-02 21:20:38,749 - 10000 samples (128 per mini-batch)
2018-11-02 21:20:39,486 - Epoch: [35][   50/   78]    Loss 0.584947    Top1 80.468750    Top5 99.125000    
2018-11-02 21:20:39,878 - ==> Top1: 80.750    Top5: 99.180    Loss: 0.582

2018-11-02 21:20:39,879 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 21:20:39,879 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:20:39,888 - 

2018-11-02 21:20:39,888 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:20:41,102 - Epoch: [36][   50/  391]    Overall Loss 0.381908    Objective Loss 0.381908    Top1 86.968750    Top5 99.578125    LR 0.300000    Time 0.024243    
2018-11-02 21:20:42,252 - Epoch: [36][  100/  391]    Overall Loss 0.383460    Objective Loss 0.383460    Top1 87.070312    Top5 99.507812    LR 0.300000    Time 0.023605    
2018-11-02 21:20:43,399 - Epoch: [36][  150/  391]    Overall Loss 0.382355    Objective Loss 0.382355    Top1 87.109375    Top5 99.505208    LR 0.300000    Time 0.023374    
2018-11-02 21:20:44,554 - Epoch: [36][  200/  391]    Overall Loss 0.385280    Objective Loss 0.385280    Top1 86.914062    Top5 99.519531    LR 0.300000    Time 0.023300    
2018-11-02 21:20:45,708 - Epoch: [36][  250/  391]    Overall Loss 0.388177    Objective Loss 0.388177    Top1 86.871875    Top5 99.471875    LR 0.300000    Time 0.023251    
2018-11-02 21:20:46,855 - Epoch: [36][  300/  391]    Overall Loss 0.390870    Objective Loss 0.390870    Top1 86.661458    Top5 99.486979    LR 0.300000    Time 0.023182    
2018-11-02 21:20:48,008 - Epoch: [36][  350/  391]    Overall Loss 0.393173    Objective Loss 0.393173    Top1 86.540179    Top5 99.493304    LR 0.300000    Time 0.023159    
2018-11-02 21:20:49,034 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57051 | -0.00490 |    0.37519 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15476 |  0.00286 |    0.09442 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15459 | -0.00175 |    0.10571 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19316 | -0.01221 |    0.13701 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19046 | -0.01325 |    0.14130 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19311 | -0.02961 |    0.14095 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17138 | -0.00269 |    0.12192 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20820 | -0.00655 |    0.15228 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17713 | -0.00486 |    0.13670 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39493 | -0.01528 |    0.28281 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15333 | -0.01052 |    0.11787 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13540 | -0.00962 |    0.10625 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15208 | -0.02387 |    0.12002 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12309 | -0.00027 |    0.09642 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15178 | -0.01430 |    0.12035 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13686 | -0.01192 |    0.10804 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21319 | -0.02403 |    0.16671 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13447 | -0.01363 |    0.10579 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09873 | -0.00104 |    0.07470 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06224 | -0.00186 |    0.04677 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05003 | -0.00665 |    0.03653 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60330 | -0.00006 |    0.46832 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:20:49,034 - Total sparsity: 0.00

2018-11-02 21:20:49,034 - --- validate (epoch=36)-----------
2018-11-02 21:20:49,034 - 10000 samples (128 per mini-batch)
2018-11-02 21:20:49,756 - Epoch: [36][   50/   78]    Loss 0.638649    Top1 80.640625    Top5 98.703125    
2018-11-02 21:20:50,153 - ==> Top1: 80.520    Top5: 98.850    Loss: 0.643

2018-11-02 21:20:50,154 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 21:20:50,154 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:20:50,163 - 

2018-11-02 21:20:50,163 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:20:51,375 - Epoch: [37][   50/  391]    Overall Loss 0.386654    Objective Loss 0.386654    Top1 86.718750    Top5 99.500000    LR 0.300000    Time 0.024198    
2018-11-02 21:20:52,519 - Epoch: [37][  100/  391]    Overall Loss 0.391948    Objective Loss 0.391948    Top1 86.281250    Top5 99.523438    LR 0.300000    Time 0.023531    
2018-11-02 21:20:53,659 - Epoch: [37][  150/  391]    Overall Loss 0.394762    Objective Loss 0.394762    Top1 86.307292    Top5 99.552083    LR 0.300000    Time 0.023279    
2018-11-02 21:20:54,824 - Epoch: [37][  200/  391]    Overall Loss 0.397692    Objective Loss 0.397692    Top1 86.179688    Top5 99.562500    LR 0.300000    Time 0.023277    
2018-11-02 21:20:55,990 - Epoch: [37][  250/  391]    Overall Loss 0.395309    Objective Loss 0.395309    Top1 86.275000    Top5 99.571875    LR 0.300000    Time 0.023280    
2018-11-02 21:20:57,137 - Epoch: [37][  300/  391]    Overall Loss 0.395639    Objective Loss 0.395639    Top1 86.286458    Top5 99.520833    LR 0.300000    Time 0.023216    
2018-11-02 21:20:58,277 - Epoch: [37][  350/  391]    Overall Loss 0.390825    Objective Loss 0.390825    Top1 86.397321    Top5 99.526786    LR 0.300000    Time 0.023153    
2018-11-02 21:20:59,299 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57129 | -0.01010 |    0.37393 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15529 |  0.00043 |    0.09540 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15473 | -0.00511 |    0.10536 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19367 | -0.01462 |    0.13760 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19126 | -0.01200 |    0.14196 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19564 | -0.03049 |    0.14210 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17308 |  0.00023 |    0.12420 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20884 | -0.00562 |    0.15229 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17742 | -0.00566 |    0.13639 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39546 | -0.01447 |    0.28083 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15359 | -0.00978 |    0.11802 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13574 | -0.00975 |    0.10672 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15247 | -0.02374 |    0.12005 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12326 |  0.00001 |    0.09647 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15192 | -0.01547 |    0.12072 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13693 | -0.01170 |    0.10805 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21184 | -0.02565 |    0.16489 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13439 | -0.01343 |    0.10562 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09851 | -0.00124 |    0.07446 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06249 | -0.00171 |    0.04707 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04998 | -0.00657 |    0.03669 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60392 | -0.00005 |    0.46970 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:20:59,299 - Total sparsity: 0.00

2018-11-02 21:20:59,300 - --- validate (epoch=37)-----------
2018-11-02 21:20:59,300 - 10000 samples (128 per mini-batch)
2018-11-02 21:21:00,031 - Epoch: [37][   50/   78]    Loss 0.497753    Top1 84.187500    Top5 99.171875    
2018-11-02 21:21:00,433 - ==> Top1: 84.260    Top5: 99.300    Loss: 0.500

2018-11-02 21:21:00,434 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:21:00,434 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:21:00,449 - 

2018-11-02 21:21:00,449 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:21:01,628 - Epoch: [38][   50/  391]    Overall Loss 0.397983    Objective Loss 0.397983    Top1 86.406250    Top5 99.562500    LR 0.300000    Time 0.023530    
2018-11-02 21:21:02,781 - Epoch: [38][  100/  391]    Overall Loss 0.388733    Objective Loss 0.388733    Top1 86.898438    Top5 99.578125    LR 0.300000    Time 0.023278    
2018-11-02 21:21:03,933 - Epoch: [38][  150/  391]    Overall Loss 0.389110    Objective Loss 0.389110    Top1 86.869792    Top5 99.567708    LR 0.300000    Time 0.023189    
2018-11-02 21:21:05,083 - Epoch: [38][  200/  391]    Overall Loss 0.391187    Objective Loss 0.391187    Top1 86.652344    Top5 99.562500    LR 0.300000    Time 0.023135    
2018-11-02 21:21:06,250 - Epoch: [38][  250/  391]    Overall Loss 0.388206    Objective Loss 0.388206    Top1 86.721875    Top5 99.568750    LR 0.300000    Time 0.023169    
2018-11-02 21:21:07,422 - Epoch: [38][  300/  391]    Overall Loss 0.387472    Objective Loss 0.387472    Top1 86.739583    Top5 99.565104    LR 0.300000    Time 0.023210    
2018-11-02 21:21:08,610 - Epoch: [38][  350/  391]    Overall Loss 0.389868    Objective Loss 0.389868    Top1 86.613839    Top5 99.555804    LR 0.300000    Time 0.023284    
2018-11-02 21:21:09,630 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57448 |  0.00024 |    0.37410 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15565 |  0.00006 |    0.09618 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15506 | -0.00316 |    0.10618 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19355 | -0.01570 |    0.13769 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19166 | -0.01168 |    0.14240 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19684 | -0.02689 |    0.14312 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17388 |  0.00217 |    0.12384 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20838 | -0.00727 |    0.15252 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17704 | -0.00493 |    0.13602 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39669 | -0.01347 |    0.28242 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15379 | -0.01000 |    0.11862 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13581 | -0.00934 |    0.10659 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15209 | -0.02434 |    0.11968 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12323 | -0.00150 |    0.09630 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15208 | -0.01551 |    0.12123 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13687 | -0.01186 |    0.10788 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21300 | -0.02419 |    0.16592 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13443 | -0.01323 |    0.10585 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09854 | -0.00117 |    0.07445 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06314 | -0.00233 |    0.04758 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05036 | -0.00659 |    0.03705 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60145 | -0.00004 |    0.46797 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:21:09,630 - Total sparsity: 0.00

2018-11-02 21:21:09,630 - --- validate (epoch=38)-----------
2018-11-02 21:21:09,630 - 10000 samples (128 per mini-batch)
2018-11-02 21:21:10,370 - Epoch: [38][   50/   78]    Loss 0.666466    Top1 80.109375    Top5 98.656250    
2018-11-02 21:21:10,769 - ==> Top1: 80.020    Top5: 98.800    Loss: 0.652

2018-11-02 21:21:10,770 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:21:10,770 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:21:10,779 - 

2018-11-02 21:21:10,779 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:21:11,988 - Epoch: [39][   50/  391]    Overall Loss 0.383837    Objective Loss 0.383837    Top1 86.750000    Top5 99.687500    LR 0.300000    Time 0.024147    
2018-11-02 21:21:13,134 - Epoch: [39][  100/  391]    Overall Loss 0.391670    Objective Loss 0.391670    Top1 86.429688    Top5 99.523438    LR 0.300000    Time 0.023516    
2018-11-02 21:21:14,271 - Epoch: [39][  150/  391]    Overall Loss 0.392625    Objective Loss 0.392625    Top1 86.411458    Top5 99.505208    LR 0.300000    Time 0.023248    
2018-11-02 21:21:15,410 - Epoch: [39][  200/  391]    Overall Loss 0.396717    Objective Loss 0.396717    Top1 86.171875    Top5 99.488281    LR 0.300000    Time 0.023126    
2018-11-02 21:21:16,560 - Epoch: [39][  250/  391]    Overall Loss 0.392740    Objective Loss 0.392740    Top1 86.321875    Top5 99.509375    LR 0.300000    Time 0.023096    
2018-11-02 21:21:17,707 - Epoch: [39][  300/  391]    Overall Loss 0.392885    Objective Loss 0.392885    Top1 86.335938    Top5 99.502604    LR 0.300000    Time 0.023064    
2018-11-02 21:21:18,849 - Epoch: [39][  350/  391]    Overall Loss 0.396572    Objective Loss 0.396572    Top1 86.209821    Top5 99.491071    LR 0.300000    Time 0.023027    
2018-11-02 21:21:19,863 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57586 | -0.00231 |    0.37629 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15550 | -0.00043 |    0.09524 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15612 | -0.00284 |    0.10576 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19363 | -0.01922 |    0.13819 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19307 | -0.01191 |    0.14343 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19758 | -0.02916 |    0.14319 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17473 |  0.00089 |    0.12416 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20869 | -0.00565 |    0.15315 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17742 | -0.00541 |    0.13647 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39953 | -0.01929 |    0.28610 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15451 | -0.01017 |    0.11886 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13645 | -0.00903 |    0.10695 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15266 | -0.02395 |    0.12012 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12361 | -0.00047 |    0.09613 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15288 | -0.01479 |    0.12147 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13766 | -0.01187 |    0.10857 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21370 | -0.02638 |    0.16774 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13495 | -0.01322 |    0.10604 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09897 | -0.00101 |    0.07483 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06394 | -0.00270 |    0.04826 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05107 | -0.00682 |    0.03762 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60270 | -0.00004 |    0.46885 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:21:19,864 - Total sparsity: 0.00

2018-11-02 21:21:19,864 - --- validate (epoch=39)-----------
2018-11-02 21:21:19,864 - 10000 samples (128 per mini-batch)
2018-11-02 21:21:20,587 - Epoch: [39][   50/   78]    Loss 0.510502    Top1 83.500000    Top5 99.156250    
2018-11-02 21:21:20,983 - ==> Top1: 83.680    Top5: 99.300    Loss: 0.498

2018-11-02 21:21:20,984 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:21:20,984 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:21:20,992 - 

2018-11-02 21:21:20,992 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:21:22,191 - Epoch: [40][   50/  391]    Overall Loss 0.359594    Objective Loss 0.359594    Top1 87.703125    Top5 99.609375    LR 0.300000    Time 0.023941    
2018-11-02 21:21:23,337 - Epoch: [40][  100/  391]    Overall Loss 0.376621    Objective Loss 0.376621    Top1 87.062500    Top5 99.570312    LR 0.300000    Time 0.023419    
2018-11-02 21:21:24,480 - Epoch: [40][  150/  391]    Overall Loss 0.380616    Objective Loss 0.380616    Top1 86.848958    Top5 99.598958    LR 0.300000    Time 0.023223    
2018-11-02 21:21:25,626 - Epoch: [40][  200/  391]    Overall Loss 0.382799    Objective Loss 0.382799    Top1 86.792969    Top5 99.570312    LR 0.300000    Time 0.023139    
2018-11-02 21:21:26,771 - Epoch: [40][  250/  391]    Overall Loss 0.386505    Objective Loss 0.386505    Top1 86.681250    Top5 99.537500    LR 0.300000    Time 0.023084    
2018-11-02 21:21:27,912 - Epoch: [40][  300/  391]    Overall Loss 0.388464    Objective Loss 0.388464    Top1 86.591146    Top5 99.510417    LR 0.300000    Time 0.023037    
2018-11-02 21:21:29,054 - Epoch: [40][  350/  391]    Overall Loss 0.389417    Objective Loss 0.389417    Top1 86.562500    Top5 99.511161    LR 0.300000    Time 0.023006    
2018-11-02 21:21:30,073 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57914 | -0.00716 |    0.38283 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15572 | -0.00054 |    0.09513 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15605 | -0.00442 |    0.10622 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19404 | -0.01824 |    0.13733 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19343 | -0.01014 |    0.14370 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19694 | -0.03076 |    0.14253 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17379 |  0.00015 |    0.12390 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20963 | -0.00777 |    0.15381 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17784 | -0.00421 |    0.13665 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39772 | -0.01838 |    0.28802 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 | -0.01014 |    0.11895 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13686 | -0.01004 |    0.10730 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15283 | -0.02431 |    0.12027 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12351 | -0.00055 |    0.09615 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15289 | -0.01476 |    0.12185 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13771 | -0.01209 |    0.10867 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21410 | -0.02506 |    0.16844 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13527 | -0.01317 |    0.10624 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09909 | -0.00147 |    0.07476 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06418 | -0.00301 |    0.04852 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05129 | -0.00659 |    0.03772 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60034 | -0.00003 |    0.46704 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:21:30,073 - Total sparsity: 0.00

2018-11-02 21:21:30,073 - --- validate (epoch=40)-----------
2018-11-02 21:21:30,073 - 10000 samples (128 per mini-batch)
2018-11-02 21:21:30,811 - Epoch: [40][   50/   78]    Loss 0.608204    Top1 80.906250    Top5 99.062500    
2018-11-02 21:21:31,207 - ==> Top1: 80.890    Top5: 99.090    Loss: 0.617

2018-11-02 21:21:31,208 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:21:31,208 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:21:31,216 - 

2018-11-02 21:21:31,216 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:21:32,417 - Epoch: [41][   50/  391]    Overall Loss 0.385813    Objective Loss 0.385813    Top1 86.921875    Top5 99.531250    LR 0.300000    Time 0.023970    
2018-11-02 21:21:33,569 - Epoch: [41][  100/  391]    Overall Loss 0.391539    Objective Loss 0.391539    Top1 86.906250    Top5 99.531250    LR 0.300000    Time 0.023496    
2018-11-02 21:21:34,712 - Epoch: [41][  150/  391]    Overall Loss 0.384758    Objective Loss 0.384758    Top1 86.953125    Top5 99.541667    LR 0.300000    Time 0.023273    
2018-11-02 21:21:35,864 - Epoch: [41][  200/  391]    Overall Loss 0.387104    Objective Loss 0.387104    Top1 86.656250    Top5 99.554688    LR 0.300000    Time 0.023209    
2018-11-02 21:21:37,046 - Epoch: [41][  250/  391]    Overall Loss 0.386684    Objective Loss 0.386684    Top1 86.606250    Top5 99.550000    LR 0.300000    Time 0.023288    
2018-11-02 21:21:38,273 - Epoch: [41][  300/  391]    Overall Loss 0.391078    Objective Loss 0.391078    Top1 86.500000    Top5 99.523438    LR 0.300000    Time 0.023490    
2018-11-02 21:21:39,532 - Epoch: [41][  350/  391]    Overall Loss 0.389381    Objective Loss 0.389381    Top1 86.502232    Top5 99.508929    LR 0.300000    Time 0.023726    
2018-11-02 21:21:40,675 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57916 | -0.00482 |    0.38114 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.00169 |    0.09511 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15575 | -0.00359 |    0.10712 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19394 | -0.01556 |    0.13741 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19364 | -0.01149 |    0.14318 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19717 | -0.03201 |    0.14379 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17442 |  0.00155 |    0.12502 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21049 | -0.00742 |    0.15442 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17801 | -0.00586 |    0.13686 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39757 | -0.01891 |    0.28807 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15466 | -0.01055 |    0.11896 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13709 | -0.00925 |    0.10722 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15328 | -0.02264 |    0.12045 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12332 | -0.00227 |    0.09607 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15324 | -0.01404 |    0.12203 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13790 | -0.01214 |    0.10893 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21399 | -0.02593 |    0.16650 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13558 | -0.01358 |    0.10666 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09929 | -0.00141 |    0.07498 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06483 | -0.00275 |    0.04894 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05165 | -0.00651 |    0.03791 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60362 | -0.00003 |    0.46881 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:21:40,675 - Total sparsity: 0.00

2018-11-02 21:21:40,675 - --- validate (epoch=41)-----------
2018-11-02 21:21:40,675 - 10000 samples (128 per mini-batch)
2018-11-02 21:21:41,594 - Epoch: [41][   50/   78]    Loss 0.591298    Top1 80.515625    Top5 99.062500    
2018-11-02 21:21:42,148 - ==> Top1: 79.930    Top5: 99.150    Loss: 0.599

2018-11-02 21:21:42,149 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:21:42,149 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:21:42,159 - 

2018-11-02 21:21:42,159 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:21:43,493 - Epoch: [42][   50/  391]    Overall Loss 0.372359    Objective Loss 0.372359    Top1 87.203125    Top5 99.500000    LR 0.300000    Time 0.026639    
2018-11-02 21:21:44,750 - Epoch: [42][  100/  391]    Overall Loss 0.387696    Objective Loss 0.387696    Top1 86.695312    Top5 99.476562    LR 0.300000    Time 0.025876    
2018-11-02 21:21:46,015 - Epoch: [42][  150/  391]    Overall Loss 0.386491    Objective Loss 0.386491    Top1 86.692708    Top5 99.468750    LR 0.300000    Time 0.025672    
2018-11-02 21:21:47,270 - Epoch: [42][  200/  391]    Overall Loss 0.390770    Objective Loss 0.390770    Top1 86.535156    Top5 99.472656    LR 0.300000    Time 0.025517    
2018-11-02 21:21:48,528 - Epoch: [42][  250/  391]    Overall Loss 0.387877    Objective Loss 0.387877    Top1 86.775000    Top5 99.465625    LR 0.300000    Time 0.025440    
2018-11-02 21:21:49,778 - Epoch: [42][  300/  391]    Overall Loss 0.382643    Objective Loss 0.382643    Top1 86.924479    Top5 99.505208    LR 0.300000    Time 0.025362    
2018-11-02 21:21:51,057 - Epoch: [42][  350/  391]    Overall Loss 0.386288    Objective Loss 0.386288    Top1 86.810268    Top5 99.482143    LR 0.300000    Time 0.025389    
2018-11-02 21:21:52,185 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57800 | -0.00452 |    0.38257 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15433 | -0.00161 |    0.09481 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15470 | -0.00379 |    0.10585 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19418 | -0.01716 |    0.13734 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19384 | -0.01374 |    0.14393 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19718 | -0.03035 |    0.14398 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17421 | -0.00081 |    0.12530 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21041 | -0.00777 |    0.15386 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17821 | -0.00479 |    0.13689 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39769 | -0.01766 |    0.28687 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15406 | -0.01070 |    0.11888 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13596 | -0.01004 |    0.10654 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15274 | -0.02208 |    0.12012 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12310 | -0.00198 |    0.09566 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15337 | -0.01426 |    0.12192 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13796 | -0.01140 |    0.10874 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21366 | -0.02475 |    0.16664 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13564 | -0.01364 |    0.10681 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09945 | -0.00133 |    0.07509 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06550 | -0.00331 |    0.04944 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05211 | -0.00632 |    0.03829 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60314 | -0.00003 |    0.46886 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:21:52,185 - Total sparsity: 0.00

2018-11-02 21:21:52,185 - --- validate (epoch=42)-----------
2018-11-02 21:21:52,185 - 10000 samples (128 per mini-batch)
2018-11-02 21:21:53,025 - Epoch: [42][   50/   78]    Loss 0.623701    Top1 79.843750    Top5 99.015625    
2018-11-02 21:21:53,457 - ==> Top1: 79.800    Top5: 99.090    Loss: 0.620

2018-11-02 21:21:53,458 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:21:53,458 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:21:53,472 - 

2018-11-02 21:21:53,473 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:21:54,826 - Epoch: [43][   50/  391]    Overall Loss 0.361358    Objective Loss 0.361358    Top1 87.437500    Top5 99.546875    LR 0.300000    Time 0.027008    
2018-11-02 21:21:56,096 - Epoch: [43][  100/  391]    Overall Loss 0.367443    Objective Loss 0.367443    Top1 87.281250    Top5 99.554688    LR 0.300000    Time 0.026194    
2018-11-02 21:21:57,354 - Epoch: [43][  150/  391]    Overall Loss 0.372298    Objective Loss 0.372298    Top1 87.177083    Top5 99.552083    LR 0.300000    Time 0.025836    
2018-11-02 21:21:58,565 - Epoch: [43][  200/  391]    Overall Loss 0.371023    Objective Loss 0.371023    Top1 87.273438    Top5 99.542969    LR 0.300000    Time 0.025428    
2018-11-02 21:21:59,819 - Epoch: [43][  250/  391]    Overall Loss 0.373509    Objective Loss 0.373509    Top1 87.196875    Top5 99.540625    LR 0.300000    Time 0.025335    
2018-11-02 21:22:01,076 - Epoch: [43][  300/  391]    Overall Loss 0.378883    Objective Loss 0.378883    Top1 86.950521    Top5 99.536458    LR 0.300000    Time 0.025300    
2018-11-02 21:22:02,335 - Epoch: [43][  350/  391]    Overall Loss 0.381268    Objective Loss 0.381268    Top1 86.837054    Top5 99.520089    LR 0.300000    Time 0.025277    
2018-11-02 21:22:03,481 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57602 | -0.00250 |    0.37617 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15451 |  0.00070 |    0.09396 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15470 | -0.00603 |    0.10547 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19365 | -0.01487 |    0.13705 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19299 | -0.01080 |    0.14332 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19714 | -0.02908 |    0.14336 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17408 |  0.00020 |    0.12448 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20987 | -0.00616 |    0.15365 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17834 | -0.00440 |    0.13723 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39654 | -0.01830 |    0.28515 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15437 | -0.00816 |    0.11929 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13598 | -0.01037 |    0.10679 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15277 | -0.02285 |    0.12048 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12284 | -0.00132 |    0.09573 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.01411 |    0.12162 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13764 | -0.01162 |    0.10876 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21331 | -0.02612 |    0.16758 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13564 | -0.01360 |    0.10691 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09939 | -0.00145 |    0.07510 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06589 | -0.00320 |    0.04974 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05232 | -0.00567 |    0.03827 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60557 | -0.00002 |    0.47033 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:22:03,481 - Total sparsity: 0.00

2018-11-02 21:22:03,481 - --- validate (epoch=43)-----------
2018-11-02 21:22:03,482 - 10000 samples (128 per mini-batch)
2018-11-02 21:22:04,401 - Epoch: [43][   50/   78]    Loss 0.689158    Top1 78.437500    Top5 98.453125    
2018-11-02 21:22:04,873 - ==> Top1: 78.120    Top5: 98.640    Loss: 0.695

2018-11-02 21:22:04,874 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:22:04,875 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:22:04,884 - 

2018-11-02 21:22:04,884 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:22:06,175 - Epoch: [44][   50/  391]    Overall Loss 0.371445    Objective Loss 0.371445    Top1 87.125000    Top5 99.515625    LR 0.300000    Time 0.025757    
2018-11-02 21:22:07,369 - Epoch: [44][  100/  391]    Overall Loss 0.376731    Objective Loss 0.376731    Top1 86.859375    Top5 99.515625    LR 0.300000    Time 0.024809    
2018-11-02 21:22:08,513 - Epoch: [44][  150/  391]    Overall Loss 0.381376    Objective Loss 0.381376    Top1 86.723958    Top5 99.510417    LR 0.300000    Time 0.024154    
2018-11-02 21:22:09,660 - Epoch: [44][  200/  391]    Overall Loss 0.382487    Objective Loss 0.382487    Top1 86.742188    Top5 99.503906    LR 0.300000    Time 0.023841    
2018-11-02 21:22:10,842 - Epoch: [44][  250/  391]    Overall Loss 0.383288    Objective Loss 0.383288    Top1 86.715625    Top5 99.500000    LR 0.300000    Time 0.023780    
2018-11-02 21:22:12,029 - Epoch: [44][  300/  391]    Overall Loss 0.388891    Objective Loss 0.388891    Top1 86.557292    Top5 99.484375    LR 0.300000    Time 0.023771    
2018-11-02 21:22:13,228 - Epoch: [44][  350/  391]    Overall Loss 0.390324    Objective Loss 0.390324    Top1 86.502232    Top5 99.495536    LR 0.300000    Time 0.023796    
2018-11-02 21:22:14,246 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57293 |  0.00882 |    0.37848 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15479 | -0.00153 |    0.09500 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15584 | -0.00414 |    0.10723 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19354 | -0.02050 |    0.13728 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19270 | -0.01126 |    0.14233 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19647 | -0.03027 |    0.14300 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17507 |  0.00152 |    0.12640 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21078 | -0.00944 |    0.15487 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17885 | -0.00443 |    0.13757 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39775 | -0.01739 |    0.28346 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15503 | -0.01004 |    0.12002 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13652 | -0.01045 |    0.10702 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15267 | -0.02278 |    0.12066 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12264 | -0.00026 |    0.09554 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15355 | -0.01496 |    0.12217 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13807 | -0.01165 |    0.10930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21403 | -0.02531 |    0.16849 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13613 | -0.01371 |    0.10727 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09991 | -0.00193 |    0.07545 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06632 | -0.00335 |    0.05004 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05257 | -0.00557 |    0.03848 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60092 | -0.00002 |    0.46661 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:22:14,246 - Total sparsity: 0.00

2018-11-02 21:22:14,246 - --- validate (epoch=44)-----------
2018-11-02 21:22:14,246 - 10000 samples (128 per mini-batch)
2018-11-02 21:22:15,014 - Epoch: [44][   50/   78]    Loss 0.553985    Top1 83.015625    Top5 99.031250    
2018-11-02 21:22:15,404 - ==> Top1: 83.040    Top5: 99.070    Loss: 0.537

2018-11-02 21:22:15,405 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:22:15,405 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:22:15,412 - 

2018-11-02 21:22:15,412 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:22:16,609 - Epoch: [45][   50/  391]    Overall Loss 0.392768    Objective Loss 0.392768    Top1 86.343750    Top5 99.421875    LR 0.300000    Time 0.023888    
2018-11-02 21:22:17,790 - Epoch: [45][  100/  391]    Overall Loss 0.379527    Objective Loss 0.379527    Top1 86.906250    Top5 99.492188    LR 0.300000    Time 0.023740    
2018-11-02 21:22:18,929 - Epoch: [45][  150/  391]    Overall Loss 0.376538    Objective Loss 0.376538    Top1 87.171875    Top5 99.526042    LR 0.300000    Time 0.023413    
2018-11-02 21:22:20,075 - Epoch: [45][  200/  391]    Overall Loss 0.379741    Objective Loss 0.379741    Top1 86.960938    Top5 99.511719    LR 0.300000    Time 0.023284    
2018-11-02 21:22:21,235 - Epoch: [45][  250/  391]    Overall Loss 0.380488    Objective Loss 0.380488    Top1 86.796875    Top5 99.500000    LR 0.300000    Time 0.023263    
2018-11-02 21:22:22,380 - Epoch: [45][  300/  391]    Overall Loss 0.380243    Objective Loss 0.380243    Top1 86.817708    Top5 99.494792    LR 0.300000    Time 0.023196    
2018-11-02 21:22:23,530 - Epoch: [45][  350/  391]    Overall Loss 0.380104    Objective Loss 0.380104    Top1 86.828125    Top5 99.502232    LR 0.300000    Time 0.023163    
2018-11-02 21:22:24,552 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57586 |  0.00615 |    0.37847 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15523 | -0.00203 |    0.09484 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15612 | -0.00416 |    0.10770 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19395 | -0.01733 |    0.13784 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19250 | -0.01031 |    0.14256 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19596 | -0.02895 |    0.14301 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17466 |  0.00120 |    0.12579 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21133 | -0.00729 |    0.15555 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17910 | -0.00572 |    0.13799 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39339 | -0.01843 |    0.28362 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15494 | -0.00945 |    0.11938 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13634 | -0.01127 |    0.10696 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15211 | -0.02190 |    0.12005 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12218 | -0.00076 |    0.09536 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15340 | -0.01617 |    0.12218 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13802 | -0.01191 |    0.10932 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21253 | -0.02463 |    0.16768 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13592 | -0.01399 |    0.10717 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10005 | -0.00213 |    0.07578 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06687 | -0.00338 |    0.05041 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05268 | -0.00593 |    0.03862 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59779 | -0.00002 |    0.46684 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:22:24,552 - Total sparsity: 0.00

2018-11-02 21:22:24,552 - --- validate (epoch=45)-----------
2018-11-02 21:22:24,552 - 10000 samples (128 per mini-batch)
2018-11-02 21:22:25,316 - Epoch: [45][   50/   78]    Loss 0.530940    Top1 82.296875    Top5 99.062500    
2018-11-02 21:22:25,715 - ==> Top1: 82.370    Top5: 99.130    Loss: 0.538

2018-11-02 21:22:25,716 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:22:25,716 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:22:25,727 - 

2018-11-02 21:22:25,728 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:22:26,933 - Epoch: [46][   50/  391]    Overall Loss 0.350981    Objective Loss 0.350981    Top1 87.718750    Top5 99.640625    LR 0.300000    Time 0.024065    
2018-11-02 21:22:28,083 - Epoch: [46][  100/  391]    Overall Loss 0.366063    Objective Loss 0.366063    Top1 87.187500    Top5 99.601562    LR 0.300000    Time 0.023521    
2018-11-02 21:22:29,228 - Epoch: [46][  150/  391]    Overall Loss 0.366871    Objective Loss 0.366871    Top1 87.057292    Top5 99.593750    LR 0.300000    Time 0.023300    
2018-11-02 21:22:30,370 - Epoch: [46][  200/  391]    Overall Loss 0.373296    Objective Loss 0.373296    Top1 86.902344    Top5 99.578125    LR 0.300000    Time 0.023182    
2018-11-02 21:22:31,516 - Epoch: [46][  250/  391]    Overall Loss 0.382082    Objective Loss 0.382082    Top1 86.618750    Top5 99.528125    LR 0.300000    Time 0.023122    
2018-11-02 21:22:32,654 - Epoch: [46][  300/  391]    Overall Loss 0.377572    Objective Loss 0.377572    Top1 86.763021    Top5 99.546875    LR 0.300000    Time 0.023058    
2018-11-02 21:22:33,792 - Epoch: [46][  350/  391]    Overall Loss 0.376213    Objective Loss 0.376213    Top1 86.892857    Top5 99.535714    LR 0.300000    Time 0.023010    
2018-11-02 21:22:34,805 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57228 | -0.00900 |    0.37768 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15423 |  0.00176 |    0.09424 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15498 | -0.00205 |    0.10704 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19481 | -0.01856 |    0.13817 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19285 | -0.01091 |    0.14247 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19646 | -0.03086 |    0.14434 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17495 | -0.00051 |    0.12631 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21168 | -0.00666 |    0.15506 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17936 | -0.00546 |    0.13828 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39207 | -0.01240 |    0.28110 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15500 | -0.01097 |    0.11942 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13622 | -0.00938 |    0.10661 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15278 | -0.02182 |    0.12026 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12217 | -0.00034 |    0.09464 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15345 | -0.01617 |    0.12210 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13829 | -0.01230 |    0.10939 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21305 | -0.02253 |    0.16791 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13631 | -0.01368 |    0.10720 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10041 | -0.00194 |    0.07586 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06763 | -0.00334 |    0.05097 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05318 | -0.00547 |    0.03893 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60135 | -0.00002 |    0.46864 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:22:34,805 - Total sparsity: 0.00

2018-11-02 21:22:34,805 - --- validate (epoch=46)-----------
2018-11-02 21:22:34,806 - 10000 samples (128 per mini-batch)
2018-11-02 21:22:35,533 - Epoch: [46][   50/   78]    Loss 0.875910    Top1 75.406250    Top5 98.156250    
2018-11-02 21:22:35,927 - ==> Top1: 75.310    Top5: 98.190    Loss: 0.881

2018-11-02 21:22:35,928 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:22:35,928 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:22:35,940 - 

2018-11-02 21:22:35,940 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:22:37,145 - Epoch: [47][   50/  391]    Overall Loss 0.388191    Objective Loss 0.388191    Top1 86.156250    Top5 99.484375    LR 0.300000    Time 0.024046    
2018-11-02 21:22:38,295 - Epoch: [47][  100/  391]    Overall Loss 0.395119    Objective Loss 0.395119    Top1 86.062500    Top5 99.476562    LR 0.300000    Time 0.023513    
2018-11-02 21:22:39,464 - Epoch: [47][  150/  391]    Overall Loss 0.387257    Objective Loss 0.387257    Top1 86.468750    Top5 99.494792    LR 0.300000    Time 0.023458    
2018-11-02 21:22:40,610 - Epoch: [47][  200/  391]    Overall Loss 0.387697    Objective Loss 0.387697    Top1 86.476562    Top5 99.492188    LR 0.300000    Time 0.023318    
2018-11-02 21:22:41,755 - Epoch: [47][  250/  391]    Overall Loss 0.387915    Objective Loss 0.387915    Top1 86.503125    Top5 99.493750    LR 0.300000    Time 0.023230    
2018-11-02 21:22:42,895 - Epoch: [47][  300/  391]    Overall Loss 0.385041    Objective Loss 0.385041    Top1 86.609375    Top5 99.505208    LR 0.300000    Time 0.023152    
2018-11-02 21:22:44,041 - Epoch: [47][  350/  391]    Overall Loss 0.385615    Objective Loss 0.385615    Top1 86.651786    Top5 99.495536    LR 0.300000    Time 0.023114    
2018-11-02 21:22:45,062 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57400 | -0.00680 |    0.38010 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 |  0.00047 |    0.09481 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15560 | -0.00201 |    0.10682 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19513 | -0.01835 |    0.13955 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19300 | -0.01199 |    0.14320 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19712 | -0.03126 |    0.14553 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17550 |  0.00033 |    0.12655 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21127 | -0.00486 |    0.15510 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17872 | -0.00536 |    0.13760 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39081 | -0.01206 |    0.27989 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15495 | -0.01048 |    0.11939 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13616 | -0.00973 |    0.10656 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15312 | -0.02324 |    0.12080 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12272 | -0.00114 |    0.09513 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15296 | -0.01649 |    0.12184 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13817 | -0.01238 |    0.10939 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21256 | -0.02300 |    0.16800 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13615 | -0.01365 |    0.10723 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10039 | -0.00213 |    0.07584 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06804 | -0.00354 |    0.05131 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05346 | -0.00529 |    0.03906 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59995 | -0.00002 |    0.46854 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:22:45,062 - Total sparsity: 0.00

2018-11-02 21:22:45,063 - --- validate (epoch=47)-----------
2018-11-02 21:22:45,063 - 10000 samples (128 per mini-batch)
2018-11-02 21:22:45,795 - Epoch: [47][   50/   78]    Loss 0.520898    Top1 82.718750    Top5 99.015625    
2018-11-02 21:22:46,195 - ==> Top1: 82.970    Top5: 99.170    Loss: 0.512

2018-11-02 21:22:46,196 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:22:46,196 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:22:46,204 - 

2018-11-02 21:22:46,205 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:22:47,404 - Epoch: [48][   50/  391]    Overall Loss 0.376542    Objective Loss 0.376542    Top1 86.843750    Top5 99.593750    LR 0.300000    Time 0.023955    
2018-11-02 21:22:48,552 - Epoch: [48][  100/  391]    Overall Loss 0.364992    Objective Loss 0.364992    Top1 87.210938    Top5 99.578125    LR 0.300000    Time 0.023438    
2018-11-02 21:22:49,691 - Epoch: [48][  150/  391]    Overall Loss 0.373912    Objective Loss 0.373912    Top1 87.046875    Top5 99.609375    LR 0.300000    Time 0.023213    
2018-11-02 21:22:50,836 - Epoch: [48][  200/  391]    Overall Loss 0.373364    Objective Loss 0.373364    Top1 87.007812    Top5 99.628906    LR 0.300000    Time 0.023108    
2018-11-02 21:22:51,984 - Epoch: [48][  250/  391]    Overall Loss 0.378693    Objective Loss 0.378693    Top1 86.818750    Top5 99.584375    LR 0.300000    Time 0.023074    
2018-11-02 21:22:53,128 - Epoch: [48][  300/  391]    Overall Loss 0.381495    Objective Loss 0.381495    Top1 86.763021    Top5 99.567708    LR 0.300000    Time 0.023037    
2018-11-02 21:22:54,270 - Epoch: [48][  350/  391]    Overall Loss 0.383118    Objective Loss 0.383118    Top1 86.787946    Top5 99.555804    LR 0.300000    Time 0.023003    
2018-11-02 21:22:55,292 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57283 |  0.00200 |    0.38067 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15492 | -0.00198 |    0.09527 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15592 | -0.00276 |    0.10719 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19488 | -0.01524 |    0.13955 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19336 | -0.01157 |    0.14301 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19671 | -0.02971 |    0.14474 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17644 |  0.00061 |    0.12705 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21125 | -0.00584 |    0.15547 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17910 | -0.00626 |    0.13755 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38993 | -0.01473 |    0.27703 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15498 | -0.00897 |    0.11948 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13625 | -0.00873 |    0.10667 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15308 | -0.02228 |    0.12066 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12251 | -0.00018 |    0.09502 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15281 | -0.01544 |    0.12137 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13807 | -0.01211 |    0.10930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21277 | -0.02363 |    0.16756 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13598 | -0.01356 |    0.10700 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10026 | -0.00191 |    0.07577 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06844 | -0.00430 |    0.05174 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05374 | -0.00479 |    0.03915 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59929 | -0.00001 |    0.46694 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:22:55,292 - Total sparsity: 0.00

2018-11-02 21:22:55,292 - --- validate (epoch=48)-----------
2018-11-02 21:22:55,293 - 10000 samples (128 per mini-batch)
2018-11-02 21:22:56,023 - Epoch: [48][   50/   78]    Loss 0.617054    Top1 81.234375    Top5 98.625000    
2018-11-02 21:22:56,419 - ==> Top1: 81.200    Top5: 98.770    Loss: 0.608

2018-11-02 21:22:56,420 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:22:56,420 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:22:56,428 - 

2018-11-02 21:22:56,428 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:22:57,628 - Epoch: [49][   50/  391]    Overall Loss 0.372690    Objective Loss 0.372690    Top1 86.937500    Top5 99.562500    LR 0.300000    Time 0.023955    
2018-11-02 21:22:58,770 - Epoch: [49][  100/  391]    Overall Loss 0.364726    Objective Loss 0.364726    Top1 87.234375    Top5 99.562500    LR 0.300000    Time 0.023382    
2018-11-02 21:22:59,920 - Epoch: [49][  150/  391]    Overall Loss 0.367160    Objective Loss 0.367160    Top1 87.135417    Top5 99.567708    LR 0.300000    Time 0.023248    
2018-11-02 21:23:01,073 - Epoch: [49][  200/  391]    Overall Loss 0.370724    Objective Loss 0.370724    Top1 87.089844    Top5 99.546875    LR 0.300000    Time 0.023193    
2018-11-02 21:23:02,224 - Epoch: [49][  250/  391]    Overall Loss 0.372558    Objective Loss 0.372558    Top1 87.040625    Top5 99.587500    LR 0.300000    Time 0.023153    
2018-11-02 21:23:03,372 - Epoch: [49][  300/  391]    Overall Loss 0.375494    Objective Loss 0.375494    Top1 86.963542    Top5 99.570312    LR 0.300000    Time 0.023115    
2018-11-02 21:23:04,519 - Epoch: [49][  350/  391]    Overall Loss 0.374240    Objective Loss 0.374240    Top1 87.049107    Top5 99.569196    LR 0.300000    Time 0.023087    
2018-11-02 21:23:05,554 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57668 |  0.00025 |    0.38141 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15566 |  0.00045 |    0.09537 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15611 | -0.00205 |    0.10672 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19605 | -0.01918 |    0.14109 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19444 | -0.00906 |    0.14326 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19685 | -0.03184 |    0.14535 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17653 |  0.00130 |    0.12577 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21188 | -0.00673 |    0.15606 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17944 | -0.00488 |    0.13762 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38968 | -0.01514 |    0.27448 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15568 | -0.00975 |    0.11975 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13685 | -0.00953 |    0.10739 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15299 | -0.02448 |    0.12098 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12276 | -0.00079 |    0.09562 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15307 | -0.01665 |    0.12171 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13817 | -0.01134 |    0.10944 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21272 | -0.02504 |    0.16722 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13597 | -0.01466 |    0.10720 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10031 | -0.00205 |    0.07589 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06918 | -0.00303 |    0.05211 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05417 | -0.00529 |    0.03954 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59709 | -0.00001 |    0.46394 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:23:05,554 - Total sparsity: 0.00

2018-11-02 21:23:05,554 - --- validate (epoch=49)-----------
2018-11-02 21:23:05,554 - 10000 samples (128 per mini-batch)
2018-11-02 21:23:06,285 - Epoch: [49][   50/   78]    Loss 0.588088    Top1 81.484375    Top5 98.859375    
2018-11-02 21:23:06,678 - ==> Top1: 81.340    Top5: 98.910    Loss: 0.583

2018-11-02 21:23:06,679 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:23:06,679 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:23:06,687 - 

2018-11-02 21:23:06,688 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:23:07,902 - Epoch: [50][   50/  391]    Overall Loss 0.366328    Objective Loss 0.366328    Top1 87.156250    Top5 99.671875    LR 0.300000    Time 0.024256    
2018-11-02 21:23:09,056 - Epoch: [50][  100/  391]    Overall Loss 0.378814    Objective Loss 0.378814    Top1 87.078125    Top5 99.609375    LR 0.300000    Time 0.023651    
2018-11-02 21:23:10,211 - Epoch: [50][  150/  391]    Overall Loss 0.374230    Objective Loss 0.374230    Top1 87.125000    Top5 99.567708    LR 0.300000    Time 0.023458    
2018-11-02 21:23:11,420 - Epoch: [50][  200/  391]    Overall Loss 0.376853    Objective Loss 0.376853    Top1 87.074219    Top5 99.558594    LR 0.300000    Time 0.023634    
2018-11-02 21:23:12,563 - Epoch: [50][  250/  391]    Overall Loss 0.380391    Objective Loss 0.380391    Top1 86.896875    Top5 99.565625    LR 0.300000    Time 0.023472    
2018-11-02 21:23:13,709 - Epoch: [50][  300/  391]    Overall Loss 0.376404    Objective Loss 0.376404    Top1 86.992188    Top5 99.570312    LR 0.300000    Time 0.023374    
2018-11-02 21:23:14,877 - Epoch: [50][  350/  391]    Overall Loss 0.379338    Objective Loss 0.379338    Top1 86.930804    Top5 99.571429    LR 0.300000    Time 0.023369    
2018-11-02 21:23:15,901 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57899 | -0.00663 |    0.38662 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15428 | -0.00316 |    0.09375 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15497 | -0.00261 |    0.10614 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19517 | -0.01668 |    0.13977 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19458 | -0.00964 |    0.14353 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19781 | -0.02957 |    0.14559 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17617 |  0.00047 |    0.12644 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21254 | -0.00543 |    0.15657 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17997 | -0.00436 |    0.13815 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39113 | -0.01489 |    0.27715 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15544 | -0.01050 |    0.11985 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13666 | -0.01011 |    0.10694 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15335 | -0.02457 |    0.12109 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12323 | -0.00137 |    0.09599 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15322 | -0.01593 |    0.12186 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13807 | -0.01104 |    0.10922 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21335 | -0.02494 |    0.16789 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13625 | -0.01432 |    0.10734 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10031 | -0.00235 |    0.07594 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06937 | -0.00339 |    0.05248 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05436 | -0.00511 |    0.03970 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59959 | -0.00001 |    0.46797 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:23:15,901 - Total sparsity: 0.00

2018-11-02 21:23:15,901 - --- validate (epoch=50)-----------
2018-11-02 21:23:15,901 - 10000 samples (128 per mini-batch)
2018-11-02 21:23:16,625 - Epoch: [50][   50/   78]    Loss 1.012070    Top1 74.281250    Top5 98.734375    
2018-11-02 21:23:17,025 - ==> Top1: 74.060    Top5: 98.750    Loss: 0.991

2018-11-02 21:23:17,026 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:23:17,026 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:23:17,037 - 

2018-11-02 21:23:17,037 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:23:18,242 - Epoch: [51][   50/  391]    Overall Loss 0.360550    Objective Loss 0.360550    Top1 87.328125    Top5 99.500000    LR 0.300000    Time 0.024056    
2018-11-02 21:23:19,387 - Epoch: [51][  100/  391]    Overall Loss 0.379422    Objective Loss 0.379422    Top1 86.585938    Top5 99.484375    LR 0.300000    Time 0.023461    
2018-11-02 21:23:20,531 - Epoch: [51][  150/  391]    Overall Loss 0.370344    Objective Loss 0.370344    Top1 87.015625    Top5 99.473958    LR 0.300000    Time 0.023253    
2018-11-02 21:23:21,674 - Epoch: [51][  200/  391]    Overall Loss 0.375459    Objective Loss 0.375459    Top1 86.761719    Top5 99.457031    LR 0.300000    Time 0.023152    
2018-11-02 21:23:22,817 - Epoch: [51][  250/  391]    Overall Loss 0.380871    Objective Loss 0.380871    Top1 86.665625    Top5 99.462500    LR 0.300000    Time 0.023086    
2018-11-02 21:23:23,957 - Epoch: [51][  300/  391]    Overall Loss 0.382398    Objective Loss 0.382398    Top1 86.606771    Top5 99.481771    LR 0.300000    Time 0.023033    
2018-11-02 21:23:25,099 - Epoch: [51][  350/  391]    Overall Loss 0.385634    Objective Loss 0.385634    Top1 86.555804    Top5 99.477679    LR 0.300000    Time 0.023003    
2018-11-02 21:23:26,120 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58062 |  0.00139 |    0.38734 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15506 |  0.00016 |    0.09383 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15583 | -0.00260 |    0.10718 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19586 | -0.01684 |    0.14017 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19576 | -0.00792 |    0.14593 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19778 | -0.03092 |    0.14463 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17665 |  0.00143 |    0.12689 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21345 | -0.00602 |    0.15623 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18032 | -0.00585 |    0.13854 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39230 | -0.01041 |    0.27821 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15603 | -0.00925 |    0.12008 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13727 | -0.00916 |    0.10711 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15397 | -0.02467 |    0.12131 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12378 | -0.00194 |    0.09680 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15380 | -0.01592 |    0.12241 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13843 | -0.01158 |    0.10964 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21361 | -0.02462 |    0.16675 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13648 | -0.01479 |    0.10785 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10059 | -0.00252 |    0.07629 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06975 | -0.00364 |    0.05263 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05463 | -0.00557 |    0.03984 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59531 | -0.00001 |    0.46337 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:23:26,120 - Total sparsity: 0.00

2018-11-02 21:23:26,120 - --- validate (epoch=51)-----------
2018-11-02 21:23:26,120 - 10000 samples (128 per mini-batch)
2018-11-02 21:23:26,849 - Epoch: [51][   50/   78]    Loss 0.541185    Top1 82.828125    Top5 99.421875    
2018-11-02 21:23:27,241 - ==> Top1: 82.900    Top5: 99.390    Loss: 0.534

2018-11-02 21:23:27,241 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:23:27,241 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:23:27,253 - 

2018-11-02 21:23:27,254 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:23:28,450 - Epoch: [52][   50/  391]    Overall Loss 0.352627    Objective Loss 0.352627    Top1 87.703125    Top5 99.578125    LR 0.300000    Time 0.023885    
2018-11-02 21:23:29,591 - Epoch: [52][  100/  391]    Overall Loss 0.367425    Objective Loss 0.367425    Top1 87.289062    Top5 99.593750    LR 0.300000    Time 0.023343    
2018-11-02 21:23:30,735 - Epoch: [52][  150/  391]    Overall Loss 0.369517    Objective Loss 0.369517    Top1 87.213542    Top5 99.552083    LR 0.300000    Time 0.023177    
2018-11-02 21:23:31,879 - Epoch: [52][  200/  391]    Overall Loss 0.367225    Objective Loss 0.367225    Top1 87.351562    Top5 99.558594    LR 0.300000    Time 0.023097    
2018-11-02 21:23:33,022 - Epoch: [52][  250/  391]    Overall Loss 0.372428    Objective Loss 0.372428    Top1 87.168750    Top5 99.515625    LR 0.300000    Time 0.023045    
2018-11-02 21:23:34,166 - Epoch: [52][  300/  391]    Overall Loss 0.373151    Objective Loss 0.373151    Top1 87.169271    Top5 99.523438    LR 0.300000    Time 0.023014    
2018-11-02 21:23:35,310 - Epoch: [52][  350/  391]    Overall Loss 0.375129    Objective Loss 0.375129    Top1 87.069196    Top5 99.511161    LR 0.300000    Time 0.022990    
2018-11-02 21:23:36,331 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58607 | -0.00506 |    0.38978 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15667 |  0.00063 |    0.09432 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15679 | -0.00034 |    0.10804 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19698 | -0.01968 |    0.14073 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19683 | -0.00992 |    0.14574 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19881 | -0.03028 |    0.14557 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17691 | -0.00150 |    0.12625 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21354 | -0.00756 |    0.15666 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18060 | -0.00464 |    0.13865 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39214 | -0.01122 |    0.27731 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15577 | -0.01107 |    0.12008 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13661 | -0.01020 |    0.10686 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15396 | -0.02416 |    0.12180 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12397 | -0.00288 |    0.09697 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15406 | -0.01546 |    0.12243 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13860 | -0.01108 |    0.10979 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21272 | -0.02458 |    0.16607 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13621 | -0.01552 |    0.10764 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10063 | -0.00195 |    0.07626 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06995 | -0.00374 |    0.05289 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05464 | -0.00561 |    0.03989 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59619 | -0.00001 |    0.46545 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:23:36,331 - Total sparsity: 0.00

2018-11-02 21:23:36,331 - --- validate (epoch=52)-----------
2018-11-02 21:23:36,331 - 10000 samples (128 per mini-batch)
2018-11-02 21:23:37,061 - Epoch: [52][   50/   78]    Loss 0.715978    Top1 77.781250    Top5 98.703125    
2018-11-02 21:23:37,453 - ==> Top1: 77.740    Top5: 98.660    Loss: 0.712

2018-11-02 21:23:37,454 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:23:37,454 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:23:37,469 - 

2018-11-02 21:23:37,469 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:23:38,671 - Epoch: [53][   50/  391]    Overall Loss 0.357944    Objective Loss 0.357944    Top1 87.671875    Top5 99.578125    LR 0.300000    Time 0.023992    
2018-11-02 21:23:39,813 - Epoch: [53][  100/  391]    Overall Loss 0.375973    Objective Loss 0.375973    Top1 86.765625    Top5 99.507812    LR 0.300000    Time 0.023405    
2018-11-02 21:23:40,955 - Epoch: [53][  150/  391]    Overall Loss 0.371998    Objective Loss 0.371998    Top1 87.041667    Top5 99.583333    LR 0.300000    Time 0.023206    
2018-11-02 21:23:42,098 - Epoch: [53][  200/  391]    Overall Loss 0.371352    Objective Loss 0.371352    Top1 87.050781    Top5 99.582031    LR 0.300000    Time 0.023109    
2018-11-02 21:23:43,259 - Epoch: [53][  250/  391]    Overall Loss 0.372533    Objective Loss 0.372533    Top1 87.046875    Top5 99.578125    LR 0.300000    Time 0.023128    
2018-11-02 21:23:44,422 - Epoch: [53][  300/  391]    Overall Loss 0.374327    Objective Loss 0.374327    Top1 87.065104    Top5 99.593750    LR 0.300000    Time 0.023146    
2018-11-02 21:23:45,564 - Epoch: [53][  350/  391]    Overall Loss 0.376050    Objective Loss 0.376050    Top1 87.008929    Top5 99.587054    LR 0.300000    Time 0.023098    
2018-11-02 21:23:46,584 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58201 |  0.00151 |    0.38881 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15648 |  0.00083 |    0.09404 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15602 | -0.00090 |    0.10569 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19657 | -0.02173 |    0.13997 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19548 | -0.01017 |    0.14415 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19799 | -0.03038 |    0.14475 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17601 | -0.00369 |    0.12532 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21328 | -0.00518 |    0.15579 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18044 | -0.00498 |    0.13841 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39160 | -0.01234 |    0.27428 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.01168 |    0.11959 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13678 | -0.00887 |    0.10734 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15358 | -0.02505 |    0.12165 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12402 | -0.00297 |    0.09676 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15388 | -0.01691 |    0.12236 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13849 | -0.01111 |    0.10961 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21174 | -0.02507 |    0.16513 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13599 | -0.01505 |    0.10736 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10066 | -0.00225 |    0.07627 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07070 | -0.00349 |    0.05337 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05515 | -0.00511 |    0.04022 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59753 | -0.00001 |    0.46609 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:23:46,584 - Total sparsity: 0.00

2018-11-02 21:23:46,585 - --- validate (epoch=53)-----------
2018-11-02 21:23:46,585 - 10000 samples (128 per mini-batch)
2018-11-02 21:23:47,314 - Epoch: [53][   50/   78]    Loss 0.523950    Top1 82.656250    Top5 99.156250    
2018-11-02 21:23:47,709 - ==> Top1: 82.490    Top5: 99.240    Loss: 0.525

2018-11-02 21:23:47,709 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:23:47,710 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:23:47,718 - 

2018-11-02 21:23:47,718 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:23:48,914 - Epoch: [54][   50/  391]    Overall Loss 0.350548    Objective Loss 0.350548    Top1 87.500000    Top5 99.687500    LR 0.300000    Time 0.023880    
2018-11-02 21:23:50,053 - Epoch: [54][  100/  391]    Overall Loss 0.370063    Objective Loss 0.370063    Top1 87.210938    Top5 99.601562    LR 0.300000    Time 0.023319    
2018-11-02 21:23:51,192 - Epoch: [54][  150/  391]    Overall Loss 0.368931    Objective Loss 0.368931    Top1 87.364583    Top5 99.578125    LR 0.300000    Time 0.023130    
2018-11-02 21:23:52,335 - Epoch: [54][  200/  391]    Overall Loss 0.370926    Objective Loss 0.370926    Top1 87.250000    Top5 99.613281    LR 0.300000    Time 0.023038    
2018-11-02 21:23:53,477 - Epoch: [54][  250/  391]    Overall Loss 0.371896    Objective Loss 0.371896    Top1 87.275000    Top5 99.568750    LR 0.300000    Time 0.022993    
2018-11-02 21:23:54,621 - Epoch: [54][  300/  391]    Overall Loss 0.369939    Objective Loss 0.369939    Top1 87.270833    Top5 99.565104    LR 0.300000    Time 0.022969    
2018-11-02 21:23:55,765 - Epoch: [54][  350/  391]    Overall Loss 0.372503    Objective Loss 0.372503    Top1 87.223214    Top5 99.560268    LR 0.300000    Time 0.022952    
2018-11-02 21:23:56,785 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58026 | -0.00532 |    0.38549 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15580 | -0.00089 |    0.09356 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15583 | -0.00309 |    0.10598 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19659 | -0.01888 |    0.13953 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19438 | -0.00876 |    0.14459 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19668 | -0.03166 |    0.14347 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17610 | -0.00252 |    0.12631 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21293 | -0.00980 |    0.15590 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18004 | -0.00527 |    0.13786 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39322 | -0.01491 |    0.27971 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15651 | -0.01054 |    0.12008 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13719 | -0.00919 |    0.10758 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15388 | -0.02418 |    0.12147 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12392 | -0.00146 |    0.09636 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15366 | -0.01602 |    0.12210 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13846 | -0.01151 |    0.10965 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21239 | -0.02584 |    0.16444 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13609 | -0.01462 |    0.10738 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10058 | -0.00204 |    0.07616 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07104 | -0.00344 |    0.05371 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05537 | -0.00508 |    0.04048 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59512 | -0.00001 |    0.46347 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:23:56,786 - Total sparsity: 0.00

2018-11-02 21:23:56,786 - --- validate (epoch=54)-----------
2018-11-02 21:23:56,786 - 10000 samples (128 per mini-batch)
2018-11-02 21:23:57,513 - Epoch: [54][   50/   78]    Loss 0.634381    Top1 80.484375    Top5 98.250000    
2018-11-02 21:23:57,905 - ==> Top1: 80.160    Top5: 98.240    Loss: 0.637

2018-11-02 21:23:57,905 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:23:57,906 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:23:57,917 - 

2018-11-02 21:23:57,917 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:23:59,117 - Epoch: [55][   50/  391]    Overall Loss 0.344069    Objective Loss 0.344069    Top1 88.000000    Top5 99.734375    LR 0.300000    Time 0.023958    
2018-11-02 21:24:00,260 - Epoch: [55][  100/  391]    Overall Loss 0.353645    Objective Loss 0.353645    Top1 87.750000    Top5 99.640625    LR 0.300000    Time 0.023389    
2018-11-02 21:24:01,401 - Epoch: [55][  150/  391]    Overall Loss 0.359416    Objective Loss 0.359416    Top1 87.640625    Top5 99.614583    LR 0.300000    Time 0.023195    
2018-11-02 21:24:02,543 - Epoch: [55][  200/  391]    Overall Loss 0.367123    Objective Loss 0.367123    Top1 87.347656    Top5 99.566406    LR 0.300000    Time 0.023100    
2018-11-02 21:24:03,685 - Epoch: [55][  250/  391]    Overall Loss 0.372761    Objective Loss 0.372761    Top1 87.225000    Top5 99.543750    LR 0.300000    Time 0.023042    
2018-11-02 21:24:04,825 - Epoch: [55][  300/  391]    Overall Loss 0.373435    Objective Loss 0.373435    Top1 87.247396    Top5 99.565104    LR 0.300000    Time 0.022996    
2018-11-02 21:24:05,968 - Epoch: [55][  350/  391]    Overall Loss 0.372927    Objective Loss 0.372927    Top1 87.196429    Top5 99.573661    LR 0.300000    Time 0.022972    
2018-11-02 21:24:06,985 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58290 | -0.01578 |    0.38976 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15425 |  0.00012 |    0.09302 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15431 | -0.00427 |    0.10545 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19716 | -0.01769 |    0.13968 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19442 | -0.00749 |    0.14399 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19651 | -0.02943 |    0.14368 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17541 |  0.00093 |    0.12568 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21275 | -0.00813 |    0.15505 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17964 | -0.00574 |    0.13774 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39230 | -0.01520 |    0.27312 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15623 | -0.01021 |    0.11970 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13680 | -0.00888 |    0.10705 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15312 | -0.02394 |    0.12038 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12291 | -0.00168 |    0.09583 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15329 | -0.01568 |    0.12190 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13806 | -0.01063 |    0.10908 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21229 | -0.02668 |    0.16420 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13535 | -0.01498 |    0.10689 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10020 | -0.00233 |    0.07590 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07101 | -0.00387 |    0.05376 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05540 | -0.00497 |    0.04047 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59626 | -0.00001 |    0.46540 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:24:06,985 - Total sparsity: 0.00

2018-11-02 21:24:06,985 - --- validate (epoch=55)-----------
2018-11-02 21:24:06,985 - 10000 samples (128 per mini-batch)
2018-11-02 21:24:07,717 - Epoch: [55][   50/   78]    Loss 0.594812    Top1 80.515625    Top5 98.671875    
2018-11-02 21:24:08,113 - ==> Top1: 80.610    Top5: 98.730    Loss: 0.601

2018-11-02 21:24:08,114 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:24:08,114 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:24:08,122 - 

2018-11-02 21:24:08,122 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:24:09,320 - Epoch: [56][   50/  391]    Overall Loss 0.345345    Objective Loss 0.345345    Top1 88.531250    Top5 99.500000    LR 0.300000    Time 0.023925    
2018-11-02 21:24:10,464 - Epoch: [56][  100/  391]    Overall Loss 0.357246    Objective Loss 0.357246    Top1 87.992188    Top5 99.578125    LR 0.300000    Time 0.023382    
2018-11-02 21:24:11,607 - Epoch: [56][  150/  391]    Overall Loss 0.361197    Objective Loss 0.361197    Top1 87.671875    Top5 99.604167    LR 0.300000    Time 0.023202    
2018-11-02 21:24:12,748 - Epoch: [56][  200/  391]    Overall Loss 0.360559    Objective Loss 0.360559    Top1 87.695312    Top5 99.628906    LR 0.300000    Time 0.023098    
2018-11-02 21:24:13,889 - Epoch: [56][  250/  391]    Overall Loss 0.363762    Objective Loss 0.363762    Top1 87.512500    Top5 99.621875    LR 0.300000    Time 0.023023    
2018-11-02 21:24:15,032 - Epoch: [56][  300/  391]    Overall Loss 0.368570    Objective Loss 0.368570    Top1 87.356771    Top5 99.604167    LR 0.300000    Time 0.022990    
2018-11-02 21:24:16,169 - Epoch: [56][  350/  391]    Overall Loss 0.373027    Objective Loss 0.373027    Top1 87.247768    Top5 99.569196    LR 0.300000    Time 0.022952    
2018-11-02 21:24:17,184 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58493 | -0.00745 |    0.39175 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15364 | -0.00065 |    0.09328 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15398 | -0.00522 |    0.10492 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19564 | -0.01976 |    0.13866 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19389 | -0.01288 |    0.14356 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19542 | -0.03003 |    0.14363 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17463 |  0.00003 |    0.12521 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21233 | -0.00883 |    0.15456 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17918 | -0.00427 |    0.13746 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39212 | -0.01523 |    0.27321 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15584 | -0.01022 |    0.11951 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13664 | -0.00837 |    0.10731 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15334 | -0.02241 |    0.12043 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12302 | -0.00176 |    0.09599 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15328 | -0.01576 |    0.12191 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13815 | -0.01068 |    0.10904 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21205 | -0.02649 |    0.16539 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13551 | -0.01466 |    0.10695 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10050 | -0.00255 |    0.07608 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07157 | -0.00435 |    0.05428 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05587 | -0.00520 |    0.04086 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59387 | -0.00001 |    0.46404 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:24:17,184 - Total sparsity: 0.00

2018-11-02 21:24:17,184 - --- validate (epoch=56)-----------
2018-11-02 21:24:17,184 - 10000 samples (128 per mini-batch)
2018-11-02 21:24:17,913 - Epoch: [56][   50/   78]    Loss 0.667247    Top1 80.812500    Top5 98.484375    
2018-11-02 21:24:18,304 - ==> Top1: 80.860    Top5: 98.560    Loss: 0.659

2018-11-02 21:24:18,305 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:24:18,305 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:24:18,312 - 

2018-11-02 21:24:18,313 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:24:19,510 - Epoch: [57][   50/  391]    Overall Loss 0.374834    Objective Loss 0.374834    Top1 86.968750    Top5 99.656250    LR 0.300000    Time 0.023919    
2018-11-02 21:24:20,652 - Epoch: [57][  100/  391]    Overall Loss 0.366924    Objective Loss 0.366924    Top1 87.250000    Top5 99.671875    LR 0.300000    Time 0.023362    
2018-11-02 21:24:21,793 - Epoch: [57][  150/  391]    Overall Loss 0.360865    Objective Loss 0.360865    Top1 87.421875    Top5 99.661458    LR 0.300000    Time 0.023171    
2018-11-02 21:24:22,934 - Epoch: [57][  200/  391]    Overall Loss 0.370653    Objective Loss 0.370653    Top1 87.117188    Top5 99.605469    LR 0.300000    Time 0.023079    
2018-11-02 21:24:24,074 - Epoch: [57][  250/  391]    Overall Loss 0.373476    Objective Loss 0.373476    Top1 87.034375    Top5 99.615625    LR 0.300000    Time 0.023018    
2018-11-02 21:24:25,214 - Epoch: [57][  300/  391]    Overall Loss 0.371497    Objective Loss 0.371497    Top1 87.140625    Top5 99.625000    LR 0.300000    Time 0.022977    
2018-11-02 21:24:26,356 - Epoch: [57][  350/  391]    Overall Loss 0.372047    Objective Loss 0.372047    Top1 87.203125    Top5 99.620536    LR 0.300000    Time 0.022952    
2018-11-02 21:24:27,371 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58860 | -0.00856 |    0.39534 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15290 | -0.00200 |    0.09341 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15349 | -0.00093 |    0.10533 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19505 | -0.02148 |    0.13889 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19367 | -0.01102 |    0.14433 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19486 | -0.03223 |    0.14379 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17462 |  0.00026 |    0.12558 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21151 | -0.00903 |    0.15380 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17920 | -0.00479 |    0.13802 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39201 | -0.01773 |    0.27659 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15553 | -0.01006 |    0.11918 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13661 | -0.00792 |    0.10731 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15286 | -0.02334 |    0.12024 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12275 | -0.00045 |    0.09565 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15340 | -0.01626 |    0.12185 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13813 | -0.01054 |    0.10902 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21244 | -0.02467 |    0.16594 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13545 | -0.01458 |    0.10685 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10069 | -0.00224 |    0.07638 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07219 | -0.00464 |    0.05466 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05608 | -0.00476 |    0.04093 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59699 | -0.00001 |    0.46728 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:24:27,371 - Total sparsity: 0.00

2018-11-02 21:24:27,371 - --- validate (epoch=57)-----------
2018-11-02 21:24:27,371 - 10000 samples (128 per mini-batch)
2018-11-02 21:24:28,094 - Epoch: [57][   50/   78]    Loss 0.468330    Top1 84.093750    Top5 99.359375    
2018-11-02 21:24:28,484 - ==> Top1: 84.230    Top5: 99.400    Loss: 0.459

2018-11-02 21:24:28,485 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:24:28,486 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:24:28,500 - 

2018-11-02 21:24:28,500 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:24:29,698 - Epoch: [58][   50/  391]    Overall Loss 0.355721    Objective Loss 0.355721    Top1 87.812500    Top5 99.703125    LR 0.300000    Time 0.023922    
2018-11-02 21:24:30,841 - Epoch: [58][  100/  391]    Overall Loss 0.365274    Objective Loss 0.365274    Top1 87.468750    Top5 99.656250    LR 0.300000    Time 0.023378    
2018-11-02 21:24:31,981 - Epoch: [58][  150/  391]    Overall Loss 0.371087    Objective Loss 0.371087    Top1 87.223958    Top5 99.625000    LR 0.300000    Time 0.023177    
2018-11-02 21:24:33,123 - Epoch: [58][  200/  391]    Overall Loss 0.367221    Objective Loss 0.367221    Top1 87.343750    Top5 99.605469    LR 0.300000    Time 0.023085    
2018-11-02 21:24:34,266 - Epoch: [58][  250/  391]    Overall Loss 0.368508    Objective Loss 0.368508    Top1 87.346875    Top5 99.615625    LR 0.300000    Time 0.023035    
2018-11-02 21:24:35,409 - Epoch: [58][  300/  391]    Overall Loss 0.370560    Objective Loss 0.370560    Top1 87.221354    Top5 99.604167    LR 0.300000    Time 0.023001    
2018-11-02 21:24:36,552 - Epoch: [58][  350/  391]    Overall Loss 0.370076    Objective Loss 0.370076    Top1 87.205357    Top5 99.593750    LR 0.300000    Time 0.022975    
2018-11-02 21:24:37,568 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58601 |  0.00227 |    0.39164 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15283 | -0.00046 |    0.09292 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15376 | -0.00237 |    0.10573 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19650 | -0.02139 |    0.14040 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19538 | -0.00702 |    0.14484 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19737 | -0.02944 |    0.14473 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17608 | -0.00003 |    0.12721 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21226 | -0.01006 |    0.15462 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17944 | -0.00349 |    0.13750 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39308 | -0.01717 |    0.27638 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15523 | -0.01102 |    0.11958 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13638 | -0.00758 |    0.10699 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15371 | -0.02291 |    0.12096 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12309 | -0.00188 |    0.09567 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15371 | -0.01514 |    0.12202 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13840 | -0.01075 |    0.10930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21287 | -0.02617 |    0.16606 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13577 | -0.01476 |    0.10723 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10090 | -0.00283 |    0.07649 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07259 | -0.00419 |    0.05503 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05651 | -0.00445 |    0.04126 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59401 | -0.00001 |    0.46442 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:24:37,568 - Total sparsity: 0.00

2018-11-02 21:24:37,569 - --- validate (epoch=58)-----------
2018-11-02 21:24:37,569 - 10000 samples (128 per mini-batch)
2018-11-02 21:24:38,291 - Epoch: [58][   50/   78]    Loss 0.710647    Top1 78.328125    Top5 98.359375    
2018-11-02 21:24:38,688 - ==> Top1: 78.290    Top5: 98.530    Loss: 0.711

2018-11-02 21:24:38,689 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:24:38,689 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:24:38,704 - 

2018-11-02 21:24:38,705 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:24:39,902 - Epoch: [59][   50/  391]    Overall Loss 0.356405    Objective Loss 0.356405    Top1 87.687500    Top5 99.546875    LR 0.300000    Time 0.023910    
2018-11-02 21:24:41,043 - Epoch: [59][  100/  391]    Overall Loss 0.350846    Objective Loss 0.350846    Top1 87.804688    Top5 99.578125    LR 0.300000    Time 0.023347    
2018-11-02 21:24:42,184 - Epoch: [59][  150/  391]    Overall Loss 0.356522    Objective Loss 0.356522    Top1 87.552083    Top5 99.609375    LR 0.300000    Time 0.023165    
2018-11-02 21:24:43,326 - Epoch: [59][  200/  391]    Overall Loss 0.359850    Objective Loss 0.359850    Top1 87.503906    Top5 99.570312    LR 0.300000    Time 0.023077    
2018-11-02 21:24:44,470 - Epoch: [59][  250/  391]    Overall Loss 0.364711    Objective Loss 0.364711    Top1 87.321875    Top5 99.575000    LR 0.300000    Time 0.023030    
2018-11-02 21:24:45,612 - Epoch: [59][  300/  391]    Overall Loss 0.368613    Objective Loss 0.368613    Top1 87.153646    Top5 99.562500    LR 0.300000    Time 0.022996    
2018-11-02 21:24:46,755 - Epoch: [59][  350/  391]    Overall Loss 0.370577    Objective Loss 0.370577    Top1 87.095982    Top5 99.564732    LR 0.300000    Time 0.022972    
2018-11-02 21:24:47,772 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58344 |  0.00197 |    0.38667 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15253 | -0.00129 |    0.09221 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15374 | -0.00296 |    0.10486 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19632 | -0.02156 |    0.14088 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19506 | -0.01051 |    0.14528 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19728 | -0.02951 |    0.14544 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17654 |  0.00275 |    0.12793 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21196 | -0.01159 |    0.15440 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17898 | -0.00589 |    0.13719 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39402 | -0.01477 |    0.27482 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15486 | -0.01103 |    0.11887 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13599 | -0.00892 |    0.10700 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15309 | -0.02448 |    0.12088 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12235 | -0.00141 |    0.09511 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15332 | -0.01507 |    0.12189 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13851 | -0.01052 |    0.10964 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21293 | -0.02691 |    0.16600 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13593 | -0.01473 |    0.10733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10105 | -0.00322 |    0.07668 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07292 | -0.00498 |    0.05542 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05678 | -0.00452 |    0.04148 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59524 | -0.00000 |    0.46574 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:24:47,772 - Total sparsity: 0.00

2018-11-02 21:24:47,772 - --- validate (epoch=59)-----------
2018-11-02 21:24:47,772 - 10000 samples (128 per mini-batch)
2018-11-02 21:24:48,503 - Epoch: [59][   50/   78]    Loss 0.567302    Top1 81.859375    Top5 98.968750    
2018-11-02 21:24:48,900 - ==> Top1: 81.570    Top5: 99.030    Loss: 0.575

2018-11-02 21:24:48,901 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:24:48,901 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:24:48,913 - 

2018-11-02 21:24:48,913 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:24:50,111 - Epoch: [60][   50/  391]    Overall Loss 0.358251    Objective Loss 0.358251    Top1 87.812500    Top5 99.546875    LR 0.300000    Time 0.023926    
2018-11-02 21:24:51,253 - Epoch: [60][  100/  391]    Overall Loss 0.360223    Objective Loss 0.360223    Top1 87.523438    Top5 99.617188    LR 0.300000    Time 0.023366    
2018-11-02 21:24:52,395 - Epoch: [60][  150/  391]    Overall Loss 0.363785    Objective Loss 0.363785    Top1 87.375000    Top5 99.526042    LR 0.300000    Time 0.023182    
2018-11-02 21:24:53,538 - Epoch: [60][  200/  391]    Overall Loss 0.370346    Objective Loss 0.370346    Top1 87.238281    Top5 99.535156    LR 0.300000    Time 0.023092    
2018-11-02 21:24:54,680 - Epoch: [60][  250/  391]    Overall Loss 0.369158    Objective Loss 0.369158    Top1 87.284375    Top5 99.556250    LR 0.300000    Time 0.023038    
2018-11-02 21:24:55,823 - Epoch: [60][  300/  391]    Overall Loss 0.368584    Objective Loss 0.368584    Top1 87.289062    Top5 99.554688    LR 0.300000    Time 0.023003    
2018-11-02 21:24:56,966 - Epoch: [60][  350/  391]    Overall Loss 0.371470    Objective Loss 0.371470    Top1 87.236607    Top5 99.540179    LR 0.300000    Time 0.022980    
2018-11-02 21:24:57,994 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58161 | -0.01213 |    0.38699 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15316 | -0.00009 |    0.09270 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15376 | -0.00047 |    0.10522 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19564 | -0.02223 |    0.13995 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19511 | -0.00664 |    0.14469 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19684 | -0.02817 |    0.14525 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17688 |  0.00130 |    0.12739 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21280 | -0.00733 |    0.15464 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17934 | -0.00562 |    0.13739 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39332 | -0.01627 |    0.27621 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15546 | -0.00892 |    0.11969 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13660 | -0.00718 |    0.10767 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15357 | -0.02341 |    0.12133 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12225 | -0.00272 |    0.09467 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15334 | -0.01424 |    0.12182 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13870 | -0.01040 |    0.10967 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21250 | -0.02545 |    0.16650 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13614 | -0.01477 |    0.10748 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10135 | -0.00318 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07348 | -0.00506 |    0.05575 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05710 | -0.00437 |    0.04169 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59472 | -0.00000 |    0.46563 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:24:57,995 - Total sparsity: 0.00

2018-11-02 21:24:57,995 - --- validate (epoch=60)-----------
2018-11-02 21:24:57,995 - 10000 samples (128 per mini-batch)
2018-11-02 21:24:58,722 - Epoch: [60][   50/   78]    Loss 0.611825    Top1 80.156250    Top5 99.062500    
2018-11-02 21:24:59,114 - ==> Top1: 80.160    Top5: 99.130    Loss: 0.613

2018-11-02 21:24:59,115 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:24:59,115 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:24:59,124 - 

2018-11-02 21:24:59,124 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:25:00,324 - Epoch: [61][   50/  391]    Overall Loss 0.377001    Objective Loss 0.377001    Top1 86.578125    Top5 99.546875    LR 0.300000    Time 0.023975    
2018-11-02 21:25:01,467 - Epoch: [61][  100/  391]    Overall Loss 0.370452    Objective Loss 0.370452    Top1 87.289062    Top5 99.578125    LR 0.300000    Time 0.023394    
2018-11-02 21:25:02,607 - Epoch: [61][  150/  391]    Overall Loss 0.373855    Objective Loss 0.373855    Top1 87.192708    Top5 99.578125    LR 0.300000    Time 0.023188    
2018-11-02 21:25:03,747 - Epoch: [61][  200/  391]    Overall Loss 0.372166    Objective Loss 0.372166    Top1 87.253906    Top5 99.578125    LR 0.300000    Time 0.023069    
2018-11-02 21:25:04,891 - Epoch: [61][  250/  391]    Overall Loss 0.376301    Objective Loss 0.376301    Top1 87.062500    Top5 99.553125    LR 0.300000    Time 0.023025    
2018-11-02 21:25:06,032 - Epoch: [61][  300/  391]    Overall Loss 0.374283    Objective Loss 0.374283    Top1 87.151042    Top5 99.562500    LR 0.300000    Time 0.022985    
2018-11-02 21:25:07,174 - Epoch: [61][  350/  391]    Overall Loss 0.370377    Objective Loss 0.370377    Top1 87.216518    Top5 99.584821    LR 0.300000    Time 0.022961    
2018-11-02 21:25:08,190 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58484 |  0.00306 |    0.39041 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15438 | -0.00197 |    0.09390 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15516 |  0.00211 |    0.10572 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19627 | -0.02331 |    0.14048 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19493 | -0.00851 |    0.14464 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19734 | -0.02749 |    0.14562 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17776 |  0.00351 |    0.12810 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21337 | -0.00699 |    0.15579 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17991 | -0.00590 |    0.13801 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39465 | -0.01665 |    0.27438 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15635 | -0.01039 |    0.11992 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13751 | -0.00751 |    0.10828 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15398 | -0.02410 |    0.12186 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12216 | -0.00302 |    0.09472 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15340 | -0.01565 |    0.12201 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13889 | -0.00989 |    0.10987 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21239 | -0.02359 |    0.16483 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13628 | -0.01419 |    0.10747 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10130 | -0.00335 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07382 | -0.00517 |    0.05610 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05715 | -0.00496 |    0.04178 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59633 | -0.00000 |    0.46609 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:25:08,190 - Total sparsity: 0.00

2018-11-02 21:25:08,190 - --- validate (epoch=61)-----------
2018-11-02 21:25:08,190 - 10000 samples (128 per mini-batch)
2018-11-02 21:25:08,909 - Epoch: [61][   50/   78]    Loss 0.530655    Top1 83.328125    Top5 99.187500    
2018-11-02 21:25:09,299 - ==> Top1: 83.450    Top5: 99.140    Loss: 0.526

2018-11-02 21:25:09,300 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:25:09,300 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:25:09,311 - 

2018-11-02 21:25:09,311 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:25:10,510 - Epoch: [62][   50/  391]    Overall Loss 0.373307    Objective Loss 0.373307    Top1 86.562500    Top5 99.671875    LR 0.300000    Time 0.023944    
2018-11-02 21:25:11,651 - Epoch: [62][  100/  391]    Overall Loss 0.370972    Objective Loss 0.370972    Top1 87.054688    Top5 99.593750    LR 0.300000    Time 0.023360    
2018-11-02 21:25:12,791 - Epoch: [62][  150/  391]    Overall Loss 0.371886    Objective Loss 0.371886    Top1 87.072917    Top5 99.583333    LR 0.300000    Time 0.023167    
2018-11-02 21:25:13,932 - Epoch: [62][  200/  391]    Overall Loss 0.369283    Objective Loss 0.369283    Top1 87.101562    Top5 99.582031    LR 0.300000    Time 0.023071    
2018-11-02 21:25:15,072 - Epoch: [62][  250/  391]    Overall Loss 0.371146    Objective Loss 0.371146    Top1 87.184375    Top5 99.534375    LR 0.300000    Time 0.023014    
2018-11-02 21:25:16,215 - Epoch: [62][  300/  391]    Overall Loss 0.372086    Objective Loss 0.372086    Top1 87.127604    Top5 99.531250    LR 0.300000    Time 0.022982    
2018-11-02 21:25:17,357 - Epoch: [62][  350/  391]    Overall Loss 0.372854    Objective Loss 0.372854    Top1 87.084821    Top5 99.533482    LR 0.300000    Time 0.022958    
2018-11-02 21:25:18,377 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59279 | -0.00416 |    0.39543 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15664 | -0.00021 |    0.09469 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15697 |  0.00057 |    0.10811 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19863 | -0.02190 |    0.14106 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19566 | -0.01049 |    0.14664 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19781 | -0.02713 |    0.14437 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17725 |  0.00078 |    0.12851 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21389 | -0.00631 |    0.15523 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18078 | -0.00671 |    0.13845 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39608 | -0.01538 |    0.27810 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15690 | -0.01063 |    0.12064 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13816 | -0.00734 |    0.10877 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15478 | -0.02166 |    0.12236 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12240 | -0.00249 |    0.09505 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15425 | -0.01538 |    0.12265 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13927 | -0.01058 |    0.11029 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21239 | -0.02372 |    0.16549 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13673 | -0.01400 |    0.10785 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10173 | -0.00305 |    0.07692 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07447 | -0.00526 |    0.05666 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05772 | -0.00441 |    0.04203 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58919 | -0.00000 |    0.46179 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:25:18,377 - Total sparsity: 0.00

2018-11-02 21:25:18,377 - --- validate (epoch=62)-----------
2018-11-02 21:25:18,377 - 10000 samples (128 per mini-batch)
2018-11-02 21:25:19,104 - Epoch: [62][   50/   78]    Loss 0.667681    Top1 78.562500    Top5 98.390625    
2018-11-02 21:25:19,497 - ==> Top1: 78.670    Top5: 98.500    Loss: 0.664

2018-11-02 21:25:19,497 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:25:19,497 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:25:19,506 - 

2018-11-02 21:25:19,506 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:25:20,702 - Epoch: [63][   50/  391]    Overall Loss 0.371705    Objective Loss 0.371705    Top1 87.250000    Top5 99.562500    LR 0.300000    Time 0.023882    
2018-11-02 21:25:21,843 - Epoch: [63][  100/  391]    Overall Loss 0.364246    Objective Loss 0.364246    Top1 87.367188    Top5 99.601562    LR 0.300000    Time 0.023336    
2018-11-02 21:25:22,985 - Epoch: [63][  150/  391]    Overall Loss 0.364779    Objective Loss 0.364779    Top1 87.348958    Top5 99.609375    LR 0.300000    Time 0.023163    
2018-11-02 21:25:24,126 - Epoch: [63][  200/  391]    Overall Loss 0.362288    Objective Loss 0.362288    Top1 87.441406    Top5 99.617188    LR 0.300000    Time 0.023067    
2018-11-02 21:25:25,266 - Epoch: [63][  250/  391]    Overall Loss 0.365628    Objective Loss 0.365628    Top1 87.362500    Top5 99.600000    LR 0.300000    Time 0.023012    
2018-11-02 21:25:26,409 - Epoch: [63][  300/  391]    Overall Loss 0.367478    Objective Loss 0.367478    Top1 87.348958    Top5 99.588542    LR 0.300000    Time 0.022978    
2018-11-02 21:25:27,550 - Epoch: [63][  350/  391]    Overall Loss 0.366994    Objective Loss 0.366994    Top1 87.323661    Top5 99.602679    LR 0.300000    Time 0.022954    
2018-11-02 21:25:28,569 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58696 |  0.00427 |    0.38815 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15527 | -0.00188 |    0.09359 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15630 | -0.00009 |    0.10842 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19729 | -0.02010 |    0.14061 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19380 | -0.01329 |    0.14408 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19730 | -0.02719 |    0.14424 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17679 |  0.00088 |    0.12888 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21322 | -0.00879 |    0.15530 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18059 | -0.00659 |    0.13775 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39379 | -0.02026 |    0.27939 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15639 | -0.01005 |    0.12032 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13790 | -0.00732 |    0.10867 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15428 | -0.02220 |    0.12197 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12252 | -0.00233 |    0.09501 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15402 | -0.01517 |    0.12249 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13897 | -0.01085 |    0.10990 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21218 | -0.02298 |    0.16580 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13623 | -0.01460 |    0.10758 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10163 | -0.00344 |    0.07687 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07472 | -0.00484 |    0.05687 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05797 | -0.00412 |    0.04226 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59121 | -0.00000 |    0.46438 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:25:28,569 - Total sparsity: 0.00

2018-11-02 21:25:28,569 - --- validate (epoch=63)-----------
2018-11-02 21:25:28,569 - 10000 samples (128 per mini-batch)
2018-11-02 21:25:29,296 - Epoch: [63][   50/   78]    Loss 0.523905    Top1 83.140625    Top5 99.281250    
2018-11-02 21:25:29,688 - ==> Top1: 83.170    Top5: 99.270    Loss: 0.518

2018-11-02 21:25:29,689 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:25:29,689 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:25:29,701 - 

2018-11-02 21:25:29,701 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:25:30,899 - Epoch: [64][   50/  391]    Overall Loss 0.349117    Objective Loss 0.349117    Top1 88.140625    Top5 99.640625    LR 0.300000    Time 0.023921    
2018-11-02 21:25:32,040 - Epoch: [64][  100/  391]    Overall Loss 0.355823    Objective Loss 0.355823    Top1 87.789062    Top5 99.585938    LR 0.300000    Time 0.023354    
2018-11-02 21:25:33,181 - Epoch: [64][  150/  391]    Overall Loss 0.362368    Objective Loss 0.362368    Top1 87.489583    Top5 99.583333    LR 0.300000    Time 0.023167    
2018-11-02 21:25:34,323 - Epoch: [64][  200/  391]    Overall Loss 0.362702    Objective Loss 0.362702    Top1 87.484375    Top5 99.566406    LR 0.300000    Time 0.023076    
2018-11-02 21:25:35,465 - Epoch: [64][  250/  391]    Overall Loss 0.360772    Objective Loss 0.360772    Top1 87.571875    Top5 99.568750    LR 0.300000    Time 0.023024    
2018-11-02 21:25:36,605 - Epoch: [64][  300/  391]    Overall Loss 0.359008    Objective Loss 0.359008    Top1 87.710938    Top5 99.567708    LR 0.300000    Time 0.022984    
2018-11-02 21:25:37,748 - Epoch: [64][  350/  391]    Overall Loss 0.359938    Objective Loss 0.359938    Top1 87.658482    Top5 99.587054    LR 0.300000    Time 0.022961    
2018-11-02 21:25:38,764 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58403 | -0.00430 |    0.38605 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15536 | -0.00443 |    0.09306 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15636 | -0.00287 |    0.10863 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19721 | -0.01954 |    0.13984 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19486 | -0.01028 |    0.14586 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19596 | -0.02777 |    0.14339 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17628 |  0.00273 |    0.12857 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21273 | -0.00765 |    0.15539 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18023 | -0.00716 |    0.13764 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39422 | -0.01831 |    0.27581 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15689 | -0.01028 |    0.12054 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13838 | -0.00780 |    0.10905 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15405 | -0.02323 |    0.12202 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12253 | -0.00241 |    0.09535 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15373 | -0.01541 |    0.12244 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13891 | -0.01078 |    0.10976 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21272 | -0.02371 |    0.16571 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13624 | -0.01406 |    0.10732 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10140 | -0.00283 |    0.07680 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07496 | -0.00533 |    0.05720 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05803 | -0.00439 |    0.04236 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59209 | -0.00000 |    0.46396 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:25:38,765 - Total sparsity: 0.00

2018-11-02 21:25:38,765 - --- validate (epoch=64)-----------
2018-11-02 21:25:38,765 - 10000 samples (128 per mini-batch)
2018-11-02 21:25:39,493 - Epoch: [64][   50/   78]    Loss 0.494399    Top1 84.093750    Top5 99.109375    
2018-11-02 21:25:39,886 - ==> Top1: 84.130    Top5: 99.180    Loss: 0.489

2018-11-02 21:25:39,887 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:25:39,887 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:25:39,902 - 

2018-11-02 21:25:39,903 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:25:41,103 - Epoch: [65][   50/  391]    Overall Loss 0.369167    Objective Loss 0.369167    Top1 87.437500    Top5 99.562500    LR 0.300000    Time 0.023963    
2018-11-02 21:25:42,243 - Epoch: [65][  100/  391]    Overall Loss 0.358091    Objective Loss 0.358091    Top1 87.851562    Top5 99.601562    LR 0.300000    Time 0.023365    
2018-11-02 21:25:43,387 - Epoch: [65][  150/  391]    Overall Loss 0.363735    Objective Loss 0.363735    Top1 87.541667    Top5 99.552083    LR 0.300000    Time 0.023195    
2018-11-02 21:25:44,525 - Epoch: [65][  200/  391]    Overall Loss 0.371441    Objective Loss 0.371441    Top1 87.304688    Top5 99.519531    LR 0.300000    Time 0.023080    
2018-11-02 21:25:45,667 - Epoch: [65][  250/  391]    Overall Loss 0.376880    Objective Loss 0.376880    Top1 87.128125    Top5 99.506250    LR 0.300000    Time 0.023027    
2018-11-02 21:25:46,808 - Epoch: [65][  300/  391]    Overall Loss 0.371513    Objective Loss 0.371513    Top1 87.320312    Top5 99.526042    LR 0.300000    Time 0.022988    
2018-11-02 21:25:47,949 - Epoch: [65][  350/  391]    Overall Loss 0.369808    Objective Loss 0.369808    Top1 87.383929    Top5 99.540179    LR 0.300000    Time 0.022961    
2018-11-02 21:25:48,972 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58278 | -0.00017 |    0.38461 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15441 | -0.00016 |    0.09280 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15647 | -0.00362 |    0.10858 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19668 | -0.02091 |    0.13850 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19537 | -0.00417 |    0.14638 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19648 | -0.02902 |    0.14515 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17652 |  0.00037 |    0.12823 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21266 | -0.00940 |    0.15447 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18001 | -0.00631 |    0.13764 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39523 | -0.01706 |    0.27385 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15665 | -0.00956 |    0.12003 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13864 | -0.00752 |    0.10931 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15428 | -0.02211 |    0.12170 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12220 | -0.00273 |    0.09483 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15350 | -0.01517 |    0.12217 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13878 | -0.01078 |    0.10976 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21219 | -0.02385 |    0.16689 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13605 | -0.01465 |    0.10737 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10137 | -0.00305 |    0.07692 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07509 | -0.00467 |    0.05714 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05790 | -0.00407 |    0.04218 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59140 | -0.00000 |    0.46487 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:25:48,972 - Total sparsity: 0.00

2018-11-02 21:25:48,972 - --- validate (epoch=65)-----------
2018-11-02 21:25:48,972 - 10000 samples (128 per mini-batch)
2018-11-02 21:25:49,699 - Epoch: [65][   50/   78]    Loss 0.601330    Top1 80.781250    Top5 98.281250    
2018-11-02 21:25:50,095 - ==> Top1: 80.290    Top5: 98.440    Loss: 0.608

2018-11-02 21:25:50,096 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 21:25:50,096 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:25:50,107 - 

2018-11-02 21:25:50,108 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:25:51,306 - Epoch: [66][   50/  391]    Overall Loss 0.343766    Objective Loss 0.343766    Top1 88.125000    Top5 99.796875    LR 0.300000    Time 0.023942    
2018-11-02 21:25:52,447 - Epoch: [66][  100/  391]    Overall Loss 0.354052    Objective Loss 0.354052    Top1 87.835938    Top5 99.671875    LR 0.300000    Time 0.023363    
2018-11-02 21:25:53,591 - Epoch: [66][  150/  391]    Overall Loss 0.356267    Objective Loss 0.356267    Top1 87.807292    Top5 99.656250    LR 0.300000    Time 0.023191    
2018-11-02 21:25:54,735 - Epoch: [66][  200/  391]    Overall Loss 0.359005    Objective Loss 0.359005    Top1 87.675781    Top5 99.628906    LR 0.300000    Time 0.023105    
2018-11-02 21:25:55,878 - Epoch: [66][  250/  391]    Overall Loss 0.359086    Objective Loss 0.359086    Top1 87.615625    Top5 99.603125    LR 0.300000    Time 0.023050    
2018-11-02 21:25:57,019 - Epoch: [66][  300/  391]    Overall Loss 0.363042    Objective Loss 0.363042    Top1 87.432292    Top5 99.580729    LR 0.300000    Time 0.023009    
2018-11-02 21:25:58,161 - Epoch: [66][  350/  391]    Overall Loss 0.363990    Objective Loss 0.363990    Top1 87.363839    Top5 99.578125    LR 0.300000    Time 0.022979    
2018-11-02 21:25:59,180 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57975 |  0.00670 |    0.38739 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15473 | -0.00110 |    0.09408 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15663 | -0.00440 |    0.10921 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19591 | -0.02009 |    0.13862 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19543 | -0.01106 |    0.14594 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19800 | -0.02866 |    0.14625 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17718 | -0.00002 |    0.12798 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21229 | -0.00911 |    0.15536 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17920 | -0.00640 |    0.13706 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39750 | -0.01286 |    0.27647 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15665 | -0.00927 |    0.11985 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13856 | -0.00793 |    0.10893 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15342 | -0.02206 |    0.12130 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12187 | -0.00223 |    0.09468 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15328 | -0.01524 |    0.12195 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13849 | -0.01108 |    0.10969 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21296 | -0.02223 |    0.16632 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13585 | -0.01487 |    0.10723 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10152 | -0.00308 |    0.07696 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07539 | -0.00512 |    0.05735 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05818 | -0.00380 |    0.04237 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59186 | -0.00000 |    0.46510 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:25:59,180 - Total sparsity: 0.00

2018-11-02 21:25:59,180 - --- validate (epoch=66)-----------
2018-11-02 21:25:59,180 - 10000 samples (128 per mini-batch)
2018-11-02 21:25:59,911 - Epoch: [66][   50/   78]    Loss 0.458660    Top1 84.984375    Top5 99.125000    
2018-11-02 21:26:00,307 - ==> Top1: 84.880    Top5: 99.160    Loss: 0.453

2018-11-02 21:26:00,307 - ==> Best Top1: 84.880   On Epoch: 66

2018-11-02 21:26:00,307 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:26:00,319 - 

2018-11-02 21:26:00,319 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:26:01,521 - Epoch: [67][   50/  391]    Overall Loss 0.337491    Objective Loss 0.337491    Top1 88.375000    Top5 99.671875    LR 0.300000    Time 0.023985    
2018-11-02 21:26:02,661 - Epoch: [67][  100/  391]    Overall Loss 0.345358    Objective Loss 0.345358    Top1 88.218750    Top5 99.609375    LR 0.300000    Time 0.023382    
2018-11-02 21:26:03,801 - Epoch: [67][  150/  391]    Overall Loss 0.358755    Objective Loss 0.358755    Top1 87.807292    Top5 99.593750    LR 0.300000    Time 0.023182    
2018-11-02 21:26:04,941 - Epoch: [67][  200/  391]    Overall Loss 0.358570    Objective Loss 0.358570    Top1 87.761719    Top5 99.613281    LR 0.300000    Time 0.023061    
2018-11-02 21:26:06,082 - Epoch: [67][  250/  391]    Overall Loss 0.359954    Objective Loss 0.359954    Top1 87.659375    Top5 99.615625    LR 0.300000    Time 0.023006    
2018-11-02 21:26:07,226 - Epoch: [67][  300/  391]    Overall Loss 0.361223    Objective Loss 0.361223    Top1 87.601562    Top5 99.611979    LR 0.300000    Time 0.022980    
2018-11-02 21:26:08,368 - Epoch: [67][  350/  391]    Overall Loss 0.362151    Objective Loss 0.362151    Top1 87.589286    Top5 99.580357    LR 0.300000    Time 0.022956    
2018-11-02 21:26:09,390 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57514 | -0.00033 |    0.38347 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15476 | -0.00029 |    0.09466 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15626 | -0.00242 |    0.10964 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19468 | -0.02187 |    0.13805 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19475 | -0.01166 |    0.14604 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19899 | -0.02695 |    0.14585 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17768 | -0.00091 |    0.12841 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21260 | -0.01018 |    0.15446 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17897 | -0.00633 |    0.13672 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39581 | -0.00919 |    0.27439 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15646 | -0.00953 |    0.11971 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13804 | -0.00851 |    0.10829 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15311 | -0.02235 |    0.12107 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12229 | -0.00206 |    0.09517 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15316 | -0.01500 |    0.12163 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13846 | -0.01039 |    0.10939 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21248 | -0.02115 |    0.16607 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13564 | -0.01451 |    0.10704 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10150 | -0.00282 |    0.07712 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07566 | -0.00530 |    0.05755 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05826 | -0.00362 |    0.04230 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59383 | -0.00000 |    0.46723 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:26:09,390 - Total sparsity: 0.00

2018-11-02 21:26:09,390 - --- validate (epoch=67)-----------
2018-11-02 21:26:09,390 - 10000 samples (128 per mini-batch)
2018-11-02 21:26:10,119 - Epoch: [67][   50/   78]    Loss 0.662499    Top1 80.062500    Top5 98.593750    
2018-11-02 21:26:10,519 - ==> Top1: 80.080    Top5: 98.690    Loss: 0.653

2018-11-02 21:26:10,520 - ==> Best Top1: 84.880   On Epoch: 66

2018-11-02 21:26:10,520 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:26:10,528 - 

2018-11-02 21:26:10,529 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:26:11,726 - Epoch: [68][   50/  391]    Overall Loss 0.378479    Objective Loss 0.378479    Top1 86.640625    Top5 99.609375    LR 0.300000    Time 0.023920    
2018-11-02 21:26:12,866 - Epoch: [68][  100/  391]    Overall Loss 0.375701    Objective Loss 0.375701    Top1 86.976562    Top5 99.609375    LR 0.300000    Time 0.023347    
2018-11-02 21:26:14,009 - Epoch: [68][  150/  391]    Overall Loss 0.367333    Objective Loss 0.367333    Top1 87.390625    Top5 99.567708    LR 0.300000    Time 0.023174    
2018-11-02 21:26:15,152 - Epoch: [68][  200/  391]    Overall Loss 0.356960    Objective Loss 0.356960    Top1 87.738281    Top5 99.617188    LR 0.300000    Time 0.023086    
2018-11-02 21:26:16,296 - Epoch: [68][  250/  391]    Overall Loss 0.361419    Objective Loss 0.361419    Top1 87.596875    Top5 99.590625    LR 0.300000    Time 0.023042    
2018-11-02 21:26:17,439 - Epoch: [68][  300/  391]    Overall Loss 0.364162    Objective Loss 0.364162    Top1 87.518229    Top5 99.559896    LR 0.300000    Time 0.023007    
2018-11-02 21:26:18,581 - Epoch: [68][  350/  391]    Overall Loss 0.366617    Objective Loss 0.366617    Top1 87.430804    Top5 99.551339    LR 0.300000    Time 0.022979    
2018-11-02 21:26:19,602 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57644 | -0.00715 |    0.38454 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15504 | -0.00457 |    0.09465 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15627 | -0.00132 |    0.10911 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19362 | -0.02205 |    0.13696 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19504 | -0.00823 |    0.14563 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19860 | -0.02575 |    0.14620 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17696 |  0.00082 |    0.12832 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21274 | -0.00791 |    0.15393 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17929 | -0.00524 |    0.13740 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39388 | -0.00714 |    0.27033 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15675 | -0.01057 |    0.12063 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13827 | -0.00841 |    0.10898 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15268 | -0.02177 |    0.12010 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12187 | -0.00169 |    0.09508 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15333 | -0.01428 |    0.12197 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13872 | -0.01040 |    0.10984 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21372 | -0.02379 |    0.16716 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13600 | -0.01513 |    0.10734 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10195 | -0.00297 |    0.07737 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07641 | -0.00544 |    0.05817 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05881 | -0.00363 |    0.04272 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59265 | -0.00000 |    0.46500 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:26:19,602 - Total sparsity: 0.00

2018-11-02 21:26:19,602 - --- validate (epoch=68)-----------
2018-11-02 21:26:19,602 - 10000 samples (128 per mini-batch)
2018-11-02 21:26:20,330 - Epoch: [68][   50/   78]    Loss 0.687742    Top1 78.781250    Top5 98.593750    
2018-11-02 21:26:20,724 - ==> Top1: 78.560    Top5: 98.730    Loss: 0.691

2018-11-02 21:26:20,725 - ==> Best Top1: 84.880   On Epoch: 66

2018-11-02 21:26:20,725 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:26:20,734 - 

2018-11-02 21:26:20,734 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:26:21,930 - Epoch: [69][   50/  391]    Overall Loss 0.326471    Objective Loss 0.326471    Top1 88.640625    Top5 99.656250    LR 0.300000    Time 0.023895    
2018-11-02 21:26:23,072 - Epoch: [69][  100/  391]    Overall Loss 0.336309    Objective Loss 0.336309    Top1 88.414062    Top5 99.593750    LR 0.300000    Time 0.023348    
2018-11-02 21:26:24,214 - Epoch: [69][  150/  391]    Overall Loss 0.349757    Objective Loss 0.349757    Top1 87.989583    Top5 99.604167    LR 0.300000    Time 0.023173    
2018-11-02 21:26:25,356 - Epoch: [69][  200/  391]    Overall Loss 0.352988    Objective Loss 0.352988    Top1 87.804688    Top5 99.593750    LR 0.300000    Time 0.023082    
2018-11-02 21:26:26,498 - Epoch: [69][  250/  391]    Overall Loss 0.353973    Objective Loss 0.353973    Top1 87.771875    Top5 99.584375    LR 0.300000    Time 0.023025    
2018-11-02 21:26:27,639 - Epoch: [69][  300/  391]    Overall Loss 0.357665    Objective Loss 0.357665    Top1 87.718750    Top5 99.580729    LR 0.300000    Time 0.022988    
2018-11-02 21:26:28,782 - Epoch: [69][  350/  391]    Overall Loss 0.360153    Objective Loss 0.360153    Top1 87.660714    Top5 99.569196    LR 0.300000    Time 0.022964    
2018-11-02 21:26:29,798 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57501 |  0.00128 |    0.38394 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15465 | -0.00407 |    0.09430 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15573 | -0.00314 |    0.10886 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19269 | -0.02058 |    0.13592 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19492 | -0.01115 |    0.14576 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19840 | -0.02967 |    0.14578 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17718 |  0.00056 |    0.12795 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21220 | -0.00878 |    0.15411 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17931 | -0.00550 |    0.13743 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39264 | -0.01396 |    0.27146 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15701 | -0.01006 |    0.12049 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13836 | -0.00879 |    0.10873 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15281 | -0.02416 |    0.12061 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12218 | -0.00114 |    0.09550 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15325 | -0.01475 |    0.12178 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13862 | -0.01095 |    0.10982 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21459 | -0.02263 |    0.16713 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13601 | -0.01443 |    0.10724 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10195 | -0.00332 |    0.07739 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07656 | -0.00583 |    0.05848 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05866 | -0.00408 |    0.04266 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58703 | -0.00000 |    0.46267 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:26:29,799 - Total sparsity: 0.00

2018-11-02 21:26:29,799 - --- validate (epoch=69)-----------
2018-11-02 21:26:29,799 - 10000 samples (128 per mini-batch)
2018-11-02 21:26:30,529 - Epoch: [69][   50/   78]    Loss 0.458947    Top1 85.031250    Top5 99.375000    
2018-11-02 21:26:30,927 - ==> Top1: 85.230    Top5: 99.410    Loss: 0.453

2018-11-02 21:26:30,928 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 21:26:30,928 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:26:30,947 - 

2018-11-02 21:26:30,947 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:26:32,115 - Epoch: [70][   50/  391]    Overall Loss 0.325120    Objective Loss 0.325120    Top1 88.734375    Top5 99.578125    LR 0.300000    Time 0.023339    
2018-11-02 21:26:33,256 - Epoch: [70][  100/  391]    Overall Loss 0.337656    Objective Loss 0.337656    Top1 88.468750    Top5 99.648438    LR 0.300000    Time 0.023057    
2018-11-02 21:26:34,397 - Epoch: [70][  150/  391]    Overall Loss 0.350805    Objective Loss 0.350805    Top1 87.880208    Top5 99.598958    LR 0.300000    Time 0.022972    
2018-11-02 21:26:35,540 - Epoch: [70][  200/  391]    Overall Loss 0.355499    Objective Loss 0.355499    Top1 87.769531    Top5 99.578125    LR 0.300000    Time 0.022935    
2018-11-02 21:26:36,682 - Epoch: [70][  250/  391]    Overall Loss 0.355922    Objective Loss 0.355922    Top1 87.728125    Top5 99.575000    LR 0.300000    Time 0.022913    
2018-11-02 21:26:37,827 - Epoch: [70][  300/  391]    Overall Loss 0.355059    Objective Loss 0.355059    Top1 87.750000    Top5 99.562500    LR 0.300000    Time 0.022904    
2018-11-02 21:26:38,968 - Epoch: [70][  350/  391]    Overall Loss 0.358405    Objective Loss 0.358405    Top1 87.700893    Top5 99.555804    LR 0.300000    Time 0.022880    
2018-11-02 21:26:39,987 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57385 |  0.00725 |    0.38208 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15461 | -0.00234 |    0.09461 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15590 | -0.00279 |    0.10895 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19146 | -0.02221 |    0.13489 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19465 | -0.01383 |    0.14558 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19804 | -0.02797 |    0.14568 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17671 |  0.00098 |    0.12629 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21246 | -0.00873 |    0.15508 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17953 | -0.00551 |    0.13795 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39129 | -0.01571 |    0.27173 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15645 | -0.00895 |    0.11991 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13791 | -0.00769 |    0.10810 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15311 | -0.02373 |    0.12080 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12224 | -0.00195 |    0.09526 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15293 | -0.01448 |    0.12151 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13836 | -0.01073 |    0.10941 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21315 | -0.02434 |    0.16728 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13567 | -0.01477 |    0.10697 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10199 | -0.00369 |    0.07749 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07700 | -0.00591 |    0.05884 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05871 | -0.00364 |    0.04262 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58745 | -0.00000 |    0.46265 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:26:39,987 - Total sparsity: 0.00

2018-11-02 21:26:39,987 - --- validate (epoch=70)-----------
2018-11-02 21:26:39,987 - 10000 samples (128 per mini-batch)
2018-11-02 21:26:40,715 - Epoch: [70][   50/   78]    Loss 0.529082    Top1 83.062500    Top5 99.125000    
2018-11-02 21:26:41,111 - ==> Top1: 82.880    Top5: 99.160    Loss: 0.548

2018-11-02 21:26:41,112 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 21:26:41,112 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:26:41,124 - 

2018-11-02 21:26:41,124 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:26:42,320 - Epoch: [71][   50/  391]    Overall Loss 0.324568    Objective Loss 0.324568    Top1 88.437500    Top5 99.593750    LR 0.300000    Time 0.023883    
2018-11-02 21:26:43,460 - Epoch: [71][  100/  391]    Overall Loss 0.341827    Objective Loss 0.341827    Top1 88.023438    Top5 99.585938    LR 0.300000    Time 0.023331    
2018-11-02 21:26:44,598 - Epoch: [71][  150/  391]    Overall Loss 0.358082    Objective Loss 0.358082    Top1 87.562500    Top5 99.520833    LR 0.300000    Time 0.023131    
2018-11-02 21:26:45,738 - Epoch: [71][  200/  391]    Overall Loss 0.356161    Objective Loss 0.356161    Top1 87.609375    Top5 99.542969    LR 0.300000    Time 0.023043    
2018-11-02 21:26:46,879 - Epoch: [71][  250/  391]    Overall Loss 0.367224    Objective Loss 0.367224    Top1 87.256250    Top5 99.493750    LR 0.300000    Time 0.022990    
2018-11-02 21:26:48,020 - Epoch: [71][  300/  391]    Overall Loss 0.365446    Objective Loss 0.365446    Top1 87.309896    Top5 99.515625    LR 0.300000    Time 0.022958    
2018-11-02 21:26:49,161 - Epoch: [71][  350/  391]    Overall Loss 0.366375    Objective Loss 0.366375    Top1 87.339286    Top5 99.520089    LR 0.300000    Time 0.022933    
2018-11-02 21:26:50,174 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57406 |  0.00403 |    0.38070 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15404 | -0.00388 |    0.09330 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15581 | -0.00108 |    0.10828 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19116 | -0.02068 |    0.13523 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19466 | -0.01146 |    0.14642 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19880 | -0.03308 |    0.14700 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17707 |  0.00280 |    0.12699 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21237 | -0.00947 |    0.15477 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17905 | -0.00555 |    0.13781 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39311 | -0.01410 |    0.27385 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15653 | -0.01030 |    0.12007 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13738 | -0.00807 |    0.10780 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15272 | -0.02494 |    0.12080 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12236 | -0.00006 |    0.09532 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15275 | -0.01437 |    0.12158 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13829 | -0.01013 |    0.10944 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21407 | -0.02409 |    0.16866 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13600 | -0.01504 |    0.10717 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10221 | -0.00372 |    0.07783 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07766 | -0.00570 |    0.05937 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05920 | -0.00380 |    0.04302 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58744 | -0.00000 |    0.46199 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:26:50,175 - Total sparsity: 0.00

2018-11-02 21:26:50,175 - --- validate (epoch=71)-----------
2018-11-02 21:26:50,175 - 10000 samples (128 per mini-batch)
2018-11-02 21:26:50,906 - Epoch: [71][   50/   78]    Loss 0.791164    Top1 78.718750    Top5 98.218750    
2018-11-02 21:26:51,303 - ==> Top1: 78.440    Top5: 98.470    Loss: 0.784

2018-11-02 21:26:51,304 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 21:26:51,304 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:26:51,312 - 

2018-11-02 21:26:51,312 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:26:52,509 - Epoch: [72][   50/  391]    Overall Loss 0.349584    Objective Loss 0.349584    Top1 87.875000    Top5 99.562500    LR 0.300000    Time 0.023911    
2018-11-02 21:26:53,650 - Epoch: [72][  100/  391]    Overall Loss 0.355217    Objective Loss 0.355217    Top1 87.718750    Top5 99.578125    LR 0.300000    Time 0.023346    
2018-11-02 21:26:54,790 - Epoch: [72][  150/  391]    Overall Loss 0.358645    Objective Loss 0.358645    Top1 87.682292    Top5 99.583333    LR 0.300000    Time 0.023159    
2018-11-02 21:26:55,934 - Epoch: [72][  200/  391]    Overall Loss 0.364239    Objective Loss 0.364239    Top1 87.480469    Top5 99.535156    LR 0.300000    Time 0.023064    
2018-11-02 21:26:57,074 - Epoch: [72][  250/  391]    Overall Loss 0.362750    Objective Loss 0.362750    Top1 87.565625    Top5 99.556250    LR 0.300000    Time 0.023005    
2018-11-02 21:26:58,217 - Epoch: [72][  300/  391]    Overall Loss 0.359024    Objective Loss 0.359024    Top1 87.640625    Top5 99.580729    LR 0.300000    Time 0.022974    
2018-11-02 21:26:59,358 - Epoch: [72][  350/  391]    Overall Loss 0.360906    Objective Loss 0.360906    Top1 87.584821    Top5 99.573661    LR 0.300000    Time 0.022949    
2018-11-02 21:27:00,376 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57610 | -0.00670 |    0.38467 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15530 | -0.00328 |    0.09393 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15741 | -0.00066 |    0.10932 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19249 | -0.01963 |    0.13773 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19560 | -0.01332 |    0.14750 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19996 | -0.02826 |    0.14797 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17853 |  0.00154 |    0.12889 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21301 | -0.00844 |    0.15550 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17932 | -0.00613 |    0.13809 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39352 | -0.01773 |    0.27574 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15665 | -0.00958 |    0.11987 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13703 | -0.01024 |    0.10771 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15402 | -0.02459 |    0.12167 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12293 | -0.00050 |    0.09578 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15303 | -0.01510 |    0.12168 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13820 | -0.01032 |    0.10929 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21387 | -0.02425 |    0.16881 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01468 |    0.10707 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10225 | -0.00391 |    0.07785 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07814 | -0.00549 |    0.05975 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05936 | -0.00382 |    0.04307 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58326 | -0.00000 |    0.45963 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:27:00,376 - Total sparsity: 0.00

2018-11-02 21:27:00,376 - --- validate (epoch=72)-----------
2018-11-02 21:27:00,376 - 10000 samples (128 per mini-batch)
2018-11-02 21:27:01,113 - Epoch: [72][   50/   78]    Loss 0.530105    Top1 83.656250    Top5 98.828125    
2018-11-02 21:27:01,529 - ==> Top1: 83.680    Top5: 98.900    Loss: 0.528

2018-11-02 21:27:01,530 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 21:27:01,530 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:27:01,538 - 

2018-11-02 21:27:01,538 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:27:02,736 - Epoch: [73][   50/  391]    Overall Loss 0.353449    Objective Loss 0.353449    Top1 87.625000    Top5 99.609375    LR 0.300000    Time 0.023915    
2018-11-02 21:27:03,877 - Epoch: [73][  100/  391]    Overall Loss 0.363672    Objective Loss 0.363672    Top1 87.429688    Top5 99.601562    LR 0.300000    Time 0.023358    
2018-11-02 21:27:05,019 - Epoch: [73][  150/  391]    Overall Loss 0.366192    Objective Loss 0.366192    Top1 87.307292    Top5 99.588542    LR 0.300000    Time 0.023175    
2018-11-02 21:27:06,161 - Epoch: [73][  200/  391]    Overall Loss 0.368148    Objective Loss 0.368148    Top1 87.156250    Top5 99.613281    LR 0.300000    Time 0.023084    
2018-11-02 21:27:07,304 - Epoch: [73][  250/  391]    Overall Loss 0.368611    Objective Loss 0.368611    Top1 87.193750    Top5 99.587500    LR 0.300000    Time 0.023032    
2018-11-02 21:27:08,446 - Epoch: [73][  300/  391]    Overall Loss 0.372394    Objective Loss 0.372394    Top1 87.101562    Top5 99.567708    LR 0.300000    Time 0.022997    
2018-11-02 21:27:09,588 - Epoch: [73][  350/  391]    Overall Loss 0.372888    Objective Loss 0.372888    Top1 87.189732    Top5 99.562500    LR 0.300000    Time 0.022970    
2018-11-02 21:27:10,609 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57881 | -0.00347 |    0.38552 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15833 | -0.00077 |    0.09631 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15940 | -0.00048 |    0.11138 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19512 | -0.01890 |    0.14052 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19710 | -0.01235 |    0.14767 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19998 | -0.02794 |    0.14780 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17901 |  0.00203 |    0.12883 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21377 | -0.00915 |    0.15572 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17960 | -0.00612 |    0.13760 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39349 | -0.01861 |    0.27337 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15692 | -0.00932 |    0.11983 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13742 | -0.00987 |    0.10795 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15469 | -0.02396 |    0.12212 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12276 | -0.00085 |    0.09542 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15319 | -0.01473 |    0.12160 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13837 | -0.01090 |    0.10949 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21492 | -0.02411 |    0.16857 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13632 | -0.01478 |    0.10708 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10277 | -0.00376 |    0.07836 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07921 | -0.00572 |    0.06058 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06001 | -0.00383 |    0.04361 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58623 | -0.00000 |    0.46236 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:27:10,609 - Total sparsity: 0.00

2018-11-02 21:27:10,609 - --- validate (epoch=73)-----------
2018-11-02 21:27:10,609 - 10000 samples (128 per mini-batch)
2018-11-02 21:27:11,335 - Epoch: [73][   50/   78]    Loss 0.569891    Top1 82.406250    Top5 99.015625    
2018-11-02 21:27:11,731 - ==> Top1: 82.220    Top5: 99.060    Loss: 0.561

2018-11-02 21:27:11,732 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 21:27:11,732 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:27:11,740 - 

2018-11-02 21:27:11,741 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:27:12,941 - Epoch: [74][   50/  391]    Overall Loss 0.344257    Objective Loss 0.344257    Top1 87.796875    Top5 99.562500    LR 0.300000    Time 0.023970    
2018-11-02 21:27:14,082 - Epoch: [74][  100/  391]    Overall Loss 0.353297    Objective Loss 0.353297    Top1 87.617188    Top5 99.554688    LR 0.300000    Time 0.023384    
2018-11-02 21:27:15,223 - Epoch: [74][  150/  391]    Overall Loss 0.352323    Objective Loss 0.352323    Top1 87.901042    Top5 99.526042    LR 0.300000    Time 0.023189    
2018-11-02 21:27:16,365 - Epoch: [74][  200/  391]    Overall Loss 0.353342    Objective Loss 0.353342    Top1 87.816406    Top5 99.546875    LR 0.300000    Time 0.023095    
2018-11-02 21:27:17,508 - Epoch: [74][  250/  391]    Overall Loss 0.359248    Objective Loss 0.359248    Top1 87.584375    Top5 99.553125    LR 0.300000    Time 0.023042    
2018-11-02 21:27:18,652 - Epoch: [74][  300/  391]    Overall Loss 0.361720    Objective Loss 0.361720    Top1 87.489583    Top5 99.567708    LR 0.300000    Time 0.023010    
2018-11-02 21:27:19,790 - Epoch: [74][  350/  391]    Overall Loss 0.368442    Objective Loss 0.368442    Top1 87.252232    Top5 99.569196    LR 0.300000    Time 0.022969    
2018-11-02 21:27:20,805 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58433 |  0.00515 |    0.38813 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16141 |  0.00051 |    0.09762 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16108 |  0.00274 |    0.11220 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19513 | -0.01765 |    0.13906 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19696 | -0.01302 |    0.14854 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19970 | -0.02870 |    0.14760 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17940 |  0.00114 |    0.12928 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21475 | -0.00962 |    0.15668 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17990 | -0.00557 |    0.13809 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39532 | -0.01415 |    0.27548 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15644 | -0.01022 |    0.11963 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13738 | -0.00869 |    0.10798 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15496 | -0.02378 |    0.12218 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12266 | -0.00025 |    0.09544 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15337 | -0.01454 |    0.12161 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13857 | -0.01082 |    0.10951 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21523 | -0.02323 |    0.16936 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13629 | -0.01497 |    0.10747 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10287 | -0.00354 |    0.07835 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07990 | -0.00603 |    0.06100 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06053 | -0.00408 |    0.04396 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58704 | -0.00000 |    0.46274 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:27:20,805 - Total sparsity: 0.00

2018-11-02 21:27:20,806 - --- validate (epoch=74)-----------
2018-11-02 21:27:20,806 - 10000 samples (128 per mini-batch)
2018-11-02 21:27:21,541 - Epoch: [74][   50/   78]    Loss 0.432354    Top1 85.656250    Top5 99.234375    
2018-11-02 21:27:21,937 - ==> Top1: 85.560    Top5: 99.280    Loss: 0.433

2018-11-02 21:27:21,938 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:27:21,938 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:27:21,950 - 

2018-11-02 21:27:21,950 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:27:23,148 - Epoch: [75][   50/  391]    Overall Loss 0.331911    Objective Loss 0.331911    Top1 88.671875    Top5 99.640625    LR 0.300000    Time 0.023925    
2018-11-02 21:27:24,289 - Epoch: [75][  100/  391]    Overall Loss 0.337037    Objective Loss 0.337037    Top1 88.414062    Top5 99.570312    LR 0.300000    Time 0.023357    
2018-11-02 21:27:25,430 - Epoch: [75][  150/  391]    Overall Loss 0.349491    Objective Loss 0.349491    Top1 88.104167    Top5 99.520833    LR 0.300000    Time 0.023166    
2018-11-02 21:27:26,571 - Epoch: [75][  200/  391]    Overall Loss 0.351721    Objective Loss 0.351721    Top1 88.101562    Top5 99.527344    LR 0.300000    Time 0.023073    
2018-11-02 21:27:27,711 - Epoch: [75][  250/  391]    Overall Loss 0.355358    Objective Loss 0.355358    Top1 87.946875    Top5 99.540625    LR 0.300000    Time 0.023012    
2018-11-02 21:27:28,850 - Epoch: [75][  300/  391]    Overall Loss 0.356682    Objective Loss 0.356682    Top1 87.856771    Top5 99.533854    LR 0.300000    Time 0.022957    
2018-11-02 21:27:29,988 - Epoch: [75][  350/  391]    Overall Loss 0.358344    Objective Loss 0.358344    Top1 87.810268    Top5 99.540179    LR 0.300000    Time 0.022924    
2018-11-02 21:27:31,004 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58032 | -0.01009 |    0.38514 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16190 | -0.00036 |    0.09785 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16170 | -0.00128 |    0.11247 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19531 | -0.01723 |    0.13994 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19738 | -0.00995 |    0.14855 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20022 | -0.03103 |    0.14813 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17922 |  0.00332 |    0.12921 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21408 | -0.01155 |    0.15763 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17924 | -0.00625 |    0.13771 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39389 | -0.01008 |    0.27173 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15585 | -0.00984 |    0.11896 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13683 | -0.00845 |    0.10759 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15492 | -0.02387 |    0.12215 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12309 | -0.00090 |    0.09559 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15318 | -0.01452 |    0.12150 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13858 | -0.01047 |    0.10963 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21375 | -0.02221 |    0.16738 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13598 | -0.01467 |    0.10717 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10266 | -0.00380 |    0.07824 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07990 | -0.00614 |    0.06103 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06040 | -0.00367 |    0.04381 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58471 | -0.00000 |    0.45890 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:27:31,004 - Total sparsity: 0.00

2018-11-02 21:27:31,004 - --- validate (epoch=75)-----------
2018-11-02 21:27:31,005 - 10000 samples (128 per mini-batch)
2018-11-02 21:27:31,733 - Epoch: [75][   50/   78]    Loss 0.589786    Top1 81.781250    Top5 98.796875    
2018-11-02 21:27:32,127 - ==> Top1: 81.830    Top5: 98.820    Loss: 0.585

2018-11-02 21:27:32,127 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:27:32,127 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:27:32,139 - 

2018-11-02 21:27:32,140 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:27:33,338 - Epoch: [76][   50/  391]    Overall Loss 0.361537    Objective Loss 0.361537    Top1 87.531250    Top5 99.640625    LR 0.300000    Time 0.023929    
2018-11-02 21:27:34,478 - Epoch: [76][  100/  391]    Overall Loss 0.360168    Objective Loss 0.360168    Top1 87.609375    Top5 99.484375    LR 0.300000    Time 0.023347    
2018-11-02 21:27:35,618 - Epoch: [76][  150/  391]    Overall Loss 0.364459    Objective Loss 0.364459    Top1 87.463542    Top5 99.531250    LR 0.300000    Time 0.023156    
2018-11-02 21:27:36,758 - Epoch: [76][  200/  391]    Overall Loss 0.361261    Objective Loss 0.361261    Top1 87.691406    Top5 99.523438    LR 0.300000    Time 0.023063    
2018-11-02 21:27:37,900 - Epoch: [76][  250/  391]    Overall Loss 0.362021    Objective Loss 0.362021    Top1 87.681250    Top5 99.509375    LR 0.300000    Time 0.023011    
2018-11-02 21:27:39,044 - Epoch: [76][  300/  391]    Overall Loss 0.366297    Objective Loss 0.366297    Top1 87.437500    Top5 99.507812    LR 0.300000    Time 0.022978    
2018-11-02 21:27:40,183 - Epoch: [76][  350/  391]    Overall Loss 0.362800    Objective Loss 0.362800    Top1 87.566964    Top5 99.500000    LR 0.300000    Time 0.022948    
2018-11-02 21:27:41,200 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58279 |  0.00175 |    0.38537 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16204 | -0.00176 |    0.09742 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16130 | -0.00379 |    0.11198 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19543 | -0.02010 |    0.13981 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19779 | -0.00854 |    0.14839 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20070 | -0.02928 |    0.14789 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17910 |  0.00454 |    0.12906 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21518 | -0.00948 |    0.15734 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18001 | -0.00674 |    0.13829 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39509 | -0.00887 |    0.27390 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15605 | -0.00902 |    0.11905 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.00944 |    0.10779 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15562 | -0.02253 |    0.12237 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12314 | -0.00207 |    0.09595 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15289 | -0.01498 |    0.12146 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13863 | -0.01055 |    0.10976 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21397 | -0.02355 |    0.16751 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13628 | -0.01469 |    0.10749 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10278 | -0.00373 |    0.07841 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07985 | -0.00675 |    0.06121 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06036 | -0.00347 |    0.04387 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58190 | -0.00000 |    0.45844 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:27:41,200 - Total sparsity: 0.00

2018-11-02 21:27:41,200 - --- validate (epoch=76)-----------
2018-11-02 21:27:41,200 - 10000 samples (128 per mini-batch)
2018-11-02 21:27:41,924 - Epoch: [76][   50/   78]    Loss 0.784544    Top1 75.343750    Top5 97.875000    
2018-11-02 21:27:42,317 - ==> Top1: 75.490    Top5: 98.030    Loss: 0.773

2018-11-02 21:27:42,318 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:27:42,318 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:27:42,330 - 

2018-11-02 21:27:42,330 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:27:43,526 - Epoch: [77][   50/  391]    Overall Loss 0.352298    Objective Loss 0.352298    Top1 87.750000    Top5 99.625000    LR 0.300000    Time 0.023882    
2018-11-02 21:27:44,668 - Epoch: [77][  100/  391]    Overall Loss 0.340547    Objective Loss 0.340547    Top1 88.304688    Top5 99.656250    LR 0.300000    Time 0.023345    
2018-11-02 21:27:45,810 - Epoch: [77][  150/  391]    Overall Loss 0.339013    Objective Loss 0.339013    Top1 88.322917    Top5 99.697917    LR 0.300000    Time 0.023172    
2018-11-02 21:27:46,954 - Epoch: [77][  200/  391]    Overall Loss 0.350968    Objective Loss 0.350968    Top1 87.914062    Top5 99.636719    LR 0.300000    Time 0.023089    
2018-11-02 21:27:48,094 - Epoch: [77][  250/  391]    Overall Loss 0.360900    Objective Loss 0.360900    Top1 87.543750    Top5 99.603125    LR 0.300000    Time 0.023029    
2018-11-02 21:27:49,237 - Epoch: [77][  300/  391]    Overall Loss 0.362733    Objective Loss 0.362733    Top1 87.445312    Top5 99.585938    LR 0.300000    Time 0.022995    
2018-11-02 21:27:50,379 - Epoch: [77][  350/  391]    Overall Loss 0.363929    Objective Loss 0.363929    Top1 87.462054    Top5 99.578125    LR 0.300000    Time 0.022969    
2018-11-02 21:27:51,396 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57909 |  0.00588 |    0.38460 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16078 | -0.00324 |    0.09643 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16005 |  0.00053 |    0.11204 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19398 | -0.02128 |    0.13931 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19666 | -0.00821 |    0.14832 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19956 | -0.02931 |    0.14701 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17884 |  0.00428 |    0.12889 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21496 | -0.00881 |    0.15696 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18020 | -0.00556 |    0.13845 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39341 | -0.01198 |    0.26840 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15554 | -0.00993 |    0.11890 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13619 | -0.00837 |    0.10702 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15481 | -0.02399 |    0.12207 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12271 | -0.00132 |    0.09549 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15287 | -0.01518 |    0.12144 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13867 | -0.01061 |    0.10971 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21379 | -0.02268 |    0.16666 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13626 | -0.01476 |    0.10769 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10316 | -0.00389 |    0.07879 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08063 | -0.00600 |    0.06167 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06087 | -0.00347 |    0.04422 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58469 | -0.00000 |    0.45912 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:27:51,397 - Total sparsity: 0.00

2018-11-02 21:27:51,397 - --- validate (epoch=77)-----------
2018-11-02 21:27:51,397 - 10000 samples (128 per mini-batch)
2018-11-02 21:27:52,125 - Epoch: [77][   50/   78]    Loss 0.486990    Top1 83.828125    Top5 99.078125    
2018-11-02 21:27:52,522 - ==> Top1: 83.970    Top5: 99.110    Loss: 0.489

2018-11-02 21:27:52,523 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:27:52,523 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:27:52,531 - 

2018-11-02 21:27:52,532 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:27:53,728 - Epoch: [78][   50/  391]    Overall Loss 0.337259    Objective Loss 0.337259    Top1 88.125000    Top5 99.656250    LR 0.300000    Time 0.023896    
2018-11-02 21:27:54,869 - Epoch: [78][  100/  391]    Overall Loss 0.338134    Objective Loss 0.338134    Top1 88.359375    Top5 99.632812    LR 0.300000    Time 0.023345    
2018-11-02 21:27:56,011 - Epoch: [78][  150/  391]    Overall Loss 0.346158    Objective Loss 0.346158    Top1 88.093750    Top5 99.593750    LR 0.300000    Time 0.023165    
2018-11-02 21:27:57,151 - Epoch: [78][  200/  391]    Overall Loss 0.355771    Objective Loss 0.355771    Top1 87.718750    Top5 99.593750    LR 0.300000    Time 0.023067    
2018-11-02 21:27:58,293 - Epoch: [78][  250/  391]    Overall Loss 0.357283    Objective Loss 0.357283    Top1 87.706250    Top5 99.615625    LR 0.300000    Time 0.023016    
2018-11-02 21:27:59,434 - Epoch: [78][  300/  391]    Overall Loss 0.356687    Objective Loss 0.356687    Top1 87.697917    Top5 99.609375    LR 0.300000    Time 0.022981    
2018-11-02 21:28:00,576 - Epoch: [78][  350/  391]    Overall Loss 0.358765    Objective Loss 0.358765    Top1 87.582589    Top5 99.609375    LR 0.300000    Time 0.022955    
2018-11-02 21:28:01,595 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58133 |  0.00431 |    0.38169 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15976 | -0.00231 |    0.09663 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15990 |  0.00086 |    0.11172 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19361 | -0.02239 |    0.13801 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19669 | -0.00758 |    0.14827 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19825 | -0.02991 |    0.14493 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17847 |  0.00601 |    0.12782 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21455 | -0.00971 |    0.15643 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18003 | -0.00610 |    0.13824 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39424 | -0.01082 |    0.27064 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15534 | -0.00822 |    0.11845 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01005 |    0.10677 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15505 | -0.02382 |    0.12221 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12298 | -0.00146 |    0.09558 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15325 | -0.01462 |    0.12149 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13847 | -0.01078 |    0.10955 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21453 | -0.02130 |    0.16752 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13625 | -0.01423 |    0.10771 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10335 | -0.00401 |    0.07907 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08116 | -0.00618 |    0.06229 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06109 | -0.00337 |    0.04436 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58166 | -0.00000 |    0.45887 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:28:01,595 - Total sparsity: 0.00

2018-11-02 21:28:01,595 - --- validate (epoch=78)-----------
2018-11-02 21:28:01,596 - 10000 samples (128 per mini-batch)
2018-11-02 21:28:02,331 - Epoch: [78][   50/   78]    Loss 0.496168    Top1 83.312500    Top5 99.203125    
2018-11-02 21:28:02,728 - ==> Top1: 83.300    Top5: 99.290    Loss: 0.490

2018-11-02 21:28:02,729 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:28:02,729 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:28:02,738 - 

2018-11-02 21:28:02,738 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:28:03,935 - Epoch: [79][   50/  391]    Overall Loss 0.349152    Objective Loss 0.349152    Top1 88.171875    Top5 99.640625    LR 0.300000    Time 0.023900    
2018-11-02 21:28:05,074 - Epoch: [79][  100/  391]    Overall Loss 0.343227    Objective Loss 0.343227    Top1 88.125000    Top5 99.671875    LR 0.300000    Time 0.023332    
2018-11-02 21:28:06,216 - Epoch: [79][  150/  391]    Overall Loss 0.345369    Objective Loss 0.345369    Top1 88.093750    Top5 99.692708    LR 0.300000    Time 0.023158    
2018-11-02 21:28:07,356 - Epoch: [79][  200/  391]    Overall Loss 0.347544    Objective Loss 0.347544    Top1 88.089844    Top5 99.664062    LR 0.300000    Time 0.023060    
2018-11-02 21:28:08,498 - Epoch: [79][  250/  391]    Overall Loss 0.351265    Objective Loss 0.351265    Top1 87.968750    Top5 99.653125    LR 0.300000    Time 0.023010    
2018-11-02 21:28:09,641 - Epoch: [79][  300/  391]    Overall Loss 0.358217    Objective Loss 0.358217    Top1 87.760417    Top5 99.617188    LR 0.300000    Time 0.022981    
2018-11-02 21:28:10,783 - Epoch: [79][  350/  391]    Overall Loss 0.358434    Objective Loss 0.358434    Top1 87.747768    Top5 99.595982    LR 0.300000    Time 0.022958    
2018-11-02 21:28:11,802 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57744 | -0.01124 |    0.38679 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15759 |  0.00015 |    0.09600 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15889 | -0.00138 |    0.11180 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19380 | -0.02106 |    0.13850 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19648 | -0.00569 |    0.14732 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19842 | -0.02844 |    0.14523 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17830 |  0.00317 |    0.12824 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21429 | -0.01100 |    0.15608 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17957 | -0.00537 |    0.13786 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39381 | -0.01135 |    0.27250 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15566 | -0.00765 |    0.11888 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13643 | -0.01046 |    0.10715 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15474 | -0.02416 |    0.12155 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12272 | -0.00147 |    0.09513 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15285 | -0.01493 |    0.12105 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13844 | -0.01047 |    0.10950 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21515 | -0.02145 |    0.16889 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01514 |    0.10725 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10328 | -0.00391 |    0.07905 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08158 | -0.00616 |    0.06259 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06128 | -0.00274 |    0.04458 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58594 | -0.00000 |    0.46207 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:28:11,802 - Total sparsity: 0.00

2018-11-02 21:28:11,802 - --- validate (epoch=79)-----------
2018-11-02 21:28:11,802 - 10000 samples (128 per mini-batch)
2018-11-02 21:28:12,531 - Epoch: [79][   50/   78]    Loss 0.585901    Top1 83.015625    Top5 98.828125    
2018-11-02 21:28:12,927 - ==> Top1: 82.700    Top5: 98.960    Loss: 0.582

2018-11-02 21:28:12,928 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:28:12,928 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:28:12,936 - 

2018-11-02 21:28:12,937 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:28:14,133 - Epoch: [80][   50/  391]    Overall Loss 0.358028    Objective Loss 0.358028    Top1 88.093750    Top5 99.546875    LR 0.300000    Time 0.023899    
2018-11-02 21:28:15,275 - Epoch: [80][  100/  391]    Overall Loss 0.352480    Objective Loss 0.352480    Top1 87.992188    Top5 99.609375    LR 0.300000    Time 0.023351    
2018-11-02 21:28:16,416 - Epoch: [80][  150/  391]    Overall Loss 0.359773    Objective Loss 0.359773    Top1 87.583333    Top5 99.609375    LR 0.300000    Time 0.023163    
2018-11-02 21:28:17,558 - Epoch: [80][  200/  391]    Overall Loss 0.358910    Objective Loss 0.358910    Top1 87.578125    Top5 99.613281    LR 0.300000    Time 0.023076    
2018-11-02 21:28:18,699 - Epoch: [80][  250/  391]    Overall Loss 0.360229    Objective Loss 0.360229    Top1 87.578125    Top5 99.565625    LR 0.300000    Time 0.023020    
2018-11-02 21:28:19,842 - Epoch: [80][  300/  391]    Overall Loss 0.363888    Objective Loss 0.363888    Top1 87.447917    Top5 99.557292    LR 0.300000    Time 0.022989    
2018-11-02 21:28:20,987 - Epoch: [80][  350/  391]    Overall Loss 0.365429    Objective Loss 0.365429    Top1 87.433036    Top5 99.558036    LR 0.300000    Time 0.022973    
2018-11-02 21:28:22,005 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58147 | -0.01100 |    0.38708 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15879 | -0.00095 |    0.09684 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15920 | -0.00343 |    0.11214 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19347 | -0.01986 |    0.13854 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19686 | -0.00631 |    0.14776 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19976 | -0.03175 |    0.14718 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17966 |  0.00272 |    0.12891 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21452 | -0.00892 |    0.15620 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18028 | -0.00578 |    0.13829 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39431 | -0.01013 |    0.27071 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15568 | -0.01044 |    0.11934 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13635 | -0.01083 |    0.10747 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15472 | -0.02394 |    0.12109 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12248 | -0.00197 |    0.09504 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15325 | -0.01421 |    0.12120 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13882 | -0.01022 |    0.10982 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21680 | -0.02169 |    0.17062 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13622 | -0.01508 |    0.10746 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10361 | -0.00403 |    0.07919 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08240 | -0.00667 |    0.06335 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06169 | -0.00307 |    0.04481 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58346 | -0.00000 |    0.46125 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:28:22,005 - Total sparsity: 0.00

2018-11-02 21:28:22,006 - --- validate (epoch=80)-----------
2018-11-02 21:28:22,006 - 10000 samples (128 per mini-batch)
2018-11-02 21:28:22,739 - Epoch: [80][   50/   78]    Loss 0.617419    Top1 80.734375    Top5 98.890625    
2018-11-02 21:28:23,152 - ==> Top1: 80.560    Top5: 98.860    Loss: 0.619

2018-11-02 21:28:23,153 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:28:23,153 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:28:23,166 - 

2018-11-02 21:28:23,166 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:28:24,364 - Epoch: [81][   50/  391]    Overall Loss 0.344466    Objective Loss 0.344466    Top1 88.281250    Top5 99.609375    LR 0.300000    Time 0.023919    
2018-11-02 21:28:25,505 - Epoch: [81][  100/  391]    Overall Loss 0.347940    Objective Loss 0.347940    Top1 88.179688    Top5 99.585938    LR 0.300000    Time 0.023362    
2018-11-02 21:28:26,647 - Epoch: [81][  150/  391]    Overall Loss 0.348988    Objective Loss 0.348988    Top1 88.062500    Top5 99.619792    LR 0.300000    Time 0.023177    
2018-11-02 21:28:27,788 - Epoch: [81][  200/  391]    Overall Loss 0.346437    Objective Loss 0.346437    Top1 88.132812    Top5 99.644531    LR 0.300000    Time 0.023081    
2018-11-02 21:28:28,930 - Epoch: [81][  250/  391]    Overall Loss 0.355752    Objective Loss 0.355752    Top1 87.875000    Top5 99.609375    LR 0.300000    Time 0.023027    
2018-11-02 21:28:30,071 - Epoch: [81][  300/  391]    Overall Loss 0.358641    Objective Loss 0.358641    Top1 87.742188    Top5 99.604167    LR 0.300000    Time 0.022989    
2018-11-02 21:28:31,214 - Epoch: [81][  350/  391]    Overall Loss 0.361226    Objective Loss 0.361226    Top1 87.587054    Top5 99.611607    LR 0.300000    Time 0.022966    
2018-11-02 21:28:32,229 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58378 | -0.01378 |    0.38808 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15760 | -0.00257 |    0.09508 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15961 | -0.00308 |    0.11154 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19260 | -0.02195 |    0.13868 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19661 | -0.00850 |    0.14691 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19962 | -0.03087 |    0.14702 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17864 |  0.00634 |    0.12917 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21392 | -0.01023 |    0.15663 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17951 | -0.00704 |    0.13809 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39447 | -0.00822 |    0.27018 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15491 | -0.01062 |    0.11834 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13525 | -0.01233 |    0.10665 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15409 | -0.02367 |    0.12080 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12188 | -0.00048 |    0.09440 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15291 | -0.01424 |    0.12107 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13855 | -0.01012 |    0.10931 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21719 | -0.02288 |    0.17159 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13596 | -0.01553 |    0.10737 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10349 | -0.00410 |    0.07913 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08265 | -0.00685 |    0.06354 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06174 | -0.00315 |    0.04481 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58690 | -0.00000 |    0.46500 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:28:32,229 - Total sparsity: 0.00

2018-11-02 21:28:32,229 - --- validate (epoch=81)-----------
2018-11-02 21:28:32,229 - 10000 samples (128 per mini-batch)
2018-11-02 21:28:32,957 - Epoch: [81][   50/   78]    Loss 0.578229    Top1 81.718750    Top5 99.156250    
2018-11-02 21:28:33,351 - ==> Top1: 81.330    Top5: 99.150    Loss: 0.579

2018-11-02 21:28:33,352 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:28:33,352 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:28:33,364 - 

2018-11-02 21:28:33,364 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:28:34,563 - Epoch: [82][   50/  391]    Overall Loss 0.328816    Objective Loss 0.328816    Top1 88.328125    Top5 99.640625    LR 0.300000    Time 0.023943    
2018-11-02 21:28:35,745 - Epoch: [82][  100/  391]    Overall Loss 0.342758    Objective Loss 0.342758    Top1 88.085938    Top5 99.585938    LR 0.300000    Time 0.023777    
2018-11-02 21:28:36,887 - Epoch: [82][  150/  391]    Overall Loss 0.343574    Objective Loss 0.343574    Top1 88.187500    Top5 99.546875    LR 0.300000    Time 0.023459    
2018-11-02 21:28:38,030 - Epoch: [82][  200/  391]    Overall Loss 0.351913    Objective Loss 0.351913    Top1 87.890625    Top5 99.574219    LR 0.300000    Time 0.023300    
2018-11-02 21:28:39,173 - Epoch: [82][  250/  391]    Overall Loss 0.353094    Objective Loss 0.353094    Top1 87.881250    Top5 99.593750    LR 0.300000    Time 0.023208    
2018-11-02 21:28:40,317 - Epoch: [82][  300/  391]    Overall Loss 0.355497    Objective Loss 0.355497    Top1 87.781250    Top5 99.580729    LR 0.300000    Time 0.023148    
2018-11-02 21:28:41,459 - Epoch: [82][  350/  391]    Overall Loss 0.356388    Objective Loss 0.356388    Top1 87.743304    Top5 99.551339    LR 0.300000    Time 0.023102    
2018-11-02 21:28:42,483 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58259 |  0.00283 |    0.38659 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15638 | -0.00214 |    0.09368 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15888 | -0.00414 |    0.11094 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19364 | -0.01969 |    0.13911 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19662 | -0.00511 |    0.14732 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19984 | -0.03197 |    0.14764 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17925 |  0.00084 |    0.12922 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21409 | -0.00848 |    0.15556 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17947 | -0.00542 |    0.13808 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39608 | -0.00497 |    0.27500 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15494 | -0.01107 |    0.11862 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13530 | -0.01090 |    0.10647 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15414 | -0.02331 |    0.12085 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12168 |  0.00018 |    0.09410 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15281 | -0.01516 |    0.12127 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13850 | -0.01083 |    0.10931 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21655 | -0.02262 |    0.17107 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01482 |    0.10725 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10338 | -0.00413 |    0.07900 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08276 | -0.00698 |    0.06344 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06170 | -0.00297 |    0.04484 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58236 | -0.00000 |    0.46129 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:28:42,483 - Total sparsity: 0.00

2018-11-02 21:28:42,483 - --- validate (epoch=82)-----------
2018-11-02 21:28:42,483 - 10000 samples (128 per mini-batch)
2018-11-02 21:28:43,217 - Epoch: [82][   50/   78]    Loss 0.547235    Top1 82.468750    Top5 99.187500    
2018-11-02 21:28:43,613 - ==> Top1: 82.280    Top5: 99.210    Loss: 0.549

2018-11-02 21:28:43,614 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:28:43,614 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:28:43,622 - 

2018-11-02 21:28:43,623 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:28:44,837 - Epoch: [83][   50/  391]    Overall Loss 0.340317    Objective Loss 0.340317    Top1 88.156250    Top5 99.609375    LR 0.300000    Time 0.024257    
2018-11-02 21:28:46,099 - Epoch: [83][  100/  391]    Overall Loss 0.352678    Objective Loss 0.352678    Top1 87.671875    Top5 99.523438    LR 0.300000    Time 0.024734    
2018-11-02 21:28:47,366 - Epoch: [83][  150/  391]    Overall Loss 0.356975    Objective Loss 0.356975    Top1 87.500000    Top5 99.588542    LR 0.300000    Time 0.024928    
2018-11-02 21:28:48,631 - Epoch: [83][  200/  391]    Overall Loss 0.351577    Objective Loss 0.351577    Top1 87.816406    Top5 99.625000    LR 0.300000    Time 0.025013    
2018-11-02 21:28:49,896 - Epoch: [83][  250/  391]    Overall Loss 0.354465    Objective Loss 0.354465    Top1 87.793750    Top5 99.603125    LR 0.300000    Time 0.025067    
2018-11-02 21:28:51,160 - Epoch: [83][  300/  391]    Overall Loss 0.356266    Objective Loss 0.356266    Top1 87.739583    Top5 99.578125    LR 0.300000    Time 0.025097    
2018-11-02 21:28:52,427 - Epoch: [83][  350/  391]    Overall Loss 0.357792    Objective Loss 0.357792    Top1 87.658482    Top5 99.562500    LR 0.300000    Time 0.025129    
2018-11-02 21:28:53,550 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57922 | -0.00905 |    0.38390 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15593 |  0.00025 |    0.09292 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15916 | -0.00356 |    0.11081 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19348 | -0.02239 |    0.13838 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19760 | -0.00333 |    0.14798 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20009 | -0.03115 |    0.14643 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17957 |  0.00310 |    0.12999 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21461 | -0.00939 |    0.15672 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17985 | -0.00684 |    0.13838 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39639 | -0.00716 |    0.27167 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15508 | -0.00948 |    0.11817 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13548 | -0.01114 |    0.10690 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15481 | -0.02268 |    0.12100 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12166 | -0.00002 |    0.09430 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15280 | -0.01504 |    0.12141 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13841 | -0.01024 |    0.10926 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21574 | -0.02126 |    0.16975 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13567 | -0.01452 |    0.10707 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10321 | -0.00502 |    0.07902 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08306 | -0.00663 |    0.06374 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06199 | -0.00282 |    0.04498 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58156 | -0.00000 |    0.46043 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:28:53,550 - Total sparsity: 0.00

2018-11-02 21:28:53,550 - --- validate (epoch=83)-----------
2018-11-02 21:28:53,550 - 10000 samples (128 per mini-batch)
2018-11-02 21:28:54,287 - Epoch: [83][   50/   78]    Loss 0.444961    Top1 85.125000    Top5 99.187500    
2018-11-02 21:28:54,689 - ==> Top1: 85.450    Top5: 99.290    Loss: 0.440

2018-11-02 21:28:54,690 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:28:54,690 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:28:54,698 - 

2018-11-02 21:28:54,698 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:28:56,023 - Epoch: [84][   50/  391]    Overall Loss 0.345773    Objective Loss 0.345773    Top1 87.843750    Top5 99.671875    LR 0.300000    Time 0.026457    
2018-11-02 21:28:57,208 - Epoch: [84][  100/  391]    Overall Loss 0.351027    Objective Loss 0.351027    Top1 87.851562    Top5 99.585938    LR 0.300000    Time 0.025062    
2018-11-02 21:28:58,349 - Epoch: [84][  150/  391]    Overall Loss 0.351747    Objective Loss 0.351747    Top1 87.734375    Top5 99.640625    LR 0.300000    Time 0.024305    
2018-11-02 21:28:59,491 - Epoch: [84][  200/  391]    Overall Loss 0.351929    Objective Loss 0.351929    Top1 87.703125    Top5 99.621094    LR 0.300000    Time 0.023931    
2018-11-02 21:29:00,637 - Epoch: [84][  250/  391]    Overall Loss 0.353502    Objective Loss 0.353502    Top1 87.671875    Top5 99.618750    LR 0.300000    Time 0.023724    
2018-11-02 21:29:01,781 - Epoch: [84][  300/  391]    Overall Loss 0.360440    Objective Loss 0.360440    Top1 87.476562    Top5 99.596354    LR 0.300000    Time 0.023579    
2018-11-02 21:29:02,922 - Epoch: [84][  350/  391]    Overall Loss 0.362630    Objective Loss 0.362630    Top1 87.437500    Top5 99.595982    LR 0.300000    Time 0.023467    
2018-11-02 21:29:03,948 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58040 | -0.00230 |    0.38366 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15511 |  0.00050 |    0.09268 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15925 | -0.00055 |    0.11144 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19365 | -0.02172 |    0.13843 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19785 | -0.00321 |    0.14869 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20131 | -0.03288 |    0.14735 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18160 |  0.00062 |    0.13072 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21554 | -0.00899 |    0.15641 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18046 | -0.00712 |    0.13871 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39756 | -0.00693 |    0.27635 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15497 | -0.01041 |    0.11801 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13557 | -0.00975 |    0.10690 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15448 | -0.02336 |    0.12105 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12205 | -0.00185 |    0.09465 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15384 | -0.01494 |    0.12211 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13894 | -0.00992 |    0.10974 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21601 | -0.02188 |    0.16980 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13619 | -0.01446 |    0.10740 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10410 | -0.00535 |    0.07977 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08434 | -0.00599 |    0.06469 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06281 | -0.00305 |    0.04560 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57973 | -0.00000 |    0.45888 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:29:03,949 - Total sparsity: 0.00

2018-11-02 21:29:03,949 - --- validate (epoch=84)-----------
2018-11-02 21:29:03,949 - 10000 samples (128 per mini-batch)
2018-11-02 21:29:04,678 - Epoch: [84][   50/   78]    Loss 0.698327    Top1 78.500000    Top5 98.484375    
2018-11-02 21:29:05,071 - ==> Top1: 79.010    Top5: 98.580    Loss: 0.680

2018-11-02 21:29:05,071 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:29:05,072 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:29:05,080 - 

2018-11-02 21:29:05,080 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:29:06,280 - Epoch: [85][   50/  391]    Overall Loss 0.347180    Objective Loss 0.347180    Top1 88.093750    Top5 99.593750    LR 0.300000    Time 0.023953    
2018-11-02 21:29:07,419 - Epoch: [85][  100/  391]    Overall Loss 0.355327    Objective Loss 0.355327    Top1 87.500000    Top5 99.570312    LR 0.300000    Time 0.023352    
2018-11-02 21:29:08,559 - Epoch: [85][  150/  391]    Overall Loss 0.355847    Objective Loss 0.355847    Top1 87.661458    Top5 99.562500    LR 0.300000    Time 0.023163    
2018-11-02 21:29:09,699 - Epoch: [85][  200/  391]    Overall Loss 0.353425    Objective Loss 0.353425    Top1 87.761719    Top5 99.578125    LR 0.300000    Time 0.023065    
2018-11-02 21:29:10,837 - Epoch: [85][  250/  391]    Overall Loss 0.351074    Objective Loss 0.351074    Top1 87.903125    Top5 99.593750    LR 0.300000    Time 0.022998    
2018-11-02 21:29:11,976 - Epoch: [85][  300/  391]    Overall Loss 0.353246    Objective Loss 0.353246    Top1 87.867188    Top5 99.591146    LR 0.300000    Time 0.022957    
2018-11-02 21:29:13,119 - Epoch: [85][  350/  391]    Overall Loss 0.356855    Objective Loss 0.356855    Top1 87.761161    Top5 99.598214    LR 0.300000    Time 0.022938    
2018-11-02 21:29:14,136 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57506 | -0.00008 |    0.38006 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15469 | -0.00289 |    0.09258 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15783 | -0.00323 |    0.10987 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19458 | -0.02172 |    0.13957 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19775 | -0.00917 |    0.14888 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20130 | -0.03172 |    0.14779 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18125 |  0.00007 |    0.13074 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21569 | -0.00887 |    0.15599 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18080 | -0.00510 |    0.13855 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39714 | -0.00685 |    0.27435 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15494 | -0.01121 |    0.11804 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13526 | -0.01096 |    0.10692 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15471 | -0.02176 |    0.12133 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12204 | -0.00086 |    0.09483 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15409 | -0.01506 |    0.12212 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13893 | -0.01031 |    0.10978 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21690 | -0.02049 |    0.17011 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13610 | -0.01462 |    0.10733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10428 | -0.00528 |    0.07981 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08481 | -0.00643 |    0.06541 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06295 | -0.00302 |    0.04564 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57755 | -0.00000 |    0.45679 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:29:14,136 - Total sparsity: 0.00

2018-11-02 21:29:14,136 - --- validate (epoch=85)-----------
2018-11-02 21:29:14,136 - 10000 samples (128 per mini-batch)
2018-11-02 21:29:14,866 - Epoch: [85][   50/   78]    Loss 0.470824    Top1 84.703125    Top5 99.125000    
2018-11-02 21:29:15,264 - ==> Top1: 84.620    Top5: 99.220    Loss: 0.474

2018-11-02 21:29:15,265 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:29:15,265 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:29:15,274 - 

2018-11-02 21:29:15,274 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:29:16,473 - Epoch: [86][   50/  391]    Overall Loss 0.359602    Objective Loss 0.359602    Top1 87.625000    Top5 99.500000    LR 0.300000    Time 0.023943    
2018-11-02 21:29:17,615 - Epoch: [86][  100/  391]    Overall Loss 0.365388    Objective Loss 0.365388    Top1 87.375000    Top5 99.562500    LR 0.300000    Time 0.023375    
2018-11-02 21:29:18,759 - Epoch: [86][  150/  391]    Overall Loss 0.364516    Objective Loss 0.364516    Top1 87.427083    Top5 99.588542    LR 0.300000    Time 0.023205    
2018-11-02 21:29:19,903 - Epoch: [86][  200/  391]    Overall Loss 0.359842    Objective Loss 0.359842    Top1 87.628906    Top5 99.613281    LR 0.300000    Time 0.023114    
2018-11-02 21:29:21,049 - Epoch: [86][  250/  391]    Overall Loss 0.359473    Objective Loss 0.359473    Top1 87.712500    Top5 99.584375    LR 0.300000    Time 0.023055    
2018-11-02 21:29:22,189 - Epoch: [86][  300/  391]    Overall Loss 0.361632    Objective Loss 0.361632    Top1 87.635417    Top5 99.591146    LR 0.300000    Time 0.023010    
2018-11-02 21:29:23,331 - Epoch: [86][  350/  391]    Overall Loss 0.357555    Objective Loss 0.357555    Top1 87.796875    Top5 99.604911    LR 0.300000    Time 0.022981    
2018-11-02 21:29:24,353 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57843 |  0.01086 |    0.38115 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15442 | -0.00138 |    0.09276 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15752 | -0.00175 |    0.11010 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19303 | -0.02157 |    0.13814 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19640 | -0.00930 |    0.14796 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19885 | -0.03701 |    0.14732 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18074 | -0.00117 |    0.12988 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21499 | -0.00717 |    0.15518 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18049 | -0.00422 |    0.13884 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39596 | -0.00795 |    0.27365 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15536 | -0.00930 |    0.11827 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13536 | -0.00989 |    0.10689 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15428 | -0.02226 |    0.12084 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12169 | -0.00227 |    0.09446 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15379 | -0.01433 |    0.12178 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13875 | -0.01035 |    0.10992 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21616 | -0.02110 |    0.17011 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13607 | -0.01483 |    0.10722 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10421 | -0.00478 |    0.07958 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08507 | -0.00684 |    0.06559 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06299 | -0.00233 |    0.04562 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57903 | -0.00000 |    0.45782 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:29:24,354 - Total sparsity: 0.00

2018-11-02 21:29:24,354 - --- validate (epoch=86)-----------
2018-11-02 21:29:24,354 - 10000 samples (128 per mini-batch)
2018-11-02 21:29:25,081 - Epoch: [86][   50/   78]    Loss 0.794246    Top1 76.718750    Top5 98.390625    
2018-11-02 21:29:25,472 - ==> Top1: 76.790    Top5: 98.440    Loss: 0.790

2018-11-02 21:29:25,473 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:29:25,473 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:29:25,482 - 

2018-11-02 21:29:25,482 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:29:26,682 - Epoch: [87][   50/  391]    Overall Loss 0.330018    Objective Loss 0.330018    Top1 88.687500    Top5 99.609375    LR 0.300000    Time 0.023962    
2018-11-02 21:29:27,822 - Epoch: [87][  100/  391]    Overall Loss 0.344887    Objective Loss 0.344887    Top1 88.109375    Top5 99.562500    LR 0.300000    Time 0.023372    
2018-11-02 21:29:28,966 - Epoch: [87][  150/  391]    Overall Loss 0.345845    Objective Loss 0.345845    Top1 87.973958    Top5 99.562500    LR 0.300000    Time 0.023194    
2018-11-02 21:29:30,108 - Epoch: [87][  200/  391]    Overall Loss 0.351426    Objective Loss 0.351426    Top1 87.882812    Top5 99.558594    LR 0.300000    Time 0.023103    
2018-11-02 21:29:31,252 - Epoch: [87][  250/  391]    Overall Loss 0.353999    Objective Loss 0.353999    Top1 87.821875    Top5 99.575000    LR 0.300000    Time 0.023037    
2018-11-02 21:29:32,393 - Epoch: [87][  300/  391]    Overall Loss 0.353605    Objective Loss 0.353605    Top1 87.786458    Top5 99.575521    LR 0.300000    Time 0.022995    
2018-11-02 21:29:33,537 - Epoch: [87][  350/  391]    Overall Loss 0.356574    Objective Loss 0.356574    Top1 87.725446    Top5 99.551339    LR 0.300000    Time 0.022975    
2018-11-02 21:29:34,553 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58516 | -0.00712 |    0.38592 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15506 | -0.00327 |    0.09347 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15755 |  0.00009 |    0.10856 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19434 | -0.02160 |    0.13972 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19688 | -0.00760 |    0.14773 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19985 | -0.03383 |    0.14747 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18137 |  0.00193 |    0.13074 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21397 | -0.00981 |    0.15492 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17985 | -0.00550 |    0.13802 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39663 | -0.01124 |    0.26880 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15529 | -0.00944 |    0.11846 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13556 | -0.00977 |    0.10694 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15477 | -0.02250 |    0.12141 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12167 | -0.00167 |    0.09440 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15366 | -0.01459 |    0.12166 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13876 | -0.01039 |    0.10979 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21499 | -0.02140 |    0.16892 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13575 | -0.01461 |    0.10674 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10414 | -0.00505 |    0.07965 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08550 | -0.00645 |    0.06584 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06315 | -0.00234 |    0.04579 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57686 | -0.00000 |    0.45707 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:29:34,554 - Total sparsity: 0.00

2018-11-02 21:29:34,554 - --- validate (epoch=87)-----------
2018-11-02 21:29:34,554 - 10000 samples (128 per mini-batch)
2018-11-02 21:29:35,283 - Epoch: [87][   50/   78]    Loss 0.597173    Top1 81.718750    Top5 98.906250    
2018-11-02 21:29:35,676 - ==> Top1: 81.600    Top5: 98.960    Loss: 0.588

2018-11-02 21:29:35,676 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:29:35,677 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:29:35,685 - 

2018-11-02 21:29:35,685 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:29:36,887 - Epoch: [88][   50/  391]    Overall Loss 0.349058    Objective Loss 0.349058    Top1 87.640625    Top5 99.671875    LR 0.300000    Time 0.023996    
2018-11-02 21:29:38,027 - Epoch: [88][  100/  391]    Overall Loss 0.345193    Objective Loss 0.345193    Top1 87.875000    Top5 99.671875    LR 0.300000    Time 0.023389    
2018-11-02 21:29:39,170 - Epoch: [88][  150/  391]    Overall Loss 0.338443    Objective Loss 0.338443    Top1 88.213542    Top5 99.666667    LR 0.300000    Time 0.023203    
2018-11-02 21:29:40,314 - Epoch: [88][  200/  391]    Overall Loss 0.344477    Objective Loss 0.344477    Top1 88.027344    Top5 99.636719    LR 0.300000    Time 0.023114    
2018-11-02 21:29:41,458 - Epoch: [88][  250/  391]    Overall Loss 0.355100    Objective Loss 0.355100    Top1 87.737500    Top5 99.618750    LR 0.300000    Time 0.023063    
2018-11-02 21:29:42,603 - Epoch: [88][  300/  391]    Overall Loss 0.361594    Objective Loss 0.361594    Top1 87.572917    Top5 99.617188    LR 0.300000    Time 0.023030    
2018-11-02 21:29:43,747 - Epoch: [88][  350/  391]    Overall Loss 0.364307    Objective Loss 0.364307    Top1 87.491071    Top5 99.595982    LR 0.300000    Time 0.023006    
2018-11-02 21:29:44,767 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58842 | -0.00691 |    0.38938 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15415 | -0.00042 |    0.09283 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15724 | -0.00018 |    0.10857 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19511 | -0.02058 |    0.14035 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19792 | -0.00666 |    0.14901 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20083 | -0.03200 |    0.14794 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18088 |  0.00259 |    0.13031 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21387 | -0.01000 |    0.15477 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18002 | -0.00503 |    0.13791 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39654 | -0.01008 |    0.27228 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15525 | -0.01010 |    0.11859 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13530 | -0.01105 |    0.10685 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15511 | -0.02213 |    0.12123 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12192 | -0.00284 |    0.09459 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15406 | -0.01453 |    0.12199 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13930 | -0.01078 |    0.11017 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21486 | -0.02225 |    0.16906 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13614 | -0.01530 |    0.10752 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10460 | -0.00536 |    0.08009 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08591 | -0.00712 |    0.06637 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06354 | -0.00298 |    0.04617 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57756 | -0.00000 |    0.45716 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:29:44,767 - Total sparsity: 0.00

2018-11-02 21:29:44,768 - --- validate (epoch=88)-----------
2018-11-02 21:29:44,768 - 10000 samples (128 per mini-batch)
2018-11-02 21:29:45,494 - Epoch: [88][   50/   78]    Loss 0.478435    Top1 83.875000    Top5 99.109375    
2018-11-02 21:29:45,888 - ==> Top1: 83.820    Top5: 99.240    Loss: 0.482

2018-11-02 21:29:45,889 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:29:45,889 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:29:45,901 - 

2018-11-02 21:29:45,901 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:29:47,102 - Epoch: [89][   50/  391]    Overall Loss 0.345961    Objective Loss 0.345961    Top1 87.515625    Top5 99.640625    LR 0.300000    Time 0.023977    
2018-11-02 21:29:48,242 - Epoch: [89][  100/  391]    Overall Loss 0.342799    Objective Loss 0.342799    Top1 87.992188    Top5 99.664062    LR 0.300000    Time 0.023374    
2018-11-02 21:29:49,386 - Epoch: [89][  150/  391]    Overall Loss 0.343193    Objective Loss 0.343193    Top1 87.958333    Top5 99.666667    LR 0.300000    Time 0.023200    
2018-11-02 21:29:50,528 - Epoch: [89][  200/  391]    Overall Loss 0.346132    Objective Loss 0.346132    Top1 87.832031    Top5 99.621094    LR 0.300000    Time 0.023104    
2018-11-02 21:29:51,669 - Epoch: [89][  250/  391]    Overall Loss 0.346025    Objective Loss 0.346025    Top1 87.871875    Top5 99.631250    LR 0.300000    Time 0.023039    
2018-11-02 21:29:52,809 - Epoch: [89][  300/  391]    Overall Loss 0.351546    Objective Loss 0.351546    Top1 87.679688    Top5 99.638021    LR 0.300000    Time 0.022996    
2018-11-02 21:29:53,954 - Epoch: [89][  350/  391]    Overall Loss 0.353608    Objective Loss 0.353608    Top1 87.687500    Top5 99.627232    LR 0.300000    Time 0.022977    
2018-11-02 21:29:54,972 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58596 | -0.00273 |    0.38768 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15296 | -0.00208 |    0.09138 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15674 | -0.00123 |    0.10831 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19476 | -0.01876 |    0.13917 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19852 | -0.00571 |    0.15042 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20144 | -0.03410 |    0.14900 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18169 |  0.00209 |    0.13089 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21470 | -0.01068 |    0.15558 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17996 | -0.00602 |    0.13798 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39578 | -0.00939 |    0.26991 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15554 | -0.00827 |    0.11865 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13582 | -0.01086 |    0.10748 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15576 | -0.02329 |    0.12198 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12187 | -0.00253 |    0.09441 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15361 | -0.01518 |    0.12204 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13919 | -0.01062 |    0.10988 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21409 | -0.02383 |    0.16867 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13622 | -0.01482 |    0.10757 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10464 | -0.00513 |    0.07989 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08626 | -0.00621 |    0.06646 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06376 | -0.00224 |    0.04619 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58254 | -0.00000 |    0.46250 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:29:54,972 - Total sparsity: 0.00

2018-11-02 21:29:54,973 - --- validate (epoch=89)-----------
2018-11-02 21:29:54,973 - 10000 samples (128 per mini-batch)
2018-11-02 21:29:55,725 - Epoch: [89][   50/   78]    Loss 0.504838    Top1 84.046875    Top5 99.015625    
2018-11-02 21:29:56,116 - ==> Top1: 84.070    Top5: 99.100    Loss: 0.500

2018-11-02 21:29:56,116 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:29:56,117 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:29:56,128 - 

2018-11-02 21:29:56,129 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:29:57,331 - Epoch: [90][   50/  391]    Overall Loss 0.328805    Objective Loss 0.328805    Top1 88.625000    Top5 99.640625    LR 0.300000    Time 0.024005    
2018-11-02 21:29:58,473 - Epoch: [90][  100/  391]    Overall Loss 0.348147    Objective Loss 0.348147    Top1 87.867188    Top5 99.585938    LR 0.300000    Time 0.023412    
2018-11-02 21:29:59,616 - Epoch: [90][  150/  391]    Overall Loss 0.349156    Objective Loss 0.349156    Top1 87.973958    Top5 99.588542    LR 0.300000    Time 0.023219    
2018-11-02 21:30:00,761 - Epoch: [90][  200/  391]    Overall Loss 0.356440    Objective Loss 0.356440    Top1 87.664062    Top5 99.562500    LR 0.300000    Time 0.023132    
2018-11-02 21:30:01,903 - Epoch: [90][  250/  391]    Overall Loss 0.355889    Objective Loss 0.355889    Top1 87.796875    Top5 99.565625    LR 0.300000    Time 0.023066    
2018-11-02 21:30:03,044 - Epoch: [90][  300/  391]    Overall Loss 0.355555    Objective Loss 0.355555    Top1 87.825521    Top5 99.588542    LR 0.300000    Time 0.023023    
2018-11-02 21:30:04,187 - Epoch: [90][  350/  391]    Overall Loss 0.357536    Objective Loss 0.357536    Top1 87.758929    Top5 99.600446    LR 0.300000    Time 0.022994    
2018-11-02 21:30:05,205 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58394 | -0.00335 |    0.38568 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15264 | -0.00164 |    0.09129 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15571 | -0.00232 |    0.10648 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19439 | -0.01995 |    0.13874 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19798 | -0.00649 |    0.14945 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20081 | -0.03513 |    0.14775 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18109 |  0.00128 |    0.13021 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21472 | -0.00902 |    0.15598 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18023 | -0.00483 |    0.13802 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39458 | -0.00689 |    0.27080 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15546 | -0.00734 |    0.11842 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13604 | -0.01133 |    0.10727 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15604 | -0.02200 |    0.12216 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12178 | -0.00185 |    0.09422 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15383 | -0.01324 |    0.12183 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13917 | -0.01058 |    0.10990 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21372 | -0.02233 |    0.16843 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13596 | -0.01485 |    0.10733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10465 | -0.00548 |    0.07988 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08651 | -0.00666 |    0.06657 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06387 | -0.00239 |    0.04630 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58177 | -0.00000 |    0.45718 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:30:05,205 - Total sparsity: 0.00

2018-11-02 21:30:05,205 - --- validate (epoch=90)-----------
2018-11-02 21:30:05,205 - 10000 samples (128 per mini-batch)
2018-11-02 21:30:05,931 - Epoch: [90][   50/   78]    Loss 0.544479    Top1 83.015625    Top5 99.171875    
2018-11-02 21:30:06,325 - ==> Top1: 83.060    Top5: 99.260    Loss: 0.535

2018-11-02 21:30:06,325 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:30:06,326 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:30:06,334 - 

2018-11-02 21:30:06,334 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:30:07,534 - Epoch: [91][   50/  391]    Overall Loss 0.358869    Objective Loss 0.358869    Top1 87.250000    Top5 99.593750    LR 0.300000    Time 0.023956    
2018-11-02 21:30:08,675 - Epoch: [91][  100/  391]    Overall Loss 0.353461    Objective Loss 0.353461    Top1 87.523438    Top5 99.609375    LR 0.300000    Time 0.023370    
2018-11-02 21:30:09,817 - Epoch: [91][  150/  391]    Overall Loss 0.362057    Objective Loss 0.362057    Top1 87.296875    Top5 99.625000    LR 0.300000    Time 0.023186    
2018-11-02 21:30:10,959 - Epoch: [91][  200/  391]    Overall Loss 0.359222    Objective Loss 0.359222    Top1 87.500000    Top5 99.597656    LR 0.300000    Time 0.023096    
2018-11-02 21:30:12,099 - Epoch: [91][  250/  391]    Overall Loss 0.357766    Objective Loss 0.357766    Top1 87.609375    Top5 99.590625    LR 0.300000    Time 0.023029    
2018-11-02 21:30:13,241 - Epoch: [91][  300/  391]    Overall Loss 0.357559    Objective Loss 0.357559    Top1 87.700521    Top5 99.596354    LR 0.300000    Time 0.022992    
2018-11-02 21:30:14,383 - Epoch: [91][  350/  391]    Overall Loss 0.356270    Objective Loss 0.356270    Top1 87.736607    Top5 99.607143    LR 0.300000    Time 0.022967    
2018-11-02 21:30:15,398 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58445 |  0.00651 |    0.38503 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15293 | -0.00144 |    0.09174 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15531 | -0.00381 |    0.10651 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19502 | -0.02283 |    0.13778 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19908 | -0.00687 |    0.15024 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20172 | -0.03229 |    0.14788 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18041 | -0.00144 |    0.12970 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21450 | -0.00775 |    0.15529 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17996 | -0.00530 |    0.13767 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39481 | -0.01225 |    0.27223 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15559 | -0.00750 |    0.11863 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13626 | -0.01206 |    0.10764 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15585 | -0.02149 |    0.12193 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12181 | -0.00307 |    0.09438 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15349 | -0.01456 |    0.12170 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13915 | -0.01055 |    0.10984 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21450 | -0.02076 |    0.16964 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13615 | -0.01490 |    0.10761 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10493 | -0.00549 |    0.08024 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08696 | -0.00688 |    0.06700 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06414 | -0.00239 |    0.04643 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57947 | -0.00000 |    0.45937 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:30:15,398 - Total sparsity: 0.00

2018-11-02 21:30:15,399 - --- validate (epoch=91)-----------
2018-11-02 21:30:15,399 - 10000 samples (128 per mini-batch)
2018-11-02 21:30:16,128 - Epoch: [91][   50/   78]    Loss 0.626094    Top1 80.687500    Top5 98.406250    
2018-11-02 21:30:16,516 - ==> Top1: 80.420    Top5: 98.440    Loss: 0.619

2018-11-02 21:30:16,516 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:30:16,516 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:30:16,525 - 

2018-11-02 21:30:16,525 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:30:17,725 - Epoch: [92][   50/  391]    Overall Loss 0.346163    Objective Loss 0.346163    Top1 87.843750    Top5 99.656250    LR 0.300000    Time 0.023974    
2018-11-02 21:30:18,864 - Epoch: [92][  100/  391]    Overall Loss 0.338359    Objective Loss 0.338359    Top1 88.148438    Top5 99.703125    LR 0.300000    Time 0.023364    
2018-11-02 21:30:20,007 - Epoch: [92][  150/  391]    Overall Loss 0.349338    Objective Loss 0.349338    Top1 87.937500    Top5 99.671875    LR 0.300000    Time 0.023184    
2018-11-02 21:30:21,149 - Epoch: [92][  200/  391]    Overall Loss 0.353174    Objective Loss 0.353174    Top1 87.820312    Top5 99.644531    LR 0.300000    Time 0.023090    
2018-11-02 21:30:22,290 - Epoch: [92][  250/  391]    Overall Loss 0.354473    Objective Loss 0.354473    Top1 87.771875    Top5 99.628125    LR 0.300000    Time 0.023033    
2018-11-02 21:30:23,431 - Epoch: [92][  300/  391]    Overall Loss 0.354508    Objective Loss 0.354508    Top1 87.700521    Top5 99.617188    LR 0.300000    Time 0.022992    
2018-11-02 21:30:24,574 - Epoch: [92][  350/  391]    Overall Loss 0.355530    Objective Loss 0.355530    Top1 87.705357    Top5 99.616071    LR 0.300000    Time 0.022969    
2018-11-02 21:30:25,596 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58344 |  0.00078 |    0.38077 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15364 | -0.00155 |    0.09154 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15599 | -0.00174 |    0.10588 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19509 | -0.01733 |    0.13847 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19885 | -0.00897 |    0.15020 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20286 | -0.03222 |    0.14819 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18165 |  0.00158 |    0.13040 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21441 | -0.00967 |    0.15562 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17982 | -0.00543 |    0.13793 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39432 | -0.00842 |    0.27226 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15461 | -0.00912 |    0.11806 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13538 | -0.01036 |    0.10660 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15556 | -0.02272 |    0.12210 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12197 | -0.00274 |    0.09427 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15347 | -0.01475 |    0.12173 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13909 | -0.00995 |    0.10984 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21406 | -0.02095 |    0.16871 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13636 | -0.01493 |    0.10771 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10519 | -0.00619 |    0.08062 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08749 | -0.00684 |    0.06754 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06437 | -0.00237 |    0.04675 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57826 | -0.00000 |    0.45865 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:30:25,596 - Total sparsity: 0.00

2018-11-02 21:30:25,596 - --- validate (epoch=92)-----------
2018-11-02 21:30:25,596 - 10000 samples (128 per mini-batch)
2018-11-02 21:30:26,327 - Epoch: [92][   50/   78]    Loss 0.783357    Top1 75.953125    Top5 98.687500    
2018-11-02 21:30:26,722 - ==> Top1: 75.660    Top5: 98.690    Loss: 0.790

2018-11-02 21:30:26,723 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:30:26,723 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:30:26,731 - 

2018-11-02 21:30:26,732 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:30:27,933 - Epoch: [93][   50/  391]    Overall Loss 0.356770    Objective Loss 0.356770    Top1 87.312500    Top5 99.625000    LR 0.300000    Time 0.023986    
2018-11-02 21:30:29,073 - Epoch: [93][  100/  391]    Overall Loss 0.341466    Objective Loss 0.341466    Top1 87.906250    Top5 99.656250    LR 0.300000    Time 0.023385    
2018-11-02 21:30:30,213 - Epoch: [93][  150/  391]    Overall Loss 0.347631    Objective Loss 0.347631    Top1 87.875000    Top5 99.671875    LR 0.300000    Time 0.023181    
2018-11-02 21:30:31,356 - Epoch: [93][  200/  391]    Overall Loss 0.347856    Objective Loss 0.347856    Top1 87.804688    Top5 99.652344    LR 0.300000    Time 0.023094    
2018-11-02 21:30:32,497 - Epoch: [93][  250/  391]    Overall Loss 0.350547    Objective Loss 0.350547    Top1 87.709375    Top5 99.650000    LR 0.300000    Time 0.023031    
2018-11-02 21:30:33,638 - Epoch: [93][  300/  391]    Overall Loss 0.354421    Objective Loss 0.354421    Top1 87.643229    Top5 99.635417    LR 0.300000    Time 0.022991    
2018-11-02 21:30:34,781 - Epoch: [93][  350/  391]    Overall Loss 0.354831    Objective Loss 0.354831    Top1 87.642857    Top5 99.631696    LR 0.300000    Time 0.022970    
2018-11-02 21:30:35,799 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58862 | -0.00180 |    0.38711 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15349 |  0.00104 |    0.09198 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15572 | -0.00254 |    0.10657 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19499 | -0.02016 |    0.13936 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19963 | -0.01022 |    0.15055 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20281 | -0.03243 |    0.14820 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18244 | -0.00122 |    0.13075 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21338 | -0.01184 |    0.15586 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17939 | -0.00566 |    0.13759 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39465 | -0.01055 |    0.27165 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15471 | -0.00804 |    0.11766 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13513 | -0.01021 |    0.10670 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15518 | -0.02234 |    0.12151 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12172 | -0.00186 |    0.09422 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15314 | -0.01435 |    0.12127 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13867 | -0.01048 |    0.10963 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21348 | -0.01960 |    0.16772 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13592 | -0.01464 |    0.10724 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10516 | -0.00632 |    0.08052 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08790 | -0.00716 |    0.06787 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06441 | -0.00253 |    0.04697 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57898 | -0.00000 |    0.45808 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:30:35,799 - Total sparsity: 0.00

2018-11-02 21:30:35,799 - --- validate (epoch=93)-----------
2018-11-02 21:30:35,799 - 10000 samples (128 per mini-batch)
2018-11-02 21:30:36,520 - Epoch: [93][   50/   78]    Loss 0.551857    Top1 81.828125    Top5 98.984375    
2018-11-02 21:30:36,913 - ==> Top1: 81.930    Top5: 99.030    Loss: 0.552

2018-11-02 21:30:36,914 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:30:36,914 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:30:36,926 - 

2018-11-02 21:30:36,926 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:30:38,126 - Epoch: [94][   50/  391]    Overall Loss 0.323947    Objective Loss 0.323947    Top1 88.562500    Top5 99.765625    LR 0.300000    Time 0.023966    
2018-11-02 21:30:39,268 - Epoch: [94][  100/  391]    Overall Loss 0.337933    Objective Loss 0.337933    Top1 88.421875    Top5 99.710938    LR 0.300000    Time 0.023386    
2018-11-02 21:30:40,409 - Epoch: [94][  150/  391]    Overall Loss 0.337792    Objective Loss 0.337792    Top1 88.526042    Top5 99.692708    LR 0.300000    Time 0.023192    
2018-11-02 21:30:41,551 - Epoch: [94][  200/  391]    Overall Loss 0.342728    Objective Loss 0.342728    Top1 88.308594    Top5 99.695312    LR 0.300000    Time 0.023095    
2018-11-02 21:30:42,691 - Epoch: [94][  250/  391]    Overall Loss 0.344948    Objective Loss 0.344948    Top1 88.190625    Top5 99.665625    LR 0.300000    Time 0.023031    
2018-11-02 21:30:43,834 - Epoch: [94][  300/  391]    Overall Loss 0.346149    Objective Loss 0.346149    Top1 88.143229    Top5 99.640625    LR 0.300000    Time 0.022998    
2018-11-02 21:30:44,974 - Epoch: [94][  350/  391]    Overall Loss 0.349596    Objective Loss 0.349596    Top1 87.979911    Top5 99.631696    LR 0.300000    Time 0.022966    
2018-11-02 21:30:45,992 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58341 | -0.00654 |    0.38384 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15288 | -0.00080 |    0.09139 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15601 | -0.00163 |    0.10707 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19385 | -0.01946 |    0.13905 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19820 | -0.00842 |    0.14982 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20249 | -0.03384 |    0.14769 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18279 | -0.00020 |    0.13091 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21281 | -0.01056 |    0.15503 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17923 | -0.00502 |    0.13751 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39473 | -0.01372 |    0.27023 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15435 | -0.00758 |    0.11769 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13496 | -0.01134 |    0.10595 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15460 | -0.02291 |    0.12136 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12117 | -0.00116 |    0.09360 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15259 | -0.01528 |    0.12090 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13834 | -0.01008 |    0.10927 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21281 | -0.02135 |    0.16635 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13562 | -0.01486 |    0.10702 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10512 | -0.00666 |    0.08068 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08795 | -0.00709 |    0.06783 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06454 | -0.00249 |    0.04689 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58008 | -0.00000 |    0.45911 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:30:45,992 - Total sparsity: 0.00

2018-11-02 21:30:45,992 - --- validate (epoch=94)-----------
2018-11-02 21:30:45,993 - 10000 samples (128 per mini-batch)
2018-11-02 21:30:46,721 - Epoch: [94][   50/   78]    Loss 0.532411    Top1 82.453125    Top5 99.250000    
2018-11-02 21:30:47,115 - ==> Top1: 82.420    Top5: 99.310    Loss: 0.525

2018-11-02 21:30:47,116 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:30:47,116 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:30:47,128 - 

2018-11-02 21:30:47,128 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:30:48,327 - Epoch: [95][   50/  391]    Overall Loss 0.335700    Objective Loss 0.335700    Top1 88.078125    Top5 99.656250    LR 0.300000    Time 0.023941    
2018-11-02 21:30:49,466 - Epoch: [95][  100/  391]    Overall Loss 0.338746    Objective Loss 0.338746    Top1 88.046875    Top5 99.601562    LR 0.300000    Time 0.023346    
2018-11-02 21:30:50,608 - Epoch: [95][  150/  391]    Overall Loss 0.349044    Objective Loss 0.349044    Top1 87.869792    Top5 99.598958    LR 0.300000    Time 0.023168    
2018-11-02 21:30:51,748 - Epoch: [95][  200/  391]    Overall Loss 0.353322    Objective Loss 0.353322    Top1 87.726562    Top5 99.566406    LR 0.300000    Time 0.023069    
2018-11-02 21:30:52,889 - Epoch: [95][  250/  391]    Overall Loss 0.354421    Objective Loss 0.354421    Top1 87.771875    Top5 99.562500    LR 0.300000    Time 0.023013    
2018-11-02 21:30:54,030 - Epoch: [95][  300/  391]    Overall Loss 0.356142    Objective Loss 0.356142    Top1 87.799479    Top5 99.565104    LR 0.300000    Time 0.022974    
2018-11-02 21:30:55,175 - Epoch: [95][  350/  391]    Overall Loss 0.355077    Objective Loss 0.355077    Top1 87.861607    Top5 99.569196    LR 0.300000    Time 0.022960    
2018-11-02 21:30:56,194 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58202 | -0.00157 |    0.38078 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15391 |  0.00059 |    0.09148 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15690 | -0.00081 |    0.10691 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19538 | -0.01766 |    0.13976 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19934 | -0.00735 |    0.14948 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20378 | -0.03116 |    0.14831 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18355 | -0.00040 |    0.13179 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21287 | -0.01132 |    0.15540 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17895 | -0.00406 |    0.13705 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39622 | -0.00902 |    0.26997 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15378 | -0.00818 |    0.11710 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13496 | -0.01126 |    0.10635 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15490 | -0.02360 |    0.12173 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12190 | -0.00104 |    0.09447 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15259 | -0.01518 |    0.12097 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13837 | -0.01037 |    0.10934 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21259 | -0.02018 |    0.16598 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13548 | -0.01477 |    0.10697 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10509 | -0.00632 |    0.08042 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08811 | -0.00734 |    0.06799 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06461 | -0.00174 |    0.04690 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57569 | -0.00000 |    0.45712 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:30:56,194 - Total sparsity: 0.00

2018-11-02 21:30:56,194 - --- validate (epoch=95)-----------
2018-11-02 21:30:56,194 - 10000 samples (128 per mini-batch)
2018-11-02 21:30:56,924 - Epoch: [95][   50/   78]    Loss 0.655224    Top1 79.828125    Top5 99.000000    
2018-11-02 21:30:57,321 - ==> Top1: 79.800    Top5: 99.020    Loss: 0.643

2018-11-02 21:30:57,321 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:30:57,321 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:30:57,330 - 

2018-11-02 21:30:57,330 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:30:58,529 - Epoch: [96][   50/  391]    Overall Loss 0.353573    Objective Loss 0.353573    Top1 87.859375    Top5 99.625000    LR 0.300000    Time 0.023935    
2018-11-02 21:30:59,671 - Epoch: [96][  100/  391]    Overall Loss 0.350237    Objective Loss 0.350237    Top1 87.945312    Top5 99.609375    LR 0.300000    Time 0.023377    
2018-11-02 21:31:00,820 - Epoch: [96][  150/  391]    Overall Loss 0.350138    Objective Loss 0.350138    Top1 87.958333    Top5 99.666667    LR 0.300000    Time 0.023237    
2018-11-02 21:31:01,978 - Epoch: [96][  200/  391]    Overall Loss 0.349772    Objective Loss 0.349772    Top1 87.992188    Top5 99.648438    LR 0.300000    Time 0.023212    
2018-11-02 21:31:03,125 - Epoch: [96][  250/  391]    Overall Loss 0.354892    Objective Loss 0.354892    Top1 87.859375    Top5 99.634375    LR 0.300000    Time 0.023153    
2018-11-02 21:31:04,290 - Epoch: [96][  300/  391]    Overall Loss 0.357295    Objective Loss 0.357295    Top1 87.789062    Top5 99.625000    LR 0.300000    Time 0.023172    
2018-11-02 21:31:05,454 - Epoch: [96][  350/  391]    Overall Loss 0.357161    Objective Loss 0.357161    Top1 87.779018    Top5 99.604911    LR 0.300000    Time 0.023183    
2018-11-02 21:31:06,552 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58285 |  0.00291 |    0.37977 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15470 |  0.00310 |    0.09255 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15765 | -0.00334 |    0.10797 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19543 | -0.02060 |    0.14019 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19951 | -0.00643 |    0.14977 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20329 | -0.03268 |    0.14885 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18331 |  0.00228 |    0.13158 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21431 | -0.01007 |    0.15653 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17933 | -0.00466 |    0.13727 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39554 | -0.01332 |    0.27091 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15400 | -0.00794 |    0.11690 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13504 | -0.01008 |    0.10635 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.02239 |    0.12198 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12240 | -0.00208 |    0.09476 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15258 | -0.01421 |    0.12127 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13823 | -0.00998 |    0.10916 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21390 | -0.02210 |    0.16741 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13541 | -0.01462 |    0.10681 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10502 | -0.00622 |    0.08055 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08831 | -0.00718 |    0.06803 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06467 | -0.00222 |    0.04689 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57855 | -0.00000 |    0.45868 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:31:06,552 - Total sparsity: 0.00

2018-11-02 21:31:06,552 - --- validate (epoch=96)-----------
2018-11-02 21:31:06,552 - 10000 samples (128 per mini-batch)
2018-11-02 21:31:07,287 - Epoch: [96][   50/   78]    Loss 0.506718    Top1 83.875000    Top5 99.156250    
2018-11-02 21:31:07,681 - ==> Top1: 84.120    Top5: 99.270    Loss: 0.484

2018-11-02 21:31:07,682 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:31:07,682 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:31:07,690 - 

2018-11-02 21:31:07,691 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:31:08,891 - Epoch: [97][   50/  391]    Overall Loss 0.332719    Objective Loss 0.332719    Top1 88.437500    Top5 99.531250    LR 0.300000    Time 0.023963    
2018-11-02 21:31:10,031 - Epoch: [97][  100/  391]    Overall Loss 0.347201    Objective Loss 0.347201    Top1 88.023438    Top5 99.562500    LR 0.300000    Time 0.023373    
2018-11-02 21:31:11,174 - Epoch: [97][  150/  391]    Overall Loss 0.347562    Objective Loss 0.347562    Top1 87.921875    Top5 99.598958    LR 0.300000    Time 0.023191    
2018-11-02 21:31:12,316 - Epoch: [97][  200/  391]    Overall Loss 0.348140    Objective Loss 0.348140    Top1 87.925781    Top5 99.570312    LR 0.300000    Time 0.023097    
2018-11-02 21:31:13,458 - Epoch: [97][  250/  391]    Overall Loss 0.348274    Objective Loss 0.348274    Top1 87.884375    Top5 99.581250    LR 0.300000    Time 0.023040    
2018-11-02 21:31:14,601 - Epoch: [97][  300/  391]    Overall Loss 0.352051    Objective Loss 0.352051    Top1 87.789062    Top5 99.554688    LR 0.300000    Time 0.023004    
2018-11-02 21:31:15,745 - Epoch: [97][  350/  391]    Overall Loss 0.350634    Objective Loss 0.350634    Top1 87.843750    Top5 99.578125    LR 0.300000    Time 0.022984    
2018-11-02 21:31:16,770 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57876 | -0.00857 |    0.37859 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15378 |  0.00186 |    0.09228 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15724 | -0.00344 |    0.10729 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19518 | -0.01859 |    0.13982 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19840 | -0.00746 |    0.14903 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20268 | -0.03296 |    0.14849 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18236 |  0.00276 |    0.13076 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21406 | -0.00970 |    0.15638 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17912 | -0.00507 |    0.13744 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39354 | -0.00653 |    0.27055 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15377 | -0.00853 |    0.11702 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13531 | -0.00943 |    0.10648 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15510 | -0.02218 |    0.12174 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12208 | -0.00223 |    0.09445 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15210 | -0.01475 |    0.12077 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13773 | -0.01004 |    0.10870 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21473 | -0.02292 |    0.16846 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13483 | -0.01462 |    0.10639 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10482 | -0.00693 |    0.08036 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08842 | -0.00700 |    0.06819 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06470 | -0.00175 |    0.04703 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57553 | -0.00000 |    0.45596 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:31:16,770 - Total sparsity: 0.00

2018-11-02 21:31:16,770 - --- validate (epoch=97)-----------
2018-11-02 21:31:16,770 - 10000 samples (128 per mini-batch)
2018-11-02 21:31:17,499 - Epoch: [97][   50/   78]    Loss 0.590262    Top1 81.906250    Top5 98.937500    
2018-11-02 21:31:17,895 - ==> Top1: 82.020    Top5: 99.020    Loss: 0.579

2018-11-02 21:31:17,896 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:31:17,896 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:31:17,904 - 

2018-11-02 21:31:17,904 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:31:19,103 - Epoch: [98][   50/  391]    Overall Loss 0.358343    Objective Loss 0.358343    Top1 87.781250    Top5 99.593750    LR 0.300000    Time 0.023940    
2018-11-02 21:31:20,243 - Epoch: [98][  100/  391]    Overall Loss 0.342274    Objective Loss 0.342274    Top1 88.226562    Top5 99.625000    LR 0.300000    Time 0.023348    
2018-11-02 21:31:21,383 - Epoch: [98][  150/  391]    Overall Loss 0.349137    Objective Loss 0.349137    Top1 88.041667    Top5 99.635417    LR 0.300000    Time 0.023156    
2018-11-02 21:31:22,524 - Epoch: [98][  200/  391]    Overall Loss 0.345941    Objective Loss 0.345941    Top1 88.136719    Top5 99.648438    LR 0.300000    Time 0.023068    
2018-11-02 21:31:23,666 - Epoch: [98][  250/  391]    Overall Loss 0.345141    Objective Loss 0.345141    Top1 88.025000    Top5 99.668750    LR 0.300000    Time 0.023015    
2018-11-02 21:31:24,807 - Epoch: [98][  300/  391]    Overall Loss 0.347952    Objective Loss 0.347952    Top1 87.937500    Top5 99.653646    LR 0.300000    Time 0.022978    
2018-11-02 21:31:25,949 - Epoch: [98][  350/  391]    Overall Loss 0.352269    Objective Loss 0.352269    Top1 87.779018    Top5 99.640625    LR 0.300000    Time 0.022954    
2018-11-02 21:31:26,966 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57688 | -0.01609 |    0.37451 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15276 |  0.00201 |    0.09127 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15628 | -0.00065 |    0.10618 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19432 | -0.02056 |    0.13884 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19822 | -0.00905 |    0.14917 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20272 | -0.03229 |    0.14912 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18214 |  0.00036 |    0.13040 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21414 | -0.01188 |    0.15717 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17942 | -0.00663 |    0.13748 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39238 | -0.00594 |    0.26836 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15395 | -0.00845 |    0.11685 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13540 | -0.01132 |    0.10662 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15575 | -0.02237 |    0.12220 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12272 | -0.00231 |    0.09485 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15244 | -0.01385 |    0.12116 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13793 | -0.01007 |    0.10896 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21560 | -0.02066 |    0.16847 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13502 | -0.01481 |    0.10660 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10502 | -0.00688 |    0.08053 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08878 | -0.00705 |    0.06847 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06506 | -0.00173 |    0.04711 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57734 | -0.00000 |    0.45728 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:31:26,967 - Total sparsity: 0.00

2018-11-02 21:31:26,967 - --- validate (epoch=98)-----------
2018-11-02 21:31:26,967 - 10000 samples (128 per mini-batch)
2018-11-02 21:31:27,693 - Epoch: [98][   50/   78]    Loss 0.637701    Top1 80.390625    Top5 98.656250    
2018-11-02 21:31:28,079 - ==> Top1: 80.080    Top5: 98.690    Loss: 0.637

2018-11-02 21:31:28,080 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:31:28,080 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:31:28,088 - 

2018-11-02 21:31:28,089 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:31:29,287 - Epoch: [99][   50/  391]    Overall Loss 0.340450    Objective Loss 0.340450    Top1 88.046875    Top5 99.453125    LR 0.300000    Time 0.023922    
2018-11-02 21:31:30,430 - Epoch: [99][  100/  391]    Overall Loss 0.341834    Objective Loss 0.341834    Top1 88.226562    Top5 99.585938    LR 0.300000    Time 0.023382    
2018-11-02 21:31:31,572 - Epoch: [99][  150/  391]    Overall Loss 0.348524    Objective Loss 0.348524    Top1 88.062500    Top5 99.572917    LR 0.300000    Time 0.023192    
2018-11-02 21:31:32,720 - Epoch: [99][  200/  391]    Overall Loss 0.354018    Objective Loss 0.354018    Top1 87.820312    Top5 99.582031    LR 0.300000    Time 0.023125    
2018-11-02 21:31:33,866 - Epoch: [99][  250/  391]    Overall Loss 0.357502    Objective Loss 0.357502    Top1 87.668750    Top5 99.581250    LR 0.300000    Time 0.023078    
2018-11-02 21:31:35,006 - Epoch: [99][  300/  391]    Overall Loss 0.357957    Objective Loss 0.357957    Top1 87.546875    Top5 99.593750    LR 0.300000    Time 0.023028    
2018-11-02 21:31:36,147 - Epoch: [99][  350/  391]    Overall Loss 0.356599    Objective Loss 0.356599    Top1 87.607143    Top5 99.609375    LR 0.300000    Time 0.022995    
2018-11-02 21:31:37,166 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58184 | -0.00510 |    0.37792 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15341 |  0.00300 |    0.09123 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15680 | -0.00243 |    0.10700 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19354 | -0.01653 |    0.13778 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19733 | -0.00576 |    0.14821 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20280 | -0.03422 |    0.14847 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18160 | -0.00062 |    0.12993 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21431 | -0.00985 |    0.15665 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17934 | -0.00560 |    0.13754 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39397 | -0.01344 |    0.26790 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15414 | -0.00874 |    0.11666 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13588 | -0.01053 |    0.10710 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15530 | -0.02345 |    0.12211 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12266 | -0.00170 |    0.09463 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15276 | -0.01501 |    0.12128 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13809 | -0.01047 |    0.10917 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21665 | -0.02037 |    0.16895 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13528 | -0.01460 |    0.10678 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10516 | -0.00706 |    0.08076 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.00741 |    0.06879 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06517 | -0.00229 |    0.04731 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57210 | -0.00000 |    0.45287 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:31:37,166 - Total sparsity: 0.00

2018-11-02 21:31:37,166 - --- validate (epoch=99)-----------
2018-11-02 21:31:37,166 - 10000 samples (128 per mini-batch)
2018-11-02 21:31:37,895 - Epoch: [99][   50/   78]    Loss 0.582730    Top1 81.953125    Top5 98.968750    
2018-11-02 21:31:38,291 - ==> Top1: 81.280    Top5: 99.070    Loss: 0.598

2018-11-02 21:31:38,292 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:31:38,292 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:31:38,304 - 

2018-11-02 21:31:38,304 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:31:39,503 - Epoch: [100][   50/  391]    Overall Loss 0.362207    Objective Loss 0.362207    Top1 87.609375    Top5 99.562500    LR 0.300000    Time 0.023934    
2018-11-02 21:31:40,643 - Epoch: [100][  100/  391]    Overall Loss 0.342985    Objective Loss 0.342985    Top1 88.382812    Top5 99.601562    LR 0.300000    Time 0.023352    
2018-11-02 21:31:41,784 - Epoch: [100][  150/  391]    Overall Loss 0.351201    Objective Loss 0.351201    Top1 88.072917    Top5 99.614583    LR 0.300000    Time 0.023168    
2018-11-02 21:31:42,926 - Epoch: [100][  200/  391]    Overall Loss 0.347222    Objective Loss 0.347222    Top1 88.218750    Top5 99.609375    LR 0.300000    Time 0.023078    
2018-11-02 21:31:44,069 - Epoch: [100][  250/  391]    Overall Loss 0.349192    Objective Loss 0.349192    Top1 87.990625    Top5 99.625000    LR 0.300000    Time 0.023028    
2018-11-02 21:31:45,209 - Epoch: [100][  300/  391]    Overall Loss 0.353833    Objective Loss 0.353833    Top1 87.841146    Top5 99.622396    LR 0.300000    Time 0.022986    
2018-11-02 21:31:46,351 - Epoch: [100][  350/  391]    Overall Loss 0.358260    Objective Loss 0.358260    Top1 87.712054    Top5 99.611607    LR 0.300000    Time 0.022961    
2018-11-02 21:31:47,374 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58271 |  0.00324 |    0.37557 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15351 | -0.00186 |    0.09054 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15798 | -0.00311 |    0.10761 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19286 | -0.01734 |    0.13760 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19728 | -0.00637 |    0.14841 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20305 | -0.03294 |    0.14779 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18183 |  0.00020 |    0.12942 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21400 | -0.01148 |    0.15600 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17948 | -0.00657 |    0.13738 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39644 | -0.01078 |    0.26978 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15421 | -0.00856 |    0.11652 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13577 | -0.01042 |    0.10699 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15515 | -0.02359 |    0.12164 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12241 | -0.00430 |    0.09475 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15313 | -0.01464 |    0.12144 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13813 | -0.01016 |    0.10905 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21678 | -0.01860 |    0.16923 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13538 | -0.01466 |    0.10682 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10533 | -0.00674 |    0.08084 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08936 | -0.00669 |    0.06871 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06546 | -0.00211 |    0.04747 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57220 | -0.00000 |    0.45544 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:31:47,374 - Total sparsity: 0.00

2018-11-02 21:31:47,375 - --- validate (epoch=100)-----------
2018-11-02 21:31:47,375 - 10000 samples (128 per mini-batch)
2018-11-02 21:31:48,107 - Epoch: [100][   50/   78]    Loss 0.656440    Top1 79.796875    Top5 98.859375    
2018-11-02 21:31:48,503 - ==> Top1: 79.300    Top5: 98.960    Loss: 0.667

2018-11-02 21:31:48,504 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:31:48,504 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:31:48,519 - 

2018-11-02 21:31:48,519 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:31:49,719 - Epoch: [101][   50/  391]    Overall Loss 0.369313    Objective Loss 0.369313    Top1 87.656250    Top5 99.578125    LR 0.300000    Time 0.023952    
2018-11-02 21:31:50,860 - Epoch: [101][  100/  391]    Overall Loss 0.338917    Objective Loss 0.338917    Top1 88.468750    Top5 99.601562    LR 0.300000    Time 0.023368    
2018-11-02 21:31:52,001 - Epoch: [101][  150/  391]    Overall Loss 0.353874    Objective Loss 0.353874    Top1 87.968750    Top5 99.578125    LR 0.300000    Time 0.023178    
2018-11-02 21:31:53,144 - Epoch: [101][  200/  391]    Overall Loss 0.356370    Objective Loss 0.356370    Top1 87.976562    Top5 99.550781    LR 0.300000    Time 0.023091    
2018-11-02 21:31:54,285 - Epoch: [101][  250/  391]    Overall Loss 0.355124    Objective Loss 0.355124    Top1 87.903125    Top5 99.565625    LR 0.300000    Time 0.023034    
2018-11-02 21:31:55,427 - Epoch: [101][  300/  391]    Overall Loss 0.353080    Objective Loss 0.353080    Top1 88.007812    Top5 99.539062    LR 0.300000    Time 0.022997    
2018-11-02 21:31:56,568 - Epoch: [101][  350/  391]    Overall Loss 0.352084    Objective Loss 0.352084    Top1 88.024554    Top5 99.553571    LR 0.300000    Time 0.022967    
2018-11-02 21:31:57,589 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58263 | -0.01133 |    0.37890 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15374 | -0.00125 |    0.09116 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15830 | -0.00280 |    0.10867 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19439 | -0.01687 |    0.13959 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19789 | -0.00951 |    0.14987 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20338 | -0.03003 |    0.14801 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18197 | -0.00057 |    0.12966 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21440 | -0.00912 |    0.15561 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17966 | -0.00589 |    0.13771 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39564 | -0.01260 |    0.27050 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15418 | -0.00772 |    0.11616 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13518 | -0.01163 |    0.10666 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15548 | -0.02299 |    0.12252 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12268 | -0.00180 |    0.09458 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15255 | -0.01483 |    0.12140 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13769 | -0.00975 |    0.10864 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21704 | -0.01949 |    0.17012 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13507 | -0.01566 |    0.10658 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10537 | -0.00678 |    0.08095 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08978 | -0.00694 |    0.06914 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06569 | -0.00213 |    0.04762 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57866 | -0.00000 |    0.45772 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:31:57,589 - Total sparsity: 0.00

2018-11-02 21:31:57,590 - --- validate (epoch=101)-----------
2018-11-02 21:31:57,590 - 10000 samples (128 per mini-batch)
2018-11-02 21:31:58,317 - Epoch: [101][   50/   78]    Loss 0.771993    Top1 76.921875    Top5 99.171875    
2018-11-02 21:31:58,713 - ==> Top1: 77.260    Top5: 99.190    Loss: 0.754

2018-11-02 21:31:58,714 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:31:58,714 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:31:58,726 - 

2018-11-02 21:31:58,726 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:31:59,925 - Epoch: [102][   50/  391]    Overall Loss 0.374033    Objective Loss 0.374033    Top1 87.234375    Top5 99.781250    LR 0.300000    Time 0.023936    
2018-11-02 21:32:01,067 - Epoch: [102][  100/  391]    Overall Loss 0.359457    Objective Loss 0.359457    Top1 87.609375    Top5 99.718750    LR 0.300000    Time 0.023378    
2018-11-02 21:32:02,211 - Epoch: [102][  150/  391]    Overall Loss 0.353071    Objective Loss 0.353071    Top1 87.750000    Top5 99.682292    LR 0.300000    Time 0.023203    
2018-11-02 21:32:03,355 - Epoch: [102][  200/  391]    Overall Loss 0.347527    Objective Loss 0.347527    Top1 88.062500    Top5 99.691406    LR 0.300000    Time 0.023112    
2018-11-02 21:32:04,499 - Epoch: [102][  250/  391]    Overall Loss 0.350590    Objective Loss 0.350590    Top1 87.965625    Top5 99.634375    LR 0.300000    Time 0.023062    
2018-11-02 21:32:05,642 - Epoch: [102][  300/  391]    Overall Loss 0.353320    Objective Loss 0.353320    Top1 87.861979    Top5 99.632812    LR 0.300000    Time 0.023024    
2018-11-02 21:32:06,787 - Epoch: [102][  350/  391]    Overall Loss 0.353162    Objective Loss 0.353162    Top1 87.901786    Top5 99.598214    LR 0.300000    Time 0.023001    
2018-11-02 21:32:07,802 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58401 |  0.00099 |    0.37840 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15455 | -0.00288 |    0.09065 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15792 |  0.00126 |    0.10800 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19345 | -0.02034 |    0.13811 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19661 | -0.00866 |    0.14850 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20245 | -0.03479 |    0.14689 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18165 |  0.00053 |    0.12998 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21428 | -0.00945 |    0.15566 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17980 | -0.00490 |    0.13794 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39645 | -0.01068 |    0.26816 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15442 | -0.00841 |    0.11682 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13546 | -0.01159 |    0.10708 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15589 | -0.02253 |    0.12287 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12273 | -0.00226 |    0.09449 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15274 | -0.01469 |    0.12088 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13801 | -0.00930 |    0.10889 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21573 | -0.02139 |    0.16749 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13527 | -0.01512 |    0.10669 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10545 | -0.00702 |    0.08114 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09017 | -0.00739 |    0.06952 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06578 | -0.00238 |    0.04763 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57466 | -0.00000 |    0.45542 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:32:07,803 - Total sparsity: 0.00

2018-11-02 21:32:07,803 - --- validate (epoch=102)-----------
2018-11-02 21:32:07,803 - 10000 samples (128 per mini-batch)
2018-11-02 21:32:08,517 - Epoch: [102][   50/   78]    Loss 0.557152    Top1 83.109375    Top5 98.859375    
2018-11-02 21:32:08,904 - ==> Top1: 83.170    Top5: 98.940    Loss: 0.551

2018-11-02 21:32:08,905 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:32:08,905 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:32:08,913 - 

2018-11-02 21:32:08,913 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:32:10,112 - Epoch: [103][   50/  391]    Overall Loss 0.321332    Objective Loss 0.321332    Top1 88.609375    Top5 99.812500    LR 0.300000    Time 0.023928    
2018-11-02 21:32:11,254 - Epoch: [103][  100/  391]    Overall Loss 0.334604    Objective Loss 0.334604    Top1 88.242188    Top5 99.710938    LR 0.300000    Time 0.023370    
2018-11-02 21:32:12,395 - Epoch: [103][  150/  391]    Overall Loss 0.348860    Objective Loss 0.348860    Top1 87.864583    Top5 99.677083    LR 0.300000    Time 0.023182    
2018-11-02 21:32:13,539 - Epoch: [103][  200/  391]    Overall Loss 0.355423    Objective Loss 0.355423    Top1 87.718750    Top5 99.648438    LR 0.300000    Time 0.023096    
2018-11-02 21:32:14,680 - Epoch: [103][  250/  391]    Overall Loss 0.351467    Objective Loss 0.351467    Top1 87.825000    Top5 99.625000    LR 0.300000    Time 0.023038    
2018-11-02 21:32:15,821 - Epoch: [103][  300/  391]    Overall Loss 0.353965    Objective Loss 0.353965    Top1 87.799479    Top5 99.627604    LR 0.300000    Time 0.022998    
2018-11-02 21:32:16,963 - Epoch: [103][  350/  391]    Overall Loss 0.355429    Objective Loss 0.355429    Top1 87.761161    Top5 99.620536    LR 0.300000    Time 0.022970    
2018-11-02 21:32:17,981 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58782 |  0.00128 |    0.37600 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15541 | -0.00142 |    0.09133 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15921 |  0.00068 |    0.10892 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19435 | -0.01826 |    0.13957 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19782 | -0.00706 |    0.14938 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20296 | -0.03256 |    0.14785 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18193 | -0.00070 |    0.13168 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21470 | -0.00925 |    0.15576 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18042 | -0.00726 |    0.13855 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39739 | -0.01643 |    0.26957 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15445 | -0.00781 |    0.11721 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13559 | -0.01116 |    0.10689 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15607 | -0.02230 |    0.12246 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12295 | -0.00263 |    0.09486 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15280 | -0.01468 |    0.12104 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13815 | -0.00967 |    0.10918 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21619 | -0.02331 |    0.16762 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13573 | -0.01414 |    0.10689 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10560 | -0.00637 |    0.08115 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09055 | -0.00775 |    0.06988 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06613 | -0.00161 |    0.04783 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57566 | -0.00000 |    0.45731 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:32:17,981 - Total sparsity: 0.00

2018-11-02 21:32:17,981 - --- validate (epoch=103)-----------
2018-11-02 21:32:17,981 - 10000 samples (128 per mini-batch)
2018-11-02 21:32:18,711 - Epoch: [103][   50/   78]    Loss 0.504865    Top1 83.765625    Top5 99.140625    
2018-11-02 21:32:19,110 - ==> Top1: 83.780    Top5: 99.160    Loss: 0.503

2018-11-02 21:32:19,111 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:32:19,111 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:32:19,122 - 

2018-11-02 21:32:19,123 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:32:20,322 - Epoch: [104][   50/  391]    Overall Loss 0.342914    Objective Loss 0.342914    Top1 87.671875    Top5 99.531250    LR 0.300000    Time 0.023951    
2018-11-02 21:32:21,465 - Epoch: [104][  100/  391]    Overall Loss 0.335250    Objective Loss 0.335250    Top1 88.054688    Top5 99.585938    LR 0.300000    Time 0.023388    
2018-11-02 21:32:22,607 - Epoch: [104][  150/  391]    Overall Loss 0.340706    Objective Loss 0.340706    Top1 88.020833    Top5 99.557292    LR 0.300000    Time 0.023199    
2018-11-02 21:32:23,748 - Epoch: [104][  200/  391]    Overall Loss 0.343939    Objective Loss 0.343939    Top1 87.906250    Top5 99.574219    LR 0.300000    Time 0.023095    
2018-11-02 21:32:24,889 - Epoch: [104][  250/  391]    Overall Loss 0.348246    Objective Loss 0.348246    Top1 87.781250    Top5 99.562500    LR 0.300000    Time 0.023036    
2018-11-02 21:32:26,031 - Epoch: [104][  300/  391]    Overall Loss 0.354621    Objective Loss 0.354621    Top1 87.578125    Top5 99.562500    LR 0.300000    Time 0.022996    
2018-11-02 21:32:27,173 - Epoch: [104][  350/  391]    Overall Loss 0.352662    Objective Loss 0.352662    Top1 87.687500    Top5 99.578125    LR 0.300000    Time 0.022971    
2018-11-02 21:32:28,190 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58509 | -0.01241 |    0.37488 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15504 | -0.00212 |    0.09036 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15869 | -0.00174 |    0.10886 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19340 | -0.02019 |    0.13765 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19671 | -0.00658 |    0.14756 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20105 | -0.03277 |    0.14690 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18103 |  0.00306 |    0.13014 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21482 | -0.01122 |    0.15638 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18060 | -0.00651 |    0.13873 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39611 | -0.01514 |    0.26925 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15414 | -0.00951 |    0.11673 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13527 | -0.01251 |    0.10679 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15610 | -0.02191 |    0.12278 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12350 | -0.00140 |    0.09535 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15293 | -0.01446 |    0.12097 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13802 | -0.00966 |    0.10894 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21544 | -0.02241 |    0.16710 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13521 | -0.01474 |    0.10661 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10558 | -0.00793 |    0.08133 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09103 | -0.00773 |    0.07021 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06654 | -0.00169 |    0.04805 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57288 | -0.00000 |    0.45573 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:32:28,190 - Total sparsity: 0.00

2018-11-02 21:32:28,190 - --- validate (epoch=104)-----------
2018-11-02 21:32:28,190 - 10000 samples (128 per mini-batch)
2018-11-02 21:32:28,937 - Epoch: [104][   50/   78]    Loss 0.498030    Top1 83.828125    Top5 98.953125    
2018-11-02 21:32:29,335 - ==> Top1: 83.760    Top5: 99.090    Loss: 0.508

2018-11-02 21:32:29,336 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:32:29,336 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:32:29,345 - 

2018-11-02 21:32:29,345 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:32:30,541 - Epoch: [105][   50/  391]    Overall Loss 0.340362    Objective Loss 0.340362    Top1 87.781250    Top5 99.796875    LR 0.300000    Time 0.023890    
2018-11-02 21:32:31,682 - Epoch: [105][  100/  391]    Overall Loss 0.356266    Objective Loss 0.356266    Top1 87.375000    Top5 99.718750    LR 0.300000    Time 0.023336    
2018-11-02 21:32:32,824 - Epoch: [105][  150/  391]    Overall Loss 0.355210    Objective Loss 0.355210    Top1 87.494792    Top5 99.687500    LR 0.300000    Time 0.023161    
2018-11-02 21:32:33,966 - Epoch: [105][  200/  391]    Overall Loss 0.352537    Objective Loss 0.352537    Top1 87.660156    Top5 99.695312    LR 0.300000    Time 0.023076    
2018-11-02 21:32:35,109 - Epoch: [105][  250/  391]    Overall Loss 0.356633    Objective Loss 0.356633    Top1 87.571875    Top5 99.653125    LR 0.300000    Time 0.023025    
2018-11-02 21:32:36,249 - Epoch: [105][  300/  391]    Overall Loss 0.354547    Objective Loss 0.354547    Top1 87.661458    Top5 99.638021    LR 0.300000    Time 0.022986    
2018-11-02 21:32:37,390 - Epoch: [105][  350/  391]    Overall Loss 0.357720    Objective Loss 0.357720    Top1 87.555804    Top5 99.627232    LR 0.300000    Time 0.022955    
2018-11-02 21:32:38,406 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58664 | -0.00370 |    0.37428 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15595 | -0.00215 |    0.09123 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15931 |  0.00005 |    0.10922 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19462 | -0.01824 |    0.13908 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19851 | -0.00641 |    0.14930 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20120 | -0.02969 |    0.14724 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18158 |  0.00139 |    0.13064 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21467 | -0.01049 |    0.15664 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18018 | -0.00736 |    0.13858 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39447 | -0.01410 |    0.26910 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15332 | -0.00852 |    0.11593 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13510 | -0.01092 |    0.10665 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15617 | -0.02185 |    0.12292 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12346 | -0.00092 |    0.09502 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.01461 |    0.12109 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13790 | -0.00962 |    0.10898 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21458 | -0.02317 |    0.16752 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13482 | -0.01489 |    0.10635 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10567 | -0.00736 |    0.08125 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09119 | -0.00692 |    0.07027 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06646 | -0.00167 |    0.04805 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57628 | -0.00000 |    0.45762 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:32:38,406 - Total sparsity: 0.00

2018-11-02 21:32:38,406 - --- validate (epoch=105)-----------
2018-11-02 21:32:38,406 - 10000 samples (128 per mini-batch)
2018-11-02 21:32:39,131 - Epoch: [105][   50/   78]    Loss 0.519521    Top1 83.578125    Top5 98.921875    
2018-11-02 21:32:39,515 - ==> Top1: 83.390    Top5: 99.120    Loss: 0.513

2018-11-02 21:32:39,516 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:32:39,516 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:32:39,528 - 

2018-11-02 21:32:39,528 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:32:40,728 - Epoch: [106][   50/  391]    Overall Loss 0.328931    Objective Loss 0.328931    Top1 88.125000    Top5 99.703125    LR 0.300000    Time 0.023973    
2018-11-02 21:32:41,870 - Epoch: [106][  100/  391]    Overall Loss 0.339039    Objective Loss 0.339039    Top1 87.992188    Top5 99.601562    LR 0.300000    Time 0.023387    
2018-11-02 21:32:43,013 - Epoch: [106][  150/  391]    Overall Loss 0.353001    Objective Loss 0.353001    Top1 87.666667    Top5 99.598958    LR 0.300000    Time 0.023202    
2018-11-02 21:32:44,156 - Epoch: [106][  200/  391]    Overall Loss 0.350162    Objective Loss 0.350162    Top1 87.796875    Top5 99.617188    LR 0.300000    Time 0.023111    
2018-11-02 21:32:45,297 - Epoch: [106][  250/  391]    Overall Loss 0.347743    Objective Loss 0.347743    Top1 87.918750    Top5 99.606250    LR 0.300000    Time 0.023048    
2018-11-02 21:32:46,438 - Epoch: [106][  300/  391]    Overall Loss 0.349309    Objective Loss 0.349309    Top1 87.854167    Top5 99.591146    LR 0.300000    Time 0.023004    
2018-11-02 21:32:47,582 - Epoch: [106][  350/  391]    Overall Loss 0.355795    Objective Loss 0.355795    Top1 87.620536    Top5 99.575893    LR 0.300000    Time 0.022981    
2018-11-02 21:32:48,603 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58549 | -0.00678 |    0.37474 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15585 |  0.00069 |    0.09108 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15947 | -0.00165 |    0.10762 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19520 | -0.01591 |    0.13839 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19913 | -0.00720 |    0.15056 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20150 | -0.03146 |    0.14754 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18195 |  0.00404 |    0.13085 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21554 | -0.00948 |    0.15657 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18070 | -0.00787 |    0.13944 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39572 | -0.01855 |    0.26798 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15373 | -0.00913 |    0.11635 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13536 | -0.01151 |    0.10678 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15667 | -0.02136 |    0.12283 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12371 | -0.00258 |    0.09537 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15330 | -0.01501 |    0.12175 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13832 | -0.01023 |    0.10908 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21492 | -0.02294 |    0.16790 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13495 | -0.01458 |    0.10645 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10610 | -0.00745 |    0.08161 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09182 | -0.00697 |    0.07083 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06688 | -0.00137 |    0.04825 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57195 | -0.00000 |    0.45442 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:32:48,603 - Total sparsity: 0.00

2018-11-02 21:32:48,603 - --- validate (epoch=106)-----------
2018-11-02 21:32:48,603 - 10000 samples (128 per mini-batch)
2018-11-02 21:32:49,339 - Epoch: [106][   50/   78]    Loss 0.552547    Top1 81.343750    Top5 99.000000    
2018-11-02 21:32:49,738 - ==> Top1: 81.560    Top5: 99.120    Loss: 0.558

2018-11-02 21:32:49,739 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:32:49,739 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:32:49,751 - 

2018-11-02 21:32:49,752 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:32:50,947 - Epoch: [107][   50/  391]    Overall Loss 0.339420    Objective Loss 0.339420    Top1 88.359375    Top5 99.671875    LR 0.300000    Time 0.023874    
2018-11-02 21:32:52,089 - Epoch: [107][  100/  391]    Overall Loss 0.349706    Objective Loss 0.349706    Top1 87.984375    Top5 99.632812    LR 0.300000    Time 0.023342    
2018-11-02 21:32:53,233 - Epoch: [107][  150/  391]    Overall Loss 0.349439    Objective Loss 0.349439    Top1 88.020833    Top5 99.625000    LR 0.300000    Time 0.023181    
2018-11-02 21:32:54,374 - Epoch: [107][  200/  391]    Overall Loss 0.344409    Objective Loss 0.344409    Top1 88.187500    Top5 99.648438    LR 0.300000    Time 0.023081    
2018-11-02 21:32:55,516 - Epoch: [107][  250/  391]    Overall Loss 0.349776    Objective Loss 0.349776    Top1 88.000000    Top5 99.640625    LR 0.300000    Time 0.023027    
2018-11-02 21:32:56,657 - Epoch: [107][  300/  391]    Overall Loss 0.351161    Objective Loss 0.351161    Top1 87.958333    Top5 99.617188    LR 0.300000    Time 0.022987    
2018-11-02 21:32:57,797 - Epoch: [107][  350/  391]    Overall Loss 0.349670    Objective Loss 0.349670    Top1 87.986607    Top5 99.611607    LR 0.300000    Time 0.022957    
2018-11-02 21:32:58,815 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58103 | -0.00581 |    0.37173 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 |  0.00014 |    0.09066 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15813 | -0.00594 |    0.10895 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19305 | -0.01850 |    0.13809 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19816 | -0.00676 |    0.14969 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20239 | -0.03295 |    0.14751 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18137 |  0.00111 |    0.12906 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21479 | -0.00765 |    0.15573 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18009 | -0.00730 |    0.13847 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39576 | -0.01222 |    0.26557 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15371 | -0.00837 |    0.11628 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13549 | -0.01383 |    0.10724 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15674 | -0.02127 |    0.12316 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12331 |  0.00007 |    0.09494 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15334 | -0.01548 |    0.12162 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13819 | -0.00972 |    0.10896 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21433 | -0.02358 |    0.16758 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13445 | -0.01446 |    0.10602 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10591 | -0.00744 |    0.08150 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09207 | -0.00749 |    0.07103 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06686 | -0.00108 |    0.04816 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57496 | -0.00000 |    0.45375 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:32:58,815 - Total sparsity: 0.00

2018-11-02 21:32:58,815 - --- validate (epoch=107)-----------
2018-11-02 21:32:58,815 - 10000 samples (128 per mini-batch)
2018-11-02 21:32:59,548 - Epoch: [107][   50/   78]    Loss 0.624793    Top1 81.093750    Top5 98.250000    
2018-11-02 21:32:59,945 - ==> Top1: 80.960    Top5: 98.280    Loss: 0.626

2018-11-02 21:32:59,946 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:32:59,946 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:32:59,958 - 

2018-11-02 21:32:59,958 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:33:01,158 - Epoch: [108][   50/  391]    Overall Loss 0.337892    Objective Loss 0.337892    Top1 88.125000    Top5 99.734375    LR 0.300000    Time 0.023964    
2018-11-02 21:33:02,300 - Epoch: [108][  100/  391]    Overall Loss 0.345541    Objective Loss 0.345541    Top1 88.164062    Top5 99.656250    LR 0.300000    Time 0.023387    
2018-11-02 21:33:03,441 - Epoch: [108][  150/  391]    Overall Loss 0.342308    Objective Loss 0.342308    Top1 88.156250    Top5 99.671875    LR 0.300000    Time 0.023183    
2018-11-02 21:33:04,583 - Epoch: [108][  200/  391]    Overall Loss 0.342360    Objective Loss 0.342360    Top1 88.144531    Top5 99.679688    LR 0.300000    Time 0.023093    
2018-11-02 21:33:05,727 - Epoch: [108][  250/  391]    Overall Loss 0.344009    Objective Loss 0.344009    Top1 88.109375    Top5 99.662500    LR 0.300000    Time 0.023046    
2018-11-02 21:33:06,871 - Epoch: [108][  300/  391]    Overall Loss 0.348853    Objective Loss 0.348853    Top1 87.877604    Top5 99.632812    LR 0.300000    Time 0.023013    
2018-11-02 21:33:08,014 - Epoch: [108][  350/  391]    Overall Loss 0.349322    Objective Loss 0.349322    Top1 87.924107    Top5 99.616071    LR 0.300000    Time 0.022986    
2018-11-02 21:33:09,031 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58040 | -0.01065 |    0.37174 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15425 |  0.00041 |    0.09040 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15770 | -0.00346 |    0.10823 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19305 | -0.02028 |    0.13854 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19905 | -0.00806 |    0.15058 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20251 | -0.03125 |    0.14680 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18033 | -0.00022 |    0.12963 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21403 | -0.00843 |    0.15583 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17957 | -0.00686 |    0.13772 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39445 | -0.00797 |    0.26677 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15359 | -0.00770 |    0.11609 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13551 | -0.01221 |    0.10685 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15600 | -0.02034 |    0.12268 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12249 | -0.00073 |    0.09468 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.01533 |    0.12114 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13800 | -0.01050 |    0.10900 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21436 | -0.02169 |    0.16779 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13425 | -0.01527 |    0.10589 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10608 | -0.00736 |    0.08150 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09244 | -0.00768 |    0.07146 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06705 | -0.00121 |    0.04833 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57280 | -0.00000 |    0.45132 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:33:09,031 - Total sparsity: 0.00

2018-11-02 21:33:09,031 - --- validate (epoch=108)-----------
2018-11-02 21:33:09,031 - 10000 samples (128 per mini-batch)
2018-11-02 21:33:09,759 - Epoch: [108][   50/   78]    Loss 0.608294    Top1 81.093750    Top5 98.703125    
2018-11-02 21:33:10,155 - ==> Top1: 81.190    Top5: 98.690    Loss: 0.611

2018-11-02 21:33:10,156 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:33:10,156 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:33:10,164 - 

2018-11-02 21:33:10,165 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:33:11,363 - Epoch: [109][   50/  391]    Overall Loss 0.340455    Objective Loss 0.340455    Top1 88.218750    Top5 99.484375    LR 0.300000    Time 0.023938    
2018-11-02 21:33:12,507 - Epoch: [109][  100/  391]    Overall Loss 0.342588    Objective Loss 0.342588    Top1 88.046875    Top5 99.523438    LR 0.300000    Time 0.023390    
2018-11-02 21:33:13,651 - Epoch: [109][  150/  391]    Overall Loss 0.347271    Objective Loss 0.347271    Top1 87.796875    Top5 99.572917    LR 0.300000    Time 0.023214    
2018-11-02 21:33:14,794 - Epoch: [109][  200/  391]    Overall Loss 0.341829    Objective Loss 0.341829    Top1 88.042969    Top5 99.601562    LR 0.300000    Time 0.023116    
2018-11-02 21:33:15,937 - Epoch: [109][  250/  391]    Overall Loss 0.343134    Objective Loss 0.343134    Top1 87.928125    Top5 99.596875    LR 0.300000    Time 0.023061    
2018-11-02 21:33:17,079 - Epoch: [109][  300/  391]    Overall Loss 0.344584    Objective Loss 0.344584    Top1 87.895833    Top5 99.604167    LR 0.300000    Time 0.023020    
2018-11-02 21:33:18,222 - Epoch: [109][  350/  391]    Overall Loss 0.351023    Objective Loss 0.351023    Top1 87.763393    Top5 99.595982    LR 0.300000    Time 0.022993    
2018-11-02 21:33:19,244 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57687 | -0.00382 |    0.36851 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15517 |  0.00031 |    0.09160 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15741 | -0.00131 |    0.10794 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19383 | -0.02170 |    0.13857 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19921 | -0.00825 |    0.15030 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20275 | -0.03163 |    0.14723 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18109 | -0.00166 |    0.12949 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21477 | -0.00956 |    0.15632 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17986 | -0.00626 |    0.13807 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39516 | -0.01155 |    0.26754 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15435 | -0.00756 |    0.11683 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13587 | -0.01367 |    0.10712 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15625 | -0.02221 |    0.12320 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12295 | -0.00176 |    0.09494 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15331 | -0.01559 |    0.12136 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13846 | -0.01062 |    0.10932 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21566 | -0.02091 |    0.16726 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13460 | -0.01538 |    0.10620 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10639 | -0.00782 |    0.08190 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09295 | -0.00773 |    0.07196 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06733 | -0.00109 |    0.04846 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56743 | -0.00000 |    0.44620 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:33:19,244 - Total sparsity: 0.00

2018-11-02 21:33:19,244 - --- validate (epoch=109)-----------
2018-11-02 21:33:19,245 - 10000 samples (128 per mini-batch)
2018-11-02 21:33:19,977 - Epoch: [109][   50/   78]    Loss 0.476690    Top1 85.031250    Top5 99.078125    
2018-11-02 21:33:20,376 - ==> Top1: 85.240    Top5: 99.110    Loss: 0.465

2018-11-02 21:33:20,377 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:33:20,377 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:33:20,385 - 

2018-11-02 21:33:20,385 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:33:21,587 - Epoch: [110][   50/  391]    Overall Loss 0.331856    Objective Loss 0.331856    Top1 88.546875    Top5 99.625000    LR 0.300000    Time 0.023988    
2018-11-02 21:33:22,730 - Epoch: [110][  100/  391]    Overall Loss 0.350157    Objective Loss 0.350157    Top1 87.992188    Top5 99.539062    LR 0.300000    Time 0.023415    
2018-11-02 21:33:23,871 - Epoch: [110][  150/  391]    Overall Loss 0.344926    Objective Loss 0.344926    Top1 88.192708    Top5 99.552083    LR 0.300000    Time 0.023209    
2018-11-02 21:33:25,011 - Epoch: [110][  200/  391]    Overall Loss 0.347423    Objective Loss 0.347423    Top1 88.082031    Top5 99.558594    LR 0.300000    Time 0.023098    
2018-11-02 21:33:26,153 - Epoch: [110][  250/  391]    Overall Loss 0.346988    Objective Loss 0.346988    Top1 88.059375    Top5 99.587500    LR 0.300000    Time 0.023027    
2018-11-02 21:33:27,295 - Epoch: [110][  300/  391]    Overall Loss 0.349999    Objective Loss 0.349999    Top1 87.903646    Top5 99.588542    LR 0.300000    Time 0.022990    
2018-11-02 21:33:28,436 - Epoch: [110][  350/  391]    Overall Loss 0.350810    Objective Loss 0.350810    Top1 87.917411    Top5 99.591518    LR 0.300000    Time 0.022961    
2018-11-02 21:33:29,452 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58126 | -0.00060 |    0.37017 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15480 |  0.00167 |    0.09137 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15686 | -0.00187 |    0.10692 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19435 | -0.02066 |    0.13878 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19949 | -0.00644 |    0.15050 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20306 | -0.03424 |    0.14810 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18155 |  0.00346 |    0.12859 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21420 | -0.01000 |    0.15582 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17977 | -0.00674 |    0.13818 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39472 | -0.01139 |    0.26680 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15439 | -0.00638 |    0.11658 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13597 | -0.01280 |    0.10721 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15631 | -0.02268 |    0.12314 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12292 | -0.00070 |    0.09456 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15311 | -0.01563 |    0.12136 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13852 | -0.01009 |    0.10945 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21527 | -0.02130 |    0.16650 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13457 | -0.01537 |    0.10632 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10655 | -0.00791 |    0.08207 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09331 | -0.00704 |    0.07211 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06754 | -0.00081 |    0.04854 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57276 | -0.00000 |    0.45260 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:33:29,452 - Total sparsity: 0.00

2018-11-02 21:33:29,452 - --- validate (epoch=110)-----------
2018-11-02 21:33:29,452 - 10000 samples (128 per mini-batch)
2018-11-02 21:33:30,183 - Epoch: [110][   50/   78]    Loss 0.524308    Top1 83.281250    Top5 98.843750    
2018-11-02 21:33:30,581 - ==> Top1: 83.050    Top5: 99.000    Loss: 0.527

2018-11-02 21:33:30,581 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:33:30,582 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:33:30,590 - 

2018-11-02 21:33:30,590 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:33:31,788 - Epoch: [111][   50/  391]    Overall Loss 0.325063    Objective Loss 0.325063    Top1 88.828125    Top5 99.609375    LR 0.300000    Time 0.023914    
2018-11-02 21:33:32,929 - Epoch: [111][  100/  391]    Overall Loss 0.338124    Objective Loss 0.338124    Top1 88.421875    Top5 99.585938    LR 0.300000    Time 0.023352    
2018-11-02 21:33:34,070 - Epoch: [111][  150/  391]    Overall Loss 0.332669    Objective Loss 0.332669    Top1 88.463542    Top5 99.588542    LR 0.300000    Time 0.023166    
2018-11-02 21:33:35,211 - Epoch: [111][  200/  391]    Overall Loss 0.339950    Objective Loss 0.339950    Top1 88.214844    Top5 99.554688    LR 0.300000    Time 0.023074    
2018-11-02 21:33:36,355 - Epoch: [111][  250/  391]    Overall Loss 0.339644    Objective Loss 0.339644    Top1 88.278125    Top5 99.562500    LR 0.300000    Time 0.023030    
2018-11-02 21:33:37,500 - Epoch: [111][  300/  391]    Overall Loss 0.344177    Objective Loss 0.344177    Top1 88.164062    Top5 99.559896    LR 0.300000    Time 0.023001    
2018-11-02 21:33:38,644 - Epoch: [111][  350/  391]    Overall Loss 0.344297    Objective Loss 0.344297    Top1 88.125000    Top5 99.575893    LR 0.300000    Time 0.022979    
2018-11-02 21:33:39,662 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58126 | -0.00962 |    0.36999 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15372 |  0.00329 |    0.09029 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15667 | -0.00109 |    0.10678 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19400 | -0.02224 |    0.13820 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19871 | -0.00839 |    0.14897 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20309 | -0.03028 |    0.14723 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18065 |  0.00259 |    0.12779 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21466 | -0.00858 |    0.15656 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17996 | -0.00756 |    0.13848 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39361 | -0.01692 |    0.26697 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15420 | -0.00912 |    0.11701 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13573 | -0.01185 |    0.10713 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15631 | -0.02121 |    0.12260 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12297 | -0.00272 |    0.09431 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15340 | -0.01491 |    0.12151 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13868 | -0.01018 |    0.10969 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21569 | -0.01995 |    0.16678 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13439 | -0.01485 |    0.10617 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10658 | -0.00824 |    0.08228 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09314 | -0.00848 |    0.07227 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06737 | -0.00138 |    0.04862 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56560 | -0.00000 |    0.44692 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:33:39,662 - Total sparsity: 0.00

2018-11-02 21:33:39,663 - --- validate (epoch=111)-----------
2018-11-02 21:33:39,663 - 10000 samples (128 per mini-batch)
2018-11-02 21:33:40,393 - Epoch: [111][   50/   78]    Loss 0.537423    Top1 82.859375    Top5 99.093750    
2018-11-02 21:33:40,790 - ==> Top1: 83.090    Top5: 99.210    Loss: 0.528

2018-11-02 21:33:40,791 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 21:33:40,791 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:33:40,803 - 

2018-11-02 21:33:40,803 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:33:42,000 - Epoch: [112][   50/  391]    Overall Loss 0.352962    Objective Loss 0.352962    Top1 87.750000    Top5 99.593750    LR 0.300000    Time 0.023908    
2018-11-02 21:33:43,142 - Epoch: [112][  100/  391]    Overall Loss 0.348732    Objective Loss 0.348732    Top1 87.843750    Top5 99.570312    LR 0.300000    Time 0.023359    
2018-11-02 21:33:44,285 - Epoch: [112][  150/  391]    Overall Loss 0.355258    Objective Loss 0.355258    Top1 87.666667    Top5 99.578125    LR 0.300000    Time 0.023180    
2018-11-02 21:33:45,427 - Epoch: [112][  200/  391]    Overall Loss 0.352599    Objective Loss 0.352599    Top1 87.828125    Top5 99.589844    LR 0.300000    Time 0.023089    
2018-11-02 21:33:46,568 - Epoch: [112][  250/  391]    Overall Loss 0.353798    Objective Loss 0.353798    Top1 87.762500    Top5 99.565625    LR 0.300000    Time 0.023030    
2018-11-02 21:33:47,709 - Epoch: [112][  300/  391]    Overall Loss 0.356517    Objective Loss 0.356517    Top1 87.671875    Top5 99.567708    LR 0.300000    Time 0.022991    
2018-11-02 21:33:48,849 - Epoch: [112][  350/  391]    Overall Loss 0.357931    Objective Loss 0.357931    Top1 87.616071    Top5 99.564732    LR 0.300000    Time 0.022961    
2018-11-02 21:33:49,869 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58329 |  0.00039 |    0.36892 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15181 |  0.00138 |    0.08893 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15547 |  0.00042 |    0.10651 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19338 | -0.02269 |    0.13850 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19852 | -0.00927 |    0.14912 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20277 | -0.03224 |    0.14687 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18076 |  0.00234 |    0.12795 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21485 | -0.01123 |    0.15747 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18012 | -0.00584 |    0.13772 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39286 | -0.00815 |    0.26417 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15365 | -0.00669 |    0.11624 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13513 | -0.01157 |    0.10647 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15621 | -0.02277 |    0.12262 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12342 | -0.00335 |    0.09499 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15352 | -0.01439 |    0.12167 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13882 | -0.00945 |    0.10964 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21584 | -0.02013 |    0.16681 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13402 | -0.01550 |    0.10574 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10674 | -0.00810 |    0.08243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09382 | -0.00811 |    0.07278 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06768 | -0.00120 |    0.04881 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56664 | -0.00000 |    0.44768 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:33:49,869 - Total sparsity: 0.00

2018-11-02 21:33:49,869 - --- validate (epoch=112)-----------
2018-11-02 21:33:49,869 - 10000 samples (128 per mini-batch)
2018-11-02 21:33:50,595 - Epoch: [112][   50/   78]    Loss 0.412460    Top1 86.078125    Top5 99.375000    
2018-11-02 21:33:50,989 - ==> Top1: 86.340    Top5: 99.430    Loss: 0.398

2018-11-02 21:33:50,989 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:33:50,990 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:33:51,006 - 

2018-11-02 21:33:51,006 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:33:52,175 - Epoch: [113][   50/  391]    Overall Loss 0.329004    Objective Loss 0.329004    Top1 88.703125    Top5 99.671875    LR 0.300000    Time 0.023354    
2018-11-02 21:33:53,316 - Epoch: [113][  100/  391]    Overall Loss 0.334383    Objective Loss 0.334383    Top1 88.414062    Top5 99.687500    LR 0.300000    Time 0.023074    
2018-11-02 21:33:54,457 - Epoch: [113][  150/  391]    Overall Loss 0.338987    Objective Loss 0.338987    Top1 88.250000    Top5 99.687500    LR 0.300000    Time 0.022976    
2018-11-02 21:33:55,602 - Epoch: [113][  200/  391]    Overall Loss 0.345576    Objective Loss 0.345576    Top1 88.156250    Top5 99.636719    LR 0.300000    Time 0.022950    
2018-11-02 21:33:56,741 - Epoch: [113][  250/  391]    Overall Loss 0.346628    Objective Loss 0.346628    Top1 88.075000    Top5 99.621875    LR 0.300000    Time 0.022913    
2018-11-02 21:33:57,884 - Epoch: [113][  300/  391]    Overall Loss 0.346236    Objective Loss 0.346236    Top1 88.111979    Top5 99.609375    LR 0.300000    Time 0.022899    
2018-11-02 21:33:59,026 - Epoch: [113][  350/  391]    Overall Loss 0.346581    Objective Loss 0.346581    Top1 88.107143    Top5 99.611607    LR 0.300000    Time 0.022887    
2018-11-02 21:34:00,046 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58394 |  0.00303 |    0.36760 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15197 |  0.00019 |    0.08911 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15545 |  0.00127 |    0.10662 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19078 | -0.02379 |    0.13671 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19649 | -0.00850 |    0.14823 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20239 | -0.03193 |    0.14801 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18115 |  0.00234 |    0.12704 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21489 | -0.00982 |    0.15693 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17968 | -0.00461 |    0.13778 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39198 | -0.00769 |    0.26831 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15341 | -0.00913 |    0.11632 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13518 | -0.01161 |    0.10656 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15560 | -0.02367 |    0.12199 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12332 | -0.00276 |    0.09464 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15299 | -0.01534 |    0.12111 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13833 | -0.00995 |    0.10938 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21613 | -0.02137 |    0.16688 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13412 | -0.01395 |    0.10565 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10681 | -0.00781 |    0.08232 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09380 | -0.00780 |    0.07274 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06758 | -0.00126 |    0.04868 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56476 | -0.00000 |    0.44689 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:34:00,046 - Total sparsity: 0.00

2018-11-02 21:34:00,046 - --- validate (epoch=113)-----------
2018-11-02 21:34:00,046 - 10000 samples (128 per mini-batch)
2018-11-02 21:34:00,778 - Epoch: [113][   50/   78]    Loss 0.551884    Top1 82.312500    Top5 99.250000    
2018-11-02 21:34:01,175 - ==> Top1: 82.780    Top5: 99.270    Loss: 0.543

2018-11-02 21:34:01,175 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:34:01,176 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:34:01,184 - 

2018-11-02 21:34:01,184 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:34:02,385 - Epoch: [114][   50/  391]    Overall Loss 0.319302    Objective Loss 0.319302    Top1 88.953125    Top5 99.703125    LR 0.300000    Time 0.023982    
2018-11-02 21:34:03,528 - Epoch: [114][  100/  391]    Overall Loss 0.328264    Objective Loss 0.328264    Top1 88.476562    Top5 99.734375    LR 0.300000    Time 0.023408    
2018-11-02 21:34:04,670 - Epoch: [114][  150/  391]    Overall Loss 0.331718    Objective Loss 0.331718    Top1 88.223958    Top5 99.723958    LR 0.300000    Time 0.023205    
2018-11-02 21:34:05,808 - Epoch: [114][  200/  391]    Overall Loss 0.341509    Objective Loss 0.341509    Top1 88.015625    Top5 99.652344    LR 0.300000    Time 0.023072    
2018-11-02 21:34:06,948 - Epoch: [114][  250/  391]    Overall Loss 0.344195    Objective Loss 0.344195    Top1 87.959375    Top5 99.637500    LR 0.300000    Time 0.023010    
2018-11-02 21:34:08,088 - Epoch: [114][  300/  391]    Overall Loss 0.344113    Objective Loss 0.344113    Top1 87.989583    Top5 99.648438    LR 0.300000    Time 0.022971    
2018-11-02 21:34:09,231 - Epoch: [114][  350/  391]    Overall Loss 0.343726    Objective Loss 0.343726    Top1 87.993304    Top5 99.629464    LR 0.300000    Time 0.022952    
2018-11-02 21:34:10,251 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58249 | -0.00812 |    0.36653 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15252 |  0.00414 |    0.08901 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.00121 |    0.10638 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19117 | -0.02168 |    0.13587 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19654 | -0.01242 |    0.14862 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20185 | -0.03193 |    0.14722 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18014 | -0.00019 |    0.12699 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21453 | -0.00983 |    0.15627 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17967 | -0.00630 |    0.13743 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39075 | -0.01339 |    0.26512 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.00967 |    0.11607 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13480 | -0.01093 |    0.10607 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15555 | -0.02285 |    0.12157 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12278 | -0.00208 |    0.09446 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15305 | -0.01408 |    0.12093 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13808 | -0.01015 |    0.10921 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21549 | -0.02123 |    0.16738 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13357 | -0.01426 |    0.10512 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10655 | -0.00786 |    0.08219 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09398 | -0.00804 |    0.07279 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06762 | -0.00077 |    0.04862 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56711 | -0.00000 |    0.44668 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:34:10,251 - Total sparsity: 0.00

2018-11-02 21:34:10,251 - --- validate (epoch=114)-----------
2018-11-02 21:34:10,252 - 10000 samples (128 per mini-batch)
2018-11-02 21:34:10,985 - Epoch: [114][   50/   78]    Loss 0.645550    Top1 80.015625    Top5 99.000000    
2018-11-02 21:34:11,385 - ==> Top1: 80.550    Top5: 99.110    Loss: 0.626

2018-11-02 21:34:11,385 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:34:11,385 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:34:11,394 - 

2018-11-02 21:34:11,394 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:34:12,591 - Epoch: [115][   50/  391]    Overall Loss 0.350901    Objective Loss 0.350901    Top1 87.953125    Top5 99.687500    LR 0.300000    Time 0.023896    
2018-11-02 21:34:13,734 - Epoch: [115][  100/  391]    Overall Loss 0.339238    Objective Loss 0.339238    Top1 88.281250    Top5 99.671875    LR 0.300000    Time 0.023365    
2018-11-02 21:34:14,876 - Epoch: [115][  150/  391]    Overall Loss 0.346118    Objective Loss 0.346118    Top1 87.916667    Top5 99.619792    LR 0.300000    Time 0.023184    
2018-11-02 21:34:16,019 - Epoch: [115][  200/  391]    Overall Loss 0.348559    Objective Loss 0.348559    Top1 87.710938    Top5 99.613281    LR 0.300000    Time 0.023097    
2018-11-02 21:34:17,159 - Epoch: [115][  250/  391]    Overall Loss 0.356639    Objective Loss 0.356639    Top1 87.556250    Top5 99.618750    LR 0.300000    Time 0.023031    
2018-11-02 21:34:18,302 - Epoch: [115][  300/  391]    Overall Loss 0.357339    Objective Loss 0.357339    Top1 87.494792    Top5 99.614583    LR 0.300000    Time 0.022997    
2018-11-02 21:34:19,443 - Epoch: [115][  350/  391]    Overall Loss 0.355854    Objective Loss 0.355854    Top1 87.526786    Top5 99.616071    LR 0.300000    Time 0.022969    
2018-11-02 21:34:20,465 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58391 | -0.00485 |    0.36713 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15260 |  0.00690 |    0.08952 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15623 | -0.00173 |    0.10704 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19175 | -0.02364 |    0.13786 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19721 | -0.00930 |    0.14840 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20354 | -0.02988 |    0.14816 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18091 | -0.00067 |    0.12838 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21527 | -0.00878 |    0.15615 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18076 | -0.00645 |    0.13875 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39216 | -0.01462 |    0.26767 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15336 | -0.00726 |    0.11581 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13499 | -0.01215 |    0.10593 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15589 | -0.02373 |    0.12244 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12286 | -0.00220 |    0.09457 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15394 | -0.01444 |    0.12154 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13881 | -0.01014 |    0.10958 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21652 | -0.02221 |    0.16899 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13400 | -0.01419 |    0.10550 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10691 | -0.00849 |    0.08243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09478 | -0.00752 |    0.07348 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06806 | -0.00051 |    0.04888 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56539 | -0.00000 |    0.44555 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:34:20,465 - Total sparsity: 0.00

2018-11-02 21:34:20,465 - --- validate (epoch=115)-----------
2018-11-02 21:34:20,465 - 10000 samples (128 per mini-batch)
2018-11-02 21:34:21,195 - Epoch: [115][   50/   78]    Loss 0.564161    Top1 82.671875    Top5 99.062500    
2018-11-02 21:34:21,595 - ==> Top1: 82.670    Top5: 99.060    Loss: 0.557

2018-11-02 21:34:21,596 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:34:21,596 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:34:21,604 - 

2018-11-02 21:34:21,605 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:34:22,802 - Epoch: [116][   50/  391]    Overall Loss 0.333288    Objective Loss 0.333288    Top1 88.625000    Top5 99.671875    LR 0.300000    Time 0.023901    
2018-11-02 21:34:23,943 - Epoch: [116][  100/  391]    Overall Loss 0.340168    Objective Loss 0.340168    Top1 88.453125    Top5 99.585938    LR 0.300000    Time 0.023353    
2018-11-02 21:34:25,085 - Epoch: [116][  150/  391]    Overall Loss 0.346464    Objective Loss 0.346464    Top1 88.286458    Top5 99.546875    LR 0.300000    Time 0.023172    
2018-11-02 21:34:26,228 - Epoch: [116][  200/  391]    Overall Loss 0.349537    Objective Loss 0.349537    Top1 88.191406    Top5 99.542969    LR 0.300000    Time 0.023086    
2018-11-02 21:34:27,369 - Epoch: [116][  250/  391]    Overall Loss 0.347111    Objective Loss 0.347111    Top1 88.156250    Top5 99.559375    LR 0.300000    Time 0.023028    
2018-11-02 21:34:28,510 - Epoch: [116][  300/  391]    Overall Loss 0.351174    Objective Loss 0.351174    Top1 88.028646    Top5 99.554688    LR 0.300000    Time 0.022987    
2018-11-02 21:34:29,651 - Epoch: [116][  350/  391]    Overall Loss 0.353172    Objective Loss 0.353172    Top1 87.973214    Top5 99.544643    LR 0.300000    Time 0.022960    
2018-11-02 21:34:30,671 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57833 | -0.00580 |    0.36492 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15165 |  0.00039 |    0.08817 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15500 |  0.00057 |    0.10524 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19126 | -0.02335 |    0.13749 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19575 | -0.01136 |    0.14738 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20261 | -0.03085 |    0.14676 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18117 | -0.00058 |    0.12866 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21453 | -0.01235 |    0.15577 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17998 | -0.00635 |    0.13777 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39335 | -0.01207 |    0.26745 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15326 | -0.00815 |    0.11598 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13526 | -0.01287 |    0.10618 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15567 | -0.02536 |    0.12248 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12266 | -0.00094 |    0.09433 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15309 | -0.01396 |    0.12094 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13835 | -0.00983 |    0.10910 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21742 | -0.02221 |    0.16994 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13391 | -0.01398 |    0.10529 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10691 | -0.00772 |    0.08243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09498 | -0.00759 |    0.07374 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06790 | -0.00053 |    0.04880 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56341 | -0.00000 |    0.44179 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:34:30,671 - Total sparsity: 0.00

2018-11-02 21:34:30,671 - --- validate (epoch=116)-----------
2018-11-02 21:34:30,671 - 10000 samples (128 per mini-batch)
2018-11-02 21:34:31,391 - Epoch: [116][   50/   78]    Loss 0.512306    Top1 83.734375    Top5 99.234375    
2018-11-02 21:34:31,780 - ==> Top1: 83.680    Top5: 99.340    Loss: 0.510

2018-11-02 21:34:31,781 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:34:31,781 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:34:31,793 - 

2018-11-02 21:34:31,793 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:34:32,991 - Epoch: [117][   50/  391]    Overall Loss 0.354314    Objective Loss 0.354314    Top1 88.156250    Top5 99.687500    LR 0.300000    Time 0.023927    
2018-11-02 21:34:34,133 - Epoch: [117][  100/  391]    Overall Loss 0.338712    Objective Loss 0.338712    Top1 88.640625    Top5 99.640625    LR 0.300000    Time 0.023371    
2018-11-02 21:34:35,276 - Epoch: [117][  150/  391]    Overall Loss 0.339697    Objective Loss 0.339697    Top1 88.541667    Top5 99.645833    LR 0.300000    Time 0.023186    
2018-11-02 21:34:36,418 - Epoch: [117][  200/  391]    Overall Loss 0.340104    Objective Loss 0.340104    Top1 88.406250    Top5 99.667969    LR 0.300000    Time 0.023093    
2018-11-02 21:34:37,560 - Epoch: [117][  250/  391]    Overall Loss 0.345998    Objective Loss 0.345998    Top1 88.278125    Top5 99.650000    LR 0.300000    Time 0.023036    
2018-11-02 21:34:38,703 - Epoch: [117][  300/  391]    Overall Loss 0.350432    Objective Loss 0.350432    Top1 88.101562    Top5 99.651042    LR 0.300000    Time 0.023004    
2018-11-02 21:34:39,844 - Epoch: [117][  350/  391]    Overall Loss 0.352743    Objective Loss 0.352743    Top1 87.970982    Top5 99.625000    LR 0.300000    Time 0.022973    
2018-11-02 21:34:40,863 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58168 | -0.00096 |    0.36212 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15336 |  0.00013 |    0.08960 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15599 |  0.00162 |    0.10554 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19108 | -0.02520 |    0.13854 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19617 | -0.00665 |    0.14747 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20291 | -0.03033 |    0.14651 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18189 |  0.00261 |    0.12951 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21528 | -0.00932 |    0.15659 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18014 | -0.00646 |    0.13762 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39365 | -0.00715 |    0.26851 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15391 | -0.00665 |    0.11600 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13609 | -0.01250 |    0.10680 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15596 | -0.02606 |    0.12268 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12285 | -0.00077 |    0.09445 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15333 | -0.01448 |    0.12123 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13877 | -0.01026 |    0.10970 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21763 | -0.02141 |    0.16868 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13407 | -0.01418 |    0.10558 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10720 | -0.00784 |    0.08271 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09550 | -0.00809 |    0.07407 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06804 | -0.00092 |    0.04888 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56466 | -0.00000 |    0.44450 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:34:40,863 - Total sparsity: 0.00

2018-11-02 21:34:40,863 - --- validate (epoch=117)-----------
2018-11-02 21:34:40,863 - 10000 samples (128 per mini-batch)
2018-11-02 21:34:41,593 - Epoch: [117][   50/   78]    Loss 0.577824    Top1 83.203125    Top5 99.093750    
2018-11-02 21:34:41,990 - ==> Top1: 83.090    Top5: 99.140    Loss: 0.571

2018-11-02 21:34:41,991 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:34:41,991 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:34:42,003 - 

2018-11-02 21:34:42,003 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:34:43,203 - Epoch: [118][   50/  391]    Overall Loss 0.317889    Objective Loss 0.317889    Top1 89.109375    Top5 99.640625    LR 0.300000    Time 0.023965    
2018-11-02 21:34:44,345 - Epoch: [118][  100/  391]    Overall Loss 0.327573    Objective Loss 0.327573    Top1 88.726562    Top5 99.671875    LR 0.300000    Time 0.023389    
2018-11-02 21:34:45,487 - Epoch: [118][  150/  391]    Overall Loss 0.337918    Objective Loss 0.337918    Top1 88.520833    Top5 99.651042    LR 0.300000    Time 0.023197    
2018-11-02 21:34:46,631 - Epoch: [118][  200/  391]    Overall Loss 0.340188    Objective Loss 0.340188    Top1 88.359375    Top5 99.640625    LR 0.300000    Time 0.023109    
2018-11-02 21:34:47,773 - Epoch: [118][  250/  391]    Overall Loss 0.341165    Objective Loss 0.341165    Top1 88.362500    Top5 99.615625    LR 0.300000    Time 0.023053    
2018-11-02 21:34:48,918 - Epoch: [118][  300/  391]    Overall Loss 0.346346    Objective Loss 0.346346    Top1 88.132812    Top5 99.598958    LR 0.300000    Time 0.023022    
2018-11-02 21:34:50,061 - Epoch: [118][  350/  391]    Overall Loss 0.346611    Objective Loss 0.346611    Top1 88.082589    Top5 99.602679    LR 0.300000    Time 0.022996    
2018-11-02 21:34:51,078 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57764 | -0.00714 |    0.35942 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15153 |  0.00229 |    0.08797 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15465 | -0.00299 |    0.10538 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19093 | -0.02345 |    0.13721 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19584 | -0.00948 |    0.14760 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20190 | -0.02966 |    0.14614 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18130 | -0.00095 |    0.12838 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21470 | -0.00928 |    0.15622 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17945 | -0.00734 |    0.13713 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39284 | -0.00246 |    0.26815 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15321 | -0.00746 |    0.11531 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13568 | -0.01102 |    0.10612 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15613 | -0.02508 |    0.12262 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12312 | -0.00119 |    0.09521 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15286 | -0.01420 |    0.12092 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13852 | -0.00973 |    0.10931 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21755 | -0.02177 |    0.16912 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13396 | -0.01352 |    0.10541 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10728 | -0.00799 |    0.08279 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09590 | -0.00811 |    0.07428 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06828 | -0.00055 |    0.04903 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56432 | -0.00000 |    0.44360 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:34:51,079 - Total sparsity: 0.00

2018-11-02 21:34:51,079 - --- validate (epoch=118)-----------
2018-11-02 21:34:51,079 - 10000 samples (128 per mini-batch)
2018-11-02 21:34:51,808 - Epoch: [118][   50/   78]    Loss 0.581377    Top1 81.562500    Top5 99.062500    
2018-11-02 21:34:52,199 - ==> Top1: 81.410    Top5: 99.160    Loss: 0.579

2018-11-02 21:34:52,200 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:34:52,200 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:34:52,209 - 

2018-11-02 21:34:52,209 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:34:53,405 - Epoch: [119][   50/  391]    Overall Loss 0.309591    Objective Loss 0.309591    Top1 88.953125    Top5 99.656250    LR 0.300000    Time 0.023889    
2018-11-02 21:34:54,546 - Epoch: [119][  100/  391]    Overall Loss 0.336421    Objective Loss 0.336421    Top1 88.117188    Top5 99.625000    LR 0.300000    Time 0.023341    
2018-11-02 21:34:55,688 - Epoch: [119][  150/  391]    Overall Loss 0.338255    Objective Loss 0.338255    Top1 88.140625    Top5 99.593750    LR 0.300000    Time 0.023161    
2018-11-02 21:34:56,828 - Epoch: [119][  200/  391]    Overall Loss 0.340081    Objective Loss 0.340081    Top1 88.164062    Top5 99.593750    LR 0.300000    Time 0.023066    
2018-11-02 21:34:57,970 - Epoch: [119][  250/  391]    Overall Loss 0.342082    Objective Loss 0.342082    Top1 88.100000    Top5 99.593750    LR 0.300000    Time 0.023015    
2018-11-02 21:34:59,113 - Epoch: [119][  300/  391]    Overall Loss 0.346321    Objective Loss 0.346321    Top1 87.981771    Top5 99.578125    LR 0.300000    Time 0.022986    
2018-11-02 21:35:00,257 - Epoch: [119][  350/  391]    Overall Loss 0.348946    Objective Loss 0.348946    Top1 87.982143    Top5 99.546875    LR 0.300000    Time 0.022967    
2018-11-02 21:35:01,281 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57777 |  0.00078 |    0.35939 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15192 |  0.00155 |    0.08958 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15485 | -0.00370 |    0.10626 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19196 | -0.02280 |    0.13791 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19633 | -0.00874 |    0.14696 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20034 | -0.03112 |    0.14515 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18018 |  0.00153 |    0.12741 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21419 | -0.01013 |    0.15614 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17952 | -0.00627 |    0.13746 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39319 | -0.00925 |    0.26537 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15336 | -0.00728 |    0.11512 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13582 | -0.01148 |    0.10625 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15587 | -0.02451 |    0.12208 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12295 | -0.00033 |    0.09485 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15320 | -0.01436 |    0.12106 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13854 | -0.00967 |    0.10930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21729 | -0.02137 |    0.16877 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13373 | -0.01340 |    0.10536 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10744 | -0.00804 |    0.08292 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09627 | -0.00827 |    0.07450 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06862 | -0.00046 |    0.04929 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56709 | -0.00000 |    0.44440 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:35:01,281 - Total sparsity: 0.00

2018-11-02 21:35:01,281 - --- validate (epoch=119)-----------
2018-11-02 21:35:01,282 - 10000 samples (128 per mini-batch)
2018-11-02 21:35:02,011 - Epoch: [119][   50/   78]    Loss 0.726162    Top1 79.078125    Top5 98.500000    
2018-11-02 21:35:02,407 - ==> Top1: 79.380    Top5: 98.500    Loss: 0.712

2018-11-02 21:35:02,408 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:35:02,408 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:35:02,416 - 

2018-11-02 21:35:02,417 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-02 21:35:02,418 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.750 goal=0.800 (12/16)
2018-11-02 21:35:02,418 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-02 21:35:02,419 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-02 21:35:02,420 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.781 goal=0.800 (25/32)
2018-11-02 21:35:02,421 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.781 goal=0.800 (25/32)
2018-11-02 21:35:02,422 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.391 goal=0.400 (25/64)
2018-11-02 21:35:02,423 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.391 goal=0.400 (25/64)
2018-11-02 21:35:02,424 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.391 goal=0.400 (25/64)
2018-11-02 21:35:02,424 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:35:02,466 - ==> using cifar10 dataset
2018-11-02 21:35:02,466 - => creating resnet20_cifar model for CIFAR10
2018-11-02 21:35:02,500 - Invoking create_thinning_recipe_filters
2018-11-02 21:35:02,501 - In tensor module.layer1.0.conv1.weight found 9/16 zero filters
2018-11-02 21:35:02,502 - In tensor module.layer1.1.conv1.weight found 12/16 zero filters
2018-11-02 21:35:02,503 - In tensor module.layer1.2.conv1.weight found 9/16 zero filters
2018-11-02 21:35:02,504 - In tensor module.layer2.0.conv1.weight found 19/32 zero filters
2018-11-02 21:35:02,506 - In tensor module.layer2.1.conv1.weight found 25/32 zero filters
2018-11-02 21:35:02,507 - In tensor module.layer2.2.conv1.weight found 25/32 zero filters
2018-11-02 21:35:02,508 - In tensor module.layer3.0.conv1.weight found 25/64 zero filters
2018-11-02 21:35:02,509 - In tensor module.layer3.1.conv1.weight found 25/64 zero filters
2018-11-02 21:35:02,510 - In tensor module.layer3.2.conv1.weight found 25/64 zero filters
2018-11-02 21:35:02,517 - Created, applied and saved a thinning recipe
2018-11-02 21:35:03,506 - Epoch: [120][   50/  391]    Overall Loss 0.737524    Objective Loss 0.737524    Top1 75.000000    Top5 98.281250    LR 0.300000    Time 0.021595    
2018-11-02 21:35:04,503 - Epoch: [120][  100/  391]    Overall Loss 0.658832    Objective Loss 0.658832    Top1 77.289062    Top5 98.562500    LR 0.300000    Time 0.020760    
2018-11-02 21:35:05,501 - Epoch: [120][  150/  391]    Overall Loss 0.617546    Objective Loss 0.617546    Top1 78.635417    Top5 98.697917    LR 0.300000    Time 0.020481    
2018-11-02 21:35:06,498 - Epoch: [120][  200/  391]    Overall Loss 0.595291    Objective Loss 0.595291    Top1 79.476562    Top5 98.792969    LR 0.300000    Time 0.020336    
2018-11-02 21:35:07,495 - Epoch: [120][  250/  391]    Overall Loss 0.584380    Objective Loss 0.584380    Top1 79.812500    Top5 98.850000    LR 0.300000    Time 0.020251    
2018-11-02 21:35:08,493 - Epoch: [120][  300/  391]    Overall Loss 0.573821    Objective Loss 0.573821    Top1 80.184896    Top5 98.888021    LR 0.300000    Time 0.020200    
2018-11-02 21:35:09,491 - Epoch: [120][  350/  391]    Overall Loss 0.566123    Objective Loss 0.566123    Top1 80.433036    Top5 98.906250    LR 0.300000    Time 0.020160    
2018-11-02 21:35:10,394 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59159 | -0.00629 |    0.37057 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21674 |  0.00496 |    0.13128 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22882 | -0.00908 |    0.16818 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27912 | -0.07690 |    0.21935 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29837 |  0.00722 |    0.23776 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25159 | -0.04022 |    0.18904 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25452 |  0.00059 |    0.18670 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28418 | -0.01383 |    0.21589 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23163 | -0.01135 |    0.17793 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41948 | -0.01513 |    0.29123 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21177 | -0.00570 |    0.15948 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17558 | -0.01583 |    0.13984 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21432 | -0.02969 |    0.16857 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16217 | -0.00370 |    0.12499 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17576 | -0.02504 |    0.14075 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15874 | -0.00371 |    0.12492 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23142 | -0.02548 |    0.18246 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15142 | -0.01821 |    0.11962 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12076 | -0.00592 |    0.09279 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11337 | -0.01333 |    0.08868 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07943 |  0.00294 |    0.05658 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55775 | -0.00000 |    0.43679 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:35:10,394 - Total sparsity: 0.00

2018-11-02 21:35:10,394 - --- validate (epoch=120)-----------
2018-11-02 21:35:10,395 - 10000 samples (128 per mini-batch)
2018-11-02 21:35:11,121 - Epoch: [120][   50/   78]    Loss 0.582734    Top1 80.406250    Top5 99.015625    
2018-11-02 21:35:11,516 - ==> Top1: 80.430    Top5: 99.050    Loss: 0.577

2018-11-02 21:35:11,516 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:35:11,517 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:35:11,524 - 

2018-11-02 21:35:11,525 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:35:12,577 - Epoch: [121][   50/  391]    Overall Loss 0.462081    Objective Loss 0.462081    Top1 84.531250    Top5 99.359375    LR 0.300000    Time 0.021005    
2018-11-02 21:35:13,554 - Epoch: [121][  100/  391]    Overall Loss 0.477437    Objective Loss 0.477437    Top1 83.921875    Top5 99.148438    LR 0.300000    Time 0.020261    
2018-11-02 21:35:14,532 - Epoch: [121][  150/  391]    Overall Loss 0.473099    Objective Loss 0.473099    Top1 83.958333    Top5 99.151042    LR 0.300000    Time 0.020018    
2018-11-02 21:35:15,508 - Epoch: [121][  200/  391]    Overall Loss 0.474132    Objective Loss 0.474132    Top1 83.855469    Top5 99.148438    LR 0.300000    Time 0.019887    
2018-11-02 21:35:16,485 - Epoch: [121][  250/  391]    Overall Loss 0.475011    Objective Loss 0.475011    Top1 83.812500    Top5 99.162500    LR 0.300000    Time 0.019812    
2018-11-02 21:35:17,466 - Epoch: [121][  300/  391]    Overall Loss 0.477597    Objective Loss 0.477597    Top1 83.690104    Top5 99.166667    LR 0.300000    Time 0.019777    
2018-11-02 21:35:18,445 - Epoch: [121][  350/  391]    Overall Loss 0.478468    Objective Loss 0.478468    Top1 83.665179    Top5 99.171875    LR 0.300000    Time 0.019745    
2018-11-02 21:35:19,328 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59361 |  0.00328 |    0.36981 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22552 | -0.00071 |    0.13590 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23727 | -0.01463 |    0.17459 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28910 | -0.08128 |    0.22498 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31135 |  0.00897 |    0.24848 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25794 | -0.04464 |    0.19485 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26149 | -0.00087 |    0.19241 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29867 | -0.01828 |    0.22728 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24367 | -0.01306 |    0.18762 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42649 | -0.01495 |    0.29376 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22203 | -0.00330 |    0.16667 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18225 | -0.01650 |    0.14453 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21983 | -0.02841 |    0.17255 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16645 | -0.00471 |    0.12797 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18205 | -0.02342 |    0.14544 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16401 | -0.00470 |    0.12907 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23526 | -0.02528 |    0.18548 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15468 | -0.01910 |    0.12240 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12384 | -0.00685 |    0.09529 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11643 | -0.01538 |    0.09132 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08209 |  0.00249 |    0.05867 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56922 | -0.00000 |    0.44423 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:35:19,329 - Total sparsity: 0.00

2018-11-02 21:35:19,329 - --- validate (epoch=121)-----------
2018-11-02 21:35:19,329 - 10000 samples (128 per mini-batch)
2018-11-02 21:35:20,055 - Epoch: [121][   50/   78]    Loss 0.768672    Top1 75.265625    Top5 97.578125    
2018-11-02 21:35:20,448 - ==> Top1: 75.130    Top5: 97.580    Loss: 0.768

2018-11-02 21:35:20,449 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:35:20,449 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:35:20,464 - 

2018-11-02 21:35:20,464 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:35:21,524 - Epoch: [122][   50/  391]    Overall Loss 0.449672    Objective Loss 0.449672    Top1 84.437500    Top5 99.531250    LR 0.285000    Time 0.021150    
2018-11-02 21:35:22,504 - Epoch: [122][  100/  391]    Overall Loss 0.449680    Objective Loss 0.449680    Top1 84.539062    Top5 99.437500    LR 0.285000    Time 0.020362    
2018-11-02 21:35:23,483 - Epoch: [122][  150/  391]    Overall Loss 0.450210    Objective Loss 0.450210    Top1 84.463542    Top5 99.411458    LR 0.285000    Time 0.020094    
2018-11-02 21:35:24,462 - Epoch: [122][  200/  391]    Overall Loss 0.446611    Objective Loss 0.446611    Top1 84.566406    Top5 99.441406    LR 0.285000    Time 0.019959    
2018-11-02 21:35:25,442 - Epoch: [122][  250/  391]    Overall Loss 0.443884    Objective Loss 0.443884    Top1 84.700000    Top5 99.431250    LR 0.285000    Time 0.019883    
2018-11-02 21:35:26,421 - Epoch: [122][  300/  391]    Overall Loss 0.446796    Objective Loss 0.446796    Top1 84.653646    Top5 99.377604    LR 0.285000    Time 0.019828    
2018-11-02 21:35:27,401 - Epoch: [122][  350/  391]    Overall Loss 0.445769    Objective Loss 0.445769    Top1 84.696429    Top5 99.377232    LR 0.285000    Time 0.019793    
2018-11-02 21:35:28,283 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58904 | -0.00919 |    0.36876 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22777 | -0.00002 |    0.13666 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23877 | -0.01423 |    0.17574 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28906 | -0.08109 |    0.22377 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31358 |  0.00967 |    0.25043 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26126 | -0.04330 |    0.19744 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26409 | -0.00229 |    0.19210 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30288 | -0.01209 |    0.22783 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24794 | -0.01070 |    0.19156 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42970 | -0.01477 |    0.29205 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22688 | -0.00434 |    0.16983 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18479 | -0.01734 |    0.14627 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22029 | -0.02937 |    0.17368 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16737 | -0.00470 |    0.12926 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18427 | -0.02557 |    0.14750 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16644 | -0.00409 |    0.13094 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23628 | -0.02434 |    0.18487 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15594 | -0.01890 |    0.12346 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12517 | -0.00767 |    0.09668 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11845 | -0.01501 |    0.09319 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08320 |  0.00287 |    0.05944 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57267 | -0.00000 |    0.44609 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:35:28,283 - Total sparsity: 0.00

2018-11-02 21:35:28,283 - --- validate (epoch=122)-----------
2018-11-02 21:35:28,283 - 10000 samples (128 per mini-batch)
2018-11-02 21:35:29,009 - Epoch: [122][   50/   78]    Loss 0.638227    Top1 79.562500    Top5 99.125000    
2018-11-02 21:35:29,403 - ==> Top1: 79.610    Top5: 99.030    Loss: 0.644

2018-11-02 21:35:29,404 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:35:29,404 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:35:29,411 - 

2018-11-02 21:35:29,411 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:35:30,449 - Epoch: [123][   50/  391]    Overall Loss 0.447449    Objective Loss 0.447449    Top1 84.375000    Top5 99.375000    LR 0.270750    Time 0.020720    
2018-11-02 21:35:31,428 - Epoch: [123][  100/  391]    Overall Loss 0.434380    Objective Loss 0.434380    Top1 84.984375    Top5 99.406250    LR 0.270750    Time 0.020137    
2018-11-02 21:35:32,405 - Epoch: [123][  150/  391]    Overall Loss 0.433870    Objective Loss 0.433870    Top1 85.151042    Top5 99.406250    LR 0.270750    Time 0.019926    
2018-11-02 21:35:33,384 - Epoch: [123][  200/  391]    Overall Loss 0.431679    Objective Loss 0.431679    Top1 85.289062    Top5 99.410156    LR 0.270750    Time 0.019835    
2018-11-02 21:35:34,362 - Epoch: [123][  250/  391]    Overall Loss 0.432788    Objective Loss 0.432788    Top1 85.190625    Top5 99.396875    LR 0.270750    Time 0.019774    
2018-11-02 21:35:35,339 - Epoch: [123][  300/  391]    Overall Loss 0.428482    Objective Loss 0.428482    Top1 85.302083    Top5 99.388021    LR 0.270750    Time 0.019730    
2018-11-02 21:35:36,319 - Epoch: [123][  350/  391]    Overall Loss 0.427565    Objective Loss 0.427565    Top1 85.345982    Top5 99.399554    LR 0.270750    Time 0.019709    
2018-11-02 21:35:37,200 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58664 | -0.01433 |    0.36997 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23111 |  0.00061 |    0.14256 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24173 | -0.00729 |    0.17751 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28958 | -0.08315 |    0.22505 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31535 |  0.01586 |    0.25187 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26287 | -0.03861 |    0.19833 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26439 | -0.00695 |    0.19333 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30562 | -0.01887 |    0.22973 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25014 | -0.01248 |    0.19256 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42894 | -0.01891 |    0.29447 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22977 | -0.00364 |    0.17330 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18683 | -0.01851 |    0.14863 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21984 | -0.02829 |    0.17256 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16690 | -0.00727 |    0.12902 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18484 | -0.02485 |    0.14796 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16726 | -0.00434 |    0.13199 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23620 | -0.02363 |    0.18455 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15637 | -0.01814 |    0.12347 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12609 | -0.00852 |    0.09752 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12001 | -0.01402 |    0.09428 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08405 |  0.00247 |    0.06025 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57084 | -0.00000 |    0.44551 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:35:37,200 - Total sparsity: 0.00

2018-11-02 21:35:37,200 - --- validate (epoch=123)-----------
2018-11-02 21:35:37,200 - 10000 samples (128 per mini-batch)
2018-11-02 21:35:37,914 - Epoch: [123][   50/   78]    Loss 0.736519    Top1 77.281250    Top5 98.906250    
2018-11-02 21:35:38,302 - ==> Top1: 77.060    Top5: 98.940    Loss: 0.735

2018-11-02 21:35:38,303 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:35:38,303 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:35:38,314 - 

2018-11-02 21:35:38,315 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:35:39,351 - Epoch: [124][   50/  391]    Overall Loss 0.389562    Objective Loss 0.389562    Top1 86.203125    Top5 99.500000    LR 0.257212    Time 0.020699    
2018-11-02 21:35:40,331 - Epoch: [124][  100/  391]    Overall Loss 0.391807    Objective Loss 0.391807    Top1 86.179688    Top5 99.468750    LR 0.257212    Time 0.020128    
2018-11-02 21:35:41,311 - Epoch: [124][  150/  391]    Overall Loss 0.388307    Objective Loss 0.388307    Top1 86.390625    Top5 99.432292    LR 0.257212    Time 0.019948    
2018-11-02 21:35:42,290 - Epoch: [124][  200/  391]    Overall Loss 0.394061    Objective Loss 0.394061    Top1 86.234375    Top5 99.476562    LR 0.257212    Time 0.019848    
2018-11-02 21:35:43,267 - Epoch: [124][  250/  391]    Overall Loss 0.400198    Objective Loss 0.400198    Top1 86.059375    Top5 99.421875    LR 0.257212    Time 0.019782    
2018-11-02 21:35:44,246 - Epoch: [124][  300/  391]    Overall Loss 0.403290    Objective Loss 0.403290    Top1 85.973958    Top5 99.445312    LR 0.257212    Time 0.019741    
2018-11-02 21:35:45,223 - Epoch: [124][  350/  391]    Overall Loss 0.406565    Objective Loss 0.406565    Top1 85.924107    Top5 99.437500    LR 0.257212    Time 0.019708    
2018-11-02 21:35:46,107 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58732 | -0.00831 |    0.37222 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23461 | -0.00214 |    0.14492 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24421 | -0.01032 |    0.18110 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29226 | -0.08134 |    0.22519 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31768 |  0.01140 |    0.25048 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26256 | -0.04395 |    0.19931 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26576 | -0.01042 |    0.19421 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30824 | -0.01433 |    0.23082 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25206 | -0.01270 |    0.19472 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42723 | -0.01405 |    0.29035 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23098 | -0.00747 |    0.17295 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18719 | -0.01869 |    0.14850 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21921 | -0.02602 |    0.17345 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16597 | -0.00679 |    0.12822 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18452 | -0.02535 |    0.14756 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16737 | -0.00520 |    0.13198 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23603 | -0.02108 |    0.18345 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15605 | -0.01810 |    0.12354 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12622 | -0.00845 |    0.09759 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12070 | -0.01490 |    0.09502 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08431 |  0.00295 |    0.06041 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56881 | -0.00000 |    0.44250 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:35:46,107 - Total sparsity: 0.00

2018-11-02 21:35:46,107 - --- validate (epoch=124)-----------
2018-11-02 21:35:46,107 - 10000 samples (128 per mini-batch)
2018-11-02 21:35:46,856 - Epoch: [124][   50/   78]    Loss 0.607569    Top1 80.406250    Top5 98.906250    
2018-11-02 21:35:47,251 - ==> Top1: 80.020    Top5: 98.990    Loss: 0.607

2018-11-02 21:35:47,251 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:35:47,252 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:35:47,259 - 

2018-11-02 21:35:47,260 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:35:48,296 - Epoch: [125][   50/  391]    Overall Loss 0.396533    Objective Loss 0.396533    Top1 86.375000    Top5 99.531250    LR 0.244352    Time 0.020699    
2018-11-02 21:35:49,310 - Epoch: [125][  100/  391]    Overall Loss 0.398227    Objective Loss 0.398227    Top1 86.109375    Top5 99.578125    LR 0.244352    Time 0.020469    
2018-11-02 21:35:50,325 - Epoch: [125][  150/  391]    Overall Loss 0.392968    Objective Loss 0.392968    Top1 86.406250    Top5 99.572917    LR 0.244352    Time 0.020408    
2018-11-02 21:35:51,305 - Epoch: [125][  200/  391]    Overall Loss 0.393509    Objective Loss 0.393509    Top1 86.347656    Top5 99.546875    LR 0.244352    Time 0.020183    
2018-11-02 21:35:52,284 - Epoch: [125][  250/  391]    Overall Loss 0.395154    Objective Loss 0.395154    Top1 86.346875    Top5 99.540625    LR 0.244352    Time 0.020056    
2018-11-02 21:35:53,261 - Epoch: [125][  300/  391]    Overall Loss 0.396588    Objective Loss 0.396588    Top1 86.263021    Top5 99.531250    LR 0.244352    Time 0.019964    
2018-11-02 21:35:54,239 - Epoch: [125][  350/  391]    Overall Loss 0.398993    Objective Loss 0.398993    Top1 86.234375    Top5 99.522321    LR 0.244352    Time 0.019904    
2018-11-02 21:35:55,121 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57900 | -0.00799 |    0.36249 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23362 |  0.00129 |    0.14322 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24242 | -0.00831 |    0.17941 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29227 | -0.07658 |    0.22425 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31614 |  0.01148 |    0.25035 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26018 | -0.04201 |    0.19609 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26261 | -0.00806 |    0.19103 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30790 | -0.01641 |    0.23054 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25189 | -0.01214 |    0.19430 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42300 | -0.01496 |    0.29219 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23004 | -0.00385 |    0.17321 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18671 | -0.01903 |    0.14779 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21948 | -0.02502 |    0.17266 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16453 | -0.00840 |    0.12716 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18381 | -0.02621 |    0.14695 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16692 | -0.00519 |    0.13172 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23358 | -0.02211 |    0.18124 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15559 | -0.01831 |    0.12324 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12596 | -0.00884 |    0.09755 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12060 | -0.01577 |    0.09506 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08417 |  0.00300 |    0.06034 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57162 | -0.00000 |    0.44590 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:35:55,121 - Total sparsity: 0.00

2018-11-02 21:35:55,122 - --- validate (epoch=125)-----------
2018-11-02 21:35:55,122 - 10000 samples (128 per mini-batch)
2018-11-02 21:35:55,845 - Epoch: [125][   50/   78]    Loss 0.462904    Top1 84.703125    Top5 99.281250    
2018-11-02 21:35:56,231 - ==> Top1: 84.480    Top5: 99.260    Loss: 0.468

2018-11-02 21:35:56,231 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:35:56,232 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:35:56,239 - 

2018-11-02 21:35:56,239 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:35:57,276 - Epoch: [126][   50/  391]    Overall Loss 0.333063    Objective Loss 0.333063    Top1 88.718750    Top5 99.437500    LR 0.232134    Time 0.020703    
2018-11-02 21:35:58,254 - Epoch: [126][  100/  391]    Overall Loss 0.353679    Objective Loss 0.353679    Top1 87.835938    Top5 99.492188    LR 0.232134    Time 0.020116    
2018-11-02 21:35:59,234 - Epoch: [126][  150/  391]    Overall Loss 0.371721    Objective Loss 0.371721    Top1 87.375000    Top5 99.453125    LR 0.232134    Time 0.019941    
2018-11-02 21:36:00,214 - Epoch: [126][  200/  391]    Overall Loss 0.379329    Objective Loss 0.379329    Top1 87.128906    Top5 99.437500    LR 0.232134    Time 0.019849    
2018-11-02 21:36:01,193 - Epoch: [126][  250/  391]    Overall Loss 0.383417    Objective Loss 0.383417    Top1 86.956250    Top5 99.434375    LR 0.232134    Time 0.019787    
2018-11-02 21:36:02,171 - Epoch: [126][  300/  391]    Overall Loss 0.385689    Objective Loss 0.385689    Top1 86.791667    Top5 99.427083    LR 0.232134    Time 0.019748    
2018-11-02 21:36:03,150 - Epoch: [126][  350/  391]    Overall Loss 0.385639    Objective Loss 0.385639    Top1 86.792411    Top5 99.433036    LR 0.232134    Time 0.019720    
2018-11-02 21:36:04,030 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57417 | -0.00929 |    0.35770 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23438 | -0.00336 |    0.14411 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24189 | -0.00918 |    0.17844 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29016 | -0.07667 |    0.22233 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31415 |  0.01488 |    0.24786 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25982 | -0.04100 |    0.19565 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26122 | -0.00938 |    0.18980 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30584 | -0.01354 |    0.22791 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25013 | -0.01341 |    0.19227 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41784 | -0.01670 |    0.28529 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22713 | -0.00342 |    0.17094 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18537 | -0.02030 |    0.14705 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21944 | -0.02290 |    0.17183 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16391 | -0.00773 |    0.12612 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18266 | -0.02612 |    0.14634 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16624 | -0.00525 |    0.13124 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23137 | -0.02229 |    0.17997 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15482 | -0.01825 |    0.12268 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12564 | -0.00877 |    0.09736 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12074 | -0.01544 |    0.09512 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08395 |  0.00271 |    0.06022 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57269 | -0.00000 |    0.44669 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:36:04,031 - Total sparsity: 0.00

2018-11-02 21:36:04,031 - --- validate (epoch=126)-----------
2018-11-02 21:36:04,031 - 10000 samples (128 per mini-batch)
2018-11-02 21:36:04,752 - Epoch: [126][   50/   78]    Loss 0.617276    Top1 80.703125    Top5 98.500000    
2018-11-02 21:36:05,143 - ==> Top1: 80.680    Top5: 98.450    Loss: 0.617

2018-11-02 21:36:05,144 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:36:05,144 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:36:05,152 - 

2018-11-02 21:36:05,152 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:36:06,190 - Epoch: [127][   50/  391]    Overall Loss 0.358952    Objective Loss 0.358952    Top1 87.484375    Top5 99.593750    LR 0.220528    Time 0.020725    
2018-11-02 21:36:07,169 - Epoch: [127][  100/  391]    Overall Loss 0.371624    Objective Loss 0.371624    Top1 86.921875    Top5 99.554688    LR 0.220528    Time 0.020137    
2018-11-02 21:36:08,148 - Epoch: [127][  150/  391]    Overall Loss 0.370678    Objective Loss 0.370678    Top1 87.072917    Top5 99.562500    LR 0.220528    Time 0.019948    
2018-11-02 21:36:09,124 - Epoch: [127][  200/  391]    Overall Loss 0.373780    Objective Loss 0.373780    Top1 87.035156    Top5 99.542969    LR 0.220528    Time 0.019835    
2018-11-02 21:36:10,115 - Epoch: [127][  250/  391]    Overall Loss 0.377256    Objective Loss 0.377256    Top1 86.915625    Top5 99.559375    LR 0.220528    Time 0.019823    
2018-11-02 21:36:11,095 - Epoch: [127][  300/  391]    Overall Loss 0.376341    Objective Loss 0.376341    Top1 86.966146    Top5 99.528646    LR 0.220528    Time 0.019783    
2018-11-02 21:36:12,071 - Epoch: [127][  350/  391]    Overall Loss 0.374952    Objective Loss 0.374952    Top1 87.000000    Top5 99.531250    LR 0.220528    Time 0.019741    
2018-11-02 21:36:12,955 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56859 | -0.00561 |    0.35591 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23404 |  0.00152 |    0.14483 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24045 | -0.00751 |    0.17815 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28798 | -0.07802 |    0.22330 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31365 |  0.01154 |    0.24947 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25784 | -0.04594 |    0.19398 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25999 | -0.00994 |    0.18800 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30428 | -0.01259 |    0.22601 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24868 | -0.01100 |    0.19079 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41339 | -0.01547 |    0.27995 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22535 | -0.00695 |    0.16883 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18507 | -0.02025 |    0.14689 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21741 | -0.02466 |    0.17125 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16206 | -0.00940 |    0.12506 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18171 | -0.02505 |    0.14541 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16564 | -0.00481 |    0.13037 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22934 | -0.02201 |    0.17814 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15403 | -0.01830 |    0.12224 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12531 | -0.00871 |    0.09716 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12102 | -0.01471 |    0.09512 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08377 |  0.00306 |    0.06015 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57282 | -0.00000 |    0.44530 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:36:12,955 - Total sparsity: 0.00

2018-11-02 21:36:12,955 - --- validate (epoch=127)-----------
2018-11-02 21:36:12,955 - 10000 samples (128 per mini-batch)
2018-11-02 21:36:13,679 - Epoch: [127][   50/   78]    Loss 0.544251    Top1 82.250000    Top5 99.046875    
2018-11-02 21:36:14,071 - ==> Top1: 82.200    Top5: 99.150    Loss: 0.541

2018-11-02 21:36:14,072 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:36:14,072 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:36:14,080 - 

2018-11-02 21:36:14,080 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:36:15,117 - Epoch: [128][   50/  391]    Overall Loss 0.376280    Objective Loss 0.376280    Top1 87.109375    Top5 99.453125    LR 0.209501    Time 0.020708    
2018-11-02 21:36:16,095 - Epoch: [128][  100/  391]    Overall Loss 0.371420    Objective Loss 0.371420    Top1 87.085938    Top5 99.492188    LR 0.209501    Time 0.020119    
2018-11-02 21:36:17,075 - Epoch: [128][  150/  391]    Overall Loss 0.367557    Objective Loss 0.367557    Top1 87.109375    Top5 99.520833    LR 0.209501    Time 0.019937    
2018-11-02 21:36:18,057 - Epoch: [128][  200/  391]    Overall Loss 0.369563    Objective Loss 0.369563    Top1 87.097656    Top5 99.535156    LR 0.209501    Time 0.019858    
2018-11-02 21:36:19,043 - Epoch: [128][  250/  391]    Overall Loss 0.370013    Objective Loss 0.370013    Top1 87.128125    Top5 99.512500    LR 0.209501    Time 0.019824    
2018-11-02 21:36:20,024 - Epoch: [128][  300/  391]    Overall Loss 0.367806    Objective Loss 0.367806    Top1 87.231771    Top5 99.541667    LR 0.209501    Time 0.019787    
2018-11-02 21:36:21,003 - Epoch: [128][  350/  391]    Overall Loss 0.374143    Objective Loss 0.374143    Top1 87.042411    Top5 99.529018    LR 0.209501    Time 0.019754    
2018-11-02 21:36:21,888 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56310 |  0.00221 |    0.35328 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23453 | -0.00225 |    0.14410 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23920 | -0.00881 |    0.17806 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28720 | -0.07424 |    0.21956 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30953 |  0.01595 |    0.24596 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25654 | -0.04108 |    0.19498 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25729 | -0.00508 |    0.18644 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30163 | -0.01110 |    0.22413 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24720 | -0.01158 |    0.19019 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40604 | -0.01973 |    0.27778 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22288 | -0.00485 |    0.16592 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18406 | -0.01762 |    0.14606 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21549 | -0.02331 |    0.16994 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15965 | -0.00843 |    0.12316 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18000 | -0.02475 |    0.14399 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16474 | -0.00475 |    0.12973 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22679 | -0.02159 |    0.17593 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15308 | -0.01881 |    0.12148 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12481 | -0.00834 |    0.09688 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12111 | -0.01516 |    0.09534 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08353 |  0.00248 |    0.06006 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57187 | -0.00000 |    0.44484 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:36:21,888 - Total sparsity: 0.00

2018-11-02 21:36:21,888 - --- validate (epoch=128)-----------
2018-11-02 21:36:21,888 - 10000 samples (128 per mini-batch)
2018-11-02 21:36:22,616 - Epoch: [128][   50/   78]    Loss 0.547774    Top1 82.703125    Top5 99.406250    
2018-11-02 21:36:23,012 - ==> Top1: 82.420    Top5: 99.340    Loss: 0.556

2018-11-02 21:36:23,013 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:36:23,013 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:36:23,025 - 

2018-11-02 21:36:23,025 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:36:24,081 - Epoch: [129][   50/  391]    Overall Loss 0.352713    Objective Loss 0.352713    Top1 88.250000    Top5 99.531250    LR 0.199026    Time 0.021081    
2018-11-02 21:36:25,060 - Epoch: [129][  100/  391]    Overall Loss 0.349856    Objective Loss 0.349856    Top1 88.179688    Top5 99.531250    LR 0.199026    Time 0.020323    
2018-11-02 21:36:26,037 - Epoch: [129][  150/  391]    Overall Loss 0.350993    Objective Loss 0.350993    Top1 88.104167    Top5 99.583333    LR 0.199026    Time 0.020054    
2018-11-02 21:36:27,018 - Epoch: [129][  200/  391]    Overall Loss 0.347790    Objective Loss 0.347790    Top1 88.007812    Top5 99.582031    LR 0.199026    Time 0.019937    
2018-11-02 21:36:27,996 - Epoch: [129][  250/  391]    Overall Loss 0.348896    Objective Loss 0.348896    Top1 87.946875    Top5 99.550000    LR 0.199026    Time 0.019857    
2018-11-02 21:36:28,973 - Epoch: [129][  300/  391]    Overall Loss 0.348008    Objective Loss 0.348008    Top1 87.992188    Top5 99.559896    LR 0.199026    Time 0.019799    
2018-11-02 21:36:29,950 - Epoch: [129][  350/  391]    Overall Loss 0.353142    Objective Loss 0.353142    Top1 87.834821    Top5 99.542411    LR 0.199026    Time 0.019757    
2018-11-02 21:36:30,835 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55758 | -0.00894 |    0.35019 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23478 | -0.00185 |    0.14531 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23822 | -0.00983 |    0.17876 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28379 | -0.08026 |    0.21887 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30715 |  0.01209 |    0.24397 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25576 | -0.03643 |    0.19262 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25473 | -0.00431 |    0.18515 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29942 | -0.01268 |    0.22291 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24567 | -0.01051 |    0.18874 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40157 | -0.02212 |    0.27479 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22158 | -0.00532 |    0.16588 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18320 | -0.01990 |    0.14544 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21449 | -0.02366 |    0.16942 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15853 | -0.00854 |    0.12235 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17850 | -0.02429 |    0.14309 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16369 | -0.00440 |    0.12882 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22422 | -0.02058 |    0.17306 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15210 | -0.01807 |    0.12064 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12413 | -0.00845 |    0.09623 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12090 | -0.01407 |    0.09511 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08304 |  0.00258 |    0.05986 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56750 | -0.00000 |    0.44105 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:36:30,836 - Total sparsity: 0.00

2018-11-02 21:36:30,836 - --- validate (epoch=129)-----------
2018-11-02 21:36:30,836 - 10000 samples (128 per mini-batch)
2018-11-02 21:36:31,565 - Epoch: [129][   50/   78]    Loss 0.608714    Top1 80.671875    Top5 99.015625    
2018-11-02 21:36:31,957 - ==> Top1: 80.680    Top5: 99.030    Loss: 0.606

2018-11-02 21:36:31,958 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:36:31,958 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:36:31,969 - 

2018-11-02 21:36:31,969 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:36:33,006 - Epoch: [130][   50/  391]    Overall Loss 0.310777    Objective Loss 0.310777    Top1 89.234375    Top5 99.687500    LR 0.189075    Time 0.020701    
2018-11-02 21:36:33,985 - Epoch: [130][  100/  391]    Overall Loss 0.319323    Objective Loss 0.319323    Top1 88.859375    Top5 99.679688    LR 0.189075    Time 0.020123    
2018-11-02 21:36:34,967 - Epoch: [130][  150/  391]    Overall Loss 0.338356    Objective Loss 0.338356    Top1 88.067708    Top5 99.614583    LR 0.189075    Time 0.019956    
2018-11-02 21:36:35,949 - Epoch: [130][  200/  391]    Overall Loss 0.338482    Objective Loss 0.338482    Top1 88.101562    Top5 99.640625    LR 0.189075    Time 0.019867    
2018-11-02 21:36:36,941 - Epoch: [130][  250/  391]    Overall Loss 0.344505    Objective Loss 0.344505    Top1 87.987500    Top5 99.612500    LR 0.189075    Time 0.019858    
2018-11-02 21:36:38,001 - Epoch: [130][  300/  391]    Overall Loss 0.347964    Objective Loss 0.347964    Top1 87.895833    Top5 99.606771    LR 0.189075    Time 0.020076    
2018-11-02 21:36:39,054 - Epoch: [130][  350/  391]    Overall Loss 0.348533    Objective Loss 0.348533    Top1 87.906250    Top5 99.613839    LR 0.189075    Time 0.020213    
2018-11-02 21:36:40,004 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54970 | -0.00830 |    0.34420 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23414 | -0.00171 |    0.14571 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23817 | -0.00796 |    0.17916 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28177 | -0.07824 |    0.21711 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30395 |  0.01550 |    0.24051 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25229 | -0.04024 |    0.19137 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25267 | -0.00435 |    0.18265 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29784 | -0.01464 |    0.22060 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24373 | -0.00806 |    0.18701 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39744 | -0.02551 |    0.27280 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21964 | -0.00656 |    0.16432 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18135 | -0.02030 |    0.14385 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21319 | -0.02505 |    0.16836 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15765 | -0.00700 |    0.12051 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17700 | -0.02340 |    0.14163 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16232 | -0.00428 |    0.12791 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22168 | -0.02005 |    0.17201 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15091 | -0.01801 |    0.11956 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12326 | -0.00899 |    0.09557 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12038 | -0.01467 |    0.09486 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08241 |  0.00267 |    0.05959 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56880 | -0.00000 |    0.44246 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:36:40,004 - Total sparsity: 0.00

2018-11-02 21:36:40,004 - --- validate (epoch=130)-----------
2018-11-02 21:36:40,004 - 10000 samples (128 per mini-batch)
2018-11-02 21:36:40,735 - Epoch: [130][   50/   78]    Loss 0.502000    Top1 83.437500    Top5 99.078125    
2018-11-02 21:36:41,130 - ==> Top1: 83.520    Top5: 99.170    Loss: 0.497

2018-11-02 21:36:41,130 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:36:41,130 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:36:41,138 - 

2018-11-02 21:36:41,138 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:36:42,256 - Epoch: [131][   50/  391]    Overall Loss 0.305373    Objective Loss 0.305373    Top1 89.250000    Top5 99.718750    LR 0.179621    Time 0.022322    
2018-11-02 21:36:43,315 - Epoch: [131][  100/  391]    Overall Loss 0.314841    Objective Loss 0.314841    Top1 89.187500    Top5 99.664062    LR 0.179621    Time 0.021730    
2018-11-02 21:36:44,372 - Epoch: [131][  150/  391]    Overall Loss 0.318880    Objective Loss 0.318880    Top1 88.880208    Top5 99.661458    LR 0.179621    Time 0.021528    
2018-11-02 21:36:45,432 - Epoch: [131][  200/  391]    Overall Loss 0.322670    Objective Loss 0.322670    Top1 88.781250    Top5 99.656250    LR 0.179621    Time 0.021421    
2018-11-02 21:36:46,495 - Epoch: [131][  250/  391]    Overall Loss 0.325646    Objective Loss 0.325646    Top1 88.634375    Top5 99.659375    LR 0.179621    Time 0.021380    
2018-11-02 21:36:47,531 - Epoch: [131][  300/  391]    Overall Loss 0.328244    Objective Loss 0.328244    Top1 88.593750    Top5 99.664062    LR 0.179621    Time 0.021266    
2018-11-02 21:36:48,577 - Epoch: [131][  350/  391]    Overall Loss 0.332825    Objective Loss 0.332825    Top1 88.377232    Top5 99.658482    LR 0.179621    Time 0.021214    
2018-11-02 21:36:49,479 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54424 | -0.00723 |    0.34234 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23103 | -0.00060 |    0.14384 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23481 | -0.00935 |    0.17681 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28086 | -0.07371 |    0.21357 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30218 |  0.01854 |    0.23952 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24989 | -0.04278 |    0.19055 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25005 | -0.00288 |    0.18163 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29552 | -0.00861 |    0.21898 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24155 | -0.00624 |    0.18505 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39298 | -0.02161 |    0.26991 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21798 | -0.00634 |    0.16250 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17929 | -0.02098 |    0.14213 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21133 | -0.02293 |    0.16630 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15575 | -0.00574 |    0.11899 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17531 | -0.02194 |    0.14013 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16070 | -0.00480 |    0.12660 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21911 | -0.01813 |    0.16992 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14960 | -0.01777 |    0.11867 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12224 | -0.00871 |    0.09486 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11982 | -0.01410 |    0.09442 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08166 |  0.00269 |    0.05914 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56591 | -0.00000 |    0.44019 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:36:49,480 - Total sparsity: 0.00

2018-11-02 21:36:49,480 - --- validate (epoch=131)-----------
2018-11-02 21:36:49,480 - 10000 samples (128 per mini-batch)
2018-11-02 21:36:50,205 - Epoch: [131][   50/   78]    Loss 0.524493    Top1 82.734375    Top5 99.250000    
2018-11-02 21:36:50,599 - ==> Top1: 82.800    Top5: 99.200    Loss: 0.522

2018-11-02 21:36:50,600 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:36:50,600 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:36:50,608 - 

2018-11-02 21:36:50,608 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:36:51,649 - Epoch: [132][   50/  391]    Overall Loss 0.327472    Objective Loss 0.327472    Top1 88.562500    Top5 99.765625    LR 0.170640    Time 0.020779    
2018-11-02 21:36:52,625 - Epoch: [132][  100/  391]    Overall Loss 0.323467    Objective Loss 0.323467    Top1 88.773438    Top5 99.671875    LR 0.170640    Time 0.020137    
2018-11-02 21:36:53,604 - Epoch: [132][  150/  391]    Overall Loss 0.318735    Objective Loss 0.318735    Top1 88.869792    Top5 99.692708    LR 0.170640    Time 0.019944    
2018-11-02 21:36:54,583 - Epoch: [132][  200/  391]    Overall Loss 0.322003    Objective Loss 0.322003    Top1 88.687500    Top5 99.648438    LR 0.170640    Time 0.019846    
2018-11-02 21:36:55,562 - Epoch: [132][  250/  391]    Overall Loss 0.323641    Objective Loss 0.323641    Top1 88.690625    Top5 99.650000    LR 0.170640    Time 0.019773    
2018-11-02 21:36:56,539 - Epoch: [132][  300/  391]    Overall Loss 0.325217    Objective Loss 0.325217    Top1 88.638021    Top5 99.658854    LR 0.170640    Time 0.019728    
2018-11-02 21:36:57,515 - Epoch: [132][  350/  391]    Overall Loss 0.328395    Objective Loss 0.328395    Top1 88.488839    Top5 99.649554    LR 0.170640    Time 0.019697    
2018-11-02 21:36:58,397 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53720 | -0.00456 |    0.33575 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22963 |  0.00118 |    0.14239 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23266 | -0.00657 |    0.17353 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27895 | -0.07382 |    0.21450 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30066 |  0.01062 |    0.23811 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24822 | -0.03871 |    0.18818 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24775 | -0.00134 |    0.17874 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29329 | -0.01023 |    0.21675 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23979 | -0.00911 |    0.18416 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38756 | -0.02314 |    0.26788 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21590 | -0.00524 |    0.16140 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17800 | -0.02033 |    0.14124 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20958 | -0.02409 |    0.16507 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15490 | -0.00561 |    0.11953 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17359 | -0.02313 |    0.13902 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15939 | -0.00521 |    0.12555 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21647 | -0.01880 |    0.16713 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14841 | -0.01756 |    0.11781 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12150 | -0.00876 |    0.09430 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11962 | -0.01360 |    0.09417 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08107 |  0.00312 |    0.05873 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56616 | -0.00000 |    0.44026 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:36:58,397 - Total sparsity: 0.00

2018-11-02 21:36:58,397 - --- validate (epoch=132)-----------
2018-11-02 21:36:58,397 - 10000 samples (128 per mini-batch)
2018-11-02 21:36:59,128 - Epoch: [132][   50/   78]    Loss 0.510420    Top1 83.640625    Top5 99.359375    
2018-11-02 21:36:59,522 - ==> Top1: 83.750    Top5: 99.400    Loss: 0.502

2018-11-02 21:36:59,522 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:36:59,523 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:36:59,534 - 

2018-11-02 21:36:59,535 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:37:00,576 - Epoch: [133][   50/  391]    Overall Loss 0.314294    Objective Loss 0.314294    Top1 88.984375    Top5 99.703125    LR 0.162108    Time 0.020798    
2018-11-02 21:37:01,555 - Epoch: [133][  100/  391]    Overall Loss 0.319034    Objective Loss 0.319034    Top1 88.796875    Top5 99.687500    LR 0.162108    Time 0.020174    
2018-11-02 21:37:02,533 - Epoch: [133][  150/  391]    Overall Loss 0.321776    Objective Loss 0.321776    Top1 88.750000    Top5 99.671875    LR 0.162108    Time 0.019961    
2018-11-02 21:37:03,511 - Epoch: [133][  200/  391]    Overall Loss 0.320792    Objective Loss 0.320792    Top1 88.914062    Top5 99.652344    LR 0.162108    Time 0.019854    
2018-11-02 21:37:04,490 - Epoch: [133][  250/  391]    Overall Loss 0.322115    Objective Loss 0.322115    Top1 88.837500    Top5 99.650000    LR 0.162108    Time 0.019791    
2018-11-02 21:37:05,468 - Epoch: [133][  300/  391]    Overall Loss 0.321063    Objective Loss 0.321063    Top1 88.864583    Top5 99.643229    LR 0.162108    Time 0.019750    
2018-11-02 21:37:06,448 - Epoch: [133][  350/  391]    Overall Loss 0.323234    Objective Loss 0.323234    Top1 88.843750    Top5 99.629464    LR 0.162108    Time 0.019725    
2018-11-02 21:37:07,328 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53007 | -0.00900 |    0.33376 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22757 |  0.00058 |    0.14190 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23021 | -0.00567 |    0.17234 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27679 | -0.07086 |    0.21170 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29778 |  0.01146 |    0.23603 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24607 | -0.04109 |    0.18682 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24578 | -0.00515 |    0.17887 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29118 | -0.00773 |    0.21466 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23808 | -0.00907 |    0.18347 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38271 | -0.02022 |    0.26130 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21415 | -0.00461 |    0.15988 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17668 | -0.01821 |    0.13983 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20779 | -0.02388 |    0.16289 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15390 | -0.00486 |    0.11772 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17204 | -0.02282 |    0.13771 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15816 | -0.00599 |    0.12505 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21393 | -0.01790 |    0.16439 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14734 | -0.01707 |    0.11671 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12059 | -0.00926 |    0.09374 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11905 | -0.01407 |    0.09388 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08047 |  0.00280 |    0.05844 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56663 | -0.00000 |    0.44109 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:37:07,328 - Total sparsity: 0.00

2018-11-02 21:37:07,328 - --- validate (epoch=133)-----------
2018-11-02 21:37:07,328 - 10000 samples (128 per mini-batch)
2018-11-02 21:37:08,047 - Epoch: [133][   50/   78]    Loss 0.560684    Top1 83.015625    Top5 99.234375    
2018-11-02 21:37:08,437 - ==> Top1: 82.880    Top5: 99.260    Loss: 0.558

2018-11-02 21:37:08,438 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:37:08,438 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:37:08,450 - 

2018-11-02 21:37:08,450 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:37:09,487 - Epoch: [134][   50/  391]    Overall Loss 0.319524    Objective Loss 0.319524    Top1 88.562500    Top5 99.687500    LR 0.154003    Time 0.020690    
2018-11-02 21:37:10,467 - Epoch: [134][  100/  391]    Overall Loss 0.316297    Objective Loss 0.316297    Top1 88.671875    Top5 99.710938    LR 0.154003    Time 0.020137    
2018-11-02 21:37:11,448 - Epoch: [134][  150/  391]    Overall Loss 0.313937    Objective Loss 0.313937    Top1 88.885417    Top5 99.692708    LR 0.154003    Time 0.019953    
2018-11-02 21:37:12,426 - Epoch: [134][  200/  391]    Overall Loss 0.316856    Objective Loss 0.316856    Top1 88.867188    Top5 99.667969    LR 0.154003    Time 0.019851    
2018-11-02 21:37:13,401 - Epoch: [134][  250/  391]    Overall Loss 0.313893    Objective Loss 0.313893    Top1 89.053125    Top5 99.653125    LR 0.154003    Time 0.019776    
2018-11-02 21:37:14,380 - Epoch: [134][  300/  391]    Overall Loss 0.315821    Objective Loss 0.315821    Top1 88.916667    Top5 99.640625    LR 0.154003    Time 0.019739    
2018-11-02 21:37:15,358 - Epoch: [134][  350/  391]    Overall Loss 0.317340    Objective Loss 0.317340    Top1 88.881696    Top5 99.645089    LR 0.154003    Time 0.019709    
2018-11-02 21:37:16,249 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.52758 | -0.01505 |    0.33142 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22696 | -0.00153 |    0.14192 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22825 | -0.01407 |    0.17109 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27267 | -0.07384 |    0.21155 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29534 |  0.00875 |    0.23435 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24375 | -0.03754 |    0.18463 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24291 | -0.00367 |    0.17674 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28888 | -0.00971 |    0.21298 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23680 | -0.00876 |    0.18207 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37920 | -0.01742 |    0.25812 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21242 | -0.00484 |    0.15748 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17548 | -0.02043 |    0.14052 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20647 | -0.02454 |    0.16238 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15323 | -0.00762 |    0.11810 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17066 | -0.02340 |    0.13654 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15703 | -0.00498 |    0.12385 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21126 | -0.01812 |    0.16202 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14608 | -0.01708 |    0.11587 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11988 | -0.00934 |    0.09316 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11867 | -0.01412 |    0.09365 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07994 |  0.00279 |    0.05813 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56575 | -0.00000 |    0.44093 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:37:16,249 - Total sparsity: 0.00

2018-11-02 21:37:16,250 - --- validate (epoch=134)-----------
2018-11-02 21:37:16,250 - 10000 samples (128 per mini-batch)
2018-11-02 21:37:16,967 - Epoch: [134][   50/   78]    Loss 0.531434    Top1 82.968750    Top5 99.343750    
2018-11-02 21:37:17,359 - ==> Top1: 82.940    Top5: 99.450    Loss: 0.529

2018-11-02 21:37:17,360 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:37:17,360 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:37:17,367 - 

2018-11-02 21:37:17,368 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:37:18,466 - Epoch: [135][   50/  391]    Overall Loss 0.298008    Objective Loss 0.298008    Top1 89.546875    Top5 99.765625    LR 0.146302    Time 0.021928    
2018-11-02 21:37:19,498 - Epoch: [135][  100/  391]    Overall Loss 0.303349    Objective Loss 0.303349    Top1 89.429688    Top5 99.742188    LR 0.146302    Time 0.021274    
2018-11-02 21:37:20,537 - Epoch: [135][  150/  391]    Overall Loss 0.300312    Objective Loss 0.300312    Top1 89.515625    Top5 99.718750    LR 0.146302    Time 0.021100    
2018-11-02 21:37:21,572 - Epoch: [135][  200/  391]    Overall Loss 0.300152    Objective Loss 0.300152    Top1 89.542969    Top5 99.710938    LR 0.146302    Time 0.020997    
2018-11-02 21:37:22,602 - Epoch: [135][  250/  391]    Overall Loss 0.304586    Objective Loss 0.304586    Top1 89.356250    Top5 99.690625    LR 0.146302    Time 0.020899    
2018-11-02 21:37:23,638 - Epoch: [135][  300/  391]    Overall Loss 0.304849    Objective Loss 0.304849    Top1 89.369792    Top5 99.687500    LR 0.146302    Time 0.020863    
2018-11-02 21:37:24,668 - Epoch: [135][  350/  391]    Overall Loss 0.306983    Objective Loss 0.306983    Top1 89.314732    Top5 99.687500    LR 0.146302    Time 0.020822    
2018-11-02 21:37:25,594 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.52379 | -0.01055 |    0.33004 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22605 |  0.00123 |    0.14185 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22662 | -0.01077 |    0.17036 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27113 | -0.07177 |    0.20919 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29331 |  0.00558 |    0.23333 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24241 | -0.03606 |    0.18238 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24113 | -0.00401 |    0.17432 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28644 | -0.00853 |    0.21206 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23498 | -0.00655 |    0.18094 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37474 | -0.01765 |    0.25377 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21053 | -0.00254 |    0.15721 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17436 | -0.01857 |    0.13912 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20510 | -0.02209 |    0.16148 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15201 | -0.00579 |    0.11686 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16940 | -0.02157 |    0.13545 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15588 | -0.00504 |    0.12296 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20938 | -0.01896 |    0.16037 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14506 | -0.01542 |    0.11489 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11921 | -0.00900 |    0.09276 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11836 | -0.01388 |    0.09331 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07934 |  0.00314 |    0.05781 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56511 | -0.00000 |    0.44012 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:37:25,594 - Total sparsity: 0.00

2018-11-02 21:37:25,594 - --- validate (epoch=135)-----------
2018-11-02 21:37:25,594 - 10000 samples (128 per mini-batch)
2018-11-02 21:37:26,321 - Epoch: [135][   50/   78]    Loss 0.561129    Top1 82.421875    Top5 99.125000    
2018-11-02 21:37:26,714 - ==> Top1: 82.190    Top5: 99.110    Loss: 0.567

2018-11-02 21:37:26,718 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:37:26,718 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:37:26,726 - 

2018-11-02 21:37:26,726 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:37:27,763 - Epoch: [136][   50/  391]    Overall Loss 0.291312    Objective Loss 0.291312    Top1 89.796875    Top5 99.640625    LR 0.138987    Time 0.020699    
2018-11-02 21:37:28,740 - Epoch: [136][  100/  391]    Overall Loss 0.294176    Objective Loss 0.294176    Top1 89.585938    Top5 99.632812    LR 0.138987    Time 0.020105    
2018-11-02 21:37:29,719 - Epoch: [136][  150/  391]    Overall Loss 0.290639    Objective Loss 0.290639    Top1 89.848958    Top5 99.677083    LR 0.138987    Time 0.019924    
2018-11-02 21:37:30,699 - Epoch: [136][  200/  391]    Overall Loss 0.294482    Objective Loss 0.294482    Top1 89.777344    Top5 99.707031    LR 0.138987    Time 0.019836    
2018-11-02 21:37:31,682 - Epoch: [136][  250/  391]    Overall Loss 0.295072    Objective Loss 0.295072    Top1 89.712500    Top5 99.703125    LR 0.138987    Time 0.019794    
2018-11-02 21:37:32,661 - Epoch: [136][  300/  391]    Overall Loss 0.298110    Objective Loss 0.298110    Top1 89.601562    Top5 99.674479    LR 0.138987    Time 0.019754    
2018-11-02 21:37:33,641 - Epoch: [136][  350/  391]    Overall Loss 0.298757    Objective Loss 0.298757    Top1 89.600446    Top5 99.680804    LR 0.138987    Time 0.019729    
2018-11-02 21:37:34,525 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.51786 | -0.01233 |    0.32782 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22459 | -0.00065 |    0.14027 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22509 | -0.01196 |    0.16903 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26927 | -0.06692 |    0.20679 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29081 |  0.00684 |    0.23085 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23946 | -0.03517 |    0.17999 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23820 | -0.00525 |    0.17219 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28362 | -0.01063 |    0.21029 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23261 | -0.00660 |    0.17901 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37012 | -0.01645 |    0.25085 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20845 | -0.00375 |    0.15592 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17312 | -0.01676 |    0.13796 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20314 | -0.02202 |    0.15943 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15102 | -0.00401 |    0.11599 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16760 | -0.02235 |    0.13410 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15457 | -0.00418 |    0.12191 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20698 | -0.01949 |    0.15945 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14391 | -0.01474 |    0.11388 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11850 | -0.00880 |    0.09236 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11780 | -0.01378 |    0.09296 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07866 |  0.00279 |    0.05733 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56490 | -0.00000 |    0.43899 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:37:34,525 - Total sparsity: 0.00

2018-11-02 21:37:34,525 - --- validate (epoch=136)-----------
2018-11-02 21:37:34,526 - 10000 samples (128 per mini-batch)
2018-11-02 21:37:35,247 - Epoch: [136][   50/   78]    Loss 0.476413    Top1 84.640625    Top5 99.328125    
2018-11-02 21:37:35,638 - ==> Top1: 84.790    Top5: 99.410    Loss: 0.468

2018-11-02 21:37:35,639 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:37:35,639 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:37:35,654 - 

2018-11-02 21:37:35,654 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:37:36,692 - Epoch: [137][   50/  391]    Overall Loss 0.289697    Objective Loss 0.289697    Top1 90.000000    Top5 99.750000    LR 0.132038    Time 0.020716    
2018-11-02 21:37:37,672 - Epoch: [137][  100/  391]    Overall Loss 0.278177    Objective Loss 0.278177    Top1 90.093750    Top5 99.812500    LR 0.132038    Time 0.020148    
2018-11-02 21:37:38,653 - Epoch: [137][  150/  391]    Overall Loss 0.280796    Objective Loss 0.280796    Top1 89.968750    Top5 99.760417    LR 0.132038    Time 0.019965    
2018-11-02 21:37:39,639 - Epoch: [137][  200/  391]    Overall Loss 0.289806    Objective Loss 0.289806    Top1 89.707031    Top5 99.722656    LR 0.132038    Time 0.019898    
2018-11-02 21:37:40,625 - Epoch: [137][  250/  391]    Overall Loss 0.291195    Objective Loss 0.291195    Top1 89.625000    Top5 99.731250    LR 0.132038    Time 0.019857    
2018-11-02 21:37:41,603 - Epoch: [137][  300/  391]    Overall Loss 0.293722    Objective Loss 0.293722    Top1 89.617188    Top5 99.726562    LR 0.132038    Time 0.019802    
2018-11-02 21:37:42,578 - Epoch: [137][  350/  391]    Overall Loss 0.294713    Objective Loss 0.294713    Top1 89.636161    Top5 99.720982    LR 0.132038    Time 0.019756    
2018-11-02 21:37:43,462 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.51458 | -0.01071 |    0.32551 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22329 |  0.00177 |    0.13874 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22315 | -0.00965 |    0.16710 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26733 | -0.06789 |    0.20496 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28907 |  0.00324 |    0.22852 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23709 | -0.03711 |    0.17898 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23601 | -0.00432 |    0.17135 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28177 | -0.00889 |    0.20947 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23083 | -0.00676 |    0.17678 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36495 | -0.01927 |    0.24814 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20646 | -0.00390 |    0.15377 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17177 | -0.01804 |    0.13738 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20147 | -0.02400 |    0.15841 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15009 | -0.00396 |    0.11504 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16647 | -0.02256 |    0.13338 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15369 | -0.00411 |    0.12108 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20519 | -0.01972 |    0.15780 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14303 | -0.01557 |    0.11338 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11801 | -0.00881 |    0.09196 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11750 | -0.01417 |    0.09266 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07830 |  0.00285 |    0.05718 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56315 | -0.00000 |    0.43806 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:37:43,462 - Total sparsity: 0.00

2018-11-02 21:37:43,462 - --- validate (epoch=137)-----------
2018-11-02 21:37:43,462 - 10000 samples (128 per mini-batch)
2018-11-02 21:37:44,189 - Epoch: [137][   50/   78]    Loss 0.506872    Top1 84.000000    Top5 99.171875    
2018-11-02 21:37:44,583 - ==> Top1: 83.900    Top5: 99.240    Loss: 0.503

2018-11-02 21:37:44,584 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:37:44,584 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:37:44,592 - 

2018-11-02 21:37:44,592 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:37:45,633 - Epoch: [138][   50/  391]    Overall Loss 0.274615    Objective Loss 0.274615    Top1 90.546875    Top5 99.609375    LR 0.125436    Time 0.020775    
2018-11-02 21:37:46,609 - Epoch: [138][  100/  391]    Overall Loss 0.277918    Objective Loss 0.277918    Top1 90.367188    Top5 99.718750    LR 0.125436    Time 0.020139    
2018-11-02 21:37:47,590 - Epoch: [138][  150/  391]    Overall Loss 0.286652    Objective Loss 0.286652    Top1 89.942708    Top5 99.713542    LR 0.125436    Time 0.019956    
2018-11-02 21:37:48,572 - Epoch: [138][  200/  391]    Overall Loss 0.286243    Objective Loss 0.286243    Top1 90.007812    Top5 99.699219    LR 0.125436    Time 0.019870    
2018-11-02 21:37:49,549 - Epoch: [138][  250/  391]    Overall Loss 0.290864    Objective Loss 0.290864    Top1 89.871875    Top5 99.690625    LR 0.125436    Time 0.019786    
2018-11-02 21:37:50,526 - Epoch: [138][  300/  391]    Overall Loss 0.292826    Objective Loss 0.292826    Top1 89.812500    Top5 99.695312    LR 0.125436    Time 0.019740    
2018-11-02 21:37:51,502 - Epoch: [138][  350/  391]    Overall Loss 0.291399    Objective Loss 0.291399    Top1 89.825893    Top5 99.696429    LR 0.125436    Time 0.019705    
2018-11-02 21:37:52,385 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.51100 | -0.00519 |    0.32368 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22137 | -0.00175 |    0.13676 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22202 | -0.00935 |    0.16644 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26554 | -0.06729 |    0.20428 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28702 |  0.00751 |    0.22723 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23578 | -0.03460 |    0.17736 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23421 | -0.00625 |    0.16986 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27969 | -0.00739 |    0.20723 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22896 | -0.01014 |    0.17588 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36090 | -0.02184 |    0.24448 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20467 | -0.00359 |    0.15207 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17056 | -0.01736 |    0.13625 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20005 | -0.02237 |    0.15645 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14865 | -0.00471 |    0.11462 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16513 | -0.02209 |    0.13213 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15264 | -0.00441 |    0.12017 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20321 | -0.01932 |    0.15637 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14216 | -0.01508 |    0.11264 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11742 | -0.00853 |    0.09158 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11702 | -0.01445 |    0.09244 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07773 |  0.00278 |    0.05675 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56260 | -0.00000 |    0.43692 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:37:52,385 - Total sparsity: 0.00

2018-11-02 21:37:52,385 - --- validate (epoch=138)-----------
2018-11-02 21:37:52,386 - 10000 samples (128 per mini-batch)
2018-11-02 21:37:53,112 - Epoch: [138][   50/   78]    Loss 0.501411    Top1 83.968750    Top5 99.468750    
2018-11-02 21:37:53,506 - ==> Top1: 84.320    Top5: 99.490    Loss: 0.486

2018-11-02 21:37:53,507 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 21:37:53,507 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:37:53,515 - 

2018-11-02 21:37:53,515 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:37:54,665 - Epoch: [139][   50/  391]    Overall Loss 0.281271    Objective Loss 0.281271    Top1 90.156250    Top5 99.687500    LR 0.119164    Time 0.022965    
2018-11-02 21:37:55,644 - Epoch: [139][  100/  391]    Overall Loss 0.283094    Objective Loss 0.283094    Top1 90.015625    Top5 99.726562    LR 0.119164    Time 0.021254    
2018-11-02 21:37:56,622 - Epoch: [139][  150/  391]    Overall Loss 0.277019    Objective Loss 0.277019    Top1 90.286458    Top5 99.776042    LR 0.119164    Time 0.020680    
2018-11-02 21:37:57,600 - Epoch: [139][  200/  391]    Overall Loss 0.273869    Objective Loss 0.273869    Top1 90.417969    Top5 99.753906    LR 0.119164    Time 0.020392    
2018-11-02 21:37:58,579 - Epoch: [139][  250/  391]    Overall Loss 0.278250    Objective Loss 0.278250    Top1 90.225000    Top5 99.743750    LR 0.119164    Time 0.020228    
2018-11-02 21:37:59,559 - Epoch: [139][  300/  391]    Overall Loss 0.278571    Objective Loss 0.278571    Top1 90.174479    Top5 99.773438    LR 0.119164    Time 0.020118    
2018-11-02 21:38:00,544 - Epoch: [139][  350/  391]    Overall Loss 0.280032    Objective Loss 0.280032    Top1 90.227679    Top5 99.741071    LR 0.119164    Time 0.020055    
2018-11-02 21:38:01,431 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.50512 | -0.00086 |    0.31921 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21961 | -0.00098 |    0.13630 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22032 | -0.00725 |    0.16473 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26309 | -0.06490 |    0.20291 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28442 |  0.00823 |    0.22445 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23328 | -0.03727 |    0.17577 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23237 | -0.00578 |    0.16815 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27731 | -0.00776 |    0.20505 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22721 | -0.00784 |    0.17421 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35743 | -0.01921 |    0.24114 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20271 | -0.00070 |    0.14938 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16951 | -0.01536 |    0.13516 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19867 | -0.02296 |    0.15620 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14766 | -0.00473 |    0.11319 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16375 | -0.02167 |    0.13079 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15143 | -0.00426 |    0.11926 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20080 | -0.01936 |    0.15460 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14105 | -0.01486 |    0.11185 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11669 | -0.00849 |    0.09095 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11654 | -0.01351 |    0.09190 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07703 |  0.00315 |    0.05640 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56168 | -0.00000 |    0.43697 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:38:01,431 - Total sparsity: 0.00

2018-11-02 21:38:01,431 - --- validate (epoch=139)-----------
2018-11-02 21:38:01,431 - 10000 samples (128 per mini-batch)
2018-11-02 21:38:02,158 - Epoch: [139][   50/   78]    Loss 0.417412    Top1 86.671875    Top5 99.500000    
2018-11-02 21:38:02,551 - ==> Top1: 86.710    Top5: 99.570    Loss: 0.413

2018-11-02 21:38:02,552 - ==> Best Top1: 86.710   On Epoch: 139

2018-11-02 21:38:02,552 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:38:02,567 - 

2018-11-02 21:38:02,567 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:38:03,604 - Epoch: [140][   50/  391]    Overall Loss 0.276285    Objective Loss 0.276285    Top1 90.718750    Top5 99.765625    LR 0.113206    Time 0.020701    
2018-11-02 21:38:04,583 - Epoch: [140][  100/  391]    Overall Loss 0.272402    Objective Loss 0.272402    Top1 90.671875    Top5 99.796875    LR 0.113206    Time 0.020122    
2018-11-02 21:38:05,564 - Epoch: [140][  150/  391]    Overall Loss 0.269365    Objective Loss 0.269365    Top1 90.755208    Top5 99.796875    LR 0.113206    Time 0.019944    
2018-11-02 21:38:06,545 - Epoch: [140][  200/  391]    Overall Loss 0.271050    Objective Loss 0.271050    Top1 90.687500    Top5 99.781250    LR 0.113206    Time 0.019859    
2018-11-02 21:38:07,522 - Epoch: [140][  250/  391]    Overall Loss 0.272218    Objective Loss 0.272218    Top1 90.675000    Top5 99.771875    LR 0.113206    Time 0.019788    
2018-11-02 21:38:08,501 - Epoch: [140][  300/  391]    Overall Loss 0.273523    Objective Loss 0.273523    Top1 90.611979    Top5 99.770833    LR 0.113206    Time 0.019750    
2018-11-02 21:38:09,479 - Epoch: [140][  350/  391]    Overall Loss 0.274658    Objective Loss 0.274658    Top1 90.517857    Top5 99.765625    LR 0.113206    Time 0.019719    
2018-11-02 21:38:10,360 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.49854 | -0.00269 |    0.31510 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21770 |  0.00225 |    0.13460 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21878 | -0.00717 |    0.16325 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26096 | -0.06294 |    0.19977 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28171 |  0.00732 |    0.22186 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23142 | -0.03539 |    0.17416 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23032 | -0.00627 |    0.16693 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27464 | -0.00806 |    0.20260 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22526 | -0.00887 |    0.17247 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35314 | -0.01977 |    0.23873 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20062 | -0.00330 |    0.14752 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16766 | -0.01759 |    0.13303 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19736 | -0.02159 |    0.15464 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14659 | -0.00610 |    0.11208 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16226 | -0.02093 |    0.12980 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15017 | -0.00454 |    0.11843 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19893 | -0.01826 |    0.15366 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13997 | -0.01450 |    0.11105 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11594 | -0.00834 |    0.09034 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11582 | -0.01347 |    0.09135 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07639 |  0.00311 |    0.05601 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56017 | -0.00000 |    0.43599 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:38:10,361 - Total sparsity: 0.00

2018-11-02 21:38:10,361 - --- validate (epoch=140)-----------
2018-11-02 21:38:10,361 - 10000 samples (128 per mini-batch)
2018-11-02 21:38:11,088 - Epoch: [140][   50/   78]    Loss 0.450699    Top1 85.984375    Top5 99.203125    
2018-11-02 21:38:11,482 - ==> Top1: 86.110    Top5: 99.280    Loss: 0.440

2018-11-02 21:38:11,483 - ==> Best Top1: 86.710   On Epoch: 139

2018-11-02 21:38:11,483 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:38:11,491 - 

2018-11-02 21:38:11,491 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:38:12,530 - Epoch: [141][   50/  391]    Overall Loss 0.267266    Objective Loss 0.267266    Top1 90.578125    Top5 99.781250    LR 0.107546    Time 0.020740    
2018-11-02 21:38:13,507 - Epoch: [141][  100/  391]    Overall Loss 0.259136    Objective Loss 0.259136    Top1 90.859375    Top5 99.804688    LR 0.107546    Time 0.020124    
2018-11-02 21:38:14,487 - Epoch: [141][  150/  391]    Overall Loss 0.262580    Objective Loss 0.262580    Top1 90.682292    Top5 99.791667    LR 0.107546    Time 0.019944    
2018-11-02 21:38:15,467 - Epoch: [141][  200/  391]    Overall Loss 0.259086    Objective Loss 0.259086    Top1 90.839844    Top5 99.796875    LR 0.107546    Time 0.019848    
2018-11-02 21:38:16,454 - Epoch: [141][  250/  391]    Overall Loss 0.265074    Objective Loss 0.265074    Top1 90.628125    Top5 99.781250    LR 0.107546    Time 0.019824    
2018-11-02 21:38:17,434 - Epoch: [141][  300/  391]    Overall Loss 0.262404    Objective Loss 0.262404    Top1 90.713542    Top5 99.783854    LR 0.107546    Time 0.019780    
2018-11-02 21:38:18,412 - Epoch: [141][  350/  391]    Overall Loss 0.263942    Objective Loss 0.263942    Top1 90.636161    Top5 99.787946    LR 0.107546    Time 0.019745    
2018-11-02 21:38:19,298 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.49186 | -0.00799 |    0.31143 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21560 |  0.00274 |    0.13404 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21686 | -0.00793 |    0.16192 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25723 | -0.06794 |    0.19717 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27931 |  0.01042 |    0.22127 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22917 | -0.03375 |    0.17269 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22814 | -0.00362 |    0.16559 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27212 | -0.00659 |    0.20054 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22342 | -0.00723 |    0.17176 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34893 | -0.01736 |    0.23801 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19847 | -0.00314 |    0.14591 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16604 | -0.01688 |    0.13142 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19570 | -0.02246 |    0.15371 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14571 | -0.00425 |    0.11130 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16072 | -0.02132 |    0.12848 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14895 | -0.00425 |    0.11753 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19687 | -0.01775 |    0.15183 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13890 | -0.01432 |    0.11010 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11524 | -0.00807 |    0.08981 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11511 | -0.01381 |    0.09099 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07575 |  0.00324 |    0.05560 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55975 | -0.00000 |    0.43582 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:38:19,298 - Total sparsity: 0.00

2018-11-02 21:38:19,298 - --- validate (epoch=141)-----------
2018-11-02 21:38:19,298 - 10000 samples (128 per mini-batch)
2018-11-02 21:38:20,030 - Epoch: [141][   50/   78]    Loss 0.394362    Top1 87.531250    Top5 99.453125    
2018-11-02 21:38:20,443 - ==> Top1: 87.410    Top5: 99.550    Loss: 0.393

2018-11-02 21:38:20,444 - ==> Best Top1: 87.410   On Epoch: 141

2018-11-02 21:38:20,444 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:38:20,453 - 

2018-11-02 21:38:20,453 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:38:21,491 - Epoch: [142][   50/  391]    Overall Loss 0.257219    Objective Loss 0.257219    Top1 91.093750    Top5 99.859375    LR 0.102168    Time 0.020722    
2018-11-02 21:38:22,469 - Epoch: [142][  100/  391]    Overall Loss 0.256108    Objective Loss 0.256108    Top1 91.140625    Top5 99.757812    LR 0.102168    Time 0.020131    
2018-11-02 21:38:23,448 - Epoch: [142][  150/  391]    Overall Loss 0.261752    Objective Loss 0.261752    Top1 90.942708    Top5 99.723958    LR 0.102168    Time 0.019939    
2018-11-02 21:38:24,426 - Epoch: [142][  200/  391]    Overall Loss 0.259801    Objective Loss 0.259801    Top1 90.957031    Top5 99.734375    LR 0.102168    Time 0.019835    
2018-11-02 21:38:25,406 - Epoch: [142][  250/  391]    Overall Loss 0.260541    Objective Loss 0.260541    Top1 90.943750    Top5 99.746875    LR 0.102168    Time 0.019784    
2018-11-02 21:38:26,385 - Epoch: [142][  300/  391]    Overall Loss 0.260214    Objective Loss 0.260214    Top1 90.927083    Top5 99.757812    LR 0.102168    Time 0.019733    
2018-11-02 21:38:27,364 - Epoch: [142][  350/  391]    Overall Loss 0.262607    Objective Loss 0.262607    Top1 90.801339    Top5 99.754464    LR 0.102168    Time 0.019710    
2018-11-02 21:38:28,270 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.48772 | -0.00988 |    0.31008 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21436 |  0.00196 |    0.13401 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21561 | -0.00583 |    0.16083 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25559 | -0.06529 |    0.19678 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27650 |  0.00917 |    0.21821 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22738 | -0.03405 |    0.17187 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22637 | -0.00604 |    0.16470 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27000 | -0.00629 |    0.19910 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22187 | -0.00707 |    0.17000 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34521 | -0.01894 |    0.23343 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19663 | -0.00337 |    0.14478 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16463 | -0.01578 |    0.13073 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19434 | -0.02230 |    0.15253 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14453 | -0.00398 |    0.11061 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15949 | -0.02082 |    0.12755 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14789 | -0.00420 |    0.11670 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19512 | -0.01743 |    0.14999 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13799 | -0.01442 |    0.10923 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11464 | -0.00799 |    0.08933 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11476 | -0.01325 |    0.09061 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07518 |  0.00294 |    0.05525 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55865 | -0.00000 |    0.43526 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:38:28,270 - Total sparsity: 0.00

2018-11-02 21:38:28,270 - --- validate (epoch=142)-----------
2018-11-02 21:38:28,270 - 10000 samples (128 per mini-batch)
2018-11-02 21:38:28,991 - Epoch: [142][   50/   78]    Loss 0.446930    Top1 85.765625    Top5 99.281250    
2018-11-02 21:38:29,383 - ==> Top1: 85.700    Top5: 99.410    Loss: 0.438

2018-11-02 21:38:29,384 - ==> Best Top1: 87.410   On Epoch: 141

2018-11-02 21:38:29,384 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:38:29,392 - 

2018-11-02 21:38:29,392 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:38:30,428 - Epoch: [143][   50/  391]    Overall Loss 0.240929    Objective Loss 0.240929    Top1 91.625000    Top5 99.828125    LR 0.097060    Time 0.020679    
2018-11-02 21:38:31,407 - Epoch: [143][  100/  391]    Overall Loss 0.246129    Objective Loss 0.246129    Top1 91.273438    Top5 99.789062    LR 0.097060    Time 0.020111    
2018-11-02 21:38:32,385 - Epoch: [143][  150/  391]    Overall Loss 0.252301    Objective Loss 0.252301    Top1 91.109375    Top5 99.791667    LR 0.097060    Time 0.019918    
2018-11-02 21:38:33,364 - Epoch: [143][  200/  391]    Overall Loss 0.253900    Objective Loss 0.253900    Top1 91.015625    Top5 99.792969    LR 0.097060    Time 0.019829    
2018-11-02 21:38:34,344 - Epoch: [143][  250/  391]    Overall Loss 0.255939    Objective Loss 0.255939    Top1 90.940625    Top5 99.784375    LR 0.097060    Time 0.019776    
2018-11-02 21:38:35,324 - Epoch: [143][  300/  391]    Overall Loss 0.256818    Objective Loss 0.256818    Top1 90.937500    Top5 99.778646    LR 0.097060    Time 0.019743    
2018-11-02 21:38:36,302 - Epoch: [143][  350/  391]    Overall Loss 0.259994    Objective Loss 0.259994    Top1 90.828125    Top5 99.774554    LR 0.097060    Time 0.019715    
2018-11-02 21:38:37,185 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.48436 | -0.01192 |    0.30883 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21288 |  0.00232 |    0.13297 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21396 | -0.00705 |    0.15984 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25340 | -0.06501 |    0.19566 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27375 |  0.00748 |    0.21589 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22587 | -0.03336 |    0.16996 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22435 | -0.00629 |    0.16316 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26762 | -0.00694 |    0.19703 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22025 | -0.00776 |    0.16902 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34185 | -0.01773 |    0.23030 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19511 | -0.00346 |    0.14378 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16311 | -0.01581 |    0.12946 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19265 | -0.02092 |    0.15117 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14330 | -0.00536 |    0.10967 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15828 | -0.02073 |    0.12656 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14683 | -0.00415 |    0.11589 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19324 | -0.01747 |    0.14876 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13712 | -0.01439 |    0.10857 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11407 | -0.00796 |    0.08894 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11438 | -0.01297 |    0.09035 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07462 |  0.00304 |    0.05489 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55876 | -0.00000 |    0.43480 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:38:37,185 - Total sparsity: 0.00

2018-11-02 21:38:37,185 - --- validate (epoch=143)-----------
2018-11-02 21:38:37,185 - 10000 samples (128 per mini-batch)
2018-11-02 21:38:37,910 - Epoch: [143][   50/   78]    Loss 0.457416    Top1 85.781250    Top5 99.421875    
2018-11-02 21:38:38,303 - ==> Top1: 85.730    Top5: 99.480    Loss: 0.449

2018-11-02 21:38:38,304 - ==> Best Top1: 87.410   On Epoch: 141

2018-11-02 21:38:38,304 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:38:38,312 - 

2018-11-02 21:38:38,312 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:38:39,350 - Epoch: [144][   50/  391]    Overall Loss 0.233546    Objective Loss 0.233546    Top1 91.906250    Top5 99.765625    LR 0.092207    Time 0.020729    
2018-11-02 21:38:40,330 - Epoch: [144][  100/  391]    Overall Loss 0.241852    Objective Loss 0.241852    Top1 91.593750    Top5 99.789062    LR 0.092207    Time 0.020147    
2018-11-02 21:38:41,309 - Epoch: [144][  150/  391]    Overall Loss 0.238734    Objective Loss 0.238734    Top1 91.651042    Top5 99.817708    LR 0.092207    Time 0.019949    
2018-11-02 21:38:42,285 - Epoch: [144][  200/  391]    Overall Loss 0.240975    Objective Loss 0.240975    Top1 91.593750    Top5 99.800781    LR 0.092207    Time 0.019834    
2018-11-02 21:38:43,285 - Epoch: [144][  250/  391]    Overall Loss 0.246358    Objective Loss 0.246358    Top1 91.306250    Top5 99.796875    LR 0.092207    Time 0.019863    
2018-11-02 21:38:44,320 - Epoch: [144][  300/  391]    Overall Loss 0.244189    Objective Loss 0.244189    Top1 91.388021    Top5 99.796875    LR 0.092207    Time 0.019999    
2018-11-02 21:38:45,354 - Epoch: [144][  350/  391]    Overall Loss 0.247845    Objective Loss 0.247845    Top1 91.267857    Top5 99.803571    LR 0.092207    Time 0.020094    
2018-11-02 21:38:46,279 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.47985 | -0.00952 |    0.30521 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21114 |  0.00165 |    0.13113 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21223 | -0.00638 |    0.15929 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25203 | -0.06273 |    0.19264 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27120 |  0.00713 |    0.21420 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22376 | -0.03645 |    0.16869 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22253 | -0.00520 |    0.16248 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26563 | -0.00819 |    0.19712 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21847 | -0.00654 |    0.16773 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33862 | -0.01591 |    0.22796 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19356 | -0.00459 |    0.14238 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16136 | -0.01648 |    0.12858 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19131 | -0.02020 |    0.15033 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14212 | -0.00529 |    0.10889 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15693 | -0.02073 |    0.12563 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14571 | -0.00442 |    0.11497 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19140 | -0.01639 |    0.14706 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13619 | -0.01437 |    0.10804 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11347 | -0.00744 |    0.08852 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11392 | -0.01256 |    0.09003 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07408 |  0.00300 |    0.05453 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56009 | -0.00000 |    0.43545 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:38:46,280 - Total sparsity: 0.00

2018-11-02 21:38:46,280 - --- validate (epoch=144)-----------
2018-11-02 21:38:46,280 - 10000 samples (128 per mini-batch)
2018-11-02 21:38:47,021 - Epoch: [144][   50/   78]    Loss 0.472816    Top1 86.515625    Top5 99.437500    
2018-11-02 21:38:47,416 - ==> Top1: 86.120    Top5: 99.470    Loss: 0.468

2018-11-02 21:38:47,416 - ==> Best Top1: 87.410   On Epoch: 141

2018-11-02 21:38:47,417 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:38:47,424 - 

2018-11-02 21:38:47,425 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:38:48,557 - Epoch: [145][   50/  391]    Overall Loss 0.243877    Objective Loss 0.243877    Top1 91.375000    Top5 99.812500    LR 0.087597    Time 0.022612    
2018-11-02 21:38:49,567 - Epoch: [145][  100/  391]    Overall Loss 0.236144    Objective Loss 0.236144    Top1 91.554688    Top5 99.843750    LR 0.087597    Time 0.021388    
2018-11-02 21:38:50,546 - Epoch: [145][  150/  391]    Overall Loss 0.237902    Objective Loss 0.237902    Top1 91.536458    Top5 99.864583    LR 0.087597    Time 0.020780    
2018-11-02 21:38:51,523 - Epoch: [145][  200/  391]    Overall Loss 0.240476    Objective Loss 0.240476    Top1 91.488281    Top5 99.851562    LR 0.087597    Time 0.020464    
2018-11-02 21:38:52,504 - Epoch: [145][  250/  391]    Overall Loss 0.242909    Objective Loss 0.242909    Top1 91.359375    Top5 99.846875    LR 0.087597    Time 0.020274    
2018-11-02 21:38:53,484 - Epoch: [145][  300/  391]    Overall Loss 0.244223    Objective Loss 0.244223    Top1 91.385417    Top5 99.828125    LR 0.087597    Time 0.020158    
2018-11-02 21:38:54,461 - Epoch: [145][  350/  391]    Overall Loss 0.245793    Objective Loss 0.245793    Top1 91.350446    Top5 99.819196    LR 0.087597    Time 0.020067    
2018-11-02 21:38:55,340 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.47555 | -0.00405 |    0.30082 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20987 |  0.00060 |    0.13074 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21069 | -0.00901 |    0.15830 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24922 | -0.06515 |    0.19201 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26871 |  0.01018 |    0.21328 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22254 | -0.03406 |    0.16670 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22071 | -0.00556 |    0.16182 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26368 | -0.00605 |    0.19420 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21672 | -0.00688 |    0.16661 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33545 | -0.01483 |    0.22579 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19172 | -0.00175 |    0.14163 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15995 | -0.01686 |    0.12747 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18985 | -0.02154 |    0.14899 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14089 | -0.00540 |    0.10797 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15583 | -0.01972 |    0.12459 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14477 | -0.00412 |    0.11420 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18965 | -0.01642 |    0.14658 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13537 | -0.01423 |    0.10727 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11296 | -0.00745 |    0.08812 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11337 | -0.01299 |    0.08957 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07358 |  0.00280 |    0.05426 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55915 | -0.00000 |    0.43489 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:38:55,340 - Total sparsity: 0.00

2018-11-02 21:38:55,340 - --- validate (epoch=145)-----------
2018-11-02 21:38:55,340 - 10000 samples (128 per mini-batch)
2018-11-02 21:38:56,067 - Epoch: [145][   50/   78]    Loss 0.436916    Top1 86.437500    Top5 99.375000    
2018-11-02 21:38:56,459 - ==> Top1: 86.500    Top5: 99.430    Loss: 0.424

2018-11-02 21:38:56,460 - ==> Best Top1: 87.410   On Epoch: 141

2018-11-02 21:38:56,460 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:38:56,468 - 

2018-11-02 21:38:56,468 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:38:57,559 - Epoch: [146][   50/  391]    Overall Loss 0.226409    Objective Loss 0.226409    Top1 91.843750    Top5 99.875000    LR 0.083217    Time 0.021781    
2018-11-02 21:38:58,537 - Epoch: [146][  100/  391]    Overall Loss 0.223335    Objective Loss 0.223335    Top1 92.179688    Top5 99.882812    LR 0.083217    Time 0.020659    
2018-11-02 21:38:59,514 - Epoch: [146][  150/  391]    Overall Loss 0.227520    Objective Loss 0.227520    Top1 91.958333    Top5 99.859375    LR 0.083217    Time 0.020278    
2018-11-02 21:39:00,497 - Epoch: [146][  200/  391]    Overall Loss 0.231846    Objective Loss 0.231846    Top1 91.933594    Top5 99.835938    LR 0.083217    Time 0.020119    
2018-11-02 21:39:01,478 - Epoch: [146][  250/  391]    Overall Loss 0.233592    Objective Loss 0.233592    Top1 91.815625    Top5 99.837500    LR 0.083217    Time 0.020013    
2018-11-02 21:39:02,454 - Epoch: [146][  300/  391]    Overall Loss 0.237046    Objective Loss 0.237046    Top1 91.695312    Top5 99.835938    LR 0.083217    Time 0.019927    
2018-11-02 21:39:03,434 - Epoch: [146][  350/  391]    Overall Loss 0.237811    Objective Loss 0.237811    Top1 91.716518    Top5 99.834821    LR 0.083217    Time 0.019875    
2018-11-02 21:39:04,319 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.47111 | -0.00283 |    0.29968 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20853 | -0.00042 |    0.12954 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20916 | -0.00759 |    0.15693 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24796 | -0.06278 |    0.18976 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26648 |  0.00875 |    0.21172 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22102 | -0.03257 |    0.16622 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21893 | -0.00574 |    0.15969 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26166 | -0.00633 |    0.19255 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21518 | -0.00759 |    0.16501 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33222 | -0.01676 |    0.22500 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19027 | -0.00472 |    0.13996 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15871 | -0.01749 |    0.12662 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18918 | -0.02011 |    0.14840 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13988 | -0.00598 |    0.10727 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15466 | -0.01940 |    0.12379 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14381 | -0.00402 |    0.11339 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18805 | -0.01610 |    0.14544 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13457 | -0.01421 |    0.10670 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11241 | -0.00743 |    0.08777 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11293 | -0.01263 |    0.08925 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07307 |  0.00270 |    0.05394 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55739 | -0.00000 |    0.43381 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:39:04,319 - Total sparsity: 0.00

2018-11-02 21:39:04,320 - --- validate (epoch=146)-----------
2018-11-02 21:39:04,320 - 10000 samples (128 per mini-batch)
2018-11-02 21:39:05,046 - Epoch: [146][   50/   78]    Loss 0.399242    Top1 87.406250    Top5 99.500000    
2018-11-02 21:39:05,439 - ==> Top1: 87.580    Top5: 99.620    Loss: 0.388

2018-11-02 21:39:05,440 - ==> Best Top1: 87.580   On Epoch: 146

2018-11-02 21:39:05,440 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:39:05,450 - 

2018-11-02 21:39:05,450 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:39:06,487 - Epoch: [147][   50/  391]    Overall Loss 0.229313    Objective Loss 0.229313    Top1 92.015625    Top5 99.828125    LR 0.079056    Time 0.020698    
2018-11-02 21:39:07,479 - Epoch: [147][  100/  391]    Overall Loss 0.224673    Objective Loss 0.224673    Top1 92.148438    Top5 99.843750    LR 0.079056    Time 0.020251    
2018-11-02 21:39:08,529 - Epoch: [147][  150/  391]    Overall Loss 0.227109    Objective Loss 0.227109    Top1 92.140625    Top5 99.848958    LR 0.079056    Time 0.020497    
2018-11-02 21:39:09,573 - Epoch: [147][  200/  391]    Overall Loss 0.230497    Objective Loss 0.230497    Top1 92.015625    Top5 99.843750    LR 0.079056    Time 0.020587    
2018-11-02 21:39:10,622 - Epoch: [147][  250/  391]    Overall Loss 0.231859    Objective Loss 0.231859    Top1 91.893750    Top5 99.840625    LR 0.079056    Time 0.020658    
2018-11-02 21:39:11,626 - Epoch: [147][  300/  391]    Overall Loss 0.229160    Objective Loss 0.229160    Top1 92.002604    Top5 99.843750    LR 0.079056    Time 0.020557    
2018-11-02 21:39:12,607 - Epoch: [147][  350/  391]    Overall Loss 0.227875    Objective Loss 0.227875    Top1 92.024554    Top5 99.845982    LR 0.079056    Time 0.020421    
2018-11-02 21:39:13,494 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.46724 | -0.00387 |    0.29760 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20697 |  0.00072 |    0.12941 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20743 | -0.00574 |    0.15665 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24598 | -0.06172 |    0.18901 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26391 |  0.01238 |    0.21036 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21894 | -0.03275 |    0.16465 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21700 | -0.00658 |    0.15727 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25954 | -0.00432 |    0.19007 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21343 | -0.00714 |    0.16396 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32911 | -0.01418 |    0.22253 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18847 | -0.00339 |    0.13834 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15710 | -0.01869 |    0.12578 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18805 | -0.02038 |    0.14769 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13872 | -0.00547 |    0.10628 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15333 | -0.01927 |    0.12266 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14274 | -0.00389 |    0.11264 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18632 | -0.01557 |    0.14374 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13364 | -0.01399 |    0.10595 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11171 | -0.00749 |    0.08732 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11228 | -0.01288 |    0.08886 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07244 |  0.00284 |    0.05357 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55913 | -0.00000 |    0.43536 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:39:13,494 - Total sparsity: 0.00

2018-11-02 21:39:13,494 - --- validate (epoch=147)-----------
2018-11-02 21:39:13,495 - 10000 samples (128 per mini-batch)
2018-11-02 21:39:14,224 - Epoch: [147][   50/   78]    Loss 0.436974    Top1 86.421875    Top5 99.562500    
2018-11-02 21:39:14,618 - ==> Top1: 86.550    Top5: 99.600    Loss: 0.429

2018-11-02 21:39:14,618 - ==> Best Top1: 87.580   On Epoch: 146

2018-11-02 21:39:14,618 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:39:14,625 - 

2018-11-02 21:39:14,626 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:39:15,662 - Epoch: [148][   50/  391]    Overall Loss 0.216116    Objective Loss 0.216116    Top1 92.140625    Top5 99.875000    LR 0.075103    Time 0.020689    
2018-11-02 21:39:16,643 - Epoch: [148][  100/  391]    Overall Loss 0.220991    Objective Loss 0.220991    Top1 92.000000    Top5 99.851562    LR 0.075103    Time 0.020134    
2018-11-02 21:39:17,620 - Epoch: [148][  150/  391]    Overall Loss 0.221031    Objective Loss 0.221031    Top1 92.010417    Top5 99.869792    LR 0.075103    Time 0.019932    
2018-11-02 21:39:18,599 - Epoch: [148][  200/  391]    Overall Loss 0.222228    Objective Loss 0.222228    Top1 92.054688    Top5 99.875000    LR 0.075103    Time 0.019834    
2018-11-02 21:39:19,578 - Epoch: [148][  250/  391]    Overall Loss 0.222429    Objective Loss 0.222429    Top1 92.031250    Top5 99.871875    LR 0.075103    Time 0.019778    
2018-11-02 21:39:20,558 - Epoch: [148][  300/  391]    Overall Loss 0.223181    Objective Loss 0.223181    Top1 92.057292    Top5 99.864583    LR 0.075103    Time 0.019744    
2018-11-02 21:39:21,539 - Epoch: [148][  350/  391]    Overall Loss 0.224194    Objective Loss 0.224194    Top1 92.064732    Top5 99.848214    LR 0.075103    Time 0.019724    
2018-11-02 21:39:22,422 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.46248 | -0.00945 |    0.29498 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20519 | -0.00042 |    0.12787 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20576 | -0.00449 |    0.15580 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24315 | -0.06382 |    0.18836 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26175 |  0.00758 |    0.20676 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21622 | -0.03611 |    0.16344 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21514 | -0.00641 |    0.15567 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25741 | -0.00342 |    0.18938 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21181 | -0.00629 |    0.16241 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32611 | -0.01501 |    0.21781 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18714 | -0.00146 |    0.13697 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15604 | -0.01734 |    0.12465 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18671 | -0.02080 |    0.14667 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13771 | -0.00491 |    0.10543 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15213 | -0.01893 |    0.12177 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14171 | -0.00411 |    0.11191 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18464 | -0.01535 |    0.14252 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13272 | -0.01390 |    0.10524 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11108 | -0.00732 |    0.08687 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11174 | -0.01273 |    0.08845 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07187 |  0.00277 |    0.05322 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56037 | -0.00000 |    0.43653 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:39:22,422 - Total sparsity: 0.00

2018-11-02 21:39:22,422 - --- validate (epoch=148)-----------
2018-11-02 21:39:22,422 - 10000 samples (128 per mini-batch)
2018-11-02 21:39:23,150 - Epoch: [148][   50/   78]    Loss 0.410087    Top1 87.515625    Top5 99.484375    
2018-11-02 21:39:23,535 - ==> Top1: 87.610    Top5: 99.590    Loss: 0.402

2018-11-02 21:39:23,535 - ==> Best Top1: 87.610   On Epoch: 148

2018-11-02 21:39:23,536 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:39:23,544 - 

2018-11-02 21:39:23,544 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:39:24,656 - Epoch: [149][   50/  391]    Overall Loss 0.214855    Objective Loss 0.214855    Top1 92.390625    Top5 99.843750    LR 0.071348    Time 0.022188    
2018-11-02 21:39:25,691 - Epoch: [149][  100/  391]    Overall Loss 0.219022    Objective Loss 0.219022    Top1 92.304688    Top5 99.859375    LR 0.071348    Time 0.021433    
2018-11-02 21:39:26,670 - Epoch: [149][  150/  391]    Overall Loss 0.220770    Objective Loss 0.220770    Top1 92.343750    Top5 99.838542    LR 0.071348    Time 0.020810    
2018-11-02 21:39:27,651 - Epoch: [149][  200/  391]    Overall Loss 0.221061    Objective Loss 0.221061    Top1 92.230469    Top5 99.851562    LR 0.071348    Time 0.020503    
2018-11-02 21:39:28,630 - Epoch: [149][  250/  391]    Overall Loss 0.219752    Objective Loss 0.219752    Top1 92.284375    Top5 99.837500    LR 0.071348    Time 0.020317    
2018-11-02 21:39:29,618 - Epoch: [149][  300/  391]    Overall Loss 0.220834    Objective Loss 0.220834    Top1 92.244792    Top5 99.812500    LR 0.071348    Time 0.020217    
2018-11-02 21:39:30,597 - Epoch: [149][  350/  391]    Overall Loss 0.221256    Objective Loss 0.221256    Top1 92.261161    Top5 99.819196    LR 0.071348    Time 0.020122    
2018-11-02 21:39:31,479 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.45933 | -0.00467 |    0.29232 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20362 | -0.00018 |    0.12724 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20408 | -0.00625 |    0.15473 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24149 | -0.06321 |    0.18804 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25975 |  0.00647 |    0.20497 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21522 | -0.03289 |    0.16163 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21330 | -0.00647 |    0.15433 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25555 | -0.00502 |    0.18786 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21029 | -0.00617 |    0.16083 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32327 | -0.01625 |    0.21547 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18584 | -0.00062 |    0.13673 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15514 | -0.01702 |    0.12400 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18558 | -0.02035 |    0.14564 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13683 | -0.00611 |    0.10413 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15104 | -0.01860 |    0.12078 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14077 | -0.00411 |    0.11117 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18312 | -0.01501 |    0.14126 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13186 | -0.01420 |    0.10477 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11049 | -0.00753 |    0.08630 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11122 | -0.01247 |    0.08796 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07132 |  0.00272 |    0.05279 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55927 | -0.00000 |    0.43600 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:39:31,479 - Total sparsity: 0.00

2018-11-02 21:39:31,480 - --- validate (epoch=149)-----------
2018-11-02 21:39:31,480 - 10000 samples (128 per mini-batch)
2018-11-02 21:39:32,209 - Epoch: [149][   50/   78]    Loss 0.394380    Top1 87.250000    Top5 99.578125    
2018-11-02 21:39:32,604 - ==> Top1: 87.290    Top5: 99.570    Loss: 0.391

2018-11-02 21:39:32,605 - ==> Best Top1: 87.610   On Epoch: 148

2018-11-02 21:39:32,605 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:39:32,619 - 

2018-11-02 21:39:32,620 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:39:33,656 - Epoch: [150][   50/  391]    Overall Loss 0.206373    Objective Loss 0.206373    Top1 92.578125    Top5 99.906250    LR 0.067781    Time 0.020683    
2018-11-02 21:39:34,635 - Epoch: [150][  100/  391]    Overall Loss 0.204091    Objective Loss 0.204091    Top1 92.710938    Top5 99.882812    LR 0.067781    Time 0.020122    
2018-11-02 21:39:35,613 - Epoch: [150][  150/  391]    Overall Loss 0.207508    Objective Loss 0.207508    Top1 92.635417    Top5 99.880208    LR 0.067781    Time 0.019921    
2018-11-02 21:39:36,591 - Epoch: [150][  200/  391]    Overall Loss 0.209151    Objective Loss 0.209151    Top1 92.539062    Top5 99.875000    LR 0.067781    Time 0.019826    
2018-11-02 21:39:37,570 - Epoch: [150][  250/  391]    Overall Loss 0.209067    Objective Loss 0.209067    Top1 92.615625    Top5 99.859375    LR 0.067781    Time 0.019773    
2018-11-02 21:39:38,548 - Epoch: [150][  300/  391]    Overall Loss 0.209291    Objective Loss 0.209291    Top1 92.606771    Top5 99.859375    LR 0.067781    Time 0.019733    
2018-11-02 21:39:39,528 - Epoch: [150][  350/  391]    Overall Loss 0.212726    Objective Loss 0.212726    Top1 92.515625    Top5 99.861607    LR 0.067781    Time 0.019711    
2018-11-02 21:39:40,416 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.45552 | -0.00761 |    0.28992 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20247 |  0.00060 |    0.12695 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20271 | -0.00593 |    0.15310 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24023 | -0.06126 |    0.18729 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25795 |  0.00803 |    0.20398 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21399 | -0.03169 |    0.16123 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21170 | -0.00591 |    0.15355 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25358 | -0.00465 |    0.18639 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20885 | -0.00620 |    0.15977 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32033 | -0.01704 |    0.21351 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18439 | -0.00224 |    0.13592 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15400 | -0.01786 |    0.12349 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18420 | -0.02123 |    0.14511 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13591 | -0.00541 |    0.10351 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14990 | -0.01894 |    0.11994 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13987 | -0.00457 |    0.11066 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18141 | -0.01500 |    0.13996 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13107 | -0.01366 |    0.10404 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10988 | -0.00775 |    0.08580 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11068 | -0.01212 |    0.08760 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07080 |  0.00247 |    0.05245 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55887 | -0.00000 |    0.43525 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:39:40,416 - Total sparsity: 0.00

2018-11-02 21:39:40,417 - --- validate (epoch=150)-----------
2018-11-02 21:39:40,417 - 10000 samples (128 per mini-batch)
2018-11-02 21:39:41,142 - Epoch: [150][   50/   78]    Loss 0.445214    Top1 86.968750    Top5 99.437500    
2018-11-02 21:39:41,536 - ==> Top1: 87.150    Top5: 99.430    Loss: 0.434

2018-11-02 21:39:41,536 - ==> Best Top1: 87.610   On Epoch: 148

2018-11-02 21:39:41,537 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:39:41,544 - 

2018-11-02 21:39:41,545 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:39:42,581 - Epoch: [151][   50/  391]    Overall Loss 0.212663    Objective Loss 0.212663    Top1 92.593750    Top5 99.875000    LR 0.064392    Time 0.020696    
2018-11-02 21:39:43,559 - Epoch: [151][  100/  391]    Overall Loss 0.214335    Objective Loss 0.214335    Top1 92.554688    Top5 99.890625    LR 0.064392    Time 0.020103    
2018-11-02 21:39:44,538 - Epoch: [151][  150/  391]    Overall Loss 0.205857    Objective Loss 0.205857    Top1 92.817708    Top5 99.890625    LR 0.064392    Time 0.019922    
2018-11-02 21:39:45,520 - Epoch: [151][  200/  391]    Overall Loss 0.210343    Objective Loss 0.210343    Top1 92.605469    Top5 99.875000    LR 0.064392    Time 0.019848    
2018-11-02 21:39:46,500 - Epoch: [151][  250/  391]    Overall Loss 0.212755    Objective Loss 0.212755    Top1 92.550000    Top5 99.878125    LR 0.064392    Time 0.019791    
2018-11-02 21:39:47,480 - Epoch: [151][  300/  391]    Overall Loss 0.213223    Objective Loss 0.213223    Top1 92.552083    Top5 99.872396    LR 0.064392    Time 0.019755    
2018-11-02 21:39:48,456 - Epoch: [151][  350/  391]    Overall Loss 0.214014    Objective Loss 0.214014    Top1 92.575893    Top5 99.868304    LR 0.064392    Time 0.019719    
2018-11-02 21:39:49,335 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.45212 | -0.00677 |    0.28760 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20127 |  0.00059 |    0.12658 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20136 | -0.00765 |    0.15190 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23882 | -0.06048 |    0.18606 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25620 |  0.00793 |    0.20172 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21254 | -0.03151 |    0.16031 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20992 | -0.00485 |    0.15239 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25179 | -0.00150 |    0.18481 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20754 | -0.00519 |    0.15862 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31762 | -0.01576 |    0.21123 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18285 | -0.00222 |    0.13516 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15299 | -0.01813 |    0.12255 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18331 | -0.01964 |    0.14422 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13497 | -0.00504 |    0.10305 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14893 | -0.01826 |    0.11896 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13898 | -0.00451 |    0.10987 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17991 | -0.01467 |    0.13852 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13028 | -0.01334 |    0.10342 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10931 | -0.00766 |    0.08545 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11020 | -0.01192 |    0.08721 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07030 |  0.00240 |    0.05218 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55741 | -0.00000 |    0.43419 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:39:49,336 - Total sparsity: 0.00

2018-11-02 21:39:49,336 - --- validate (epoch=151)-----------
2018-11-02 21:39:49,336 - 10000 samples (128 per mini-batch)
2018-11-02 21:39:50,061 - Epoch: [151][   50/   78]    Loss 0.389646    Top1 87.796875    Top5 99.531250    
2018-11-02 21:39:50,447 - ==> Top1: 88.010    Top5: 99.600    Loss: 0.376

2018-11-02 21:39:50,448 - ==> Best Top1: 88.010   On Epoch: 151

2018-11-02 21:39:50,448 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:39:50,456 - 

2018-11-02 21:39:50,457 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:39:51,531 - Epoch: [152][   50/  391]    Overall Loss 0.194784    Objective Loss 0.194784    Top1 93.062500    Top5 99.906250    LR 0.061172    Time 0.021454    
2018-11-02 21:39:52,522 - Epoch: [152][  100/  391]    Overall Loss 0.194685    Objective Loss 0.194685    Top1 92.968750    Top5 99.875000    LR 0.061172    Time 0.020621    
2018-11-02 21:39:53,502 - Epoch: [152][  150/  391]    Overall Loss 0.195711    Objective Loss 0.195711    Top1 92.963542    Top5 99.854167    LR 0.061172    Time 0.020274    
2018-11-02 21:39:54,480 - Epoch: [152][  200/  391]    Overall Loss 0.200214    Objective Loss 0.200214    Top1 92.796875    Top5 99.871094    LR 0.061172    Time 0.020089    
2018-11-02 21:39:55,459 - Epoch: [152][  250/  391]    Overall Loss 0.201909    Objective Loss 0.201909    Top1 92.746875    Top5 99.865625    LR 0.061172    Time 0.019982    
2018-11-02 21:39:56,435 - Epoch: [152][  300/  391]    Overall Loss 0.201465    Objective Loss 0.201465    Top1 92.799479    Top5 99.864583    LR 0.061172    Time 0.019890    
2018-11-02 21:39:57,426 - Epoch: [152][  350/  391]    Overall Loss 0.203386    Objective Loss 0.203386    Top1 92.741071    Top5 99.866071    LR 0.061172    Time 0.019875    
2018-11-02 21:39:58,333 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44877 | -0.00837 |    0.28552 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19994 |  0.00187 |    0.12561 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20018 | -0.00674 |    0.15172 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23754 | -0.06122 |    0.18591 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25482 |  0.00700 |    0.20104 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21130 | -0.03106 |    0.15986 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20838 | -0.00684 |    0.15133 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25004 | -0.00366 |    0.18340 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20613 | -0.00672 |    0.15745 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31507 | -0.01492 |    0.20911 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18150 | -0.00147 |    0.13419 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15213 | -0.01751 |    0.12163 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18234 | -0.01867 |    0.14342 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13414 | -0.00488 |    0.10233 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14794 | -0.01848 |    0.11845 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13814 | -0.00427 |    0.10919 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17855 | -0.01406 |    0.13752 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12957 | -0.01313 |    0.10269 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10882 | -0.00754 |    0.08514 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10971 | -0.01213 |    0.08693 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06980 |  0.00271 |    0.05185 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55803 | -0.00000 |    0.43495 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:39:58,333 - Total sparsity: 0.00

2018-11-02 21:39:58,334 - --- validate (epoch=152)-----------
2018-11-02 21:39:58,334 - 10000 samples (128 per mini-batch)
2018-11-02 21:39:59,057 - Epoch: [152][   50/   78]    Loss 0.406178    Top1 87.734375    Top5 99.500000    
2018-11-02 21:39:59,448 - ==> Top1: 87.390    Top5: 99.610    Loss: 0.393

2018-11-02 21:39:59,449 - ==> Best Top1: 88.010   On Epoch: 151

2018-11-02 21:39:59,449 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:39:59,460 - 

2018-11-02 21:39:59,461 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:40:00,502 - Epoch: [153][   50/  391]    Overall Loss 0.194068    Objective Loss 0.194068    Top1 93.625000    Top5 99.953125    LR 0.058113    Time 0.020796    
2018-11-02 21:40:01,483 - Epoch: [153][  100/  391]    Overall Loss 0.198223    Objective Loss 0.198223    Top1 93.250000    Top5 99.921875    LR 0.058113    Time 0.020197    
2018-11-02 21:40:02,461 - Epoch: [153][  150/  391]    Overall Loss 0.198921    Objective Loss 0.198921    Top1 93.161458    Top5 99.880208    LR 0.058113    Time 0.019977    
2018-11-02 21:40:03,442 - Epoch: [153][  200/  391]    Overall Loss 0.198878    Objective Loss 0.198878    Top1 93.156250    Top5 99.886719    LR 0.058113    Time 0.019879    
2018-11-02 21:40:04,422 - Epoch: [153][  250/  391]    Overall Loss 0.199449    Objective Loss 0.199449    Top1 93.159375    Top5 99.878125    LR 0.058113    Time 0.019819    
2018-11-02 21:40:05,400 - Epoch: [153][  300/  391]    Overall Loss 0.200015    Objective Loss 0.200015    Top1 93.111979    Top5 99.875000    LR 0.058113    Time 0.019772    
2018-11-02 21:40:06,378 - Epoch: [153][  350/  391]    Overall Loss 0.199990    Objective Loss 0.199990    Top1 93.084821    Top5 99.877232    LR 0.058113    Time 0.019739    
2018-11-02 21:40:07,261 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44569 | -0.00479 |    0.28292 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19840 |  0.00187 |    0.12404 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19865 | -0.00761 |    0.15028 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23651 | -0.05954 |    0.18383 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25334 |  0.01045 |    0.19894 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20959 | -0.03157 |    0.15868 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20671 | -0.00344 |    0.14984 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24833 | -0.00307 |    0.18196 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20467 | -0.00612 |    0.15640 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31238 | -0.01465 |    0.20663 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18027 | -0.00249 |    0.13326 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15103 | -0.01789 |    0.12093 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18103 | -0.01896 |    0.14199 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13323 | -0.00499 |    0.10175 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14688 | -0.01825 |    0.11774 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13730 | -0.00393 |    0.10853 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17705 | -0.01416 |    0.13645 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12882 | -0.01298 |    0.10212 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10829 | -0.00743 |    0.08474 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10926 | -0.01203 |    0.08652 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06933 |  0.00255 |    0.05152 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55855 | -0.00000 |    0.43522 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:40:07,261 - Total sparsity: 0.00

2018-11-02 21:40:07,262 - --- validate (epoch=153)-----------
2018-11-02 21:40:07,262 - 10000 samples (128 per mini-batch)
2018-11-02 21:40:07,988 - Epoch: [153][   50/   78]    Loss 0.407699    Top1 87.890625    Top5 99.453125    
2018-11-02 21:40:08,381 - ==> Top1: 87.910    Top5: 99.530    Loss: 0.398

2018-11-02 21:40:08,382 - ==> Best Top1: 88.010   On Epoch: 151

2018-11-02 21:40:08,382 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:40:08,392 - 

2018-11-02 21:40:08,393 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:40:09,433 - Epoch: [154][   50/  391]    Overall Loss 0.188367    Objective Loss 0.188367    Top1 93.296875    Top5 99.859375    LR 0.055208    Time 0.020758    
2018-11-02 21:40:10,410 - Epoch: [154][  100/  391]    Overall Loss 0.186293    Objective Loss 0.186293    Top1 93.242188    Top5 99.859375    LR 0.055208    Time 0.020141    
2018-11-02 21:40:11,387 - Epoch: [154][  150/  391]    Overall Loss 0.189290    Objective Loss 0.189290    Top1 93.010417    Top5 99.869792    LR 0.055208    Time 0.019930    
2018-11-02 21:40:12,366 - Epoch: [154][  200/  391]    Overall Loss 0.192892    Objective Loss 0.192892    Top1 92.964844    Top5 99.875000    LR 0.055208    Time 0.019835    
2018-11-02 21:40:13,346 - Epoch: [154][  250/  391]    Overall Loss 0.194975    Objective Loss 0.194975    Top1 92.881250    Top5 99.887500    LR 0.055208    Time 0.019783    
2018-11-02 21:40:14,326 - Epoch: [154][  300/  391]    Overall Loss 0.199709    Objective Loss 0.199709    Top1 92.763021    Top5 99.880208    LR 0.055208    Time 0.019750    
2018-11-02 21:40:15,335 - Epoch: [154][  350/  391]    Overall Loss 0.199499    Objective Loss 0.199499    Top1 92.819196    Top5 99.881696    LR 0.055208    Time 0.019806    
2018-11-02 21:40:16,271 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44261 | -0.01069 |    0.28208 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19725 | -0.00116 |    0.12315 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19728 | -0.00659 |    0.14923 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23473 | -0.06031 |    0.18281 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25187 |  0.00915 |    0.19765 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20798 | -0.03301 |    0.15759 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20516 | -0.00260 |    0.14887 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24659 | -0.00409 |    0.18048 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20333 | -0.00601 |    0.15526 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30977 | -0.01389 |    0.20770 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17911 | -0.00214 |    0.13219 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15012 | -0.01777 |    0.12012 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17998 | -0.01837 |    0.14138 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13237 | -0.00492 |    0.10097 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14596 | -0.01766 |    0.11682 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13650 | -0.00378 |    0.10791 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17569 | -0.01326 |    0.13469 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12812 | -0.01291 |    0.10163 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10779 | -0.00762 |    0.08436 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10882 | -0.01182 |    0.08614 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06891 |  0.00262 |    0.05121 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55704 | -0.00000 |    0.43420 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:40:16,271 - Total sparsity: 0.00

2018-11-02 21:40:16,271 - --- validate (epoch=154)-----------
2018-11-02 21:40:16,271 - 10000 samples (128 per mini-batch)
2018-11-02 21:40:16,990 - Epoch: [154][   50/   78]    Loss 0.393709    Top1 88.281250    Top5 99.562500    
2018-11-02 21:40:17,383 - ==> Top1: 88.250    Top5: 99.620    Loss: 0.380

2018-11-02 21:40:17,384 - ==> Best Top1: 88.250   On Epoch: 154

2018-11-02 21:40:17,384 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:40:17,392 - 

2018-11-02 21:40:17,393 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:40:18,429 - Epoch: [155][   50/  391]    Overall Loss 0.188690    Objective Loss 0.188690    Top1 93.562500    Top5 99.875000    LR 0.052447    Time 0.020701    
2018-11-02 21:40:19,405 - Epoch: [155][  100/  391]    Overall Loss 0.187328    Objective Loss 0.187328    Top1 93.468750    Top5 99.890625    LR 0.052447    Time 0.020093    
2018-11-02 21:40:20,382 - Epoch: [155][  150/  391]    Overall Loss 0.181383    Objective Loss 0.181383    Top1 93.739583    Top5 99.906250    LR 0.052447    Time 0.019900    
2018-11-02 21:40:21,361 - Epoch: [155][  200/  391]    Overall Loss 0.184675    Objective Loss 0.184675    Top1 93.519531    Top5 99.898438    LR 0.052447    Time 0.019814    
2018-11-02 21:40:22,341 - Epoch: [155][  250/  391]    Overall Loss 0.186211    Objective Loss 0.186211    Top1 93.450000    Top5 99.900000    LR 0.052447    Time 0.019765    
2018-11-02 21:40:23,318 - Epoch: [155][  300/  391]    Overall Loss 0.187947    Objective Loss 0.187947    Top1 93.398438    Top5 99.893229    LR 0.052447    Time 0.019723    
2018-11-02 21:40:24,297 - Epoch: [155][  350/  391]    Overall Loss 0.188849    Objective Loss 0.188849    Top1 93.350446    Top5 99.895089    LR 0.052447    Time 0.019699    
2018-11-02 21:40:25,175 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43924 | -0.00827 |    0.27926 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19589 | -0.00064 |    0.12215 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19592 | -0.00326 |    0.14786 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23339 | -0.05935 |    0.18140 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25021 |  0.00931 |    0.19674 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20682 | -0.03183 |    0.15583 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20374 | -0.00315 |    0.14787 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24485 | -0.00329 |    0.17942 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20190 | -0.00590 |    0.15425 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30711 | -0.01245 |    0.20475 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17768 | -0.00138 |    0.13113 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14898 | -0.01758 |    0.11917 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17873 | -0.01875 |    0.14077 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13135 | -0.00597 |    0.10016 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14489 | -0.01749 |    0.11588 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13560 | -0.00384 |    0.10727 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17416 | -0.01313 |    0.13343 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12734 | -0.01273 |    0.10106 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10721 | -0.00742 |    0.08390 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10819 | -0.01206 |    0.08587 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06841 |  0.00250 |    0.05092 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55780 | -0.00000 |    0.43438 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:40:25,175 - Total sparsity: 0.00

2018-11-02 21:40:25,175 - --- validate (epoch=155)-----------
2018-11-02 21:40:25,175 - 10000 samples (128 per mini-batch)
2018-11-02 21:40:25,901 - Epoch: [155][   50/   78]    Loss 0.425952    Top1 87.406250    Top5 99.437500    
2018-11-02 21:40:26,300 - ==> Top1: 87.430    Top5: 99.510    Loss: 0.427

2018-11-02 21:40:26,300 - ==> Best Top1: 88.250   On Epoch: 154

2018-11-02 21:40:26,300 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:40:26,312 - 

2018-11-02 21:40:26,312 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:40:27,412 - Epoch: [156][   50/  391]    Overall Loss 0.171107    Objective Loss 0.171107    Top1 94.234375    Top5 99.906250    LR 0.049825    Time 0.021960    
2018-11-02 21:40:28,425 - Epoch: [156][  100/  391]    Overall Loss 0.177235    Objective Loss 0.177235    Top1 93.945312    Top5 99.890625    LR 0.049825    Time 0.021098    
2018-11-02 21:40:29,401 - Epoch: [156][  150/  391]    Overall Loss 0.175877    Objective Loss 0.175877    Top1 93.807292    Top5 99.885417    LR 0.049825    Time 0.020566    
2018-11-02 21:40:30,382 - Epoch: [156][  200/  391]    Overall Loss 0.177313    Objective Loss 0.177313    Top1 93.781250    Top5 99.898438    LR 0.049825    Time 0.020323    
2018-11-02 21:40:31,362 - Epoch: [156][  250/  391]    Overall Loss 0.179475    Objective Loss 0.179475    Top1 93.703125    Top5 99.909375    LR 0.049825    Time 0.020171    
2018-11-02 21:40:32,342 - Epoch: [156][  300/  391]    Overall Loss 0.181456    Objective Loss 0.181456    Top1 93.604167    Top5 99.908854    LR 0.049825    Time 0.020072    
2018-11-02 21:40:33,322 - Epoch: [156][  350/  391]    Overall Loss 0.183053    Objective Loss 0.183053    Top1 93.553571    Top5 99.904018    LR 0.049825    Time 0.019990    
2018-11-02 21:40:34,205 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43607 | -0.00640 |    0.27759 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19445 |  0.00085 |    0.12124 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19437 | -0.00448 |    0.14713 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23181 | -0.05952 |    0.18000 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24844 |  0.01118 |    0.19492 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20502 | -0.03429 |    0.15556 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20230 | -0.00410 |    0.14674 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24311 | -0.00340 |    0.17830 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20056 | -0.00576 |    0.15323 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30457 | -0.01345 |    0.20348 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17645 | -0.00142 |    0.13010 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14791 | -0.01767 |    0.11873 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17767 | -0.01748 |    0.13944 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13042 | -0.00602 |    0.09960 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14386 | -0.01766 |    0.11502 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13477 | -0.00372 |    0.10660 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17282 | -0.01252 |    0.13230 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12661 | -0.01260 |    0.10053 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10667 | -0.00721 |    0.08344 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10766 | -0.01221 |    0.08553 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06791 |  0.00271 |    0.05058 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55933 | -0.00000 |    0.43589 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:40:34,205 - Total sparsity: 0.00

2018-11-02 21:40:34,205 - --- validate (epoch=156)-----------
2018-11-02 21:40:34,205 - 10000 samples (128 per mini-batch)
2018-11-02 21:40:34,926 - Epoch: [156][   50/   78]    Loss 0.382393    Top1 89.078125    Top5 99.546875    
2018-11-02 21:40:35,317 - ==> Top1: 89.130    Top5: 99.630    Loss: 0.378

2018-11-02 21:40:35,318 - ==> Best Top1: 89.130   On Epoch: 156

2018-11-02 21:40:35,318 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:40:35,328 - 

2018-11-02 21:40:35,329 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:40:36,366 - Epoch: [157][   50/  391]    Overall Loss 0.169245    Objective Loss 0.169245    Top1 94.078125    Top5 99.953125    LR 0.047334    Time 0.020719    
2018-11-02 21:40:37,343 - Epoch: [157][  100/  391]    Overall Loss 0.173189    Objective Loss 0.173189    Top1 93.867188    Top5 99.929688    LR 0.047334    Time 0.020119    
2018-11-02 21:40:38,323 - Epoch: [157][  150/  391]    Overall Loss 0.172927    Objective Loss 0.172927    Top1 93.932292    Top5 99.927083    LR 0.047334    Time 0.019935    
2018-11-02 21:40:39,299 - Epoch: [157][  200/  391]    Overall Loss 0.176358    Objective Loss 0.176358    Top1 93.808594    Top5 99.929688    LR 0.047334    Time 0.019825    
2018-11-02 21:40:40,277 - Epoch: [157][  250/  391]    Overall Loss 0.181288    Objective Loss 0.181288    Top1 93.587500    Top5 99.925000    LR 0.047334    Time 0.019764    
2018-11-02 21:40:41,255 - Epoch: [157][  300/  391]    Overall Loss 0.181739    Objective Loss 0.181739    Top1 93.625000    Top5 99.906250    LR 0.047334    Time 0.019724    
2018-11-02 21:40:42,231 - Epoch: [157][  350/  391]    Overall Loss 0.183089    Objective Loss 0.183089    Top1 93.544643    Top5 99.901786    LR 0.047334    Time 0.019692    
2018-11-02 21:40:43,114 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43301 | -0.00249 |    0.27484 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19302 | -0.00023 |    0.12034 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19302 | -0.00656 |    0.14554 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23046 | -0.05914 |    0.17923 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24704 |  0.00913 |    0.19530 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20387 | -0.03393 |    0.15448 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20101 | -0.00199 |    0.14595 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24168 | -0.00329 |    0.17733 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19927 | -0.00681 |    0.15234 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30227 | -0.01378 |    0.20202 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17540 | -0.00186 |    0.12958 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14699 | -0.01756 |    0.11801 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17640 | -0.01885 |    0.13830 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12961 | -0.00524 |    0.09925 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14295 | -0.01728 |    0.11435 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13402 | -0.00315 |    0.10597 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17154 | -0.01292 |    0.13169 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12592 | -0.01248 |    0.10001 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10619 | -0.00722 |    0.08311 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10723 | -0.01214 |    0.08513 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06747 |  0.00281 |    0.05028 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55953 | -0.00000 |    0.43615 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:40:43,114 - Total sparsity: 0.00

2018-11-02 21:40:43,114 - --- validate (epoch=157)-----------
2018-11-02 21:40:43,114 - 10000 samples (128 per mini-batch)
2018-11-02 21:40:43,840 - Epoch: [157][   50/   78]    Loss 0.400111    Top1 88.156250    Top5 99.468750    
2018-11-02 21:40:44,234 - ==> Top1: 88.290    Top5: 99.550    Loss: 0.388

2018-11-02 21:40:44,234 - ==> Best Top1: 89.130   On Epoch: 156

2018-11-02 21:40:44,235 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:40:44,242 - 

2018-11-02 21:40:44,243 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:40:45,280 - Epoch: [158][   50/  391]    Overall Loss 0.163889    Objective Loss 0.163889    Top1 94.093750    Top5 99.937500    LR 0.044967    Time 0.020723    
2018-11-02 21:40:46,260 - Epoch: [158][  100/  391]    Overall Loss 0.171349    Objective Loss 0.171349    Top1 93.867188    Top5 99.914062    LR 0.044967    Time 0.020144    
2018-11-02 21:40:47,238 - Epoch: [158][  150/  391]    Overall Loss 0.173226    Objective Loss 0.173226    Top1 93.848958    Top5 99.937500    LR 0.044967    Time 0.019942    
2018-11-02 21:40:48,214 - Epoch: [158][  200/  391]    Overall Loss 0.168869    Objective Loss 0.168869    Top1 93.984375    Top5 99.925781    LR 0.044967    Time 0.019828    
2018-11-02 21:40:49,192 - Epoch: [158][  250/  391]    Overall Loss 0.173899    Objective Loss 0.173899    Top1 93.746875    Top5 99.925000    LR 0.044967    Time 0.019768    
2018-11-02 21:40:50,169 - Epoch: [158][  300/  391]    Overall Loss 0.176970    Objective Loss 0.176970    Top1 93.627604    Top5 99.914062    LR 0.044967    Time 0.019726    
2018-11-02 21:40:51,147 - Epoch: [158][  350/  391]    Overall Loss 0.176701    Objective Loss 0.176701    Top1 93.665179    Top5 99.924107    LR 0.044967    Time 0.019698    
2018-11-02 21:40:52,028 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42983 | -0.00470 |    0.27355 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19175 | -0.00061 |    0.11962 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19173 | -0.00671 |    0.14456 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22971 | -0.05568 |    0.17768 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24542 |  0.00905 |    0.19280 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20234 | -0.03487 |    0.15414 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19959 | -0.00321 |    0.14479 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24005 | -0.00341 |    0.17593 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19803 | -0.00686 |    0.15163 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30002 | -0.01277 |    0.19959 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17427 | -0.00269 |    0.12859 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14595 | -0.01839 |    0.11734 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17534 | -0.01879 |    0.13756 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12877 | -0.00524 |    0.09845 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14196 | -0.01769 |    0.11353 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13326 | -0.00330 |    0.10533 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17034 | -0.01230 |    0.13108 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12523 | -0.01246 |    0.09944 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10572 | -0.00737 |    0.08285 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10676 | -0.01209 |    0.08482 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06703 |  0.00282 |    0.05002 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55931 | -0.00000 |    0.43559 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:40:52,028 - Total sparsity: 0.00

2018-11-02 21:40:52,028 - --- validate (epoch=158)-----------
2018-11-02 21:40:52,029 - 10000 samples (128 per mini-batch)
2018-11-02 21:40:52,753 - Epoch: [158][   50/   78]    Loss 0.386423    Top1 88.484375    Top5 99.437500    
2018-11-02 21:40:53,161 - ==> Top1: 88.220    Top5: 99.560    Loss: 0.383

2018-11-02 21:40:53,162 - ==> Best Top1: 89.130   On Epoch: 156

2018-11-02 21:40:53,162 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:40:53,174 - 

2018-11-02 21:40:53,174 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:40:54,210 - Epoch: [159][   50/  391]    Overall Loss 0.161410    Objective Loss 0.161410    Top1 93.968750    Top5 99.921875    LR 0.042719    Time 0.020681    
2018-11-02 21:40:55,189 - Epoch: [159][  100/  391]    Overall Loss 0.165493    Objective Loss 0.165493    Top1 94.070312    Top5 99.906250    LR 0.042719    Time 0.020119    
2018-11-02 21:40:56,168 - Epoch: [159][  150/  391]    Overall Loss 0.166355    Objective Loss 0.166355    Top1 94.114583    Top5 99.906250    LR 0.042719    Time 0.019931    
2018-11-02 21:40:57,142 - Epoch: [159][  200/  391]    Overall Loss 0.165831    Objective Loss 0.165831    Top1 94.140625    Top5 99.898438    LR 0.042719    Time 0.019813    
2018-11-02 21:40:58,123 - Epoch: [159][  250/  391]    Overall Loss 0.164484    Objective Loss 0.164484    Top1 94.259375    Top5 99.881250    LR 0.042719    Time 0.019767    
2018-11-02 21:40:59,104 - Epoch: [159][  300/  391]    Overall Loss 0.166820    Objective Loss 0.166820    Top1 94.132812    Top5 99.882812    LR 0.042719    Time 0.019739    
2018-11-02 21:41:00,083 - Epoch: [159][  350/  391]    Overall Loss 0.167637    Objective Loss 0.167637    Top1 94.078125    Top5 99.888393    LR 0.042719    Time 0.019714    
2018-11-02 21:41:00,969 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42629 | -0.00560 |    0.27033 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19028 | -0.00083 |    0.11889 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19031 | -0.00607 |    0.14362 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22787 | -0.05618 |    0.17642 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24367 |  0.01097 |    0.19181 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20135 | -0.03270 |    0.15310 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19821 | -0.00394 |    0.14353 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23838 | -0.00433 |    0.17436 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19672 | -0.00676 |    0.15053 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29771 | -0.01288 |    0.19768 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17318 | -0.00201 |    0.12782 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14505 | -0.01745 |    0.11680 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17437 | -0.01796 |    0.13653 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12796 | -0.00521 |    0.09779 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14105 | -0.01719 |    0.11281 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13246 | -0.00333 |    0.10467 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16905 | -0.01212 |    0.12994 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12453 | -0.01218 |    0.09882 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10519 | -0.00736 |    0.08243 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10627 | -0.01208 |    0.08444 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06660 |  0.00277 |    0.04972 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56063 | -0.00000 |    0.43707 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:41:00,969 - Total sparsity: 0.00

2018-11-02 21:41:00,969 - --- validate (epoch=159)-----------
2018-11-02 21:41:00,969 - 10000 samples (128 per mini-batch)
2018-11-02 21:41:01,688 - Epoch: [159][   50/   78]    Loss 0.398750    Top1 88.390625    Top5 99.593750    
2018-11-02 21:41:02,082 - ==> Top1: 88.400    Top5: 99.610    Loss: 0.395

2018-11-02 21:41:02,083 - ==> Best Top1: 89.130   On Epoch: 156

2018-11-02 21:41:02,083 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:41:02,090 - 

2018-11-02 21:41:02,091 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:41:03,129 - Epoch: [160][   50/  391]    Overall Loss 0.165916    Objective Loss 0.165916    Top1 94.187500    Top5 99.906250    LR 0.040583    Time 0.020740    
2018-11-02 21:41:04,109 - Epoch: [160][  100/  391]    Overall Loss 0.161514    Objective Loss 0.161514    Top1 94.234375    Top5 99.929688    LR 0.040583    Time 0.020155    
2018-11-02 21:41:05,087 - Epoch: [160][  150/  391]    Overall Loss 0.163496    Objective Loss 0.163496    Top1 94.171875    Top5 99.942708    LR 0.040583    Time 0.019943    
2018-11-02 21:41:06,066 - Epoch: [160][  200/  391]    Overall Loss 0.163912    Objective Loss 0.163912    Top1 94.199219    Top5 99.941406    LR 0.040583    Time 0.019848    
2018-11-02 21:41:07,046 - Epoch: [160][  250/  391]    Overall Loss 0.165508    Objective Loss 0.165508    Top1 94.190625    Top5 99.943750    LR 0.040583    Time 0.019790    
2018-11-02 21:41:08,023 - Epoch: [160][  300/  391]    Overall Loss 0.166481    Objective Loss 0.166481    Top1 94.158854    Top5 99.934896    LR 0.040583    Time 0.019747    
2018-11-02 21:41:09,001 - Epoch: [160][  350/  391]    Overall Loss 0.167301    Objective Loss 0.167301    Top1 94.107143    Top5 99.919643    LR 0.040583    Time 0.019715    
2018-11-02 21:41:09,884 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42371 | -0.00750 |    0.26949 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18896 | -0.00079 |    0.11832 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18904 | -0.00503 |    0.14276 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22653 | -0.05542 |    0.17580 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24203 |  0.01070 |    0.19015 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20017 | -0.03216 |    0.15145 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19696 | -0.00393 |    0.14322 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23686 | -0.00473 |    0.17322 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19551 | -0.00595 |    0.14952 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29556 | -0.01144 |    0.19695 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17217 | -0.00143 |    0.12722 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14410 | -0.01745 |    0.11584 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17332 | -0.01867 |    0.13566 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12722 | -0.00430 |    0.09743 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14012 | -0.01716 |    0.11201 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13167 | -0.00343 |    0.10409 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16781 | -0.01190 |    0.12892 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12381 | -0.01232 |    0.09822 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10470 | -0.00694 |    0.08205 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10574 | -0.01221 |    0.08400 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06615 |  0.00253 |    0.04943 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55989 | -0.00000 |    0.43605 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:41:09,884 - Total sparsity: 0.00

2018-11-02 21:41:09,884 - --- validate (epoch=160)-----------
2018-11-02 21:41:09,884 - 10000 samples (128 per mini-batch)
2018-11-02 21:41:10,612 - Epoch: [160][   50/   78]    Loss 0.397668    Top1 88.812500    Top5 99.468750    
2018-11-02 21:41:11,004 - ==> Top1: 88.540    Top5: 99.510    Loss: 0.388

2018-11-02 21:41:11,005 - ==> Best Top1: 89.130   On Epoch: 156

2018-11-02 21:41:11,005 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:41:11,016 - 

2018-11-02 21:41:11,016 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:41:12,056 - Epoch: [161][   50/  391]    Overall Loss 0.147290    Objective Loss 0.147290    Top1 94.828125    Top5 99.953125    LR 0.038554    Time 0.020764    
2018-11-02 21:41:13,037 - Epoch: [161][  100/  391]    Overall Loss 0.151928    Objective Loss 0.151928    Top1 94.734375    Top5 99.953125    LR 0.038554    Time 0.020180    
2018-11-02 21:41:14,017 - Epoch: [161][  150/  391]    Overall Loss 0.155794    Objective Loss 0.155794    Top1 94.536458    Top5 99.942708    LR 0.038554    Time 0.019977    
2018-11-02 21:41:14,996 - Epoch: [161][  200/  391]    Overall Loss 0.160784    Objective Loss 0.160784    Top1 94.367188    Top5 99.937500    LR 0.038554    Time 0.019870    
2018-11-02 21:41:15,975 - Epoch: [161][  250/  391]    Overall Loss 0.162379    Objective Loss 0.162379    Top1 94.331250    Top5 99.931250    LR 0.038554    Time 0.019793    
2018-11-02 21:41:16,953 - Epoch: [161][  300/  391]    Overall Loss 0.162498    Objective Loss 0.162498    Top1 94.361979    Top5 99.929688    LR 0.038554    Time 0.019749    
2018-11-02 21:41:17,932 - Epoch: [161][  350/  391]    Overall Loss 0.163311    Objective Loss 0.163311    Top1 94.310268    Top5 99.930804    LR 0.038554    Time 0.019720    
2018-11-02 21:41:18,814 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42095 | -0.00788 |    0.26748 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18777 | -0.00113 |    0.11799 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18778 | -0.00481 |    0.14173 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22550 | -0.05338 |    0.17472 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24036 |  0.00924 |    0.18873 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19897 | -0.03221 |    0.15088 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19558 | -0.00354 |    0.14201 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23538 | -0.00384 |    0.17226 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19428 | -0.00573 |    0.14856 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29326 | -0.01203 |    0.19542 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17108 | -0.00210 |    0.12654 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14322 | -0.01716 |    0.11515 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17256 | -0.01674 |    0.13479 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12647 | -0.00509 |    0.09715 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13925 | -0.01686 |    0.11119 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13092 | -0.00277 |    0.10352 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16663 | -0.01162 |    0.12798 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12315 | -0.01204 |    0.09769 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10421 | -0.00697 |    0.08170 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10525 | -0.01219 |    0.08366 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06571 |  0.00249 |    0.04917 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56067 | -0.00000 |    0.43695 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:41:18,814 - Total sparsity: 0.00

2018-11-02 21:41:18,814 - --- validate (epoch=161)-----------
2018-11-02 21:41:18,814 - 10000 samples (128 per mini-batch)
2018-11-02 21:41:19,539 - Epoch: [161][   50/   78]    Loss 0.370092    Top1 89.046875    Top5 99.609375    
2018-11-02 21:41:19,943 - ==> Top1: 88.850    Top5: 99.630    Loss: 0.367

2018-11-02 21:41:19,943 - ==> Best Top1: 89.130   On Epoch: 156

2018-11-02 21:41:19,944 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:41:19,951 - 

2018-11-02 21:41:19,951 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:41:20,988 - Epoch: [162][   50/  391]    Overall Loss 0.151893    Objective Loss 0.151893    Top1 94.609375    Top5 99.937500    LR 0.036626    Time 0.020694    
2018-11-02 21:41:21,963 - Epoch: [162][  100/  391]    Overall Loss 0.156276    Objective Loss 0.156276    Top1 94.523438    Top5 99.937500    LR 0.036626    Time 0.020083    
2018-11-02 21:41:22,940 - Epoch: [162][  150/  391]    Overall Loss 0.151825    Objective Loss 0.151825    Top1 94.697917    Top5 99.916667    LR 0.036626    Time 0.019891    
2018-11-02 21:41:23,918 - Epoch: [162][  200/  391]    Overall Loss 0.152728    Objective Loss 0.152728    Top1 94.617188    Top5 99.929688    LR 0.036626    Time 0.019805    
2018-11-02 21:41:24,896 - Epoch: [162][  250/  391]    Overall Loss 0.153831    Objective Loss 0.153831    Top1 94.518750    Top5 99.928125    LR 0.036626    Time 0.019750    
2018-11-02 21:41:25,873 - Epoch: [162][  300/  391]    Overall Loss 0.154035    Objective Loss 0.154035    Top1 94.526042    Top5 99.927083    LR 0.036626    Time 0.019712    
2018-11-02 21:41:26,852 - Epoch: [162][  350/  391]    Overall Loss 0.154760    Objective Loss 0.154760    Top1 94.482143    Top5 99.926339    LR 0.036626    Time 0.019688    
2018-11-02 21:41:27,734 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41827 | -0.00528 |    0.26563 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18655 | -0.00191 |    0.11693 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18648 | -0.00513 |    0.14071 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22359 | -0.05432 |    0.17380 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23873 |  0.00906 |    0.18737 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19795 | -0.03100 |    0.15042 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19430 | -0.00290 |    0.14150 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23390 | -0.00348 |    0.17137 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19305 | -0.00580 |    0.14756 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29107 | -0.01221 |    0.19365 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17009 | -0.00177 |    0.12550 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14231 | -0.01696 |    0.11453 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17144 | -0.01746 |    0.13398 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12577 | -0.00426 |    0.09625 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13834 | -0.01687 |    0.11047 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13014 | -0.00286 |    0.10283 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16544 | -0.01152 |    0.12721 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12248 | -0.01178 |    0.09715 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10372 | -0.00685 |    0.08135 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10479 | -0.01196 |    0.08332 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06528 |  0.00254 |    0.04888 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56138 | -0.00000 |    0.43739 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:41:27,735 - Total sparsity: 0.00

2018-11-02 21:41:27,735 - --- validate (epoch=162)-----------
2018-11-02 21:41:27,735 - 10000 samples (128 per mini-batch)
2018-11-02 21:41:28,481 - Epoch: [162][   50/   78]    Loss 0.357122    Top1 89.218750    Top5 99.671875    
2018-11-02 21:41:28,874 - ==> Top1: 89.230    Top5: 99.720    Loss: 0.355

2018-11-02 21:41:28,875 - ==> Best Top1: 89.230   On Epoch: 162

2018-11-02 21:41:28,875 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:41:28,888 - 

2018-11-02 21:41:28,889 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:41:29,927 - Epoch: [163][   50/  391]    Overall Loss 0.143220    Objective Loss 0.143220    Top1 95.031250    Top5 99.921875    LR 0.034795    Time 0.020726    
2018-11-02 21:41:30,904 - Epoch: [163][  100/  391]    Overall Loss 0.149296    Objective Loss 0.149296    Top1 94.593750    Top5 99.945312    LR 0.034795    Time 0.020122    
2018-11-02 21:41:31,882 - Epoch: [163][  150/  391]    Overall Loss 0.146030    Objective Loss 0.146030    Top1 94.739583    Top5 99.932292    LR 0.034795    Time 0.019926    
2018-11-02 21:41:32,863 - Epoch: [163][  200/  391]    Overall Loss 0.145942    Objective Loss 0.145942    Top1 94.796875    Top5 99.937500    LR 0.034795    Time 0.019841    
2018-11-02 21:41:33,841 - Epoch: [163][  250/  391]    Overall Loss 0.145876    Objective Loss 0.145876    Top1 94.803125    Top5 99.931250    LR 0.034795    Time 0.019781    
2018-11-02 21:41:34,819 - Epoch: [163][  300/  391]    Overall Loss 0.148774    Objective Loss 0.148774    Top1 94.708333    Top5 99.921875    LR 0.034795    Time 0.019740    
2018-11-02 21:41:35,797 - Epoch: [163][  350/  391]    Overall Loss 0.148723    Objective Loss 0.148723    Top1 94.720982    Top5 99.926339    LR 0.034795    Time 0.019710    
2018-11-02 21:41:36,677 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41543 | -0.00766 |    0.26375 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18535 | -0.00171 |    0.11599 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18523 | -0.00533 |    0.13960 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22198 | -0.05437 |    0.17213 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23724 |  0.00757 |    0.18672 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19670 | -0.03080 |    0.14929 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19301 | -0.00340 |    0.14067 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23243 | -0.00285 |    0.17022 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19190 | -0.00552 |    0.14674 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28901 | -0.01247 |    0.19311 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16906 | -0.00162 |    0.12473 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14142 | -0.01730 |    0.11391 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17047 | -0.01666 |    0.13263 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12498 | -0.00492 |    0.09557 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13753 | -0.01629 |    0.10974 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12939 | -0.00277 |    0.10230 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16427 | -0.01134 |    0.12647 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12178 | -0.01207 |    0.09667 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10324 | -0.00675 |    0.08100 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10431 | -0.01195 |    0.08296 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06486 |  0.00265 |    0.04861 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56287 | -0.00000 |    0.43840 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:41:36,677 - Total sparsity: 0.00

2018-11-02 21:41:36,677 - --- validate (epoch=163)-----------
2018-11-02 21:41:36,677 - 10000 samples (128 per mini-batch)
2018-11-02 21:41:37,405 - Epoch: [163][   50/   78]    Loss 0.389932    Top1 89.015625    Top5 99.687500    
2018-11-02 21:41:37,797 - ==> Top1: 88.740    Top5: 99.700    Loss: 0.389

2018-11-02 21:41:37,798 - ==> Best Top1: 89.230   On Epoch: 162

2018-11-02 21:41:37,798 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:41:37,806 - 

2018-11-02 21:41:37,806 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:41:38,852 - Epoch: [164][   50/  391]    Overall Loss 0.141611    Objective Loss 0.141611    Top1 95.234375    Top5 99.906250    LR 0.033055    Time 0.020880    
2018-11-02 21:41:39,830 - Epoch: [164][  100/  391]    Overall Loss 0.144219    Objective Loss 0.144219    Top1 94.992188    Top5 99.937500    LR 0.033055    Time 0.020207    
2018-11-02 21:41:40,810 - Epoch: [164][  150/  391]    Overall Loss 0.144220    Objective Loss 0.144220    Top1 94.921875    Top5 99.927083    LR 0.033055    Time 0.019992    
2018-11-02 21:41:41,790 - Epoch: [164][  200/  391]    Overall Loss 0.142553    Objective Loss 0.142553    Top1 95.062500    Top5 99.929688    LR 0.033055    Time 0.019890    
2018-11-02 21:41:42,768 - Epoch: [164][  250/  391]    Overall Loss 0.144034    Objective Loss 0.144034    Top1 94.965625    Top5 99.931250    LR 0.033055    Time 0.019804    
2018-11-02 21:41:43,750 - Epoch: [164][  300/  391]    Overall Loss 0.146996    Objective Loss 0.146996    Top1 94.828125    Top5 99.919271    LR 0.033055    Time 0.019773    
2018-11-02 21:41:44,729 - Epoch: [164][  350/  391]    Overall Loss 0.147113    Objective Loss 0.147113    Top1 94.845982    Top5 99.910714    LR 0.033055    Time 0.019742    
2018-11-02 21:41:45,613 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41263 | -0.00780 |    0.26224 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18409 | -0.00368 |    0.11516 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18402 | -0.00557 |    0.13863 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22066 | -0.05378 |    0.17126 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23582 |  0.00724 |    0.18580 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19522 | -0.03301 |    0.14879 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19191 | -0.00279 |    0.14008 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23104 | -0.00317 |    0.16913 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19080 | -0.00541 |    0.14584 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28707 | -0.01297 |    0.19213 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16811 | -0.00215 |    0.12425 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14063 | -0.01718 |    0.11320 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16954 | -0.01605 |    0.13242 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12419 | -0.00535 |    0.09512 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13674 | -0.01605 |    0.10907 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12870 | -0.00260 |    0.10168 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16316 | -0.01130 |    0.12552 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12117 | -0.01194 |    0.09611 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10279 | -0.00693 |    0.08066 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10388 | -0.01174 |    0.08263 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06448 |  0.00252 |    0.04834 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56294 | -0.00001 |    0.43868 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:41:45,613 - Total sparsity: 0.00

2018-11-02 21:41:45,613 - --- validate (epoch=164)-----------
2018-11-02 21:41:45,614 - 10000 samples (128 per mini-batch)
2018-11-02 21:41:46,340 - Epoch: [164][   50/   78]    Loss 0.364764    Top1 89.671875    Top5 99.562500    
2018-11-02 21:41:46,734 - ==> Top1: 89.620    Top5: 99.600    Loss: 0.359

2018-11-02 21:41:46,735 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:41:46,735 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:41:46,748 - 

2018-11-02 21:41:46,749 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:41:47,789 - Epoch: [165][   50/  391]    Overall Loss 0.135943    Objective Loss 0.135943    Top1 95.125000    Top5 99.953125    LR 0.031402    Time 0.020777    
2018-11-02 21:41:48,765 - Epoch: [165][  100/  391]    Overall Loss 0.139315    Objective Loss 0.139315    Top1 94.960938    Top5 99.953125    LR 0.031402    Time 0.020137    
2018-11-02 21:41:49,748 - Epoch: [165][  150/  391]    Overall Loss 0.138828    Objective Loss 0.138828    Top1 95.031250    Top5 99.947917    LR 0.031402    Time 0.019966    
2018-11-02 21:41:50,727 - Epoch: [165][  200/  391]    Overall Loss 0.138955    Objective Loss 0.138955    Top1 95.000000    Top5 99.937500    LR 0.031402    Time 0.019863    
2018-11-02 21:41:51,708 - Epoch: [165][  250/  391]    Overall Loss 0.139783    Objective Loss 0.139783    Top1 94.993750    Top5 99.946875    LR 0.031402    Time 0.019811    
2018-11-02 21:41:52,689 - Epoch: [165][  300/  391]    Overall Loss 0.140909    Objective Loss 0.140909    Top1 94.992188    Top5 99.940104    LR 0.031402    Time 0.019775    
2018-11-02 21:41:53,668 - Epoch: [165][  350/  391]    Overall Loss 0.141314    Objective Loss 0.141314    Top1 94.959821    Top5 99.941964    LR 0.031402    Time 0.019744    
2018-11-02 21:41:54,550 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41031 | -0.00464 |    0.26034 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18294 | -0.00235 |    0.11460 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18293 | -0.00439 |    0.13770 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21948 | -0.05268 |    0.17017 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23433 |  0.00910 |    0.18486 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19435 | -0.03154 |    0.14788 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19071 | -0.00355 |    0.13886 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22962 | -0.00413 |    0.16823 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18970 | -0.00554 |    0.14492 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28512 | -0.01413 |    0.19017 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16715 | -0.00215 |    0.12343 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13985 | -0.01689 |    0.11243 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16849 | -0.01646 |    0.13143 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12345 | -0.00521 |    0.09453 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13593 | -0.01591 |    0.10847 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12800 | -0.00276 |    0.10115 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16207 | -0.01093 |    0.12461 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12056 | -0.01162 |    0.09568 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10233 | -0.00702 |    0.08038 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10341 | -0.01175 |    0.08226 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06408 |  0.00243 |    0.04808 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56387 | -0.00001 |    0.43938 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:41:54,551 - Total sparsity: 0.00

2018-11-02 21:41:54,551 - --- validate (epoch=165)-----------
2018-11-02 21:41:54,551 - 10000 samples (128 per mini-batch)
2018-11-02 21:41:55,276 - Epoch: [165][   50/   78]    Loss 0.382091    Top1 88.640625    Top5 99.578125    
2018-11-02 21:41:55,670 - ==> Top1: 88.990    Top5: 99.650    Loss: 0.377

2018-11-02 21:41:55,671 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:41:55,671 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:41:55,683 - 

2018-11-02 21:41:55,683 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:41:56,719 - Epoch: [166][   50/  391]    Overall Loss 0.126043    Objective Loss 0.126043    Top1 95.625000    Top5 99.984375    LR 0.029832    Time 0.020695    
2018-11-02 21:41:57,697 - Epoch: [166][  100/  391]    Overall Loss 0.131104    Objective Loss 0.131104    Top1 95.187500    Top5 99.968750    LR 0.029832    Time 0.020112    
2018-11-02 21:41:58,673 - Epoch: [166][  150/  391]    Overall Loss 0.135979    Objective Loss 0.135979    Top1 95.114583    Top5 99.958333    LR 0.029832    Time 0.019902    
2018-11-02 21:41:59,656 - Epoch: [166][  200/  391]    Overall Loss 0.138531    Objective Loss 0.138531    Top1 95.085938    Top5 99.957031    LR 0.029832    Time 0.019836    
2018-11-02 21:42:00,652 - Epoch: [166][  250/  391]    Overall Loss 0.139692    Objective Loss 0.139692    Top1 95.018750    Top5 99.946875    LR 0.029832    Time 0.019850    
2018-11-02 21:42:01,629 - Epoch: [166][  300/  391]    Overall Loss 0.140334    Objective Loss 0.140334    Top1 94.994792    Top5 99.947917    LR 0.029832    Time 0.019794    
2018-11-02 21:42:02,617 - Epoch: [166][  350/  391]    Overall Loss 0.142566    Objective Loss 0.142566    Top1 94.930804    Top5 99.950893    LR 0.029832    Time 0.019785    
2018-11-02 21:42:03,500 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40803 | -0.00447 |    0.25833 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18194 | -0.00227 |    0.11350 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18193 | -0.00334 |    0.13773 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21821 | -0.05283 |    0.16922 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23312 |  0.00769 |    0.18446 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19334 | -0.03146 |    0.14750 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18966 | -0.00335 |    0.13829 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22841 | -0.00254 |    0.16711 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18872 | -0.00530 |    0.14423 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28343 | -0.01278 |    0.18802 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16626 | -0.00249 |    0.12289 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13918 | -0.01649 |    0.11195 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16755 | -0.01666 |    0.13108 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12277 | -0.00518 |    0.09387 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13521 | -0.01569 |    0.10789 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12736 | -0.00298 |    0.10069 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16109 | -0.01087 |    0.12395 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12001 | -0.01165 |    0.09528 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10195 | -0.00686 |    0.08006 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10303 | -0.01161 |    0.08191 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06373 |  0.00252 |    0.04782 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56379 | -0.00001 |    0.43933 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:42:03,500 - Total sparsity: 0.00

2018-11-02 21:42:03,500 - --- validate (epoch=166)-----------
2018-11-02 21:42:03,500 - 10000 samples (128 per mini-batch)
2018-11-02 21:42:04,228 - Epoch: [166][   50/   78]    Loss 0.383337    Top1 89.078125    Top5 99.703125    
2018-11-02 21:42:04,625 - ==> Top1: 89.150    Top5: 99.750    Loss: 0.372

2018-11-02 21:42:04,626 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:42:04,626 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:42:04,633 - 

2018-11-02 21:42:04,633 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:42:05,729 - Epoch: [167][   50/  391]    Overall Loss 0.122454    Objective Loss 0.122454    Top1 95.843750    Top5 99.984375    LR 0.028340    Time 0.021877    
2018-11-02 21:42:06,705 - Epoch: [167][  100/  391]    Overall Loss 0.130673    Objective Loss 0.130673    Top1 95.429688    Top5 99.945312    LR 0.028340    Time 0.020683    
2018-11-02 21:42:07,684 - Epoch: [167][  150/  391]    Overall Loss 0.129884    Objective Loss 0.129884    Top1 95.453125    Top5 99.937500    LR 0.028340    Time 0.020306    
2018-11-02 21:42:08,663 - Epoch: [167][  200/  391]    Overall Loss 0.132172    Objective Loss 0.132172    Top1 95.351562    Top5 99.945312    LR 0.028340    Time 0.020121    
2018-11-02 21:42:09,643 - Epoch: [167][  250/  391]    Overall Loss 0.135886    Objective Loss 0.135886    Top1 95.265625    Top5 99.950000    LR 0.028340    Time 0.019995    
2018-11-02 21:42:10,622 - Epoch: [167][  300/  391]    Overall Loss 0.136278    Objective Loss 0.136278    Top1 95.250000    Top5 99.947917    LR 0.028340    Time 0.019922    
2018-11-02 21:42:11,600 - Epoch: [167][  350/  391]    Overall Loss 0.136743    Objective Loss 0.136743    Top1 95.225446    Top5 99.948661    LR 0.028340    Time 0.019867    
2018-11-02 21:42:12,483 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40550 | -0.00644 |    0.25714 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18084 | -0.00129 |    0.11285 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18082 | -0.00408 |    0.13689 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21678 | -0.05316 |    0.16813 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23174 |  0.00725 |    0.18303 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19237 | -0.03103 |    0.14696 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18858 | -0.00286 |    0.13771 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22718 | -0.00286 |    0.16622 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18772 | -0.00525 |    0.14358 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28171 | -0.01190 |    0.18730 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16535 | -0.00218 |    0.12233 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13837 | -0.01683 |    0.11140 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16674 | -0.01551 |    0.13035 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12211 | -0.00538 |    0.09324 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13442 | -0.01593 |    0.10737 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12672 | -0.00304 |    0.10019 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16013 | -0.01036 |    0.12338 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11944 | -0.01151 |    0.09487 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10154 | -0.00670 |    0.07969 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10260 | -0.01153 |    0.08167 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06336 |  0.00259 |    0.04760 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56427 | -0.00001 |    0.43984 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:42:12,484 - Total sparsity: 0.00

2018-11-02 21:42:12,484 - --- validate (epoch=167)-----------
2018-11-02 21:42:12,484 - 10000 samples (128 per mini-batch)
2018-11-02 21:42:13,198 - Epoch: [167][   50/   78]    Loss 0.372609    Top1 89.234375    Top5 99.656250    
2018-11-02 21:42:13,584 - ==> Top1: 89.380    Top5: 99.680    Loss: 0.364

2018-11-02 21:42:13,585 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:42:13,585 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:42:13,596 - 

2018-11-02 21:42:13,597 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:42:14,692 - Epoch: [168][   50/  391]    Overall Loss 0.130113    Objective Loss 0.130113    Top1 95.562500    Top5 99.937500    LR 0.026923    Time 0.021880    
2018-11-02 21:42:15,733 - Epoch: [168][  100/  391]    Overall Loss 0.132490    Objective Loss 0.132490    Top1 95.406250    Top5 99.937500    LR 0.026923    Time 0.021338    
2018-11-02 21:42:16,773 - Epoch: [168][  150/  391]    Overall Loss 0.130600    Objective Loss 0.130600    Top1 95.390625    Top5 99.953125    LR 0.026923    Time 0.021149    
2018-11-02 21:42:17,810 - Epoch: [168][  200/  391]    Overall Loss 0.131780    Objective Loss 0.131780    Top1 95.371094    Top5 99.960938    LR 0.026923    Time 0.021043    
2018-11-02 21:42:18,842 - Epoch: [168][  250/  391]    Overall Loss 0.132161    Objective Loss 0.132161    Top1 95.315625    Top5 99.962500    LR 0.026923    Time 0.020956    
2018-11-02 21:42:19,882 - Epoch: [168][  300/  391]    Overall Loss 0.132875    Objective Loss 0.132875    Top1 95.278646    Top5 99.950521    LR 0.026923    Time 0.020913    
2018-11-02 21:42:20,873 - Epoch: [168][  350/  391]    Overall Loss 0.133174    Objective Loss 0.133174    Top1 95.316964    Top5 99.948661    LR 0.026923    Time 0.020753    
2018-11-02 21:42:21,756 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40304 | -0.00817 |    0.25538 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17975 | -0.00195 |    0.11212 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17972 | -0.00548 |    0.13601 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21541 | -0.05331 |    0.16743 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23045 |  0.00647 |    0.18216 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19129 | -0.03108 |    0.14608 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18748 | -0.00321 |    0.13663 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22589 | -0.00362 |    0.16516 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18672 | -0.00491 |    0.14256 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27997 | -0.01288 |    0.18674 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16450 | -0.00118 |    0.12153 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13763 | -0.01685 |    0.11089 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16589 | -0.01557 |    0.12999 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12149 | -0.00559 |    0.09277 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13368 | -0.01587 |    0.10674 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12608 | -0.00298 |    0.09976 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15914 | -0.01056 |    0.12263 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11890 | -0.01139 |    0.09448 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10112 | -0.00676 |    0.07944 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10217 | -0.01160 |    0.08133 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06300 |  0.00262 |    0.04736 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56493 | -0.00001 |    0.44012 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:42:21,756 - Total sparsity: 0.00

2018-11-02 21:42:21,756 - --- validate (epoch=168)-----------
2018-11-02 21:42:21,757 - 10000 samples (128 per mini-batch)
2018-11-02 21:42:22,485 - Epoch: [168][   50/   78]    Loss 0.397738    Top1 88.437500    Top5 99.546875    
2018-11-02 21:42:22,877 - ==> Top1: 88.580    Top5: 99.560    Loss: 0.391

2018-11-02 21:42:22,878 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:42:22,878 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:42:22,889 - 

2018-11-02 21:42:22,890 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:42:23,928 - Epoch: [169][   50/  391]    Overall Loss 0.126691    Objective Loss 0.126691    Top1 95.703125    Top5 99.953125    LR 0.025577    Time 0.020730    
2018-11-02 21:42:24,905 - Epoch: [169][  100/  391]    Overall Loss 0.126323    Objective Loss 0.126323    Top1 95.507812    Top5 99.960938    LR 0.025577    Time 0.020117    
2018-11-02 21:42:25,883 - Epoch: [169][  150/  391]    Overall Loss 0.128625    Objective Loss 0.128625    Top1 95.375000    Top5 99.968750    LR 0.025577    Time 0.019929    
2018-11-02 21:42:26,862 - Epoch: [169][  200/  391]    Overall Loss 0.129547    Objective Loss 0.129547    Top1 95.410156    Top5 99.960938    LR 0.025577    Time 0.019833    
2018-11-02 21:42:27,841 - Epoch: [169][  250/  391]    Overall Loss 0.128951    Objective Loss 0.128951    Top1 95.450000    Top5 99.959375    LR 0.025577    Time 0.019776    
2018-11-02 21:42:28,821 - Epoch: [169][  300/  391]    Overall Loss 0.127948    Objective Loss 0.127948    Top1 95.486979    Top5 99.953125    LR 0.025577    Time 0.019743    
2018-11-02 21:42:29,799 - Epoch: [169][  350/  391]    Overall Loss 0.128741    Objective Loss 0.128741    Top1 95.444196    Top5 99.953125    LR 0.025577    Time 0.019714    
2018-11-02 21:42:30,681 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40087 | -0.00521 |    0.25353 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17879 | -0.00133 |    0.11148 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17877 | -0.00406 |    0.13525 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21477 | -0.05108 |    0.16649 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22922 |  0.00796 |    0.18122 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19046 | -0.03076 |    0.14555 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18652 | -0.00169 |    0.13554 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22475 | -0.00273 |    0.16485 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18579 | -0.00520 |    0.14210 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27840 | -0.01292 |    0.18562 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16367 | -0.00116 |    0.12057 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13696 | -0.01665 |    0.11044 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16506 | -0.01571 |    0.12934 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12093 | -0.00466 |    0.09239 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13300 | -0.01576 |    0.10615 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12549 | -0.00265 |    0.09932 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15824 | -0.01014 |    0.12190 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11836 | -0.01149 |    0.09406 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10073 | -0.00655 |    0.07911 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10176 | -0.01165 |    0.08105 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06265 |  0.00253 |    0.04711 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56571 | -0.00001 |    0.44083 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:42:30,681 - Total sparsity: 0.00

2018-11-02 21:42:30,682 - --- validate (epoch=169)-----------
2018-11-02 21:42:30,682 - 10000 samples (128 per mini-batch)
2018-11-02 21:42:31,407 - Epoch: [169][   50/   78]    Loss 0.394173    Top1 88.890625    Top5 99.609375    
2018-11-02 21:42:31,801 - ==> Top1: 89.200    Top5: 99.690    Loss: 0.383

2018-11-02 21:42:31,802 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:42:31,802 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:42:31,813 - 

2018-11-02 21:42:31,813 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:42:32,853 - Epoch: [170][   50/  391]    Overall Loss 0.120470    Objective Loss 0.120470    Top1 95.906250    Top5 99.984375    LR 0.024298    Time 0.020746    
2018-11-02 21:42:33,829 - Epoch: [170][  100/  391]    Overall Loss 0.120714    Objective Loss 0.120714    Top1 95.804688    Top5 99.968750    LR 0.024298    Time 0.020120    
2018-11-02 21:42:34,807 - Epoch: [170][  150/  391]    Overall Loss 0.119382    Objective Loss 0.119382    Top1 95.895833    Top5 99.958333    LR 0.024298    Time 0.019922    
2018-11-02 21:42:35,785 - Epoch: [170][  200/  391]    Overall Loss 0.122823    Objective Loss 0.122823    Top1 95.722656    Top5 99.960938    LR 0.024298    Time 0.019829    
2018-11-02 21:42:36,762 - Epoch: [170][  250/  391]    Overall Loss 0.124595    Objective Loss 0.124595    Top1 95.668750    Top5 99.956250    LR 0.024298    Time 0.019762    
2018-11-02 21:42:37,740 - Epoch: [170][  300/  391]    Overall Loss 0.125885    Objective Loss 0.125885    Top1 95.643229    Top5 99.958333    LR 0.024298    Time 0.019725    
2018-11-02 21:42:38,742 - Epoch: [170][  350/  391]    Overall Loss 0.126544    Objective Loss 0.126544    Top1 95.622768    Top5 99.957589    LR 0.024298    Time 0.019766    
2018-11-02 21:42:39,677 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39872 | -0.00682 |    0.25234 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17786 | -0.00100 |    0.11093 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17778 | -0.00508 |    0.13482 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21369 | -0.05092 |    0.16568 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22808 |  0.00662 |    0.17983 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18954 | -0.03107 |    0.14456 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18554 | -0.00284 |    0.13510 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22363 | -0.00250 |    0.16402 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18486 | -0.00556 |    0.14122 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27679 | -0.01341 |    0.18435 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16284 | -0.00029 |    0.12006 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13621 | -0.01715 |    0.10988 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16428 | -0.01536 |    0.12873 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12029 | -0.00562 |    0.09184 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13230 | -0.01592 |    0.10555 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12489 | -0.00277 |    0.09888 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15732 | -0.01034 |    0.12111 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11784 | -0.01143 |    0.09365 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10032 | -0.00670 |    0.07878 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10135 | -0.01174 |    0.08073 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06232 |  0.00249 |    0.04687 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56637 | -0.00001 |    0.44151 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:42:39,677 - Total sparsity: 0.00

2018-11-02 21:42:39,677 - --- validate (epoch=170)-----------
2018-11-02 21:42:39,677 - 10000 samples (128 per mini-batch)
2018-11-02 21:42:40,397 - Epoch: [170][   50/   78]    Loss 0.371752    Top1 89.593750    Top5 99.687500    
2018-11-02 21:42:40,791 - ==> Top1: 89.440    Top5: 99.720    Loss: 0.375

2018-11-02 21:42:40,791 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:42:40,792 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:42:40,800 - 

2018-11-02 21:42:40,800 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:42:41,907 - Epoch: [171][   50/  391]    Overall Loss 0.115831    Objective Loss 0.115831    Top1 95.875000    Top5 99.906250    LR 0.023083    Time 0.022108    
2018-11-02 21:42:42,955 - Epoch: [171][  100/  391]    Overall Loss 0.112701    Objective Loss 0.112701    Top1 95.945312    Top5 99.937500    LR 0.023083    Time 0.021523    
2018-11-02 21:42:44,005 - Epoch: [171][  150/  391]    Overall Loss 0.114231    Objective Loss 0.114231    Top1 95.911458    Top5 99.953125    LR 0.023083    Time 0.021339    
2018-11-02 21:42:44,994 - Epoch: [171][  200/  391]    Overall Loss 0.114922    Objective Loss 0.114922    Top1 95.917969    Top5 99.960938    LR 0.023083    Time 0.020944    
2018-11-02 21:42:45,971 - Epoch: [171][  250/  391]    Overall Loss 0.116311    Objective Loss 0.116311    Top1 95.831250    Top5 99.965625    LR 0.023083    Time 0.020660    
2018-11-02 21:42:46,952 - Epoch: [171][  300/  391]    Overall Loss 0.117055    Objective Loss 0.117055    Top1 95.794271    Top5 99.968750    LR 0.023083    Time 0.020470    
2018-11-02 21:42:47,932 - Epoch: [171][  350/  391]    Overall Loss 0.117479    Objective Loss 0.117479    Top1 95.794643    Top5 99.970982    LR 0.023083    Time 0.020342    
2018-11-02 21:42:48,812 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39663 | -0.00743 |    0.25084 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17692 | -0.00115 |    0.11052 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17685 | -0.00498 |    0.13382 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21254 | -0.05098 |    0.16497 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22697 |  0.00761 |    0.17874 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18890 | -0.03004 |    0.14413 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18466 | -0.00311 |    0.13441 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22253 | -0.00307 |    0.16309 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18396 | -0.00517 |    0.14077 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27529 | -0.01221 |    0.18382 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16202 | -0.00084 |    0.11937 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13560 | -0.01641 |    0.10939 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16351 | -0.01515 |    0.12817 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11973 | -0.00530 |    0.09125 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13161 | -0.01600 |    0.10503 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12430 | -0.00285 |    0.09843 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15644 | -0.01029 |    0.12059 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11733 | -0.01118 |    0.09325 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09990 | -0.00683 |    0.07848 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10096 | -0.01166 |    0.08040 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06198 |  0.00264 |    0.04664 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56720 | -0.00001 |    0.44193 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:42:48,812 - Total sparsity: 0.00

2018-11-02 21:42:48,812 - --- validate (epoch=171)-----------
2018-11-02 21:42:48,812 - 10000 samples (128 per mini-batch)
2018-11-02 21:42:49,537 - Epoch: [171][   50/   78]    Loss 0.377769    Top1 89.437500    Top5 99.562500    
2018-11-02 21:42:49,931 - ==> Top1: 89.420    Top5: 99.610    Loss: 0.376

2018-11-02 21:42:49,932 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:42:49,932 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:42:49,943 - 

2018-11-02 21:42:49,944 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:42:50,982 - Epoch: [172][   50/  391]    Overall Loss 0.115932    Objective Loss 0.115932    Top1 96.109375    Top5 99.953125    LR 0.021929    Time 0.020737    
2018-11-02 21:42:51,957 - Epoch: [172][  100/  391]    Overall Loss 0.114663    Objective Loss 0.114663    Top1 96.054688    Top5 99.953125    LR 0.021929    Time 0.020107    
2018-11-02 21:42:52,939 - Epoch: [172][  150/  391]    Overall Loss 0.111780    Objective Loss 0.111780    Top1 96.119792    Top5 99.968750    LR 0.021929    Time 0.019938    
2018-11-02 21:42:53,920 - Epoch: [172][  200/  391]    Overall Loss 0.114867    Objective Loss 0.114867    Top1 96.015625    Top5 99.964844    LR 0.021929    Time 0.019856    
2018-11-02 21:42:54,904 - Epoch: [172][  250/  391]    Overall Loss 0.117765    Objective Loss 0.117765    Top1 95.928125    Top5 99.962500    LR 0.021929    Time 0.019813    
2018-11-02 21:42:55,883 - Epoch: [172][  300/  391]    Overall Loss 0.118402    Objective Loss 0.118402    Top1 95.911458    Top5 99.960938    LR 0.021929    Time 0.019770    
2018-11-02 21:42:56,860 - Epoch: [172][  350/  391]    Overall Loss 0.118307    Objective Loss 0.118307    Top1 95.886161    Top5 99.962054    LR 0.021929    Time 0.019734    
2018-11-02 21:42:57,745 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39477 | -0.00432 |    0.24943 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17603 | -0.00039 |    0.11020 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17595 | -0.00520 |    0.13341 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21193 | -0.04886 |    0.16451 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22590 |  0.00703 |    0.17791 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18812 | -0.02943 |    0.14360 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18377 | -0.00379 |    0.13394 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22148 | -0.00340 |    0.16238 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18310 | -0.00562 |    0.14013 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27385 | -0.01161 |    0.18320 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16127 | -0.00051 |    0.11898 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13497 | -0.01628 |    0.10891 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16271 | -0.01598 |    0.12768 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11920 | -0.00488 |    0.09096 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13102 | -0.01562 |    0.10458 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12376 | -0.00277 |    0.09804 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15560 | -0.01007 |    0.11991 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11685 | -0.01111 |    0.09282 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09952 | -0.00688 |    0.07824 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10055 | -0.01185 |    0.08011 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06167 |  0.00249 |    0.04644 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56750 | -0.00001 |    0.44257 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:42:57,745 - Total sparsity: 0.00

2018-11-02 21:42:57,745 - --- validate (epoch=172)-----------
2018-11-02 21:42:57,746 - 10000 samples (128 per mini-batch)
2018-11-02 21:42:58,469 - Epoch: [172][   50/   78]    Loss 0.401711    Top1 89.359375    Top5 99.609375    
2018-11-02 21:42:58,862 - ==> Top1: 89.330    Top5: 99.680    Loss: 0.388

2018-11-02 21:42:58,863 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:42:58,863 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:42:58,871 - 

2018-11-02 21:42:58,872 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:42:59,910 - Epoch: [173][   50/  391]    Overall Loss 0.111566    Objective Loss 0.111566    Top1 96.218750    Top5 99.968750    LR 0.020833    Time 0.020733    
2018-11-02 21:43:00,892 - Epoch: [173][  100/  391]    Overall Loss 0.114564    Objective Loss 0.114564    Top1 96.085938    Top5 99.968750    LR 0.020833    Time 0.020172    
2018-11-02 21:43:01,871 - Epoch: [173][  150/  391]    Overall Loss 0.117649    Objective Loss 0.117649    Top1 95.890625    Top5 99.953125    LR 0.020833    Time 0.019966    
2018-11-02 21:43:02,847 - Epoch: [173][  200/  391]    Overall Loss 0.119227    Objective Loss 0.119227    Top1 95.777344    Top5 99.964844    LR 0.020833    Time 0.019852    
2018-11-02 21:43:03,825 - Epoch: [173][  250/  391]    Overall Loss 0.119452    Objective Loss 0.119452    Top1 95.753125    Top5 99.965625    LR 0.020833    Time 0.019788    
2018-11-02 21:43:04,810 - Epoch: [173][  300/  391]    Overall Loss 0.119489    Objective Loss 0.119489    Top1 95.742188    Top5 99.963542    LR 0.020833    Time 0.019770    
2018-11-02 21:43:05,787 - Epoch: [173][  350/  391]    Overall Loss 0.119651    Objective Loss 0.119651    Top1 95.743304    Top5 99.957589    LR 0.020833    Time 0.019733    
2018-11-02 21:43:06,670 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39277 | -0.00833 |    0.24834 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17519 | -0.00027 |    0.10964 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17507 | -0.00591 |    0.13263 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21073 | -0.04980 |    0.16343 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22484 |  0.00722 |    0.17723 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18728 | -0.02951 |    0.14296 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18288 | -0.00442 |    0.13326 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22044 | -0.00364 |    0.16179 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18227 | -0.00524 |    0.13949 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27243 | -0.01161 |    0.18144 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16053 | -0.00062 |    0.11861 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13437 | -0.01615 |    0.10853 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16201 | -0.01596 |    0.12705 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11869 | -0.00465 |    0.09087 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13044 | -0.01537 |    0.10418 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12323 | -0.00290 |    0.09759 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15481 | -0.00996 |    0.11934 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11638 | -0.01108 |    0.09244 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09917 | -0.00681 |    0.07801 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10019 | -0.01183 |    0.07983 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06137 |  0.00252 |    0.04625 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56771 | -0.00001 |    0.44261 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:43:06,670 - Total sparsity: 0.00

2018-11-02 21:43:06,671 - --- validate (epoch=173)-----------
2018-11-02 21:43:06,671 - 10000 samples (128 per mini-batch)
2018-11-02 21:43:07,396 - Epoch: [173][   50/   78]    Loss 0.388011    Top1 89.546875    Top5 99.593750    
2018-11-02 21:43:07,787 - ==> Top1: 89.380    Top5: 99.640    Loss: 0.388

2018-11-02 21:43:07,788 - ==> Best Top1: 89.620   On Epoch: 164

2018-11-02 21:43:07,789 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:43:07,799 - 

2018-11-02 21:43:07,800 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:43:08,837 - Epoch: [174][   50/  391]    Overall Loss 0.107862    Objective Loss 0.107862    Top1 96.250000    Top5 99.984375    LR 0.019791    Time 0.020708    
2018-11-02 21:43:09,816 - Epoch: [174][  100/  391]    Overall Loss 0.110825    Objective Loss 0.110825    Top1 96.140625    Top5 99.960938    LR 0.019791    Time 0.020128    
2018-11-02 21:43:10,795 - Epoch: [174][  150/  391]    Overall Loss 0.110160    Objective Loss 0.110160    Top1 96.135417    Top5 99.973958    LR 0.019791    Time 0.019934    
2018-11-02 21:43:11,771 - Epoch: [174][  200/  391]    Overall Loss 0.109349    Objective Loss 0.109349    Top1 96.167969    Top5 99.972656    LR 0.019791    Time 0.019823    
2018-11-02 21:43:12,749 - Epoch: [174][  250/  391]    Overall Loss 0.110215    Objective Loss 0.110215    Top1 96.134375    Top5 99.971875    LR 0.019791    Time 0.019769    
2018-11-02 21:43:13,732 - Epoch: [174][  300/  391]    Overall Loss 0.110839    Objective Loss 0.110839    Top1 96.125000    Top5 99.971354    LR 0.019791    Time 0.019735    
2018-11-02 21:43:14,711 - Epoch: [174][  350/  391]    Overall Loss 0.111248    Objective Loss 0.111248    Top1 96.104911    Top5 99.962054    LR 0.019791    Time 0.019709    
2018-11-02 21:43:15,597 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39088 | -0.00785 |    0.24639 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17437 | -0.00032 |    0.10927 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17424 | -0.00591 |    0.13204 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20995 | -0.04890 |    0.16261 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22377 |  0.00764 |    0.17654 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18648 | -0.02934 |    0.14233 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18208 | -0.00356 |    0.13275 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21943 | -0.00318 |    0.16085 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18143 | -0.00531 |    0.13896 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27106 | -0.01070 |    0.17992 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15979 | -0.00046 |    0.11795 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13377 | -0.01601 |    0.10806 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16129 | -0.01588 |    0.12659 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11814 | -0.00512 |    0.09082 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12983 | -0.01534 |    0.10359 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12270 | -0.00278 |    0.09707 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15401 | -0.00991 |    0.11876 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11590 | -0.01099 |    0.09208 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09881 | -0.00662 |    0.07775 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09980 | -0.01182 |    0.07954 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06107 |  0.00248 |    0.04604 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56833 | -0.00001 |    0.44329 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:43:15,597 - Total sparsity: 0.00

2018-11-02 21:43:15,597 - --- validate (epoch=174)-----------
2018-11-02 21:43:15,597 - 10000 samples (128 per mini-batch)
2018-11-02 21:43:16,317 - Epoch: [174][   50/   78]    Loss 0.365957    Top1 89.984375    Top5 99.734375    
2018-11-02 21:43:16,705 - ==> Top1: 89.930    Top5: 99.760    Loss: 0.364

2018-11-02 21:43:16,706 - ==> Best Top1: 89.930   On Epoch: 174

2018-11-02 21:43:16,706 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:43:16,722 - 

2018-11-02 21:43:16,723 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:43:17,732 - Epoch: [175][   50/  391]    Overall Loss 0.102632    Objective Loss 0.102632    Top1 96.281250    Top5 99.968750    LR 0.018802    Time 0.020162    
2018-11-02 21:43:18,712 - Epoch: [175][  100/  391]    Overall Loss 0.106247    Objective Loss 0.106247    Top1 96.171875    Top5 99.976562    LR 0.018802    Time 0.019864    
2018-11-02 21:43:19,688 - Epoch: [175][  150/  391]    Overall Loss 0.106297    Objective Loss 0.106297    Top1 96.218750    Top5 99.973958    LR 0.018802    Time 0.019740    
2018-11-02 21:43:20,666 - Epoch: [175][  200/  391]    Overall Loss 0.105441    Objective Loss 0.105441    Top1 96.257812    Top5 99.960938    LR 0.018802    Time 0.019687    
2018-11-02 21:43:21,645 - Epoch: [175][  250/  391]    Overall Loss 0.104624    Objective Loss 0.104624    Top1 96.293750    Top5 99.968750    LR 0.018802    Time 0.019661    
2018-11-02 21:43:22,623 - Epoch: [175][  300/  391]    Overall Loss 0.105200    Objective Loss 0.105200    Top1 96.276042    Top5 99.973958    LR 0.018802    Time 0.019640    
2018-11-02 21:43:23,601 - Epoch: [175][  350/  391]    Overall Loss 0.106343    Objective Loss 0.106343    Top1 96.191964    Top5 99.977679    LR 0.018802    Time 0.019623    
2018-11-02 21:43:24,484 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38919 | -0.00387 |    0.24599 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17355 | -0.00045 |    0.10859 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17343 | -0.00573 |    0.13149 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20879 | -0.04941 |    0.16217 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22276 |  0.00719 |    0.17566 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18564 | -0.02942 |    0.14179 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18122 | -0.00356 |    0.13205 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21841 | -0.00433 |    0.16001 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18064 | -0.00501 |    0.13852 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26971 | -0.01074 |    0.17854 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15909 | -0.00077 |    0.11764 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13324 | -0.01542 |    0.10746 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16058 | -0.01588 |    0.12592 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11762 | -0.00526 |    0.09035 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12923 | -0.01542 |    0.10323 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12218 | -0.00275 |    0.09662 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15324 | -0.00984 |    0.11829 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11544 | -0.01082 |    0.09175 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09844 | -0.00666 |    0.07748 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09945 | -0.01158 |    0.07926 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06079 |  0.00245 |    0.04587 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56926 | -0.00001 |    0.44392 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:43:24,484 - Total sparsity: 0.00

2018-11-02 21:43:24,484 - --- validate (epoch=175)-----------
2018-11-02 21:43:24,484 - 10000 samples (128 per mini-batch)
2018-11-02 21:43:25,197 - Epoch: [175][   50/   78]    Loss 0.386157    Top1 89.562500    Top5 99.687500    
2018-11-02 21:43:25,588 - ==> Top1: 89.710    Top5: 99.690    Loss: 0.380

2018-11-02 21:43:25,588 - ==> Best Top1: 89.930   On Epoch: 174

2018-11-02 21:43:25,588 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:43:25,596 - 

2018-11-02 21:43:25,596 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:43:26,634 - Epoch: [176][   50/  391]    Overall Loss 0.101561    Objective Loss 0.101561    Top1 96.500000    Top5 99.984375    LR 0.017862    Time 0.020718    
2018-11-02 21:43:27,614 - Epoch: [176][  100/  391]    Overall Loss 0.103253    Objective Loss 0.103253    Top1 96.351562    Top5 99.976562    LR 0.017862    Time 0.020140    
2018-11-02 21:43:28,592 - Epoch: [176][  150/  391]    Overall Loss 0.103749    Objective Loss 0.103749    Top1 96.322917    Top5 99.979167    LR 0.017862    Time 0.019937    
2018-11-02 21:43:29,572 - Epoch: [176][  200/  391]    Overall Loss 0.105266    Objective Loss 0.105266    Top1 96.285156    Top5 99.960938    LR 0.017862    Time 0.019846    
2018-11-02 21:43:30,550 - Epoch: [176][  250/  391]    Overall Loss 0.106210    Objective Loss 0.106210    Top1 96.256250    Top5 99.965625    LR 0.017862    Time 0.019783    
2018-11-02 21:43:31,530 - Epoch: [176][  300/  391]    Overall Loss 0.106280    Objective Loss 0.106280    Top1 96.231771    Top5 99.971354    LR 0.017862    Time 0.019749    
2018-11-02 21:43:32,510 - Epoch: [176][  350/  391]    Overall Loss 0.108944    Objective Loss 0.108944    Top1 96.169643    Top5 99.973214    LR 0.017862    Time 0.019724    
2018-11-02 21:43:33,393 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38753 | -0.00506 |    0.24497 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17279 | -0.00085 |    0.10835 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17271 | -0.00525 |    0.13098 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20804 | -0.04871 |    0.16154 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22181 |  0.00733 |    0.17508 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18464 | -0.03073 |    0.14134 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18048 | -0.00325 |    0.13137 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21753 | -0.00341 |    0.15940 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17990 | -0.00479 |    0.13793 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26849 | -0.00995 |    0.17762 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15846 | -0.00095 |    0.11724 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13271 | -0.01513 |    0.10700 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15992 | -0.01566 |    0.12536 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11713 | -0.00525 |    0.08987 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12869 | -0.01534 |    0.10281 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12170 | -0.00268 |    0.09624 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15253 | -0.00977 |    0.11758 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11502 | -0.01065 |    0.09140 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09811 | -0.00657 |    0.07725 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09911 | -0.01155 |    0.07901 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06051 |  0.00250 |    0.04570 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56951 | -0.00001 |    0.44406 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:43:33,393 - Total sparsity: 0.00

2018-11-02 21:43:33,393 - --- validate (epoch=176)-----------
2018-11-02 21:43:33,393 - 10000 samples (128 per mini-batch)
2018-11-02 21:43:34,117 - Epoch: [176][   50/   78]    Loss 0.386550    Top1 89.343750    Top5 99.609375    
2018-11-02 21:43:34,511 - ==> Top1: 89.350    Top5: 99.690    Loss: 0.386

2018-11-02 21:43:34,512 - ==> Best Top1: 89.930   On Epoch: 174

2018-11-02 21:43:34,512 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:43:34,520 - 

2018-11-02 21:43:34,520 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:43:35,614 - Epoch: [177][   50/  391]    Overall Loss 0.102186    Objective Loss 0.102186    Top1 96.328125    Top5 99.984375    LR 0.016968    Time 0.021843    
2018-11-02 21:43:36,591 - Epoch: [177][  100/  391]    Overall Loss 0.098408    Objective Loss 0.098408    Top1 96.554688    Top5 99.984375    LR 0.016968    Time 0.020672    
2018-11-02 21:43:37,570 - Epoch: [177][  150/  391]    Overall Loss 0.101301    Objective Loss 0.101301    Top1 96.500000    Top5 99.979167    LR 0.016968    Time 0.020301    
2018-11-02 21:43:38,553 - Epoch: [177][  200/  391]    Overall Loss 0.102216    Objective Loss 0.102216    Top1 96.429688    Top5 99.968750    LR 0.016968    Time 0.020136    
2018-11-02 21:43:39,539 - Epoch: [177][  250/  391]    Overall Loss 0.102744    Objective Loss 0.102744    Top1 96.412500    Top5 99.971875    LR 0.016968    Time 0.020047    
2018-11-02 21:43:40,526 - Epoch: [177][  300/  391]    Overall Loss 0.102927    Objective Loss 0.102927    Top1 96.414062    Top5 99.973958    LR 0.016968    Time 0.019993    
2018-11-02 21:43:41,517 - Epoch: [177][  350/  391]    Overall Loss 0.104226    Objective Loss 0.104226    Top1 96.352679    Top5 99.977679    LR 0.016968    Time 0.019966    
2018-11-02 21:43:42,449 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38588 | -0.00491 |    0.24360 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17207 | -0.00112 |    0.10785 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17200 | -0.00465 |    0.13033 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20697 | -0.04946 |    0.16071 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22090 |  0.00668 |    0.17486 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18402 | -0.02974 |    0.14049 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17973 | -0.00342 |    0.13100 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21665 | -0.00324 |    0.15858 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17915 | -0.00513 |    0.13729 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26724 | -0.01053 |    0.17696 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15781 | -0.00066 |    0.11690 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13211 | -0.01557 |    0.10666 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15934 | -0.01510 |    0.12465 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11664 | -0.00554 |    0.08964 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12819 | -0.01497 |    0.10240 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12123 | -0.00267 |    0.09588 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15185 | -0.00945 |    0.11709 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11458 | -0.01066 |    0.09104 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09778 | -0.00647 |    0.07698 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09877 | -0.01152 |    0.07879 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06024 |  0.00269 |    0.04549 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56971 | -0.00001 |    0.44429 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:43:42,449 - Total sparsity: 0.00

2018-11-02 21:43:42,449 - --- validate (epoch=177)-----------
2018-11-02 21:43:42,449 - 10000 samples (128 per mini-batch)
2018-11-02 21:43:43,175 - Epoch: [177][   50/   78]    Loss 0.375611    Top1 89.750000    Top5 99.593750    
2018-11-02 21:43:43,568 - ==> Top1: 89.890    Top5: 99.610    Loss: 0.369

2018-11-02 21:43:43,568 - ==> Best Top1: 89.930   On Epoch: 174

2018-11-02 21:43:43,569 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:43:43,580 - 

2018-11-02 21:43:43,580 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:43:44,618 - Epoch: [178][   50/  391]    Overall Loss 0.093503    Objective Loss 0.093503    Top1 96.609375    Top5 100.000000    LR 0.016120    Time 0.020720    
2018-11-02 21:43:45,598 - Epoch: [178][  100/  391]    Overall Loss 0.095063    Objective Loss 0.095063    Top1 96.632812    Top5 99.992188    LR 0.016120    Time 0.020143    
2018-11-02 21:43:46,577 - Epoch: [178][  150/  391]    Overall Loss 0.096765    Objective Loss 0.096765    Top1 96.635417    Top5 99.979167    LR 0.016120    Time 0.019947    
2018-11-02 21:43:47,557 - Epoch: [178][  200/  391]    Overall Loss 0.097302    Objective Loss 0.097302    Top1 96.578125    Top5 99.984375    LR 0.016120    Time 0.019856    
2018-11-02 21:43:48,534 - Epoch: [178][  250/  391]    Overall Loss 0.096791    Objective Loss 0.096791    Top1 96.628125    Top5 99.981250    LR 0.016120    Time 0.019786    
2018-11-02 21:43:49,514 - Epoch: [178][  300/  391]    Overall Loss 0.096590    Objective Loss 0.096590    Top1 96.640625    Top5 99.981771    LR 0.016120    Time 0.019749    
2018-11-02 21:43:50,600 - Epoch: [178][  350/  391]    Overall Loss 0.098336    Objective Loss 0.098336    Top1 96.578125    Top5 99.982143    LR 0.016120    Time 0.020027    
2018-11-02 21:43:51,482 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38419 | -0.00521 |    0.24268 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17136 | -0.00024 |    0.10747 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17128 | -0.00490 |    0.12949 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20613 | -0.04924 |    0.16034 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21999 |  0.00721 |    0.17387 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18324 | -0.02982 |    0.14006 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17900 | -0.00339 |    0.13031 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21575 | -0.00317 |    0.15792 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17841 | -0.00503 |    0.13671 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26604 | -0.01071 |    0.17621 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15717 | -0.00037 |    0.11643 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13161 | -0.01513 |    0.10618 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15867 | -0.01531 |    0.12430 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11618 | -0.00540 |    0.08912 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12767 | -0.01478 |    0.10198 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12075 | -0.00254 |    0.09546 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15117 | -0.00929 |    0.11646 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11414 | -0.01071 |    0.09070 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09744 | -0.00641 |    0.07669 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09841 | -0.01163 |    0.07847 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05998 |  0.00268 |    0.04530 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57074 | -0.00001 |    0.44510 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:43:51,482 - Total sparsity: 0.00

2018-11-02 21:43:51,482 - --- validate (epoch=178)-----------
2018-11-02 21:43:51,482 - 10000 samples (128 per mini-batch)
2018-11-02 21:43:52,208 - Epoch: [178][   50/   78]    Loss 0.385769    Top1 89.578125    Top5 99.500000    
2018-11-02 21:43:52,600 - ==> Top1: 89.690    Top5: 99.620    Loss: 0.377

2018-11-02 21:43:52,601 - ==> Best Top1: 89.930   On Epoch: 174

2018-11-02 21:43:52,601 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:43:52,608 - 

2018-11-02 21:43:52,609 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:43:53,649 - Epoch: [179][   50/  391]    Overall Loss 0.099197    Objective Loss 0.099197    Top1 96.609375    Top5 99.968750    LR 0.015314    Time 0.020762    
2018-11-02 21:43:54,623 - Epoch: [179][  100/  391]    Overall Loss 0.097490    Objective Loss 0.097490    Top1 96.648438    Top5 99.984375    LR 0.015314    Time 0.020106    
2018-11-02 21:43:55,601 - Epoch: [179][  150/  391]    Overall Loss 0.096100    Objective Loss 0.096100    Top1 96.614583    Top5 99.984375    LR 0.015314    Time 0.019918    
2018-11-02 21:43:56,584 - Epoch: [179][  200/  391]    Overall Loss 0.097540    Objective Loss 0.097540    Top1 96.574219    Top5 99.984375    LR 0.015314    Time 0.019847    
2018-11-02 21:43:57,564 - Epoch: [179][  250/  391]    Overall Loss 0.096378    Objective Loss 0.096378    Top1 96.609375    Top5 99.978125    LR 0.015314    Time 0.019790    
2018-11-02 21:43:58,540 - Epoch: [179][  300/  391]    Overall Loss 0.096688    Objective Loss 0.096688    Top1 96.567708    Top5 99.973958    LR 0.015314    Time 0.019743    
2018-11-02 21:43:59,520 - Epoch: [179][  350/  391]    Overall Loss 0.097136    Objective Loss 0.097136    Top1 96.569196    Top5 99.973214    LR 0.015314    Time 0.019718    
2018-11-02 21:44:00,406 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38262 | -0.00540 |    0.24180 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17068 | -0.00149 |    0.10730 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17061 | -0.00458 |    0.12898 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20519 | -0.04960 |    0.15960 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21910 |  0.00768 |    0.17354 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18260 | -0.02936 |    0.13958 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17832 | -0.00299 |    0.13004 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21491 | -0.00247 |    0.15717 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17770 | -0.00514 |    0.13612 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26490 | -0.01093 |    0.17537 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15654 | -0.00073 |    0.11589 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13109 | -0.01514 |    0.10562 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15805 | -0.01547 |    0.12390 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11573 | -0.00540 |    0.08881 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12717 | -0.01471 |    0.10154 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12030 | -0.00259 |    0.09514 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15053 | -0.00924 |    0.11588 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11373 | -0.01069 |    0.09036 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09712 | -0.00630 |    0.07646 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09808 | -0.01167 |    0.07825 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05973 |  0.00268 |    0.04512 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57133 | -0.00001 |    0.44564 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:44:00,406 - Total sparsity: 0.00

2018-11-02 21:44:00,406 - --- validate (epoch=179)-----------
2018-11-02 21:44:00,406 - 10000 samples (128 per mini-batch)
2018-11-02 21:44:01,148 - Epoch: [179][   50/   78]    Loss 0.369176    Top1 90.046875    Top5 99.640625    
2018-11-02 21:44:01,582 - ==> Top1: 90.120    Top5: 99.710    Loss: 0.367

2018-11-02 21:44:01,582 - ==> Best Top1: 90.120   On Epoch: 179

2018-11-02 21:44:01,583 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:44:01,595 - 

2018-11-02 21:44:01,595 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:44:02,635 - Epoch: [180][   50/  391]    Overall Loss 0.091698    Objective Loss 0.091698    Top1 96.703125    Top5 100.000000    LR 0.014548    Time 0.020760    
2018-11-02 21:44:03,631 - Epoch: [180][  100/  391]    Overall Loss 0.090912    Objective Loss 0.090912    Top1 96.718750    Top5 99.992188    LR 0.014548    Time 0.020323    
2018-11-02 21:44:04,608 - Epoch: [180][  150/  391]    Overall Loss 0.094951    Objective Loss 0.094951    Top1 96.588542    Top5 99.973958    LR 0.014548    Time 0.020055    
2018-11-02 21:44:05,590 - Epoch: [180][  200/  391]    Overall Loss 0.095031    Objective Loss 0.095031    Top1 96.660156    Top5 99.980469    LR 0.014548    Time 0.019948    
2018-11-02 21:44:06,567 - Epoch: [180][  250/  391]    Overall Loss 0.094197    Objective Loss 0.094197    Top1 96.653125    Top5 99.981250    LR 0.014548    Time 0.019859    
2018-11-02 21:44:07,546 - Epoch: [180][  300/  391]    Overall Loss 0.094830    Objective Loss 0.094830    Top1 96.632812    Top5 99.981771    LR 0.014548    Time 0.019798    
2018-11-02 21:44:08,526 - Epoch: [180][  350/  391]    Overall Loss 0.094991    Objective Loss 0.094991    Top1 96.611607    Top5 99.984375    LR 0.014548    Time 0.019765    
2018-11-02 21:44:09,409 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38119 | -0.00700 |    0.24069 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17004 | -0.00128 |    0.10700 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16994 | -0.00476 |    0.12840 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20426 | -0.05000 |    0.15913 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21830 |  0.00630 |    0.17268 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18196 | -0.02898 |    0.13883 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17765 | -0.00331 |    0.12972 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21410 | -0.00290 |    0.15653 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17705 | -0.00463 |    0.13555 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26382 | -0.01068 |    0.17437 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15595 | -0.00063 |    0.11539 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13061 | -0.01498 |    0.10523 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15744 | -0.01583 |    0.12343 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11531 | -0.00532 |    0.08842 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12668 | -0.01469 |    0.10111 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11987 | -0.00267 |    0.09484 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14993 | -0.00905 |    0.11543 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11334 | -0.01058 |    0.09005 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09681 | -0.00628 |    0.07620 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09778 | -0.01144 |    0.07800 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05948 |  0.00269 |    0.04496 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57186 | -0.00001 |    0.44603 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:44:09,409 - Total sparsity: 0.00

2018-11-02 21:44:09,409 - --- validate (epoch=180)-----------
2018-11-02 21:44:09,410 - 10000 samples (128 per mini-batch)
2018-11-02 21:44:10,135 - Epoch: [180][   50/   78]    Loss 0.384355    Top1 89.937500    Top5 99.671875    
2018-11-02 21:44:10,530 - ==> Top1: 90.180    Top5: 99.690    Loss: 0.380

2018-11-02 21:44:10,531 - ==> Best Top1: 90.180   On Epoch: 180

2018-11-02 21:44:10,531 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:44:10,541 - 

2018-11-02 21:44:10,541 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:44:11,580 - Epoch: [181][   50/  391]    Overall Loss 0.089392    Objective Loss 0.089392    Top1 96.921875    Top5 99.984375    LR 0.013821    Time 0.020736    
2018-11-02 21:44:12,557 - Epoch: [181][  100/  391]    Overall Loss 0.085052    Objective Loss 0.085052    Top1 97.070312    Top5 99.984375    LR 0.013821    Time 0.020123    
2018-11-02 21:44:13,536 - Epoch: [181][  150/  391]    Overall Loss 0.087145    Objective Loss 0.087145    Top1 96.890625    Top5 99.989583    LR 0.013821    Time 0.019934    
2018-11-02 21:44:14,515 - Epoch: [181][  200/  391]    Overall Loss 0.087363    Objective Loss 0.087363    Top1 96.875000    Top5 99.984375    LR 0.013821    Time 0.019840    
2018-11-02 21:44:15,492 - Epoch: [181][  250/  391]    Overall Loss 0.087963    Objective Loss 0.087963    Top1 96.900000    Top5 99.981250    LR 0.013821    Time 0.019774    
2018-11-02 21:44:16,473 - Epoch: [181][  300/  391]    Overall Loss 0.089676    Objective Loss 0.089676    Top1 96.843750    Top5 99.984375    LR 0.013821    Time 0.019743    
2018-11-02 21:44:17,452 - Epoch: [181][  350/  391]    Overall Loss 0.090435    Objective Loss 0.090435    Top1 96.812500    Top5 99.986607    LR 0.013821    Time 0.019716    
2018-11-02 21:44:18,340 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37979 | -0.00628 |    0.24027 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16939 | -0.00200 |    0.10660 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16929 | -0.00521 |    0.12792 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20365 | -0.04926 |    0.15827 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21747 |  0.00672 |    0.17209 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18123 | -0.02934 |    0.13836 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17699 | -0.00379 |    0.12917 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21331 | -0.00330 |    0.15617 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17639 | -0.00455 |    0.13506 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26274 | -0.01131 |    0.17397 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.00057 |    0.11492 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13015 | -0.01471 |    0.10487 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15688 | -0.01588 |    0.12301 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11490 | -0.00533 |    0.08811 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12621 | -0.01464 |    0.10071 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11944 | -0.00281 |    0.09453 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14933 | -0.00891 |    0.11492 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11296 | -0.01047 |    0.08972 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09651 | -0.00628 |    0.07600 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09748 | -0.01137 |    0.07773 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05925 |  0.00275 |    0.04478 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57246 | -0.00001 |    0.44657 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:44:18,340 - Total sparsity: 0.00

2018-11-02 21:44:18,340 - --- validate (epoch=181)-----------
2018-11-02 21:44:18,340 - 10000 samples (128 per mini-batch)
2018-11-02 21:44:19,065 - Epoch: [181][   50/   78]    Loss 0.379243    Top1 90.140625    Top5 99.640625    
2018-11-02 21:44:19,459 - ==> Top1: 90.150    Top5: 99.680    Loss: 0.369

2018-11-02 21:44:19,460 - ==> Best Top1: 90.180   On Epoch: 180

2018-11-02 21:44:19,460 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:44:19,468 - 

2018-11-02 21:44:19,468 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:44:20,508 - Epoch: [182][   50/  391]    Overall Loss 0.078881    Objective Loss 0.078881    Top1 97.187500    Top5 99.984375    LR 0.013130    Time 0.020767    
2018-11-02 21:44:21,489 - Epoch: [182][  100/  391]    Overall Loss 0.079791    Objective Loss 0.079791    Top1 97.164062    Top5 99.984375    LR 0.013130    Time 0.020175    
2018-11-02 21:44:22,523 - Epoch: [182][  150/  391]    Overall Loss 0.084044    Objective Loss 0.084044    Top1 97.020833    Top5 99.979167    LR 0.013130    Time 0.020340    
2018-11-02 21:44:23,504 - Epoch: [182][  200/  391]    Overall Loss 0.086156    Objective Loss 0.086156    Top1 96.921875    Top5 99.984375    LR 0.013130    Time 0.020153    
2018-11-02 21:44:24,484 - Epoch: [182][  250/  391]    Overall Loss 0.087412    Objective Loss 0.087412    Top1 96.865625    Top5 99.987500    LR 0.013130    Time 0.020039    
2018-11-02 21:44:25,464 - Epoch: [182][  300/  391]    Overall Loss 0.088618    Objective Loss 0.088618    Top1 96.809896    Top5 99.984375    LR 0.013130    Time 0.019960    
2018-11-02 21:44:26,444 - Epoch: [182][  350/  391]    Overall Loss 0.088908    Objective Loss 0.088908    Top1 96.808036    Top5 99.982143    LR 0.013130    Time 0.019905    
2018-11-02 21:44:27,327 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37833 | -0.00762 |    0.23917 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16879 | -0.00105 |    0.10618 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16869 | -0.00452 |    0.12753 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20279 | -0.04955 |    0.15767 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21664 |  0.00781 |    0.17128 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18070 | -0.02854 |    0.13788 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17639 | -0.00396 |    0.12886 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21257 | -0.00318 |    0.15556 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17576 | -0.00480 |    0.13452 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26173 | -0.01126 |    0.17324 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15483 | -0.00089 |    0.11447 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12966 | -0.01489 |    0.10454 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15639 | -0.01531 |    0.12268 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11449 | -0.00544 |    0.08776 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12575 | -0.01465 |    0.10038 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11904 | -0.00263 |    0.09420 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14875 | -0.00884 |    0.11437 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11258 | -0.01049 |    0.08943 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09621 | -0.00617 |    0.07578 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09717 | -0.01141 |    0.07752 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05903 |  0.00268 |    0.04462 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57301 | -0.00001 |    0.44688 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:44:27,328 - Total sparsity: 0.00

2018-11-02 21:44:27,328 - --- validate (epoch=182)-----------
2018-11-02 21:44:27,328 - 10000 samples (128 per mini-batch)
2018-11-02 21:44:28,049 - Epoch: [182][   50/   78]    Loss 0.386200    Top1 89.703125    Top5 99.640625    
2018-11-02 21:44:28,443 - ==> Top1: 89.780    Top5: 99.680    Loss: 0.383

2018-11-02 21:44:28,444 - ==> Best Top1: 90.180   On Epoch: 180

2018-11-02 21:44:28,444 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:44:28,455 - 

2018-11-02 21:44:28,455 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:44:29,495 - Epoch: [183][   50/  391]    Overall Loss 0.074959    Objective Loss 0.074959    Top1 97.515625    Top5 99.984375    LR 0.012473    Time 0.020746    
2018-11-02 21:44:30,476 - Epoch: [183][  100/  391]    Overall Loss 0.079648    Objective Loss 0.079648    Top1 97.343750    Top5 99.992188    LR 0.012473    Time 0.020173    
2018-11-02 21:44:31,457 - Epoch: [183][  150/  391]    Overall Loss 0.082591    Objective Loss 0.082591    Top1 97.135417    Top5 99.989583    LR 0.012473    Time 0.019979    
2018-11-02 21:44:32,439 - Epoch: [183][  200/  391]    Overall Loss 0.082966    Objective Loss 0.082966    Top1 97.128906    Top5 99.988281    LR 0.012473    Time 0.019889    
2018-11-02 21:44:33,416 - Epoch: [183][  250/  391]    Overall Loss 0.083678    Objective Loss 0.083678    Top1 97.115625    Top5 99.987500    LR 0.012473    Time 0.019815    
2018-11-02 21:44:34,395 - Epoch: [183][  300/  391]    Overall Loss 0.083787    Objective Loss 0.083787    Top1 97.106771    Top5 99.986979    LR 0.012473    Time 0.019760    
2018-11-02 21:44:35,372 - Epoch: [183][  350/  391]    Overall Loss 0.084533    Objective Loss 0.084533    Top1 97.082589    Top5 99.988839    LR 0.012473    Time 0.019725    
2018-11-02 21:44:36,256 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37700 | -0.00548 |    0.23807 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16819 | -0.00080 |    0.10609 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16807 | -0.00461 |    0.12692 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20200 | -0.04965 |    0.15711 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21588 |  0.00698 |    0.17045 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18012 | -0.02810 |    0.13757 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17575 | -0.00449 |    0.12833 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21183 | -0.00323 |    0.15485 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17515 | -0.00482 |    0.13395 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26073 | -0.01165 |    0.17244 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15429 | -0.00073 |    0.11405 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12924 | -0.01453 |    0.10416 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15587 | -0.01521 |    0.12223 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11410 | -0.00536 |    0.08754 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12529 | -0.01474 |    0.09995 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11864 | -0.00259 |    0.09390 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14819 | -0.00876 |    0.11383 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11223 | -0.01035 |    0.08911 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09593 | -0.00606 |    0.07555 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09687 | -0.01138 |    0.07727 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05881 |  0.00262 |    0.04445 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57362 | -0.00001 |    0.44748 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:44:36,256 - Total sparsity: 0.00

2018-11-02 21:44:36,256 - --- validate (epoch=183)-----------
2018-11-02 21:44:36,256 - 10000 samples (128 per mini-batch)
2018-11-02 21:44:36,985 - Epoch: [183][   50/   78]    Loss 0.388126    Top1 89.890625    Top5 99.687500    
2018-11-02 21:44:37,383 - ==> Top1: 89.880    Top5: 99.720    Loss: 0.381

2018-11-02 21:44:37,383 - ==> Best Top1: 90.180   On Epoch: 180

2018-11-02 21:44:37,384 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:44:37,395 - 

2018-11-02 21:44:37,395 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:44:38,436 - Epoch: [184][   50/  391]    Overall Loss 0.079956    Objective Loss 0.079956    Top1 97.171875    Top5 99.984375    LR 0.011850    Time 0.020774    
2018-11-02 21:44:39,413 - Epoch: [184][  100/  391]    Overall Loss 0.085080    Objective Loss 0.085080    Top1 96.945312    Top5 99.984375    LR 0.011850    Time 0.020148    
2018-11-02 21:44:40,395 - Epoch: [184][  150/  391]    Overall Loss 0.084265    Objective Loss 0.084265    Top1 96.989583    Top5 99.989583    LR 0.011850    Time 0.019971    
2018-11-02 21:44:41,375 - Epoch: [184][  200/  391]    Overall Loss 0.083652    Objective Loss 0.083652    Top1 96.996094    Top5 99.992188    LR 0.011850    Time 0.019870    
2018-11-02 21:44:42,356 - Epoch: [184][  250/  391]    Overall Loss 0.085220    Objective Loss 0.085220    Top1 96.946875    Top5 99.987500    LR 0.011850    Time 0.019815    
2018-11-02 21:44:43,336 - Epoch: [184][  300/  391]    Overall Loss 0.085714    Objective Loss 0.085714    Top1 96.973958    Top5 99.984375    LR 0.011850    Time 0.019776    
2018-11-02 21:44:44,316 - Epoch: [184][  350/  391]    Overall Loss 0.085870    Objective Loss 0.085870    Top1 96.984375    Top5 99.982143    LR 0.011850    Time 0.019745    
2018-11-02 21:44:45,205 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37569 | -0.00562 |    0.23769 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16762 | -0.00079 |    0.10563 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16751 | -0.00453 |    0.12668 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20127 | -0.04976 |    0.15666 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21515 |  0.00756 |    0.16970 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17966 | -0.02722 |    0.13703 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17520 | -0.00402 |    0.12781 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21115 | -0.00246 |    0.15435 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17458 | -0.00482 |    0.13341 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25983 | -0.01142 |    0.17169 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15379 | -0.00123 |    0.11371 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12883 | -0.01447 |    0.10371 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15540 | -0.01495 |    0.12174 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11374 | -0.00530 |    0.08729 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12487 | -0.01469 |    0.09961 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11827 | -0.00259 |    0.09364 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14767 | -0.00878 |    0.11349 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11188 | -0.01028 |    0.08886 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09565 | -0.00596 |    0.07532 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09659 | -0.01129 |    0.07707 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05860 |  0.00265 |    0.04431 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57391 | -0.00001 |    0.44762 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:44:45,205 - Total sparsity: 0.00

2018-11-02 21:44:45,206 - --- validate (epoch=184)-----------
2018-11-02 21:44:45,206 - 10000 samples (128 per mini-batch)
2018-11-02 21:44:45,932 - Epoch: [184][   50/   78]    Loss 0.393139    Top1 89.593750    Top5 99.671875    
2018-11-02 21:44:46,327 - ==> Top1: 89.710    Top5: 99.690    Loss: 0.393

2018-11-02 21:44:46,328 - ==> Best Top1: 90.180   On Epoch: 180

2018-11-02 21:44:46,328 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:44:46,336 - 

2018-11-02 21:44:46,336 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:44:47,372 - Epoch: [185][   50/  391]    Overall Loss 0.081311    Objective Loss 0.081311    Top1 97.171875    Top5 100.000000    LR 0.011257    Time 0.020689    
2018-11-02 21:44:48,351 - Epoch: [185][  100/  391]    Overall Loss 0.082741    Objective Loss 0.082741    Top1 97.125000    Top5 99.984375    LR 0.011257    Time 0.020120    
2018-11-02 21:44:49,331 - Epoch: [185][  150/  391]    Overall Loss 0.081902    Objective Loss 0.081902    Top1 97.130208    Top5 99.989583    LR 0.011257    Time 0.019935    
2018-11-02 21:44:50,339 - Epoch: [185][  200/  391]    Overall Loss 0.082755    Objective Loss 0.082755    Top1 97.140625    Top5 99.984375    LR 0.011257    Time 0.019984    
2018-11-02 21:44:51,318 - Epoch: [185][  250/  391]    Overall Loss 0.082543    Objective Loss 0.082543    Top1 97.187500    Top5 99.981250    LR 0.011257    Time 0.019902    
2018-11-02 21:44:52,297 - Epoch: [185][  300/  391]    Overall Loss 0.083092    Objective Loss 0.083092    Top1 97.151042    Top5 99.981771    LR 0.011257    Time 0.019844    
2018-11-02 21:44:53,276 - Epoch: [185][  350/  391]    Overall Loss 0.083127    Objective Loss 0.083127    Top1 97.154018    Top5 99.984375    LR 0.011257    Time 0.019801    
2018-11-02 21:44:54,159 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37441 | -0.00634 |    0.23694 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16707 | -0.00049 |    0.10534 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16697 | -0.00430 |    0.12623 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20074 | -0.04910 |    0.15630 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21445 |  0.00750 |    0.16922 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17901 | -0.02774 |    0.13671 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17464 | -0.00444 |    0.12751 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21047 | -0.00242 |    0.15372 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17402 | -0.00479 |    0.13303 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25895 | -0.01099 |    0.17093 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15330 | -0.00092 |    0.11347 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12841 | -0.01444 |    0.10334 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15496 | -0.01470 |    0.12130 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11339 | -0.00519 |    0.08703 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12449 | -0.01446 |    0.09922 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11790 | -0.00260 |    0.09333 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14717 | -0.00863 |    0.11306 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11155 | -0.01019 |    0.08857 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09538 | -0.00604 |    0.07514 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09633 | -0.01124 |    0.07686 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05841 |  0.00262 |    0.04419 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57427 | -0.00001 |    0.44812 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:44:54,160 - Total sparsity: 0.00

2018-11-02 21:44:54,160 - --- validate (epoch=185)-----------
2018-11-02 21:44:54,160 - 10000 samples (128 per mini-batch)
2018-11-02 21:44:54,885 - Epoch: [185][   50/   78]    Loss 0.381145    Top1 89.765625    Top5 99.703125    
2018-11-02 21:44:55,279 - ==> Top1: 90.040    Top5: 99.740    Loss: 0.376

2018-11-02 21:44:55,280 - ==> Best Top1: 90.180   On Epoch: 180

2018-11-02 21:44:55,280 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:44:55,291 - 

2018-11-02 21:44:55,291 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:44:56,331 - Epoch: [186][   50/  391]    Overall Loss 0.075636    Objective Loss 0.075636    Top1 97.562500    Top5 99.984375    LR 0.010694    Time 0.020748    
2018-11-02 21:44:57,309 - Epoch: [186][  100/  391]    Overall Loss 0.075434    Objective Loss 0.075434    Top1 97.554688    Top5 99.984375    LR 0.010694    Time 0.020146    
2018-11-02 21:44:58,285 - Epoch: [186][  150/  391]    Overall Loss 0.076999    Objective Loss 0.076999    Top1 97.473958    Top5 99.989583    LR 0.010694    Time 0.019929    
2018-11-02 21:44:59,263 - Epoch: [186][  200/  391]    Overall Loss 0.077035    Objective Loss 0.077035    Top1 97.445312    Top5 99.992188    LR 0.010694    Time 0.019830    
2018-11-02 21:45:00,244 - Epoch: [186][  250/  391]    Overall Loss 0.077359    Objective Loss 0.077359    Top1 97.421875    Top5 99.990625    LR 0.010694    Time 0.019783    
2018-11-02 21:45:01,223 - Epoch: [186][  300/  391]    Overall Loss 0.077147    Objective Loss 0.077147    Top1 97.393229    Top5 99.992188    LR 0.010694    Time 0.019746    
2018-11-02 21:45:02,202 - Epoch: [186][  350/  391]    Overall Loss 0.077824    Objective Loss 0.077824    Top1 97.337054    Top5 99.991071    LR 0.010694    Time 0.019717    
2018-11-02 21:45:03,084 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37319 | -0.00655 |    0.23596 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16654 | -0.00004 |    0.10501 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16642 | -0.00487 |    0.12593 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20016 | -0.04867 |    0.15587 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21378 |  0.00700 |    0.16897 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17841 | -0.02801 |    0.13661 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17409 | -0.00477 |    0.12718 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20981 | -0.00246 |    0.15323 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17348 | -0.00477 |    0.13261 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25807 | -0.01142 |    0.17022 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15283 | -0.00065 |    0.11307 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12795 | -0.01495 |    0.10299 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15450 | -0.01474 |    0.12089 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11303 | -0.00546 |    0.08675 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12409 | -0.01446 |    0.09893 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11755 | -0.00255 |    0.09305 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14668 | -0.00853 |    0.11266 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11124 | -0.01002 |    0.08831 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09511 | -0.00611 |    0.07494 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09605 | -0.01127 |    0.07664 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05822 |  0.00250 |    0.04405 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57479 | -0.00001 |    0.44848 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:45:03,084 - Total sparsity: 0.00

2018-11-02 21:45:03,084 - --- validate (epoch=186)-----------
2018-11-02 21:45:03,084 - 10000 samples (128 per mini-batch)
2018-11-02 21:45:03,813 - Epoch: [186][   50/   78]    Loss 0.382798    Top1 89.765625    Top5 99.609375    
2018-11-02 21:45:04,206 - ==> Top1: 90.040    Top5: 99.670    Loss: 0.378

2018-11-02 21:45:04,206 - ==> Best Top1: 90.180   On Epoch: 180

2018-11-02 21:45:04,206 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:45:04,218 - 

2018-11-02 21:45:04,219 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:45:05,256 - Epoch: [187][   50/  391]    Overall Loss 0.069271    Objective Loss 0.069271    Top1 97.500000    Top5 100.000000    LR 0.010160    Time 0.020708    
2018-11-02 21:45:06,237 - Epoch: [187][  100/  391]    Overall Loss 0.076226    Objective Loss 0.076226    Top1 97.257812    Top5 100.000000    LR 0.010160    Time 0.020152    
2018-11-02 21:45:07,218 - Epoch: [187][  150/  391]    Overall Loss 0.078560    Objective Loss 0.078560    Top1 97.182292    Top5 99.994792    LR 0.010160    Time 0.019969    
2018-11-02 21:45:08,197 - Epoch: [187][  200/  391]    Overall Loss 0.076915    Objective Loss 0.076915    Top1 97.253906    Top5 99.992188    LR 0.010160    Time 0.019863    
2018-11-02 21:45:09,175 - Epoch: [187][  250/  391]    Overall Loss 0.076825    Objective Loss 0.076825    Top1 97.243750    Top5 99.990625    LR 0.010160    Time 0.019799    
2018-11-02 21:45:10,175 - Epoch: [187][  300/  391]    Overall Loss 0.077894    Objective Loss 0.077894    Top1 97.208333    Top5 99.989583    LR 0.010160    Time 0.019828    
2018-11-02 21:45:11,225 - Epoch: [187][  350/  391]    Overall Loss 0.077541    Objective Loss 0.077541    Top1 97.218750    Top5 99.988839    LR 0.010160    Time 0.019993    
2018-11-02 21:45:12,159 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37204 | -0.00667 |    0.23523 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16604 | -0.00029 |    0.10472 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16593 | -0.00397 |    0.12558 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19950 | -0.04868 |    0.15524 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21310 |  0.00764 |    0.16848 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17794 | -0.02761 |    0.13628 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17358 | -0.00440 |    0.12691 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20919 | -0.00242 |    0.15295 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17297 | -0.00459 |    0.13226 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25726 | -0.01097 |    0.16956 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15238 | -0.00083 |    0.11278 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12756 | -0.01503 |    0.10276 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15408 | -0.01442 |    0.12064 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11270 | -0.00532 |    0.08642 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12372 | -0.01443 |    0.09869 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11721 | -0.00248 |    0.09275 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14621 | -0.00853 |    0.11235 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11093 | -0.00992 |    0.08802 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09486 | -0.00607 |    0.07476 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09579 | -0.01133 |    0.07643 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05804 |  0.00246 |    0.04392 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57516 | -0.00001 |    0.44883 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:45:12,160 - Total sparsity: 0.00

2018-11-02 21:45:12,160 - --- validate (epoch=187)-----------
2018-11-02 21:45:12,160 - 10000 samples (128 per mini-batch)
2018-11-02 21:45:12,888 - Epoch: [187][   50/   78]    Loss 0.382493    Top1 90.078125    Top5 99.687500    
2018-11-02 21:45:13,279 - ==> Top1: 90.060    Top5: 99.700    Loss: 0.378

2018-11-02 21:45:13,280 - ==> Best Top1: 90.180   On Epoch: 180

2018-11-02 21:45:13,280 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:45:13,288 - 

2018-11-02 21:45:13,288 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:45:14,326 - Epoch: [188][   50/  391]    Overall Loss 0.066883    Objective Loss 0.066883    Top1 97.609375    Top5 100.000000    LR 0.009652    Time 0.020716    
2018-11-02 21:45:15,304 - Epoch: [188][  100/  391]    Overall Loss 0.071168    Objective Loss 0.071168    Top1 97.468750    Top5 100.000000    LR 0.009652    Time 0.020126    
2018-11-02 21:45:16,281 - Epoch: [188][  150/  391]    Overall Loss 0.072739    Objective Loss 0.072739    Top1 97.505208    Top5 100.000000    LR 0.009652    Time 0.019925    
2018-11-02 21:45:17,261 - Epoch: [188][  200/  391]    Overall Loss 0.073930    Objective Loss 0.073930    Top1 97.460938    Top5 100.000000    LR 0.009652    Time 0.019839    
2018-11-02 21:45:18,243 - Epoch: [188][  250/  391]    Overall Loss 0.075162    Objective Loss 0.075162    Top1 97.428125    Top5 100.000000    LR 0.009652    Time 0.019794    
2018-11-02 21:45:19,221 - Epoch: [188][  300/  391]    Overall Loss 0.075971    Objective Loss 0.075971    Top1 97.440104    Top5 99.997396    LR 0.009652    Time 0.019750    
2018-11-02 21:45:20,201 - Epoch: [188][  350/  391]    Overall Loss 0.077299    Objective Loss 0.077299    Top1 97.395089    Top5 99.993304    LR 0.009652    Time 0.019726    
2018-11-02 21:45:21,080 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37093 | -0.00675 |    0.23447 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16556 | -0.00022 |    0.10432 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16545 | -0.00397 |    0.12532 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19894 | -0.04849 |    0.15479 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21251 |  0.00642 |    0.16781 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17740 | -0.02790 |    0.13587 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17310 | -0.00410 |    0.12638 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20859 | -0.00279 |    0.15247 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17247 | -0.00470 |    0.13184 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25649 | -0.01059 |    0.16882 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15194 | -0.00098 |    0.11248 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12724 | -0.01469 |    0.10244 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15364 | -0.01462 |    0.12038 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11238 | -0.00543 |    0.08627 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12337 | -0.01427 |    0.09836 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11688 | -0.00255 |    0.09249 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14577 | -0.00847 |    0.11207 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11062 | -0.00998 |    0.08780 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09462 | -0.00602 |    0.07460 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09554 | -0.01128 |    0.07623 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05787 |  0.00242 |    0.04381 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57554 | -0.00001 |    0.44915 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:45:21,081 - Total sparsity: 0.00

2018-11-02 21:45:21,081 - --- validate (epoch=188)-----------
2018-11-02 21:45:21,081 - 10000 samples (128 per mini-batch)
2018-11-02 21:45:21,802 - Epoch: [188][   50/   78]    Loss 0.374107    Top1 90.062500    Top5 99.656250    
2018-11-02 21:45:22,193 - ==> Top1: 90.310    Top5: 99.660    Loss: 0.371

2018-11-02 21:45:22,194 - ==> Best Top1: 90.310   On Epoch: 188

2018-11-02 21:45:22,194 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:45:22,203 - 

2018-11-02 21:45:22,203 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:45:23,312 - Epoch: [189][   50/  391]    Overall Loss 0.065167    Objective Loss 0.065167    Top1 97.750000    Top5 99.984375    LR 0.009169    Time 0.022156    
2018-11-02 21:45:24,308 - Epoch: [189][  100/  391]    Overall Loss 0.071858    Objective Loss 0.071858    Top1 97.484375    Top5 99.984375    LR 0.009169    Time 0.021020    
2018-11-02 21:45:25,286 - Epoch: [189][  150/  391]    Overall Loss 0.072683    Objective Loss 0.072683    Top1 97.458333    Top5 99.989583    LR 0.009169    Time 0.020524    
2018-11-02 21:45:26,263 - Epoch: [189][  200/  391]    Overall Loss 0.072864    Objective Loss 0.072864    Top1 97.441406    Top5 99.992188    LR 0.009169    Time 0.020272    
2018-11-02 21:45:27,240 - Epoch: [189][  250/  391]    Overall Loss 0.072893    Objective Loss 0.072893    Top1 97.440625    Top5 99.990625    LR 0.009169    Time 0.020119    
2018-11-02 21:45:28,219 - Epoch: [189][  300/  391]    Overall Loss 0.073728    Objective Loss 0.073728    Top1 97.375000    Top5 99.989583    LR 0.009169    Time 0.020014    
2018-11-02 21:45:29,198 - Epoch: [189][  350/  391]    Overall Loss 0.073523    Objective Loss 0.073523    Top1 97.375000    Top5 99.991071    LR 0.009169    Time 0.019948    
2018-11-02 21:45:30,085 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36986 | -0.00623 |    0.23387 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16510 | -0.00001 |    0.10396 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16499 | -0.00381 |    0.12479 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19844 | -0.04809 |    0.15439 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21191 |  0.00642 |    0.16750 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17688 | -0.02816 |    0.13526 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17262 | -0.00396 |    0.12607 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20801 | -0.00299 |    0.15205 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17200 | -0.00450 |    0.13147 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25576 | -0.01014 |    0.16840 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15151 | -0.00095 |    0.11232 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12689 | -0.01465 |    0.10223 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15323 | -0.01458 |    0.12006 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11207 | -0.00556 |    0.08598 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12304 | -0.01416 |    0.09809 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11657 | -0.00243 |    0.09224 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14534 | -0.00839 |    0.11169 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11033 | -0.00993 |    0.08757 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09438 | -0.00596 |    0.07440 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09530 | -0.01129 |    0.07605 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05769 |  0.00249 |    0.04368 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57605 | -0.00001 |    0.44957 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:45:30,086 - Total sparsity: 0.00

2018-11-02 21:45:30,086 - --- validate (epoch=189)-----------
2018-11-02 21:45:30,086 - 10000 samples (128 per mini-batch)
2018-11-02 21:45:30,813 - Epoch: [189][   50/   78]    Loss 0.378670    Top1 90.312500    Top5 99.687500    
2018-11-02 21:45:31,207 - ==> Top1: 90.310    Top5: 99.690    Loss: 0.375

2018-11-02 21:45:31,208 - ==> Best Top1: 90.310   On Epoch: 188

2018-11-02 21:45:31,208 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:45:31,219 - 

2018-11-02 21:45:31,220 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:45:32,256 - Epoch: [190][   50/  391]    Overall Loss 0.068310    Objective Loss 0.068310    Top1 97.500000    Top5 99.984375    LR 0.008711    Time 0.020695    
2018-11-02 21:45:33,233 - Epoch: [190][  100/  391]    Overall Loss 0.066723    Objective Loss 0.066723    Top1 97.617188    Top5 99.992188    LR 0.008711    Time 0.020092    
2018-11-02 21:45:34,213 - Epoch: [190][  150/  391]    Overall Loss 0.070152    Objective Loss 0.070152    Top1 97.546875    Top5 99.984375    LR 0.008711    Time 0.019919    
2018-11-02 21:45:35,191 - Epoch: [190][  200/  391]    Overall Loss 0.070695    Objective Loss 0.070695    Top1 97.507812    Top5 99.984375    LR 0.008711    Time 0.019825    
2018-11-02 21:45:36,188 - Epoch: [190][  250/  391]    Overall Loss 0.070718    Objective Loss 0.070718    Top1 97.537500    Top5 99.987500    LR 0.008711    Time 0.019840    
2018-11-02 21:45:37,165 - Epoch: [190][  300/  391]    Overall Loss 0.070964    Objective Loss 0.070964    Top1 97.536458    Top5 99.989583    LR 0.008711    Time 0.019788    
2018-11-02 21:45:38,145 - Epoch: [190][  350/  391]    Overall Loss 0.071271    Objective Loss 0.071271    Top1 97.520089    Top5 99.988839    LR 0.008711    Time 0.019757    
2018-11-02 21:45:39,028 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36884 | -0.00619 |    0.23326 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16464 |  0.00018 |    0.10384 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16453 | -0.00419 |    0.12444 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19781 | -0.04829 |    0.15391 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21132 |  0.00664 |    0.16675 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17642 | -0.02802 |    0.13486 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17216 | -0.00365 |    0.12570 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20745 | -0.00271 |    0.15166 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17153 | -0.00460 |    0.13111 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25502 | -0.01060 |    0.16780 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15111 | -0.00071 |    0.11208 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12657 | -0.01438 |    0.10194 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15284 | -0.01440 |    0.11978 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11178 | -0.00536 |    0.08572 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12272 | -0.01401 |    0.09781 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11626 | -0.00245 |    0.09201 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14492 | -0.00839 |    0.11134 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11005 | -0.00983 |    0.08733 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09416 | -0.00581 |    0.07422 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09507 | -0.01123 |    0.07588 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05753 |  0.00250 |    0.04356 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57647 | -0.00001 |    0.44984 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:45:39,029 - Total sparsity: 0.00

2018-11-02 21:45:39,029 - --- validate (epoch=190)-----------
2018-11-02 21:45:39,029 - 10000 samples (128 per mini-batch)
2018-11-02 21:45:39,744 - Epoch: [190][   50/   78]    Loss 0.387654    Top1 89.968750    Top5 99.671875    
2018-11-02 21:45:40,130 - ==> Top1: 90.050    Top5: 99.700    Loss: 0.385

2018-11-02 21:45:40,131 - ==> Best Top1: 90.310   On Epoch: 188

2018-11-02 21:45:40,131 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:45:40,139 - 

2018-11-02 21:45:40,139 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:45:41,176 - Epoch: [191][   50/  391]    Overall Loss 0.066901    Objective Loss 0.066901    Top1 97.750000    Top5 99.968750    LR 0.008275    Time 0.020706    
2018-11-02 21:45:42,155 - Epoch: [191][  100/  391]    Overall Loss 0.066358    Objective Loss 0.066358    Top1 97.734375    Top5 99.984375    LR 0.008275    Time 0.020129    
2018-11-02 21:45:43,133 - Epoch: [191][  150/  391]    Overall Loss 0.067412    Objective Loss 0.067412    Top1 97.692708    Top5 99.973958    LR 0.008275    Time 0.019932    
2018-11-02 21:45:44,112 - Epoch: [191][  200/  391]    Overall Loss 0.067464    Objective Loss 0.067464    Top1 97.671875    Top5 99.980469    LR 0.008275    Time 0.019835    
2018-11-02 21:45:45,089 - Epoch: [191][  250/  391]    Overall Loss 0.067502    Objective Loss 0.067502    Top1 97.665625    Top5 99.981250    LR 0.008275    Time 0.019772    
2018-11-02 21:45:46,070 - Epoch: [191][  300/  391]    Overall Loss 0.068133    Objective Loss 0.068133    Top1 97.638021    Top5 99.981771    LR 0.008275    Time 0.019740    
2018-11-02 21:45:47,051 - Epoch: [191][  350/  391]    Overall Loss 0.069578    Objective Loss 0.069578    Top1 97.555804    Top5 99.982143    LR 0.008275    Time 0.019719    
2018-11-02 21:45:47,933 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36784 | -0.00682 |    0.23271 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16421 |  0.00033 |    0.10362 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16410 | -0.00419 |    0.12409 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19741 | -0.04769 |    0.15371 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21077 |  0.00677 |    0.16632 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17603 | -0.02761 |    0.13457 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17172 | -0.00364 |    0.12533 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20692 | -0.00270 |    0.15119 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17109 | -0.00461 |    0.13078 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25433 | -0.01046 |    0.16731 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15072 | -0.00070 |    0.11183 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12624 | -0.01443 |    0.10161 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15246 | -0.01424 |    0.11949 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11148 | -0.00569 |    0.08547 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12241 | -0.01386 |    0.09756 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11597 | -0.00238 |    0.09178 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14453 | -0.00838 |    0.11097 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10979 | -0.00974 |    0.08713 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09394 | -0.00577 |    0.07404 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09483 | -0.01131 |    0.07572 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05738 |  0.00245 |    0.04345 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57683 | -0.00001 |    0.45024 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:45:47,933 - Total sparsity: 0.00

2018-11-02 21:45:47,933 - --- validate (epoch=191)-----------
2018-11-02 21:45:47,933 - 10000 samples (128 per mini-batch)
2018-11-02 21:45:48,656 - Epoch: [191][   50/   78]    Loss 0.389633    Top1 89.984375    Top5 99.578125    
2018-11-02 21:45:49,049 - ==> Top1: 90.090    Top5: 99.600    Loss: 0.387

2018-11-02 21:45:49,050 - ==> Best Top1: 90.310   On Epoch: 188

2018-11-02 21:45:49,050 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:45:49,057 - 

2018-11-02 21:45:49,057 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:45:50,092 - Epoch: [192][   50/  391]    Overall Loss 0.060643    Objective Loss 0.060643    Top1 97.859375    Top5 100.000000    LR 0.007861    Time 0.020660    
2018-11-02 21:45:51,069 - Epoch: [192][  100/  391]    Overall Loss 0.061921    Objective Loss 0.061921    Top1 97.906250    Top5 99.992188    LR 0.007861    Time 0.020088    
2018-11-02 21:45:52,050 - Epoch: [192][  150/  391]    Overall Loss 0.063420    Objective Loss 0.063420    Top1 97.843750    Top5 99.994792    LR 0.007861    Time 0.019919    
2018-11-02 21:45:53,029 - Epoch: [192][  200/  391]    Overall Loss 0.066134    Objective Loss 0.066134    Top1 97.765625    Top5 99.996094    LR 0.007861    Time 0.019830    
2018-11-02 21:45:54,006 - Epoch: [192][  250/  391]    Overall Loss 0.065429    Objective Loss 0.065429    Top1 97.768750    Top5 99.993750    LR 0.007861    Time 0.019765    
2018-11-02 21:45:54,984 - Epoch: [192][  300/  391]    Overall Loss 0.065771    Objective Loss 0.065771    Top1 97.760417    Top5 99.994792    LR 0.007861    Time 0.019725    
2018-11-02 21:45:55,962 - Epoch: [192][  350/  391]    Overall Loss 0.066767    Objective Loss 0.066767    Top1 97.718750    Top5 99.993304    LR 0.007861    Time 0.019698    
2018-11-02 21:45:56,844 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36688 | -0.00671 |    0.23204 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16379 |  0.00010 |    0.10340 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16369 | -0.00398 |    0.12388 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19691 | -0.04759 |    0.15324 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21024 |  0.00669 |    0.16581 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17567 | -0.02704 |    0.13421 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17128 | -0.00396 |    0.12491 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20641 | -0.00287 |    0.15085 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17066 | -0.00450 |    0.13046 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25365 | -0.01061 |    0.16697 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15035 | -0.00091 |    0.11149 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12592 | -0.01442 |    0.10143 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15211 | -0.01405 |    0.11920 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11121 | -0.00558 |    0.08530 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12209 | -0.01392 |    0.09732 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11569 | -0.00235 |    0.09156 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14415 | -0.00839 |    0.11070 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10953 | -0.00968 |    0.08692 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09373 | -0.00572 |    0.07389 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09461 | -0.01136 |    0.07555 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05723 |  0.00244 |    0.04333 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57719 | -0.00001 |    0.45050 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:45:56,845 - Total sparsity: 0.00

2018-11-02 21:45:56,845 - --- validate (epoch=192)-----------
2018-11-02 21:45:56,845 - 10000 samples (128 per mini-batch)
2018-11-02 21:45:57,571 - Epoch: [192][   50/   78]    Loss 0.379637    Top1 90.437500    Top5 99.671875    
2018-11-02 21:45:57,963 - ==> Top1: 90.350    Top5: 99.710    Loss: 0.381

2018-11-02 21:45:57,964 - ==> Best Top1: 90.350   On Epoch: 192

2018-11-02 21:45:57,964 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:45:57,980 - 

2018-11-02 21:45:57,980 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:45:58,990 - Epoch: [193][   50/  391]    Overall Loss 0.061951    Objective Loss 0.061951    Top1 97.875000    Top5 99.984375    LR 0.007468    Time 0.020169    
2018-11-02 21:45:59,968 - Epoch: [193][  100/  391]    Overall Loss 0.062174    Objective Loss 0.062174    Top1 97.906250    Top5 99.992188    LR 0.007468    Time 0.019853    
2018-11-02 21:46:00,952 - Epoch: [193][  150/  391]    Overall Loss 0.063287    Objective Loss 0.063287    Top1 97.807292    Top5 99.994792    LR 0.007468    Time 0.019787    
2018-11-02 21:46:01,930 - Epoch: [193][  200/  391]    Overall Loss 0.063697    Objective Loss 0.063697    Top1 97.742188    Top5 99.996094    LR 0.007468    Time 0.019721    
2018-11-02 21:46:02,909 - Epoch: [193][  250/  391]    Overall Loss 0.065849    Objective Loss 0.065849    Top1 97.650000    Top5 99.996875    LR 0.007468    Time 0.019688    
2018-11-02 21:46:03,888 - Epoch: [193][  300/  391]    Overall Loss 0.067034    Objective Loss 0.067034    Top1 97.601562    Top5 99.994792    LR 0.007468    Time 0.019665    
2018-11-02 21:46:04,865 - Epoch: [193][  350/  391]    Overall Loss 0.066709    Objective Loss 0.066709    Top1 97.625000    Top5 99.995536    LR 0.007468    Time 0.019645    
2018-11-02 21:46:05,747 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36598 | -0.00679 |    0.23141 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16340 | -0.00035 |    0.10310 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16331 | -0.00371 |    0.12357 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19649 | -0.04729 |    0.15276 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20975 |  0.00632 |    0.16556 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17527 | -0.02694 |    0.13390 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17089 | -0.00364 |    0.12477 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20592 | -0.00276 |    0.15044 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17025 | -0.00469 |    0.13017 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25302 | -0.01084 |    0.16658 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14999 | -0.00083 |    0.11128 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12564 | -0.01425 |    0.10120 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15176 | -0.01396 |    0.11887 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11096 | -0.00537 |    0.08516 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12181 | -0.01385 |    0.09709 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11542 | -0.00229 |    0.09137 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14379 | -0.00830 |    0.11049 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10928 | -0.00972 |    0.08673 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09352 | -0.00579 |    0.07373 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09441 | -0.01130 |    0.07540 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05709 |  0.00245 |    0.04324 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57746 | -0.00001 |    0.45065 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:46:05,747 - Total sparsity: 0.00

2018-11-02 21:46:05,747 - --- validate (epoch=193)-----------
2018-11-02 21:46:05,747 - 10000 samples (128 per mini-batch)
2018-11-02 21:46:06,461 - Epoch: [193][   50/   78]    Loss 0.385886    Top1 90.234375    Top5 99.687500    
2018-11-02 21:46:06,847 - ==> Top1: 90.150    Top5: 99.700    Loss: 0.389

2018-11-02 21:46:06,848 - ==> Best Top1: 90.350   On Epoch: 192

2018-11-02 21:46:06,848 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:46:06,856 - 

2018-11-02 21:46:06,856 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:46:07,892 - Epoch: [194][   50/  391]    Overall Loss 0.068286    Objective Loss 0.068286    Top1 97.593750    Top5 99.984375    LR 0.007095    Time 0.020692    
2018-11-02 21:46:08,871 - Epoch: [194][  100/  391]    Overall Loss 0.067785    Objective Loss 0.067785    Top1 97.648438    Top5 99.984375    LR 0.007095    Time 0.020119    
2018-11-02 21:46:09,849 - Epoch: [194][  150/  391]    Overall Loss 0.068399    Objective Loss 0.068399    Top1 97.677083    Top5 99.989583    LR 0.007095    Time 0.019922    
2018-11-02 21:46:10,824 - Epoch: [194][  200/  391]    Overall Loss 0.068834    Objective Loss 0.068834    Top1 97.601562    Top5 99.992188    LR 0.007095    Time 0.019810    
2018-11-02 21:46:11,800 - Epoch: [194][  250/  391]    Overall Loss 0.068077    Objective Loss 0.068077    Top1 97.618750    Top5 99.987500    LR 0.007095    Time 0.019748    
2018-11-02 21:46:12,797 - Epoch: [194][  300/  391]    Overall Loss 0.067507    Objective Loss 0.067507    Top1 97.640625    Top5 99.986979    LR 0.007095    Time 0.019774    
2018-11-02 21:46:13,775 - Epoch: [194][  350/  391]    Overall Loss 0.067281    Objective Loss 0.067281    Top1 97.647321    Top5 99.988839    LR 0.007095    Time 0.019740    
2018-11-02 21:46:14,657 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36515 | -0.00658 |    0.23079 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16303 | -0.00074 |    0.10283 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16295 | -0.00348 |    0.12333 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19604 | -0.04723 |    0.15240 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20928 |  0.00612 |    0.16508 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17485 | -0.02711 |    0.13358 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17051 | -0.00349 |    0.12461 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20546 | -0.00287 |    0.15000 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16987 | -0.00474 |    0.12986 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25240 | -0.01116 |    0.16591 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14966 | -0.00072 |    0.11114 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12537 | -0.01408 |    0.10098 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15140 | -0.01422 |    0.11862 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11072 | -0.00526 |    0.08498 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12153 | -0.01378 |    0.09686 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11517 | -0.00225 |    0.09117 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14345 | -0.00827 |    0.11015 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10904 | -0.00970 |    0.08656 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09333 | -0.00576 |    0.07358 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09422 | -0.01120 |    0.07524 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05695 |  0.00244 |    0.04314 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57766 | -0.00001 |    0.45081 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:46:14,657 - Total sparsity: 0.00

2018-11-02 21:46:14,658 - --- validate (epoch=194)-----------
2018-11-02 21:46:14,658 - 10000 samples (128 per mini-batch)
2018-11-02 21:46:15,373 - Epoch: [194][   50/   78]    Loss 0.384730    Top1 90.328125    Top5 99.640625    
2018-11-02 21:46:15,760 - ==> Top1: 90.370    Top5: 99.670    Loss: 0.383

2018-11-02 21:46:15,760 - ==> Best Top1: 90.370   On Epoch: 194

2018-11-02 21:46:15,761 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:46:15,777 - 

2018-11-02 21:46:15,777 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:46:16,809 - Epoch: [195][   50/  391]    Overall Loss 0.059412    Objective Loss 0.059412    Top1 97.984375    Top5 100.000000    LR 0.006740    Time 0.020611    
2018-11-02 21:46:17,787 - Epoch: [195][  100/  391]    Overall Loss 0.059803    Objective Loss 0.059803    Top1 97.945312    Top5 99.984375    LR 0.006740    Time 0.020069    
2018-11-02 21:46:18,764 - Epoch: [195][  150/  391]    Overall Loss 0.061550    Objective Loss 0.061550    Top1 97.880208    Top5 99.989583    LR 0.006740    Time 0.019887    
2018-11-02 21:46:19,743 - Epoch: [195][  200/  391]    Overall Loss 0.061838    Objective Loss 0.061838    Top1 97.835938    Top5 99.992188    LR 0.006740    Time 0.019808    
2018-11-02 21:46:20,724 - Epoch: [195][  250/  391]    Overall Loss 0.062961    Objective Loss 0.062961    Top1 97.800000    Top5 99.993750    LR 0.006740    Time 0.019763    
2018-11-02 21:46:21,719 - Epoch: [195][  300/  391]    Overall Loss 0.063570    Objective Loss 0.063570    Top1 97.791667    Top5 99.994792    LR 0.006740    Time 0.019782    
2018-11-02 21:46:22,719 - Epoch: [195][  350/  391]    Overall Loss 0.063828    Objective Loss 0.063828    Top1 97.792411    Top5 99.993304    LR 0.006740    Time 0.019809    
2018-11-02 21:46:23,601 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36434 | -0.00596 |    0.23019 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16267 | -0.00067 |    0.10262 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16258 | -0.00358 |    0.12304 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19573 | -0.04661 |    0.15205 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20882 |  0.00612 |    0.16459 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17446 | -0.02710 |    0.13317 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17013 | -0.00353 |    0.12424 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20500 | -0.00299 |    0.14975 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16950 | -0.00452 |    0.12951 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25182 | -0.01121 |    0.16546 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14933 | -0.00071 |    0.11091 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12509 | -0.01413 |    0.10077 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15105 | -0.01449 |    0.11833 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11048 | -0.00524 |    0.08471 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12125 | -0.01386 |    0.09663 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11492 | -0.00232 |    0.09098 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14312 | -0.00825 |    0.10986 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10881 | -0.00972 |    0.08638 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09314 | -0.00577 |    0.07344 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09404 | -0.01110 |    0.07510 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05682 |  0.00241 |    0.04305 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57797 | -0.00001 |    0.45102 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:46:23,601 - Total sparsity: 0.00

2018-11-02 21:46:23,601 - --- validate (epoch=195)-----------
2018-11-02 21:46:23,601 - 10000 samples (128 per mini-batch)
2018-11-02 21:46:24,331 - Epoch: [195][   50/   78]    Loss 0.387485    Top1 90.437500    Top5 99.625000    
2018-11-02 21:46:24,730 - ==> Top1: 90.430    Top5: 99.670    Loss: 0.387

2018-11-02 21:46:24,730 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:46:24,730 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:46:24,740 - 

2018-11-02 21:46:24,740 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:46:25,777 - Epoch: [196][   50/  391]    Overall Loss 0.061051    Objective Loss 0.061051    Top1 97.812500    Top5 99.984375    LR 0.006403    Time 0.020703    
2018-11-02 21:46:26,755 - Epoch: [196][  100/  391]    Overall Loss 0.061580    Objective Loss 0.061580    Top1 97.851562    Top5 99.984375    LR 0.006403    Time 0.020118    
2018-11-02 21:46:27,733 - Epoch: [196][  150/  391]    Overall Loss 0.060069    Objective Loss 0.060069    Top1 97.953125    Top5 99.989583    LR 0.006403    Time 0.019922    
2018-11-02 21:46:28,764 - Epoch: [196][  200/  391]    Overall Loss 0.059674    Objective Loss 0.059674    Top1 97.992188    Top5 99.992188    LR 0.006403    Time 0.020090    
2018-11-02 21:46:29,740 - Epoch: [196][  250/  391]    Overall Loss 0.060192    Objective Loss 0.060192    Top1 97.946875    Top5 99.993750    LR 0.006403    Time 0.019974    
2018-11-02 21:46:30,720 - Epoch: [196][  300/  391]    Overall Loss 0.061182    Objective Loss 0.061182    Top1 97.861979    Top5 99.994792    LR 0.006403    Time 0.019904    
2018-11-02 21:46:31,699 - Epoch: [196][  350/  391]    Overall Loss 0.061833    Objective Loss 0.061833    Top1 97.841518    Top5 99.993304    LR 0.006403    Time 0.019856    
2018-11-02 21:46:32,583 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36355 | -0.00622 |    0.22981 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16232 | -0.00076 |    0.10242 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16224 | -0.00352 |    0.12284 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19518 | -0.04706 |    0.15181 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20835 |  0.00688 |    0.16428 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17405 | -0.02727 |    0.13291 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16977 | -0.00367 |    0.12389 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20457 | -0.00300 |    0.14949 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16914 | -0.00437 |    0.12927 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25127 | -0.01107 |    0.16533 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14902 | -0.00046 |    0.11057 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12486 | -0.01378 |    0.10055 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15074 | -0.01447 |    0.11817 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11024 | -0.00536 |    0.08456 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12100 | -0.01382 |    0.09641 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11469 | -0.00226 |    0.09077 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14281 | -0.00821 |    0.10972 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10858 | -0.00977 |    0.08621 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09296 | -0.00573 |    0.07331 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09385 | -0.01114 |    0.07496 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05670 |  0.00245 |    0.04296 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57832 | -0.00001 |    0.45133 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:46:32,584 - Total sparsity: 0.00

2018-11-02 21:46:32,584 - --- validate (epoch=196)-----------
2018-11-02 21:46:32,584 - 10000 samples (128 per mini-batch)
2018-11-02 21:46:33,306 - Epoch: [196][   50/   78]    Loss 0.386126    Top1 90.312500    Top5 99.687500    
2018-11-02 21:46:33,727 - ==> Top1: 90.360    Top5: 99.670    Loss: 0.386

2018-11-02 21:46:33,728 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:46:33,728 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:46:33,735 - 

2018-11-02 21:46:33,735 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:46:34,772 - Epoch: [197][   50/  391]    Overall Loss 0.064909    Objective Loss 0.064909    Top1 97.796875    Top5 100.000000    LR 0.006083    Time 0.020710    
2018-11-02 21:46:35,751 - Epoch: [197][  100/  391]    Overall Loss 0.067298    Objective Loss 0.067298    Top1 97.695312    Top5 100.000000    LR 0.006083    Time 0.020122    
2018-11-02 21:46:36,732 - Epoch: [197][  150/  391]    Overall Loss 0.064446    Objective Loss 0.064446    Top1 97.817708    Top5 100.000000    LR 0.006083    Time 0.019950    
2018-11-02 21:46:37,749 - Epoch: [197][  200/  391]    Overall Loss 0.063047    Objective Loss 0.063047    Top1 97.863281    Top5 99.996094    LR 0.006083    Time 0.020043    
2018-11-02 21:46:38,797 - Epoch: [197][  250/  391]    Overall Loss 0.062363    Objective Loss 0.062363    Top1 97.887500    Top5 99.990625    LR 0.006083    Time 0.020218    
2018-11-02 21:46:39,784 - Epoch: [197][  300/  391]    Overall Loss 0.061798    Objective Loss 0.061798    Top1 97.916667    Top5 99.992188    LR 0.006083    Time 0.020123    
2018-11-02 21:46:40,839 - Epoch: [197][  350/  391]    Overall Loss 0.061777    Objective Loss 0.061777    Top1 97.910714    Top5 99.993304    LR 0.006083    Time 0.020258    
2018-11-02 21:46:41,771 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36279 | -0.00750 |    0.22944 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16199 | -0.00057 |    0.10226 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16192 | -0.00340 |    0.12272 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19490 | -0.04654 |    0.15162 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20795 |  0.00630 |    0.16392 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17373 | -0.02706 |    0.13257 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16944 | -0.00364 |    0.12373 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20416 | -0.00277 |    0.14917 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16880 | -0.00438 |    0.12900 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25075 | -0.01100 |    0.16480 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14872 | -0.00069 |    0.11040 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12461 | -0.01378 |    0.10035 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15045 | -0.01430 |    0.11792 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11002 | -0.00537 |    0.08441 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12076 | -0.01375 |    0.09620 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11446 | -0.00224 |    0.09059 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14251 | -0.00817 |    0.10950 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10838 | -0.00967 |    0.08604 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09279 | -0.00570 |    0.07315 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09368 | -0.01109 |    0.07482 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05658 |  0.00246 |    0.04286 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57865 | -0.00001 |    0.45147 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:46:41,771 - Total sparsity: 0.00

2018-11-02 21:46:41,771 - --- validate (epoch=197)-----------
2018-11-02 21:46:41,771 - 10000 samples (128 per mini-batch)
2018-11-02 21:46:42,500 - Epoch: [197][   50/   78]    Loss 0.380056    Top1 90.359375    Top5 99.609375    
2018-11-02 21:46:42,894 - ==> Top1: 90.380    Top5: 99.620    Loss: 0.383

2018-11-02 21:46:42,895 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:46:42,895 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:46:42,903 - 

2018-11-02 21:46:42,903 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:46:43,949 - Epoch: [198][   50/  391]    Overall Loss 0.059145    Objective Loss 0.059145    Top1 98.093750    Top5 100.000000    LR 0.005779    Time 0.020884    
2018-11-02 21:46:44,926 - Epoch: [198][  100/  391]    Overall Loss 0.062553    Objective Loss 0.062553    Top1 97.945312    Top5 99.992188    LR 0.005779    Time 0.020203    
2018-11-02 21:46:45,907 - Epoch: [198][  150/  391]    Overall Loss 0.061798    Objective Loss 0.061798    Top1 97.963542    Top5 99.994792    LR 0.005779    Time 0.019998    
2018-11-02 21:46:46,886 - Epoch: [198][  200/  391]    Overall Loss 0.061959    Objective Loss 0.061959    Top1 97.937500    Top5 99.988281    LR 0.005779    Time 0.019888    
2018-11-02 21:46:47,865 - Epoch: [198][  250/  391]    Overall Loss 0.061859    Objective Loss 0.061859    Top1 97.946875    Top5 99.987500    LR 0.005779    Time 0.019821    
2018-11-02 21:46:48,842 - Epoch: [198][  300/  391]    Overall Loss 0.061566    Objective Loss 0.061566    Top1 97.963542    Top5 99.989583    LR 0.005779    Time 0.019771    
2018-11-02 21:46:49,822 - Epoch: [198][  350/  391]    Overall Loss 0.061272    Objective Loss 0.061272    Top1 97.959821    Top5 99.988839    LR 0.005779    Time 0.019744    
2018-11-02 21:46:50,705 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36210 | -0.00621 |    0.22882 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16168 | -0.00027 |    0.10223 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16160 | -0.00367 |    0.12242 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19454 | -0.04634 |    0.15137 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20753 |  0.00666 |    0.16351 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17337 | -0.02720 |    0.13236 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16912 | -0.00329 |    0.12343 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20378 | -0.00259 |    0.14893 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16848 | -0.00421 |    0.12877 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25026 | -0.01072 |    0.16450 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14843 | -0.00059 |    0.11027 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12438 | -0.01366 |    0.10017 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15018 | -0.01424 |    0.11765 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10982 | -0.00525 |    0.08420 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12052 | -0.01378 |    0.09600 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11424 | -0.00230 |    0.09042 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14222 | -0.00816 |    0.10934 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10818 | -0.00964 |    0.08587 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09262 | -0.00567 |    0.07303 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09351 | -0.01108 |    0.07470 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05647 |  0.00246 |    0.04278 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57891 | -0.00001 |    0.45177 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:46:50,705 - Total sparsity: 0.00

2018-11-02 21:46:50,705 - --- validate (epoch=198)-----------
2018-11-02 21:46:50,705 - 10000 samples (128 per mini-batch)
2018-11-02 21:46:51,432 - Epoch: [198][   50/   78]    Loss 0.386324    Top1 90.250000    Top5 99.609375    
2018-11-02 21:46:51,823 - ==> Top1: 90.200    Top5: 99.660    Loss: 0.389

2018-11-02 21:46:51,824 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:46:51,824 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:46:51,835 - 

2018-11-02 21:46:51,836 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:46:52,874 - Epoch: [199][   50/  391]    Overall Loss 0.053780    Objective Loss 0.053780    Top1 97.953125    Top5 100.000000    LR 0.005490    Time 0.020726    
2018-11-02 21:46:53,852 - Epoch: [199][  100/  391]    Overall Loss 0.055034    Objective Loss 0.055034    Top1 97.953125    Top5 100.000000    LR 0.005490    Time 0.020127    
2018-11-02 21:46:54,830 - Epoch: [199][  150/  391]    Overall Loss 0.053710    Objective Loss 0.053710    Top1 98.031250    Top5 100.000000    LR 0.005490    Time 0.019929    
2018-11-02 21:46:55,810 - Epoch: [199][  200/  391]    Overall Loss 0.054568    Objective Loss 0.054568    Top1 98.050781    Top5 100.000000    LR 0.005490    Time 0.019836    
2018-11-02 21:46:56,791 - Epoch: [199][  250/  391]    Overall Loss 0.055332    Objective Loss 0.055332    Top1 98.056250    Top5 100.000000    LR 0.005490    Time 0.019788    
2018-11-02 21:46:57,769 - Epoch: [199][  300/  391]    Overall Loss 0.057066    Objective Loss 0.057066    Top1 98.015625    Top5 100.000000    LR 0.005490    Time 0.019747    
2018-11-02 21:46:58,748 - Epoch: [199][  350/  391]    Overall Loss 0.057669    Objective Loss 0.057669    Top1 98.015625    Top5 99.997768    LR 0.005490    Time 0.019720    
2018-11-02 21:46:59,649 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36142 | -0.00650 |    0.22844 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16138 | -0.00018 |    0.10191 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16130 | -0.00368 |    0.12219 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19410 | -0.04661 |    0.15118 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20715 |  0.00658 |    0.16308 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17311 | -0.02681 |    0.13203 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16881 | -0.00321 |    0.12327 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20340 | -0.00267 |    0.14863 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16817 | -0.00422 |    0.12851 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24977 | -0.01090 |    0.16417 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14816 | -0.00058 |    0.10996 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12415 | -0.01365 |    0.09993 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14990 | -0.01426 |    0.11741 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10962 | -0.00527 |    0.08402 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12029 | -0.01380 |    0.09581 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11404 | -0.00224 |    0.09026 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14195 | -0.00815 |    0.10914 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10798 | -0.00966 |    0.08571 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09247 | -0.00562 |    0.07289 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09333 | -0.01116 |    0.07457 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05636 |  0.00244 |    0.04270 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57917 | -0.00001 |    0.45195 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:46:59,650 - Total sparsity: 0.00

2018-11-02 21:46:59,650 - --- validate (epoch=199)-----------
2018-11-02 21:46:59,650 - 10000 samples (128 per mini-batch)
2018-11-02 21:47:00,375 - Epoch: [199][   50/   78]    Loss 0.386835    Top1 90.343750    Top5 99.687500    
2018-11-02 21:47:00,771 - ==> Top1: 90.340    Top5: 99.740    Loss: 0.387

2018-11-02 21:47:00,772 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:47:00,772 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:47:00,780 - 

2018-11-02 21:47:00,780 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:47:01,821 - Epoch: [200][   50/  391]    Overall Loss 0.058054    Objective Loss 0.058054    Top1 98.125000    Top5 100.000000    LR 0.005215    Time 0.020787    
2018-11-02 21:47:02,802 - Epoch: [200][  100/  391]    Overall Loss 0.055529    Objective Loss 0.055529    Top1 98.210938    Top5 100.000000    LR 0.005215    Time 0.020185    
2018-11-02 21:47:03,778 - Epoch: [200][  150/  391]    Overall Loss 0.056595    Objective Loss 0.056595    Top1 98.130208    Top5 100.000000    LR 0.005215    Time 0.019960    
2018-11-02 21:47:04,758 - Epoch: [200][  200/  391]    Overall Loss 0.056507    Objective Loss 0.056507    Top1 98.140625    Top5 99.996094    LR 0.005215    Time 0.019864    
2018-11-02 21:47:05,733 - Epoch: [200][  250/  391]    Overall Loss 0.057563    Objective Loss 0.057563    Top1 98.093750    Top5 99.996875    LR 0.005215    Time 0.019787    
2018-11-02 21:47:06,712 - Epoch: [200][  300/  391]    Overall Loss 0.057343    Objective Loss 0.057343    Top1 98.088542    Top5 99.997396    LR 0.005215    Time 0.019747    
2018-11-02 21:47:07,690 - Epoch: [200][  350/  391]    Overall Loss 0.057624    Objective Loss 0.057624    Top1 98.069196    Top5 99.997768    LR 0.005215    Time 0.019718    
2018-11-02 21:47:08,571 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36077 | -0.00615 |    0.22810 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16110 | -0.00014 |    0.10180 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16101 | -0.00382 |    0.12197 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19368 | -0.04685 |    0.15096 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20678 |  0.00665 |    0.16283 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17283 | -0.02659 |    0.13188 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16852 | -0.00311 |    0.12303 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20304 | -0.00256 |    0.14835 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16787 | -0.00425 |    0.12828 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24932 | -0.01082 |    0.16386 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14790 | -0.00059 |    0.10978 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12393 | -0.01364 |    0.09975 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14965 | -0.01416 |    0.11720 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10943 | -0.00522 |    0.08385 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12008 | -0.01375 |    0.09564 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11384 | -0.00231 |    0.09011 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14169 | -0.00812 |    0.10896 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10780 | -0.00954 |    0.08557 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09231 | -0.00562 |    0.07278 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09317 | -0.01117 |    0.07443 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05625 |  0.00245 |    0.04262 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57936 | -0.00001 |    0.45208 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:47:08,571 - Total sparsity: 0.00

2018-11-02 21:47:08,571 - --- validate (epoch=200)-----------
2018-11-02 21:47:08,571 - 10000 samples (128 per mini-batch)
2018-11-02 21:47:09,297 - Epoch: [200][   50/   78]    Loss 0.389833    Top1 90.171875    Top5 99.593750    
2018-11-02 21:47:09,691 - ==> Top1: 90.180    Top5: 99.640    Loss: 0.390

2018-11-02 21:47:09,692 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:47:09,692 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:47:09,704 - 

2018-11-02 21:47:09,704 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:47:10,741 - Epoch: [201][   50/  391]    Overall Loss 0.054851    Objective Loss 0.054851    Top1 98.156250    Top5 100.000000    LR 0.004955    Time 0.020704    
2018-11-02 21:47:11,720 - Epoch: [201][  100/  391]    Overall Loss 0.056391    Objective Loss 0.056391    Top1 98.125000    Top5 100.000000    LR 0.004955    Time 0.020130    
2018-11-02 21:47:12,701 - Epoch: [201][  150/  391]    Overall Loss 0.057360    Objective Loss 0.057360    Top1 98.125000    Top5 100.000000    LR 0.004955    Time 0.019947    
2018-11-02 21:47:13,681 - Epoch: [201][  200/  391]    Overall Loss 0.058044    Objective Loss 0.058044    Top1 98.085938    Top5 100.000000    LR 0.004955    Time 0.019856    
2018-11-02 21:47:14,659 - Epoch: [201][  250/  391]    Overall Loss 0.057814    Objective Loss 0.057814    Top1 98.106250    Top5 100.000000    LR 0.004955    Time 0.019790    
2018-11-02 21:47:15,637 - Epoch: [201][  300/  391]    Overall Loss 0.058734    Objective Loss 0.058734    Top1 98.070312    Top5 100.000000    LR 0.004955    Time 0.019748    
2018-11-02 21:47:16,617 - Epoch: [201][  350/  391]    Overall Loss 0.057462    Objective Loss 0.057462    Top1 98.118304    Top5 100.000000    LR 0.004955    Time 0.019725    
2018-11-02 21:47:17,503 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36015 | -0.00613 |    0.22774 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16082 |  0.00014 |    0.10157 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16074 | -0.00334 |    0.12176 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19340 | -0.04657 |    0.15076 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20643 |  0.00645 |    0.16251 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17256 | -0.02644 |    0.13172 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16823 | -0.00315 |    0.12278 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20269 | -0.00271 |    0.14808 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16758 | -0.00432 |    0.12805 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24889 | -0.01058 |    0.16361 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14765 | -0.00036 |    0.10960 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12372 | -0.01366 |    0.09955 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14940 | -0.01411 |    0.11698 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10924 | -0.00517 |    0.08376 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11988 | -0.01363 |    0.09547 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11365 | -0.00234 |    0.08997 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14144 | -0.00800 |    0.10876 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10762 | -0.00955 |    0.08543 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09216 | -0.00566 |    0.07267 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09302 | -0.01122 |    0.07432 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05616 |  0.00244 |    0.04256 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57959 | -0.00001 |    0.45221 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:47:17,504 - Total sparsity: 0.00

2018-11-02 21:47:17,504 - --- validate (epoch=201)-----------
2018-11-02 21:47:17,504 - 10000 samples (128 per mini-batch)
2018-11-02 21:47:18,232 - Epoch: [201][   50/   78]    Loss 0.383650    Top1 90.484375    Top5 99.609375    
2018-11-02 21:47:18,623 - ==> Top1: 90.390    Top5: 99.640    Loss: 0.387

2018-11-02 21:47:18,624 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:47:18,624 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:47:18,631 - 

2018-11-02 21:47:18,631 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:47:19,670 - Epoch: [202][   50/  391]    Overall Loss 0.053281    Objective Loss 0.053281    Top1 98.187500    Top5 99.984375    LR 0.004707    Time 0.020744    
2018-11-02 21:47:20,649 - Epoch: [202][  100/  391]    Overall Loss 0.055826    Objective Loss 0.055826    Top1 98.117188    Top5 99.992188    LR 0.004707    Time 0.020152    
2018-11-02 21:47:21,631 - Epoch: [202][  150/  391]    Overall Loss 0.055054    Objective Loss 0.055054    Top1 98.208333    Top5 99.989583    LR 0.004707    Time 0.019972    
2018-11-02 21:47:22,610 - Epoch: [202][  200/  391]    Overall Loss 0.054857    Objective Loss 0.054857    Top1 98.207031    Top5 99.992188    LR 0.004707    Time 0.019866    
2018-11-02 21:47:23,590 - Epoch: [202][  250/  391]    Overall Loss 0.056405    Objective Loss 0.056405    Top1 98.168750    Top5 99.993750    LR 0.004707    Time 0.019808    
2018-11-02 21:47:24,568 - Epoch: [202][  300/  391]    Overall Loss 0.057088    Objective Loss 0.057088    Top1 98.091146    Top5 99.992188    LR 0.004707    Time 0.019760    
2018-11-02 21:47:25,547 - Epoch: [202][  350/  391]    Overall Loss 0.056998    Objective Loss 0.056998    Top1 98.093750    Top5 99.991071    LR 0.004707    Time 0.019730    
2018-11-02 21:47:26,426 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35956 | -0.00574 |    0.22745 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16056 | -0.00006 |    0.10141 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16048 | -0.00347 |    0.12153 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19309 | -0.04648 |    0.15056 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20608 |  0.00687 |    0.16228 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17228 | -0.02638 |    0.13139 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16796 | -0.00319 |    0.12252 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20237 | -0.00250 |    0.14782 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16731 | -0.00420 |    0.12785 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24849 | -0.01036 |    0.16334 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14741 | -0.00043 |    0.10947 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12353 | -0.01353 |    0.09940 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14916 | -0.01414 |    0.11680 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10907 | -0.00521 |    0.08367 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11969 | -0.01360 |    0.09531 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11347 | -0.00228 |    0.08983 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14121 | -0.00795 |    0.10855 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10745 | -0.00954 |    0.08530 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09202 | -0.00566 |    0.07255 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09288 | -0.01115 |    0.07419 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05606 |  0.00242 |    0.04249 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57971 | -0.00001 |    0.45230 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:47:26,426 - Total sparsity: 0.00

2018-11-02 21:47:26,426 - --- validate (epoch=202)-----------
2018-11-02 21:47:26,427 - 10000 samples (128 per mini-batch)
2018-11-02 21:47:27,151 - Epoch: [202][   50/   78]    Loss 0.382913    Top1 90.531250    Top5 99.625000    
2018-11-02 21:47:27,539 - ==> Top1: 90.310    Top5: 99.680    Loss: 0.389

2018-11-02 21:47:27,540 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:47:27,540 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:47:27,547 - 

2018-11-02 21:47:27,548 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:47:28,584 - Epoch: [203][   50/  391]    Overall Loss 0.051234    Objective Loss 0.051234    Top1 98.296875    Top5 100.000000    LR 0.004472    Time 0.020687    
2018-11-02 21:47:29,590 - Epoch: [203][  100/  391]    Overall Loss 0.053746    Objective Loss 0.053746    Top1 98.226562    Top5 99.992188    LR 0.004472    Time 0.020389    
2018-11-02 21:47:30,570 - Epoch: [203][  150/  391]    Overall Loss 0.053640    Objective Loss 0.053640    Top1 98.250000    Top5 99.994792    LR 0.004472    Time 0.020122    
2018-11-02 21:47:31,549 - Epoch: [203][  200/  391]    Overall Loss 0.055872    Objective Loss 0.055872    Top1 98.144531    Top5 99.992188    LR 0.004472    Time 0.019980    
2018-11-02 21:47:32,527 - Epoch: [203][  250/  391]    Overall Loss 0.055706    Objective Loss 0.055706    Top1 98.159375    Top5 99.990625    LR 0.004472    Time 0.019889    
2018-11-02 21:47:33,505 - Epoch: [203][  300/  391]    Overall Loss 0.055574    Objective Loss 0.055574    Top1 98.171875    Top5 99.992188    LR 0.004472    Time 0.019816    
2018-11-02 21:47:34,481 - Epoch: [203][  350/  391]    Overall Loss 0.054949    Objective Loss 0.054949    Top1 98.167411    Top5 99.993304    LR 0.004472    Time 0.019771    
2018-11-02 21:47:35,364 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35900 | -0.00583 |    0.22708 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16031 |  0.00029 |    0.10125 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16023 | -0.00325 |    0.12133 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19280 | -0.04632 |    0.15033 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20576 |  0.00657 |    0.16194 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17203 | -0.02626 |    0.13127 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16770 | -0.00331 |    0.12235 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20206 | -0.00229 |    0.14769 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16705 | -0.00423 |    0.12760 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24809 | -0.01029 |    0.16310 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14718 | -0.00048 |    0.10929 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12334 | -0.01345 |    0.09921 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14895 | -0.01396 |    0.11658 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10891 | -0.00509 |    0.08357 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11950 | -0.01364 |    0.09517 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11329 | -0.00223 |    0.08968 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14098 | -0.00794 |    0.10837 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10729 | -0.00947 |    0.08518 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09188 | -0.00564 |    0.07244 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09274 | -0.01114 |    0.07409 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05597 |  0.00243 |    0.04242 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57994 | -0.00001 |    0.45251 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:47:35,364 - Total sparsity: 0.00

2018-11-02 21:47:35,364 - --- validate (epoch=203)-----------
2018-11-02 21:47:35,365 - 10000 samples (128 per mini-batch)
2018-11-02 21:47:36,092 - Epoch: [203][   50/   78]    Loss 0.383983    Top1 90.421875    Top5 99.734375    
2018-11-02 21:47:36,484 - ==> Top1: 90.370    Top5: 99.750    Loss: 0.387

2018-11-02 21:47:36,485 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:47:36,485 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:47:36,493 - 

2018-11-02 21:47:36,493 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:47:37,531 - Epoch: [204][   50/  391]    Overall Loss 0.052064    Objective Loss 0.052064    Top1 98.484375    Top5 99.984375    LR 0.004248    Time 0.020729    
2018-11-02 21:47:38,508 - Epoch: [204][  100/  391]    Overall Loss 0.052592    Objective Loss 0.052592    Top1 98.281250    Top5 99.992188    LR 0.004248    Time 0.020119    
2018-11-02 21:47:39,485 - Epoch: [204][  150/  391]    Overall Loss 0.052470    Objective Loss 0.052470    Top1 98.286458    Top5 99.994792    LR 0.004248    Time 0.019916    
2018-11-02 21:47:40,464 - Epoch: [204][  200/  391]    Overall Loss 0.051331    Objective Loss 0.051331    Top1 98.324219    Top5 99.996094    LR 0.004248    Time 0.019825    
2018-11-02 21:47:41,445 - Epoch: [204][  250/  391]    Overall Loss 0.050779    Objective Loss 0.050779    Top1 98.325000    Top5 99.996875    LR 0.004248    Time 0.019781    
2018-11-02 21:47:42,425 - Epoch: [204][  300/  391]    Overall Loss 0.050894    Objective Loss 0.050894    Top1 98.309896    Top5 99.994792    LR 0.004248    Time 0.019744    
2018-11-02 21:47:43,402 - Epoch: [204][  350/  391]    Overall Loss 0.051646    Objective Loss 0.051646    Top1 98.274554    Top5 99.995536    LR 0.004248    Time 0.019712    
2018-11-02 21:47:44,284 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35845 | -0.00560 |    0.22672 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16006 |  0.00009 |    0.10107 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15999 | -0.00334 |    0.12115 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19254 | -0.04615 |    0.15012 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20545 |  0.00664 |    0.16169 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17181 | -0.02598 |    0.13111 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16745 | -0.00326 |    0.12223 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20176 | -0.00228 |    0.14753 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16680 | -0.00413 |    0.12738 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24771 | -0.01018 |    0.16291 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14696 | -0.00048 |    0.10911 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12317 | -0.01339 |    0.09906 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14874 | -0.01382 |    0.11647 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10874 | -0.00506 |    0.08345 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11933 | -0.01354 |    0.09502 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11313 | -0.00222 |    0.08954 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14077 | -0.00792 |    0.10819 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10714 | -0.00942 |    0.08505 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09175 | -0.00561 |    0.07234 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09261 | -0.01109 |    0.07399 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05589 |  0.00246 |    0.04235 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58019 | -0.00001 |    0.45267 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:47:44,284 - Total sparsity: 0.00

2018-11-02 21:47:44,284 - --- validate (epoch=204)-----------
2018-11-02 21:47:44,284 - 10000 samples (128 per mini-batch)
2018-11-02 21:47:45,012 - Epoch: [204][   50/   78]    Loss 0.400015    Top1 90.484375    Top5 99.609375    
2018-11-02 21:47:45,403 - ==> Top1: 90.420    Top5: 99.640    Loss: 0.397

2018-11-02 21:47:45,404 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:47:45,404 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:47:45,412 - 

2018-11-02 21:47:45,412 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:47:46,453 - Epoch: [205][   50/  391]    Overall Loss 0.053572    Objective Loss 0.053572    Top1 98.406250    Top5 100.000000    LR 0.004036    Time 0.020792    
2018-11-02 21:47:47,432 - Epoch: [205][  100/  391]    Overall Loss 0.050725    Objective Loss 0.050725    Top1 98.406250    Top5 100.000000    LR 0.004036    Time 0.020166    
2018-11-02 21:47:48,410 - Epoch: [205][  150/  391]    Overall Loss 0.051333    Objective Loss 0.051333    Top1 98.390625    Top5 99.989583    LR 0.004036    Time 0.019957    
2018-11-02 21:47:49,388 - Epoch: [205][  200/  391]    Overall Loss 0.052173    Objective Loss 0.052173    Top1 98.328125    Top5 99.992188    LR 0.004036    Time 0.019849    
2018-11-02 21:47:50,368 - Epoch: [205][  250/  391]    Overall Loss 0.051858    Objective Loss 0.051858    Top1 98.346875    Top5 99.993750    LR 0.004036    Time 0.019793    
2018-11-02 21:47:51,345 - Epoch: [205][  300/  391]    Overall Loss 0.052908    Objective Loss 0.052908    Top1 98.278646    Top5 99.994792    LR 0.004036    Time 0.019746    
2018-11-02 21:47:52,322 - Epoch: [205][  350/  391]    Overall Loss 0.052529    Objective Loss 0.052529    Top1 98.267857    Top5 99.995536    LR 0.004036    Time 0.019715    
2018-11-02 21:47:53,204 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35794 | -0.00557 |    0.22631 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15984 | -0.00012 |    0.10086 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15975 | -0.00358 |    0.12100 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19229 | -0.04601 |    0.14989 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20515 |  0.00693 |    0.16143 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17159 | -0.02584 |    0.13085 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16721 | -0.00341 |    0.12212 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20147 | -0.00235 |    0.14730 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16657 | -0.00409 |    0.12721 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24735 | -0.01022 |    0.16278 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14676 | -0.00038 |    0.10891 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12299 | -0.01334 |    0.09894 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14853 | -0.01374 |    0.11632 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10860 | -0.00497 |    0.08332 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11916 | -0.01348 |    0.09489 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11297 | -0.00223 |    0.08941 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14056 | -0.00785 |    0.10802 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10699 | -0.00941 |    0.08492 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09163 | -0.00565 |    0.07223 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09249 | -0.01107 |    0.07389 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05580 |  0.00244 |    0.04229 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58034 | -0.00001 |    0.45284 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:47:53,204 - Total sparsity: 0.00

2018-11-02 21:47:53,204 - --- validate (epoch=205)-----------
2018-11-02 21:47:53,204 - 10000 samples (128 per mini-batch)
2018-11-02 21:47:53,921 - Epoch: [205][   50/   78]    Loss 0.401594    Top1 90.296875    Top5 99.640625    
2018-11-02 21:47:54,309 - ==> Top1: 90.290    Top5: 99.670    Loss: 0.400

2018-11-02 21:47:54,310 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:47:54,310 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:47:54,317 - 

2018-11-02 21:47:54,318 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:47:55,353 - Epoch: [206][   50/  391]    Overall Loss 0.053233    Objective Loss 0.053233    Top1 98.093750    Top5 99.968750    LR 0.003834    Time 0.020683    
2018-11-02 21:47:56,333 - Epoch: [206][  100/  391]    Overall Loss 0.051143    Objective Loss 0.051143    Top1 98.234375    Top5 99.984375    LR 0.003834    Time 0.020125    
2018-11-02 21:47:57,327 - Epoch: [206][  150/  391]    Overall Loss 0.051557    Objective Loss 0.051557    Top1 98.223958    Top5 99.984375    LR 0.003834    Time 0.020036    
2018-11-02 21:47:58,307 - Epoch: [206][  200/  391]    Overall Loss 0.051578    Objective Loss 0.051578    Top1 98.265625    Top5 99.988281    LR 0.003834    Time 0.019921    
2018-11-02 21:47:59,287 - Epoch: [206][  250/  391]    Overall Loss 0.051015    Objective Loss 0.051015    Top1 98.296875    Top5 99.990625    LR 0.003834    Time 0.019853    
2018-11-02 21:48:00,268 - Epoch: [206][  300/  391]    Overall Loss 0.051931    Objective Loss 0.051931    Top1 98.231771    Top5 99.992188    LR 0.003834    Time 0.019797    
2018-11-02 21:48:01,249 - Epoch: [206][  350/  391]    Overall Loss 0.051805    Objective Loss 0.051805    Top1 98.279018    Top5 99.986607    LR 0.003834    Time 0.019767    
2018-11-02 21:48:02,128 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35744 | -0.00612 |    0.22593 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15962 | -0.00002 |    0.10070 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15953 | -0.00365 |    0.12093 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19198 | -0.04612 |    0.14967 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20487 |  0.00683 |    0.16120 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17131 | -0.02611 |    0.13068 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16698 | -0.00348 |    0.12202 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20120 | -0.00232 |    0.14716 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16634 | -0.00424 |    0.12705 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24700 | -0.01037 |    0.16239 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14656 | -0.00047 |    0.10878 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12282 | -0.01336 |    0.09878 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14832 | -0.01385 |    0.11616 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10845 | -0.00505 |    0.08321 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11899 | -0.01353 |    0.09477 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11282 | -0.00222 |    0.08929 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14037 | -0.00785 |    0.10784 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10685 | -0.00940 |    0.08481 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09151 | -0.00561 |    0.07215 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09236 | -0.01112 |    0.07380 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05573 |  0.00244 |    0.04223 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58054 | -0.00001 |    0.45297 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:48:02,129 - Total sparsity: 0.00

2018-11-02 21:48:02,129 - --- validate (epoch=206)-----------
2018-11-02 21:48:02,129 - 10000 samples (128 per mini-batch)
2018-11-02 21:48:02,851 - Epoch: [206][   50/   78]    Loss 0.395823    Top1 90.031250    Top5 99.640625    
2018-11-02 21:48:03,245 - ==> Top1: 90.180    Top5: 99.690    Loss: 0.394

2018-11-02 21:48:03,246 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:48:03,246 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:48:03,258 - 

2018-11-02 21:48:03,258 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:48:04,298 - Epoch: [207][   50/  391]    Overall Loss 0.054672    Objective Loss 0.054672    Top1 98.000000    Top5 100.000000    LR 0.003642    Time 0.020750    
2018-11-02 21:48:05,278 - Epoch: [207][  100/  391]    Overall Loss 0.050406    Objective Loss 0.050406    Top1 98.304688    Top5 99.992188    LR 0.003642    Time 0.020158    
2018-11-02 21:48:06,256 - Epoch: [207][  150/  391]    Overall Loss 0.050538    Objective Loss 0.050538    Top1 98.281250    Top5 99.989583    LR 0.003642    Time 0.019953    
2018-11-02 21:48:07,234 - Epoch: [207][  200/  391]    Overall Loss 0.050492    Objective Loss 0.050492    Top1 98.304688    Top5 99.992188    LR 0.003642    Time 0.019848    
2018-11-02 21:48:08,212 - Epoch: [207][  250/  391]    Overall Loss 0.050548    Objective Loss 0.050548    Top1 98.300000    Top5 99.993750    LR 0.003642    Time 0.019782    
2018-11-02 21:48:09,190 - Epoch: [207][  300/  391]    Overall Loss 0.050697    Objective Loss 0.050697    Top1 98.307292    Top5 99.994792    LR 0.003642    Time 0.019740    
2018-11-02 21:48:10,168 - Epoch: [207][  350/  391]    Overall Loss 0.050542    Objective Loss 0.050542    Top1 98.325893    Top5 99.995536    LR 0.003642    Time 0.019712    
2018-11-02 21:48:11,053 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35697 | -0.00673 |    0.22594 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15941 |  0.00014 |    0.10059 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15933 | -0.00357 |    0.12072 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19171 | -0.04617 |    0.14954 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20461 |  0.00665 |    0.16095 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17108 | -0.02616 |    0.13057 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16676 | -0.00356 |    0.12182 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20094 | -0.00220 |    0.14703 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16612 | -0.00423 |    0.12689 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24667 | -0.01043 |    0.16208 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14637 | -0.00031 |    0.10866 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12265 | -0.01343 |    0.09868 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14812 | -0.01394 |    0.11596 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10830 | -0.00508 |    0.08312 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11883 | -0.01356 |    0.09463 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11267 | -0.00222 |    0.08918 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14018 | -0.00784 |    0.10770 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10671 | -0.00937 |    0.08471 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09140 | -0.00558 |    0.07205 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09225 | -0.01107 |    0.07372 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05565 |  0.00245 |    0.04218 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58075 | -0.00001 |    0.45309 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:48:11,053 - Total sparsity: 0.00

2018-11-02 21:48:11,053 - --- validate (epoch=207)-----------
2018-11-02 21:48:11,053 - 10000 samples (128 per mini-batch)
2018-11-02 21:48:11,780 - Epoch: [207][   50/   78]    Loss 0.391134    Top1 90.343750    Top5 99.703125    
2018-11-02 21:48:12,175 - ==> Top1: 90.380    Top5: 99.730    Loss: 0.389

2018-11-02 21:48:12,176 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:48:12,176 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:48:12,183 - 

2018-11-02 21:48:12,184 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:48:13,223 - Epoch: [208][   50/  391]    Overall Loss 0.044867    Objective Loss 0.044867    Top1 98.562500    Top5 100.000000    LR 0.003460    Time 0.020748    
2018-11-02 21:48:14,197 - Epoch: [208][  100/  391]    Overall Loss 0.045906    Objective Loss 0.045906    Top1 98.453125    Top5 100.000000    LR 0.003460    Time 0.020102    
2018-11-02 21:48:15,175 - Epoch: [208][  150/  391]    Overall Loss 0.047219    Objective Loss 0.047219    Top1 98.432292    Top5 100.000000    LR 0.003460    Time 0.019910    
2018-11-02 21:48:16,155 - Epoch: [208][  200/  391]    Overall Loss 0.047823    Objective Loss 0.047823    Top1 98.433594    Top5 100.000000    LR 0.003460    Time 0.019826    
2018-11-02 21:48:17,133 - Epoch: [208][  250/  391]    Overall Loss 0.048443    Objective Loss 0.048443    Top1 98.396875    Top5 100.000000    LR 0.003460    Time 0.019768    
2018-11-02 21:48:18,113 - Epoch: [208][  300/  391]    Overall Loss 0.048895    Objective Loss 0.048895    Top1 98.388021    Top5 100.000000    LR 0.003460    Time 0.019735    
2018-11-02 21:48:19,091 - Epoch: [208][  350/  391]    Overall Loss 0.048712    Objective Loss 0.048712    Top1 98.395089    Top5 99.997768    LR 0.003460    Time 0.019706    
2018-11-02 21:48:19,975 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35653 | -0.00629 |    0.22563 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15921 | -0.00031 |    0.10038 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15912 | -0.00394 |    0.12056 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19149 | -0.04602 |    0.14931 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20435 |  0.00659 |    0.16085 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17085 | -0.02622 |    0.13046 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16656 | -0.00351 |    0.12166 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20069 | -0.00244 |    0.14683 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16592 | -0.00423 |    0.12676 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24636 | -0.01038 |    0.16180 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14619 | -0.00060 |    0.10849 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12249 | -0.01351 |    0.09860 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14795 | -0.01387 |    0.11584 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10817 | -0.00508 |    0.08303 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11869 | -0.01354 |    0.09452 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11253 | -0.00224 |    0.08907 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14000 | -0.00781 |    0.10754 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10659 | -0.00930 |    0.08460 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09129 | -0.00561 |    0.07197 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09214 | -0.01104 |    0.07364 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05558 |  0.00247 |    0.04213 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58089 | -0.00001 |    0.45322 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:48:19,975 - Total sparsity: 0.00

2018-11-02 21:48:19,975 - --- validate (epoch=208)-----------
2018-11-02 21:48:19,975 - 10000 samples (128 per mini-batch)
2018-11-02 21:48:20,700 - Epoch: [208][   50/   78]    Loss 0.396017    Top1 90.406250    Top5 99.656250    
2018-11-02 21:48:21,099 - ==> Top1: 90.360    Top5: 99.690    Loss: 0.394

2018-11-02 21:48:21,099 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:48:21,099 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:48:21,107 - 

2018-11-02 21:48:21,107 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:48:22,146 - Epoch: [209][   50/  391]    Overall Loss 0.048889    Objective Loss 0.048889    Top1 98.343750    Top5 100.000000    LR 0.003287    Time 0.020739    
2018-11-02 21:48:23,122 - Epoch: [209][  100/  391]    Overall Loss 0.047175    Objective Loss 0.047175    Top1 98.453125    Top5 100.000000    LR 0.003287    Time 0.020121    
2018-11-02 21:48:24,099 - Epoch: [209][  150/  391]    Overall Loss 0.049181    Objective Loss 0.049181    Top1 98.328125    Top5 100.000000    LR 0.003287    Time 0.019919    
2018-11-02 21:48:25,110 - Epoch: [209][  200/  391]    Overall Loss 0.050492    Objective Loss 0.050492    Top1 98.257812    Top5 100.000000    LR 0.003287    Time 0.019987    
2018-11-02 21:48:26,088 - Epoch: [209][  250/  391]    Overall Loss 0.050470    Objective Loss 0.050470    Top1 98.246875    Top5 100.000000    LR 0.003287    Time 0.019898    
2018-11-02 21:48:27,067 - Epoch: [209][  300/  391]    Overall Loss 0.050401    Objective Loss 0.050401    Top1 98.263021    Top5 100.000000    LR 0.003287    Time 0.019840    
2018-11-02 21:48:28,044 - Epoch: [209][  350/  391]    Overall Loss 0.050488    Objective Loss 0.050488    Top1 98.252232    Top5 100.000000    LR 0.003287    Time 0.019792    
2018-11-02 21:48:28,929 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35610 | -0.00639 |    0.22525 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15902 | -0.00029 |    0.10029 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15893 | -0.00383 |    0.12040 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19130 | -0.04581 |    0.14915 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20411 |  0.00674 |    0.16059 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17066 | -0.02611 |    0.13027 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16636 | -0.00359 |    0.12153 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20045 | -0.00254 |    0.14666 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16572 | -0.00426 |    0.12663 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24607 | -0.01019 |    0.16159 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14602 | -0.00047 |    0.10829 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12235 | -0.01347 |    0.09846 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14778 | -0.01381 |    0.11575 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10805 | -0.00499 |    0.08290 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11854 | -0.01353 |    0.09440 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11240 | -0.00222 |    0.08897 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13983 | -0.00781 |    0.10743 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10646 | -0.00932 |    0.08450 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09119 | -0.00556 |    0.07189 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09203 | -0.01106 |    0.07356 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05551 |  0.00245 |    0.04208 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58099 | -0.00001 |    0.45334 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:48:28,929 - Total sparsity: 0.00

2018-11-02 21:48:28,929 - --- validate (epoch=209)-----------
2018-11-02 21:48:28,929 - 10000 samples (128 per mini-batch)
2018-11-02 21:48:29,653 - Epoch: [209][   50/   78]    Loss 0.392416    Top1 90.453125    Top5 99.609375    
2018-11-02 21:48:30,047 - ==> Top1: 90.400    Top5: 99.660    Loss: 0.393

2018-11-02 21:48:30,048 - ==> Best Top1: 90.430   On Epoch: 195

2018-11-02 21:48:30,048 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:48:30,059 - 

2018-11-02 21:48:30,060 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:48:31,098 - Epoch: [210][   50/  391]    Overall Loss 0.049798    Objective Loss 0.049798    Top1 98.406250    Top5 100.000000    LR 0.003123    Time 0.020739    
2018-11-02 21:48:32,079 - Epoch: [210][  100/  391]    Overall Loss 0.050565    Objective Loss 0.050565    Top1 98.398438    Top5 100.000000    LR 0.003123    Time 0.020164    
2018-11-02 21:48:33,061 - Epoch: [210][  150/  391]    Overall Loss 0.050676    Objective Loss 0.050676    Top1 98.364583    Top5 100.000000    LR 0.003123    Time 0.019981    
2018-11-02 21:48:34,041 - Epoch: [210][  200/  391]    Overall Loss 0.049864    Objective Loss 0.049864    Top1 98.398438    Top5 100.000000    LR 0.003123    Time 0.019879    
2018-11-02 21:48:35,020 - Epoch: [210][  250/  391]    Overall Loss 0.050574    Objective Loss 0.050574    Top1 98.334375    Top5 100.000000    LR 0.003123    Time 0.019812    
2018-11-02 21:48:35,998 - Epoch: [210][  300/  391]    Overall Loss 0.050833    Objective Loss 0.050833    Top1 98.312500    Top5 100.000000    LR 0.003123    Time 0.019768    
2018-11-02 21:48:36,978 - Epoch: [210][  350/  391]    Overall Loss 0.050352    Objective Loss 0.050352    Top1 98.345982    Top5 100.000000    LR 0.003123    Time 0.019741    
2018-11-02 21:48:37,861 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35570 | -0.00643 |    0.22490 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15884 | -0.00059 |    0.10014 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15875 | -0.00383 |    0.12020 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19107 | -0.04584 |    0.14898 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20388 |  0.00658 |    0.16044 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17048 | -0.02602 |    0.13011 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16617 | -0.00362 |    0.12137 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20022 | -0.00250 |    0.14646 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16553 | -0.00428 |    0.12651 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24579 | -0.01009 |    0.16149 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14586 | -0.00048 |    0.10817 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12222 | -0.01344 |    0.09833 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14761 | -0.01386 |    0.11562 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10793 | -0.00496 |    0.08278 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11841 | -0.01349 |    0.09431 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11228 | -0.00226 |    0.08887 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13967 | -0.00779 |    0.10729 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10635 | -0.00929 |    0.08441 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09109 | -0.00557 |    0.07181 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09193 | -0.01107 |    0.07349 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05545 |  0.00245 |    0.04203 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58114 | -0.00001 |    0.45344 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:48:37,861 - Total sparsity: 0.00

2018-11-02 21:48:37,861 - --- validate (epoch=210)-----------
2018-11-02 21:48:37,862 - 10000 samples (128 per mini-batch)
2018-11-02 21:48:38,586 - Epoch: [210][   50/   78]    Loss 0.394336    Top1 90.593750    Top5 99.609375    
2018-11-02 21:48:38,979 - ==> Top1: 90.490    Top5: 99.680    Loss: 0.395

2018-11-02 21:48:38,980 - ==> Best Top1: 90.490   On Epoch: 210

2018-11-02 21:48:38,980 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:48:38,990 - 

2018-11-02 21:48:38,990 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:48:40,050 - Epoch: [211][   50/  391]    Overall Loss 0.049439    Objective Loss 0.049439    Top1 98.390625    Top5 100.000000    LR 0.002967    Time 0.021151    
2018-11-02 21:48:41,049 - Epoch: [211][  100/  391]    Overall Loss 0.048235    Objective Loss 0.048235    Top1 98.453125    Top5 100.000000    LR 0.002967    Time 0.020555    
2018-11-02 21:48:42,106 - Epoch: [211][  150/  391]    Overall Loss 0.047553    Objective Loss 0.047553    Top1 98.484375    Top5 100.000000    LR 0.002967    Time 0.020744    
2018-11-02 21:48:43,161 - Epoch: [211][  200/  391]    Overall Loss 0.048427    Objective Loss 0.048427    Top1 98.445312    Top5 100.000000    LR 0.002967    Time 0.020827    
2018-11-02 21:48:44,210 - Epoch: [211][  250/  391]    Overall Loss 0.047437    Objective Loss 0.047437    Top1 98.493750    Top5 100.000000    LR 0.002967    Time 0.020836    
2018-11-02 21:48:45,244 - Epoch: [211][  300/  391]    Overall Loss 0.046321    Objective Loss 0.046321    Top1 98.515625    Top5 99.997396    LR 0.002967    Time 0.020809    
2018-11-02 21:48:46,226 - Epoch: [211][  350/  391]    Overall Loss 0.046421    Objective Loss 0.046421    Top1 98.495536    Top5 99.997768    LR 0.002967    Time 0.020636    
2018-11-02 21:48:47,115 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35532 | -0.00610 |    0.22478 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15867 | -0.00058 |    0.10008 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15858 | -0.00379 |    0.12007 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19081 | -0.04602 |    0.14882 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20366 |  0.00664 |    0.16027 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17028 | -0.02614 |    0.12994 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16599 | -0.00367 |    0.12123 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20001 | -0.00242 |    0.14631 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16536 | -0.00420 |    0.12639 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24552 | -0.01013 |    0.16132 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14570 | -0.00040 |    0.10805 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12209 | -0.01340 |    0.09825 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14746 | -0.01375 |    0.11550 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10782 | -0.00483 |    0.08267 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11829 | -0.01346 |    0.09421 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11216 | -0.00228 |    0.08878 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13952 | -0.00776 |    0.10717 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10624 | -0.00925 |    0.08431 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09099 | -0.00556 |    0.07174 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09183 | -0.01105 |    0.07340 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05539 |  0.00245 |    0.04199 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58127 | -0.00001 |    0.45354 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:48:47,115 - Total sparsity: 0.00

2018-11-02 21:48:47,115 - --- validate (epoch=211)-----------
2018-11-02 21:48:47,115 - 10000 samples (128 per mini-batch)
2018-11-02 21:48:47,835 - Epoch: [211][   50/   78]    Loss 0.395950    Top1 90.484375    Top5 99.687500    
2018-11-02 21:48:48,229 - ==> Top1: 90.460    Top5: 99.690    Loss: 0.399

2018-11-02 21:48:48,233 - ==> Best Top1: 90.490   On Epoch: 210

2018-11-02 21:48:48,234 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:48:48,241 - 

2018-11-02 21:48:48,242 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:48:49,280 - Epoch: [212][   50/  391]    Overall Loss 0.050437    Objective Loss 0.050437    Top1 98.406250    Top5 100.000000    LR 0.002818    Time 0.020731    
2018-11-02 21:48:50,259 - Epoch: [212][  100/  391]    Overall Loss 0.044716    Objective Loss 0.044716    Top1 98.625000    Top5 100.000000    LR 0.002818    Time 0.020140    
2018-11-02 21:48:51,238 - Epoch: [212][  150/  391]    Overall Loss 0.043375    Objective Loss 0.043375    Top1 98.666667    Top5 100.000000    LR 0.002818    Time 0.019945    
2018-11-02 21:48:52,216 - Epoch: [212][  200/  391]    Overall Loss 0.045233    Objective Loss 0.045233    Top1 98.574219    Top5 100.000000    LR 0.002818    Time 0.019843    
2018-11-02 21:48:53,192 - Epoch: [212][  250/  391]    Overall Loss 0.045544    Objective Loss 0.045544    Top1 98.546875    Top5 100.000000    LR 0.002818    Time 0.019771    
2018-11-02 21:48:54,171 - Epoch: [212][  300/  391]    Overall Loss 0.046188    Objective Loss 0.046188    Top1 98.515625    Top5 99.997396    LR 0.002818    Time 0.019738    
2018-11-02 21:48:55,163 - Epoch: [212][  350/  391]    Overall Loss 0.046744    Objective Loss 0.046744    Top1 98.488839    Top5 99.997768    LR 0.002818    Time 0.019747    
2018-11-02 21:48:56,098 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35495 | -0.00623 |    0.22443 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15851 | -0.00052 |    0.09997 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15842 | -0.00376 |    0.11992 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19063 | -0.04589 |    0.14860 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20345 |  0.00665 |    0.16015 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17010 | -0.02612 |    0.12978 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16582 | -0.00377 |    0.12112 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19980 | -0.00237 |    0.14620 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16518 | -0.00426 |    0.12627 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24526 | -0.01016 |    0.16113 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14555 | -0.00033 |    0.10793 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12196 | -0.01346 |    0.09813 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14731 | -0.01373 |    0.11539 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10771 | -0.00486 |    0.08260 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11817 | -0.01344 |    0.09412 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11204 | -0.00222 |    0.08869 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13938 | -0.00771 |    0.10710 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10613 | -0.00926 |    0.08423 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09090 | -0.00552 |    0.07167 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09174 | -0.01106 |    0.07334 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05533 |  0.00243 |    0.04195 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58138 | -0.00001 |    0.45361 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:48:56,098 - Total sparsity: 0.00

2018-11-02 21:48:56,098 - --- validate (epoch=212)-----------
2018-11-02 21:48:56,098 - 10000 samples (128 per mini-batch)
2018-11-02 21:48:56,821 - Epoch: [212][   50/   78]    Loss 0.395769    Top1 90.703125    Top5 99.640625    
2018-11-02 21:48:57,213 - ==> Top1: 90.660    Top5: 99.660    Loss: 0.395

2018-11-02 21:48:57,214 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:48:57,214 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:48:57,224 - 

2018-11-02 21:48:57,224 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:48:58,262 - Epoch: [213][   50/  391]    Overall Loss 0.045108    Objective Loss 0.045108    Top1 98.421875    Top5 100.000000    LR 0.002677    Time 0.020726    
2018-11-02 21:48:59,240 - Epoch: [213][  100/  391]    Overall Loss 0.046339    Objective Loss 0.046339    Top1 98.421875    Top5 100.000000    LR 0.002677    Time 0.020127    
2018-11-02 21:49:00,224 - Epoch: [213][  150/  391]    Overall Loss 0.046353    Objective Loss 0.046353    Top1 98.411458    Top5 100.000000    LR 0.002677    Time 0.019970    
2018-11-02 21:49:01,202 - Epoch: [213][  200/  391]    Overall Loss 0.046223    Objective Loss 0.046223    Top1 98.425781    Top5 100.000000    LR 0.002677    Time 0.019863    
2018-11-02 21:49:02,183 - Epoch: [213][  250/  391]    Overall Loss 0.046721    Objective Loss 0.046721    Top1 98.406250    Top5 100.000000    LR 0.002677    Time 0.019806    
2018-11-02 21:49:03,163 - Epoch: [213][  300/  391]    Overall Loss 0.046338    Objective Loss 0.046338    Top1 98.408854    Top5 100.000000    LR 0.002677    Time 0.019770    
2018-11-02 21:49:04,142 - Epoch: [213][  350/  391]    Overall Loss 0.045462    Objective Loss 0.045462    Top1 98.444196    Top5 100.000000    LR 0.002677    Time 0.019739    
2018-11-02 21:49:05,027 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35460 | -0.00633 |    0.22425 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15835 | -0.00055 |    0.09987 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15826 | -0.00386 |    0.11983 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19044 | -0.04584 |    0.14847 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20326 |  0.00635 |    0.15999 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16996 | -0.02597 |    0.12966 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16566 | -0.00378 |    0.12094 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19960 | -0.00264 |    0.14605 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16502 | -0.00429 |    0.12614 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24502 | -0.01013 |    0.16097 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14541 | -0.00036 |    0.10787 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12184 | -0.01339 |    0.09806 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14716 | -0.01380 |    0.11526 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10760 | -0.00496 |    0.08250 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11805 | -0.01342 |    0.09404 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11194 | -0.00223 |    0.08859 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13924 | -0.00769 |    0.10700 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10603 | -0.00925 |    0.08414 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09082 | -0.00551 |    0.07159 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09165 | -0.01104 |    0.07327 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05528 |  0.00243 |    0.04190 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58149 | -0.00001 |    0.45367 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:49:05,027 - Total sparsity: 0.00

2018-11-02 21:49:05,027 - --- validate (epoch=213)-----------
2018-11-02 21:49:05,027 - 10000 samples (128 per mini-batch)
2018-11-02 21:49:05,748 - Epoch: [213][   50/   78]    Loss 0.392362    Top1 90.593750    Top5 99.609375    
2018-11-02 21:49:06,138 - ==> Top1: 90.520    Top5: 99.670    Loss: 0.394

2018-11-02 21:49:06,139 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:49:06,139 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:49:06,146 - 

2018-11-02 21:49:06,147 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:49:07,182 - Epoch: [214][   50/  391]    Overall Loss 0.045950    Objective Loss 0.045950    Top1 98.703125    Top5 99.984375    LR 0.002543    Time 0.020669    
2018-11-02 21:49:08,161 - Epoch: [214][  100/  391]    Overall Loss 0.045195    Objective Loss 0.045195    Top1 98.648438    Top5 99.992188    LR 0.002543    Time 0.020108    
2018-11-02 21:49:09,142 - Epoch: [214][  150/  391]    Overall Loss 0.044464    Objective Loss 0.044464    Top1 98.666667    Top5 99.994792    LR 0.002543    Time 0.019936    
2018-11-02 21:49:10,122 - Epoch: [214][  200/  391]    Overall Loss 0.043491    Objective Loss 0.043491    Top1 98.667969    Top5 99.996094    LR 0.002543    Time 0.019844    
2018-11-02 21:49:11,100 - Epoch: [214][  250/  391]    Overall Loss 0.043624    Objective Loss 0.043624    Top1 98.621875    Top5 99.996875    LR 0.002543    Time 0.019784    
2018-11-02 21:49:12,080 - Epoch: [214][  300/  391]    Overall Loss 0.044429    Objective Loss 0.044429    Top1 98.596354    Top5 99.994792    LR 0.002543    Time 0.019750    
2018-11-02 21:49:13,058 - Epoch: [214][  350/  391]    Overall Loss 0.045324    Objective Loss 0.045324    Top1 98.546875    Top5 99.995536    LR 0.002543    Time 0.019717    
2018-11-02 21:49:13,944 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35426 | -0.00650 |    0.22406 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15820 | -0.00047 |    0.09983 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15812 | -0.00369 |    0.11973 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19024 | -0.04590 |    0.14839 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20306 |  0.00644 |    0.15983 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16980 | -0.02597 |    0.12953 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16551 | -0.00351 |    0.12081 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19942 | -0.00264 |    0.14591 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16487 | -0.00423 |    0.12600 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24478 | -0.01023 |    0.16079 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14527 | -0.00036 |    0.10780 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12174 | -0.01331 |    0.09798 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14701 | -0.01384 |    0.11514 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10750 | -0.00485 |    0.08243 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11794 | -0.01339 |    0.09396 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11183 | -0.00224 |    0.08851 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13911 | -0.00767 |    0.10690 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10593 | -0.00920 |    0.08406 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09074 | -0.00551 |    0.07153 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09157 | -0.01102 |    0.07320 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05522 |  0.00242 |    0.04186 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58162 | -0.00001 |    0.45378 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:49:13,945 - Total sparsity: 0.00

2018-11-02 21:49:13,945 - --- validate (epoch=214)-----------
2018-11-02 21:49:13,945 - 10000 samples (128 per mini-batch)
2018-11-02 21:49:14,702 - Epoch: [214][   50/   78]    Loss 0.398386    Top1 90.484375    Top5 99.640625    
2018-11-02 21:49:15,094 - ==> Top1: 90.430    Top5: 99.680    Loss: 0.396

2018-11-02 21:49:15,095 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:49:15,095 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:49:15,105 - 

2018-11-02 21:49:15,106 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:49:16,167 - Epoch: [215][   50/  391]    Overall Loss 0.049203    Objective Loss 0.049203    Top1 98.484375    Top5 99.968750    LR 0.002416    Time 0.021178    
2018-11-02 21:49:17,144 - Epoch: [215][  100/  391]    Overall Loss 0.047084    Objective Loss 0.047084    Top1 98.539062    Top5 99.984375    LR 0.002416    Time 0.020351    
2018-11-02 21:49:18,124 - Epoch: [215][  150/  391]    Overall Loss 0.046786    Objective Loss 0.046786    Top1 98.541667    Top5 99.989583    LR 0.002416    Time 0.020092    
2018-11-02 21:49:19,102 - Epoch: [215][  200/  391]    Overall Loss 0.046656    Objective Loss 0.046656    Top1 98.507812    Top5 99.992188    LR 0.002416    Time 0.019947    
2018-11-02 21:49:20,080 - Epoch: [215][  250/  391]    Overall Loss 0.046545    Objective Loss 0.046545    Top1 98.478125    Top5 99.993750    LR 0.002416    Time 0.019865    
2018-11-02 21:49:21,060 - Epoch: [215][  300/  391]    Overall Loss 0.047304    Objective Loss 0.047304    Top1 98.447917    Top5 99.994792    LR 0.002416    Time 0.019815    
2018-11-02 21:49:22,065 - Epoch: [215][  350/  391]    Overall Loss 0.046664    Objective Loss 0.046664    Top1 98.477679    Top5 99.995536    LR 0.002416    Time 0.019854    
2018-11-02 21:49:22,948 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35394 | -0.00637 |    0.22384 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15806 | -0.00050 |    0.09967 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15798 | -0.00359 |    0.11965 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19013 | -0.04560 |    0.14828 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20288 |  0.00638 |    0.15966 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16965 | -0.02594 |    0.12944 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16536 | -0.00349 |    0.12073 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19924 | -0.00261 |    0.14577 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16472 | -0.00419 |    0.12590 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24457 | -0.01009 |    0.16072 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14514 | -0.00025 |    0.10771 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12164 | -0.01318 |    0.09790 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14688 | -0.01388 |    0.11504 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10741 | -0.00483 |    0.08236 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11784 | -0.01335 |    0.09388 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11173 | -0.00220 |    0.08844 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13898 | -0.00765 |    0.10682 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10584 | -0.00920 |    0.08398 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09066 | -0.00547 |    0.07147 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09149 | -0.01103 |    0.07314 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05518 |  0.00241 |    0.04183 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58172 | -0.00001 |    0.45387 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:49:22,948 - Total sparsity: 0.00

2018-11-02 21:49:22,948 - --- validate (epoch=215)-----------
2018-11-02 21:49:22,948 - 10000 samples (128 per mini-batch)
2018-11-02 21:49:23,677 - Epoch: [215][   50/   78]    Loss 0.395648    Top1 90.562500    Top5 99.625000    
2018-11-02 21:49:24,076 - ==> Top1: 90.450    Top5: 99.680    Loss: 0.399

2018-11-02 21:49:24,077 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:49:24,077 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:49:24,085 - 

2018-11-02 21:49:24,085 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:49:25,123 - Epoch: [216][   50/  391]    Overall Loss 0.044731    Objective Loss 0.044731    Top1 98.656250    Top5 99.984375    LR 0.002295    Time 0.020712    
2018-11-02 21:49:26,104 - Epoch: [216][  100/  391]    Overall Loss 0.045882    Objective Loss 0.045882    Top1 98.554688    Top5 99.992188    LR 0.002295    Time 0.020158    
2018-11-02 21:49:27,100 - Epoch: [216][  150/  391]    Overall Loss 0.045956    Objective Loss 0.045956    Top1 98.500000    Top5 99.994792    LR 0.002295    Time 0.020070    
2018-11-02 21:49:28,078 - Epoch: [216][  200/  391]    Overall Loss 0.044562    Objective Loss 0.044562    Top1 98.562500    Top5 99.996094    LR 0.002295    Time 0.019935    
2018-11-02 21:49:29,058 - Epoch: [216][  250/  391]    Overall Loss 0.044081    Objective Loss 0.044081    Top1 98.587500    Top5 99.996875    LR 0.002295    Time 0.019865    
2018-11-02 21:49:30,035 - Epoch: [216][  300/  391]    Overall Loss 0.045076    Objective Loss 0.045076    Top1 98.546875    Top5 99.997396    LR 0.002295    Time 0.019804    
2018-11-02 21:49:31,012 - Epoch: [216][  350/  391]    Overall Loss 0.045194    Objective Loss 0.045194    Top1 98.546875    Top5 99.997768    LR 0.002295    Time 0.019763    
2018-11-02 21:49:31,894 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35364 | -0.00622 |    0.22374 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15793 | -0.00049 |    0.09960 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15784 | -0.00366 |    0.11953 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18995 | -0.04566 |    0.14817 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20272 |  0.00609 |    0.15951 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16950 | -0.02592 |    0.12933 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16522 | -0.00354 |    0.12062 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19907 | -0.00252 |    0.14564 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16458 | -0.00419 |    0.12578 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24435 | -0.01010 |    0.16062 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14502 | -0.00038 |    0.10764 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12153 | -0.01323 |    0.09783 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14676 | -0.01386 |    0.11495 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10732 | -0.00472 |    0.08231 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11774 | -0.01333 |    0.09378 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11164 | -0.00218 |    0.08837 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13886 | -0.00764 |    0.10672 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10575 | -0.00920 |    0.08391 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09059 | -0.00545 |    0.07141 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09141 | -0.01103 |    0.07309 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05513 |  0.00241 |    0.04179 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58184 | -0.00001 |    0.45396 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:49:31,894 - Total sparsity: 0.00

2018-11-02 21:49:31,894 - --- validate (epoch=216)-----------
2018-11-02 21:49:31,894 - 10000 samples (128 per mini-batch)
2018-11-02 21:49:32,619 - Epoch: [216][   50/   78]    Loss 0.394247    Top1 90.515625    Top5 99.640625    
2018-11-02 21:49:33,014 - ==> Top1: 90.510    Top5: 99.690    Loss: 0.396

2018-11-02 21:49:33,014 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:49:33,015 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:49:33,022 - 

2018-11-02 21:49:33,023 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:49:34,060 - Epoch: [217][   50/  391]    Overall Loss 0.039072    Objective Loss 0.039072    Top1 98.718750    Top5 100.000000    LR 0.002181    Time 0.020719    
2018-11-02 21:49:35,040 - Epoch: [217][  100/  391]    Overall Loss 0.042127    Objective Loss 0.042127    Top1 98.640625    Top5 99.992188    LR 0.002181    Time 0.020142    
2018-11-02 21:49:36,018 - Epoch: [217][  150/  391]    Overall Loss 0.041936    Objective Loss 0.041936    Top1 98.656250    Top5 99.994792    LR 0.002181    Time 0.019942    
2018-11-02 21:49:36,998 - Epoch: [217][  200/  391]    Overall Loss 0.041984    Objective Loss 0.041984    Top1 98.660156    Top5 99.992188    LR 0.002181    Time 0.019850    
2018-11-02 21:49:37,977 - Epoch: [217][  250/  391]    Overall Loss 0.042333    Objective Loss 0.042333    Top1 98.640625    Top5 99.993750    LR 0.002181    Time 0.019778    
2018-11-02 21:49:39,013 - Epoch: [217][  300/  391]    Overall Loss 0.042625    Objective Loss 0.042625    Top1 98.606771    Top5 99.994792    LR 0.002181    Time 0.019928    
2018-11-02 21:49:39,991 - Epoch: [217][  350/  391]    Overall Loss 0.042380    Objective Loss 0.042380    Top1 98.636161    Top5 99.993304    LR 0.002181    Time 0.019872    
2018-11-02 21:49:40,870 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35336 | -0.00617 |    0.22358 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15780 | -0.00046 |    0.09953 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15771 | -0.00374 |    0.11942 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18982 | -0.04550 |    0.14798 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20255 |  0.00630 |    0.15938 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16938 | -0.02582 |    0.12918 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16509 | -0.00345 |    0.12053 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19891 | -0.00261 |    0.14552 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16445 | -0.00422 |    0.12568 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24416 | -0.01004 |    0.16037 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14490 | -0.00038 |    0.10755 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12144 | -0.01322 |    0.09776 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14664 | -0.01380 |    0.11484 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10724 | -0.00466 |    0.08223 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11765 | -0.01330 |    0.09372 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11155 | -0.00223 |    0.08830 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13875 | -0.00761 |    0.10664 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10566 | -0.00919 |    0.08384 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09051 | -0.00546 |    0.07136 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09134 | -0.01103 |    0.07303 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05508 |  0.00241 |    0.04176 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58196 | -0.00001 |    0.45404 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:49:40,871 - Total sparsity: 0.00

2018-11-02 21:49:40,871 - --- validate (epoch=217)-----------
2018-11-02 21:49:40,871 - 10000 samples (128 per mini-batch)
2018-11-02 21:49:41,595 - Epoch: [217][   50/   78]    Loss 0.393758    Top1 90.375000    Top5 99.625000    
2018-11-02 21:49:41,986 - ==> Top1: 90.380    Top5: 99.690    Loss: 0.396

2018-11-02 21:49:41,986 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:49:41,987 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:49:41,994 - 

2018-11-02 21:49:41,994 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:49:43,031 - Epoch: [218][   50/  391]    Overall Loss 0.045241    Objective Loss 0.045241    Top1 98.593750    Top5 100.000000    LR 0.002072    Time 0.020711    
2018-11-02 21:49:44,010 - Epoch: [218][  100/  391]    Overall Loss 0.046287    Objective Loss 0.046287    Top1 98.531250    Top5 99.992188    LR 0.002072    Time 0.020131    
2018-11-02 21:49:44,989 - Epoch: [218][  150/  391]    Overall Loss 0.046361    Objective Loss 0.046361    Top1 98.520833    Top5 99.989583    LR 0.002072    Time 0.019941    
2018-11-02 21:49:45,968 - Epoch: [218][  200/  391]    Overall Loss 0.046269    Objective Loss 0.046269    Top1 98.476562    Top5 99.992188    LR 0.002072    Time 0.019843    
2018-11-02 21:49:46,946 - Epoch: [218][  250/  391]    Overall Loss 0.046861    Objective Loss 0.046861    Top1 98.440625    Top5 99.993750    LR 0.002072    Time 0.019780    
2018-11-02 21:49:47,924 - Epoch: [218][  300/  391]    Overall Loss 0.045591    Objective Loss 0.045591    Top1 98.500000    Top5 99.994792    LR 0.002072    Time 0.019739    
2018-11-02 21:49:48,903 - Epoch: [218][  350/  391]    Overall Loss 0.045864    Objective Loss 0.045864    Top1 98.470982    Top5 99.995536    LR 0.002072    Time 0.019702    
2018-11-02 21:49:49,787 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35308 | -0.00632 |    0.22330 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15768 | -0.00050 |    0.09945 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15759 | -0.00360 |    0.11930 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18965 | -0.04558 |    0.14789 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20239 |  0.00632 |    0.15929 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16925 | -0.02583 |    0.12907 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16497 | -0.00344 |    0.12044 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19876 | -0.00257 |    0.14544 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16432 | -0.00416 |    0.12558 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24396 | -0.01011 |    0.16022 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14479 | -0.00037 |    0.10749 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12134 | -0.01320 |    0.09770 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14654 | -0.01373 |    0.11474 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10716 | -0.00468 |    0.08214 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11756 | -0.01326 |    0.09365 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11146 | -0.00221 |    0.08823 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13864 | -0.00758 |    0.10656 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10558 | -0.00920 |    0.08378 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09044 | -0.00546 |    0.07130 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09127 | -0.01100 |    0.07297 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05504 |  0.00241 |    0.04173 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58203 | -0.00001 |    0.45409 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:49:49,787 - Total sparsity: 0.00

2018-11-02 21:49:49,787 - --- validate (epoch=218)-----------
2018-11-02 21:49:49,788 - 10000 samples (128 per mini-batch)
2018-11-02 21:49:50,518 - Epoch: [218][   50/   78]    Loss 0.396866    Top1 90.296875    Top5 99.671875    
2018-11-02 21:49:50,908 - ==> Top1: 90.420    Top5: 99.720    Loss: 0.399

2018-11-02 21:49:50,908 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:49:50,909 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:49:50,916 - 

2018-11-02 21:49:50,917 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:49:51,955 - Epoch: [219][   50/  391]    Overall Loss 0.042280    Objective Loss 0.042280    Top1 98.593750    Top5 100.000000    LR 0.001968    Time 0.020728    
2018-11-02 21:49:52,933 - Epoch: [219][  100/  391]    Overall Loss 0.043992    Objective Loss 0.043992    Top1 98.539062    Top5 99.992188    LR 0.001968    Time 0.020128    
2018-11-02 21:49:53,912 - Epoch: [219][  150/  391]    Overall Loss 0.043786    Objective Loss 0.043786    Top1 98.536458    Top5 99.994792    LR 0.001968    Time 0.019941    
2018-11-02 21:49:54,892 - Epoch: [219][  200/  391]    Overall Loss 0.043171    Objective Loss 0.043171    Top1 98.589844    Top5 99.996094    LR 0.001968    Time 0.019850    
2018-11-02 21:49:55,872 - Epoch: [219][  250/  391]    Overall Loss 0.044072    Objective Loss 0.044072    Top1 98.550000    Top5 99.996875    LR 0.001968    Time 0.019796    
2018-11-02 21:49:56,856 - Epoch: [219][  300/  391]    Overall Loss 0.044519    Objective Loss 0.044519    Top1 98.549479    Top5 99.997396    LR 0.001968    Time 0.019770    
2018-11-02 21:49:57,838 - Epoch: [219][  350/  391]    Overall Loss 0.043782    Objective Loss 0.043782    Top1 98.573661    Top5 99.997768    LR 0.001968    Time 0.019748    
2018-11-02 21:49:58,717 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35282 | -0.00614 |    0.22311 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15756 | -0.00054 |    0.09939 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15748 | -0.00364 |    0.11922 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18955 | -0.04539 |    0.14779 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20224 |  0.00636 |    0.15910 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16912 | -0.02584 |    0.12900 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16485 | -0.00324 |    0.12034 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19861 | -0.00259 |    0.14534 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16420 | -0.00421 |    0.12551 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24378 | -0.01004 |    0.16017 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14469 | -0.00034 |    0.10740 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12126 | -0.01315 |    0.09761 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14643 | -0.01377 |    0.11465 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10708 | -0.00469 |    0.08208 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11747 | -0.01327 |    0.09357 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11138 | -0.00221 |    0.08817 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13854 | -0.00757 |    0.10648 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10551 | -0.00920 |    0.08372 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09038 | -0.00547 |    0.07125 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09121 | -0.01099 |    0.07292 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05500 |  0.00240 |    0.04170 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58213 | -0.00001 |    0.45413 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:49:58,717 - Total sparsity: 0.00

2018-11-02 21:49:58,717 - --- validate (epoch=219)-----------
2018-11-02 21:49:58,717 - 10000 samples (128 per mini-batch)
2018-11-02 21:49:59,445 - Epoch: [219][   50/   78]    Loss 0.398647    Top1 90.546875    Top5 99.671875    
2018-11-02 21:49:59,835 - ==> Top1: 90.490    Top5: 99.700    Loss: 0.398

2018-11-02 21:49:59,836 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:49:59,836 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:49:59,844 - 

2018-11-02 21:49:59,844 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:50:00,885 - Epoch: [220][   50/  391]    Overall Loss 0.045458    Objective Loss 0.045458    Top1 98.421875    Top5 100.000000    LR 0.001870    Time 0.020792    
2018-11-02 21:50:01,865 - Epoch: [220][  100/  391]    Overall Loss 0.043541    Objective Loss 0.043541    Top1 98.515625    Top5 100.000000    LR 0.001870    Time 0.020182    
2018-11-02 21:50:02,844 - Epoch: [220][  150/  391]    Overall Loss 0.044071    Objective Loss 0.044071    Top1 98.531250    Top5 99.994792    LR 0.001870    Time 0.019972    
2018-11-02 21:50:03,825 - Epoch: [220][  200/  391]    Overall Loss 0.043770    Objective Loss 0.043770    Top1 98.562500    Top5 99.996094    LR 0.001870    Time 0.019876    
2018-11-02 21:50:04,801 - Epoch: [220][  250/  391]    Overall Loss 0.043556    Objective Loss 0.043556    Top1 98.590625    Top5 99.996875    LR 0.001870    Time 0.019785    
2018-11-02 21:50:05,780 - Epoch: [220][  300/  391]    Overall Loss 0.042858    Objective Loss 0.042858    Top1 98.627604    Top5 99.997396    LR 0.001870    Time 0.019747    
2018-11-02 21:50:06,760 - Epoch: [220][  350/  391]    Overall Loss 0.042776    Objective Loss 0.042776    Top1 98.645089    Top5 99.997768    LR 0.001870    Time 0.019722    
2018-11-02 21:50:07,643 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35257 | -0.00635 |    0.22291 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15745 | -0.00072 |    0.09934 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15737 | -0.00364 |    0.11911 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18938 | -0.04551 |    0.14771 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20210 |  0.00627 |    0.15898 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16899 | -0.02588 |    0.12897 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16473 | -0.00323 |    0.12029 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19847 | -0.00264 |    0.14520 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16409 | -0.00419 |    0.12539 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24362 | -0.00992 |    0.16007 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14459 | -0.00029 |    0.10733 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12117 | -0.01315 |    0.09756 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14633 | -0.01375 |    0.11458 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10700 | -0.00463 |    0.08203 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11739 | -0.01327 |    0.09350 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11131 | -0.00219 |    0.08810 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13844 | -0.00756 |    0.10640 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10543 | -0.00917 |    0.08366 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09032 | -0.00546 |    0.07120 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09115 | -0.01098 |    0.07288 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05496 |  0.00241 |    0.04167 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58221 | -0.00001 |    0.45418 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:50:07,643 - Total sparsity: 0.00

2018-11-02 21:50:07,643 - --- validate (epoch=220)-----------
2018-11-02 21:50:07,643 - 10000 samples (128 per mini-batch)
2018-11-02 21:50:08,369 - Epoch: [220][   50/   78]    Loss 0.399326    Top1 90.468750    Top5 99.640625    
2018-11-02 21:50:08,763 - ==> Top1: 90.490    Top5: 99.680    Loss: 0.400

2018-11-02 21:50:08,764 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:50:08,764 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:50:08,775 - 

2018-11-02 21:50:08,776 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:50:09,812 - Epoch: [221][   50/  391]    Overall Loss 0.045213    Objective Loss 0.045213    Top1 98.640625    Top5 99.984375    LR 0.001776    Time 0.020694    
2018-11-02 21:50:10,789 - Epoch: [221][  100/  391]    Overall Loss 0.043839    Objective Loss 0.043839    Top1 98.632812    Top5 99.992188    LR 0.001776    Time 0.020100    
2018-11-02 21:50:11,768 - Epoch: [221][  150/  391]    Overall Loss 0.044781    Objective Loss 0.044781    Top1 98.593750    Top5 99.989583    LR 0.001776    Time 0.019922    
2018-11-02 21:50:12,746 - Epoch: [221][  200/  391]    Overall Loss 0.045906    Objective Loss 0.045906    Top1 98.527344    Top5 99.988281    LR 0.001776    Time 0.019824    
2018-11-02 21:50:13,723 - Epoch: [221][  250/  391]    Overall Loss 0.045596    Objective Loss 0.045596    Top1 98.559375    Top5 99.990625    LR 0.001776    Time 0.019761    
2018-11-02 21:50:14,702 - Epoch: [221][  300/  391]    Overall Loss 0.045065    Objective Loss 0.045065    Top1 98.565104    Top5 99.992188    LR 0.001776    Time 0.019727    
2018-11-02 21:50:15,677 - Epoch: [221][  350/  391]    Overall Loss 0.044745    Objective Loss 0.044745    Top1 98.587054    Top5 99.993304    LR 0.001776    Time 0.019694    
2018-11-02 21:50:16,561 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35234 | -0.00613 |    0.22277 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15735 | -0.00059 |    0.09925 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15726 | -0.00366 |    0.11903 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18926 | -0.04546 |    0.14764 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20196 |  0.00637 |    0.15890 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16888 | -0.02587 |    0.12886 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16462 | -0.00339 |    0.12021 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19834 | -0.00255 |    0.14511 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16398 | -0.00414 |    0.12531 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24346 | -0.00986 |    0.15996 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14449 | -0.00034 |    0.10725 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12110 | -0.01309 |    0.09749 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14623 | -0.01377 |    0.11450 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10693 | -0.00466 |    0.08199 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11731 | -0.01328 |    0.09344 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11123 | -0.00215 |    0.08804 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13835 | -0.00756 |    0.10632 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10536 | -0.00918 |    0.08361 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09026 | -0.00545 |    0.07115 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09109 | -0.01098 |    0.07282 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05492 |  0.00241 |    0.04164 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58228 | -0.00001 |    0.45425 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:50:16,561 - Total sparsity: 0.00

2018-11-02 21:50:16,561 - --- validate (epoch=221)-----------
2018-11-02 21:50:16,561 - 10000 samples (128 per mini-batch)
2018-11-02 21:50:17,287 - Epoch: [221][   50/   78]    Loss 0.399714    Top1 90.453125    Top5 99.578125    
2018-11-02 21:50:17,682 - ==> Top1: 90.370    Top5: 99.650    Loss: 0.399

2018-11-02 21:50:17,683 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:50:17,683 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:50:17,694 - 

2018-11-02 21:50:17,695 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:50:18,731 - Epoch: [222][   50/  391]    Overall Loss 0.038118    Objective Loss 0.038118    Top1 98.812500    Top5 100.000000    LR 0.001687    Time 0.020702    
2018-11-02 21:50:19,708 - Epoch: [222][  100/  391]    Overall Loss 0.042881    Objective Loss 0.042881    Top1 98.578125    Top5 100.000000    LR 0.001687    Time 0.020102    
2018-11-02 21:50:20,688 - Epoch: [222][  150/  391]    Overall Loss 0.042743    Objective Loss 0.042743    Top1 98.625000    Top5 99.994792    LR 0.001687    Time 0.019926    
2018-11-02 21:50:21,665 - Epoch: [222][  200/  391]    Overall Loss 0.042788    Objective Loss 0.042788    Top1 98.644531    Top5 99.996094    LR 0.001687    Time 0.019822    
2018-11-02 21:50:22,644 - Epoch: [222][  250/  391]    Overall Loss 0.043140    Objective Loss 0.043140    Top1 98.628125    Top5 99.996875    LR 0.001687    Time 0.019769    
2018-11-02 21:50:23,622 - Epoch: [222][  300/  391]    Overall Loss 0.043230    Objective Loss 0.043230    Top1 98.651042    Top5 99.997396    LR 0.001687    Time 0.019731    
2018-11-02 21:50:24,602 - Epoch: [222][  350/  391]    Overall Loss 0.043482    Objective Loss 0.043482    Top1 98.629464    Top5 99.997768    LR 0.001687    Time 0.019710    
2018-11-02 21:50:25,485 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35211 | -0.00628 |    0.22266 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15725 | -0.00055 |    0.09921 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15716 | -0.00365 |    0.11898 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18917 | -0.04529 |    0.14751 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20183 |  0.00639 |    0.15878 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16880 | -0.02569 |    0.12881 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16452 | -0.00339 |    0.12015 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19822 | -0.00259 |    0.14501 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16388 | -0.00406 |    0.12522 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24330 | -0.00990 |    0.15981 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14440 | -0.00039 |    0.10720 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12102 | -0.01310 |    0.09741 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14614 | -0.01372 |    0.11444 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10687 | -0.00465 |    0.08194 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11724 | -0.01324 |    0.09338 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11116 | -0.00215 |    0.08799 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13826 | -0.00753 |    0.10626 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10530 | -0.00916 |    0.08355 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09020 | -0.00542 |    0.07111 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09103 | -0.01097 |    0.07278 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05489 |  0.00241 |    0.04162 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58236 | -0.00001 |    0.45431 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:50:25,485 - Total sparsity: 0.00

2018-11-02 21:50:25,485 - --- validate (epoch=222)-----------
2018-11-02 21:50:25,486 - 10000 samples (128 per mini-batch)
2018-11-02 21:50:26,212 - Epoch: [222][   50/   78]    Loss 0.398289    Top1 90.484375    Top5 99.640625    
2018-11-02 21:50:26,606 - ==> Top1: 90.480    Top5: 99.680    Loss: 0.397

2018-11-02 21:50:26,607 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:50:26,607 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:50:26,618 - 

2018-11-02 21:50:26,618 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:50:27,656 - Epoch: [223][   50/  391]    Overall Loss 0.033933    Objective Loss 0.033933    Top1 98.906250    Top5 99.984375    LR 0.001603    Time 0.020712    
2018-11-02 21:50:28,634 - Epoch: [223][  100/  391]    Overall Loss 0.036775    Objective Loss 0.036775    Top1 98.906250    Top5 99.992188    LR 0.001603    Time 0.020129    
2018-11-02 21:50:29,615 - Epoch: [223][  150/  391]    Overall Loss 0.039616    Objective Loss 0.039616    Top1 98.734375    Top5 99.994792    LR 0.001603    Time 0.019953    
2018-11-02 21:50:30,595 - Epoch: [223][  200/  391]    Overall Loss 0.041778    Objective Loss 0.041778    Top1 98.636719    Top5 99.996094    LR 0.001603    Time 0.019855    
2018-11-02 21:50:31,576 - Epoch: [223][  250/  391]    Overall Loss 0.042620    Objective Loss 0.042620    Top1 98.581250    Top5 99.996875    LR 0.001603    Time 0.019804    
2018-11-02 21:50:32,554 - Epoch: [223][  300/  391]    Overall Loss 0.042291    Objective Loss 0.042291    Top1 98.578125    Top5 99.997396    LR 0.001603    Time 0.019761    
2018-11-02 21:50:33,535 - Epoch: [223][  350/  391]    Overall Loss 0.042316    Objective Loss 0.042316    Top1 98.584821    Top5 99.997768    LR 0.001603    Time 0.019737    
2018-11-02 21:50:34,418 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35190 | -0.00631 |    0.22243 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15715 | -0.00068 |    0.09912 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15707 | -0.00355 |    0.11889 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18910 | -0.04510 |    0.14740 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20170 |  0.00669 |    0.15869 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16869 | -0.02570 |    0.12872 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16442 | -0.00344 |    0.12005 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19810 | -0.00257 |    0.14493 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16378 | -0.00410 |    0.12516 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24315 | -0.00982 |    0.15972 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14431 | -0.00044 |    0.10715 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12095 | -0.01308 |    0.09735 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14605 | -0.01375 |    0.11435 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10680 | -0.00466 |    0.08188 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11717 | -0.01324 |    0.09332 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11110 | -0.00215 |    0.08793 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13818 | -0.00751 |    0.10618 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10524 | -0.00914 |    0.08350 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09015 | -0.00542 |    0.07107 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09098 | -0.01097 |    0.07274 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05485 |  0.00241 |    0.04159 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58240 | -0.00001 |    0.45435 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:50:34,418 - Total sparsity: 0.00

2018-11-02 21:50:34,418 - --- validate (epoch=223)-----------
2018-11-02 21:50:34,418 - 10000 samples (128 per mini-batch)
2018-11-02 21:50:35,144 - Epoch: [223][   50/   78]    Loss 0.400460    Top1 90.406250    Top5 99.609375    
2018-11-02 21:50:35,539 - ==> Top1: 90.360    Top5: 99.680    Loss: 0.401

2018-11-02 21:50:35,540 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:50:35,540 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:50:35,547 - 

2018-11-02 21:50:35,548 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:50:36,585 - Epoch: [224][   50/  391]    Overall Loss 0.039824    Objective Loss 0.039824    Top1 98.765625    Top5 100.000000    LR 0.001523    Time 0.020721    
2018-11-02 21:50:37,566 - Epoch: [224][  100/  391]    Overall Loss 0.040920    Objective Loss 0.040920    Top1 98.718750    Top5 100.000000    LR 0.001523    Time 0.020152    
2018-11-02 21:50:38,545 - Epoch: [224][  150/  391]    Overall Loss 0.040516    Objective Loss 0.040516    Top1 98.739583    Top5 100.000000    LR 0.001523    Time 0.019953    
2018-11-02 21:50:39,525 - Epoch: [224][  200/  391]    Overall Loss 0.041244    Objective Loss 0.041244    Top1 98.718750    Top5 100.000000    LR 0.001523    Time 0.019860    
2018-11-02 21:50:40,505 - Epoch: [224][  250/  391]    Overall Loss 0.042047    Objective Loss 0.042047    Top1 98.700000    Top5 99.996875    LR 0.001523    Time 0.019803    
2018-11-02 21:50:41,485 - Epoch: [224][  300/  391]    Overall Loss 0.042886    Objective Loss 0.042886    Top1 98.664062    Top5 99.997396    LR 0.001523    Time 0.019764    
2018-11-02 21:50:42,463 - Epoch: [224][  350/  391]    Overall Loss 0.042908    Objective Loss 0.042908    Top1 98.658482    Top5 99.997768    LR 0.001523    Time 0.019731    
2018-11-02 21:50:43,344 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35170 | -0.00623 |    0.22231 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15706 | -0.00065 |    0.09909 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15698 | -0.00357 |    0.11883 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18898 | -0.04511 |    0.14732 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20159 |  0.00670 |    0.15859 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16859 | -0.02570 |    0.12865 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16432 | -0.00336 |    0.11998 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19798 | -0.00262 |    0.14485 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16368 | -0.00415 |    0.12507 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24301 | -0.00991 |    0.15958 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14423 | -0.00051 |    0.10710 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12087 | -0.01316 |    0.09729 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14596 | -0.01379 |    0.11431 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10674 | -0.00463 |    0.08183 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11710 | -0.01322 |    0.09327 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11103 | -0.00217 |    0.08788 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13810 | -0.00751 |    0.10613 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10518 | -0.00910 |    0.08345 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09010 | -0.00540 |    0.07103 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09092 | -0.01097 |    0.07270 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05482 |  0.00241 |    0.04157 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58246 | -0.00001 |    0.45438 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:50:43,344 - Total sparsity: 0.00

2018-11-02 21:50:43,344 - --- validate (epoch=224)-----------
2018-11-02 21:50:43,345 - 10000 samples (128 per mini-batch)
2018-11-02 21:50:44,072 - Epoch: [224][   50/   78]    Loss 0.402902    Top1 90.453125    Top5 99.625000    
2018-11-02 21:50:44,465 - ==> Top1: 90.480    Top5: 99.680    Loss: 0.403

2018-11-02 21:50:44,466 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:50:44,466 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:50:44,478 - 

2018-11-02 21:50:44,478 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:50:45,515 - Epoch: [225][   50/  391]    Overall Loss 0.041368    Objective Loss 0.041368    Top1 98.656250    Top5 100.000000    LR 0.001447    Time 0.020703    
2018-11-02 21:50:46,494 - Epoch: [225][  100/  391]    Overall Loss 0.043663    Objective Loss 0.043663    Top1 98.515625    Top5 99.992188    LR 0.001447    Time 0.020135    
2018-11-02 21:50:47,473 - Epoch: [225][  150/  391]    Overall Loss 0.044102    Objective Loss 0.044102    Top1 98.505208    Top5 99.994792    LR 0.001447    Time 0.019942    
2018-11-02 21:50:48,449 - Epoch: [225][  200/  391]    Overall Loss 0.044344    Objective Loss 0.044344    Top1 98.511719    Top5 99.992188    LR 0.001447    Time 0.019831    
2018-11-02 21:50:49,427 - Epoch: [225][  250/  391]    Overall Loss 0.044673    Objective Loss 0.044673    Top1 98.509375    Top5 99.990625    LR 0.001447    Time 0.019771    
2018-11-02 21:50:50,406 - Epoch: [225][  300/  391]    Overall Loss 0.043666    Objective Loss 0.043666    Top1 98.562500    Top5 99.992188    LR 0.001447    Time 0.019733    
2018-11-02 21:50:51,385 - Epoch: [225][  350/  391]    Overall Loss 0.043019    Objective Loss 0.043019    Top1 98.593750    Top5 99.993304    LR 0.001447    Time 0.019709    
2018-11-02 21:50:52,266 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35150 | -0.00638 |    0.22221 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15698 | -0.00042 |    0.09903 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15689 | -0.00348 |    0.11875 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18884 | -0.04522 |    0.14729 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20148 |  0.00658 |    0.15849 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16851 | -0.02565 |    0.12858 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16424 | -0.00335 |    0.11992 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19788 | -0.00256 |    0.14478 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16359 | -0.00410 |    0.12500 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24287 | -0.00995 |    0.15952 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14415 | -0.00051 |    0.10703 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12081 | -0.01315 |    0.09725 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14588 | -0.01375 |    0.11423 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10668 | -0.00463 |    0.08180 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11704 | -0.01320 |    0.09321 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11097 | -0.00214 |    0.08784 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13802 | -0.00750 |    0.10605 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10512 | -0.00909 |    0.08341 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09005 | -0.00541 |    0.07099 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09087 | -0.01097 |    0.07266 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05479 |  0.00240 |    0.04155 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58252 | -0.00001 |    0.45443 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:50:52,266 - Total sparsity: 0.00

2018-11-02 21:50:52,266 - --- validate (epoch=225)-----------
2018-11-02 21:50:52,266 - 10000 samples (128 per mini-batch)
2018-11-02 21:50:52,992 - Epoch: [225][   50/   78]    Loss 0.407406    Top1 90.187500    Top5 99.609375    
2018-11-02 21:50:53,386 - ==> Top1: 90.290    Top5: 99.680    Loss: 0.407

2018-11-02 21:50:53,387 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:50:53,387 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:50:53,398 - 

2018-11-02 21:50:53,398 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:50:54,472 - Epoch: [226][   50/  391]    Overall Loss 0.040489    Objective Loss 0.040489    Top1 98.843750    Top5 100.000000    LR 0.001374    Time 0.021433    
2018-11-02 21:50:55,447 - Epoch: [226][  100/  391]    Overall Loss 0.042062    Objective Loss 0.042062    Top1 98.703125    Top5 100.000000    LR 0.001374    Time 0.020456    
2018-11-02 21:50:56,427 - Epoch: [226][  150/  391]    Overall Loss 0.042103    Objective Loss 0.042103    Top1 98.640625    Top5 100.000000    LR 0.001374    Time 0.020158    
2018-11-02 21:50:57,425 - Epoch: [226][  200/  391]    Overall Loss 0.042194    Objective Loss 0.042194    Top1 98.652344    Top5 99.996094    LR 0.001374    Time 0.020103    
2018-11-02 21:50:58,403 - Epoch: [226][  250/  391]    Overall Loss 0.041339    Objective Loss 0.041339    Top1 98.709375    Top5 99.996875    LR 0.001374    Time 0.019977    
2018-11-02 21:50:59,381 - Epoch: [226][  300/  391]    Overall Loss 0.041606    Objective Loss 0.041606    Top1 98.692708    Top5 99.997396    LR 0.001374    Time 0.019903    
2018-11-02 21:51:00,367 - Epoch: [226][  350/  391]    Overall Loss 0.041745    Objective Loss 0.041745    Top1 98.669643    Top5 99.997768    LR 0.001374    Time 0.019872    
2018-11-02 21:51:01,254 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35132 | -0.00628 |    0.22206 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15689 | -0.00048 |    0.09902 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15681 | -0.00344 |    0.11871 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18871 | -0.04533 |    0.14723 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20138 |  0.00647 |    0.15843 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16841 | -0.02569 |    0.12855 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16415 | -0.00337 |    0.11985 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19777 | -0.00258 |    0.14470 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16351 | -0.00409 |    0.12492 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24275 | -0.00992 |    0.15944 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14408 | -0.00045 |    0.10697 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12075 | -0.01311 |    0.09719 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14581 | -0.01376 |    0.11418 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10663 | -0.00464 |    0.08177 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11698 | -0.01318 |    0.09316 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11092 | -0.00215 |    0.08779 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13795 | -0.00749 |    0.10600 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10507 | -0.00907 |    0.08336 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09001 | -0.00539 |    0.07095 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09083 | -0.01096 |    0.07263 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05476 |  0.00239 |    0.04153 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58258 | -0.00001 |    0.45448 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:51:01,254 - Total sparsity: 0.00

2018-11-02 21:51:01,254 - --- validate (epoch=226)-----------
2018-11-02 21:51:01,254 - 10000 samples (128 per mini-batch)
2018-11-02 21:51:01,975 - Epoch: [226][   50/   78]    Loss 0.402397    Top1 90.468750    Top5 99.656250    
2018-11-02 21:51:02,367 - ==> Top1: 90.520    Top5: 99.710    Loss: 0.402

2018-11-02 21:51:02,368 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:51:02,368 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:51:02,383 - 

2018-11-02 21:51:02,383 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:51:03,486 - Epoch: [227][   50/  391]    Overall Loss 0.038654    Objective Loss 0.038654    Top1 98.765625    Top5 100.000000    LR 0.001306    Time 0.022021    
2018-11-02 21:51:04,528 - Epoch: [227][  100/  391]    Overall Loss 0.040286    Objective Loss 0.040286    Top1 98.695312    Top5 100.000000    LR 0.001306    Time 0.021413    
2018-11-02 21:51:05,569 - Epoch: [227][  150/  391]    Overall Loss 0.040592    Objective Loss 0.040592    Top1 98.666667    Top5 100.000000    LR 0.001306    Time 0.021212    
2018-11-02 21:51:06,616 - Epoch: [227][  200/  391]    Overall Loss 0.041393    Objective Loss 0.041393    Top1 98.656250    Top5 100.000000    LR 0.001306    Time 0.021134    
2018-11-02 21:51:07,661 - Epoch: [227][  250/  391]    Overall Loss 0.040777    Objective Loss 0.040777    Top1 98.712500    Top5 100.000000    LR 0.001306    Time 0.021084    
2018-11-02 21:51:08,707 - Epoch: [227][  300/  391]    Overall Loss 0.041437    Objective Loss 0.041437    Top1 98.697917    Top5 99.997396    LR 0.001306    Time 0.021039    
2018-11-02 21:51:09,684 - Epoch: [227][  350/  391]    Overall Loss 0.041321    Objective Loss 0.041321    Top1 98.714286    Top5 99.997768    LR 0.001306    Time 0.020821    
2018-11-02 21:51:10,571 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35115 | -0.00632 |    0.22203 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15682 | -0.00037 |    0.09901 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15674 | -0.00331 |    0.11866 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18863 | -0.04526 |    0.14715 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20128 |  0.00660 |    0.15834 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16833 | -0.02571 |    0.12850 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16407 | -0.00338 |    0.11979 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19768 | -0.00249 |    0.14462 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16343 | -0.00411 |    0.12484 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24263 | -0.00985 |    0.15937 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14400 | -0.00049 |    0.10692 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12069 | -0.01309 |    0.09716 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14574 | -0.01373 |    0.11411 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10658 | -0.00456 |    0.08172 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11692 | -0.01317 |    0.09311 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11086 | -0.00212 |    0.08775 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13788 | -0.00747 |    0.10595 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10502 | -0.00907 |    0.08332 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08996 | -0.00537 |    0.07092 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09078 | -0.01098 |    0.07260 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05474 |  0.00238 |    0.04151 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58261 | -0.00001 |    0.45449 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:51:10,571 - Total sparsity: 0.00

2018-11-02 21:51:10,571 - --- validate (epoch=227)-----------
2018-11-02 21:51:10,571 - 10000 samples (128 per mini-batch)
2018-11-02 21:51:11,293 - Epoch: [227][   50/   78]    Loss 0.405687    Top1 90.406250    Top5 99.625000    
2018-11-02 21:51:11,685 - ==> Top1: 90.470    Top5: 99.690    Loss: 0.404

2018-11-02 21:51:11,686 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:51:11,686 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:51:11,700 - 

2018-11-02 21:51:11,701 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:51:12,737 - Epoch: [228][   50/  391]    Overall Loss 0.039188    Objective Loss 0.039188    Top1 98.687500    Top5 100.000000    LR 0.001240    Time 0.020687    
2018-11-02 21:51:13,708 - Epoch: [228][  100/  391]    Overall Loss 0.040487    Objective Loss 0.040487    Top1 98.726562    Top5 100.000000    LR 0.001240    Time 0.020045    
2018-11-02 21:51:14,681 - Epoch: [228][  150/  391]    Overall Loss 0.040134    Objective Loss 0.040134    Top1 98.750000    Top5 100.000000    LR 0.001240    Time 0.019840    
2018-11-02 21:51:15,671 - Epoch: [228][  200/  391]    Overall Loss 0.039800    Objective Loss 0.039800    Top1 98.773438    Top5 100.000000    LR 0.001240    Time 0.019824    
2018-11-02 21:51:16,645 - Epoch: [228][  250/  391]    Overall Loss 0.039969    Objective Loss 0.039969    Top1 98.759375    Top5 100.000000    LR 0.001240    Time 0.019752    
2018-11-02 21:51:17,618 - Epoch: [228][  300/  391]    Overall Loss 0.039823    Objective Loss 0.039823    Top1 98.744792    Top5 100.000000    LR 0.001240    Time 0.019699    
2018-11-02 21:51:18,591 - Epoch: [228][  350/  391]    Overall Loss 0.041177    Objective Loss 0.041177    Top1 98.683036    Top5 99.995536    LR 0.001240    Time 0.019659    
2018-11-02 21:51:19,466 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35098 | -0.00615 |    0.22197 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15674 | -0.00041 |    0.09898 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15666 | -0.00328 |    0.11862 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18855 | -0.04521 |    0.14709 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20118 |  0.00665 |    0.15825 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16824 | -0.02576 |    0.12841 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16399 | -0.00339 |    0.11973 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19758 | -0.00252 |    0.14456 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16335 | -0.00415 |    0.12480 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24251 | -0.00982 |    0.15932 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14394 | -0.00055 |    0.10687 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12063 | -0.01308 |    0.09711 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14567 | -0.01371 |    0.11405 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10653 | -0.00458 |    0.08169 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11687 | -0.01316 |    0.09307 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11081 | -0.00214 |    0.08771 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13782 | -0.00747 |    0.10589 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10497 | -0.00905 |    0.08328 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08992 | -0.00537 |    0.07089 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09074 | -0.01098 |    0.07256 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05471 |  0.00238 |    0.04149 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58266 | -0.00001 |    0.45452 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:51:19,467 - Total sparsity: 0.00

2018-11-02 21:51:19,467 - --- validate (epoch=228)-----------
2018-11-02 21:51:19,467 - 10000 samples (128 per mini-batch)
2018-11-02 21:51:20,193 - Epoch: [228][   50/   78]    Loss 0.405161    Top1 90.250000    Top5 99.593750    
2018-11-02 21:51:20,584 - ==> Top1: 90.260    Top5: 99.660    Loss: 0.405

2018-11-02 21:51:20,585 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:51:20,585 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:51:20,596 - 

2018-11-02 21:51:20,596 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:51:21,633 - Epoch: [229][   50/  391]    Overall Loss 0.039965    Objective Loss 0.039965    Top1 98.812500    Top5 100.000000    LR 0.001178    Time 0.020703    
2018-11-02 21:51:22,610 - Epoch: [229][  100/  391]    Overall Loss 0.039836    Objective Loss 0.039836    Top1 98.796875    Top5 100.000000    LR 0.001178    Time 0.020106    
2018-11-02 21:51:23,582 - Epoch: [229][  150/  391]    Overall Loss 0.038758    Objective Loss 0.038758    Top1 98.807292    Top5 100.000000    LR 0.001178    Time 0.019875    
2018-11-02 21:51:24,553 - Epoch: [229][  200/  391]    Overall Loss 0.039060    Objective Loss 0.039060    Top1 98.742188    Top5 100.000000    LR 0.001178    Time 0.019753    
2018-11-02 21:51:25,526 - Epoch: [229][  250/  391]    Overall Loss 0.040177    Objective Loss 0.040177    Top1 98.700000    Top5 100.000000    LR 0.001178    Time 0.019690    
2018-11-02 21:51:26,498 - Epoch: [229][  300/  391]    Overall Loss 0.040511    Objective Loss 0.040511    Top1 98.687500    Top5 100.000000    LR 0.001178    Time 0.019644    
2018-11-02 21:51:27,477 - Epoch: [229][  350/  391]    Overall Loss 0.040464    Objective Loss 0.040464    Top1 98.671875    Top5 100.000000    LR 0.001178    Time 0.019630    
2018-11-02 21:51:28,361 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35082 | -0.00655 |    0.22181 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15667 | -0.00037 |    0.09896 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15660 | -0.00324 |    0.11857 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18847 | -0.04518 |    0.14703 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20109 |  0.00667 |    0.15822 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16816 | -0.02577 |    0.12834 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16392 | -0.00337 |    0.11969 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19749 | -0.00254 |    0.14452 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16328 | -0.00413 |    0.12474 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24240 | -0.00984 |    0.15923 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14387 | -0.00052 |    0.10684 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12058 | -0.01304 |    0.09706 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14560 | -0.01373 |    0.11400 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10648 | -0.00459 |    0.08167 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11681 | -0.01317 |    0.09302 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11076 | -0.00214 |    0.08767 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13775 | -0.00747 |    0.10585 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10493 | -0.00904 |    0.08324 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08988 | -0.00537 |    0.07085 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09070 | -0.01097 |    0.07253 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05469 |  0.00238 |    0.04147 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58271 | -0.00001 |    0.45455 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:51:28,362 - Total sparsity: 0.00

2018-11-02 21:51:28,362 - --- validate (epoch=229)-----------
2018-11-02 21:51:28,362 - 10000 samples (128 per mini-batch)
2018-11-02 21:51:29,087 - Epoch: [229][   50/   78]    Loss 0.404840    Top1 90.296875    Top5 99.625000    
2018-11-02 21:51:29,490 - ==> Top1: 90.400    Top5: 99.700    Loss: 0.403

2018-11-02 21:51:29,491 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:51:29,491 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:51:29,505 - 

2018-11-02 21:51:29,506 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:51:30,538 - Epoch: [230][   50/  391]    Overall Loss 0.040140    Objective Loss 0.040140    Top1 98.781250    Top5 100.000000    LR 0.001119    Time 0.020602    
2018-11-02 21:51:31,507 - Epoch: [230][  100/  391]    Overall Loss 0.040789    Objective Loss 0.040789    Top1 98.742188    Top5 100.000000    LR 0.001119    Time 0.019985    
2018-11-02 21:51:32,484 - Epoch: [230][  150/  391]    Overall Loss 0.041053    Objective Loss 0.041053    Top1 98.713542    Top5 100.000000    LR 0.001119    Time 0.019824    
2018-11-02 21:51:33,457 - Epoch: [230][  200/  391]    Overall Loss 0.041014    Objective Loss 0.041014    Top1 98.710938    Top5 100.000000    LR 0.001119    Time 0.019727    
2018-11-02 21:51:34,432 - Epoch: [230][  250/  391]    Overall Loss 0.041086    Objective Loss 0.041086    Top1 98.715625    Top5 100.000000    LR 0.001119    Time 0.019674    
2018-11-02 21:51:35,403 - Epoch: [230][  300/  391]    Overall Loss 0.040698    Objective Loss 0.040698    Top1 98.757812    Top5 100.000000    LR 0.001119    Time 0.019628    
2018-11-02 21:51:36,377 - Epoch: [230][  350/  391]    Overall Loss 0.040548    Objective Loss 0.040548    Top1 98.765625    Top5 100.000000    LR 0.001119    Time 0.019603    
2018-11-02 21:51:37,255 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35067 | -0.00647 |    0.22172 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15661 | -0.00045 |    0.09892 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15653 | -0.00329 |    0.11849 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18836 | -0.04526 |    0.14699 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20100 |  0.00669 |    0.15814 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16810 | -0.02566 |    0.12830 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16385 | -0.00342 |    0.11964 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19741 | -0.00258 |    0.14445 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16321 | -0.00413 |    0.12468 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24230 | -0.00988 |    0.15916 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14381 | -0.00051 |    0.10678 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12053 | -0.01308 |    0.09700 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14554 | -0.01371 |    0.11393 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10643 | -0.00460 |    0.08162 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11676 | -0.01316 |    0.09298 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11071 | -0.00214 |    0.08763 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13770 | -0.00747 |    0.10581 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10488 | -0.00904 |    0.08321 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08984 | -0.00537 |    0.07082 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09066 | -0.01097 |    0.07250 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05466 |  0.00237 |    0.04145 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58276 | -0.00001 |    0.45459 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:51:37,255 - Total sparsity: 0.00

2018-11-02 21:51:37,255 - --- validate (epoch=230)-----------
2018-11-02 21:51:37,255 - 10000 samples (128 per mini-batch)
2018-11-02 21:51:37,981 - Epoch: [230][   50/   78]    Loss 0.401745    Top1 90.500000    Top5 99.578125    
2018-11-02 21:51:38,374 - ==> Top1: 90.570    Top5: 99.660    Loss: 0.400

2018-11-02 21:51:38,374 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:51:38,375 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:51:38,382 - 

2018-11-02 21:51:38,382 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:51:39,433 - Epoch: [231][   50/  391]    Overall Loss 0.042781    Objective Loss 0.042781    Top1 98.468750    Top5 100.000000    LR 0.001063    Time 0.020991    
2018-11-02 21:51:40,408 - Epoch: [231][  100/  391]    Overall Loss 0.042802    Objective Loss 0.042802    Top1 98.507812    Top5 100.000000    LR 0.001063    Time 0.020227    
2018-11-02 21:51:41,382 - Epoch: [231][  150/  391]    Overall Loss 0.041962    Objective Loss 0.041962    Top1 98.567708    Top5 99.994792    LR 0.001063    Time 0.019972    
2018-11-02 21:51:42,355 - Epoch: [231][  200/  391]    Overall Loss 0.040772    Objective Loss 0.040772    Top1 98.632812    Top5 99.996094    LR 0.001063    Time 0.019836    
2018-11-02 21:51:43,327 - Epoch: [231][  250/  391]    Overall Loss 0.041033    Objective Loss 0.041033    Top1 98.628125    Top5 99.996875    LR 0.001063    Time 0.019752    
2018-11-02 21:51:44,301 - Epoch: [231][  300/  391]    Overall Loss 0.040485    Objective Loss 0.040485    Top1 98.651042    Top5 99.997396    LR 0.001063    Time 0.019703    
2018-11-02 21:51:45,274 - Epoch: [231][  350/  391]    Overall Loss 0.041742    Objective Loss 0.041742    Top1 98.609375    Top5 99.997768    LR 0.001063    Time 0.019663    
2018-11-02 21:51:46,150 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35053 | -0.00659 |    0.22164 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15654 | -0.00037 |    0.09887 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15646 | -0.00324 |    0.11846 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18829 | -0.04523 |    0.14695 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20092 |  0.00663 |    0.15806 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16802 | -0.02575 |    0.12825 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16378 | -0.00342 |    0.11958 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19733 | -0.00265 |    0.14440 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16314 | -0.00407 |    0.12462 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24220 | -0.00988 |    0.15904 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14375 | -0.00047 |    0.10673 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12048 | -0.01305 |    0.09696 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14548 | -0.01374 |    0.11390 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10639 | -0.00459 |    0.08158 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11672 | -0.01317 |    0.09294 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11067 | -0.00213 |    0.08760 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13764 | -0.00746 |    0.10576 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10484 | -0.00903 |    0.08318 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08981 | -0.00536 |    0.07079 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09062 | -0.01095 |    0.07248 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05464 |  0.00237 |    0.04144 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58280 | -0.00001 |    0.45462 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:51:46,150 - Total sparsity: 0.00

2018-11-02 21:51:46,150 - --- validate (epoch=231)-----------
2018-11-02 21:51:46,150 - 10000 samples (128 per mini-batch)
2018-11-02 21:51:46,877 - Epoch: [231][   50/   78]    Loss 0.403236    Top1 90.390625    Top5 99.609375    
2018-11-02 21:51:47,272 - ==> Top1: 90.430    Top5: 99.690    Loss: 0.403

2018-11-02 21:51:47,273 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:51:47,273 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:51:47,284 - 

2018-11-02 21:51:47,284 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:51:48,316 - Epoch: [232][   50/  391]    Overall Loss 0.040849    Objective Loss 0.040849    Top1 98.671875    Top5 99.984375    LR 0.001010    Time 0.020608    
2018-11-02 21:51:49,291 - Epoch: [232][  100/  391]    Overall Loss 0.039070    Objective Loss 0.039070    Top1 98.734375    Top5 99.992188    LR 0.001010    Time 0.020031    
2018-11-02 21:51:50,264 - Epoch: [232][  150/  391]    Overall Loss 0.039326    Objective Loss 0.039326    Top1 98.713542    Top5 99.994792    LR 0.001010    Time 0.019837    
2018-11-02 21:51:51,237 - Epoch: [232][  200/  391]    Overall Loss 0.038809    Objective Loss 0.038809    Top1 98.734375    Top5 99.996094    LR 0.001010    Time 0.019735    
2018-11-02 21:51:52,208 - Epoch: [232][  250/  391]    Overall Loss 0.038818    Objective Loss 0.038818    Top1 98.740625    Top5 99.996875    LR 0.001010    Time 0.019668    
2018-11-02 21:51:53,183 - Epoch: [232][  300/  391]    Overall Loss 0.039398    Objective Loss 0.039398    Top1 98.716146    Top5 99.994792    LR 0.001010    Time 0.019635    
2018-11-02 21:51:54,156 - Epoch: [232][  350/  391]    Overall Loss 0.039444    Objective Loss 0.039444    Top1 98.725446    Top5 99.991071    LR 0.001010    Time 0.019607    
2018-11-02 21:51:55,037 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35039 | -0.00670 |    0.22158 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15648 | -0.00034 |    0.09883 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15640 | -0.00322 |    0.11843 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18822 | -0.04519 |    0.14689 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20085 |  0.00650 |    0.15800 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16796 | -0.02573 |    0.12821 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16372 | -0.00342 |    0.11951 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19725 | -0.00263 |    0.14435 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16308 | -0.00409 |    0.12459 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24211 | -0.00983 |    0.15898 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14370 | -0.00044 |    0.10671 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12043 | -0.01303 |    0.09692 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14543 | -0.01372 |    0.11385 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10635 | -0.00455 |    0.08156 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11667 | -0.01314 |    0.09290 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11062 | -0.00213 |    0.08756 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13759 | -0.00746 |    0.10571 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10480 | -0.00903 |    0.08315 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08978 | -0.00535 |    0.07077 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09059 | -0.01095 |    0.07245 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05462 |  0.00237 |    0.04142 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58285 | -0.00001 |    0.45466 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:51:55,037 - Total sparsity: 0.00

2018-11-02 21:51:55,037 - --- validate (epoch=232)-----------
2018-11-02 21:51:55,037 - 10000 samples (128 per mini-batch)
2018-11-02 21:51:55,761 - Epoch: [232][   50/   78]    Loss 0.400945    Top1 90.453125    Top5 99.625000    
2018-11-02 21:51:56,153 - ==> Top1: 90.480    Top5: 99.690    Loss: 0.400

2018-11-02 21:51:56,154 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:51:56,154 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:51:56,165 - 

2018-11-02 21:51:56,165 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:51:57,265 - Epoch: [233][   50/  391]    Overall Loss 0.036076    Objective Loss 0.036076    Top1 98.781250    Top5 100.000000    LR 0.000960    Time 0.021959    
2018-11-02 21:51:58,259 - Epoch: [233][  100/  391]    Overall Loss 0.036787    Objective Loss 0.036787    Top1 98.765625    Top5 100.000000    LR 0.000960    Time 0.020904    
2018-11-02 21:51:59,232 - Epoch: [233][  150/  391]    Overall Loss 0.038271    Objective Loss 0.038271    Top1 98.718750    Top5 99.994792    LR 0.000960    Time 0.020414    
2018-11-02 21:52:00,208 - Epoch: [233][  200/  391]    Overall Loss 0.037756    Objective Loss 0.037756    Top1 98.757812    Top5 99.996094    LR 0.000960    Time 0.020183    
2018-11-02 21:52:01,183 - Epoch: [233][  250/  391]    Overall Loss 0.039318    Objective Loss 0.039318    Top1 98.715625    Top5 99.996875    LR 0.000960    Time 0.020042    
2018-11-02 21:52:02,158 - Epoch: [233][  300/  391]    Overall Loss 0.040093    Objective Loss 0.040093    Top1 98.682292    Top5 99.997396    LR 0.000960    Time 0.019948    
2018-11-02 21:52:03,133 - Epoch: [233][  350/  391]    Overall Loss 0.039792    Objective Loss 0.039792    Top1 98.696429    Top5 99.997768    LR 0.000960    Time 0.019880    
2018-11-02 21:52:04,012 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35027 | -0.00626 |    0.22151 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15642 | -0.00041 |    0.09877 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15635 | -0.00322 |    0.11838 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18814 | -0.04523 |    0.14686 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20077 |  0.00656 |    0.15793 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16791 | -0.02565 |    0.12814 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16366 | -0.00340 |    0.11948 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19718 | -0.00262 |    0.14429 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16302 | -0.00408 |    0.12454 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24202 | -0.00979 |    0.15895 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14364 | -0.00044 |    0.10667 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12039 | -0.01304 |    0.09688 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14537 | -0.01371 |    0.11379 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10631 | -0.00455 |    0.08152 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11663 | -0.01313 |    0.09287 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11058 | -0.00212 |    0.08753 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13753 | -0.00746 |    0.10567 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10476 | -0.00901 |    0.08312 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08974 | -0.00534 |    0.07074 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09056 | -0.01096 |    0.07242 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05460 |  0.00237 |    0.04141 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58289 | -0.00001 |    0.45469 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:52:04,012 - Total sparsity: 0.00

2018-11-02 21:52:04,012 - --- validate (epoch=233)-----------
2018-11-02 21:52:04,012 - 10000 samples (128 per mini-batch)
2018-11-02 21:52:04,734 - Epoch: [233][   50/   78]    Loss 0.407079    Top1 90.281250    Top5 99.609375    
2018-11-02 21:52:05,125 - ==> Top1: 90.360    Top5: 99.690    Loss: 0.407

2018-11-02 21:52:05,126 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:52:05,126 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:52:05,138 - 

2018-11-02 21:52:05,138 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:52:06,246 - Epoch: [234][   50/  391]    Overall Loss 0.036699    Objective Loss 0.036699    Top1 98.906250    Top5 100.000000    LR 0.000912    Time 0.022124    
2018-11-02 21:52:07,248 - Epoch: [234][  100/  391]    Overall Loss 0.039095    Objective Loss 0.039095    Top1 98.773438    Top5 100.000000    LR 0.000912    Time 0.021065    
2018-11-02 21:52:08,223 - Epoch: [234][  150/  391]    Overall Loss 0.039240    Objective Loss 0.039240    Top1 98.786458    Top5 99.994792    LR 0.000912    Time 0.020535    
2018-11-02 21:52:09,199 - Epoch: [234][  200/  391]    Overall Loss 0.038664    Objective Loss 0.038664    Top1 98.796875    Top5 99.996094    LR 0.000912    Time 0.020276    
2018-11-02 21:52:10,172 - Epoch: [234][  250/  391]    Overall Loss 0.039023    Objective Loss 0.039023    Top1 98.781250    Top5 99.993750    LR 0.000912    Time 0.020107    
2018-11-02 21:52:11,145 - Epoch: [234][  300/  391]    Overall Loss 0.039138    Objective Loss 0.039138    Top1 98.776042    Top5 99.994792    LR 0.000912    Time 0.019998    
2018-11-02 21:52:12,121 - Epoch: [234][  350/  391]    Overall Loss 0.039362    Objective Loss 0.039362    Top1 98.770089    Top5 99.995536    LR 0.000912    Time 0.019926    
2018-11-02 21:52:13,004 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35014 | -0.00656 |    0.22145 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15637 | -0.00049 |    0.09873 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15629 | -0.00324 |    0.11834 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18808 | -0.04519 |    0.14679 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20070 |  0.00654 |    0.15789 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16785 | -0.02564 |    0.12809 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16360 | -0.00333 |    0.11943 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19711 | -0.00262 |    0.14426 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16296 | -0.00411 |    0.12451 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24193 | -0.00978 |    0.15884 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14359 | -0.00046 |    0.10663 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12034 | -0.01307 |    0.09686 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14532 | -0.01368 |    0.11375 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10627 | -0.00456 |    0.08150 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11659 | -0.01312 |    0.09284 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11055 | -0.00213 |    0.08750 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13749 | -0.00745 |    0.10563 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10473 | -0.00900 |    0.08309 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08971 | -0.00533 |    0.07072 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09052 | -0.01096 |    0.07240 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05458 |  0.00237 |    0.04139 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58292 | -0.00001 |    0.45471 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:52:13,004 - Total sparsity: 0.00

2018-11-02 21:52:13,004 - --- validate (epoch=234)-----------
2018-11-02 21:52:13,005 - 10000 samples (128 per mini-batch)
2018-11-02 21:52:13,733 - Epoch: [234][   50/   78]    Loss 0.403732    Top1 90.343750    Top5 99.625000    
2018-11-02 21:52:14,129 - ==> Top1: 90.400    Top5: 99.690    Loss: 0.404

2018-11-02 21:52:14,130 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:52:14,130 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:52:14,138 - 

2018-11-02 21:52:14,138 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:52:15,170 - Epoch: [235][   50/  391]    Overall Loss 0.040644    Objective Loss 0.040644    Top1 98.656250    Top5 99.968750    LR 0.000866    Time 0.020603    
2018-11-02 21:52:16,144 - Epoch: [235][  100/  391]    Overall Loss 0.037600    Objective Loss 0.037600    Top1 98.796875    Top5 99.984375    LR 0.000866    Time 0.020024    
2018-11-02 21:52:17,114 - Epoch: [235][  150/  391]    Overall Loss 0.039152    Objective Loss 0.039152    Top1 98.760417    Top5 99.989583    LR 0.000866    Time 0.019814    
2018-11-02 21:52:18,090 - Epoch: [235][  200/  391]    Overall Loss 0.038863    Objective Loss 0.038863    Top1 98.773438    Top5 99.992188    LR 0.000866    Time 0.019732    
2018-11-02 21:52:19,065 - Epoch: [235][  250/  391]    Overall Loss 0.038896    Objective Loss 0.038896    Top1 98.803125    Top5 99.993750    LR 0.000866    Time 0.019682    
2018-11-02 21:52:20,040 - Epoch: [235][  300/  391]    Overall Loss 0.038520    Objective Loss 0.038520    Top1 98.789062    Top5 99.992188    LR 0.000866    Time 0.019648    
2018-11-02 21:52:21,012 - Epoch: [235][  350/  391]    Overall Loss 0.038360    Objective Loss 0.038360    Top1 98.783482    Top5 99.993304    LR 0.000866    Time 0.019616    
2018-11-02 21:52:21,891 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35003 | -0.00622 |    0.22134 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15632 | -0.00052 |    0.09868 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15624 | -0.00329 |    0.11831 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18803 | -0.04512 |    0.14675 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20063 |  0.00662 |    0.15784 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16780 | -0.02560 |    0.12806 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16355 | -0.00334 |    0.11938 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19705 | -0.00258 |    0.14420 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16291 | -0.00413 |    0.12447 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24185 | -0.00979 |    0.15875 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14355 | -0.00043 |    0.10659 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12031 | -0.01303 |    0.09683 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14528 | -0.01366 |    0.11371 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10624 | -0.00458 |    0.08148 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11655 | -0.01311 |    0.09281 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11051 | -0.00212 |    0.08748 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13744 | -0.00746 |    0.10559 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10469 | -0.00899 |    0.08306 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08968 | -0.00532 |    0.07069 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09049 | -0.01096 |    0.07237 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05456 |  0.00237 |    0.04138 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58296 | -0.00001 |    0.45474 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:52:21,891 - Total sparsity: 0.00

2018-11-02 21:52:21,891 - --- validate (epoch=235)-----------
2018-11-02 21:52:21,891 - 10000 samples (128 per mini-batch)
2018-11-02 21:52:22,617 - Epoch: [235][   50/   78]    Loss 0.404596    Top1 90.234375    Top5 99.609375    
2018-11-02 21:52:23,014 - ==> Top1: 90.330    Top5: 99.670    Loss: 0.404

2018-11-02 21:52:23,015 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:52:23,015 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:52:23,026 - 

2018-11-02 21:52:23,026 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:52:24,059 - Epoch: [236][   50/  391]    Overall Loss 0.038472    Objective Loss 0.038472    Top1 98.796875    Top5 99.984375    LR 0.000823    Time 0.020628    
2018-11-02 21:52:25,033 - Epoch: [236][  100/  391]    Overall Loss 0.040556    Objective Loss 0.040556    Top1 98.625000    Top5 99.992188    LR 0.000823    Time 0.020038    
2018-11-02 21:52:26,004 - Epoch: [236][  150/  391]    Overall Loss 0.040372    Objective Loss 0.040372    Top1 98.671875    Top5 99.994792    LR 0.000823    Time 0.019828    
2018-11-02 21:52:26,976 - Epoch: [236][  200/  391]    Overall Loss 0.039096    Objective Loss 0.039096    Top1 98.761719    Top5 99.996094    LR 0.000823    Time 0.019719    
2018-11-02 21:52:27,948 - Epoch: [236][  250/  391]    Overall Loss 0.038020    Objective Loss 0.038020    Top1 98.800000    Top5 99.996875    LR 0.000823    Time 0.019660    
2018-11-02 21:52:28,922 - Epoch: [236][  300/  391]    Overall Loss 0.038103    Objective Loss 0.038103    Top1 98.817708    Top5 99.997396    LR 0.000823    Time 0.019626    
2018-11-02 21:52:29,897 - Epoch: [236][  350/  391]    Overall Loss 0.038187    Objective Loss 0.038187    Top1 98.810268    Top5 99.997768    LR 0.000823    Time 0.019594    
2018-11-02 21:52:30,777 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34992 | -0.00627 |    0.22129 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15627 | -0.00046 |    0.09867 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15619 | -0.00336 |    0.11826 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18797 | -0.04510 |    0.14671 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20057 |  0.00677 |    0.15779 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16774 | -0.02562 |    0.12800 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16350 | -0.00334 |    0.11934 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19698 | -0.00257 |    0.14416 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16286 | -0.00412 |    0.12442 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24178 | -0.00980 |    0.15870 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14350 | -0.00038 |    0.10657 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12027 | -0.01303 |    0.09679 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14524 | -0.01361 |    0.11367 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10620 | -0.00459 |    0.08145 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11652 | -0.01310 |    0.09278 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11047 | -0.00213 |    0.08745 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13740 | -0.00745 |    0.10555 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10466 | -0.00898 |    0.08303 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08966 | -0.00531 |    0.07067 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09047 | -0.01096 |    0.07235 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05454 |  0.00237 |    0.04137 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58300 | -0.00001 |    0.45477 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:52:30,777 - Total sparsity: 0.00

2018-11-02 21:52:30,777 - --- validate (epoch=236)-----------
2018-11-02 21:52:30,777 - 10000 samples (128 per mini-batch)
2018-11-02 21:52:31,504 - Epoch: [236][   50/   78]    Loss 0.407146    Top1 90.484375    Top5 99.609375    
2018-11-02 21:52:31,898 - ==> Top1: 90.520    Top5: 99.700    Loss: 0.408

2018-11-02 21:52:31,899 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:52:31,899 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:52:31,907 - 

2018-11-02 21:52:31,907 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:52:32,942 - Epoch: [237][   50/  391]    Overall Loss 0.037925    Objective Loss 0.037925    Top1 98.781250    Top5 100.000000    LR 0.000782    Time 0.020659    
2018-11-02 21:52:33,913 - Epoch: [237][  100/  391]    Overall Loss 0.038577    Objective Loss 0.038577    Top1 98.773438    Top5 99.992188    LR 0.000782    Time 0.020026    
2018-11-02 21:52:34,887 - Epoch: [237][  150/  391]    Overall Loss 0.037601    Objective Loss 0.037601    Top1 98.812500    Top5 99.989583    LR 0.000782    Time 0.019834    
2018-11-02 21:52:35,860 - Epoch: [237][  200/  391]    Overall Loss 0.039102    Objective Loss 0.039102    Top1 98.750000    Top5 99.992188    LR 0.000782    Time 0.019738    
2018-11-02 21:52:36,829 - Epoch: [237][  250/  391]    Overall Loss 0.039332    Objective Loss 0.039332    Top1 98.718750    Top5 99.993750    LR 0.000782    Time 0.019659    
2018-11-02 21:52:37,802 - Epoch: [237][  300/  391]    Overall Loss 0.038699    Objective Loss 0.038699    Top1 98.747396    Top5 99.994792    LR 0.000782    Time 0.019622    
2018-11-02 21:52:38,773 - Epoch: [237][  350/  391]    Overall Loss 0.038620    Objective Loss 0.038620    Top1 98.747768    Top5 99.993304    LR 0.000782    Time 0.019592    
2018-11-02 21:52:39,650 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34981 | -0.00644 |    0.22122 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15622 | -0.00046 |    0.09865 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15614 | -0.00334 |    0.11822 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18794 | -0.04499 |    0.14663 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20051 |  0.00664 |    0.15773 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16769 | -0.02560 |    0.12801 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16345 | -0.00330 |    0.11931 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19693 | -0.00253 |    0.14410 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16281 | -0.00409 |    0.12437 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24170 | -0.00976 |    0.15866 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14346 | -0.00037 |    0.10653 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12023 | -0.01303 |    0.09677 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14520 | -0.01358 |    0.11364 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10617 | -0.00456 |    0.08143 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11648 | -0.01310 |    0.09275 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11044 | -0.00213 |    0.08742 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13736 | -0.00745 |    0.10552 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10463 | -0.00899 |    0.08301 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08963 | -0.00531 |    0.07065 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09044 | -0.01096 |    0.07233 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05453 |  0.00237 |    0.04135 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58303 | -0.00001 |    0.45480 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:52:39,651 - Total sparsity: 0.00

2018-11-02 21:52:39,651 - --- validate (epoch=237)-----------
2018-11-02 21:52:39,651 - 10000 samples (128 per mini-batch)
2018-11-02 21:52:40,377 - Epoch: [237][   50/   78]    Loss 0.407896    Top1 90.312500    Top5 99.625000    
2018-11-02 21:52:40,771 - ==> Top1: 90.300    Top5: 99.690    Loss: 0.408

2018-11-02 21:52:40,771 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:52:40,771 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:52:40,779 - 

2018-11-02 21:52:40,779 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:52:41,812 - Epoch: [238][   50/  391]    Overall Loss 0.035956    Objective Loss 0.035956    Top1 98.953125    Top5 100.000000    LR 0.000743    Time 0.020617    
2018-11-02 21:52:42,782 - Epoch: [238][  100/  391]    Overall Loss 0.036771    Objective Loss 0.036771    Top1 98.898438    Top5 100.000000    LR 0.000743    Time 0.020001    
2018-11-02 21:52:43,756 - Epoch: [238][  150/  391]    Overall Loss 0.036689    Objective Loss 0.036689    Top1 98.859375    Top5 100.000000    LR 0.000743    Time 0.019815    
2018-11-02 21:52:44,727 - Epoch: [238][  200/  391]    Overall Loss 0.036716    Objective Loss 0.036716    Top1 98.859375    Top5 100.000000    LR 0.000743    Time 0.019710    
2018-11-02 21:52:45,700 - Epoch: [238][  250/  391]    Overall Loss 0.036164    Objective Loss 0.036164    Top1 98.887500    Top5 100.000000    LR 0.000743    Time 0.019657    
2018-11-02 21:52:46,674 - Epoch: [238][  300/  391]    Overall Loss 0.035603    Objective Loss 0.035603    Top1 98.916667    Top5 100.000000    LR 0.000743    Time 0.019611    
2018-11-02 21:52:47,645 - Epoch: [238][  350/  391]    Overall Loss 0.036146    Objective Loss 0.036146    Top1 98.919643    Top5 99.997768    LR 0.000743    Time 0.019578    
2018-11-02 21:52:48,539 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34971 | -0.00618 |    0.22114 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15618 | -0.00053 |    0.09861 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15610 | -0.00331 |    0.11819 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18788 | -0.04500 |    0.14659 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20045 |  0.00671 |    0.15769 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16764 | -0.02560 |    0.12797 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16340 | -0.00331 |    0.11927 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19687 | -0.00257 |    0.14405 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16276 | -0.00409 |    0.12434 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24163 | -0.00976 |    0.15862 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14342 | -0.00034 |    0.10651 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12020 | -0.01300 |    0.09674 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14515 | -0.01358 |    0.11361 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10614 | -0.00457 |    0.08140 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11645 | -0.01309 |    0.09272 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11041 | -0.00214 |    0.08740 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13732 | -0.00745 |    0.10550 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10460 | -0.00898 |    0.08298 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08960 | -0.00531 |    0.07063 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09041 | -0.01095 |    0.07231 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05451 |  0.00236 |    0.04134 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58306 | -0.00001 |    0.45483 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:52:48,539 - Total sparsity: 0.00

2018-11-02 21:52:48,539 - --- validate (epoch=238)-----------
2018-11-02 21:52:48,539 - 10000 samples (128 per mini-batch)
2018-11-02 21:52:49,265 - Epoch: [238][   50/   78]    Loss 0.405457    Top1 90.500000    Top5 99.625000    
2018-11-02 21:52:49,661 - ==> Top1: 90.490    Top5: 99.690    Loss: 0.405

2018-11-02 21:52:49,662 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:52:49,662 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:52:49,677 - 

2018-11-02 21:52:49,678 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:52:50,779 - Epoch: [239][   50/  391]    Overall Loss 0.038001    Objective Loss 0.038001    Top1 98.796875    Top5 99.984375    LR 0.000706    Time 0.021985    
2018-11-02 21:52:51,830 - Epoch: [239][  100/  391]    Overall Loss 0.036534    Objective Loss 0.036534    Top1 98.843750    Top5 99.992188    LR 0.000706    Time 0.021489    
2018-11-02 21:52:52,881 - Epoch: [239][  150/  391]    Overall Loss 0.036498    Objective Loss 0.036498    Top1 98.838542    Top5 99.994792    LR 0.000706    Time 0.021327    
2018-11-02 21:52:53,930 - Epoch: [239][  200/  391]    Overall Loss 0.036493    Objective Loss 0.036493    Top1 98.855469    Top5 99.996094    LR 0.000706    Time 0.021233    
2018-11-02 21:52:54,965 - Epoch: [239][  250/  391]    Overall Loss 0.037147    Objective Loss 0.037147    Top1 98.862500    Top5 99.996875    LR 0.000706    Time 0.021122    
2018-11-02 21:52:56,001 - Epoch: [239][  300/  391]    Overall Loss 0.037634    Objective Loss 0.037634    Top1 98.828125    Top5 99.997396    LR 0.000706    Time 0.021053    
2018-11-02 21:52:57,022 - Epoch: [239][  350/  391]    Overall Loss 0.038440    Objective Loss 0.038440    Top1 98.799107    Top5 99.997768    LR 0.000706    Time 0.020948    
2018-11-02 21:52:57,899 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34962 | -0.00628 |    0.22108 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15613 | -0.00051 |    0.09858 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15606 | -0.00330 |    0.11815 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18784 | -0.04492 |    0.14654 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20040 |  0.00670 |    0.15763 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16760 | -0.02559 |    0.12795 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16336 | -0.00332 |    0.11924 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19682 | -0.00257 |    0.14401 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16272 | -0.00411 |    0.12431 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24157 | -0.00978 |    0.15858 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14338 | -0.00033 |    0.10649 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12017 | -0.01300 |    0.09672 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14512 | -0.01356 |    0.11357 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10612 | -0.00456 |    0.08137 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11642 | -0.01309 |    0.09270 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11038 | -0.00215 |    0.08737 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13728 | -0.00745 |    0.10547 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10457 | -0.00898 |    0.08296 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08958 | -0.00531 |    0.07061 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09039 | -0.01095 |    0.07229 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05450 |  0.00235 |    0.04133 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58309 | -0.00001 |    0.45485 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:52:57,899 - Total sparsity: 0.00

2018-11-02 21:52:57,899 - --- validate (epoch=239)-----------
2018-11-02 21:52:57,899 - 10000 samples (128 per mini-batch)
2018-11-02 21:52:58,625 - Epoch: [239][   50/   78]    Loss 0.407934    Top1 90.421875    Top5 99.609375    
2018-11-02 21:52:59,019 - ==> Top1: 90.390    Top5: 99.670    Loss: 0.408

2018-11-02 21:52:59,020 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:52:59,020 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:52:59,027 - 

2018-11-02 21:52:59,028 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:53:00,063 - Epoch: [240][   50/  391]    Overall Loss 0.037289    Objective Loss 0.037289    Top1 98.859375    Top5 100.000000    LR 0.000670    Time 0.020664    
2018-11-02 21:53:01,043 - Epoch: [240][  100/  391]    Overall Loss 0.036185    Objective Loss 0.036185    Top1 98.882812    Top5 100.000000    LR 0.000670    Time 0.020120    
2018-11-02 21:53:02,020 - Epoch: [240][  150/  391]    Overall Loss 0.037629    Objective Loss 0.037629    Top1 98.854167    Top5 100.000000    LR 0.000670    Time 0.019917    
2018-11-02 21:53:02,995 - Epoch: [240][  200/  391]    Overall Loss 0.037847    Objective Loss 0.037847    Top1 98.812500    Top5 99.996094    LR 0.000670    Time 0.019809    
2018-11-02 21:53:03,968 - Epoch: [240][  250/  391]    Overall Loss 0.038112    Objective Loss 0.038112    Top1 98.787500    Top5 99.996875    LR 0.000670    Time 0.019733    
2018-11-02 21:53:04,944 - Epoch: [240][  300/  391]    Overall Loss 0.037311    Objective Loss 0.037311    Top1 98.841146    Top5 99.997396    LR 0.000670    Time 0.019693    
2018-11-02 21:53:05,919 - Epoch: [240][  350/  391]    Overall Loss 0.037859    Objective Loss 0.037859    Top1 98.812500    Top5 99.997768    LR 0.000670    Time 0.019664    
2018-11-02 21:53:06,800 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34953 | -0.00614 |    0.22100 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15609 | -0.00053 |    0.09857 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15602 | -0.00326 |    0.11812 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18778 | -0.04496 |    0.14650 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20034 |  0.00675 |    0.15761 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16755 | -0.02561 |    0.12792 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16331 | -0.00332 |    0.11920 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19677 | -0.00255 |    0.14397 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16268 | -0.00409 |    0.12427 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24151 | -0.00978 |    0.15852 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14334 | -0.00033 |    0.10646 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12013 | -0.01301 |    0.09671 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14508 | -0.01353 |    0.11354 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10609 | -0.00457 |    0.08136 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11639 | -0.01308 |    0.09267 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11035 | -0.00215 |    0.08735 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13724 | -0.00745 |    0.10544 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10454 | -0.00897 |    0.08294 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08956 | -0.00531 |    0.07059 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09037 | -0.01094 |    0.07227 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05448 |  0.00236 |    0.04132 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58313 | -0.00001 |    0.45486 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:53:06,800 - Total sparsity: 0.00

2018-11-02 21:53:06,800 - --- validate (epoch=240)-----------
2018-11-02 21:53:06,800 - 10000 samples (128 per mini-batch)
2018-11-02 21:53:07,528 - Epoch: [240][   50/   78]    Loss 0.409143    Top1 90.265625    Top5 99.609375    
2018-11-02 21:53:07,922 - ==> Top1: 90.400    Top5: 99.680    Loss: 0.410

2018-11-02 21:53:07,923 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:53:07,923 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:53:07,931 - 

2018-11-02 21:53:07,931 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:53:08,964 - Epoch: [241][   50/  391]    Overall Loss 0.037002    Objective Loss 0.037002    Top1 98.890625    Top5 99.984375    LR 0.000637    Time 0.020627    
2018-11-02 21:53:09,936 - Epoch: [241][  100/  391]    Overall Loss 0.038194    Objective Loss 0.038194    Top1 98.796875    Top5 99.992188    LR 0.000637    Time 0.020019    
2018-11-02 21:53:10,911 - Epoch: [241][  150/  391]    Overall Loss 0.038508    Objective Loss 0.038508    Top1 98.760417    Top5 99.994792    LR 0.000637    Time 0.019840    
2018-11-02 21:53:11,887 - Epoch: [241][  200/  391]    Overall Loss 0.037815    Objective Loss 0.037815    Top1 98.785156    Top5 99.996094    LR 0.000637    Time 0.019752    
2018-11-02 21:53:12,879 - Epoch: [241][  250/  391]    Overall Loss 0.037886    Objective Loss 0.037886    Top1 98.787500    Top5 99.996875    LR 0.000637    Time 0.019750    
2018-11-02 21:53:13,853 - Epoch: [241][  300/  391]    Overall Loss 0.037696    Objective Loss 0.037696    Top1 98.781250    Top5 99.997396    LR 0.000637    Time 0.019700    
2018-11-02 21:53:14,824 - Epoch: [241][  350/  391]    Overall Loss 0.037810    Objective Loss 0.037810    Top1 98.787946    Top5 99.997768    LR 0.000637    Time 0.019656    
2018-11-02 21:53:15,699 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34944 | -0.00618 |    0.22094 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15606 | -0.00051 |    0.09853 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15598 | -0.00330 |    0.11809 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18773 | -0.04498 |    0.14646 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20029 |  0.00678 |    0.15757 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16751 | -0.02559 |    0.12788 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16328 | -0.00328 |    0.11917 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19672 | -0.00256 |    0.14394 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16263 | -0.00411 |    0.12425 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24145 | -0.00979 |    0.15848 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14331 | -0.00032 |    0.10643 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12011 | -0.01299 |    0.09668 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14505 | -0.01353 |    0.11351 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10606 | -0.00457 |    0.08133 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11636 | -0.01307 |    0.09266 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11032 | -0.00213 |    0.08733 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13721 | -0.00745 |    0.10541 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10452 | -0.00896 |    0.08292 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08953 | -0.00530 |    0.07058 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09034 | -0.01093 |    0.07225 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05447 |  0.00236 |    0.04131 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58315 | -0.00001 |    0.45489 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:53:15,699 - Total sparsity: 0.00

2018-11-02 21:53:15,699 - --- validate (epoch=241)-----------
2018-11-02 21:53:15,699 - 10000 samples (128 per mini-batch)
2018-11-02 21:53:16,425 - Epoch: [241][   50/   78]    Loss 0.407869    Top1 90.281250    Top5 99.593750    
2018-11-02 21:53:16,819 - ==> Top1: 90.360    Top5: 99.670    Loss: 0.407

2018-11-02 21:53:16,820 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:53:16,820 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:53:16,831 - 

2018-11-02 21:53:16,832 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:53:17,865 - Epoch: [242][   50/  391]    Overall Loss 0.038538    Objective Loss 0.038538    Top1 98.718750    Top5 100.000000    LR 0.000605    Time 0.020639    
2018-11-02 21:53:18,837 - Epoch: [242][  100/  391]    Overall Loss 0.037441    Objective Loss 0.037441    Top1 98.820312    Top5 100.000000    LR 0.000605    Time 0.020022    
2018-11-02 21:53:19,810 - Epoch: [242][  150/  391]    Overall Loss 0.039610    Objective Loss 0.039610    Top1 98.755208    Top5 100.000000    LR 0.000605    Time 0.019829    
2018-11-02 21:53:20,783 - Epoch: [242][  200/  391]    Overall Loss 0.039745    Objective Loss 0.039745    Top1 98.730469    Top5 100.000000    LR 0.000605    Time 0.019730    
2018-11-02 21:53:21,757 - Epoch: [242][  250/  391]    Overall Loss 0.040296    Objective Loss 0.040296    Top1 98.681250    Top5 100.000000    LR 0.000605    Time 0.019676    
2018-11-02 21:53:22,732 - Epoch: [242][  300/  391]    Overall Loss 0.040539    Objective Loss 0.040539    Top1 98.692708    Top5 100.000000    LR 0.000605    Time 0.019641    
2018-11-02 21:53:23,706 - Epoch: [242][  350/  391]    Overall Loss 0.040344    Objective Loss 0.040344    Top1 98.714286    Top5 99.997768    LR 0.000605    Time 0.019615    
2018-11-02 21:53:24,586 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34936 | -0.00609 |    0.22089 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15602 | -0.00054 |    0.09850 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15594 | -0.00327 |    0.11807 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18769 | -0.04495 |    0.14643 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20024 |  0.00679 |    0.15754 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16747 | -0.02557 |    0.12784 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16324 | -0.00331 |    0.11916 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19667 | -0.00256 |    0.14392 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16260 | -0.00411 |    0.12422 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24139 | -0.00975 |    0.15844 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14327 | -0.00035 |    0.10641 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12008 | -0.01298 |    0.09666 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14501 | -0.01350 |    0.11348 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10604 | -0.00455 |    0.08132 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11633 | -0.01306 |    0.09263 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11030 | -0.00212 |    0.08731 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13718 | -0.00745 |    0.10539 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10449 | -0.00896 |    0.08290 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08951 | -0.00530 |    0.07056 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09032 | -0.01093 |    0.07224 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05446 |  0.00236 |    0.04130 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58317 | -0.00001 |    0.45491 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:53:24,587 - Total sparsity: 0.00

2018-11-02 21:53:24,587 - --- validate (epoch=242)-----------
2018-11-02 21:53:24,587 - 10000 samples (128 per mini-batch)
2018-11-02 21:53:25,315 - Epoch: [242][   50/   78]    Loss 0.409339    Top1 90.375000    Top5 99.593750    
2018-11-02 21:53:25,710 - ==> Top1: 90.380    Top5: 99.670    Loss: 0.409

2018-11-02 21:53:25,710 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:53:25,711 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:53:25,722 - 

2018-11-02 21:53:25,723 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:53:26,757 - Epoch: [243][   50/  391]    Overall Loss 0.040613    Objective Loss 0.040613    Top1 98.687500    Top5 100.000000    LR 0.000575    Time 0.020653    
2018-11-02 21:53:27,740 - Epoch: [243][  100/  391]    Overall Loss 0.042487    Objective Loss 0.042487    Top1 98.601562    Top5 99.992188    LR 0.000575    Time 0.020139    
2018-11-02 21:53:28,723 - Epoch: [243][  150/  391]    Overall Loss 0.040587    Objective Loss 0.040587    Top1 98.671875    Top5 99.994792    LR 0.000575    Time 0.019970    
2018-11-02 21:53:29,694 - Epoch: [243][  200/  391]    Overall Loss 0.039447    Objective Loss 0.039447    Top1 98.734375    Top5 99.996094    LR 0.000575    Time 0.019828    
2018-11-02 21:53:30,667 - Epoch: [243][  250/  391]    Overall Loss 0.039484    Objective Loss 0.039484    Top1 98.740625    Top5 99.996875    LR 0.000575    Time 0.019749    
2018-11-02 21:53:31,639 - Epoch: [243][  300/  391]    Overall Loss 0.040239    Objective Loss 0.040239    Top1 98.731771    Top5 99.997396    LR 0.000575    Time 0.019694    
2018-11-02 21:53:32,613 - Epoch: [243][  350/  391]    Overall Loss 0.040020    Objective Loss 0.040020    Top1 98.741071    Top5 99.997768    LR 0.000575    Time 0.019659    
2018-11-02 21:53:33,492 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34928 | -0.00617 |    0.22081 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15598 | -0.00055 |    0.09849 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15591 | -0.00326 |    0.11804 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18764 | -0.04496 |    0.14640 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20020 |  0.00679 |    0.15750 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16744 | -0.02555 |    0.12780 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16320 | -0.00333 |    0.11912 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19663 | -0.00260 |    0.14389 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16256 | -0.00411 |    0.12420 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24133 | -0.00979 |    0.15839 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14324 | -0.00036 |    0.10638 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12005 | -0.01299 |    0.09663 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14498 | -0.01351 |    0.11347 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10601 | -0.00455 |    0.08129 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11631 | -0.01306 |    0.09261 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11027 | -0.00212 |    0.08729 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13715 | -0.00745 |    0.10537 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10447 | -0.00896 |    0.08288 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08949 | -0.00530 |    0.07054 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09030 | -0.01093 |    0.07222 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05445 |  0.00236 |    0.04129 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58318 | -0.00001 |    0.45491 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:53:33,492 - Total sparsity: 0.00

2018-11-02 21:53:33,492 - --- validate (epoch=243)-----------
2018-11-02 21:53:33,492 - 10000 samples (128 per mini-batch)
2018-11-02 21:53:34,218 - Epoch: [243][   50/   78]    Loss 0.410358    Top1 90.328125    Top5 99.578125    
2018-11-02 21:53:34,610 - ==> Top1: 90.390    Top5: 99.660    Loss: 0.410

2018-11-02 21:53:34,611 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:53:34,611 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:53:34,619 - 

2018-11-02 21:53:34,619 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:53:35,651 - Epoch: [244][   50/  391]    Overall Loss 0.036377    Objective Loss 0.036377    Top1 98.890625    Top5 100.000000    LR 0.000546    Time 0.020595    
2018-11-02 21:53:36,658 - Epoch: [244][  100/  391]    Overall Loss 0.038351    Objective Loss 0.038351    Top1 98.789062    Top5 100.000000    LR 0.000546    Time 0.020356    
2018-11-02 21:53:37,630 - Epoch: [244][  150/  391]    Overall Loss 0.039073    Objective Loss 0.039073    Top1 98.776042    Top5 100.000000    LR 0.000546    Time 0.020042    
2018-11-02 21:53:38,604 - Epoch: [244][  200/  391]    Overall Loss 0.038703    Objective Loss 0.038703    Top1 98.777344    Top5 100.000000    LR 0.000546    Time 0.019894    
2018-11-02 21:53:39,577 - Epoch: [244][  250/  391]    Overall Loss 0.039382    Objective Loss 0.039382    Top1 98.728125    Top5 100.000000    LR 0.000546    Time 0.019805    
2018-11-02 21:53:40,546 - Epoch: [244][  300/  391]    Overall Loss 0.039173    Objective Loss 0.039173    Top1 98.723958    Top5 100.000000    LR 0.000546    Time 0.019730    
2018-11-02 21:53:41,522 - Epoch: [244][  350/  391]    Overall Loss 0.038374    Objective Loss 0.038374    Top1 98.752232    Top5 100.000000    LR 0.000546    Time 0.019695    
2018-11-02 21:53:42,399 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34921 | -0.00626 |    0.22076 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15595 | -0.00054 |    0.09846 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15587 | -0.00328 |    0.11801 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18760 | -0.04499 |    0.14638 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20016 |  0.00674 |    0.15747 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16740 | -0.02557 |    0.12777 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16317 | -0.00332 |    0.11908 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19659 | -0.00262 |    0.14385 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16253 | -0.00409 |    0.12417 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24128 | -0.00979 |    0.15834 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14321 | -0.00034 |    0.10636 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12003 | -0.01300 |    0.09661 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14495 | -0.01351 |    0.11344 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10599 | -0.00455 |    0.08127 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11628 | -0.01305 |    0.09260 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11025 | -0.00213 |    0.08727 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13712 | -0.00745 |    0.10534 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10445 | -0.00895 |    0.08287 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08948 | -0.00531 |    0.07053 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09028 | -0.01093 |    0.07220 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05443 |  0.00236 |    0.04128 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58320 | -0.00001 |    0.45492 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:53:42,399 - Total sparsity: 0.00

2018-11-02 21:53:42,399 - --- validate (epoch=244)-----------
2018-11-02 21:53:42,399 - 10000 samples (128 per mini-batch)
2018-11-02 21:53:43,125 - Epoch: [244][   50/   78]    Loss 0.409938    Top1 90.312500    Top5 99.578125    
2018-11-02 21:53:43,519 - ==> Top1: 90.370    Top5: 99.650    Loss: 0.409

2018-11-02 21:53:43,520 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:53:43,520 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:53:43,527 - 

2018-11-02 21:53:43,528 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:53:44,560 - Epoch: [245][   50/  391]    Overall Loss 0.039298    Objective Loss 0.039298    Top1 98.734375    Top5 99.984375    LR 0.000519    Time 0.020606    
2018-11-02 21:53:45,533 - Epoch: [245][  100/  391]    Overall Loss 0.038667    Objective Loss 0.038667    Top1 98.804688    Top5 99.992188    LR 0.000519    Time 0.020024    
2018-11-02 21:53:46,505 - Epoch: [245][  150/  391]    Overall Loss 0.037716    Objective Loss 0.037716    Top1 98.838542    Top5 99.994792    LR 0.000519    Time 0.019816    
2018-11-02 21:53:47,478 - Epoch: [245][  200/  391]    Overall Loss 0.037817    Objective Loss 0.037817    Top1 98.875000    Top5 99.996094    LR 0.000519    Time 0.019720    
2018-11-02 21:53:48,447 - Epoch: [245][  250/  391]    Overall Loss 0.038987    Objective Loss 0.038987    Top1 98.834375    Top5 99.996875    LR 0.000519    Time 0.019649    
2018-11-02 21:53:49,420 - Epoch: [245][  300/  391]    Overall Loss 0.038676    Objective Loss 0.038676    Top1 98.846354    Top5 99.997396    LR 0.000519    Time 0.019611    
2018-11-02 21:53:50,393 - Epoch: [245][  350/  391]    Overall Loss 0.038007    Objective Loss 0.038007    Top1 98.868304    Top5 99.997768    LR 0.000519    Time 0.019587    
2018-11-02 21:53:51,271 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34914 | -0.00629 |    0.22075 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15592 | -0.00053 |    0.09843 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15584 | -0.00330 |    0.11798 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18756 | -0.04496 |    0.14636 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20012 |  0.00681 |    0.15743 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16736 | -0.02559 |    0.12773 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16313 | -0.00335 |    0.11905 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19655 | -0.00261 |    0.14382 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16249 | -0.00409 |    0.12415 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24124 | -0.00978 |    0.15832 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14318 | -0.00035 |    0.10634 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12000 | -0.01301 |    0.09659 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14492 | -0.01350 |    0.11343 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10597 | -0.00455 |    0.08125 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11626 | -0.01304 |    0.09258 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11023 | -0.00211 |    0.08725 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13709 | -0.00744 |    0.10532 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10443 | -0.00895 |    0.08285 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08946 | -0.00530 |    0.07052 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09027 | -0.01094 |    0.07219 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05442 |  0.00236 |    0.04128 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58323 | -0.00001 |    0.45495 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:53:51,271 - Total sparsity: 0.00

2018-11-02 21:53:51,271 - --- validate (epoch=245)-----------
2018-11-02 21:53:51,271 - 10000 samples (128 per mini-batch)
2018-11-02 21:53:51,996 - Epoch: [245][   50/   78]    Loss 0.404395    Top1 90.687500    Top5 99.593750    
2018-11-02 21:53:52,389 - ==> Top1: 90.630    Top5: 99.680    Loss: 0.406

2018-11-02 21:53:52,390 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:53:52,390 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:53:52,405 - 

2018-11-02 21:53:52,405 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:53:53,438 - Epoch: [246][   50/  391]    Overall Loss 0.037459    Objective Loss 0.037459    Top1 98.703125    Top5 100.000000    LR 0.000493    Time 0.020612    
2018-11-02 21:53:54,411 - Epoch: [246][  100/  391]    Overall Loss 0.037289    Objective Loss 0.037289    Top1 98.789062    Top5 100.000000    LR 0.000493    Time 0.020021    
2018-11-02 21:53:55,386 - Epoch: [246][  150/  391]    Overall Loss 0.038156    Objective Loss 0.038156    Top1 98.744792    Top5 100.000000    LR 0.000493    Time 0.019841    
2018-11-02 21:53:56,361 - Epoch: [246][  200/  391]    Overall Loss 0.038435    Objective Loss 0.038435    Top1 98.777344    Top5 99.996094    LR 0.000493    Time 0.019750    
2018-11-02 21:53:57,334 - Epoch: [246][  250/  391]    Overall Loss 0.039151    Objective Loss 0.039151    Top1 98.750000    Top5 99.996875    LR 0.000493    Time 0.019685    
2018-11-02 21:53:58,307 - Epoch: [246][  300/  391]    Overall Loss 0.038900    Objective Loss 0.038900    Top1 98.768229    Top5 99.997396    LR 0.000493    Time 0.019643    
2018-11-02 21:53:59,281 - Epoch: [246][  350/  391]    Overall Loss 0.039006    Objective Loss 0.039006    Top1 98.767857    Top5 99.997768    LR 0.000493    Time 0.019616    
2018-11-02 21:54:00,163 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34907 | -0.00632 |    0.22070 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15589 | -0.00051 |    0.09843 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15581 | -0.00331 |    0.11796 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18752 | -0.04496 |    0.14633 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20008 |  0.00682 |    0.15740 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16733 | -0.02561 |    0.12772 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16310 | -0.00337 |    0.11903 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19651 | -0.00263 |    0.14379 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16246 | -0.00408 |    0.12412 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24119 | -0.00981 |    0.15828 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14316 | -0.00033 |    0.10631 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11998 | -0.01299 |    0.09657 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14490 | -0.01348 |    0.11342 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10595 | -0.00454 |    0.08124 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11624 | -0.01304 |    0.09256 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11021 | -0.00211 |    0.08724 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13706 | -0.00743 |    0.10531 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10441 | -0.00895 |    0.08283 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08944 | -0.00529 |    0.07050 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09025 | -0.01094 |    0.07218 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05441 |  0.00237 |    0.04127 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58324 | -0.00001 |    0.45495 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:54:00,163 - Total sparsity: 0.00

2018-11-02 21:54:00,163 - --- validate (epoch=246)-----------
2018-11-02 21:54:00,163 - 10000 samples (128 per mini-batch)
2018-11-02 21:54:00,890 - Epoch: [246][   50/   78]    Loss 0.407645    Top1 90.328125    Top5 99.562500    
2018-11-02 21:54:01,284 - ==> Top1: 90.360    Top5: 99.630    Loss: 0.408

2018-11-02 21:54:01,284 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:54:01,285 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:54:01,292 - 

2018-11-02 21:54:01,292 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:54:02,325 - Epoch: [247][   50/  391]    Overall Loss 0.039293    Objective Loss 0.039293    Top1 98.656250    Top5 100.000000    LR 0.000468    Time 0.020613    
2018-11-02 21:54:03,298 - Epoch: [247][  100/  391]    Overall Loss 0.039814    Objective Loss 0.039814    Top1 98.687500    Top5 100.000000    LR 0.000468    Time 0.020024    
2018-11-02 21:54:04,271 - Epoch: [247][  150/  391]    Overall Loss 0.040121    Objective Loss 0.040121    Top1 98.708333    Top5 100.000000    LR 0.000468    Time 0.019831    
2018-11-02 21:54:05,244 - Epoch: [247][  200/  391]    Overall Loss 0.040424    Objective Loss 0.040424    Top1 98.710938    Top5 99.996094    LR 0.000468    Time 0.019728    
2018-11-02 21:54:06,217 - Epoch: [247][  250/  391]    Overall Loss 0.039109    Objective Loss 0.039109    Top1 98.768750    Top5 99.996875    LR 0.000468    Time 0.019671    
2018-11-02 21:54:07,190 - Epoch: [247][  300/  391]    Overall Loss 0.039031    Objective Loss 0.039031    Top1 98.773438    Top5 99.997396    LR 0.000468    Time 0.019631    
2018-11-02 21:54:08,162 - Epoch: [247][  350/  391]    Overall Loss 0.038430    Objective Loss 0.038430    Top1 98.812500    Top5 99.997768    LR 0.000468    Time 0.019597    
2018-11-02 21:54:09,037 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34901 | -0.00643 |    0.22065 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15586 | -0.00051 |    0.09842 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15578 | -0.00332 |    0.11795 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18748 | -0.04498 |    0.14630 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20004 |  0.00681 |    0.15737 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16729 | -0.02562 |    0.12769 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16307 | -0.00334 |    0.11901 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19647 | -0.00263 |    0.14377 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16243 | -0.00409 |    0.12410 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24114 | -0.00981 |    0.15824 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14313 | -0.00031 |    0.10630 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11996 | -0.01298 |    0.09655 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14487 | -0.01348 |    0.11340 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10593 | -0.00455 |    0.08122 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11622 | -0.01305 |    0.09254 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11019 | -0.00212 |    0.08722 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13704 | -0.00744 |    0.10529 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10439 | -0.00894 |    0.08282 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08942 | -0.00530 |    0.07049 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09023 | -0.01094 |    0.07217 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05440 |  0.00236 |    0.04126 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58326 | -0.00001 |    0.45496 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:54:09,037 - Total sparsity: 0.00

2018-11-02 21:54:09,038 - --- validate (epoch=247)-----------
2018-11-02 21:54:09,038 - 10000 samples (128 per mini-batch)
2018-11-02 21:54:09,759 - Epoch: [247][   50/   78]    Loss 0.408454    Top1 90.328125    Top5 99.578125    
2018-11-02 21:54:10,149 - ==> Top1: 90.470    Top5: 99.640    Loss: 0.408

2018-11-02 21:54:10,150 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:54:10,150 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:54:10,161 - 

2018-11-02 21:54:10,162 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:54:11,193 - Epoch: [248][   50/  391]    Overall Loss 0.038148    Objective Loss 0.038148    Top1 98.593750    Top5 100.000000    LR 0.000445    Time 0.020601    
2018-11-02 21:54:12,168 - Epoch: [248][  100/  391]    Overall Loss 0.036508    Objective Loss 0.036508    Top1 98.726562    Top5 100.000000    LR 0.000445    Time 0.020034    
2018-11-02 21:54:13,143 - Epoch: [248][  150/  391]    Overall Loss 0.035388    Objective Loss 0.035388    Top1 98.833333    Top5 100.000000    LR 0.000445    Time 0.019849    
2018-11-02 21:54:14,135 - Epoch: [248][  200/  391]    Overall Loss 0.035463    Objective Loss 0.035463    Top1 98.847656    Top5 100.000000    LR 0.000445    Time 0.019838    
2018-11-02 21:54:15,187 - Epoch: [248][  250/  391]    Overall Loss 0.036765    Objective Loss 0.036765    Top1 98.818750    Top5 99.996875    LR 0.000445    Time 0.020074    
2018-11-02 21:54:16,195 - Epoch: [248][  300/  391]    Overall Loss 0.036576    Objective Loss 0.036576    Top1 98.825521    Top5 99.994792    LR 0.000445    Time 0.020085    
2018-11-02 21:54:17,186 - Epoch: [248][  350/  391]    Overall Loss 0.036801    Objective Loss 0.036801    Top1 98.805804    Top5 99.995536    LR 0.000445    Time 0.020044    
2018-11-02 21:54:18,065 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34894 | -0.00654 |    0.22063 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15584 | -0.00049 |    0.09839 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15576 | -0.00333 |    0.11792 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18745 | -0.04497 |    0.14627 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20001 |  0.00681 |    0.15735 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16727 | -0.02562 |    0.12768 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16304 | -0.00333 |    0.11899 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19644 | -0.00259 |    0.14374 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16241 | -0.00409 |    0.12408 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24110 | -0.00981 |    0.15823 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14311 | -0.00032 |    0.10628 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11994 | -0.01296 |    0.09654 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14485 | -0.01346 |    0.11338 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10591 | -0.00455 |    0.08120 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11620 | -0.01305 |    0.09252 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11017 | -0.00213 |    0.08721 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13701 | -0.00744 |    0.10528 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10437 | -0.00894 |    0.08280 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08941 | -0.00529 |    0.07048 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09021 | -0.01094 |    0.07215 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05439 |  0.00236 |    0.04125 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58328 | -0.00001 |    0.45499 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:54:18,065 - Total sparsity: 0.00

2018-11-02 21:54:18,065 - --- validate (epoch=248)-----------
2018-11-02 21:54:18,065 - 10000 samples (128 per mini-batch)
2018-11-02 21:54:18,794 - Epoch: [248][   50/   78]    Loss 0.409109    Top1 90.546875    Top5 99.562500    
2018-11-02 21:54:19,192 - ==> Top1: 90.490    Top5: 99.650    Loss: 0.410

2018-11-02 21:54:19,193 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:54:19,193 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:54:19,200 - 

2018-11-02 21:54:19,201 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:54:20,239 - Epoch: [249][   50/  391]    Overall Loss 0.033641    Objective Loss 0.033641    Top1 99.078125    Top5 100.000000    LR 0.000422    Time 0.020738    
2018-11-02 21:54:21,211 - Epoch: [249][  100/  391]    Overall Loss 0.035724    Objective Loss 0.035724    Top1 98.898438    Top5 99.984375    LR 0.000422    Time 0.020077    
2018-11-02 21:54:22,183 - Epoch: [249][  150/  391]    Overall Loss 0.036231    Objective Loss 0.036231    Top1 98.875000    Top5 99.989583    LR 0.000422    Time 0.019851    
2018-11-02 21:54:23,160 - Epoch: [249][  200/  391]    Overall Loss 0.037088    Objective Loss 0.037088    Top1 98.828125    Top5 99.992188    LR 0.000422    Time 0.019768    
2018-11-02 21:54:24,135 - Epoch: [249][  250/  391]    Overall Loss 0.036768    Objective Loss 0.036768    Top1 98.853125    Top5 99.993750    LR 0.000422    Time 0.019711    
2018-11-02 21:54:25,107 - Epoch: [249][  300/  391]    Overall Loss 0.037247    Objective Loss 0.037247    Top1 98.854167    Top5 99.994792    LR 0.000422    Time 0.019660    
2018-11-02 21:54:26,078 - Epoch: [249][  350/  391]    Overall Loss 0.037077    Objective Loss 0.037077    Top1 98.839286    Top5 99.995536    LR 0.000422    Time 0.019621    
2018-11-02 21:54:26,954 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34888 | -0.00660 |    0.22059 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15581 | -0.00048 |    0.09838 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15573 | -0.00333 |    0.11791 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18742 | -0.04496 |    0.14624 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19997 |  0.00683 |    0.15732 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16724 | -0.02563 |    0.12767 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16302 | -0.00332 |    0.11897 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19641 | -0.00256 |    0.14372 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16238 | -0.00408 |    0.12406 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24106 | -0.00980 |    0.15821 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14308 | -0.00032 |    0.10627 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11992 | -0.01295 |    0.09652 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14482 | -0.01346 |    0.11336 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10590 | -0.00454 |    0.08119 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11618 | -0.01304 |    0.09251 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11015 | -0.00213 |    0.08719 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13699 | -0.00744 |    0.10526 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10436 | -0.00894 |    0.08279 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08940 | -0.00529 |    0.07046 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09020 | -0.01094 |    0.07214 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05438 |  0.00237 |    0.04125 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58330 | -0.00001 |    0.45499 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:54:26,954 - Total sparsity: 0.00

2018-11-02 21:54:26,954 - --- validate (epoch=249)-----------
2018-11-02 21:54:26,954 - 10000 samples (128 per mini-batch)
2018-11-02 21:54:27,676 - Epoch: [249][   50/   78]    Loss 0.411608    Top1 90.265625    Top5 99.578125    
2018-11-02 21:54:28,066 - ==> Top1: 90.410    Top5: 99.640    Loss: 0.412

2018-11-02 21:54:28,067 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:54:28,067 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:54:28,078 - 

2018-11-02 21:54:28,078 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:54:29,110 - Epoch: [250][   50/  391]    Overall Loss 0.037249    Objective Loss 0.037249    Top1 98.796875    Top5 100.000000    LR 0.000401    Time 0.020590    
2018-11-02 21:54:30,083 - Epoch: [250][  100/  391]    Overall Loss 0.037331    Objective Loss 0.037331    Top1 98.859375    Top5 100.000000    LR 0.000401    Time 0.020017    
2018-11-02 21:54:31,056 - Epoch: [250][  150/  391]    Overall Loss 0.037146    Objective Loss 0.037146    Top1 98.848958    Top5 100.000000    LR 0.000401    Time 0.019822    
2018-11-02 21:54:32,027 - Epoch: [250][  200/  391]    Overall Loss 0.038718    Objective Loss 0.038718    Top1 98.773438    Top5 100.000000    LR 0.000401    Time 0.019715    
2018-11-02 21:54:32,997 - Epoch: [250][  250/  391]    Overall Loss 0.038501    Objective Loss 0.038501    Top1 98.759375    Top5 100.000000    LR 0.000401    Time 0.019649    
2018-11-02 21:54:33,970 - Epoch: [250][  300/  391]    Overall Loss 0.037922    Objective Loss 0.037922    Top1 98.794271    Top5 100.000000    LR 0.000401    Time 0.019613    
2018-11-02 21:54:34,943 - Epoch: [250][  350/  391]    Overall Loss 0.037885    Objective Loss 0.037885    Top1 98.783482    Top5 100.000000    LR 0.000401    Time 0.019589    
2018-11-02 21:54:35,823 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34883 | -0.00645 |    0.22053 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15579 | -0.00048 |    0.09836 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15571 | -0.00333 |    0.11789 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18738 | -0.04499 |    0.14621 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19995 |  0.00679 |    0.15730 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16721 | -0.02564 |    0.12765 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16299 | -0.00334 |    0.11894 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19638 | -0.00262 |    0.14371 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16235 | -0.00407 |    0.12404 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24103 | -0.00978 |    0.15817 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14306 | -0.00034 |    0.10626 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11990 | -0.01294 |    0.09650 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14480 | -0.01346 |    0.11335 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10588 | -0.00453 |    0.08118 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11616 | -0.01305 |    0.09250 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11013 | -0.00212 |    0.08718 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13697 | -0.00743 |    0.10525 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10434 | -0.00894 |    0.08278 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08938 | -0.00529 |    0.07045 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09019 | -0.01094 |    0.07213 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05438 |  0.00237 |    0.04124 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58332 | -0.00001 |    0.45501 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:54:35,823 - Total sparsity: 0.00

2018-11-02 21:54:35,823 - --- validate (epoch=250)-----------
2018-11-02 21:54:35,824 - 10000 samples (128 per mini-batch)
2018-11-02 21:54:36,557 - Epoch: [250][   50/   78]    Loss 0.406571    Top1 90.468750    Top5 99.562500    
2018-11-02 21:54:36,951 - ==> Top1: 90.450    Top5: 99.620    Loss: 0.408

2018-11-02 21:54:36,952 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:54:36,952 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:54:36,960 - 

2018-11-02 21:54:36,960 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:54:38,062 - Epoch: [251][   50/  391]    Overall Loss 0.042642    Objective Loss 0.042642    Top1 98.593750    Top5 100.000000    LR 0.000381    Time 0.021994    
2018-11-02 21:54:39,064 - Epoch: [251][  100/  391]    Overall Loss 0.040265    Objective Loss 0.040265    Top1 98.656250    Top5 100.000000    LR 0.000381    Time 0.021008    
2018-11-02 21:54:40,037 - Epoch: [251][  150/  391]    Overall Loss 0.039898    Objective Loss 0.039898    Top1 98.697917    Top5 100.000000    LR 0.000381    Time 0.020481    
2018-11-02 21:54:41,010 - Epoch: [251][  200/  391]    Overall Loss 0.039232    Objective Loss 0.039232    Top1 98.734375    Top5 100.000000    LR 0.000381    Time 0.020221    
2018-11-02 21:54:41,985 - Epoch: [251][  250/  391]    Overall Loss 0.039096    Objective Loss 0.039096    Top1 98.743750    Top5 99.993750    LR 0.000381    Time 0.020071    
2018-11-02 21:54:42,959 - Epoch: [251][  300/  391]    Overall Loss 0.038366    Objective Loss 0.038366    Top1 98.802083    Top5 99.994792    LR 0.000381    Time 0.019967    
2018-11-02 21:54:43,936 - Epoch: [251][  350/  391]    Overall Loss 0.038463    Objective Loss 0.038463    Top1 98.792411    Top5 99.995536    LR 0.000381    Time 0.019905    
2018-11-02 21:54:44,818 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34878 | -0.00646 |    0.22050 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15576 | -0.00049 |    0.09835 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15568 | -0.00333 |    0.11787 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18736 | -0.04498 |    0.14618 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19991 |  0.00681 |    0.15726 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16718 | -0.02563 |    0.12763 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16297 | -0.00335 |    0.11893 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19635 | -0.00263 |    0.14367 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16233 | -0.00407 |    0.12403 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24099 | -0.00976 |    0.15812 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14304 | -0.00036 |    0.10624 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11989 | -0.01293 |    0.09649 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14478 | -0.01346 |    0.11334 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10586 | -0.00452 |    0.08117 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11614 | -0.01304 |    0.09248 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11012 | -0.00212 |    0.08717 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13695 | -0.00743 |    0.10523 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10432 | -0.00893 |    0.08277 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08937 | -0.00528 |    0.07044 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09017 | -0.01093 |    0.07212 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05437 |  0.00237 |    0.04123 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58333 | -0.00001 |    0.45502 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:54:44,818 - Total sparsity: 0.00

2018-11-02 21:54:44,818 - --- validate (epoch=251)-----------
2018-11-02 21:54:44,818 - 10000 samples (128 per mini-batch)
2018-11-02 21:54:45,553 - Epoch: [251][   50/   78]    Loss 0.410224    Top1 90.250000    Top5 99.578125    
2018-11-02 21:54:45,947 - ==> Top1: 90.390    Top5: 99.640    Loss: 0.410

2018-11-02 21:54:45,948 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:54:45,948 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:54:45,955 - 

2018-11-02 21:54:45,955 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:54:47,067 - Epoch: [252][   50/  391]    Overall Loss 0.037950    Objective Loss 0.037950    Top1 98.812500    Top5 100.000000    LR 0.000362    Time 0.022192    
2018-11-02 21:54:48,056 - Epoch: [252][  100/  391]    Overall Loss 0.038479    Objective Loss 0.038479    Top1 98.796875    Top5 100.000000    LR 0.000362    Time 0.020976    
2018-11-02 21:54:49,028 - Epoch: [252][  150/  391]    Overall Loss 0.037507    Objective Loss 0.037507    Top1 98.828125    Top5 100.000000    LR 0.000362    Time 0.020458    
2018-11-02 21:54:50,000 - Epoch: [252][  200/  391]    Overall Loss 0.037183    Objective Loss 0.037183    Top1 98.867188    Top5 100.000000    LR 0.000362    Time 0.020198    
2018-11-02 21:54:50,969 - Epoch: [252][  250/  391]    Overall Loss 0.036766    Objective Loss 0.036766    Top1 98.871875    Top5 100.000000    LR 0.000362    Time 0.020029    
2018-11-02 21:54:51,940 - Epoch: [252][  300/  391]    Overall Loss 0.037045    Objective Loss 0.037045    Top1 98.882812    Top5 100.000000    LR 0.000362    Time 0.019910    
2018-11-02 21:54:52,913 - Epoch: [252][  350/  391]    Overall Loss 0.036882    Objective Loss 0.036882    Top1 98.881696    Top5 100.000000    LR 0.000362    Time 0.019841    
2018-11-02 21:54:53,793 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34873 | -0.00650 |    0.22048 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15574 | -0.00046 |    0.09834 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15566 | -0.00333 |    0.11785 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18733 | -0.04498 |    0.14615 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19989 |  0.00681 |    0.15724 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16716 | -0.02562 |    0.12761 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16295 | -0.00332 |    0.11891 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19632 | -0.00264 |    0.14366 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16231 | -0.00407 |    0.12401 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24096 | -0.00977 |    0.15811 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14302 | -0.00038 |    0.10623 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11987 | -0.01294 |    0.09648 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14476 | -0.01346 |    0.11332 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10585 | -0.00452 |    0.08115 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11612 | -0.01304 |    0.09247 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11010 | -0.00211 |    0.08715 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13693 | -0.00743 |    0.10522 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10431 | -0.00893 |    0.08275 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08936 | -0.00528 |    0.07043 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09016 | -0.01093 |    0.07211 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05436 |  0.00237 |    0.04123 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58335 | -0.00001 |    0.45503 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:54:53,793 - Total sparsity: 0.00

2018-11-02 21:54:53,793 - --- validate (epoch=252)-----------
2018-11-02 21:54:53,793 - 10000 samples (128 per mini-batch)
2018-11-02 21:54:54,521 - Epoch: [252][   50/   78]    Loss 0.409164    Top1 90.406250    Top5 99.562500    
2018-11-02 21:54:54,915 - ==> Top1: 90.460    Top5: 99.620    Loss: 0.409

2018-11-02 21:54:54,916 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:54:54,916 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:54:54,928 - 

2018-11-02 21:54:54,928 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:54:55,962 - Epoch: [253][   50/  391]    Overall Loss 0.035230    Objective Loss 0.035230    Top1 98.984375    Top5 100.000000    LR 0.000344    Time 0.020641    
2018-11-02 21:54:56,935 - Epoch: [253][  100/  391]    Overall Loss 0.034511    Objective Loss 0.034511    Top1 99.000000    Top5 100.000000    LR 0.000344    Time 0.020038    
2018-11-02 21:54:57,910 - Epoch: [253][  150/  391]    Overall Loss 0.035721    Objective Loss 0.035721    Top1 98.947917    Top5 99.994792    LR 0.000344    Time 0.019850    
2018-11-02 21:54:58,885 - Epoch: [253][  200/  391]    Overall Loss 0.036402    Objective Loss 0.036402    Top1 98.914062    Top5 99.996094    LR 0.000344    Time 0.019756    
2018-11-02 21:54:59,923 - Epoch: [253][  250/  391]    Overall Loss 0.037160    Objective Loss 0.037160    Top1 98.893750    Top5 99.990625    LR 0.000344    Time 0.019952    
2018-11-02 21:55:00,900 - Epoch: [253][  300/  391]    Overall Loss 0.037508    Objective Loss 0.037508    Top1 98.856771    Top5 99.992188    LR 0.000344    Time 0.019880    
2018-11-02 21:55:01,875 - Epoch: [253][  350/  391]    Overall Loss 0.037886    Objective Loss 0.037886    Top1 98.799107    Top5 99.993304    LR 0.000344    Time 0.019821    
2018-11-02 21:55:02,770 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34869 | -0.00650 |    0.22045 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15572 | -0.00047 |    0.09832 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15564 | -0.00332 |    0.11784 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18731 | -0.04493 |    0.14613 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19986 |  0.00674 |    0.15723 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16714 | -0.02563 |    0.12760 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16292 | -0.00330 |    0.11889 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19629 | -0.00266 |    0.14364 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16229 | -0.00408 |    0.12399 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24093 | -0.00977 |    0.15810 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14300 | -0.00038 |    0.10622 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11985 | -0.01293 |    0.09646 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14474 | -0.01345 |    0.11331 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10584 | -0.00451 |    0.08114 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11611 | -0.01304 |    0.09246 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11009 | -0.00211 |    0.08714 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13691 | -0.00743 |    0.10520 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10430 | -0.00893 |    0.08274 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08934 | -0.00528 |    0.07042 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09015 | -0.01093 |    0.07210 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05435 |  0.00237 |    0.04122 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58336 | -0.00001 |    0.45504 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:55:02,771 - Total sparsity: 0.00

2018-11-02 21:55:02,771 - --- validate (epoch=253)-----------
2018-11-02 21:55:02,771 - 10000 samples (128 per mini-batch)
2018-11-02 21:55:03,504 - Epoch: [253][   50/   78]    Loss 0.409454    Top1 90.375000    Top5 99.593750    
2018-11-02 21:55:03,895 - ==> Top1: 90.460    Top5: 99.660    Loss: 0.409

2018-11-02 21:55:03,896 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:55:03,896 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:55:03,903 - 

2018-11-02 21:55:03,904 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:55:04,940 - Epoch: [254][   50/  391]    Overall Loss 0.034521    Objective Loss 0.034521    Top1 98.937500    Top5 100.000000    LR 0.000327    Time 0.020684    
2018-11-02 21:55:05,960 - Epoch: [254][  100/  391]    Overall Loss 0.038529    Objective Loss 0.038529    Top1 98.734375    Top5 100.000000    LR 0.000327    Time 0.020527    
2018-11-02 21:55:06,931 - Epoch: [254][  150/  391]    Overall Loss 0.040033    Objective Loss 0.040033    Top1 98.703125    Top5 100.000000    LR 0.000327    Time 0.020153    
2018-11-02 21:55:07,903 - Epoch: [254][  200/  391]    Overall Loss 0.040183    Objective Loss 0.040183    Top1 98.691406    Top5 100.000000    LR 0.000327    Time 0.019967    
2018-11-02 21:55:08,937 - Epoch: [254][  250/  391]    Overall Loss 0.039945    Objective Loss 0.039945    Top1 98.700000    Top5 100.000000    LR 0.000327    Time 0.020091    
2018-11-02 21:55:09,925 - Epoch: [254][  300/  391]    Overall Loss 0.040047    Objective Loss 0.040047    Top1 98.700521    Top5 100.000000    LR 0.000327    Time 0.020032    
2018-11-02 21:55:10,902 - Epoch: [254][  350/  391]    Overall Loss 0.040313    Objective Loss 0.040313    Top1 98.676339    Top5 100.000000    LR 0.000327    Time 0.019957    
2018-11-02 21:55:11,779 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34864 | -0.00651 |    0.22043 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15570 | -0.00048 |    0.09830 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15562 | -0.00334 |    0.11783 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18729 | -0.04494 |    0.14611 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19984 |  0.00675 |    0.15722 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16712 | -0.02558 |    0.12759 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16290 | -0.00332 |    0.11888 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19627 | -0.00266 |    0.14362 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16227 | -0.00407 |    0.12398 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24089 | -0.00978 |    0.15805 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14298 | -0.00036 |    0.10620 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11984 | -0.01293 |    0.09645 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14472 | -0.01345 |    0.11329 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10582 | -0.00451 |    0.08113 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11610 | -0.01303 |    0.09244 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11007 | -0.00210 |    0.08713 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13690 | -0.00742 |    0.10519 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10428 | -0.00893 |    0.08273 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08933 | -0.00528 |    0.07041 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09014 | -0.01093 |    0.07209 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05435 |  0.00237 |    0.04122 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58337 | -0.00001 |    0.45504 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:55:11,780 - Total sparsity: 0.00

2018-11-02 21:55:11,780 - --- validate (epoch=254)-----------
2018-11-02 21:55:11,780 - 10000 samples (128 per mini-batch)
2018-11-02 21:55:12,497 - Epoch: [254][   50/   78]    Loss 0.408869    Top1 90.640625    Top5 99.578125    
2018-11-02 21:55:12,882 - ==> Top1: 90.600    Top5: 99.640    Loss: 0.410

2018-11-02 21:55:12,883 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:55:12,883 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:55:12,895 - 

2018-11-02 21:55:12,895 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:55:13,927 - Epoch: [255][   50/  391]    Overall Loss 0.036986    Objective Loss 0.036986    Top1 98.796875    Top5 100.000000    LR 0.000311    Time 0.020612    
2018-11-02 21:55:14,901 - Epoch: [255][  100/  391]    Overall Loss 0.038995    Objective Loss 0.038995    Top1 98.781250    Top5 100.000000    LR 0.000311    Time 0.020027    
2018-11-02 21:55:15,876 - Epoch: [255][  150/  391]    Overall Loss 0.038065    Objective Loss 0.038065    Top1 98.807292    Top5 100.000000    LR 0.000311    Time 0.019844    
2018-11-02 21:55:16,851 - Epoch: [255][  200/  391]    Overall Loss 0.037334    Objective Loss 0.037334    Top1 98.804688    Top5 100.000000    LR 0.000311    Time 0.019755    
2018-11-02 21:55:17,823 - Epoch: [255][  250/  391]    Overall Loss 0.037685    Objective Loss 0.037685    Top1 98.778125    Top5 100.000000    LR 0.000311    Time 0.019687    
2018-11-02 21:55:18,798 - Epoch: [255][  300/  391]    Overall Loss 0.037821    Objective Loss 0.037821    Top1 98.768229    Top5 99.997396    LR 0.000311    Time 0.019650    
2018-11-02 21:55:19,771 - Epoch: [255][  350/  391]    Overall Loss 0.037222    Objective Loss 0.037222    Top1 98.790179    Top5 99.997768    LR 0.000311    Time 0.019620    
2018-11-02 21:55:20,656 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34860 | -0.00649 |    0.22040 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15568 | -0.00051 |    0.09829 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15560 | -0.00334 |    0.11781 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18726 | -0.04496 |    0.14609 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19981 |  0.00675 |    0.15719 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16710 | -0.02559 |    0.12757 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16288 | -0.00331 |    0.11886 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19624 | -0.00266 |    0.14360 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16225 | -0.00407 |    0.12396 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24086 | -0.00979 |    0.15802 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14296 | -0.00038 |    0.10619 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11982 | -0.01293 |    0.09644 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14470 | -0.01345 |    0.11327 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10581 | -0.00451 |    0.08112 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11608 | -0.01303 |    0.09243 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11006 | -0.00210 |    0.08712 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13688 | -0.00743 |    0.10518 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10427 | -0.00893 |    0.08272 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08932 | -0.00528 |    0.07041 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09013 | -0.01092 |    0.07209 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05434 |  0.00237 |    0.04121 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58338 | -0.00001 |    0.45505 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:55:20,657 - Total sparsity: 0.00

2018-11-02 21:55:20,657 - --- validate (epoch=255)-----------
2018-11-02 21:55:20,657 - 10000 samples (128 per mini-batch)
2018-11-02 21:55:21,380 - Epoch: [255][   50/   78]    Loss 0.407541    Top1 90.437500    Top5 99.609375    
2018-11-02 21:55:21,796 - ==> Top1: 90.460    Top5: 99.680    Loss: 0.407

2018-11-02 21:55:21,797 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:55:21,797 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:55:21,805 - 

2018-11-02 21:55:21,805 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:55:22,839 - Epoch: [256][   50/  391]    Overall Loss 0.035424    Objective Loss 0.035424    Top1 98.859375    Top5 100.000000    LR 0.000295    Time 0.020645    
2018-11-02 21:55:23,812 - Epoch: [256][  100/  391]    Overall Loss 0.037305    Objective Loss 0.037305    Top1 98.789062    Top5 100.000000    LR 0.000295    Time 0.020040    
2018-11-02 21:55:24,783 - Epoch: [256][  150/  391]    Overall Loss 0.037794    Objective Loss 0.037794    Top1 98.791667    Top5 100.000000    LR 0.000295    Time 0.019824    
2018-11-02 21:55:25,759 - Epoch: [256][  200/  391]    Overall Loss 0.037864    Objective Loss 0.037864    Top1 98.789062    Top5 100.000000    LR 0.000295    Time 0.019738    
2018-11-02 21:55:26,735 - Epoch: [256][  250/  391]    Overall Loss 0.037569    Objective Loss 0.037569    Top1 98.806250    Top5 100.000000    LR 0.000295    Time 0.019690    
2018-11-02 21:55:27,710 - Epoch: [256][  300/  391]    Overall Loss 0.037719    Objective Loss 0.037719    Top1 98.778646    Top5 100.000000    LR 0.000295    Time 0.019655    
2018-11-02 21:55:28,683 - Epoch: [256][  350/  391]    Overall Loss 0.037311    Objective Loss 0.037311    Top1 98.801339    Top5 100.000000    LR 0.000295    Time 0.019624    
2018-11-02 21:55:29,562 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34856 | -0.00638 |    0.22037 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15566 | -0.00052 |    0.09828 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15559 | -0.00332 |    0.11780 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18723 | -0.04497 |    0.14608 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19979 |  0.00674 |    0.15718 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16708 | -0.02559 |    0.12756 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16287 | -0.00331 |    0.11885 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19622 | -0.00263 |    0.14359 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16223 | -0.00406 |    0.12395 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24084 | -0.00977 |    0.15799 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14295 | -0.00038 |    0.10619 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11981 | -0.01293 |    0.09643 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14469 | -0.01345 |    0.11326 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10580 | -0.00451 |    0.08111 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11607 | -0.01302 |    0.09242 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11005 | -0.00210 |    0.08711 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13686 | -0.00742 |    0.10517 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10426 | -0.00893 |    0.08271 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08931 | -0.00528 |    0.07040 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09012 | -0.01093 |    0.07208 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05433 |  0.00237 |    0.04121 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58339 | -0.00001 |    0.45506 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:55:29,563 - Total sparsity: 0.00

2018-11-02 21:55:29,563 - --- validate (epoch=256)-----------
2018-11-02 21:55:29,563 - 10000 samples (128 per mini-batch)
2018-11-02 21:55:30,284 - Epoch: [256][   50/   78]    Loss 0.408738    Top1 90.671875    Top5 99.593750    
2018-11-02 21:55:30,667 - ==> Top1: 90.610    Top5: 99.660    Loss: 0.409

2018-11-02 21:55:30,668 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:55:30,668 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:55:30,676 - 

2018-11-02 21:55:30,677 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:55:31,711 - Epoch: [257][   50/  391]    Overall Loss 0.036340    Objective Loss 0.036340    Top1 98.843750    Top5 100.000000    LR 0.000280    Time 0.020653    
2018-11-02 21:55:32,686 - Epoch: [257][  100/  391]    Overall Loss 0.035472    Objective Loss 0.035472    Top1 98.859375    Top5 100.000000    LR 0.000280    Time 0.020065    
2018-11-02 21:55:33,663 - Epoch: [257][  150/  391]    Overall Loss 0.037524    Objective Loss 0.037524    Top1 98.796875    Top5 100.000000    LR 0.000280    Time 0.019877    
2018-11-02 21:55:34,634 - Epoch: [257][  200/  391]    Overall Loss 0.037388    Objective Loss 0.037388    Top1 98.847656    Top5 99.996094    LR 0.000280    Time 0.019759    
2018-11-02 21:55:35,608 - Epoch: [257][  250/  391]    Overall Loss 0.037029    Objective Loss 0.037029    Top1 98.862500    Top5 99.996875    LR 0.000280    Time 0.019684    
2018-11-02 21:55:36,584 - Epoch: [257][  300/  391]    Overall Loss 0.038240    Objective Loss 0.038240    Top1 98.807292    Top5 99.997396    LR 0.000280    Time 0.019651    
2018-11-02 21:55:37,558 - Epoch: [257][  350/  391]    Overall Loss 0.038278    Objective Loss 0.038278    Top1 98.812500    Top5 99.997768    LR 0.000280    Time 0.019624    
2018-11-02 21:55:38,449 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34852 | -0.00629 |    0.22035 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15565 | -0.00052 |    0.09827 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15557 | -0.00334 |    0.11779 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18721 | -0.04497 |    0.14608 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19977 |  0.00676 |    0.15716 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16707 | -0.02557 |    0.12754 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16285 | -0.00331 |    0.11883 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19620 | -0.00264 |    0.14357 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16221 | -0.00406 |    0.12393 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24081 | -0.00979 |    0.15797 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14293 | -0.00038 |    0.10617 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11979 | -0.01295 |    0.09642 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14467 | -0.01346 |    0.11325 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10579 | -0.00452 |    0.08111 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11606 | -0.01303 |    0.09241 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11004 | -0.00210 |    0.08710 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13685 | -0.00742 |    0.10515 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10425 | -0.00893 |    0.08270 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08930 | -0.00528 |    0.07039 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09011 | -0.01093 |    0.07207 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05433 |  0.00237 |    0.04121 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58340 | -0.00001 |    0.45506 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:55:38,449 - Total sparsity: 0.00

2018-11-02 21:55:38,449 - --- validate (epoch=257)-----------
2018-11-02 21:55:38,449 - 10000 samples (128 per mini-batch)
2018-11-02 21:55:39,177 - Epoch: [257][   50/   78]    Loss 0.410647    Top1 90.484375    Top5 99.578125    
2018-11-02 21:55:39,570 - ==> Top1: 90.540    Top5: 99.670    Loss: 0.410

2018-11-02 21:55:39,571 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:55:39,571 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:55:39,583 - 

2018-11-02 21:55:39,583 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:55:40,614 - Epoch: [258][   50/  391]    Overall Loss 0.035457    Objective Loss 0.035457    Top1 98.859375    Top5 100.000000    LR 0.000266    Time 0.020588    
2018-11-02 21:55:41,588 - Epoch: [258][  100/  391]    Overall Loss 0.036277    Objective Loss 0.036277    Top1 98.859375    Top5 100.000000    LR 0.000266    Time 0.020019    
2018-11-02 21:55:42,560 - Epoch: [258][  150/  391]    Overall Loss 0.037526    Objective Loss 0.037526    Top1 98.822917    Top5 100.000000    LR 0.000266    Time 0.019816    
2018-11-02 21:55:43,534 - Epoch: [258][  200/  391]    Overall Loss 0.038319    Objective Loss 0.038319    Top1 98.800781    Top5 100.000000    LR 0.000266    Time 0.019727    
2018-11-02 21:55:44,508 - Epoch: [258][  250/  391]    Overall Loss 0.038547    Objective Loss 0.038547    Top1 98.800000    Top5 100.000000    LR 0.000266    Time 0.019673    
2018-11-02 21:55:45,481 - Epoch: [258][  300/  391]    Overall Loss 0.039130    Objective Loss 0.039130    Top1 98.763021    Top5 100.000000    LR 0.000266    Time 0.019631    
2018-11-02 21:55:46,455 - Epoch: [258][  350/  391]    Overall Loss 0.038347    Objective Loss 0.038347    Top1 98.796875    Top5 100.000000    LR 0.000266    Time 0.019606    
2018-11-02 21:55:47,329 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34849 | -0.00644 |    0.22032 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15563 | -0.00052 |    0.09826 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15555 | -0.00331 |    0.11777 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18719 | -0.04499 |    0.14607 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19975 |  0.00672 |    0.15714 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16705 | -0.02555 |    0.12752 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16283 | -0.00330 |    0.11881 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19618 | -0.00263 |    0.14355 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16219 | -0.00406 |    0.12392 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24079 | -0.00978 |    0.15797 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14292 | -0.00038 |    0.10616 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11978 | -0.01295 |    0.09641 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14465 | -0.01346 |    0.11324 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10578 | -0.00452 |    0.08110 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11604 | -0.01303 |    0.09240 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11003 | -0.00210 |    0.08709 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13683 | -0.00742 |    0.10514 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10424 | -0.00893 |    0.08270 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08929 | -0.00528 |    0.07038 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09010 | -0.01092 |    0.07206 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05432 |  0.00237 |    0.04120 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58340 | -0.00001 |    0.45507 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:55:47,329 - Total sparsity: 0.00

2018-11-02 21:55:47,329 - --- validate (epoch=258)-----------
2018-11-02 21:55:47,329 - 10000 samples (128 per mini-batch)
2018-11-02 21:55:48,052 - Epoch: [258][   50/   78]    Loss 0.406991    Top1 90.546875    Top5 99.593750    
2018-11-02 21:55:48,446 - ==> Top1: 90.550    Top5: 99.680    Loss: 0.406

2018-11-02 21:55:48,447 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:55:48,447 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:55:48,455 - 

2018-11-02 21:55:48,455 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:55:49,489 - Epoch: [259][   50/  391]    Overall Loss 0.036018    Objective Loss 0.036018    Top1 99.000000    Top5 100.000000    LR 0.000253    Time 0.020644    
2018-11-02 21:55:50,462 - Epoch: [259][  100/  391]    Overall Loss 0.035746    Objective Loss 0.035746    Top1 98.953125    Top5 100.000000    LR 0.000253    Time 0.020042    
2018-11-02 21:55:51,435 - Epoch: [259][  150/  391]    Overall Loss 0.035469    Objective Loss 0.035469    Top1 98.958333    Top5 100.000000    LR 0.000253    Time 0.019839    
2018-11-02 21:55:52,410 - Epoch: [259][  200/  391]    Overall Loss 0.034961    Objective Loss 0.034961    Top1 98.972656    Top5 100.000000    LR 0.000253    Time 0.019749    
2018-11-02 21:55:53,382 - Epoch: [259][  250/  391]    Overall Loss 0.035398    Objective Loss 0.035398    Top1 98.937500    Top5 100.000000    LR 0.000253    Time 0.019682    
2018-11-02 21:55:54,358 - Epoch: [259][  300/  391]    Overall Loss 0.036168    Objective Loss 0.036168    Top1 98.890625    Top5 100.000000    LR 0.000253    Time 0.019651    
2018-11-02 21:55:55,333 - Epoch: [259][  350/  391]    Overall Loss 0.035581    Objective Loss 0.035581    Top1 98.906250    Top5 100.000000    LR 0.000253    Time 0.019625    
2018-11-02 21:55:56,215 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34845 | -0.00636 |    0.22030 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15562 | -0.00053 |    0.09825 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15554 | -0.00330 |    0.11776 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18716 | -0.04500 |    0.14606 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19973 |  0.00674 |    0.15712 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16704 | -0.02554 |    0.12751 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16281 | -0.00330 |    0.11880 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19616 | -0.00262 |    0.14354 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16218 | -0.00405 |    0.12391 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24076 | -0.00977 |    0.15795 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14290 | -0.00038 |    0.10615 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11977 | -0.01295 |    0.09640 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14464 | -0.01346 |    0.11323 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10576 | -0.00451 |    0.08109 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11603 | -0.01302 |    0.09239 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11001 | -0.00210 |    0.08708 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13682 | -0.00742 |    0.10513 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10423 | -0.00892 |    0.08269 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08928 | -0.00528 |    0.07037 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09009 | -0.01092 |    0.07205 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05432 |  0.00237 |    0.04120 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58342 | -0.00001 |    0.45508 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:55:56,215 - Total sparsity: 0.00

2018-11-02 21:55:56,215 - --- validate (epoch=259)-----------
2018-11-02 21:55:56,215 - 10000 samples (128 per mini-batch)
2018-11-02 21:55:56,944 - Epoch: [259][   50/   78]    Loss 0.410333    Top1 90.406250    Top5 99.609375    
2018-11-02 21:55:57,339 - ==> Top1: 90.470    Top5: 99.670    Loss: 0.410

2018-11-02 21:55:57,340 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:55:57,340 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:55:57,347 - 

2018-11-02 21:55:57,347 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:55:58,379 - Epoch: [260][   50/  391]    Overall Loss 0.036401    Objective Loss 0.036401    Top1 98.921875    Top5 100.000000    LR 0.000240    Time 0.020605    
2018-11-02 21:55:59,354 - Epoch: [260][  100/  391]    Overall Loss 0.035933    Objective Loss 0.035933    Top1 98.875000    Top5 100.000000    LR 0.000240    Time 0.020033    
2018-11-02 21:56:00,332 - Epoch: [260][  150/  391]    Overall Loss 0.036318    Objective Loss 0.036318    Top1 98.880208    Top5 100.000000    LR 0.000240    Time 0.019866    
2018-11-02 21:56:01,310 - Epoch: [260][  200/  391]    Overall Loss 0.037026    Objective Loss 0.037026    Top1 98.851562    Top5 100.000000    LR 0.000240    Time 0.019785    
2018-11-02 21:56:02,289 - Epoch: [260][  250/  391]    Overall Loss 0.036574    Objective Loss 0.036574    Top1 98.881250    Top5 100.000000    LR 0.000240    Time 0.019742    
2018-11-02 21:56:03,268 - Epoch: [260][  300/  391]    Overall Loss 0.036321    Objective Loss 0.036321    Top1 98.882812    Top5 100.000000    LR 0.000240    Time 0.019708    
2018-11-02 21:56:04,241 - Epoch: [260][  350/  391]    Overall Loss 0.035968    Objective Loss 0.035968    Top1 98.886161    Top5 100.000000    LR 0.000240    Time 0.019670    
2018-11-02 21:56:05,120 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34842 | -0.00636 |    0.22027 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15560 | -0.00054 |    0.09824 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15552 | -0.00329 |    0.11774 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18715 | -0.04498 |    0.14605 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19971 |  0.00674 |    0.15710 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16702 | -0.02554 |    0.12750 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16280 | -0.00329 |    0.11879 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19614 | -0.00262 |    0.14353 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16216 | -0.00405 |    0.12390 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24074 | -0.00977 |    0.15794 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14289 | -0.00038 |    0.10615 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11976 | -0.01295 |    0.09639 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14463 | -0.01347 |    0.11322 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10575 | -0.00451 |    0.08108 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11602 | -0.01303 |    0.09239 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11000 | -0.00210 |    0.08708 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13681 | -0.00742 |    0.10512 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10422 | -0.00892 |    0.08268 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08928 | -0.00528 |    0.07037 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09008 | -0.01092 |    0.07205 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05431 |  0.00237 |    0.04119 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58343 | -0.00001 |    0.45509 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:56:05,120 - Total sparsity: 0.00

2018-11-02 21:56:05,120 - --- validate (epoch=260)-----------
2018-11-02 21:56:05,120 - 10000 samples (128 per mini-batch)
2018-11-02 21:56:05,844 - Epoch: [260][   50/   78]    Loss 0.409736    Top1 90.296875    Top5 99.609375    
2018-11-02 21:56:06,237 - ==> Top1: 90.390    Top5: 99.670    Loss: 0.409

2018-11-02 21:56:06,238 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:56:06,238 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:56:06,250 - 

2018-11-02 21:56:06,250 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:56:07,315 - Epoch: [261][   50/  391]    Overall Loss 0.042180    Objective Loss 0.042180    Top1 98.609375    Top5 100.000000    LR 0.000228    Time 0.021264    
2018-11-02 21:56:08,288 - Epoch: [261][  100/  391]    Overall Loss 0.042269    Objective Loss 0.042269    Top1 98.656250    Top5 100.000000    LR 0.000228    Time 0.020346    
2018-11-02 21:56:09,261 - Epoch: [261][  150/  391]    Overall Loss 0.040401    Objective Loss 0.040401    Top1 98.682292    Top5 100.000000    LR 0.000228    Time 0.020040    
2018-11-02 21:56:10,234 - Epoch: [261][  200/  391]    Overall Loss 0.039627    Objective Loss 0.039627    Top1 98.710938    Top5 100.000000    LR 0.000228    Time 0.019890    
2018-11-02 21:56:11,209 - Epoch: [261][  250/  391]    Overall Loss 0.039377    Objective Loss 0.039377    Top1 98.728125    Top5 100.000000    LR 0.000228    Time 0.019807    
2018-11-02 21:56:12,185 - Epoch: [261][  300/  391]    Overall Loss 0.039014    Objective Loss 0.039014    Top1 98.742188    Top5 100.000000    LR 0.000228    Time 0.019755    
2018-11-02 21:56:13,158 - Epoch: [261][  350/  391]    Overall Loss 0.038700    Objective Loss 0.038700    Top1 98.758929    Top5 99.997768    LR 0.000228    Time 0.019710    
2018-11-02 21:56:14,038 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34839 | -0.00651 |    0.22026 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15559 | -0.00053 |    0.09823 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15551 | -0.00328 |    0.11773 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18714 | -0.04495 |    0.14604 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19969 |  0.00673 |    0.15709 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16700 | -0.02554 |    0.12749 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16279 | -0.00328 |    0.11877 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19613 | -0.00260 |    0.14351 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16215 | -0.00405 |    0.12389 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24072 | -0.00975 |    0.15793 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14288 | -0.00039 |    0.10614 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11975 | -0.01294 |    0.09638 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14461 | -0.01348 |    0.11321 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10575 | -0.00451 |    0.08107 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11601 | -0.01303 |    0.09238 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10999 | -0.00211 |    0.08707 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13680 | -0.00742 |    0.10511 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10421 | -0.00892 |    0.08267 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08927 | -0.00528 |    0.07036 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09007 | -0.01092 |    0.07204 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05431 |  0.00237 |    0.04119 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58344 | -0.00001 |    0.45509 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:56:14,038 - Total sparsity: 0.00

2018-11-02 21:56:14,038 - --- validate (epoch=261)-----------
2018-11-02 21:56:14,038 - 10000 samples (128 per mini-batch)
2018-11-02 21:56:14,757 - Epoch: [261][   50/   78]    Loss 0.409877    Top1 90.359375    Top5 99.609375    
2018-11-02 21:56:15,147 - ==> Top1: 90.490    Top5: 99.690    Loss: 0.410

2018-11-02 21:56:15,148 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:56:15,148 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:56:15,156 - 

2018-11-02 21:56:15,156 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:56:16,259 - Epoch: [262][   50/  391]    Overall Loss 0.035630    Objective Loss 0.035630    Top1 98.921875    Top5 100.000000    LR 0.000217    Time 0.022022    
2018-11-02 21:56:17,297 - Epoch: [262][  100/  391]    Overall Loss 0.036496    Objective Loss 0.036496    Top1 98.882812    Top5 100.000000    LR 0.000217    Time 0.021382    
2018-11-02 21:56:18,294 - Epoch: [262][  150/  391]    Overall Loss 0.036050    Objective Loss 0.036050    Top1 98.885417    Top5 100.000000    LR 0.000217    Time 0.020893    
2018-11-02 21:56:19,269 - Epoch: [262][  200/  391]    Overall Loss 0.036764    Objective Loss 0.036764    Top1 98.890625    Top5 100.000000    LR 0.000217    Time 0.020541    
2018-11-02 21:56:20,242 - Epoch: [262][  250/  391]    Overall Loss 0.036176    Objective Loss 0.036176    Top1 98.896875    Top5 100.000000    LR 0.000217    Time 0.020318    
2018-11-02 21:56:21,217 - Epoch: [262][  300/  391]    Overall Loss 0.035731    Objective Loss 0.035731    Top1 98.906250    Top5 100.000000    LR 0.000217    Time 0.020179    
2018-11-02 21:56:22,193 - Epoch: [262][  350/  391]    Overall Loss 0.035729    Objective Loss 0.035729    Top1 98.910714    Top5 100.000000    LR 0.000217    Time 0.020079    
2018-11-02 21:56:23,073 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34836 | -0.00644 |    0.22024 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15557 | -0.00054 |    0.09822 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15550 | -0.00328 |    0.11771 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18712 | -0.04496 |    0.14603 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19967 |  0.00673 |    0.15707 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16699 | -0.02556 |    0.12747 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16277 | -0.00328 |    0.11876 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19611 | -0.00261 |    0.14350 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16213 | -0.00405 |    0.12388 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24070 | -0.00975 |    0.15792 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14287 | -0.00038 |    0.10613 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11974 | -0.01293 |    0.09637 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14460 | -0.01347 |    0.11320 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10574 | -0.00451 |    0.08107 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11600 | -0.01302 |    0.09237 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10998 | -0.00211 |    0.08706 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13678 | -0.00741 |    0.10511 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10420 | -0.00892 |    0.08267 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08926 | -0.00527 |    0.07036 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09006 | -0.01092 |    0.07204 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05430 |  0.00237 |    0.04119 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58345 | -0.00001 |    0.45511 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:56:23,074 - Total sparsity: 0.00

2018-11-02 21:56:23,074 - --- validate (epoch=262)-----------
2018-11-02 21:56:23,074 - 10000 samples (128 per mini-batch)
2018-11-02 21:56:23,797 - Epoch: [262][   50/   78]    Loss 0.411248    Top1 90.437500    Top5 99.593750    
2018-11-02 21:56:24,190 - ==> Top1: 90.450    Top5: 99.660    Loss: 0.410

2018-11-02 21:56:24,191 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:56:24,191 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:56:24,206 - 

2018-11-02 21:56:24,206 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:56:25,238 - Epoch: [263][   50/  391]    Overall Loss 0.037239    Objective Loss 0.037239    Top1 98.750000    Top5 100.000000    LR 0.000206    Time 0.020589    
2018-11-02 21:56:26,210 - Epoch: [263][  100/  391]    Overall Loss 0.034017    Objective Loss 0.034017    Top1 98.906250    Top5 100.000000    LR 0.000206    Time 0.020011    
2018-11-02 21:56:27,183 - Epoch: [263][  150/  391]    Overall Loss 0.035515    Objective Loss 0.035515    Top1 98.854167    Top5 100.000000    LR 0.000206    Time 0.019817    
2018-11-02 21:56:28,158 - Epoch: [263][  200/  391]    Overall Loss 0.035018    Objective Loss 0.035018    Top1 98.898438    Top5 100.000000    LR 0.000206    Time 0.019728    
2018-11-02 21:56:29,133 - Epoch: [263][  250/  391]    Overall Loss 0.035833    Objective Loss 0.035833    Top1 98.856250    Top5 100.000000    LR 0.000206    Time 0.019680    
2018-11-02 21:56:30,109 - Epoch: [263][  300/  391]    Overall Loss 0.035785    Objective Loss 0.035785    Top1 98.877604    Top5 100.000000    LR 0.000206    Time 0.019649    
2018-11-02 21:56:31,084 - Epoch: [263][  350/  391]    Overall Loss 0.036129    Objective Loss 0.036129    Top1 98.872768    Top5 100.000000    LR 0.000206    Time 0.019614    
2018-11-02 21:56:31,965 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34833 | -0.00642 |    0.22022 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15556 | -0.00054 |    0.09821 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15548 | -0.00328 |    0.11770 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18711 | -0.04495 |    0.14601 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19966 |  0.00674 |    0.15706 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16698 | -0.02554 |    0.12746 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16276 | -0.00329 |    0.11876 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19609 | -0.00259 |    0.14349 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16212 | -0.00406 |    0.12387 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24068 | -0.00976 |    0.15791 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14285 | -0.00038 |    0.10612 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11973 | -0.01294 |    0.09636 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14459 | -0.01348 |    0.11320 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10573 | -0.00451 |    0.08106 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11599 | -0.01302 |    0.09236 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10998 | -0.00211 |    0.08705 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13677 | -0.00741 |    0.10510 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10419 | -0.00892 |    0.08266 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08925 | -0.00527 |    0.07035 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09006 | -0.01092 |    0.07203 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05430 |  0.00237 |    0.04118 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58346 | -0.00001 |    0.45511 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:56:31,965 - Total sparsity: 0.00

2018-11-02 21:56:31,965 - --- validate (epoch=263)-----------
2018-11-02 21:56:31,966 - 10000 samples (128 per mini-batch)
2018-11-02 21:56:32,693 - Epoch: [263][   50/   78]    Loss 0.411386    Top1 90.453125    Top5 99.593750    
2018-11-02 21:56:33,088 - ==> Top1: 90.540    Top5: 99.670    Loss: 0.410

2018-11-02 21:56:33,089 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:56:33,089 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:56:33,096 - 

2018-11-02 21:56:33,097 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:56:34,128 - Epoch: [264][   50/  391]    Overall Loss 0.034751    Objective Loss 0.034751    Top1 99.000000    Top5 100.000000    LR 0.000196    Time 0.020596    
2018-11-02 21:56:35,104 - Epoch: [264][  100/  391]    Overall Loss 0.036312    Objective Loss 0.036312    Top1 98.851562    Top5 100.000000    LR 0.000196    Time 0.020044    
2018-11-02 21:56:36,077 - Epoch: [264][  150/  391]    Overall Loss 0.036104    Objective Loss 0.036104    Top1 98.848958    Top5 100.000000    LR 0.000196    Time 0.019841    
2018-11-02 21:56:37,050 - Epoch: [264][  200/  391]    Overall Loss 0.037480    Objective Loss 0.037480    Top1 98.773438    Top5 100.000000    LR 0.000196    Time 0.019738    
2018-11-02 21:56:38,021 - Epoch: [264][  250/  391]    Overall Loss 0.037500    Objective Loss 0.037500    Top1 98.803125    Top5 99.996875    LR 0.000196    Time 0.019670    
2018-11-02 21:56:38,992 - Epoch: [264][  300/  391]    Overall Loss 0.037389    Objective Loss 0.037389    Top1 98.815104    Top5 99.997396    LR 0.000196    Time 0.019623    
2018-11-02 21:56:39,964 - Epoch: [264][  350/  391]    Overall Loss 0.037887    Objective Loss 0.037887    Top1 98.781250    Top5 99.997768    LR 0.000196    Time 0.019596    
2018-11-02 21:56:40,841 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34831 | -0.00638 |    0.22022 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15555 | -0.00053 |    0.09820 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15547 | -0.00327 |    0.11769 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18709 | -0.04497 |    0.14600 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19964 |  0.00674 |    0.15705 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16696 | -0.02554 |    0.12745 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16275 | -0.00329 |    0.11875 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19608 | -0.00259 |    0.14348 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16211 | -0.00406 |    0.12385 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24066 | -0.00975 |    0.15790 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14284 | -0.00038 |    0.10611 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11972 | -0.01293 |    0.09636 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14458 | -0.01348 |    0.11319 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10572 | -0.00451 |    0.08106 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11598 | -0.01302 |    0.09236 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10997 | -0.00210 |    0.08705 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13676 | -0.00742 |    0.10509 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10418 | -0.00891 |    0.08265 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08925 | -0.00527 |    0.07034 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09005 | -0.01093 |    0.07202 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05429 |  0.00237 |    0.04118 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58347 | -0.00001 |    0.45512 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:56:40,841 - Total sparsity: 0.00

2018-11-02 21:56:40,841 - --- validate (epoch=264)-----------
2018-11-02 21:56:40,841 - 10000 samples (128 per mini-batch)
2018-11-02 21:56:41,565 - Epoch: [264][   50/   78]    Loss 0.412472    Top1 90.406250    Top5 99.609375    
2018-11-02 21:56:41,953 - ==> Top1: 90.430    Top5: 99.660    Loss: 0.412

2018-11-02 21:56:41,953 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:56:41,954 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:56:41,962 - 

2018-11-02 21:56:41,962 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:56:42,996 - Epoch: [265][   50/  391]    Overall Loss 0.033390    Objective Loss 0.033390    Top1 99.015625    Top5 100.000000    LR 0.000186    Time 0.020646    
2018-11-02 21:56:43,969 - Epoch: [265][  100/  391]    Overall Loss 0.035394    Objective Loss 0.035394    Top1 98.906250    Top5 100.000000    LR 0.000186    Time 0.020037    
2018-11-02 21:56:44,944 - Epoch: [265][  150/  391]    Overall Loss 0.036598    Objective Loss 0.036598    Top1 98.802083    Top5 99.994792    LR 0.000186    Time 0.019852    
2018-11-02 21:56:45,919 - Epoch: [265][  200/  391]    Overall Loss 0.036342    Objective Loss 0.036342    Top1 98.820312    Top5 99.996094    LR 0.000186    Time 0.019756    
2018-11-02 21:56:46,891 - Epoch: [265][  250/  391]    Overall Loss 0.036619    Objective Loss 0.036619    Top1 98.800000    Top5 99.996875    LR 0.000186    Time 0.019688    
2018-11-02 21:56:47,866 - Epoch: [265][  300/  391]    Overall Loss 0.036092    Objective Loss 0.036092    Top1 98.838542    Top5 99.994792    LR 0.000186    Time 0.019651    
2018-11-02 21:56:48,840 - Epoch: [265][  350/  391]    Overall Loss 0.036486    Objective Loss 0.036486    Top1 98.837054    Top5 99.991071    LR 0.000186    Time 0.019623    
2018-11-02 21:56:49,719 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34828 | -0.00632 |    0.22020 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15554 | -0.00053 |    0.09820 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15546 | -0.00327 |    0.11768 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18707 | -0.04498 |    0.14600 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19963 |  0.00676 |    0.15704 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16695 | -0.02553 |    0.12743 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16273 | -0.00329 |    0.11873 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19607 | -0.00259 |    0.14346 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16210 | -0.00405 |    0.12384 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24064 | -0.00977 |    0.15787 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14283 | -0.00038 |    0.10611 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11971 | -0.01293 |    0.09635 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14457 | -0.01348 |    0.11318 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10571 | -0.00452 |    0.08105 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11597 | -0.01302 |    0.09235 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10996 | -0.00210 |    0.08704 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13675 | -0.00741 |    0.10508 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10417 | -0.00891 |    0.08265 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08924 | -0.00527 |    0.07034 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09004 | -0.01093 |    0.07202 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05429 |  0.00237 |    0.04118 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58347 | -0.00001 |    0.45512 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:56:49,720 - Total sparsity: 0.00

2018-11-02 21:56:49,720 - --- validate (epoch=265)-----------
2018-11-02 21:56:49,720 - 10000 samples (128 per mini-batch)
2018-11-02 21:56:50,451 - Epoch: [265][   50/   78]    Loss 0.411398    Top1 90.359375    Top5 99.593750    
2018-11-02 21:56:50,841 - ==> Top1: 90.430    Top5: 99.670    Loss: 0.410

2018-11-02 21:56:50,842 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:56:50,842 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:56:50,853 - 

2018-11-02 21:56:50,854 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:56:51,887 - Epoch: [266][   50/  391]    Overall Loss 0.037763    Objective Loss 0.037763    Top1 98.750000    Top5 100.000000    LR 0.000177    Time 0.020621    
2018-11-02 21:56:52,859 - Epoch: [266][  100/  391]    Overall Loss 0.037877    Objective Loss 0.037877    Top1 98.703125    Top5 100.000000    LR 0.000177    Time 0.020023    
2018-11-02 21:56:53,835 - Epoch: [266][  150/  391]    Overall Loss 0.038008    Objective Loss 0.038008    Top1 98.734375    Top5 100.000000    LR 0.000177    Time 0.019849    
2018-11-02 21:56:54,809 - Epoch: [266][  200/  391]    Overall Loss 0.037451    Objective Loss 0.037451    Top1 98.785156    Top5 100.000000    LR 0.000177    Time 0.019747    
2018-11-02 21:56:55,782 - Epoch: [266][  250/  391]    Overall Loss 0.037519    Objective Loss 0.037519    Top1 98.759375    Top5 100.000000    LR 0.000177    Time 0.019686    
2018-11-02 21:56:56,753 - Epoch: [266][  300/  391]    Overall Loss 0.037288    Objective Loss 0.037288    Top1 98.791667    Top5 100.000000    LR 0.000177    Time 0.019639    
2018-11-02 21:56:57,726 - Epoch: [266][  350/  391]    Overall Loss 0.037094    Objective Loss 0.037094    Top1 98.801339    Top5 100.000000    LR 0.000177    Time 0.019608    
2018-11-02 21:56:58,602 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34826 | -0.00632 |    0.22018 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15553 | -0.00052 |    0.09819 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15545 | -0.00327 |    0.11767 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18706 | -0.04498 |    0.14598 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19961 |  0.00676 |    0.15704 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16694 | -0.02552 |    0.12742 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16272 | -0.00330 |    0.11873 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19605 | -0.00259 |    0.14346 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16209 | -0.00405 |    0.12384 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24063 | -0.00977 |    0.15786 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14282 | -0.00037 |    0.10610 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11970 | -0.01294 |    0.09634 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14456 | -0.01348 |    0.11317 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10571 | -0.00451 |    0.08105 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11597 | -0.01302 |    0.09234 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10995 | -0.00210 |    0.08704 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13674 | -0.00741 |    0.10507 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10417 | -0.00891 |    0.08264 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08923 | -0.00527 |    0.07033 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09004 | -0.01093 |    0.07201 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05429 |  0.00236 |    0.04118 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58348 | -0.00001 |    0.45513 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:56:58,602 - Total sparsity: 0.00

2018-11-02 21:56:58,602 - --- validate (epoch=266)-----------
2018-11-02 21:56:58,603 - 10000 samples (128 per mini-batch)
2018-11-02 21:56:59,320 - Epoch: [266][   50/   78]    Loss 0.407784    Top1 90.343750    Top5 99.593750    
2018-11-02 21:56:59,711 - ==> Top1: 90.380    Top5: 99.660    Loss: 0.408

2018-11-02 21:56:59,711 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:56:59,712 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:56:59,723 - 

2018-11-02 21:56:59,723 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:57:00,761 - Epoch: [267][   50/  391]    Overall Loss 0.033894    Objective Loss 0.033894    Top1 99.125000    Top5 100.000000    LR 0.000168    Time 0.020717    
2018-11-02 21:57:01,736 - Epoch: [267][  100/  391]    Overall Loss 0.034938    Objective Loss 0.034938    Top1 98.960938    Top5 100.000000    LR 0.000168    Time 0.020096    
2018-11-02 21:57:02,710 - Epoch: [267][  150/  391]    Overall Loss 0.035951    Objective Loss 0.035951    Top1 98.890625    Top5 100.000000    LR 0.000168    Time 0.019883    
2018-11-02 21:57:03,683 - Epoch: [267][  200/  391]    Overall Loss 0.035869    Objective Loss 0.035869    Top1 98.886719    Top5 100.000000    LR 0.000168    Time 0.019767    
2018-11-02 21:57:04,655 - Epoch: [267][  250/  391]    Overall Loss 0.035606    Objective Loss 0.035606    Top1 98.865625    Top5 100.000000    LR 0.000168    Time 0.019684    
2018-11-02 21:57:05,628 - Epoch: [267][  300/  391]    Overall Loss 0.035916    Objective Loss 0.035916    Top1 98.848958    Top5 100.000000    LR 0.000168    Time 0.019644    
2018-11-02 21:57:06,602 - Epoch: [267][  350/  391]    Overall Loss 0.036227    Objective Loss 0.036227    Top1 98.848214    Top5 100.000000    LR 0.000168    Time 0.019617    
2018-11-02 21:57:07,483 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34824 | -0.00623 |    0.22016 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15552 | -0.00052 |    0.09819 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15544 | -0.00327 |    0.11767 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18704 | -0.04499 |    0.14597 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19960 |  0.00676 |    0.15703 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16693 | -0.02553 |    0.12741 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16271 | -0.00331 |    0.11872 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19604 | -0.00260 |    0.14344 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16208 | -0.00405 |    0.12383 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24061 | -0.00976 |    0.15785 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14281 | -0.00037 |    0.10610 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11969 | -0.01294 |    0.09634 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14455 | -0.01348 |    0.11316 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10570 | -0.00452 |    0.08104 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11596 | -0.01302 |    0.09234 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10995 | -0.00210 |    0.08703 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13674 | -0.00741 |    0.10507 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10416 | -0.00891 |    0.08264 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08923 | -0.00527 |    0.07033 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09003 | -0.01092 |    0.07201 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05428 |  0.00237 |    0.04117 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58349 | -0.00001 |    0.45513 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:57:07,483 - Total sparsity: 0.00

2018-11-02 21:57:07,483 - --- validate (epoch=267)-----------
2018-11-02 21:57:07,484 - 10000 samples (128 per mini-batch)
2018-11-02 21:57:08,205 - Epoch: [267][   50/   78]    Loss 0.410043    Top1 90.296875    Top5 99.578125    
2018-11-02 21:57:08,597 - ==> Top1: 90.340    Top5: 99.660    Loss: 0.410

2018-11-02 21:57:08,598 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:57:08,598 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:57:08,612 - 

2018-11-02 21:57:08,613 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:57:09,654 - Epoch: [268][   50/  391]    Overall Loss 0.038744    Objective Loss 0.038744    Top1 98.734375    Top5 100.000000    LR 0.000159    Time 0.020785    
2018-11-02 21:57:10,638 - Epoch: [268][  100/  391]    Overall Loss 0.036548    Objective Loss 0.036548    Top1 98.812500    Top5 100.000000    LR 0.000159    Time 0.020221    
2018-11-02 21:57:11,618 - Epoch: [268][  150/  391]    Overall Loss 0.037094    Objective Loss 0.037094    Top1 98.838542    Top5 100.000000    LR 0.000159    Time 0.020005    
2018-11-02 21:57:12,593 - Epoch: [268][  200/  391]    Overall Loss 0.037668    Objective Loss 0.037668    Top1 98.824219    Top5 100.000000    LR 0.000159    Time 0.019875    
2018-11-02 21:57:13,569 - Epoch: [268][  250/  391]    Overall Loss 0.037022    Objective Loss 0.037022    Top1 98.881250    Top5 100.000000    LR 0.000159    Time 0.019797    
2018-11-02 21:57:14,541 - Epoch: [268][  300/  391]    Overall Loss 0.037172    Objective Loss 0.037172    Top1 98.872396    Top5 100.000000    LR 0.000159    Time 0.019735    
2018-11-02 21:57:15,517 - Epoch: [268][  350/  391]    Overall Loss 0.037368    Objective Loss 0.037368    Top1 98.830357    Top5 100.000000    LR 0.000159    Time 0.019700    
2018-11-02 21:57:16,397 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34821 | -0.00627 |    0.22015 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15551 | -0.00051 |    0.09819 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.00325 |    0.11767 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18703 | -0.04500 |    0.14596 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19959 |  0.00678 |    0.15701 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16692 | -0.02553 |    0.12740 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16270 | -0.00332 |    0.11871 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19603 | -0.00259 |    0.14344 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16207 | -0.00405 |    0.12382 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24060 | -0.00976 |    0.15783 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14280 | -0.00036 |    0.10609 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11969 | -0.01294 |    0.09633 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14454 | -0.01348 |    0.11316 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10569 | -0.00452 |    0.08103 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11595 | -0.01302 |    0.09233 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10994 | -0.00211 |    0.08702 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13673 | -0.00741 |    0.10506 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10415 | -0.00891 |    0.08263 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08922 | -0.00527 |    0.07033 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09002 | -0.01093 |    0.07200 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05428 |  0.00237 |    0.04117 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58349 | -0.00001 |    0.45514 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:57:16,398 - Total sparsity: 0.00

2018-11-02 21:57:16,398 - --- validate (epoch=268)-----------
2018-11-02 21:57:16,398 - 10000 samples (128 per mini-batch)
2018-11-02 21:57:17,117 - Epoch: [268][   50/   78]    Loss 0.413554    Top1 90.406250    Top5 99.578125    
2018-11-02 21:57:17,510 - ==> Top1: 90.420    Top5: 99.660    Loss: 0.413

2018-11-02 21:57:17,511 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:57:17,511 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:57:17,519 - 

2018-11-02 21:57:17,519 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:57:18,564 - Epoch: [269][   50/  391]    Overall Loss 0.037759    Objective Loss 0.037759    Top1 98.765625    Top5 100.000000    LR 0.000151    Time 0.020873    
2018-11-02 21:57:19,538 - Epoch: [269][  100/  391]    Overall Loss 0.035119    Objective Loss 0.035119    Top1 98.929688    Top5 100.000000    LR 0.000151    Time 0.020156    
2018-11-02 21:57:20,506 - Epoch: [269][  150/  391]    Overall Loss 0.035744    Objective Loss 0.035744    Top1 98.921875    Top5 100.000000    LR 0.000151    Time 0.019887    
2018-11-02 21:57:21,479 - Epoch: [269][  200/  391]    Overall Loss 0.036227    Objective Loss 0.036227    Top1 98.910156    Top5 100.000000    LR 0.000151    Time 0.019769    
2018-11-02 21:57:22,450 - Epoch: [269][  250/  391]    Overall Loss 0.036955    Objective Loss 0.036955    Top1 98.865625    Top5 99.996875    LR 0.000151    Time 0.019697    
2018-11-02 21:57:23,424 - Epoch: [269][  300/  391]    Overall Loss 0.036982    Objective Loss 0.036982    Top1 98.861979    Top5 99.997396    LR 0.000151    Time 0.019655    
2018-11-02 21:57:24,398 - Epoch: [269][  350/  391]    Overall Loss 0.037649    Objective Loss 0.037649    Top1 98.821429    Top5 99.995536    LR 0.000151    Time 0.019626    
2018-11-02 21:57:25,275 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34819 | -0.00621 |    0.22012 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15550 | -0.00051 |    0.09819 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15542 | -0.00325 |    0.11766 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18702 | -0.04500 |    0.14595 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19958 |  0.00678 |    0.15701 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16691 | -0.02554 |    0.12740 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16269 | -0.00332 |    0.11871 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19602 | -0.00259 |    0.14343 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16206 | -0.00405 |    0.12381 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24058 | -0.00976 |    0.15782 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14280 | -0.00036 |    0.10608 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11968 | -0.01294 |    0.09633 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14453 | -0.01348 |    0.11315 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10569 | -0.00452 |    0.08103 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11594 | -0.01302 |    0.09233 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10993 | -0.00210 |    0.08702 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13672 | -0.00741 |    0.10505 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10415 | -0.00891 |    0.08263 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08922 | -0.00527 |    0.07032 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09002 | -0.01093 |    0.07200 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05427 |  0.00237 |    0.04117 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58350 | -0.00001 |    0.45514 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:57:25,275 - Total sparsity: 0.00

2018-11-02 21:57:25,275 - --- validate (epoch=269)-----------
2018-11-02 21:57:25,275 - 10000 samples (128 per mini-batch)
2018-11-02 21:57:26,002 - Epoch: [269][   50/   78]    Loss 0.408742    Top1 90.500000    Top5 99.593750    
2018-11-02 21:57:26,393 - ==> Top1: 90.500    Top5: 99.670    Loss: 0.409

2018-11-02 21:57:26,397 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:57:26,398 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:57:26,405 - 

2018-11-02 21:57:26,406 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:57:27,441 - Epoch: [270][   50/  391]    Overall Loss 0.036607    Objective Loss 0.036607    Top1 98.765625    Top5 100.000000    LR 0.000144    Time 0.020676    
2018-11-02 21:57:28,413 - Epoch: [270][  100/  391]    Overall Loss 0.038338    Objective Loss 0.038338    Top1 98.773438    Top5 100.000000    LR 0.000144    Time 0.020041    
2018-11-02 21:57:29,386 - Epoch: [270][  150/  391]    Overall Loss 0.037023    Objective Loss 0.037023    Top1 98.822917    Top5 100.000000    LR 0.000144    Time 0.019839    
2018-11-02 21:57:30,360 - Epoch: [270][  200/  391]    Overall Loss 0.037020    Objective Loss 0.037020    Top1 98.792969    Top5 99.996094    LR 0.000144    Time 0.019739    
2018-11-02 21:57:31,333 - Epoch: [270][  250/  391]    Overall Loss 0.037158    Objective Loss 0.037158    Top1 98.796875    Top5 99.996875    LR 0.000144    Time 0.019678    
2018-11-02 21:57:32,308 - Epoch: [270][  300/  391]    Overall Loss 0.036796    Objective Loss 0.036796    Top1 98.822917    Top5 99.997396    LR 0.000144    Time 0.019644    
2018-11-02 21:57:33,281 - Epoch: [270][  350/  391]    Overall Loss 0.037068    Objective Loss 0.037068    Top1 98.832589    Top5 99.997768    LR 0.000144    Time 0.019615    
2018-11-02 21:57:34,158 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34817 | -0.00619 |    0.22011 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15549 | -0.00051 |    0.09818 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15541 | -0.00326 |    0.11765 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18701 | -0.04500 |    0.14594 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19957 |  0.00677 |    0.15700 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16690 | -0.02553 |    0.12739 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16268 | -0.00333 |    0.11870 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19600 | -0.00259 |    0.14342 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16205 | -0.00405 |    0.12380 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24057 | -0.00977 |    0.15781 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14279 | -0.00035 |    0.10608 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11967 | -0.01294 |    0.09632 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14452 | -0.01347 |    0.11314 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10568 | -0.00452 |    0.08102 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11594 | -0.01302 |    0.09232 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10993 | -0.00211 |    0.08701 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13671 | -0.00741 |    0.10505 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10414 | -0.00891 |    0.08262 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08921 | -0.00527 |    0.07032 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09001 | -0.01093 |    0.07200 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05427 |  0.00237 |    0.04117 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58351 | -0.00001 |    0.45515 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:57:34,158 - Total sparsity: 0.00

2018-11-02 21:57:34,158 - --- validate (epoch=270)-----------
2018-11-02 21:57:34,158 - 10000 samples (128 per mini-batch)
2018-11-02 21:57:34,897 - Epoch: [270][   50/   78]    Loss 0.411438    Top1 90.531250    Top5 99.578125    
2018-11-02 21:57:35,291 - ==> Top1: 90.520    Top5: 99.650    Loss: 0.411

2018-11-02 21:57:35,292 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:57:35,292 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:57:35,300 - 

2018-11-02 21:57:35,300 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:57:36,333 - Epoch: [271][   50/  391]    Overall Loss 0.033818    Objective Loss 0.033818    Top1 99.046875    Top5 100.000000    LR 0.000137    Time 0.020624    
2018-11-02 21:57:37,306 - Epoch: [271][  100/  391]    Overall Loss 0.036876    Objective Loss 0.036876    Top1 98.820312    Top5 100.000000    LR 0.000137    Time 0.020024    
2018-11-02 21:57:38,276 - Epoch: [271][  150/  391]    Overall Loss 0.036922    Objective Loss 0.036922    Top1 98.812500    Top5 100.000000    LR 0.000137    Time 0.019811    
2018-11-02 21:57:39,249 - Epoch: [271][  200/  391]    Overall Loss 0.036648    Objective Loss 0.036648    Top1 98.832031    Top5 100.000000    LR 0.000137    Time 0.019717    
2018-11-02 21:57:40,223 - Epoch: [271][  250/  391]    Overall Loss 0.036327    Objective Loss 0.036327    Top1 98.850000    Top5 100.000000    LR 0.000137    Time 0.019663    
2018-11-02 21:57:41,197 - Epoch: [271][  300/  391]    Overall Loss 0.036972    Objective Loss 0.036972    Top1 98.817708    Top5 100.000000    LR 0.000137    Time 0.019629    
2018-11-02 21:57:42,170 - Epoch: [271][  350/  391]    Overall Loss 0.036395    Objective Loss 0.036395    Top1 98.852679    Top5 100.000000    LR 0.000137    Time 0.019600    
2018-11-02 21:57:43,049 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34816 | -0.00620 |    0.22010 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15548 | -0.00052 |    0.09818 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15540 | -0.00326 |    0.11765 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18700 | -0.04499 |    0.14594 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19955 |  0.00679 |    0.15699 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16689 | -0.02553 |    0.12738 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16267 | -0.00333 |    0.11869 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19599 | -0.00260 |    0.14341 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16204 | -0.00405 |    0.12380 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24056 | -0.00977 |    0.15780 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14278 | -0.00035 |    0.10608 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11967 | -0.01294 |    0.09631 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14451 | -0.01347 |    0.11314 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10567 | -0.00452 |    0.08102 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11593 | -0.01302 |    0.09232 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10992 | -0.00211 |    0.08701 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13670 | -0.00741 |    0.10504 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10414 | -0.00891 |    0.08262 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08921 | -0.00527 |    0.07031 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09001 | -0.01093 |    0.07199 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05427 |  0.00237 |    0.04116 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58351 | -0.00001 |    0.45515 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:57:43,049 - Total sparsity: 0.00

2018-11-02 21:57:43,049 - --- validate (epoch=271)-----------
2018-11-02 21:57:43,050 - 10000 samples (128 per mini-batch)
2018-11-02 21:57:43,776 - Epoch: [271][   50/   78]    Loss 0.412848    Top1 90.312500    Top5 99.593750    
2018-11-02 21:57:44,170 - ==> Top1: 90.410    Top5: 99.660    Loss: 0.412

2018-11-02 21:57:44,171 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:57:44,171 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:57:44,178 - 

2018-11-02 21:57:44,179 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:57:45,212 - Epoch: [272][   50/  391]    Overall Loss 0.035722    Objective Loss 0.035722    Top1 98.906250    Top5 99.984375    LR 0.000130    Time 0.020629    
2018-11-02 21:57:46,188 - Epoch: [272][  100/  391]    Overall Loss 0.037969    Objective Loss 0.037969    Top1 98.773438    Top5 99.992188    LR 0.000130    Time 0.020067    
2018-11-02 21:57:47,165 - Epoch: [272][  150/  391]    Overall Loss 0.036388    Objective Loss 0.036388    Top1 98.869792    Top5 99.994792    LR 0.000130    Time 0.019879    
2018-11-02 21:57:48,140 - Epoch: [272][  200/  391]    Overall Loss 0.036384    Objective Loss 0.036384    Top1 98.863281    Top5 99.996094    LR 0.000130    Time 0.019778    
2018-11-02 21:57:49,115 - Epoch: [272][  250/  391]    Overall Loss 0.036278    Objective Loss 0.036278    Top1 98.837500    Top5 99.996875    LR 0.000130    Time 0.019705    
2018-11-02 21:57:50,087 - Epoch: [272][  300/  391]    Overall Loss 0.037455    Objective Loss 0.037455    Top1 98.786458    Top5 99.997396    LR 0.000130    Time 0.019656    
2018-11-02 21:57:51,063 - Epoch: [272][  350/  391]    Overall Loss 0.037729    Objective Loss 0.037729    Top1 98.790179    Top5 99.993304    LR 0.000130    Time 0.019632    
2018-11-02 21:57:51,944 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34814 | -0.00617 |    0.22009 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15547 | -0.00051 |    0.09817 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15540 | -0.00327 |    0.11764 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18699 | -0.04499 |    0.14593 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19954 |  0.00681 |    0.15698 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16688 | -0.02554 |    0.12737 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16267 | -0.00333 |    0.11869 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19598 | -0.00260 |    0.14340 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16203 | -0.00405 |    0.12379 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24054 | -0.00977 |    0.15780 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14277 | -0.00035 |    0.10607 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11966 | -0.01294 |    0.09631 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14451 | -0.01347 |    0.11313 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10567 | -0.00451 |    0.08101 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11593 | -0.01302 |    0.09231 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10991 | -0.00210 |    0.08701 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13670 | -0.00741 |    0.10504 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10413 | -0.00891 |    0.08261 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08920 | -0.00526 |    0.07031 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09000 | -0.01093 |    0.07199 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05427 |  0.00236 |    0.04116 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58352 | -0.00001 |    0.45515 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:57:51,944 - Total sparsity: 0.00

2018-11-02 21:57:51,944 - --- validate (epoch=272)-----------
2018-11-02 21:57:51,944 - 10000 samples (128 per mini-batch)
2018-11-02 21:57:52,671 - Epoch: [272][   50/   78]    Loss 0.410500    Top1 90.546875    Top5 99.578125    
2018-11-02 21:57:53,062 - ==> Top1: 90.470    Top5: 99.640    Loss: 0.411

2018-11-02 21:57:53,063 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:57:53,063 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:57:53,075 - 

2018-11-02 21:57:53,075 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:57:54,126 - Epoch: [273][   50/  391]    Overall Loss 0.040095    Objective Loss 0.040095    Top1 98.593750    Top5 100.000000    LR 0.000123    Time 0.020983    
2018-11-02 21:57:55,099 - Epoch: [273][  100/  391]    Overall Loss 0.037813    Objective Loss 0.037813    Top1 98.742188    Top5 100.000000    LR 0.000123    Time 0.020212    
2018-11-02 21:57:56,075 - Epoch: [273][  150/  391]    Overall Loss 0.036239    Objective Loss 0.036239    Top1 98.838542    Top5 100.000000    LR 0.000123    Time 0.019972    
2018-11-02 21:57:57,058 - Epoch: [273][  200/  391]    Overall Loss 0.035817    Objective Loss 0.035817    Top1 98.859375    Top5 100.000000    LR 0.000123    Time 0.019889    
2018-11-02 21:57:58,031 - Epoch: [273][  250/  391]    Overall Loss 0.036125    Objective Loss 0.036125    Top1 98.834375    Top5 100.000000    LR 0.000123    Time 0.019799    
2018-11-02 21:57:59,002 - Epoch: [273][  300/  391]    Overall Loss 0.036479    Objective Loss 0.036479    Top1 98.820312    Top5 100.000000    LR 0.000123    Time 0.019730    
2018-11-02 21:57:59,975 - Epoch: [273][  350/  391]    Overall Loss 0.036986    Objective Loss 0.036986    Top1 98.799107    Top5 100.000000    LR 0.000123    Time 0.019687    
2018-11-02 21:58:00,853 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34812 | -0.00612 |    0.22008 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15547 | -0.00051 |    0.09817 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15539 | -0.00327 |    0.11764 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18698 | -0.04498 |    0.14593 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19953 |  0.00680 |    0.15697 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16687 | -0.02553 |    0.12737 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16266 | -0.00333 |    0.11868 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19597 | -0.00260 |    0.14340 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16202 | -0.00405 |    0.12378 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24053 | -0.00977 |    0.15779 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14277 | -0.00035 |    0.10607 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11966 | -0.01294 |    0.09631 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14450 | -0.01347 |    0.11313 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10566 | -0.00452 |    0.08101 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11592 | -0.01302 |    0.09231 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10991 | -0.00210 |    0.08700 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13669 | -0.00741 |    0.10503 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10413 | -0.00891 |    0.08261 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08920 | -0.00526 |    0.07031 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09000 | -0.01093 |    0.07199 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05426 |  0.00237 |    0.04116 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58352 | -0.00001 |    0.45516 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:58:00,854 - Total sparsity: 0.00

2018-11-02 21:58:00,854 - --- validate (epoch=273)-----------
2018-11-02 21:58:00,854 - 10000 samples (128 per mini-batch)
2018-11-02 21:58:01,582 - Epoch: [273][   50/   78]    Loss 0.411086    Top1 90.593750    Top5 99.578125    
2018-11-02 21:58:01,975 - ==> Top1: 90.590    Top5: 99.650    Loss: 0.412

2018-11-02 21:58:01,976 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:58:01,976 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:58:01,984 - 

2018-11-02 21:58:01,984 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:58:03,017 - Epoch: [274][   50/  391]    Overall Loss 0.034843    Objective Loss 0.034843    Top1 99.078125    Top5 100.000000    LR 0.000117    Time 0.020631    
2018-11-02 21:58:03,992 - Epoch: [274][  100/  391]    Overall Loss 0.035847    Objective Loss 0.035847    Top1 98.968750    Top5 100.000000    LR 0.000117    Time 0.020049    
2018-11-02 21:58:04,964 - Epoch: [274][  150/  391]    Overall Loss 0.035815    Objective Loss 0.035815    Top1 98.953125    Top5 99.994792    LR 0.000117    Time 0.019839    
2018-11-02 21:58:05,939 - Epoch: [274][  200/  391]    Overall Loss 0.036142    Objective Loss 0.036142    Top1 98.921875    Top5 99.996094    LR 0.000117    Time 0.019748    
2018-11-02 21:58:06,912 - Epoch: [274][  250/  391]    Overall Loss 0.036292    Objective Loss 0.036292    Top1 98.915625    Top5 99.996875    LR 0.000117    Time 0.019684    
2018-11-02 21:58:07,887 - Epoch: [274][  300/  391]    Overall Loss 0.036258    Objective Loss 0.036258    Top1 98.898438    Top5 99.997396    LR 0.000117    Time 0.019652    
2018-11-02 21:58:08,863 - Epoch: [274][  350/  391]    Overall Loss 0.037018    Objective Loss 0.037018    Top1 98.866071    Top5 99.997768    LR 0.000117    Time 0.019628    
2018-11-02 21:58:09,739 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34811 | -0.00611 |    0.22007 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15546 | -0.00052 |    0.09816 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15538 | -0.00327 |    0.11763 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18697 | -0.04498 |    0.14592 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19953 |  0.00679 |    0.15696 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16687 | -0.02553 |    0.12736 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16265 | -0.00332 |    0.11868 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19597 | -0.00261 |    0.14339 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16201 | -0.00405 |    0.12378 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24052 | -0.00977 |    0.15779 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14276 | -0.00035 |    0.10606 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11965 | -0.01293 |    0.09630 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14449 | -0.01346 |    0.11312 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10566 | -0.00451 |    0.08101 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11591 | -0.01302 |    0.09230 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10990 | -0.00210 |    0.08700 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13668 | -0.00741 |    0.10503 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10412 | -0.00891 |    0.08260 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08920 | -0.00526 |    0.07030 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09000 | -0.01093 |    0.07198 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05426 |  0.00236 |    0.04116 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58353 | -0.00001 |    0.45516 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:58:09,739 - Total sparsity: 0.00

2018-11-02 21:58:09,740 - --- validate (epoch=274)-----------
2018-11-02 21:58:09,740 - 10000 samples (128 per mini-batch)
2018-11-02 21:58:10,475 - Epoch: [274][   50/   78]    Loss 0.412960    Top1 90.593750    Top5 99.578125    
2018-11-02 21:58:10,864 - ==> Top1: 90.490    Top5: 99.650    Loss: 0.414

2018-11-02 21:58:10,865 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:58:10,865 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:58:10,873 - 

2018-11-02 21:58:10,873 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:58:11,907 - Epoch: [275][   50/  391]    Overall Loss 0.036942    Objective Loss 0.036942    Top1 98.796875    Top5 100.000000    LR 0.000111    Time 0.020636    
2018-11-02 21:58:12,876 - Epoch: [275][  100/  391]    Overall Loss 0.038048    Objective Loss 0.038048    Top1 98.718750    Top5 99.992188    LR 0.000111    Time 0.019996    
2018-11-02 21:58:13,846 - Epoch: [275][  150/  391]    Overall Loss 0.036748    Objective Loss 0.036748    Top1 98.833333    Top5 99.989583    LR 0.000111    Time 0.019791    
2018-11-02 21:58:14,819 - Epoch: [275][  200/  391]    Overall Loss 0.036695    Objective Loss 0.036695    Top1 98.839844    Top5 99.992188    LR 0.000111    Time 0.019700    
2018-11-02 21:58:15,790 - Epoch: [275][  250/  391]    Overall Loss 0.036374    Objective Loss 0.036374    Top1 98.853125    Top5 99.993750    LR 0.000111    Time 0.019638    
2018-11-02 21:58:16,762 - Epoch: [275][  300/  391]    Overall Loss 0.036967    Objective Loss 0.036967    Top1 98.861979    Top5 99.994792    LR 0.000111    Time 0.019590    
2018-11-02 21:58:17,735 - Epoch: [275][  350/  391]    Overall Loss 0.036948    Objective Loss 0.036948    Top1 98.861607    Top5 99.995536    LR 0.000111    Time 0.019569    
2018-11-02 21:58:18,613 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34809 | -0.00617 |    0.22006 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15545 | -0.00051 |    0.09816 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15538 | -0.00327 |    0.11763 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18696 | -0.04498 |    0.14591 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19952 |  0.00679 |    0.15696 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16686 | -0.02553 |    0.12735 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16264 | -0.00333 |    0.11867 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19596 | -0.00260 |    0.14338 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16201 | -0.00405 |    0.12377 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24051 | -0.00977 |    0.15778 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14275 | -0.00036 |    0.10606 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11964 | -0.01293 |    0.09630 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14449 | -0.01346 |    0.11311 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10565 | -0.00451 |    0.08100 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11591 | -0.01302 |    0.09230 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10990 | -0.00210 |    0.08699 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13668 | -0.00741 |    0.10502 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10412 | -0.00891 |    0.08260 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08919 | -0.00526 |    0.07030 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08999 | -0.01093 |    0.07198 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05426 |  0.00236 |    0.04116 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58353 | -0.00001 |    0.45516 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:58:18,613 - Total sparsity: 0.00

2018-11-02 21:58:18,613 - --- validate (epoch=275)-----------
2018-11-02 21:58:18,614 - 10000 samples (128 per mini-batch)
2018-11-02 21:58:19,340 - Epoch: [275][   50/   78]    Loss 0.412973    Top1 90.562500    Top5 99.578125    
2018-11-02 21:58:19,735 - ==> Top1: 90.560    Top5: 99.650    Loss: 0.413

2018-11-02 21:58:19,735 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:58:19,735 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:58:19,747 - 

2018-11-02 21:58:19,747 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:58:20,807 - Epoch: [276][   50/  391]    Overall Loss 0.038780    Objective Loss 0.038780    Top1 98.781250    Top5 100.000000    LR 0.000106    Time 0.021156    
2018-11-02 21:58:21,785 - Epoch: [276][  100/  391]    Overall Loss 0.036023    Objective Loss 0.036023    Top1 98.875000    Top5 100.000000    LR 0.000106    Time 0.020350    
2018-11-02 21:58:22,758 - Epoch: [276][  150/  391]    Overall Loss 0.037192    Objective Loss 0.037192    Top1 98.843750    Top5 100.000000    LR 0.000106    Time 0.020048    
2018-11-02 21:58:23,732 - Epoch: [276][  200/  391]    Overall Loss 0.037287    Objective Loss 0.037287    Top1 98.816406    Top5 100.000000    LR 0.000106    Time 0.019898    
2018-11-02 21:58:24,705 - Epoch: [276][  250/  391]    Overall Loss 0.037183    Objective Loss 0.037183    Top1 98.818750    Top5 100.000000    LR 0.000106    Time 0.019803    
2018-11-02 21:58:25,681 - Epoch: [276][  300/  391]    Overall Loss 0.037417    Objective Loss 0.037417    Top1 98.828125    Top5 99.997396    LR 0.000106    Time 0.019751    
2018-11-02 21:58:26,653 - Epoch: [276][  350/  391]    Overall Loss 0.036958    Objective Loss 0.036958    Top1 98.830357    Top5 99.997768    LR 0.000106    Time 0.019703    
2018-11-02 21:58:27,535 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34808 | -0.00613 |    0.22005 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15545 | -0.00052 |    0.09816 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.00326 |    0.11762 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18695 | -0.04498 |    0.14590 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19951 |  0.00678 |    0.15695 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16685 | -0.02553 |    0.12735 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16264 | -0.00332 |    0.11867 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19595 | -0.00260 |    0.14338 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16200 | -0.00405 |    0.12377 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24050 | -0.00978 |    0.15777 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14275 | -0.00036 |    0.10605 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11964 | -0.01293 |    0.09629 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14448 | -0.01347 |    0.11311 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10565 | -0.00451 |    0.08100 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11591 | -0.01302 |    0.09229 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10989 | -0.00210 |    0.08699 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.00740 |    0.10502 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10411 | -0.00891 |    0.08260 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08919 | -0.00526 |    0.07030 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08999 | -0.01093 |    0.07198 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05426 |  0.00236 |    0.04115 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58353 | -0.00001 |    0.45517 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:58:27,535 - Total sparsity: 0.00

2018-11-02 21:58:27,535 - --- validate (epoch=276)-----------
2018-11-02 21:58:27,535 - 10000 samples (128 per mini-batch)
2018-11-02 21:58:28,257 - Epoch: [276][   50/   78]    Loss 0.413151    Top1 90.531250    Top5 99.578125    
2018-11-02 21:58:28,647 - ==> Top1: 90.500    Top5: 99.660    Loss: 0.413

2018-11-02 21:58:28,648 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:58:28,648 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:58:28,656 - 

2018-11-02 21:58:28,656 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:58:29,761 - Epoch: [277][   50/  391]    Overall Loss 0.038214    Objective Loss 0.038214    Top1 98.718750    Top5 100.000000    LR 0.000100    Time 0.022057    
2018-11-02 21:58:30,805 - Epoch: [277][  100/  391]    Overall Loss 0.036628    Objective Loss 0.036628    Top1 98.703125    Top5 99.992188    LR 0.000100    Time 0.021456    
2018-11-02 21:58:31,789 - Epoch: [277][  150/  391]    Overall Loss 0.037329    Objective Loss 0.037329    Top1 98.744792    Top5 99.994792    LR 0.000100    Time 0.020860    
2018-11-02 21:58:32,764 - Epoch: [277][  200/  391]    Overall Loss 0.037413    Objective Loss 0.037413    Top1 98.769531    Top5 99.996094    LR 0.000100    Time 0.020494    
2018-11-02 21:58:33,737 - Epoch: [277][  250/  391]    Overall Loss 0.037304    Objective Loss 0.037304    Top1 98.793750    Top5 99.996875    LR 0.000100    Time 0.020282    
2018-11-02 21:58:34,712 - Epoch: [277][  300/  391]    Overall Loss 0.037183    Objective Loss 0.037183    Top1 98.812500    Top5 99.997396    LR 0.000100    Time 0.020148    
2018-11-02 21:58:35,685 - Epoch: [277][  350/  391]    Overall Loss 0.037604    Objective Loss 0.037604    Top1 98.796875    Top5 99.995536    LR 0.000100    Time 0.020046    
2018-11-02 21:58:36,565 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34806 | -0.00615 |    0.22004 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15544 | -0.00052 |    0.09815 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15536 | -0.00326 |    0.11762 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18695 | -0.04498 |    0.14589 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19950 |  0.00678 |    0.15694 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16685 | -0.02552 |    0.12734 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16263 | -0.00332 |    0.11866 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19594 | -0.00260 |    0.14337 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16199 | -0.00405 |    0.12376 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24049 | -0.00978 |    0.15776 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14274 | -0.00037 |    0.10605 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11964 | -0.01293 |    0.09629 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14447 | -0.01347 |    0.11311 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10565 | -0.00451 |    0.08100 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11590 | -0.01302 |    0.09229 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10989 | -0.00210 |    0.08699 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.00740 |    0.10502 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10411 | -0.00891 |    0.08259 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08918 | -0.00526 |    0.07030 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08998 | -0.01093 |    0.07197 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05425 |  0.00236 |    0.04115 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58354 | -0.00001 |    0.45517 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:58:36,565 - Total sparsity: 0.00

2018-11-02 21:58:36,565 - --- validate (epoch=277)-----------
2018-11-02 21:58:36,565 - 10000 samples (128 per mini-batch)
2018-11-02 21:58:37,285 - Epoch: [277][   50/   78]    Loss 0.408843    Top1 90.546875    Top5 99.578125    
2018-11-02 21:58:37,677 - ==> Top1: 90.490    Top5: 99.650    Loss: 0.410

2018-11-02 21:58:37,678 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:58:37,678 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:58:37,685 - 

2018-11-02 21:58:37,685 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:58:38,717 - Epoch: [278][   50/  391]    Overall Loss 0.034925    Objective Loss 0.034925    Top1 98.843750    Top5 100.000000    LR 0.000095    Time 0.020597    
2018-11-02 21:58:39,689 - Epoch: [278][  100/  391]    Overall Loss 0.037335    Objective Loss 0.037335    Top1 98.781250    Top5 100.000000    LR 0.000095    Time 0.020007    
2018-11-02 21:58:40,660 - Epoch: [278][  150/  391]    Overall Loss 0.036749    Objective Loss 0.036749    Top1 98.828125    Top5 100.000000    LR 0.000095    Time 0.019806    
2018-11-02 21:58:41,705 - Epoch: [278][  200/  391]    Overall Loss 0.036536    Objective Loss 0.036536    Top1 98.835938    Top5 100.000000    LR 0.000095    Time 0.020070    
2018-11-02 21:58:42,752 - Epoch: [278][  250/  391]    Overall Loss 0.037288    Objective Loss 0.037288    Top1 98.787500    Top5 100.000000    LR 0.000095    Time 0.020240    
2018-11-02 21:58:43,784 - Epoch: [278][  300/  391]    Overall Loss 0.037307    Objective Loss 0.037307    Top1 98.783854    Top5 100.000000    LR 0.000095    Time 0.020290    
2018-11-02 21:58:44,758 - Epoch: [278][  350/  391]    Overall Loss 0.036331    Objective Loss 0.036331    Top1 98.848214    Top5 100.000000    LR 0.000095    Time 0.020172    
2018-11-02 21:58:45,633 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34805 | -0.00615 |    0.22003 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.00051 |    0.09815 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15536 | -0.00325 |    0.11761 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18694 | -0.04498 |    0.14588 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19949 |  0.00677 |    0.15694 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16684 | -0.02550 |    0.12734 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16262 | -0.00333 |    0.11866 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19593 | -0.00260 |    0.14337 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16199 | -0.00405 |    0.12376 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24048 | -0.00978 |    0.15775 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14274 | -0.00037 |    0.10605 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11963 | -0.01293 |    0.09629 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14447 | -0.01347 |    0.11310 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10564 | -0.00451 |    0.08099 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11590 | -0.01301 |    0.09229 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10989 | -0.00210 |    0.08698 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13666 | -0.00740 |    0.10501 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10410 | -0.00891 |    0.08259 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08918 | -0.00526 |    0.07029 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08998 | -0.01093 |    0.07197 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05425 |  0.00236 |    0.04115 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58354 | -0.00001 |    0.45517 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:58:45,633 - Total sparsity: 0.00

2018-11-02 21:58:45,633 - --- validate (epoch=278)-----------
2018-11-02 21:58:45,633 - 10000 samples (128 per mini-batch)
2018-11-02 21:58:46,363 - Epoch: [278][   50/   78]    Loss 0.409525    Top1 90.406250    Top5 99.593750    
2018-11-02 21:58:46,757 - ==> Top1: 90.510    Top5: 99.680    Loss: 0.410

2018-11-02 21:58:46,758 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:58:46,758 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:58:46,773 - 

2018-11-02 21:58:46,774 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:58:47,806 - Epoch: [279][   50/  391]    Overall Loss 0.036357    Objective Loss 0.036357    Top1 98.906250    Top5 100.000000    LR 0.000091    Time 0.020599    
2018-11-02 21:58:48,779 - Epoch: [279][  100/  391]    Overall Loss 0.039183    Objective Loss 0.039183    Top1 98.726562    Top5 100.000000    LR 0.000091    Time 0.020020    
2018-11-02 21:58:49,754 - Epoch: [279][  150/  391]    Overall Loss 0.037838    Objective Loss 0.037838    Top1 98.859375    Top5 100.000000    LR 0.000091    Time 0.019835    
2018-11-02 21:58:50,729 - Epoch: [279][  200/  391]    Overall Loss 0.037860    Objective Loss 0.037860    Top1 98.851562    Top5 100.000000    LR 0.000091    Time 0.019744    
2018-11-02 21:58:51,704 - Epoch: [279][  250/  391]    Overall Loss 0.037617    Objective Loss 0.037617    Top1 98.846875    Top5 100.000000    LR 0.000091    Time 0.019692    
2018-11-02 21:58:52,679 - Epoch: [279][  300/  391]    Overall Loss 0.037759    Objective Loss 0.037759    Top1 98.843750    Top5 100.000000    LR 0.000091    Time 0.019655    
2018-11-02 21:58:53,655 - Epoch: [279][  350/  391]    Overall Loss 0.037560    Objective Loss 0.037560    Top1 98.852679    Top5 100.000000    LR 0.000091    Time 0.019634    
2018-11-02 21:58:54,537 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34804 | -0.00612 |    0.22003 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.00052 |    0.09814 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15535 | -0.00326 |    0.11761 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18693 | -0.04499 |    0.14588 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19949 |  0.00677 |    0.15693 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16684 | -0.02550 |    0.12733 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16262 | -0.00333 |    0.11865 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19593 | -0.00260 |    0.14336 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16198 | -0.00405 |    0.12375 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24047 | -0.00978 |    0.15774 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14273 | -0.00037 |    0.10604 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11963 | -0.01293 |    0.09628 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14446 | -0.01347 |    0.11310 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10564 | -0.00451 |    0.08099 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11589 | -0.01301 |    0.09229 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10988 | -0.00210 |    0.08698 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13666 | -0.00740 |    0.10501 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10410 | -0.00891 |    0.08259 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08918 | -0.00526 |    0.07029 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08998 | -0.01093 |    0.07197 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05425 |  0.00236 |    0.04115 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58354 | -0.00001 |    0.45517 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:58:54,537 - Total sparsity: 0.00

2018-11-02 21:58:54,537 - --- validate (epoch=279)-----------
2018-11-02 21:58:54,537 - 10000 samples (128 per mini-batch)
2018-11-02 21:58:55,263 - Epoch: [279][   50/   78]    Loss 0.409299    Top1 90.453125    Top5 99.578125    
2018-11-02 21:58:55,659 - ==> Top1: 90.450    Top5: 99.640    Loss: 0.409

2018-11-02 21:58:55,660 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:58:55,660 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:58:55,668 - 

2018-11-02 21:58:55,668 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:58:56,702 - Epoch: [280][   50/  391]    Overall Loss 0.032108    Objective Loss 0.032108    Top1 99.031250    Top5 100.000000    LR 0.000086    Time 0.020641    
2018-11-02 21:58:57,677 - Epoch: [280][  100/  391]    Overall Loss 0.033257    Objective Loss 0.033257    Top1 98.960938    Top5 100.000000    LR 0.000086    Time 0.020060    
2018-11-02 21:58:58,650 - Epoch: [280][  150/  391]    Overall Loss 0.034164    Objective Loss 0.034164    Top1 99.010417    Top5 100.000000    LR 0.000086    Time 0.019848    
2018-11-02 21:58:59,626 - Epoch: [280][  200/  391]    Overall Loss 0.034555    Objective Loss 0.034555    Top1 98.992188    Top5 100.000000    LR 0.000086    Time 0.019759    
2018-11-02 21:59:00,606 - Epoch: [280][  250/  391]    Overall Loss 0.034207    Objective Loss 0.034207    Top1 98.993750    Top5 100.000000    LR 0.000086    Time 0.019721    
2018-11-02 21:59:01,581 - Epoch: [280][  300/  391]    Overall Loss 0.035331    Objective Loss 0.035331    Top1 98.927083    Top5 100.000000    LR 0.000086    Time 0.019681    
2018-11-02 21:59:02,554 - Epoch: [280][  350/  391]    Overall Loss 0.035067    Objective Loss 0.035067    Top1 98.930804    Top5 100.000000    LR 0.000086    Time 0.019645    
2018-11-02 21:59:03,434 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34803 | -0.00613 |    0.22002 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15542 | -0.00052 |    0.09814 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15535 | -0.00326 |    0.11760 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18692 | -0.04500 |    0.14588 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19948 |  0.00676 |    0.15693 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16683 | -0.02550 |    0.12733 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16261 | -0.00332 |    0.11865 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19592 | -0.00259 |    0.14336 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16198 | -0.00405 |    0.12375 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24046 | -0.00978 |    0.15774 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14273 | -0.00037 |    0.10604 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11962 | -0.01293 |    0.09628 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14446 | -0.01347 |    0.11310 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10563 | -0.00451 |    0.08099 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11589 | -0.01301 |    0.09228 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10988 | -0.00210 |    0.08698 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13665 | -0.00740 |    0.10500 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10410 | -0.00891 |    0.08259 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08918 | -0.00526 |    0.07029 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08998 | -0.01093 |    0.07197 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05425 |  0.00236 |    0.04115 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58355 | -0.00001 |    0.45518 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:59:03,434 - Total sparsity: 0.00

2018-11-02 21:59:03,434 - --- validate (epoch=280)-----------
2018-11-02 21:59:03,434 - 10000 samples (128 per mini-batch)
2018-11-02 21:59:04,157 - Epoch: [280][   50/   78]    Loss 0.412326    Top1 90.609375    Top5 99.562500    
2018-11-02 21:59:04,549 - ==> Top1: 90.570    Top5: 99.640    Loss: 0.412

2018-11-02 21:59:04,550 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:59:04,550 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:59:04,562 - 

2018-11-02 21:59:04,562 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:59:05,594 - Epoch: [281][   50/  391]    Overall Loss 0.037520    Objective Loss 0.037520    Top1 98.593750    Top5 100.000000    LR 0.000082    Time 0.020603    
2018-11-02 21:59:06,568 - Epoch: [281][  100/  391]    Overall Loss 0.038288    Objective Loss 0.038288    Top1 98.726562    Top5 100.000000    LR 0.000082    Time 0.020021    
2018-11-02 21:59:07,540 - Epoch: [281][  150/  391]    Overall Loss 0.036070    Objective Loss 0.036070    Top1 98.848958    Top5 100.000000    LR 0.000082    Time 0.019824    
2018-11-02 21:59:08,521 - Epoch: [281][  200/  391]    Overall Loss 0.036022    Objective Loss 0.036022    Top1 98.847656    Top5 100.000000    LR 0.000082    Time 0.019765    
2018-11-02 21:59:09,562 - Epoch: [281][  250/  391]    Overall Loss 0.036221    Objective Loss 0.036221    Top1 98.878125    Top5 100.000000    LR 0.000082    Time 0.019971    
2018-11-02 21:59:10,606 - Epoch: [281][  300/  391]    Overall Loss 0.036610    Objective Loss 0.036610    Top1 98.846354    Top5 100.000000    LR 0.000082    Time 0.020119    
2018-11-02 21:59:11,639 - Epoch: [281][  350/  391]    Overall Loss 0.036992    Objective Loss 0.036992    Top1 98.819196    Top5 100.000000    LR 0.000082    Time 0.020193    
2018-11-02 21:59:12,547 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34802 | -0.00615 |    0.22001 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15542 | -0.00051 |    0.09814 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15534 | -0.00326 |    0.11760 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18691 | -0.04500 |    0.14587 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19947 |  0.00675 |    0.15692 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16682 | -0.02551 |    0.12732 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16261 | -0.00332 |    0.11865 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19591 | -0.00259 |    0.14336 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16197 | -0.00405 |    0.12374 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24046 | -0.00978 |    0.15773 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14272 | -0.00037 |    0.10604 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11962 | -0.01293 |    0.09628 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14445 | -0.01347 |    0.11309 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10563 | -0.00452 |    0.08098 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11588 | -0.01301 |    0.09228 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10988 | -0.00210 |    0.08697 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13665 | -0.00740 |    0.10500 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10409 | -0.00891 |    0.08258 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08917 | -0.00526 |    0.07029 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08997 | -0.01093 |    0.07197 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05425 |  0.00236 |    0.04115 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58355 | -0.00001 |    0.45518 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:59:12,547 - Total sparsity: 0.00

2018-11-02 21:59:12,548 - --- validate (epoch=281)-----------
2018-11-02 21:59:12,548 - 10000 samples (128 per mini-batch)
2018-11-02 21:59:13,262 - Epoch: [281][   50/   78]    Loss 0.411668    Top1 90.500000    Top5 99.578125    
2018-11-02 21:59:13,649 - ==> Top1: 90.460    Top5: 99.640    Loss: 0.413

2018-11-02 21:59:13,650 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:59:13,650 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:59:13,658 - 

2018-11-02 21:59:13,659 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:59:14,690 - Epoch: [282][   50/  391]    Overall Loss 0.034119    Objective Loss 0.034119    Top1 98.984375    Top5 99.984375    LR 0.000078    Time 0.020602    
2018-11-02 21:59:15,668 - Epoch: [282][  100/  391]    Overall Loss 0.035513    Objective Loss 0.035513    Top1 98.929688    Top5 99.992188    LR 0.000078    Time 0.020061    
2018-11-02 21:59:16,640 - Epoch: [282][  150/  391]    Overall Loss 0.034922    Objective Loss 0.034922    Top1 98.921875    Top5 99.994792    LR 0.000078    Time 0.019850    
2018-11-02 21:59:17,616 - Epoch: [282][  200/  391]    Overall Loss 0.036291    Objective Loss 0.036291    Top1 98.859375    Top5 99.992188    LR 0.000078    Time 0.019761    
2018-11-02 21:59:18,590 - Epoch: [282][  250/  391]    Overall Loss 0.036260    Objective Loss 0.036260    Top1 98.862500    Top5 99.993750    LR 0.000078    Time 0.019699    
2018-11-02 21:59:19,564 - Epoch: [282][  300/  391]    Overall Loss 0.036329    Objective Loss 0.036329    Top1 98.838542    Top5 99.994792    LR 0.000078    Time 0.019657    
2018-11-02 21:59:20,540 - Epoch: [282][  350/  391]    Overall Loss 0.035947    Objective Loss 0.035947    Top1 98.845982    Top5 99.993304    LR 0.000078    Time 0.019633    
2018-11-02 21:59:21,428 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34801 | -0.00613 |    0.22000 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15541 | -0.00052 |    0.09813 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15534 | -0.00326 |    0.11760 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18691 | -0.04500 |    0.14587 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19947 |  0.00675 |    0.15692 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16682 | -0.02551 |    0.12732 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16260 | -0.00332 |    0.11864 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19591 | -0.00259 |    0.14335 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16197 | -0.00405 |    0.12374 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24045 | -0.00979 |    0.15773 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14272 | -0.00037 |    0.10603 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11962 | -0.01292 |    0.09627 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14445 | -0.01347 |    0.11309 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10563 | -0.00452 |    0.08098 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11588 | -0.01301 |    0.09228 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10987 | -0.00209 |    0.08697 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13664 | -0.00740 |    0.10500 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10409 | -0.00891 |    0.08258 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08917 | -0.00526 |    0.07028 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08997 | -0.01093 |    0.07196 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05425 |  0.00236 |    0.04115 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58355 | -0.00001 |    0.45518 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:59:21,428 - Total sparsity: 0.00

2018-11-02 21:59:21,428 - --- validate (epoch=282)-----------
2018-11-02 21:59:21,428 - 10000 samples (128 per mini-batch)
2018-11-02 21:59:22,145 - Epoch: [282][   50/   78]    Loss 0.411593    Top1 90.562500    Top5 99.578125    
2018-11-02 21:59:22,532 - ==> Top1: 90.540    Top5: 99.650    Loss: 0.413

2018-11-02 21:59:22,533 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:59:22,533 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:59:22,541 - 

2018-11-02 21:59:22,541 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:59:23,575 - Epoch: [283][   50/  391]    Overall Loss 0.036198    Objective Loss 0.036198    Top1 98.828125    Top5 100.000000    LR 0.000074    Time 0.020646    
2018-11-02 21:59:24,548 - Epoch: [283][  100/  391]    Overall Loss 0.035917    Objective Loss 0.035917    Top1 98.867188    Top5 100.000000    LR 0.000074    Time 0.020044    
2018-11-02 21:59:25,519 - Epoch: [283][  150/  391]    Overall Loss 0.035492    Objective Loss 0.035492    Top1 98.937500    Top5 100.000000    LR 0.000074    Time 0.019830    
2018-11-02 21:59:26,494 - Epoch: [283][  200/  391]    Overall Loss 0.035747    Objective Loss 0.035747    Top1 98.910156    Top5 100.000000    LR 0.000074    Time 0.019737    
2018-11-02 21:59:27,526 - Epoch: [283][  250/  391]    Overall Loss 0.036997    Objective Loss 0.036997    Top1 98.831250    Top5 100.000000    LR 0.000074    Time 0.019899    
2018-11-02 21:59:28,563 - Epoch: [283][  300/  391]    Overall Loss 0.036545    Objective Loss 0.036545    Top1 98.856771    Top5 100.000000    LR 0.000074    Time 0.020035    
2018-11-02 21:59:29,599 - Epoch: [283][  350/  391]    Overall Loss 0.036227    Objective Loss 0.036227    Top1 98.866071    Top5 100.000000    LR 0.000074    Time 0.020130    
2018-11-02 21:59:30,525 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34800 | -0.00611 |    0.21999 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15541 | -0.00052 |    0.09813 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15533 | -0.00326 |    0.11759 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18690 | -0.04500 |    0.14586 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19946 |  0.00676 |    0.15691 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16681 | -0.02551 |    0.12732 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16260 | -0.00332 |    0.11864 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19590 | -0.00259 |    0.14335 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16196 | -0.00405 |    0.12374 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24044 | -0.00978 |    0.15772 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14271 | -0.00036 |    0.10603 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11961 | -0.01292 |    0.09627 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14445 | -0.01347 |    0.11309 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10562 | -0.00452 |    0.08098 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11588 | -0.01301 |    0.09227 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10987 | -0.00210 |    0.08697 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13664 | -0.00740 |    0.10499 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10409 | -0.00891 |    0.08258 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08917 | -0.00526 |    0.07028 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08997 | -0.01093 |    0.07196 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05424 |  0.00236 |    0.04115 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58356 | -0.00001 |    0.45518 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:59:30,526 - Total sparsity: 0.00

2018-11-02 21:59:30,526 - --- validate (epoch=283)-----------
2018-11-02 21:59:30,526 - 10000 samples (128 per mini-batch)
2018-11-02 21:59:31,251 - Epoch: [283][   50/   78]    Loss 0.412159    Top1 90.312500    Top5 99.593750    
2018-11-02 21:59:31,662 - ==> Top1: 90.390    Top5: 99.670    Loss: 0.412

2018-11-02 21:59:31,666 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:59:31,666 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:59:31,674 - 

2018-11-02 21:59:31,674 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:59:32,707 - Epoch: [284][   50/  391]    Overall Loss 0.037679    Objective Loss 0.037679    Top1 98.734375    Top5 100.000000    LR 0.000070    Time 0.020622    
2018-11-02 21:59:33,682 - Epoch: [284][  100/  391]    Overall Loss 0.034240    Objective Loss 0.034240    Top1 99.000000    Top5 100.000000    LR 0.000070    Time 0.020044    
2018-11-02 21:59:34,656 - Epoch: [284][  150/  391]    Overall Loss 0.035530    Objective Loss 0.035530    Top1 98.937500    Top5 100.000000    LR 0.000070    Time 0.019850    
2018-11-02 21:59:35,669 - Epoch: [284][  200/  391]    Overall Loss 0.036226    Objective Loss 0.036226    Top1 98.910156    Top5 100.000000    LR 0.000070    Time 0.019943    
2018-11-02 21:59:36,644 - Epoch: [284][  250/  391]    Overall Loss 0.036152    Objective Loss 0.036152    Top1 98.912500    Top5 100.000000    LR 0.000070    Time 0.019850    
2018-11-02 21:59:37,617 - Epoch: [284][  300/  391]    Overall Loss 0.036420    Objective Loss 0.036420    Top1 98.867188    Top5 100.000000    LR 0.000070    Time 0.019783    
2018-11-02 21:59:38,593 - Epoch: [284][  350/  391]    Overall Loss 0.035623    Objective Loss 0.035623    Top1 98.904018    Top5 100.000000    LR 0.000070    Time 0.019740    
2018-11-02 21:59:39,467 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34799 | -0.00614 |    0.21999 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15541 | -0.00052 |    0.09813 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15533 | -0.00326 |    0.11759 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18690 | -0.04500 |    0.14586 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19946 |  0.00676 |    0.15691 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16681 | -0.02551 |    0.12731 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16259 | -0.00332 |    0.11863 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19590 | -0.00259 |    0.14334 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16196 | -0.00405 |    0.12373 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24044 | -0.00979 |    0.15772 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14271 | -0.00036 |    0.10603 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11961 | -0.01293 |    0.09627 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14444 | -0.01347 |    0.11308 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10562 | -0.00452 |    0.08098 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11587 | -0.01301 |    0.09227 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10987 | -0.00210 |    0.08697 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13664 | -0.00740 |    0.10499 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10409 | -0.00891 |    0.08258 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08916 | -0.00526 |    0.07028 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08996 | -0.01093 |    0.07196 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05424 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58356 | -0.00001 |    0.45518 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:59:39,467 - Total sparsity: 0.00

2018-11-02 21:59:39,467 - --- validate (epoch=284)-----------
2018-11-02 21:59:39,468 - 10000 samples (128 per mini-batch)
2018-11-02 21:59:40,192 - Epoch: [284][   50/   78]    Loss 0.410882    Top1 90.468750    Top5 99.578125    
2018-11-02 21:59:40,577 - ==> Top1: 90.470    Top5: 99.630    Loss: 0.411

2018-11-02 21:59:40,578 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:59:40,578 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:59:40,590 - 

2018-11-02 21:59:40,590 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:59:41,627 - Epoch: [285][   50/  391]    Overall Loss 0.041693    Objective Loss 0.041693    Top1 98.750000    Top5 100.000000    LR 0.000067    Time 0.020716    
2018-11-02 21:59:42,608 - Epoch: [285][  100/  391]    Overall Loss 0.040484    Objective Loss 0.040484    Top1 98.734375    Top5 100.000000    LR 0.000067    Time 0.020150    
2018-11-02 21:59:43,585 - Epoch: [285][  150/  391]    Overall Loss 0.039248    Objective Loss 0.039248    Top1 98.781250    Top5 100.000000    LR 0.000067    Time 0.019934    
2018-11-02 21:59:44,564 - Epoch: [285][  200/  391]    Overall Loss 0.038259    Objective Loss 0.038259    Top1 98.820312    Top5 100.000000    LR 0.000067    Time 0.019842    
2018-11-02 21:59:45,540 - Epoch: [285][  250/  391]    Overall Loss 0.037338    Objective Loss 0.037338    Top1 98.853125    Top5 100.000000    LR 0.000067    Time 0.019771    
2018-11-02 21:59:46,518 - Epoch: [285][  300/  391]    Overall Loss 0.037508    Objective Loss 0.037508    Top1 98.825521    Top5 99.997396    LR 0.000067    Time 0.019732    
2018-11-02 21:59:47,496 - Epoch: [285][  350/  391]    Overall Loss 0.037182    Objective Loss 0.037182    Top1 98.834821    Top5 99.997768    LR 0.000067    Time 0.019703    
2018-11-02 21:59:48,378 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34798 | -0.00615 |    0.21998 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15540 | -0.00052 |    0.09812 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15532 | -0.00327 |    0.11759 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18689 | -0.04500 |    0.14585 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19945 |  0.00677 |    0.15690 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16680 | -0.02551 |    0.12731 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16259 | -0.00332 |    0.11863 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19589 | -0.00260 |    0.14334 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16195 | -0.00405 |    0.12373 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24043 | -0.00979 |    0.15771 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14271 | -0.00036 |    0.10603 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11961 | -0.01293 |    0.09627 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14444 | -0.01347 |    0.11308 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10562 | -0.00452 |    0.08097 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11587 | -0.01301 |    0.09227 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10986 | -0.00210 |    0.08696 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13663 | -0.00740 |    0.10499 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10408 | -0.00891 |    0.08257 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08916 | -0.00526 |    0.07028 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08996 | -0.01093 |    0.07196 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05424 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58356 | -0.00001 |    0.45519 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:59:48,378 - Total sparsity: 0.00

2018-11-02 21:59:48,378 - --- validate (epoch=285)-----------
2018-11-02 21:59:48,378 - 10000 samples (128 per mini-batch)
2018-11-02 21:59:49,105 - Epoch: [285][   50/   78]    Loss 0.410100    Top1 90.468750    Top5 99.609375    
2018-11-02 21:59:49,500 - ==> Top1: 90.500    Top5: 99.670    Loss: 0.410

2018-11-02 21:59:49,501 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:59:49,501 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:59:49,508 - 

2018-11-02 21:59:49,509 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:59:50,548 - Epoch: [286][   50/  391]    Overall Loss 0.031784    Objective Loss 0.031784    Top1 99.062500    Top5 100.000000    LR 0.000063    Time 0.020744    
2018-11-02 21:59:51,524 - Epoch: [286][  100/  391]    Overall Loss 0.033254    Objective Loss 0.033254    Top1 98.914062    Top5 100.000000    LR 0.000063    Time 0.020121    
2018-11-02 21:59:52,504 - Epoch: [286][  150/  391]    Overall Loss 0.033834    Objective Loss 0.033834    Top1 98.885417    Top5 100.000000    LR 0.000063    Time 0.019942    
2018-11-02 21:59:53,481 - Epoch: [286][  200/  391]    Overall Loss 0.033749    Objective Loss 0.033749    Top1 98.941406    Top5 100.000000    LR 0.000063    Time 0.019834    
2018-11-02 21:59:54,496 - Epoch: [286][  250/  391]    Overall Loss 0.034238    Objective Loss 0.034238    Top1 98.950000    Top5 100.000000    LR 0.000063    Time 0.019922    
2018-11-02 21:59:55,475 - Epoch: [286][  300/  391]    Overall Loss 0.035093    Objective Loss 0.035093    Top1 98.893229    Top5 100.000000    LR 0.000063    Time 0.019858    
2018-11-02 21:59:56,518 - Epoch: [286][  350/  391]    Overall Loss 0.035408    Objective Loss 0.035408    Top1 98.895089    Top5 100.000000    LR 0.000063    Time 0.020000    
2018-11-02 21:59:57,459 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34797 | -0.00617 |    0.21998 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15540 | -0.00052 |    0.09812 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15532 | -0.00327 |    0.11758 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18689 | -0.04500 |    0.14585 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19945 |  0.00677 |    0.15690 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16680 | -0.02552 |    0.12730 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16259 | -0.00332 |    0.11863 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19589 | -0.00259 |    0.14334 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16195 | -0.00405 |    0.12373 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24042 | -0.00979 |    0.15771 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14270 | -0.00037 |    0.10602 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11960 | -0.01293 |    0.09626 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14443 | -0.01347 |    0.11308 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10562 | -0.00452 |    0.08097 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11587 | -0.01301 |    0.09227 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10986 | -0.00209 |    0.08696 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13663 | -0.00740 |    0.10499 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10408 | -0.00891 |    0.08257 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08916 | -0.00526 |    0.07028 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08996 | -0.01093 |    0.07196 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05424 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58356 | -0.00001 |    0.45519 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 21:59:57,460 - Total sparsity: 0.00

2018-11-02 21:59:57,460 - --- validate (epoch=286)-----------
2018-11-02 21:59:57,460 - 10000 samples (128 per mini-batch)
2018-11-02 21:59:58,188 - Epoch: [286][   50/   78]    Loss 0.409175    Top1 90.640625    Top5 99.593750    
2018-11-02 21:59:58,600 - ==> Top1: 90.620    Top5: 99.650    Loss: 0.409

2018-11-02 21:59:58,601 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 21:59:58,601 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 21:59:58,609 - 

2018-11-02 21:59:58,609 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 21:59:59,647 - Epoch: [287][   50/  391]    Overall Loss 0.039949    Objective Loss 0.039949    Top1 98.703125    Top5 100.000000    LR 0.000060    Time 0.020737    
2018-11-02 22:00:00,632 - Epoch: [287][  100/  391]    Overall Loss 0.036957    Objective Loss 0.036957    Top1 98.820312    Top5 100.000000    LR 0.000060    Time 0.020199    
2018-11-02 22:00:01,611 - Epoch: [287][  150/  391]    Overall Loss 0.037121    Objective Loss 0.037121    Top1 98.796875    Top5 100.000000    LR 0.000060    Time 0.019990    
2018-11-02 22:00:02,595 - Epoch: [287][  200/  391]    Overall Loss 0.036613    Objective Loss 0.036613    Top1 98.808594    Top5 100.000000    LR 0.000060    Time 0.019904    
2018-11-02 22:00:03,633 - Epoch: [287][  250/  391]    Overall Loss 0.036243    Objective Loss 0.036243    Top1 98.825000    Top5 100.000000    LR 0.000060    Time 0.020071    
2018-11-02 22:00:04,665 - Epoch: [287][  300/  391]    Overall Loss 0.036416    Objective Loss 0.036416    Top1 98.820312    Top5 100.000000    LR 0.000060    Time 0.020163    
2018-11-02 22:00:05,696 - Epoch: [287][  350/  391]    Overall Loss 0.037213    Objective Loss 0.037213    Top1 98.783482    Top5 100.000000    LR 0.000060    Time 0.020225    
2018-11-02 22:00:06,624 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34796 | -0.00618 |    0.21997 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15539 | -0.00052 |    0.09812 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15532 | -0.00327 |    0.11758 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18688 | -0.04500 |    0.14585 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19944 |  0.00677 |    0.15690 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16680 | -0.02551 |    0.12730 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16258 | -0.00332 |    0.11863 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19588 | -0.00259 |    0.14333 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16195 | -0.00406 |    0.12372 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24042 | -0.00978 |    0.15771 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14270 | -0.00037 |    0.10602 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11960 | -0.01293 |    0.09626 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14443 | -0.01347 |    0.11307 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10561 | -0.00452 |    0.08097 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11587 | -0.01301 |    0.09226 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10986 | -0.00210 |    0.08696 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13663 | -0.00740 |    0.10498 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10408 | -0.00891 |    0.08257 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08916 | -0.00526 |    0.07027 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08996 | -0.01093 |    0.07195 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05424 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58357 | -0.00001 |    0.45519 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:00:06,624 - Total sparsity: 0.00

2018-11-02 22:00:06,624 - --- validate (epoch=287)-----------
2018-11-02 22:00:06,624 - 10000 samples (128 per mini-batch)
2018-11-02 22:00:07,352 - Epoch: [287][   50/   78]    Loss 0.411028    Top1 90.453125    Top5 99.593750    
2018-11-02 22:00:07,745 - ==> Top1: 90.460    Top5: 99.660    Loss: 0.411

2018-11-02 22:00:07,746 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:00:07,746 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:00:07,758 - 

2018-11-02 22:00:07,758 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:00:08,934 - Epoch: [288][   50/  391]    Overall Loss 0.035099    Objective Loss 0.035099    Top1 98.828125    Top5 100.000000    LR 0.000057    Time 0.023496    
2018-11-02 22:00:09,936 - Epoch: [288][  100/  391]    Overall Loss 0.035154    Objective Loss 0.035154    Top1 98.859375    Top5 100.000000    LR 0.000057    Time 0.021749    
2018-11-02 22:00:10,917 - Epoch: [288][  150/  391]    Overall Loss 0.035901    Objective Loss 0.035901    Top1 98.802083    Top5 100.000000    LR 0.000057    Time 0.021032    
2018-11-02 22:00:11,894 - Epoch: [288][  200/  391]    Overall Loss 0.036283    Objective Loss 0.036283    Top1 98.804688    Top5 100.000000    LR 0.000057    Time 0.020651    
2018-11-02 22:00:12,873 - Epoch: [288][  250/  391]    Overall Loss 0.035434    Objective Loss 0.035434    Top1 98.828125    Top5 100.000000    LR 0.000057    Time 0.020434    
2018-11-02 22:00:13,854 - Epoch: [288][  300/  391]    Overall Loss 0.035810    Objective Loss 0.035810    Top1 98.817708    Top5 100.000000    LR 0.000057    Time 0.020292    
2018-11-02 22:00:14,831 - Epoch: [288][  350/  391]    Overall Loss 0.035861    Objective Loss 0.035861    Top1 98.850446    Top5 99.997768    LR 0.000057    Time 0.020181    
2018-11-02 22:00:15,714 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34795 | -0.00619 |    0.21997 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15539 | -0.00052 |    0.09812 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15531 | -0.00326 |    0.11758 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18688 | -0.04499 |    0.14584 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19944 |  0.00677 |    0.15689 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16679 | -0.02552 |    0.12730 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16258 | -0.00331 |    0.11863 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19588 | -0.00259 |    0.14333 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16194 | -0.00406 |    0.12372 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24041 | -0.00978 |    0.15770 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14270 | -0.00036 |    0.10602 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11960 | -0.01292 |    0.09626 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14443 | -0.01347 |    0.11307 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10561 | -0.00452 |    0.08097 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11586 | -0.01301 |    0.09226 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10986 | -0.00210 |    0.08696 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13662 | -0.00740 |    0.10498 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10408 | -0.00890 |    0.08257 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08916 | -0.00526 |    0.07027 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08996 | -0.01093 |    0.07195 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05424 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58357 | -0.00001 |    0.45519 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:00:15,714 - Total sparsity: 0.00

2018-11-02 22:00:15,714 - --- validate (epoch=288)-----------
2018-11-02 22:00:15,714 - 10000 samples (128 per mini-batch)
2018-11-02 22:00:16,440 - Epoch: [288][   50/   78]    Loss 0.417535    Top1 90.390625    Top5 99.578125    
2018-11-02 22:00:16,834 - ==> Top1: 90.380    Top5: 99.620    Loss: 0.418

2018-11-02 22:00:16,834 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:00:16,834 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:00:16,842 - 

2018-11-02 22:00:16,843 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:00:17,881 - Epoch: [289][   50/  391]    Overall Loss 0.035689    Objective Loss 0.035689    Top1 98.890625    Top5 100.000000    LR 0.000054    Time 0.020728    
2018-11-02 22:00:18,863 - Epoch: [289][  100/  391]    Overall Loss 0.035592    Objective Loss 0.035592    Top1 98.914062    Top5 100.000000    LR 0.000054    Time 0.020171    
2018-11-02 22:00:19,842 - Epoch: [289][  150/  391]    Overall Loss 0.035175    Objective Loss 0.035175    Top1 98.906250    Top5 100.000000    LR 0.000054    Time 0.019964    
2018-11-02 22:00:20,820 - Epoch: [289][  200/  391]    Overall Loss 0.035552    Objective Loss 0.035552    Top1 98.882812    Top5 100.000000    LR 0.000054    Time 0.019857    
2018-11-02 22:00:21,800 - Epoch: [289][  250/  391]    Overall Loss 0.035453    Objective Loss 0.035453    Top1 98.918750    Top5 100.000000    LR 0.000054    Time 0.019801    
2018-11-02 22:00:22,778 - Epoch: [289][  300/  391]    Overall Loss 0.035749    Objective Loss 0.035749    Top1 98.906250    Top5 100.000000    LR 0.000054    Time 0.019759    
2018-11-02 22:00:23,757 - Epoch: [289][  350/  391]    Overall Loss 0.035842    Objective Loss 0.035842    Top1 98.912946    Top5 100.000000    LR 0.000054    Time 0.019729    
2018-11-02 22:00:24,643 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34794 | -0.00620 |    0.21997 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15539 | -0.00052 |    0.09811 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15531 | -0.00327 |    0.11758 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18687 | -0.04499 |    0.14584 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19943 |  0.00676 |    0.15689 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16679 | -0.02551 |    0.12730 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16258 | -0.00331 |    0.11862 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19587 | -0.00259 |    0.14333 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16194 | -0.00405 |    0.12372 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24041 | -0.00978 |    0.15770 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14269 | -0.00037 |    0.10602 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11959 | -0.01292 |    0.09626 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14442 | -0.01347 |    0.11307 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10561 | -0.00452 |    0.08097 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11586 | -0.01301 |    0.09226 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10985 | -0.00210 |    0.08696 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13662 | -0.00740 |    0.10498 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10407 | -0.00891 |    0.08257 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08915 | -0.00526 |    0.07027 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08995 | -0.01093 |    0.07195 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05424 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58357 | -0.00001 |    0.45519 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:00:24,643 - Total sparsity: 0.00

2018-11-02 22:00:24,643 - --- validate (epoch=289)-----------
2018-11-02 22:00:24,643 - 10000 samples (128 per mini-batch)
2018-11-02 22:00:25,363 - Epoch: [289][   50/   78]    Loss 0.415070    Top1 90.328125    Top5 99.578125    
2018-11-02 22:00:25,755 - ==> Top1: 90.380    Top5: 99.650    Loss: 0.415

2018-11-02 22:00:25,756 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:00:25,756 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:00:25,763 - 

2018-11-02 22:00:25,764 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:00:26,878 - Epoch: [290][   50/  391]    Overall Loss 0.033131    Objective Loss 0.033131    Top1 98.843750    Top5 100.000000    LR 0.000052    Time 0.022256    
2018-11-02 22:00:27,916 - Epoch: [290][  100/  391]    Overall Loss 0.034469    Objective Loss 0.034469    Top1 98.867188    Top5 100.000000    LR 0.000052    Time 0.021491    
2018-11-02 22:00:28,962 - Epoch: [290][  150/  391]    Overall Loss 0.035444    Objective Loss 0.035444    Top1 98.843750    Top5 100.000000    LR 0.000052    Time 0.021297    
2018-11-02 22:00:29,963 - Epoch: [290][  200/  391]    Overall Loss 0.036180    Objective Loss 0.036180    Top1 98.816406    Top5 100.000000    LR 0.000052    Time 0.020968    
2018-11-02 22:00:30,949 - Epoch: [290][  250/  391]    Overall Loss 0.035735    Objective Loss 0.035735    Top1 98.850000    Top5 100.000000    LR 0.000052    Time 0.020716    
2018-11-02 22:00:31,930 - Epoch: [290][  300/  391]    Overall Loss 0.036047    Objective Loss 0.036047    Top1 98.869792    Top5 100.000000    LR 0.000052    Time 0.020516    
2018-11-02 22:00:32,920 - Epoch: [290][  350/  391]    Overall Loss 0.036082    Objective Loss 0.036082    Top1 98.870536    Top5 100.000000    LR 0.000052    Time 0.020409    
2018-11-02 22:00:33,804 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34794 | -0.00621 |    0.21996 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15538 | -0.00053 |    0.09811 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15531 | -0.00326 |    0.11757 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18687 | -0.04499 |    0.14584 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19943 |  0.00676 |    0.15689 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16679 | -0.02551 |    0.12729 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16257 | -0.00331 |    0.11862 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19587 | -0.00259 |    0.14333 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16194 | -0.00405 |    0.12372 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24040 | -0.00978 |    0.15770 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14269 | -0.00036 |    0.10602 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11959 | -0.01292 |    0.09626 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14442 | -0.01347 |    0.11307 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10561 | -0.00452 |    0.08096 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11586 | -0.01301 |    0.09226 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10985 | -0.00210 |    0.08695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13662 | -0.00740 |    0.10498 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10407 | -0.00890 |    0.08257 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08915 | -0.00526 |    0.07027 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08995 | -0.01093 |    0.07195 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58357 | -0.00001 |    0.45519 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:00:33,804 - Total sparsity: 0.00

2018-11-02 22:00:33,804 - --- validate (epoch=290)-----------
2018-11-02 22:00:33,804 - 10000 samples (128 per mini-batch)
2018-11-02 22:00:34,531 - Epoch: [290][   50/   78]    Loss 0.414608    Top1 90.375000    Top5 99.578125    
2018-11-02 22:00:34,926 - ==> Top1: 90.410    Top5: 99.660    Loss: 0.414

2018-11-02 22:00:34,927 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:00:34,927 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:00:34,939 - 

2018-11-02 22:00:34,939 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:00:35,975 - Epoch: [291][   50/  391]    Overall Loss 0.035121    Objective Loss 0.035121    Top1 98.875000    Top5 100.000000    LR 0.000049    Time 0.020694    
2018-11-02 22:00:36,982 - Epoch: [291][  100/  391]    Overall Loss 0.035559    Objective Loss 0.035559    Top1 98.914062    Top5 100.000000    LR 0.000049    Time 0.020398    
2018-11-02 22:00:37,959 - Epoch: [291][  150/  391]    Overall Loss 0.036857    Objective Loss 0.036857    Top1 98.875000    Top5 100.000000    LR 0.000049    Time 0.020107    
2018-11-02 22:00:38,936 - Epoch: [291][  200/  391]    Overall Loss 0.037260    Objective Loss 0.037260    Top1 98.875000    Top5 99.992188    LR 0.000049    Time 0.019959    
2018-11-02 22:00:39,915 - Epoch: [291][  250/  391]    Overall Loss 0.037588    Objective Loss 0.037588    Top1 98.840625    Top5 99.990625    LR 0.000049    Time 0.019879    
2018-11-02 22:00:40,892 - Epoch: [291][  300/  391]    Overall Loss 0.037697    Objective Loss 0.037697    Top1 98.817708    Top5 99.992188    LR 0.000049    Time 0.019819    
2018-11-02 22:00:41,869 - Epoch: [291][  350/  391]    Overall Loss 0.037726    Objective Loss 0.037726    Top1 98.810268    Top5 99.993304    LR 0.000049    Time 0.019772    
2018-11-02 22:00:42,748 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34793 | -0.00620 |    0.21995 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15538 | -0.00053 |    0.09811 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15530 | -0.00326 |    0.11757 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18687 | -0.04500 |    0.14584 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19943 |  0.00676 |    0.15688 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16678 | -0.02551 |    0.12729 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16257 | -0.00331 |    0.11862 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19587 | -0.00259 |    0.14332 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16193 | -0.00405 |    0.12371 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24040 | -0.00978 |    0.15770 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14269 | -0.00036 |    0.10601 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11959 | -0.01292 |    0.09625 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14442 | -0.01347 |    0.11307 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10561 | -0.00452 |    0.08096 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11586 | -0.01301 |    0.09226 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10985 | -0.00210 |    0.08695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13662 | -0.00740 |    0.10497 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10407 | -0.00890 |    0.08256 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08915 | -0.00526 |    0.07027 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08995 | -0.01093 |    0.07195 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58357 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:00:42,748 - Total sparsity: 0.00

2018-11-02 22:00:42,748 - --- validate (epoch=291)-----------
2018-11-02 22:00:42,748 - 10000 samples (128 per mini-batch)
2018-11-02 22:00:43,474 - Epoch: [291][   50/   78]    Loss 0.412928    Top1 90.421875    Top5 99.609375    
2018-11-02 22:00:43,865 - ==> Top1: 90.380    Top5: 99.650    Loss: 0.414

2018-11-02 22:00:43,866 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:00:43,866 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:00:43,874 - 

2018-11-02 22:00:43,874 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:00:44,910 - Epoch: [292][   50/  391]    Overall Loss 0.032399    Objective Loss 0.032399    Top1 99.000000    Top5 99.984375    LR 0.000047    Time 0.020689    
2018-11-02 22:00:45,889 - Epoch: [292][  100/  391]    Overall Loss 0.033728    Objective Loss 0.033728    Top1 98.914062    Top5 99.992188    LR 0.000047    Time 0.020120    
2018-11-02 22:00:46,865 - Epoch: [292][  150/  391]    Overall Loss 0.035788    Objective Loss 0.035788    Top1 98.854167    Top5 99.994792    LR 0.000047    Time 0.019908    
2018-11-02 22:00:47,845 - Epoch: [292][  200/  391]    Overall Loss 0.036338    Objective Loss 0.036338    Top1 98.847656    Top5 99.996094    LR 0.000047    Time 0.019828    
2018-11-02 22:00:48,825 - Epoch: [292][  250/  391]    Overall Loss 0.035651    Objective Loss 0.035651    Top1 98.862500    Top5 99.996875    LR 0.000047    Time 0.019777    
2018-11-02 22:00:49,805 - Epoch: [292][  300/  391]    Overall Loss 0.036267    Objective Loss 0.036267    Top1 98.854167    Top5 99.994792    LR 0.000047    Time 0.019741    
2018-11-02 22:00:50,782 - Epoch: [292][  350/  391]    Overall Loss 0.036295    Objective Loss 0.036295    Top1 98.857143    Top5 99.995536    LR 0.000047    Time 0.019711    
2018-11-02 22:00:51,665 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34792 | -0.00619 |    0.21995 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15538 | -0.00053 |    0.09811 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15530 | -0.00326 |    0.11757 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18686 | -0.04500 |    0.14583 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19942 |  0.00677 |    0.15688 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16678 | -0.02551 |    0.12729 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16257 | -0.00331 |    0.11862 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19586 | -0.00259 |    0.14332 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16193 | -0.00405 |    0.12371 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24039 | -0.00978 |    0.15769 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14269 | -0.00036 |    0.10601 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11959 | -0.01292 |    0.09625 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14442 | -0.01347 |    0.11306 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10560 | -0.00451 |    0.08096 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11585 | -0.01301 |    0.09225 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10985 | -0.00210 |    0.08695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13661 | -0.00740 |    0.10497 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10407 | -0.00890 |    0.08256 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08915 | -0.00526 |    0.07027 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08995 | -0.01093 |    0.07195 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58358 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:00:51,665 - Total sparsity: 0.00

2018-11-02 22:00:51,665 - --- validate (epoch=292)-----------
2018-11-02 22:00:51,665 - 10000 samples (128 per mini-batch)
2018-11-02 22:00:52,394 - Epoch: [292][   50/   78]    Loss 0.412549    Top1 90.687500    Top5 99.562500    
2018-11-02 22:00:52,789 - ==> Top1: 90.550    Top5: 99.650    Loss: 0.413

2018-11-02 22:00:52,790 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:00:52,790 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:00:52,798 - 

2018-11-02 22:00:52,799 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:00:53,902 - Epoch: [293][   50/  391]    Overall Loss 0.036489    Objective Loss 0.036489    Top1 98.812500    Top5 100.000000    LR 0.000044    Time 0.022033    
2018-11-02 22:00:54,881 - Epoch: [293][  100/  391]    Overall Loss 0.035747    Objective Loss 0.035747    Top1 98.859375    Top5 100.000000    LR 0.000044    Time 0.020796    
2018-11-02 22:00:55,860 - Epoch: [293][  150/  391]    Overall Loss 0.035861    Objective Loss 0.035861    Top1 98.869792    Top5 99.994792    LR 0.000044    Time 0.020378    
2018-11-02 22:00:56,837 - Epoch: [293][  200/  391]    Overall Loss 0.035470    Objective Loss 0.035470    Top1 98.902344    Top5 99.996094    LR 0.000044    Time 0.020162    
2018-11-02 22:00:57,816 - Epoch: [293][  250/  391]    Overall Loss 0.035202    Objective Loss 0.035202    Top1 98.893750    Top5 99.996875    LR 0.000044    Time 0.020042    
2018-11-02 22:00:58,793 - Epoch: [293][  300/  391]    Overall Loss 0.035438    Objective Loss 0.035438    Top1 98.867188    Top5 99.997396    LR 0.000044    Time 0.019942    
2018-11-02 22:00:59,774 - Epoch: [293][  350/  391]    Overall Loss 0.035341    Objective Loss 0.035341    Top1 98.866071    Top5 99.997768    LR 0.000044    Time 0.019891    
2018-11-02 22:01:00,667 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34792 | -0.00618 |    0.21995 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15538 | -0.00053 |    0.09811 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15530 | -0.00326 |    0.11757 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18686 | -0.04499 |    0.14583 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19942 |  0.00676 |    0.15688 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16678 | -0.02551 |    0.12729 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16256 | -0.00331 |    0.11862 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19586 | -0.00259 |    0.14332 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16193 | -0.00405 |    0.12371 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24039 | -0.00978 |    0.15769 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14268 | -0.00036 |    0.10601 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11959 | -0.01293 |    0.09625 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14441 | -0.01347 |    0.11306 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10560 | -0.00451 |    0.08096 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11585 | -0.01301 |    0.09225 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10984 | -0.00210 |    0.08695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13661 | -0.00740 |    0.10497 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10407 | -0.00890 |    0.08256 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08915 | -0.00526 |    0.07027 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08995 | -0.01093 |    0.07195 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58358 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:01:00,667 - Total sparsity: 0.00

2018-11-02 22:01:00,667 - --- validate (epoch=293)-----------
2018-11-02 22:01:00,668 - 10000 samples (128 per mini-batch)
2018-11-02 22:01:01,388 - Epoch: [293][   50/   78]    Loss 0.407349    Top1 90.546875    Top5 99.578125    
2018-11-02 22:01:01,782 - ==> Top1: 90.610    Top5: 99.630    Loss: 0.408

2018-11-02 22:01:01,783 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:01:01,783 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:01:01,791 - 

2018-11-02 22:01:01,791 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:01:02,827 - Epoch: [294][   50/  391]    Overall Loss 0.035426    Objective Loss 0.035426    Top1 99.000000    Top5 100.000000    LR 0.000042    Time 0.020691    
2018-11-02 22:01:03,805 - Epoch: [294][  100/  391]    Overall Loss 0.033385    Objective Loss 0.033385    Top1 99.085938    Top5 100.000000    LR 0.000042    Time 0.020109    
2018-11-02 22:01:04,783 - Epoch: [294][  150/  391]    Overall Loss 0.033786    Objective Loss 0.033786    Top1 99.093750    Top5 100.000000    LR 0.000042    Time 0.019916    
2018-11-02 22:01:05,761 - Epoch: [294][  200/  391]    Overall Loss 0.033717    Objective Loss 0.033717    Top1 99.035156    Top5 100.000000    LR 0.000042    Time 0.019820    
2018-11-02 22:01:06,768 - Epoch: [294][  250/  391]    Overall Loss 0.034733    Objective Loss 0.034733    Top1 98.984375    Top5 100.000000    LR 0.000042    Time 0.019879    
2018-11-02 22:01:07,758 - Epoch: [294][  300/  391]    Overall Loss 0.035534    Objective Loss 0.035534    Top1 98.945312    Top5 100.000000    LR 0.000042    Time 0.019862    
2018-11-02 22:01:08,740 - Epoch: [294][  350/  391]    Overall Loss 0.035830    Objective Loss 0.035830    Top1 98.919643    Top5 100.000000    LR 0.000042    Time 0.019827    
2018-11-02 22:01:09,621 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34791 | -0.00617 |    0.21994 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.00053 |    0.09811 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15530 | -0.00326 |    0.11757 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18686 | -0.04499 |    0.14583 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19942 |  0.00676 |    0.15687 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16677 | -0.02551 |    0.12728 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16256 | -0.00331 |    0.11861 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19586 | -0.00259 |    0.14331 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16192 | -0.00405 |    0.12371 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24039 | -0.00977 |    0.15768 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14268 | -0.00036 |    0.10601 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11958 | -0.01292 |    0.09625 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14441 | -0.01347 |    0.11306 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10560 | -0.00451 |    0.08096 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11585 | -0.01300 |    0.09225 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10984 | -0.00210 |    0.08695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13661 | -0.00740 |    0.10497 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10406 | -0.00890 |    0.08256 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08915 | -0.00526 |    0.07027 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08995 | -0.01093 |    0.07194 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58358 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:01:09,622 - Total sparsity: 0.00

2018-11-02 22:01:09,622 - --- validate (epoch=294)-----------
2018-11-02 22:01:09,622 - 10000 samples (128 per mini-batch)
2018-11-02 22:01:10,347 - Epoch: [294][   50/   78]    Loss 0.411993    Top1 90.390625    Top5 99.593750    
2018-11-02 22:01:10,741 - ==> Top1: 90.340    Top5: 99.660    Loss: 0.413

2018-11-02 22:01:10,742 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:01:10,742 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:01:10,750 - 

2018-11-02 22:01:10,750 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:01:11,789 - Epoch: [295][   50/  391]    Overall Loss 0.040856    Objective Loss 0.040856    Top1 98.703125    Top5 99.984375    LR 0.000040    Time 0.020744    
2018-11-02 22:01:12,767 - Epoch: [295][  100/  391]    Overall Loss 0.039055    Objective Loss 0.039055    Top1 98.726562    Top5 99.992188    LR 0.000040    Time 0.020133    
2018-11-02 22:01:13,744 - Epoch: [295][  150/  391]    Overall Loss 0.038117    Objective Loss 0.038117    Top1 98.755208    Top5 99.994792    LR 0.000040    Time 0.019929    
2018-11-02 22:01:14,725 - Epoch: [295][  200/  391]    Overall Loss 0.038721    Objective Loss 0.038721    Top1 98.753906    Top5 99.996094    LR 0.000040    Time 0.019844    
2018-11-02 22:01:15,702 - Epoch: [295][  250/  391]    Overall Loss 0.038569    Objective Loss 0.038569    Top1 98.746875    Top5 99.993750    LR 0.000040    Time 0.019778    
2018-11-02 22:01:16,682 - Epoch: [295][  300/  391]    Overall Loss 0.037476    Objective Loss 0.037476    Top1 98.783854    Top5 99.994792    LR 0.000040    Time 0.019746    
2018-11-02 22:01:17,690 - Epoch: [295][  350/  391]    Overall Loss 0.037688    Objective Loss 0.037688    Top1 98.790179    Top5 99.995536    LR 0.000040    Time 0.019802    
2018-11-02 22:01:18,575 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34791 | -0.00619 |    0.21994 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.00053 |    0.09810 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15529 | -0.00326 |    0.11756 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18685 | -0.04499 |    0.14583 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19941 |  0.00676 |    0.15687 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16677 | -0.02551 |    0.12728 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16256 | -0.00331 |    0.11861 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19585 | -0.00260 |    0.14331 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16192 | -0.00405 |    0.12370 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24038 | -0.00977 |    0.15768 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14268 | -0.00036 |    0.10601 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11958 | -0.01292 |    0.09625 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14441 | -0.01347 |    0.11306 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10560 | -0.00451 |    0.08096 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11585 | -0.01300 |    0.09225 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10984 | -0.00210 |    0.08695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13661 | -0.00740 |    0.10497 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10406 | -0.00890 |    0.08256 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.00526 |    0.07026 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08994 | -0.01093 |    0.07194 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04114 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58358 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:01:18,575 - Total sparsity: 0.00

2018-11-02 22:01:18,575 - --- validate (epoch=295)-----------
2018-11-02 22:01:18,575 - 10000 samples (128 per mini-batch)
2018-11-02 22:01:19,302 - Epoch: [295][   50/   78]    Loss 0.409729    Top1 90.312500    Top5 99.578125    
2018-11-02 22:01:19,698 - ==> Top1: 90.400    Top5: 99.650    Loss: 0.410

2018-11-02 22:01:19,699 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:01:19,699 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:01:19,706 - 

2018-11-02 22:01:19,706 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:01:20,744 - Epoch: [296][   50/  391]    Overall Loss 0.037006    Objective Loss 0.037006    Top1 98.781250    Top5 100.000000    LR 0.000038    Time 0.020716    
2018-11-02 22:01:21,722 - Epoch: [296][  100/  391]    Overall Loss 0.038063    Objective Loss 0.038063    Top1 98.820312    Top5 100.000000    LR 0.000038    Time 0.020126    
2018-11-02 22:01:22,703 - Epoch: [296][  150/  391]    Overall Loss 0.038171    Objective Loss 0.038171    Top1 98.817708    Top5 100.000000    LR 0.000038    Time 0.019949    
2018-11-02 22:01:23,684 - Epoch: [296][  200/  391]    Overall Loss 0.037143    Objective Loss 0.037143    Top1 98.859375    Top5 100.000000    LR 0.000038    Time 0.019863    
2018-11-02 22:01:24,665 - Epoch: [296][  250/  391]    Overall Loss 0.037732    Objective Loss 0.037732    Top1 98.821875    Top5 100.000000    LR 0.000038    Time 0.019808    
2018-11-02 22:01:25,641 - Epoch: [296][  300/  391]    Overall Loss 0.037839    Objective Loss 0.037839    Top1 98.828125    Top5 100.000000    LR 0.000038    Time 0.019741    
2018-11-02 22:01:26,617 - Epoch: [296][  350/  391]    Overall Loss 0.037997    Objective Loss 0.037997    Top1 98.832589    Top5 100.000000    LR 0.000038    Time 0.019707    
2018-11-02 22:01:27,500 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34790 | -0.00621 |    0.21993 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.00052 |    0.09810 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15529 | -0.00326 |    0.11756 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18685 | -0.04499 |    0.14582 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19941 |  0.00676 |    0.15687 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16677 | -0.02552 |    0.12728 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16256 | -0.00331 |    0.11861 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19585 | -0.00260 |    0.14331 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16192 | -0.00405 |    0.12370 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24038 | -0.00977 |    0.15768 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14268 | -0.00036 |    0.10601 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11958 | -0.01292 |    0.09625 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14441 | -0.01347 |    0.11306 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10560 | -0.00451 |    0.08096 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11585 | -0.01300 |    0.09225 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10984 | -0.00210 |    0.08695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13660 | -0.00740 |    0.10497 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10406 | -0.00890 |    0.08256 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.00526 |    0.07026 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08994 | -0.01093 |    0.07194 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04113 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58358 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:01:27,500 - Total sparsity: 0.00

2018-11-02 22:01:27,500 - --- validate (epoch=296)-----------
2018-11-02 22:01:27,500 - 10000 samples (128 per mini-batch)
2018-11-02 22:01:28,227 - Epoch: [296][   50/   78]    Loss 0.413142    Top1 90.390625    Top5 99.578125    
2018-11-02 22:01:28,619 - ==> Top1: 90.440    Top5: 99.660    Loss: 0.414

2018-11-02 22:01:28,620 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:01:28,620 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:01:28,632 - 

2018-11-02 22:01:28,632 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:01:29,671 - Epoch: [297][   50/  391]    Overall Loss 0.038410    Objective Loss 0.038410    Top1 98.765625    Top5 100.000000    LR 0.000036    Time 0.020750    
2018-11-02 22:01:30,648 - Epoch: [297][  100/  391]    Overall Loss 0.038469    Objective Loss 0.038469    Top1 98.757812    Top5 100.000000    LR 0.000036    Time 0.020132    
2018-11-02 22:01:31,623 - Epoch: [297][  150/  391]    Overall Loss 0.037736    Objective Loss 0.037736    Top1 98.848958    Top5 100.000000    LR 0.000036    Time 0.019914    
2018-11-02 22:01:32,601 - Epoch: [297][  200/  391]    Overall Loss 0.037160    Objective Loss 0.037160    Top1 98.890625    Top5 100.000000    LR 0.000036    Time 0.019816    
2018-11-02 22:01:33,577 - Epoch: [297][  250/  391]    Overall Loss 0.037496    Objective Loss 0.037496    Top1 98.856250    Top5 100.000000    LR 0.000036    Time 0.019753    
2018-11-02 22:01:34,555 - Epoch: [297][  300/  391]    Overall Loss 0.037873    Objective Loss 0.037873    Top1 98.825521    Top5 100.000000    LR 0.000036    Time 0.019716    
2018-11-02 22:01:35,570 - Epoch: [297][  350/  391]    Overall Loss 0.037652    Objective Loss 0.037652    Top1 98.823661    Top5 100.000000    LR 0.000036    Time 0.019797    
2018-11-02 22:01:36,448 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34790 | -0.00620 |    0.21993 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.00052 |    0.09810 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15529 | -0.00326 |    0.11756 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18685 | -0.04498 |    0.14582 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19941 |  0.00675 |    0.15687 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16676 | -0.02552 |    0.12728 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16255 | -0.00331 |    0.11861 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19585 | -0.00259 |    0.14331 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16192 | -0.00405 |    0.12370 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24038 | -0.00977 |    0.15768 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14267 | -0.00036 |    0.10600 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11958 | -0.01292 |    0.09625 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14441 | -0.01347 |    0.11305 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10560 | -0.00451 |    0.08095 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11585 | -0.01300 |    0.09225 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10984 | -0.00210 |    0.08695 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13660 | -0.00740 |    0.10496 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10406 | -0.00890 |    0.08256 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.00526 |    0.07026 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08994 | -0.01093 |    0.07194 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04113 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58358 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:01:36,449 - Total sparsity: 0.00

2018-11-02 22:01:36,449 - --- validate (epoch=297)-----------
2018-11-02 22:01:36,449 - 10000 samples (128 per mini-batch)
2018-11-02 22:01:37,175 - Epoch: [297][   50/   78]    Loss 0.413259    Top1 90.515625    Top5 99.609375    
2018-11-02 22:01:37,567 - ==> Top1: 90.470    Top5: 99.680    Loss: 0.414

2018-11-02 22:01:37,568 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:01:37,568 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:01:37,576 - 

2018-11-02 22:01:37,576 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:01:38,610 - Epoch: [298][   50/  391]    Overall Loss 0.038049    Objective Loss 0.038049    Top1 98.843750    Top5 100.000000    LR 0.000034    Time 0.020659    
2018-11-02 22:01:39,591 - Epoch: [298][  100/  391]    Overall Loss 0.036437    Objective Loss 0.036437    Top1 98.875000    Top5 100.000000    LR 0.000034    Time 0.020118    
2018-11-02 22:01:40,570 - Epoch: [298][  150/  391]    Overall Loss 0.036455    Objective Loss 0.036455    Top1 98.838542    Top5 100.000000    LR 0.000034    Time 0.019936    
2018-11-02 22:01:41,551 - Epoch: [298][  200/  391]    Overall Loss 0.036803    Objective Loss 0.036803    Top1 98.792969    Top5 100.000000    LR 0.000034    Time 0.019846    
2018-11-02 22:01:42,529 - Epoch: [298][  250/  391]    Overall Loss 0.037626    Objective Loss 0.037626    Top1 98.753125    Top5 100.000000    LR 0.000034    Time 0.019787    
2018-11-02 22:01:43,509 - Epoch: [298][  300/  391]    Overall Loss 0.037124    Objective Loss 0.037124    Top1 98.781250    Top5 100.000000    LR 0.000034    Time 0.019750    
2018-11-02 22:01:44,485 - Epoch: [298][  350/  391]    Overall Loss 0.037400    Objective Loss 0.037400    Top1 98.783482    Top5 100.000000    LR 0.000034    Time 0.019716    
2018-11-02 22:01:45,375 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34789 | -0.00619 |    0.21993 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15536 | -0.00052 |    0.09810 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15529 | -0.00326 |    0.11756 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18685 | -0.04498 |    0.14582 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19940 |  0.00675 |    0.15686 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16676 | -0.02552 |    0.12728 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16255 | -0.00331 |    0.11861 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19584 | -0.00259 |    0.14331 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16192 | -0.00405 |    0.12370 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24037 | -0.00977 |    0.15768 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14267 | -0.00036 |    0.10600 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11958 | -0.01292 |    0.09624 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14440 | -0.01347 |    0.11305 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10559 | -0.00451 |    0.08095 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11584 | -0.01300 |    0.09225 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10984 | -0.00210 |    0.08694 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13660 | -0.00740 |    0.10496 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10406 | -0.00890 |    0.08256 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.00526 |    0.07026 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08994 | -0.01093 |    0.07194 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04113 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58359 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:01:45,375 - Total sparsity: 0.00

2018-11-02 22:01:45,375 - --- validate (epoch=298)-----------
2018-11-02 22:01:45,375 - 10000 samples (128 per mini-batch)
2018-11-02 22:01:46,105 - Epoch: [298][   50/   78]    Loss 0.409571    Top1 90.500000    Top5 99.578125    
2018-11-02 22:01:46,498 - ==> Top1: 90.530    Top5: 99.650    Loss: 0.409

2018-11-02 22:01:46,498 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:01:46,499 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:01:46,510 - 

2018-11-02 22:01:46,510 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 22:01:47,548 - Epoch: [299][   50/  391]    Overall Loss 0.036154    Objective Loss 0.036154    Top1 98.953125    Top5 100.000000    LR 0.000033    Time 0.020724    
2018-11-02 22:01:48,525 - Epoch: [299][  100/  391]    Overall Loss 0.038215    Objective Loss 0.038215    Top1 98.789062    Top5 100.000000    LR 0.000033    Time 0.020112    
2018-11-02 22:01:49,504 - Epoch: [299][  150/  391]    Overall Loss 0.038230    Objective Loss 0.038230    Top1 98.786458    Top5 100.000000    LR 0.000033    Time 0.019927    
2018-11-02 22:01:50,480 - Epoch: [299][  200/  391]    Overall Loss 0.037679    Objective Loss 0.037679    Top1 98.804688    Top5 100.000000    LR 0.000033    Time 0.019824    
2018-11-02 22:01:51,459 - Epoch: [299][  250/  391]    Overall Loss 0.037046    Objective Loss 0.037046    Top1 98.846875    Top5 100.000000    LR 0.000033    Time 0.019769    
2018-11-02 22:01:52,454 - Epoch: [299][  300/  391]    Overall Loss 0.036888    Objective Loss 0.036888    Top1 98.854167    Top5 99.997396    LR 0.000033    Time 0.019787    
2018-11-02 22:01:53,490 - Epoch: [299][  350/  391]    Overall Loss 0.037529    Objective Loss 0.037529    Top1 98.832589    Top5 99.997768    LR 0.000033    Time 0.019916    
2018-11-02 22:01:54,427 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34789 | -0.00618 |    0.21993 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15536 | -0.00052 |    0.09810 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15528 | -0.00326 |    0.11756 |
|  3 | module.layer1.1.conv1.weight        | (4, 16, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18685 | -0.04498 |    0.14582 |
|  4 | module.layer1.1.conv2.weight        | (16, 4, 3, 3)  |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19940 |  0.00676 |    0.15686 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16676 | -0.02552 |    0.12728 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16255 | -0.00331 |    0.11861 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19584 | -0.00259 |    0.14330 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16191 | -0.00405 |    0.12370 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24037 | -0.00977 |    0.15768 |
| 10 | module.layer2.1.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14267 | -0.00036 |    0.10600 |
| 11 | module.layer2.1.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11958 | -0.01292 |    0.09624 |
| 12 | module.layer2.2.conv1.weight        | (7, 32, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14440 | -0.01347 |    0.11305 |
| 13 | module.layer2.2.conv2.weight        | (32, 7, 3, 3)  |          2016 |           2016 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10559 | -0.00451 |    0.08095 |
| 14 | module.layer3.0.conv1.weight        | (39, 32, 3, 3) |         11232 |          11232 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11584 | -0.01300 |    0.09224 |
| 15 | module.layer3.0.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10984 | -0.00210 |    0.08694 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13660 | -0.00740 |    0.10496 |
| 17 | module.layer3.1.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10406 | -0.00890 |    0.08255 |
| 18 | module.layer3.1.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.00526 |    0.07026 |
| 19 | module.layer3.2.conv1.weight        | (39, 64, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08994 | -0.01093 |    0.07194 |
| 20 | module.layer3.2.conv2.weight        | (64, 39, 3, 3) |         22464 |          22464 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05423 |  0.00236 |    0.04113 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58359 | -0.00001 |    0.45520 |
| 22 | Total sparsity:                     | -              |        146048 |         146048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 22:01:54,428 - Total sparsity: 0.00

2018-11-02 22:01:54,428 - --- validate (epoch=299)-----------
2018-11-02 22:01:54,428 - 10000 samples (128 per mini-batch)
2018-11-02 22:01:55,153 - Epoch: [299][   50/   78]    Loss 0.409027    Top1 90.562500    Top5 99.578125    
2018-11-02 22:01:55,547 - ==> Top1: 90.590    Top5: 99.660    Loss: 0.409

2018-11-02 22:01:55,548 - ==> Best Top1: 90.660   On Epoch: 212

2018-11-02 22:01:55,548 - Saving checkpoint to: logs/2018.11.02-211425/checkpoint.pth.tar
2018-11-02 22:01:55,559 - --- test ---------------------
2018-11-02 22:01:55,560 - 10000 samples (128 per mini-batch)
2018-11-02 22:01:56,316 - Test: [   50/   78]    Loss 0.409027    Top1 90.562500    Top5 99.578125    
2018-11-02 22:01:56,726 - ==> Top1: 90.590    Top5: 99.660    Loss: 0.409

2018-11-02 22:01:56,730 - 
2018-11-02 22:01:56,731 - Log file for this run: /home/ccma/Chilung/1022/distiller/examples/classifier_compression/logs/2018.11.02-211425/2018.11.02-211425.log
