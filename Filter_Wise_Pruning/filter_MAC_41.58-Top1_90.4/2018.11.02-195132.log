2018-11-02 19:51:32,711 - Log file for this run: /home/ccma/Chilung/1022/distiller/examples/classifier_compression/logs/2018.11.02-195132/2018.11.02-195132.log
2018-11-02 19:51:32,711 - Number of CPUs: 8
2018-11-02 19:51:32,747 - Number of GPUs: 1
2018-11-02 19:51:32,747 - CUDA version: 8.0.61
2018-11-02 19:51:32,747 - CUDNN version: 7102
2018-11-02 19:51:32,747 - Kernel: 4.13.0-38-generic
2018-11-02 19:51:32,748 - Python: 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
2018-11-02 19:51:32,748 - PyTorch: 0.4.0
2018-11-02 19:51:32,748 - Numpy: 1.14.3
2018-11-02 19:51:32,762 - Git is dirty
2018-11-02 19:51:32,762 - Active Git branch: master
2018-11-02 19:51:32,765 - Git commit: 8bf95d12172fb6e82a00ce40007953e23d9648c7
2018-11-02 19:51:32,766 - App args: ['compress_classifier.py', '--arch', 'resnet20_cifar', '--lr', '0.3', '-p', '50', '../../../data.cifar10', '-b', '128', '-j', '1', '--vs', '0', '--deterministic', '--epochs', '300', '--compress=../../../resnet20_cifar_baseline/resnet20_cifar_baseline.yaml']
2018-11-02 19:51:32,767 - ==> using cifar10 dataset
2018-11-02 19:51:32,767 - => creating resnet20_cifar model for CIFAR10
2018-11-02 19:51:35,592 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2018-11-02 19:51:35,592 - Optimizer Args: {'lr': 0.3, 'weight_decay': 0.0001, 'dampening': 0, 'nesterov': False, 'momentum': 0.9}
2018-11-02 19:51:37,011 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2018-11-02 19:51:37,011 - Reading compression schedule from: ../../../resnet20_cifar_baseline/resnet20_cifar_baseline.yaml
2018-11-02 19:51:37,051 - Schedule contents:
{
  "pruners": {
    "filter_pruner": {
      "class": "L1RankedStructureParameterPruner",
      "reg_regims": {
        "module.layer1.0.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer1.1.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer1.2.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer2.0.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer2.1.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer2.2.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer3.0.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer3.1.conv1.weight": [
          0.6,
          "3D"
        ],
        "module.layer3.2.conv1.weight": [
          0.6,
          "3D"
        ]
      }
    }
  },
  "extensions": {
    "net_thinner": {
      "class": "FilterRemover",
      "thinning_func_str": "remove_filters",
      "arch": "resnet20_cifar",
      "dataset": "cifar10"
    }
  },
  "lr_schedulers": {
    "exp_finetuning_lr": {
      "class": "ExponentialLR",
      "gamma": 0.95
    }
  },
  "policies": [
    {
      "pruner": {
        "instance_name": "filter_pruner"
      },
      "epochs": [
        120
      ]
    },
    {
      "extension": {
        "instance_name": "net_thinner"
      },
      "epochs": [
        120
      ]
    },
    {
      "lr_scheduler": {
        "instance_name": "exp_finetuning_lr"
      },
      "starting_epoch": 121,
      "ending_epoch": 300,
      "frequency": 1
    }
  ]
}
2018-11-02 19:51:37,052 - 

2018-11-02 19:51:37,052 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:51:38,247 - Epoch: [0][   50/  391]    Overall Loss 2.249211    Objective Loss 2.249211    Top1 19.015625    Top5 69.343750    LR 0.300000    Time 0.023863    
2018-11-02 19:51:39,359 - Epoch: [0][  100/  391]    Overall Loss 2.080102    Objective Loss 2.080102    Top1 22.304687    Top5 76.265625    LR 0.300000    Time 0.023034    
2018-11-02 19:51:40,468 - Epoch: [0][  150/  391]    Overall Loss 1.987033    Objective Loss 1.987033    Top1 24.859375    Top5 79.520833    LR 0.300000    Time 0.022740    
2018-11-02 19:51:41,576 - Epoch: [0][  200/  391]    Overall Loss 1.930329    Objective Loss 1.930329    Top1 26.828125    Top5 81.312500    LR 0.300000    Time 0.022590    
2018-11-02 19:51:42,683 - Epoch: [0][  250/  391]    Overall Loss 1.875432    Objective Loss 1.875432    Top1 29.021875    Top5 82.884375    LR 0.300000    Time 0.022496    
2018-11-02 19:51:43,793 - Epoch: [0][  300/  391]    Overall Loss 1.828787    Objective Loss 1.828787    Top1 30.838542    Top5 84.057292    LR 0.300000    Time 0.022441    
2018-11-02 19:51:44,902 - Epoch: [0][  350/  391]    Overall Loss 1.785466    Objective Loss 1.785466    Top1 32.598214    Top5 85.113839    LR 0.300000    Time 0.022402    
2018-11-02 19:51:45,899 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38050 | -0.00181 |    0.28428 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15096 |  0.00035 |    0.11653 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14372 |  0.00002 |    0.11309 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14422 | -0.00081 |    0.11371 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13851 | -0.00675 |    0.11000 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13119 | -0.01244 |    0.10391 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13018 |  0.00125 |    0.10249 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10461 | -0.00659 |    0.08339 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09446 | -0.00098 |    0.07512 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27383 | -0.01196 |    0.21812 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09312 | -0.00347 |    0.07331 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09104 | -0.00102 |    0.07217 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08823 | -0.00216 |    0.07018 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08739 | -0.00353 |    0.06937 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06462 |  0.00235 |    0.05133 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06203 | -0.00472 |    0.04929 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19659 | -0.01411 |    0.15634 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06312 | -0.00072 |    0.04979 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06331 | -0.00317 |    0.05004 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05683 |  0.00381 |    0.04536 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05852 | -0.01055 |    0.04742 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34955 | -0.00382 |    0.26083 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:51:45,899 - Total sparsity: 0.00

2018-11-02 19:51:45,899 - --- validate (epoch=0)-----------
2018-11-02 19:51:45,899 - 10000 samples (128 per mini-batch)
2018-11-02 19:51:46,615 - Epoch: [0][   50/   78]    Loss 1.543209    Top1 43.578125    Top5 92.062500    
2018-11-02 19:51:47,005 - ==> Top1: 43.020    Top5: 92.200    Loss: 1.540

2018-11-02 19:51:47,006 - ==> Best Top1: 43.020   On Epoch: 0

2018-11-02 19:51:47,006 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:51:47,121 - 

2018-11-02 19:51:47,121 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:51:48,262 - Epoch: [1][   50/  391]    Overall Loss 1.432155    Objective Loss 1.432155    Top1 47.703125    Top5 92.812500    LR 0.300000    Time 0.022788    
2018-11-02 19:51:49,376 - Epoch: [1][  100/  391]    Overall Loss 1.394355    Objective Loss 1.394355    Top1 49.156250    Top5 93.062500    LR 0.300000    Time 0.022520    
2018-11-02 19:51:50,488 - Epoch: [1][  150/  391]    Overall Loss 1.348181    Objective Loss 1.348181    Top1 51.166667    Top5 93.598958    LR 0.300000    Time 0.022414    
2018-11-02 19:51:51,601 - Epoch: [1][  200/  391]    Overall Loss 1.317914    Objective Loss 1.317914    Top1 52.265625    Top5 93.988281    LR 0.300000    Time 0.022352    
2018-11-02 19:51:52,714 - Epoch: [1][  250/  391]    Overall Loss 1.284584    Objective Loss 1.284584    Top1 53.546875    Top5 94.259375    LR 0.300000    Time 0.022329    
2018-11-02 19:51:53,829 - Epoch: [1][  300/  391]    Overall Loss 1.261676    Objective Loss 1.261676    Top1 54.458333    Top5 94.463542    LR 0.300000    Time 0.022318    
2018-11-02 19:51:54,988 - Epoch: [1][  350/  391]    Overall Loss 1.238257    Objective Loss 1.238257    Top1 55.245536    Top5 94.720982    LR 0.300000    Time 0.022438    
2018-11-02 19:51:56,022 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.45953 | -0.00249 |    0.33452 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15807 |  0.00165 |    0.11915 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15396 | -0.00644 |    0.11741 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16260 | -0.00514 |    0.12439 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15842 | -0.01287 |    0.12385 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14331 | -0.00897 |    0.10933 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14026 | -0.00313 |    0.10937 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13296 | -0.00761 |    0.10201 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11633 | -0.00307 |    0.09029 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31871 | -0.01197 |    0.25082 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11267 | -0.00666 |    0.08707 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10380 | -0.00370 |    0.08168 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09885 | -0.00670 |    0.07800 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09459 | -0.00215 |    0.07490 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07736 | -0.00279 |    0.06092 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06888 | -0.00481 |    0.05404 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21034 | -0.02617 |    0.16644 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07034 | -0.00181 |    0.05461 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06784 | -0.00219 |    0.05268 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05440 |  0.00458 |    0.04325 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05563 | -0.01096 |    0.04504 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44571 | -0.00339 |    0.34367 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:51:56,022 - Total sparsity: 0.00

2018-11-02 19:51:56,022 - --- validate (epoch=1)-----------
2018-11-02 19:51:56,022 - 10000 samples (128 per mini-batch)
2018-11-02 19:51:56,759 - Epoch: [1][   50/   78]    Loss 1.349763    Top1 56.953125    Top5 95.171875    
2018-11-02 19:51:57,149 - ==> Top1: 56.810    Top5: 94.970    Loss: 1.362

2018-11-02 19:51:57,150 - ==> Best Top1: 56.810   On Epoch: 1

2018-11-02 19:51:57,150 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:51:57,161 - 

2018-11-02 19:51:57,161 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:51:58,341 - Epoch: [2][   50/  391]    Overall Loss 1.051294    Objective Loss 1.051294    Top1 62.859375    Top5 96.500000    LR 0.300000    Time 0.023568    
2018-11-02 19:51:59,463 - Epoch: [2][  100/  391]    Overall Loss 1.043496    Objective Loss 1.043496    Top1 63.046875    Top5 96.367188    LR 0.300000    Time 0.022992    
2018-11-02 19:52:00,590 - Epoch: [2][  150/  391]    Overall Loss 1.023157    Objective Loss 1.023157    Top1 63.661458    Top5 96.505208    LR 0.300000    Time 0.022830    
2018-11-02 19:52:01,712 - Epoch: [2][  200/  391]    Overall Loss 0.998733    Objective Loss 0.998733    Top1 64.531250    Top5 96.582031    LR 0.300000    Time 0.022727    
2018-11-02 19:52:02,835 - Epoch: [2][  250/  391]    Overall Loss 0.988267    Objective Loss 0.988267    Top1 64.865625    Top5 96.693750    LR 0.300000    Time 0.022668    
2018-11-02 19:52:03,959 - Epoch: [2][  300/  391]    Overall Loss 0.974377    Objective Loss 0.974377    Top1 65.367188    Top5 96.822917    LR 0.300000    Time 0.022633    
2018-11-02 19:52:05,081 - Epoch: [2][  350/  391]    Overall Loss 0.960025    Objective Loss 0.960025    Top1 65.897321    Top5 96.957589    LR 0.300000    Time 0.022601    
2018-11-02 19:52:06,083 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.48925 |  0.00347 |    0.34664 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15822 | -0.00110 |    0.11574 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15771 | -0.00415 |    0.11743 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17224 | -0.00460 |    0.12850 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16983 | -0.01272 |    0.13061 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14941 | -0.01277 |    0.11263 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14410 | -0.00669 |    0.11163 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15118 | -0.00946 |    0.11387 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13155 | -0.00442 |    0.10064 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34933 | -0.01586 |    0.27146 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12528 | -0.00749 |    0.09604 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11283 | -0.00501 |    0.08812 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10745 | -0.00947 |    0.08426 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09987 | -0.00158 |    0.07889 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09207 | -0.00552 |    0.07226 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07809 | -0.00627 |    0.06074 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21872 | -0.02809 |    0.17216 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07803 | -0.00536 |    0.06029 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07200 | -0.00189 |    0.05512 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05241 |  0.00420 |    0.04153 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05279 | -0.01131 |    0.04277 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.50144 | -0.00302 |    0.39110 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:52:06,083 - Total sparsity: 0.00

2018-11-02 19:52:06,083 - --- validate (epoch=2)-----------
2018-11-02 19:52:06,083 - 10000 samples (128 per mini-batch)
2018-11-02 19:52:06,801 - Epoch: [2][   50/   78]    Loss 1.125182    Top1 62.046875    Top5 97.156250    
2018-11-02 19:52:07,191 - ==> Top1: 62.230    Top5: 97.240    Loss: 1.114

2018-11-02 19:52:07,192 - ==> Best Top1: 62.230   On Epoch: 2

2018-11-02 19:52:07,192 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:52:07,203 - 

2018-11-02 19:52:07,203 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:52:08,382 - Epoch: [3][   50/  391]    Overall Loss 0.831718    Objective Loss 0.831718    Top1 70.281250    Top5 98.046875    LR 0.300000    Time 0.023550    
2018-11-02 19:52:09,519 - Epoch: [3][  100/  391]    Overall Loss 0.830995    Objective Loss 0.830995    Top1 70.765625    Top5 97.898438    LR 0.300000    Time 0.023130    
2018-11-02 19:52:10,640 - Epoch: [3][  150/  391]    Overall Loss 0.817110    Objective Loss 0.817110    Top1 71.427083    Top5 97.901042    LR 0.300000    Time 0.022883    
2018-11-02 19:52:11,766 - Epoch: [3][  200/  391]    Overall Loss 0.815265    Objective Loss 0.815265    Top1 71.453125    Top5 97.929688    LR 0.300000    Time 0.022767    
2018-11-02 19:52:12,892 - Epoch: [3][  250/  391]    Overall Loss 0.808913    Objective Loss 0.808913    Top1 71.825000    Top5 97.965625    LR 0.300000    Time 0.022711    
2018-11-02 19:52:14,015 - Epoch: [3][  300/  391]    Overall Loss 0.803061    Objective Loss 0.803061    Top1 72.018229    Top5 98.015625    LR 0.300000    Time 0.022666    
2018-11-02 19:52:15,139 - Epoch: [3][  350/  391]    Overall Loss 0.797292    Objective Loss 0.797292    Top1 72.234375    Top5 97.997768    LR 0.300000    Time 0.022638    
2018-11-02 19:52:16,141 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.50562 |  0.00173 |    0.35189 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15849 |  0.00031 |    0.11249 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15957 | -0.00381 |    0.11719 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17691 | -0.00789 |    0.13131 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17571 | -0.00827 |    0.13356 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15612 | -0.01400 |    0.11595 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14641 | -0.00303 |    0.11179 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16203 | -0.00973 |    0.12074 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14065 | -0.00495 |    0.10751 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36660 | -0.01683 |    0.28433 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13319 | -0.00799 |    0.10182 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00570 |    0.09230 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11386 | -0.01353 |    0.08916 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10352 | -0.00141 |    0.08124 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10312 | -0.00847 |    0.08080 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08635 | -0.00804 |    0.06692 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22372 | -0.02903 |    0.17636 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08547 | -0.00700 |    0.06560 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07592 | -0.00103 |    0.05755 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05107 |  0.00399 |    0.04029 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05055 | -0.01131 |    0.04092 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53041 | -0.00268 |    0.41685 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:52:16,142 - Total sparsity: 0.00

2018-11-02 19:52:16,142 - --- validate (epoch=3)-----------
2018-11-02 19:52:16,142 - 10000 samples (128 per mini-batch)
2018-11-02 19:52:16,861 - Epoch: [3][   50/   78]    Loss 0.896211    Top1 70.171875    Top5 98.140625    
2018-11-02 19:52:17,249 - ==> Top1: 70.400    Top5: 98.080    Loss: 0.891

2018-11-02 19:52:17,250 - ==> Best Top1: 70.400   On Epoch: 3

2018-11-02 19:52:17,250 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:52:17,265 - 

2018-11-02 19:52:17,265 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:52:18,448 - Epoch: [4][   50/  391]    Overall Loss 0.717632    Objective Loss 0.717632    Top1 74.781250    Top5 98.406250    LR 0.300000    Time 0.023606    
2018-11-02 19:52:19,574 - Epoch: [4][  100/  391]    Overall Loss 0.722083    Objective Loss 0.722083    Top1 74.648438    Top5 98.390625    LR 0.300000    Time 0.023050    
2018-11-02 19:52:20,700 - Epoch: [4][  150/  391]    Overall Loss 0.715959    Objective Loss 0.715959    Top1 74.958333    Top5 98.359375    LR 0.300000    Time 0.022868    
2018-11-02 19:52:21,828 - Epoch: [4][  200/  391]    Overall Loss 0.711381    Objective Loss 0.711381    Top1 75.203125    Top5 98.375000    LR 0.300000    Time 0.022785    
2018-11-02 19:52:22,956 - Epoch: [4][  250/  391]    Overall Loss 0.709762    Objective Loss 0.709762    Top1 75.200000    Top5 98.440625    LR 0.300000    Time 0.022736    
2018-11-02 19:52:24,085 - Epoch: [4][  300/  391]    Overall Loss 0.709174    Objective Loss 0.709174    Top1 75.171875    Top5 98.442708    LR 0.300000    Time 0.022705    
2018-11-02 19:52:25,213 - Epoch: [4][  350/  391]    Overall Loss 0.705033    Objective Loss 0.705033    Top1 75.368304    Top5 98.457589    LR 0.300000    Time 0.022680    
2018-11-02 19:52:26,217 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.51703 | -0.00070 |    0.35452 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15868 | -0.00000 |    0.10973 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15907 | -0.00780 |    0.11562 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18134 | -0.00580 |    0.13273 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17905 | -0.00760 |    0.13420 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15944 | -0.01677 |    0.11722 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14661 | -0.00383 |    0.11189 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17026 | -0.00874 |    0.12548 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14739 | -0.00605 |    0.11225 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37612 | -0.01949 |    0.28724 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13879 | -0.00589 |    0.10613 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12244 | -0.00643 |    0.09475 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11809 | -0.01462 |    0.09246 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10535 | -0.00197 |    0.08223 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11155 | -0.00894 |    0.08747 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09342 | -0.00922 |    0.07198 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22533 | -0.02769 |    0.17637 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09163 | -0.00835 |    0.07045 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07882 | -0.00083 |    0.05952 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04977 |  0.00360 |    0.03909 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04840 | -0.01112 |    0.03908 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54627 | -0.00238 |    0.43049 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:52:26,217 - Total sparsity: 0.00

2018-11-02 19:52:26,218 - --- validate (epoch=4)-----------
2018-11-02 19:52:26,218 - 10000 samples (128 per mini-batch)
2018-11-02 19:52:26,925 - Epoch: [4][   50/   78]    Loss 0.925385    Top1 70.031250    Top5 97.531250    
2018-11-02 19:52:27,306 - ==> Top1: 69.730    Top5: 97.650    Loss: 0.919

2018-11-02 19:52:27,307 - ==> Best Top1: 70.400   On Epoch: 3

2018-11-02 19:52:27,307 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:52:27,319 - 

2018-11-02 19:52:27,319 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:52:28,503 - Epoch: [5][   50/  391]    Overall Loss 0.652075    Objective Loss 0.652075    Top1 77.609375    Top5 98.859375    LR 0.300000    Time 0.023639    
2018-11-02 19:52:29,631 - Epoch: [5][  100/  391]    Overall Loss 0.656179    Objective Loss 0.656179    Top1 77.101562    Top5 98.703125    LR 0.300000    Time 0.023083    
2018-11-02 19:52:30,756 - Epoch: [5][  150/  391]    Overall Loss 0.648720    Objective Loss 0.648720    Top1 77.458333    Top5 98.692708    LR 0.300000    Time 0.022879    
2018-11-02 19:52:31,882 - Epoch: [5][  200/  391]    Overall Loss 0.656688    Objective Loss 0.656688    Top1 77.132812    Top5 98.628906    LR 0.300000    Time 0.022783    
2018-11-02 19:52:33,010 - Epoch: [5][  250/  391]    Overall Loss 0.657535    Objective Loss 0.657535    Top1 77.115625    Top5 98.643750    LR 0.300000    Time 0.022735    
2018-11-02 19:52:34,137 - Epoch: [5][  300/  391]    Overall Loss 0.661805    Objective Loss 0.661805    Top1 76.908854    Top5 98.643229    LR 0.300000    Time 0.022697    
2018-11-02 19:52:35,271 - Epoch: [5][  350/  391]    Overall Loss 0.661302    Objective Loss 0.661302    Top1 76.926339    Top5 98.620536    LR 0.300000    Time 0.022691    
2018-11-02 19:52:36,274 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.52752 |  0.00136 |    0.35840 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15710 | -0.00037 |    0.10629 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15683 | -0.00999 |    0.11287 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18375 | -0.00339 |    0.13424 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18087 | -0.00526 |    0.13500 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16293 | -0.01785 |    0.11894 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14772 | -0.00573 |    0.11153 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17636 | -0.00825 |    0.12914 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15322 | -0.00586 |    0.11665 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38303 | -0.02554 |    0.28994 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14284 | -0.00821 |    0.10927 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12531 | -0.00692 |    0.09711 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12270 | -0.01619 |    0.09618 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10729 | -0.00083 |    0.08358 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11840 | -0.00941 |    0.09263 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09959 | -0.01077 |    0.07681 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22580 | -0.02774 |    0.17554 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09679 | -0.00886 |    0.07448 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08135 | -0.00087 |    0.06118 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04895 |  0.00342 |    0.03829 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04679 | -0.01100 |    0.03756 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55611 | -0.00212 |    0.43856 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:52:36,274 - Total sparsity: 0.00

2018-11-02 19:52:36,274 - --- validate (epoch=5)-----------
2018-11-02 19:52:36,274 - 10000 samples (128 per mini-batch)
2018-11-02 19:52:37,007 - Epoch: [5][   50/   78]    Loss 0.979193    Top1 69.421875    Top5 95.640625    
2018-11-02 19:52:37,394 - ==> Top1: 69.500    Top5: 95.900    Loss: 0.964

2018-11-02 19:52:37,395 - ==> Best Top1: 70.400   On Epoch: 3

2018-11-02 19:52:37,395 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:52:37,403 - 

2018-11-02 19:52:37,404 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:52:38,589 - Epoch: [6][   50/  391]    Overall Loss 0.599611    Objective Loss 0.599611    Top1 79.562500    Top5 98.593750    LR 0.300000    Time 0.023664    
2018-11-02 19:52:39,717 - Epoch: [6][  100/  391]    Overall Loss 0.612522    Objective Loss 0.612522    Top1 78.843750    Top5 98.765625    LR 0.300000    Time 0.023106    
2018-11-02 19:52:40,847 - Epoch: [6][  150/  391]    Overall Loss 0.613124    Objective Loss 0.613124    Top1 78.781250    Top5 98.697917    LR 0.300000    Time 0.022927    
2018-11-02 19:52:41,978 - Epoch: [6][  200/  391]    Overall Loss 0.612003    Objective Loss 0.612003    Top1 78.816406    Top5 98.750000    LR 0.300000    Time 0.022842    
2018-11-02 19:52:43,106 - Epoch: [6][  250/  391]    Overall Loss 0.617169    Objective Loss 0.617169    Top1 78.521875    Top5 98.743750    LR 0.300000    Time 0.022783    
2018-11-02 19:52:44,235 - Epoch: [6][  300/  391]    Overall Loss 0.615142    Objective Loss 0.615142    Top1 78.549479    Top5 98.770833    LR 0.300000    Time 0.022746    
2018-11-02 19:52:45,367 - Epoch: [6][  350/  391]    Overall Loss 0.614235    Objective Loss 0.614235    Top1 78.631696    Top5 98.772321    LR 0.300000    Time 0.022725    
2018-11-02 19:52:46,369 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53461 | -0.00222 |    0.35921 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15561 | -0.00008 |    0.10339 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15545 | -0.01118 |    0.11078 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18569 | -0.00217 |    0.13370 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18460 | -0.00473 |    0.13829 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16422 | -0.01816 |    0.11948 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14901 | -0.00161 |    0.11137 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18075 | -0.01099 |    0.13243 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15725 | -0.00596 |    0.11897 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38928 | -0.03055 |    0.29287 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14587 | -0.00880 |    0.11142 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12701 | -0.00730 |    0.09840 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12578 | -0.01581 |    0.09861 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10848 | -0.00112 |    0.08459 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12388 | -0.00973 |    0.09703 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10474 | -0.01049 |    0.08062 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22496 | -0.02549 |    0.17491 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10115 | -0.00967 |    0.07790 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08333 | -0.00038 |    0.06252 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04826 |  0.00301 |    0.03751 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04537 | -0.01056 |    0.03616 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56413 | -0.00188 |    0.44359 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:52:46,369 - Total sparsity: 0.00

2018-11-02 19:52:46,369 - --- validate (epoch=6)-----------
2018-11-02 19:52:46,369 - 10000 samples (128 per mini-batch)
2018-11-02 19:52:47,094 - Epoch: [6][   50/   78]    Loss 0.843975    Top1 72.765625    Top5 98.078125    
2018-11-02 19:52:47,489 - ==> Top1: 72.350    Top5: 98.110    Loss: 0.843

2018-11-02 19:52:47,490 - ==> Best Top1: 72.350   On Epoch: 6

2018-11-02 19:52:47,490 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:52:47,501 - 

2018-11-02 19:52:47,502 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:52:48,687 - Epoch: [7][   50/  391]    Overall Loss 0.565125    Objective Loss 0.565125    Top1 80.109375    Top5 99.125000    LR 0.300000    Time 0.023672    
2018-11-02 19:52:49,815 - Epoch: [7][  100/  391]    Overall Loss 0.569496    Objective Loss 0.569496    Top1 79.867188    Top5 99.093750    LR 0.300000    Time 0.023102    
2018-11-02 19:52:50,941 - Epoch: [7][  150/  391]    Overall Loss 0.579048    Objective Loss 0.579048    Top1 79.708333    Top5 99.026042    LR 0.300000    Time 0.022899    
2018-11-02 19:52:52,069 - Epoch: [7][  200/  391]    Overall Loss 0.580896    Objective Loss 0.580896    Top1 79.660156    Top5 98.988281    LR 0.300000    Time 0.022809    
2018-11-02 19:52:53,197 - Epoch: [7][  250/  391]    Overall Loss 0.580644    Objective Loss 0.580644    Top1 79.568750    Top5 98.987500    LR 0.300000    Time 0.022754    
2018-11-02 19:52:54,325 - Epoch: [7][  300/  391]    Overall Loss 0.582417    Objective Loss 0.582417    Top1 79.505208    Top5 98.950521    LR 0.300000    Time 0.022717    
2018-11-02 19:52:55,457 - Epoch: [7][  350/  391]    Overall Loss 0.583301    Objective Loss 0.583301    Top1 79.551339    Top5 98.979911    LR 0.300000    Time 0.022702    
2018-11-02 19:52:56,461 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53899 |  0.00684 |    0.36101 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15316 |  0.00199 |    0.10091 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15320 | -0.00827 |    0.10893 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18669 | -0.00564 |    0.13397 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18574 | -0.00774 |    0.13873 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16688 | -0.01609 |    0.12061 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15000 | -0.00361 |    0.11173 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18309 | -0.00872 |    0.13444 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15942 | -0.00481 |    0.12095 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39260 | -0.02750 |    0.29527 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14775 | -0.00885 |    0.11282 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12797 | -0.00758 |    0.09893 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12772 | -0.01764 |    0.10030 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10913 | -0.00141 |    0.08516 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12734 | -0.01076 |    0.10027 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10839 | -0.01165 |    0.08360 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22424 | -0.02595 |    0.17367 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10472 | -0.01080 |    0.08069 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08499 | -0.00087 |    0.06381 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04810 |  0.00253 |    0.03715 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04426 | -0.01061 |    0.03511 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57289 | -0.00167 |    0.45102 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:52:56,461 - Total sparsity: 0.00

2018-11-02 19:52:56,461 - --- validate (epoch=7)-----------
2018-11-02 19:52:56,461 - 10000 samples (128 per mini-batch)
2018-11-02 19:52:57,174 - Epoch: [7][   50/   78]    Loss 0.739096    Top1 75.421875    Top5 98.531250    
2018-11-02 19:52:57,561 - ==> Top1: 75.280    Top5: 98.680    Loss: 0.741

2018-11-02 19:52:57,562 - ==> Best Top1: 75.280   On Epoch: 7

2018-11-02 19:52:57,562 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:52:57,577 - 

2018-11-02 19:52:57,578 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:52:58,735 - Epoch: [8][   50/  391]    Overall Loss 0.541494    Objective Loss 0.541494    Top1 81.281250    Top5 99.031250    LR 0.300000    Time 0.023110    
2018-11-02 19:52:59,863 - Epoch: [8][  100/  391]    Overall Loss 0.558675    Objective Loss 0.558675    Top1 80.640625    Top5 99.007812    LR 0.300000    Time 0.022818    
2018-11-02 19:53:00,991 - Epoch: [8][  150/  391]    Overall Loss 0.552118    Objective Loss 0.552118    Top1 80.875000    Top5 99.067708    LR 0.300000    Time 0.022729    
2018-11-02 19:53:02,119 - Epoch: [8][  200/  391]    Overall Loss 0.559015    Objective Loss 0.559015    Top1 80.722656    Top5 99.039062    LR 0.300000    Time 0.022680    
2018-11-02 19:53:03,249 - Epoch: [8][  250/  391]    Overall Loss 0.556137    Objective Loss 0.556137    Top1 80.790625    Top5 99.015625    LR 0.300000    Time 0.022657    
2018-11-02 19:53:04,378 - Epoch: [8][  300/  391]    Overall Loss 0.557609    Objective Loss 0.557609    Top1 80.765625    Top5 99.023438    LR 0.300000    Time 0.022642    
2018-11-02 19:53:05,508 - Epoch: [8][  350/  391]    Overall Loss 0.557383    Objective Loss 0.557383    Top1 80.812500    Top5 98.995536    LR 0.300000    Time 0.022630    
2018-11-02 19:53:06,516 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54362 |  0.00929 |    0.36112 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15209 |  0.00190 |    0.09986 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15241 | -0.01214 |    0.10757 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18732 | -0.00451 |    0.13493 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18645 | -0.00826 |    0.13814 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16751 | -0.02158 |    0.12163 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15058 | -0.00257 |    0.11183 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18474 | -0.00973 |    0.13594 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16032 | -0.00417 |    0.12150 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39386 | -0.03099 |    0.29271 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14940 | -0.00935 |    0.11441 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12914 | -0.00837 |    0.09992 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12983 | -0.01798 |    0.10216 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10999 | -0.00128 |    0.08561 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13047 | -0.01157 |    0.10266 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11172 | -0.01194 |    0.08638 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22324 | -0.02450 |    0.17343 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10801 | -0.01096 |    0.08343 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08631 | -0.00016 |    0.06470 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04790 |  0.00232 |    0.03678 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04354 | -0.01013 |    0.03416 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57621 | -0.00149 |    0.45166 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:53:06,517 - Total sparsity: 0.00

2018-11-02 19:53:06,517 - --- validate (epoch=8)-----------
2018-11-02 19:53:06,517 - 10000 samples (128 per mini-batch)
2018-11-02 19:53:07,238 - Epoch: [8][   50/   78]    Loss 0.774249    Top1 75.234375    Top5 97.843750    
2018-11-02 19:53:07,623 - ==> Top1: 75.290    Top5: 98.020    Loss: 0.776

2018-11-02 19:53:07,623 - ==> Best Top1: 75.290   On Epoch: 8

2018-11-02 19:53:07,624 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:53:07,635 - 

2018-11-02 19:53:07,635 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:53:08,818 - Epoch: [9][   50/  391]    Overall Loss 0.530622    Objective Loss 0.530622    Top1 81.953125    Top5 99.140625    LR 0.300000    Time 0.023608    
2018-11-02 19:53:09,946 - Epoch: [9][  100/  391]    Overall Loss 0.531139    Objective Loss 0.531139    Top1 81.843750    Top5 99.156250    LR 0.300000    Time 0.023078    
2018-11-02 19:53:11,075 - Epoch: [9][  150/  391]    Overall Loss 0.541816    Objective Loss 0.541816    Top1 81.484375    Top5 99.140625    LR 0.300000    Time 0.022904    
2018-11-02 19:53:12,206 - Epoch: [9][  200/  391]    Overall Loss 0.546964    Objective Loss 0.546964    Top1 81.312500    Top5 99.082031    LR 0.300000    Time 0.022826    
2018-11-02 19:53:13,335 - Epoch: [9][  250/  391]    Overall Loss 0.544687    Objective Loss 0.544687    Top1 81.390625    Top5 99.078125    LR 0.300000    Time 0.022773    
2018-11-02 19:53:14,464 - Epoch: [9][  300/  391]    Overall Loss 0.542334    Objective Loss 0.542334    Top1 81.385417    Top5 99.098958    LR 0.300000    Time 0.022735    
2018-11-02 19:53:15,592 - Epoch: [9][  350/  391]    Overall Loss 0.544663    Objective Loss 0.544663    Top1 81.332589    Top5 99.060268    LR 0.300000    Time 0.022707    
2018-11-02 19:53:16,596 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54461 |  0.01107 |    0.36408 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15131 |  0.00219 |    0.09785 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15257 | -0.00885 |    0.10689 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18837 | -0.00506 |    0.13402 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18739 | -0.00769 |    0.13944 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16915 | -0.02010 |    0.12169 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15122 | -0.00378 |    0.11144 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18729 | -0.00551 |    0.13747 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16222 | -0.00541 |    0.12319 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39656 | -0.03214 |    0.29598 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15100 | -0.01007 |    0.11568 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13013 | -0.00802 |    0.10083 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13151 | -0.01972 |    0.10398 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11054 | -0.00108 |    0.08607 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13364 | -0.01213 |    0.10519 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11465 | -0.01176 |    0.08870 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22192 | -0.02064 |    0.17230 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11065 | -0.01132 |    0.08559 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08742 | -0.00074 |    0.06541 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04803 |  0.00224 |    0.03658 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04301 | -0.01017 |    0.03356 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57926 | -0.00132 |    0.45184 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:53:16,596 - Total sparsity: 0.00

2018-11-02 19:53:16,596 - --- validate (epoch=9)-----------
2018-11-02 19:53:16,596 - 10000 samples (128 per mini-batch)
2018-11-02 19:53:17,302 - Epoch: [9][   50/   78]    Loss 0.668818    Top1 77.718750    Top5 98.531250    
2018-11-02 19:53:17,685 - ==> Top1: 77.730    Top5: 98.620    Loss: 0.669

2018-11-02 19:53:17,685 - ==> Best Top1: 77.730   On Epoch: 9

2018-11-02 19:53:17,685 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:53:17,697 - 

2018-11-02 19:53:17,697 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:53:18,881 - Epoch: [10][   50/  391]    Overall Loss 0.524044    Objective Loss 0.524044    Top1 81.703125    Top5 98.890625    LR 0.300000    Time 0.023638    
2018-11-02 19:53:20,009 - Epoch: [10][  100/  391]    Overall Loss 0.516917    Objective Loss 0.516917    Top1 81.875000    Top5 99.117188    LR 0.300000    Time 0.023090    
2018-11-02 19:53:21,140 - Epoch: [10][  150/  391]    Overall Loss 0.530731    Objective Loss 0.530731    Top1 81.651042    Top5 99.104167    LR 0.300000    Time 0.022923    
2018-11-02 19:53:22,271 - Epoch: [10][  200/  391]    Overall Loss 0.529301    Objective Loss 0.529301    Top1 81.656250    Top5 99.136719    LR 0.300000    Time 0.022843    
2018-11-02 19:53:23,403 - Epoch: [10][  250/  391]    Overall Loss 0.530735    Objective Loss 0.530735    Top1 81.743750    Top5 99.137500    LR 0.300000    Time 0.022796    
2018-11-02 19:53:24,533 - Epoch: [10][  300/  391]    Overall Loss 0.529554    Objective Loss 0.529554    Top1 81.854167    Top5 99.148438    LR 0.300000    Time 0.022760    
2018-11-02 19:53:25,664 - Epoch: [10][  350/  391]    Overall Loss 0.527447    Objective Loss 0.527447    Top1 81.970982    Top5 99.122768    LR 0.300000    Time 0.022736    
2018-11-02 19:53:26,670 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54512 |  0.00430 |    0.36011 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15131 | -0.00084 |    0.09622 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15300 | -0.00928 |    0.10647 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18875 | -0.00664 |    0.13561 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18877 | -0.00903 |    0.14078 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17000 | -0.02060 |    0.12248 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15213 | -0.00262 |    0.11094 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18928 | -0.00703 |    0.13859 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16380 | -0.00419 |    0.12412 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39745 | -0.03288 |    0.29702 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15123 | -0.00921 |    0.11603 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13062 | -0.00833 |    0.10133 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13439 | -0.01959 |    0.10617 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11250 | -0.00156 |    0.08747 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.01225 |    0.10802 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11742 | -0.01173 |    0.09091 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22101 | -0.02162 |    0.17194 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11289 | -0.01155 |    0.08745 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08862 | -0.00024 |    0.06643 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04817 |  0.00193 |    0.03654 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04262 | -0.00997 |    0.03303 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58161 | -0.00118 |    0.45709 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:53:26,670 - Total sparsity: 0.00

2018-11-02 19:53:26,670 - --- validate (epoch=10)-----------
2018-11-02 19:53:26,671 - 10000 samples (128 per mini-batch)
2018-11-02 19:53:27,405 - Epoch: [10][   50/   78]    Loss 1.167046    Top1 67.875000    Top5 97.484375    
2018-11-02 19:53:27,795 - ==> Top1: 66.980    Top5: 97.570    Loss: 1.177

2018-11-02 19:53:27,796 - ==> Best Top1: 77.730   On Epoch: 9

2018-11-02 19:53:27,796 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:53:27,804 - 

2018-11-02 19:53:27,805 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:53:28,992 - Epoch: [11][   50/  391]    Overall Loss 0.500677    Objective Loss 0.500677    Top1 82.609375    Top5 99.187500    LR 0.300000    Time 0.023704    
2018-11-02 19:53:30,121 - Epoch: [11][  100/  391]    Overall Loss 0.510383    Objective Loss 0.510383    Top1 82.250000    Top5 99.109375    LR 0.300000    Time 0.023136    
2018-11-02 19:53:31,253 - Epoch: [11][  150/  391]    Overall Loss 0.510306    Objective Loss 0.510306    Top1 82.276042    Top5 99.130208    LR 0.300000    Time 0.022958    
2018-11-02 19:53:32,385 - Epoch: [11][  200/  391]    Overall Loss 0.513909    Objective Loss 0.513909    Top1 82.062500    Top5 99.101562    LR 0.300000    Time 0.022873    
2018-11-02 19:53:33,516 - Epoch: [11][  250/  391]    Overall Loss 0.512675    Objective Loss 0.512675    Top1 82.062500    Top5 99.118750    LR 0.300000    Time 0.022820    
2018-11-02 19:53:34,648 - Epoch: [11][  300/  391]    Overall Loss 0.511758    Objective Loss 0.511758    Top1 82.174479    Top5 99.135417    LR 0.300000    Time 0.022783    
2018-11-02 19:53:35,779 - Epoch: [11][  350/  391]    Overall Loss 0.510035    Objective Loss 0.510035    Top1 82.283482    Top5 99.109375    LR 0.300000    Time 0.022759    
2018-11-02 19:53:36,788 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54676 | -0.00794 |    0.35991 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15251 |  0.00188 |    0.09590 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15387 | -0.01053 |    0.10766 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18889 | -0.00735 |    0.13525 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18922 | -0.01055 |    0.14134 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17062 | -0.02271 |    0.12331 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15263 |  0.00097 |    0.11074 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19149 | -0.00762 |    0.14050 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16509 | -0.00372 |    0.12545 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39751 | -0.03186 |    0.29647 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15163 | -0.00923 |    0.11617 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13095 | -0.00837 |    0.10138 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13671 | -0.01989 |    0.10796 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11358 | -0.00057 |    0.08830 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13910 | -0.01195 |    0.11008 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11973 | -0.01200 |    0.09315 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22003 | -0.02260 |    0.17105 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11492 | -0.01183 |    0.08917 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08951 | -0.00076 |    0.06712 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04845 |  0.00149 |    0.03662 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04242 | -0.00995 |    0.03255 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58144 | -0.00104 |    0.45640 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:53:36,788 - Total sparsity: 0.00

2018-11-02 19:53:36,788 - --- validate (epoch=11)-----------
2018-11-02 19:53:36,788 - 10000 samples (128 per mini-batch)
2018-11-02 19:53:37,509 - Epoch: [11][   50/   78]    Loss 0.757607    Top1 76.187500    Top5 98.328125    
2018-11-02 19:53:37,901 - ==> Top1: 76.420    Top5: 98.440    Loss: 0.754

2018-11-02 19:53:37,901 - ==> Best Top1: 77.730   On Epoch: 9

2018-11-02 19:53:37,901 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:53:37,910 - 

2018-11-02 19:53:37,910 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:53:39,098 - Epoch: [12][   50/  391]    Overall Loss 0.486437    Objective Loss 0.486437    Top1 82.906250    Top5 99.203125    LR 0.300000    Time 0.023731    
2018-11-02 19:53:40,229 - Epoch: [12][  100/  391]    Overall Loss 0.483850    Objective Loss 0.483850    Top1 83.148438    Top5 99.242188    LR 0.300000    Time 0.023162    
2018-11-02 19:53:41,363 - Epoch: [12][  150/  391]    Overall Loss 0.498873    Objective Loss 0.498873    Top1 82.609375    Top5 99.192708    LR 0.300000    Time 0.022990    
2018-11-02 19:53:42,495 - Epoch: [12][  200/  391]    Overall Loss 0.500934    Objective Loss 0.500934    Top1 82.578125    Top5 99.140625    LR 0.300000    Time 0.022897    
2018-11-02 19:53:43,626 - Epoch: [12][  250/  391]    Overall Loss 0.498838    Objective Loss 0.498838    Top1 82.718750    Top5 99.175000    LR 0.300000    Time 0.022838    
2018-11-02 19:53:44,758 - Epoch: [12][  300/  391]    Overall Loss 0.501135    Objective Loss 0.501135    Top1 82.619792    Top5 99.184896    LR 0.300000    Time 0.022800    
2018-11-02 19:53:45,891 - Epoch: [12][  350/  391]    Overall Loss 0.501869    Objective Loss 0.501869    Top1 82.535714    Top5 99.185268    LR 0.300000    Time 0.022766    
2018-11-02 19:53:46,897 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54900 | -0.00715 |    0.36168 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15289 |  0.00305 |    0.09637 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15480 | -0.01216 |    0.10799 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19034 | -0.00767 |    0.13533 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18936 | -0.00756 |    0.14079 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17178 | -0.02004 |    0.12449 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15378 | -0.00126 |    0.11145 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19360 | -0.00453 |    0.14227 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16624 | -0.00500 |    0.12643 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39824 | -0.03599 |    0.29739 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15254 | -0.01062 |    0.11704 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13182 | -0.00761 |    0.10213 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13807 | -0.01880 |    0.10913 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11426 | -0.00091 |    0.08911 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14119 | -0.01314 |    0.11158 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12204 | -0.01224 |    0.09519 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21881 | -0.02171 |    0.16978 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11692 | -0.01137 |    0.09098 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09044 | -0.00036 |    0.06798 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04882 |  0.00130 |    0.03671 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04242 | -0.00920 |    0.03216 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58463 | -0.00093 |    0.46056 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:53:46,897 - Total sparsity: 0.00

2018-11-02 19:53:46,897 - --- validate (epoch=12)-----------
2018-11-02 19:53:46,897 - 10000 samples (128 per mini-batch)
2018-11-02 19:53:47,643 - Epoch: [12][   50/   78]    Loss 0.676923    Top1 77.796875    Top5 98.953125    
2018-11-02 19:53:48,034 - ==> Top1: 77.400    Top5: 98.860    Loss: 0.693

2018-11-02 19:53:48,035 - ==> Best Top1: 77.730   On Epoch: 9

2018-11-02 19:53:48,035 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:53:48,050 - 

2018-11-02 19:53:48,050 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:53:49,237 - Epoch: [13][   50/  391]    Overall Loss 0.481722    Objective Loss 0.481722    Top1 83.718750    Top5 99.281250    LR 0.300000    Time 0.023705    
2018-11-02 19:53:50,369 - Epoch: [13][  100/  391]    Overall Loss 0.475275    Objective Loss 0.475275    Top1 83.773438    Top5 99.289062    LR 0.300000    Time 0.023158    
2018-11-02 19:53:51,499 - Epoch: [13][  150/  391]    Overall Loss 0.481132    Objective Loss 0.481132    Top1 83.473958    Top5 99.265625    LR 0.300000    Time 0.022962    
2018-11-02 19:53:52,627 - Epoch: [13][  200/  391]    Overall Loss 0.484958    Objective Loss 0.484958    Top1 83.386719    Top5 99.292969    LR 0.300000    Time 0.022856    
2018-11-02 19:53:53,756 - Epoch: [13][  250/  391]    Overall Loss 0.482961    Objective Loss 0.482961    Top1 83.481250    Top5 99.275000    LR 0.300000    Time 0.022795    
2018-11-02 19:53:54,884 - Epoch: [13][  300/  391]    Overall Loss 0.482360    Objective Loss 0.482360    Top1 83.510417    Top5 99.276042    LR 0.300000    Time 0.022753    
2018-11-02 19:53:56,013 - Epoch: [13][  350/  391]    Overall Loss 0.485245    Objective Loss 0.485245    Top1 83.386161    Top5 99.261161    LR 0.300000    Time 0.022723    
2018-11-02 19:53:57,019 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55349 |  0.00370 |    0.36218 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15348 | -0.00110 |    0.09667 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15510 | -0.00969 |    0.10732 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19105 | -0.00944 |    0.13529 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19030 | -0.01051 |    0.14168 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17367 | -0.02263 |    0.12541 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 |  0.00269 |    0.11234 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19588 | -0.00169 |    0.14492 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16739 | -0.00591 |    0.12744 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39646 | -0.03399 |    0.29718 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15294 | -0.01054 |    0.11724 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13209 | -0.00868 |    0.10244 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13946 | -0.01909 |    0.11096 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11485 | -0.00144 |    0.08959 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14232 | -0.01461 |    0.11280 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12363 | -0.01177 |    0.09635 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21649 | -0.02162 |    0.16802 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11841 | -0.01150 |    0.09222 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09118 | -0.00056 |    0.06861 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04920 |  0.00080 |    0.03692 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04236 | -0.00933 |    0.03200 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58627 | -0.00083 |    0.46140 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:53:57,019 - Total sparsity: 0.00

2018-11-02 19:53:57,020 - --- validate (epoch=13)-----------
2018-11-02 19:53:57,020 - 10000 samples (128 per mini-batch)
2018-11-02 19:53:57,739 - Epoch: [13][   50/   78]    Loss 0.591525    Top1 79.968750    Top5 98.906250    
2018-11-02 19:53:58,131 - ==> Top1: 79.800    Top5: 98.950    Loss: 0.598

2018-11-02 19:53:58,131 - ==> Best Top1: 79.800   On Epoch: 13

2018-11-02 19:53:58,131 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:53:58,143 - 

2018-11-02 19:53:58,143 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:53:59,328 - Epoch: [14][   50/  391]    Overall Loss 0.468498    Objective Loss 0.468498    Top1 83.843750    Top5 99.296875    LR 0.300000    Time 0.023661    
2018-11-02 19:54:00,455 - Epoch: [14][  100/  391]    Overall Loss 0.478209    Objective Loss 0.478209    Top1 83.406250    Top5 99.265625    LR 0.300000    Time 0.023094    
2018-11-02 19:54:01,583 - Epoch: [14][  150/  391]    Overall Loss 0.483510    Objective Loss 0.483510    Top1 83.296875    Top5 99.260417    LR 0.300000    Time 0.022907    
2018-11-02 19:54:02,713 - Epoch: [14][  200/  391]    Overall Loss 0.475692    Objective Loss 0.475692    Top1 83.675781    Top5 99.246094    LR 0.300000    Time 0.022805    
2018-11-02 19:54:03,845 - Epoch: [14][  250/  391]    Overall Loss 0.480450    Objective Loss 0.480450    Top1 83.587500    Top5 99.246875    LR 0.300000    Time 0.022766    
2018-11-02 19:54:04,974 - Epoch: [14][  300/  391]    Overall Loss 0.481345    Objective Loss 0.481345    Top1 83.546875    Top5 99.263021    LR 0.300000    Time 0.022732    
2018-11-02 19:54:06,103 - Epoch: [14][  350/  391]    Overall Loss 0.477993    Objective Loss 0.477993    Top1 83.618304    Top5 99.276786    LR 0.300000    Time 0.022706    
2018-11-02 19:54:07,107 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55107 | -0.00209 |    0.35685 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15233 |  0.00099 |    0.09428 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15342 | -0.00934 |    0.10681 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19151 | -0.00915 |    0.13514 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19013 | -0.01015 |    0.14106 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17542 | -0.02505 |    0.12660 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15630 |  0.00112 |    0.11285 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19745 | -0.00645 |    0.14618 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16879 | -0.00550 |    0.12893 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39529 | -0.02779 |    0.29518 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15360 | -0.01021 |    0.11769 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13289 | -0.00918 |    0.10347 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14090 | -0.02001 |    0.11209 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11590 | -0.00005 |    0.09047 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14363 | -0.01465 |    0.11384 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12535 | -0.01174 |    0.09779 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21467 | -0.02250 |    0.16708 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11992 | -0.01255 |    0.09354 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09205 | -0.00036 |    0.06918 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04990 |  0.00076 |    0.03730 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04255 | -0.00954 |    0.03206 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59049 | -0.00073 |    0.46462 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:54:07,107 - Total sparsity: 0.00

2018-11-02 19:54:07,107 - --- validate (epoch=14)-----------
2018-11-02 19:54:07,107 - 10000 samples (128 per mini-batch)
2018-11-02 19:54:07,820 - Epoch: [14][   50/   78]    Loss 0.553592    Top1 81.796875    Top5 98.937500    
2018-11-02 19:54:08,214 - ==> Top1: 81.830    Top5: 98.940    Loss: 0.552

2018-11-02 19:54:08,215 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 19:54:08,215 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:54:08,227 - 

2018-11-02 19:54:08,227 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:54:09,411 - Epoch: [15][   50/  391]    Overall Loss 0.484880    Objective Loss 0.484880    Top1 83.625000    Top5 99.187500    LR 0.300000    Time 0.023649    
2018-11-02 19:54:10,539 - Epoch: [15][  100/  391]    Overall Loss 0.472924    Objective Loss 0.472924    Top1 83.953125    Top5 99.289062    LR 0.300000    Time 0.023091    
2018-11-02 19:54:11,668 - Epoch: [15][  150/  391]    Overall Loss 0.475943    Objective Loss 0.475943    Top1 83.588542    Top5 99.255208    LR 0.300000    Time 0.022909    
2018-11-02 19:54:12,797 - Epoch: [15][  200/  391]    Overall Loss 0.471260    Objective Loss 0.471260    Top1 83.691406    Top5 99.296875    LR 0.300000    Time 0.022823    
2018-11-02 19:54:13,925 - Epoch: [15][  250/  391]    Overall Loss 0.472324    Objective Loss 0.472324    Top1 83.650000    Top5 99.268750    LR 0.300000    Time 0.022766    
2018-11-02 19:54:15,055 - Epoch: [15][  300/  391]    Overall Loss 0.473911    Objective Loss 0.473911    Top1 83.598958    Top5 99.250000    LR 0.300000    Time 0.022733    
2018-11-02 19:54:16,185 - Epoch: [15][  350/  391]    Overall Loss 0.475216    Objective Loss 0.475216    Top1 83.569196    Top5 99.245536    LR 0.300000    Time 0.022709    
2018-11-02 19:54:17,190 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55279 |  0.00901 |    0.35802 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15245 |  0.00262 |    0.09606 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15349 | -0.00835 |    0.10611 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19157 | -0.00889 |    0.13533 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19060 | -0.00990 |    0.14089 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17727 | -0.02286 |    0.12708 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15769 |  0.00044 |    0.11474 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19858 | -0.00463 |    0.14704 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16968 | -0.00484 |    0.12943 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39967 | -0.02473 |    0.29574 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15352 | -0.00978 |    0.11710 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13348 | -0.00867 |    0.10355 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14240 | -0.02071 |    0.11367 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11719 | -0.00032 |    0.09135 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14469 | -0.01422 |    0.11459 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12681 | -0.01234 |    0.09931 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21507 | -0.02075 |    0.16668 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12158 | -0.01320 |    0.09510 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09278 | -0.00029 |    0.06991 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05035 |  0.00053 |    0.03760 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04266 | -0.00951 |    0.03186 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59383 | -0.00065 |    0.46829 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:54:17,191 - Total sparsity: 0.00

2018-11-02 19:54:17,191 - --- validate (epoch=15)-----------
2018-11-02 19:54:17,191 - 10000 samples (128 per mini-batch)
2018-11-02 19:54:17,915 - Epoch: [15][   50/   78]    Loss 0.644802    Top1 78.421875    Top5 98.546875    
2018-11-02 19:54:18,307 - ==> Top1: 78.460    Top5: 98.670    Loss: 0.645

2018-11-02 19:54:18,308 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 19:54:18,308 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:54:18,316 - 

2018-11-02 19:54:18,317 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:54:19,502 - Epoch: [16][   50/  391]    Overall Loss 0.462213    Objective Loss 0.462213    Top1 83.890625    Top5 99.218750    LR 0.300000    Time 0.023666    
2018-11-02 19:54:20,630 - Epoch: [16][  100/  391]    Overall Loss 0.466342    Objective Loss 0.466342    Top1 83.757812    Top5 99.226562    LR 0.300000    Time 0.023104    
2018-11-02 19:54:21,759 - Epoch: [16][  150/  391]    Overall Loss 0.455612    Objective Loss 0.455612    Top1 84.192708    Top5 99.291667    LR 0.300000    Time 0.022925    
2018-11-02 19:54:22,888 - Epoch: [16][  200/  391]    Overall Loss 0.466542    Objective Loss 0.466542    Top1 84.003906    Top5 99.226562    LR 0.300000    Time 0.022829    
2018-11-02 19:54:24,017 - Epoch: [16][  250/  391]    Overall Loss 0.465634    Objective Loss 0.465634    Top1 83.965625    Top5 99.240625    LR 0.300000    Time 0.022773    
2018-11-02 19:54:25,146 - Epoch: [16][  300/  391]    Overall Loss 0.466490    Objective Loss 0.466490    Top1 83.947917    Top5 99.247396    LR 0.300000    Time 0.022739    
2018-11-02 19:54:26,277 - Epoch: [16][  350/  391]    Overall Loss 0.467831    Objective Loss 0.467831    Top1 83.886161    Top5 99.234375    LR 0.300000    Time 0.022717    
2018-11-02 19:54:27,280 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55101 |  0.00327 |    0.36115 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15266 |  0.00318 |    0.09507 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15432 | -0.00735 |    0.10755 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19155 | -0.00953 |    0.13536 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19056 | -0.01257 |    0.14103 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17780 | -0.02604 |    0.12855 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15880 |  0.00287 |    0.11512 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19985 | -0.00590 |    0.14795 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17028 | -0.00348 |    0.12969 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39986 | -0.02810 |    0.29600 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15411 | -0.01175 |    0.11790 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13436 | -0.00894 |    0.10479 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14306 | -0.02140 |    0.11401 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11779 | -0.00083 |    0.09214 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14584 | -0.01490 |    0.11581 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12823 | -0.01221 |    0.10054 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21587 | -0.02027 |    0.16843 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12313 | -0.01251 |    0.09636 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09335 | -0.00049 |    0.07053 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05085 |  0.00070 |    0.03787 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04292 | -0.00890 |    0.03195 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59568 | -0.00058 |    0.46826 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:54:27,281 - Total sparsity: 0.00

2018-11-02 19:54:27,281 - --- validate (epoch=16)-----------
2018-11-02 19:54:27,281 - 10000 samples (128 per mini-batch)
2018-11-02 19:54:27,994 - Epoch: [16][   50/   78]    Loss 0.574556    Top1 81.484375    Top5 99.000000    
2018-11-02 19:54:28,380 - ==> Top1: 81.660    Top5: 99.080    Loss: 0.561

2018-11-02 19:54:28,381 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 19:54:28,381 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:54:28,396 - 

2018-11-02 19:54:28,396 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:54:29,580 - Epoch: [17][   50/  391]    Overall Loss 0.460725    Objective Loss 0.460725    Top1 84.093750    Top5 99.421875    LR 0.300000    Time 0.023645    
2018-11-02 19:54:30,710 - Epoch: [17][  100/  391]    Overall Loss 0.460128    Objective Loss 0.460128    Top1 84.031250    Top5 99.406250    LR 0.300000    Time 0.023103    
2018-11-02 19:54:31,842 - Epoch: [17][  150/  391]    Overall Loss 0.454301    Objective Loss 0.454301    Top1 84.328125    Top5 99.416667    LR 0.300000    Time 0.022940    
2018-11-02 19:54:32,973 - Epoch: [17][  200/  391]    Overall Loss 0.455855    Objective Loss 0.455855    Top1 84.351562    Top5 99.414062    LR 0.300000    Time 0.022857    
2018-11-02 19:54:34,104 - Epoch: [17][  250/  391]    Overall Loss 0.455916    Objective Loss 0.455916    Top1 84.356250    Top5 99.356250    LR 0.300000    Time 0.022803    
2018-11-02 19:54:35,235 - Epoch: [17][  300/  391]    Overall Loss 0.457474    Objective Loss 0.457474    Top1 84.307292    Top5 99.343750    LR 0.300000    Time 0.022770    
2018-11-02 19:54:36,367 - Epoch: [17][  350/  391]    Overall Loss 0.459062    Objective Loss 0.459062    Top1 84.261161    Top5 99.321429    LR 0.300000    Time 0.022747    
2018-11-02 19:54:37,375 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55572 | -0.00064 |    0.36143 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15227 |  0.00596 |    0.09559 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15449 | -0.00810 |    0.10693 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19289 | -0.01132 |    0.13571 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19102 | -0.00690 |    0.14063 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17986 | -0.02708 |    0.13028 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16057 |  0.00357 |    0.11589 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20074 | -0.00445 |    0.14873 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17094 | -0.00384 |    0.13036 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40238 | -0.03077 |    0.29962 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15454 | -0.01163 |    0.11845 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13487 | -0.00955 |    0.10525 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14455 | -0.02156 |    0.11508 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11892 | -0.00069 |    0.09308 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14711 | -0.01609 |    0.11685 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13006 | -0.01144 |    0.10183 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21591 | -0.02090 |    0.16874 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12486 | -0.01269 |    0.09789 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09413 |  0.00043 |    0.07106 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05155 |  0.00060 |    0.03842 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04323 | -0.00898 |    0.03212 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59700 | -0.00052 |    0.47026 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:54:37,375 - Total sparsity: 0.00

2018-11-02 19:54:37,375 - --- validate (epoch=17)-----------
2018-11-02 19:54:37,376 - 10000 samples (128 per mini-batch)
2018-11-02 19:54:38,094 - Epoch: [17][   50/   78]    Loss 0.620183    Top1 79.328125    Top5 98.984375    
2018-11-02 19:54:38,482 - ==> Top1: 79.560    Top5: 99.010    Loss: 0.625

2018-11-02 19:54:38,483 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 19:54:38,483 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:54:38,494 - 

2018-11-02 19:54:38,495 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:54:39,683 - Epoch: [18][   50/  391]    Overall Loss 0.438647    Objective Loss 0.438647    Top1 84.484375    Top5 99.343750    LR 0.300000    Time 0.023731    
2018-11-02 19:54:40,815 - Epoch: [18][  100/  391]    Overall Loss 0.438232    Objective Loss 0.438232    Top1 84.695312    Top5 99.351562    LR 0.300000    Time 0.023165    
2018-11-02 19:54:41,944 - Epoch: [18][  150/  391]    Overall Loss 0.454791    Objective Loss 0.454791    Top1 84.145833    Top5 99.322917    LR 0.300000    Time 0.022967    
2018-11-02 19:54:43,074 - Epoch: [18][  200/  391]    Overall Loss 0.452430    Objective Loss 0.452430    Top1 84.238281    Top5 99.335938    LR 0.300000    Time 0.022868    
2018-11-02 19:54:44,205 - Epoch: [18][  250/  391]    Overall Loss 0.447912    Objective Loss 0.447912    Top1 84.450000    Top5 99.318750    LR 0.300000    Time 0.022813    
2018-11-02 19:54:45,337 - Epoch: [18][  300/  391]    Overall Loss 0.447908    Objective Loss 0.447908    Top1 84.526042    Top5 99.317708    LR 0.300000    Time 0.022777    
2018-11-02 19:54:46,466 - Epoch: [18][  350/  391]    Overall Loss 0.448539    Objective Loss 0.448539    Top1 84.517857    Top5 99.321429    LR 0.300000    Time 0.022748    
2018-11-02 19:54:47,475 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55580 |  0.00262 |    0.36041 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15262 |  0.00509 |    0.09543 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15409 | -0.00986 |    0.10660 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19497 | -0.01176 |    0.13696 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19304 | -0.01037 |    0.14186 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18067 | -0.02625 |    0.13026 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16071 |  0.00356 |    0.11522 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20039 | -0.00482 |    0.14832 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17068 | -0.00398 |    0.13025 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40276 | -0.02892 |    0.29762 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15414 | -0.01250 |    0.11773 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13491 | -0.01059 |    0.10544 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14502 | -0.02207 |    0.11540 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11892 | -0.00007 |    0.09314 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14773 | -0.01515 |    0.11760 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13073 | -0.01171 |    0.10254 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21520 | -0.02302 |    0.16862 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12619 | -0.01301 |    0.09900 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09466 | -0.00025 |    0.07146 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05225 | -0.00010 |    0.03900 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04351 | -0.00904 |    0.03225 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59936 | -0.00046 |    0.47117 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:54:47,475 - Total sparsity: 0.00

2018-11-02 19:54:47,475 - --- validate (epoch=18)-----------
2018-11-02 19:54:47,475 - 10000 samples (128 per mini-batch)
2018-11-02 19:54:48,203 - Epoch: [18][   50/   78]    Loss 0.531873    Top1 82.000000    Top5 98.906250    
2018-11-02 19:54:48,596 - ==> Top1: 81.720    Top5: 99.130    Loss: 0.532

2018-11-02 19:54:48,597 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 19:54:48,597 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:54:48,605 - 

2018-11-02 19:54:48,606 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:54:49,794 - Epoch: [19][   50/  391]    Overall Loss 0.417357    Objective Loss 0.417357    Top1 85.484375    Top5 99.609375    LR 0.300000    Time 0.023738    
2018-11-02 19:54:50,924 - Epoch: [19][  100/  391]    Overall Loss 0.438285    Objective Loss 0.438285    Top1 84.820312    Top5 99.468750    LR 0.300000    Time 0.023156    
2018-11-02 19:54:52,054 - Epoch: [19][  150/  391]    Overall Loss 0.443575    Objective Loss 0.443575    Top1 84.598958    Top5 99.421875    LR 0.300000    Time 0.022957    
2018-11-02 19:54:53,183 - Epoch: [19][  200/  391]    Overall Loss 0.437444    Objective Loss 0.437444    Top1 84.855469    Top5 99.414062    LR 0.300000    Time 0.022856    
2018-11-02 19:54:54,314 - Epoch: [19][  250/  391]    Overall Loss 0.441505    Objective Loss 0.441505    Top1 84.734375    Top5 99.365625    LR 0.300000    Time 0.022807    
2018-11-02 19:54:55,444 - Epoch: [19][  300/  391]    Overall Loss 0.443858    Objective Loss 0.443858    Top1 84.614583    Top5 99.356771    LR 0.300000    Time 0.022768    
2018-11-02 19:54:56,574 - Epoch: [19][  350/  391]    Overall Loss 0.441310    Objective Loss 0.441310    Top1 84.676339    Top5 99.368304    LR 0.300000    Time 0.022738    
2018-11-02 19:54:57,581 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55798 | -0.00145 |    0.35900 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15383 |  0.00457 |    0.09586 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15540 | -0.01014 |    0.10807 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19522 | -0.00898 |    0.13797 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19228 | -0.01323 |    0.14205 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18116 | -0.02718 |    0.13117 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16121 |  0.00241 |    0.11514 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20039 | -0.00467 |    0.14725 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17052 | -0.00287 |    0.13006 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40346 | -0.02675 |    0.29713 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15451 | -0.01154 |    0.11783 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13552 | -0.00996 |    0.10596 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14561 | -0.02155 |    0.11552 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11908 | -0.00014 |    0.09329 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14815 | -0.01653 |    0.11787 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13120 | -0.01270 |    0.10309 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21536 | -0.02351 |    0.16869 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12709 | -0.01281 |    0.09946 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09504 | -0.00015 |    0.07175 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05315 | -0.00021 |    0.03959 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04389 | -0.00880 |    0.03242 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60234 | -0.00041 |    0.47271 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:54:57,581 - Total sparsity: 0.00

2018-11-02 19:54:57,582 - --- validate (epoch=19)-----------
2018-11-02 19:54:57,582 - 10000 samples (128 per mini-batch)
2018-11-02 19:54:58,305 - Epoch: [19][   50/   78]    Loss 0.561296    Top1 81.906250    Top5 98.968750    
2018-11-02 19:54:58,700 - ==> Top1: 81.390    Top5: 99.030    Loss: 0.564

2018-11-02 19:54:58,700 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 19:54:58,700 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:54:58,709 - 

2018-11-02 19:54:58,709 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:54:59,897 - Epoch: [20][   50/  391]    Overall Loss 0.411911    Objective Loss 0.411911    Top1 85.359375    Top5 99.515625    LR 0.300000    Time 0.023726    
2018-11-02 19:55:01,030 - Epoch: [20][  100/  391]    Overall Loss 0.430509    Objective Loss 0.430509    Top1 85.093750    Top5 99.429688    LR 0.300000    Time 0.023176    
2018-11-02 19:55:02,174 - Epoch: [20][  150/  391]    Overall Loss 0.436406    Objective Loss 0.436406    Top1 84.880208    Top5 99.380208    LR 0.300000    Time 0.023071    
2018-11-02 19:55:03,322 - Epoch: [20][  200/  391]    Overall Loss 0.438936    Objective Loss 0.438936    Top1 84.882812    Top5 99.402344    LR 0.300000    Time 0.023033    
2018-11-02 19:55:04,469 - Epoch: [20][  250/  391]    Overall Loss 0.439447    Objective Loss 0.439447    Top1 84.893750    Top5 99.393750    LR 0.300000    Time 0.023009    
2018-11-02 19:55:05,614 - Epoch: [20][  300/  391]    Overall Loss 0.441940    Objective Loss 0.441940    Top1 84.812500    Top5 99.388021    LR 0.300000    Time 0.022989    
2018-11-02 19:55:06,761 - Epoch: [20][  350/  391]    Overall Loss 0.441413    Objective Loss 0.441413    Top1 84.839286    Top5 99.401786    LR 0.300000    Time 0.022976    
2018-11-02 19:55:07,786 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56022 | -0.00214 |    0.36342 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15280 |  0.00103 |    0.09436 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15470 | -0.00647 |    0.10723 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19598 | -0.01220 |    0.13979 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19355 | -0.01037 |    0.14364 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18356 | -0.02717 |    0.13197 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16246 |  0.00271 |    0.11603 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20206 | -0.00662 |    0.14811 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17167 | -0.00418 |    0.13108 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40287 | -0.02322 |    0.29334 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 | -0.01232 |    0.11863 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13587 | -0.00949 |    0.10580 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14608 | -0.02394 |    0.11630 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11944 | -0.00131 |    0.09366 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14866 | -0.01503 |    0.11813 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13151 | -0.01202 |    0.10334 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21614 | -0.02249 |    0.16993 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12766 | -0.01177 |    0.10002 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09536 | -0.00037 |    0.07196 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05353 | -0.00058 |    0.03987 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04413 | -0.00830 |    0.03255 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60156 | -0.00036 |    0.47291 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:55:07,786 - Total sparsity: 0.00

2018-11-02 19:55:07,786 - --- validate (epoch=20)-----------
2018-11-02 19:55:07,786 - 10000 samples (128 per mini-batch)
2018-11-02 19:55:08,515 - Epoch: [20][   50/   78]    Loss 0.692618    Top1 78.000000    Top5 98.359375    
2018-11-02 19:55:08,902 - ==> Top1: 77.920    Top5: 98.530    Loss: 0.693

2018-11-02 19:55:08,903 - ==> Best Top1: 81.830   On Epoch: 14

2018-11-02 19:55:08,903 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:55:08,911 - 

2018-11-02 19:55:08,912 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:55:10,112 - Epoch: [21][   50/  391]    Overall Loss 0.419993    Objective Loss 0.419993    Top1 85.484375    Top5 99.343750    LR 0.300000    Time 0.023979    
2018-11-02 19:55:11,259 - Epoch: [21][  100/  391]    Overall Loss 0.422242    Objective Loss 0.422242    Top1 85.585938    Top5 99.406250    LR 0.300000    Time 0.023439    
2018-11-02 19:55:12,410 - Epoch: [21][  150/  391]    Overall Loss 0.427061    Objective Loss 0.427061    Top1 85.380208    Top5 99.390625    LR 0.300000    Time 0.023293    
2018-11-02 19:55:13,555 - Epoch: [21][  200/  391]    Overall Loss 0.432874    Objective Loss 0.432874    Top1 85.035156    Top5 99.402344    LR 0.300000    Time 0.023186    
2018-11-02 19:55:14,704 - Epoch: [21][  250/  391]    Overall Loss 0.436389    Objective Loss 0.436389    Top1 84.893750    Top5 99.387500    LR 0.300000    Time 0.023141    
2018-11-02 19:55:15,850 - Epoch: [21][  300/  391]    Overall Loss 0.439647    Objective Loss 0.439647    Top1 84.830729    Top5 99.382812    LR 0.300000    Time 0.023099    
2018-11-02 19:55:16,995 - Epoch: [21][  350/  391]    Overall Loss 0.438854    Objective Loss 0.438854    Top1 84.870536    Top5 99.366071    LR 0.300000    Time 0.023067    
2018-11-02 19:55:18,012 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55944 | -0.00293 |    0.36365 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15262 |  0.00155 |    0.09379 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15445 | -0.00603 |    0.10714 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19492 | -0.01450 |    0.13869 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19318 | -0.00890 |    0.14303 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18467 | -0.02714 |    0.13353 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16321 |  0.00456 |    0.11666 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20192 | -0.00659 |    0.14906 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17162 | -0.00400 |    0.13097 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40251 | -0.01938 |    0.28975 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15558 | -0.01196 |    0.11884 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13585 | -0.00914 |    0.10622 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14723 | -0.02276 |    0.11700 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11963 | -0.00149 |    0.09374 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14913 | -0.01426 |    0.11867 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13179 | -0.01228 |    0.10375 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21532 | -0.02251 |    0.16923 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12787 | -0.01295 |    0.10020 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09554 |  0.00019 |    0.07199 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05397 | -0.00037 |    0.04020 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04458 | -0.00834 |    0.03293 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60256 | -0.00032 |    0.47432 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:55:18,012 - Total sparsity: 0.00

2018-11-02 19:55:18,012 - --- validate (epoch=21)-----------
2018-11-02 19:55:18,013 - 10000 samples (128 per mini-batch)
2018-11-02 19:55:18,734 - Epoch: [21][   50/   78]    Loss 0.538879    Top1 82.671875    Top5 99.031250    
2018-11-02 19:55:19,125 - ==> Top1: 82.470    Top5: 99.150    Loss: 0.541

2018-11-02 19:55:19,126 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 19:55:19,126 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:55:19,135 - 

2018-11-02 19:55:19,135 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:55:20,338 - Epoch: [22][   50/  391]    Overall Loss 0.431970    Objective Loss 0.431970    Top1 84.859375    Top5 99.515625    LR 0.300000    Time 0.024022    
2018-11-02 19:55:21,482 - Epoch: [22][  100/  391]    Overall Loss 0.426939    Objective Loss 0.426939    Top1 85.289062    Top5 99.437500    LR 0.300000    Time 0.023440    
2018-11-02 19:55:22,626 - Epoch: [22][  150/  391]    Overall Loss 0.435777    Objective Loss 0.435777    Top1 84.947917    Top5 99.442708    LR 0.300000    Time 0.023244    
2018-11-02 19:55:23,771 - Epoch: [22][  200/  391]    Overall Loss 0.438827    Objective Loss 0.438827    Top1 84.828125    Top5 99.425781    LR 0.300000    Time 0.023148    
2018-11-02 19:55:24,914 - Epoch: [22][  250/  391]    Overall Loss 0.436408    Objective Loss 0.436408    Top1 84.956250    Top5 99.393750    LR 0.300000    Time 0.023075    
2018-11-02 19:55:26,060 - Epoch: [22][  300/  391]    Overall Loss 0.436915    Objective Loss 0.436915    Top1 85.026042    Top5 99.406250    LR 0.300000    Time 0.023042    
2018-11-02 19:55:27,206 - Epoch: [22][  350/  391]    Overall Loss 0.435117    Objective Loss 0.435117    Top1 85.044643    Top5 99.430804    LR 0.300000    Time 0.023021    
2018-11-02 19:55:28,224 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55931 | -0.00163 |    0.36545 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15193 |  0.00148 |    0.09282 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15298 | -0.00438 |    0.10528 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19470 | -0.01341 |    0.13839 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19333 | -0.00593 |    0.14213 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18637 | -0.02705 |    0.13465 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16435 |  0.00240 |    0.11810 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20318 | -0.00653 |    0.14961 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17176 | -0.00364 |    0.13141 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40091 | -0.01273 |    0.28733 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 | -0.01138 |    0.11824 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13538 | -0.00933 |    0.10614 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14787 | -0.02446 |    0.11764 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12058 | -0.00136 |    0.09446 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14888 | -0.01484 |    0.11843 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13218 | -0.01193 |    0.10413 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21486 | -0.02405 |    0.16893 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12864 | -0.01302 |    0.10091 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09585 | -0.00016 |    0.07237 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05447 | -0.00113 |    0.04058 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04486 | -0.00821 |    0.03304 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60354 | -0.00029 |    0.47180 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:55:28,224 - Total sparsity: 0.00

2018-11-02 19:55:28,224 - --- validate (epoch=22)-----------
2018-11-02 19:55:28,224 - 10000 samples (128 per mini-batch)
2018-11-02 19:55:28,957 - Epoch: [22][   50/   78]    Loss 0.580114    Top1 81.484375    Top5 99.109375    
2018-11-02 19:55:29,351 - ==> Top1: 81.150    Top5: 99.200    Loss: 0.578

2018-11-02 19:55:29,352 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 19:55:29,352 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:55:29,360 - 

2018-11-02 19:55:29,360 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:55:30,562 - Epoch: [23][   50/  391]    Overall Loss 0.421167    Objective Loss 0.421167    Top1 85.484375    Top5 99.453125    LR 0.300000    Time 0.024000    
2018-11-02 19:55:31,710 - Epoch: [23][  100/  391]    Overall Loss 0.425054    Objective Loss 0.425054    Top1 85.359375    Top5 99.359375    LR 0.300000    Time 0.023463    
2018-11-02 19:55:32,854 - Epoch: [23][  150/  391]    Overall Loss 0.426006    Objective Loss 0.426006    Top1 85.255208    Top5 99.395833    LR 0.300000    Time 0.023258    
2018-11-02 19:55:33,998 - Epoch: [23][  200/  391]    Overall Loss 0.428340    Objective Loss 0.428340    Top1 85.250000    Top5 99.351562    LR 0.300000    Time 0.023158    
2018-11-02 19:55:35,145 - Epoch: [23][  250/  391]    Overall Loss 0.429339    Objective Loss 0.429339    Top1 85.218750    Top5 99.353125    LR 0.300000    Time 0.023108    
2018-11-02 19:55:36,291 - Epoch: [23][  300/  391]    Overall Loss 0.425796    Objective Loss 0.425796    Top1 85.341146    Top5 99.367188    LR 0.300000    Time 0.023074    
2018-11-02 19:55:37,440 - Epoch: [23][  350/  391]    Overall Loss 0.427985    Objective Loss 0.427985    Top1 85.272321    Top5 99.354911    LR 0.300000    Time 0.023055    
2018-11-02 19:55:38,455 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56331 | -0.00619 |    0.37125 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15253 |  0.00098 |    0.09314 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15285 | -0.00640 |    0.10529 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19465 | -0.01107 |    0.13852 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19218 | -0.01044 |    0.14144 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18634 | -0.02971 |    0.13458 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16573 |  0.00245 |    0.11888 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20379 | -0.00878 |    0.14929 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17207 | -0.00347 |    0.13122 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40086 | -0.01714 |    0.28688 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15466 | -0.01162 |    0.11816 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13578 | -0.00972 |    0.10664 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14931 | -0.02425 |    0.11907 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12116 | -0.00075 |    0.09539 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14902 | -0.01488 |    0.11810 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13235 | -0.01206 |    0.10414 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21460 | -0.02368 |    0.16800 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12909 | -0.01330 |    0.10127 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09596 | -0.00033 |    0.07245 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05503 | -0.00124 |    0.04108 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04516 | -0.00811 |    0.03326 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60041 | -0.00025 |    0.47228 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:55:38,455 - Total sparsity: 0.00

2018-11-02 19:55:38,455 - --- validate (epoch=23)-----------
2018-11-02 19:55:38,455 - 10000 samples (128 per mini-batch)
2018-11-02 19:55:39,179 - Epoch: [23][   50/   78]    Loss 0.629701    Top1 80.968750    Top5 98.187500    
2018-11-02 19:55:39,573 - ==> Top1: 80.420    Top5: 98.330    Loss: 0.628

2018-11-02 19:55:39,574 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 19:55:39,574 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:55:39,582 - 

2018-11-02 19:55:39,582 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:55:40,794 - Epoch: [24][   50/  391]    Overall Loss 0.440332    Objective Loss 0.440332    Top1 84.796875    Top5 99.421875    LR 0.300000    Time 0.024199    
2018-11-02 19:55:41,936 - Epoch: [24][  100/  391]    Overall Loss 0.430900    Objective Loss 0.430900    Top1 85.187500    Top5 99.429688    LR 0.300000    Time 0.023509    
2018-11-02 19:55:43,082 - Epoch: [24][  150/  391]    Overall Loss 0.427604    Objective Loss 0.427604    Top1 85.312500    Top5 99.427083    LR 0.300000    Time 0.023304    
2018-11-02 19:55:44,229 - Epoch: [24][  200/  391]    Overall Loss 0.422351    Objective Loss 0.422351    Top1 85.562500    Top5 99.402344    LR 0.300000    Time 0.023204    
2018-11-02 19:55:45,374 - Epoch: [24][  250/  391]    Overall Loss 0.425870    Objective Loss 0.425870    Top1 85.506250    Top5 99.412500    LR 0.300000    Time 0.023140    
2018-11-02 19:55:46,519 - Epoch: [24][  300/  391]    Overall Loss 0.427738    Objective Loss 0.427738    Top1 85.375000    Top5 99.403646    LR 0.300000    Time 0.023094    
2018-11-02 19:55:47,663 - Epoch: [24][  350/  391]    Overall Loss 0.426338    Objective Loss 0.426338    Top1 85.404018    Top5 99.397321    LR 0.300000    Time 0.023060    
2018-11-02 19:55:48,683 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56382 |  0.00770 |    0.36859 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15389 | -0.00019 |    0.09332 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15361 | -0.00941 |    0.10601 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19384 | -0.00951 |    0.13698 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19088 | -0.01362 |    0.14025 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18972 | -0.02612 |    0.13699 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16627 |  0.00270 |    0.12032 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20425 | -0.00600 |    0.15008 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17251 | -0.00432 |    0.13138 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40070 | -0.02117 |    0.28989 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15490 | -0.01204 |    0.11851 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13635 | -0.00940 |    0.10729 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14976 | -0.02400 |    0.11934 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12153 | -0.00262 |    0.09548 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14977 | -0.01488 |    0.11875 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13321 | -0.01226 |    0.10490 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21427 | -0.02636 |    0.16802 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13004 | -0.01319 |    0.10216 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09656 | -0.00002 |    0.07290 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05565 | -0.00100 |    0.04155 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04570 | -0.00834 |    0.03372 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60339 | -0.00023 |    0.47411 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:55:48,683 - Total sparsity: 0.00

2018-11-02 19:55:48,683 - --- validate (epoch=24)-----------
2018-11-02 19:55:48,684 - 10000 samples (128 per mini-batch)
2018-11-02 19:55:49,415 - Epoch: [24][   50/   78]    Loss 0.581916    Top1 81.265625    Top5 98.671875    
2018-11-02 19:55:49,809 - ==> Top1: 81.050    Top5: 98.860    Loss: 0.575

2018-11-02 19:55:49,810 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 19:55:49,810 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:55:49,818 - 

2018-11-02 19:55:49,819 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:55:51,020 - Epoch: [25][   50/  391]    Overall Loss 0.398186    Objective Loss 0.398186    Top1 86.500000    Top5 99.437500    LR 0.300000    Time 0.023978    
2018-11-02 19:55:52,166 - Epoch: [25][  100/  391]    Overall Loss 0.411513    Objective Loss 0.411513    Top1 86.015625    Top5 99.437500    LR 0.300000    Time 0.023434    
2018-11-02 19:55:53,308 - Epoch: [25][  150/  391]    Overall Loss 0.424587    Objective Loss 0.424587    Top1 85.463542    Top5 99.432292    LR 0.300000    Time 0.023231    
2018-11-02 19:55:54,455 - Epoch: [25][  200/  391]    Overall Loss 0.422686    Objective Loss 0.422686    Top1 85.500000    Top5 99.449219    LR 0.300000    Time 0.023147    
2018-11-02 19:55:55,602 - Epoch: [25][  250/  391]    Overall Loss 0.422980    Objective Loss 0.422980    Top1 85.393750    Top5 99.453125    LR 0.300000    Time 0.023103    
2018-11-02 19:55:56,748 - Epoch: [25][  300/  391]    Overall Loss 0.424185    Objective Loss 0.424185    Top1 85.328125    Top5 99.476562    LR 0.300000    Time 0.023066    
2018-11-02 19:55:57,894 - Epoch: [25][  350/  391]    Overall Loss 0.425829    Objective Loss 0.425829    Top1 85.292411    Top5 99.468750    LR 0.300000    Time 0.023033    
2018-11-02 19:55:58,923 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56415 | -0.00388 |    0.36911 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15422 |  0.00305 |    0.09458 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15460 | -0.00816 |    0.10570 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19308 | -0.01384 |    0.13711 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19132 | -0.01003 |    0.14029 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19025 | -0.02792 |    0.13733 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16661 |  0.00637 |    0.12014 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20484 | -0.00566 |    0.14992 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17324 | -0.00478 |    0.13239 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39848 | -0.02127 |    0.28655 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15486 | -0.01146 |    0.11870 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13642 | -0.00937 |    0.10711 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14995 | -0.02438 |    0.11934 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12166 | -0.00158 |    0.09522 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15012 | -0.01503 |    0.11927 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13388 | -0.01241 |    0.10552 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21342 | -0.02524 |    0.16806 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13051 | -0.01331 |    0.10254 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09684 |  0.00036 |    0.07302 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05624 | -0.00153 |    0.04201 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04620 | -0.00782 |    0.03403 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60467 | -0.00020 |    0.47156 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:55:58,923 - Total sparsity: 0.00

2018-11-02 19:55:58,923 - --- validate (epoch=25)-----------
2018-11-02 19:55:58,923 - 10000 samples (128 per mini-batch)
2018-11-02 19:55:59,650 - Epoch: [25][   50/   78]    Loss 0.643285    Top1 79.984375    Top5 98.531250    
2018-11-02 19:56:00,047 - ==> Top1: 79.740    Top5: 98.630    Loss: 0.646

2018-11-02 19:56:00,047 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 19:56:00,048 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:56:00,059 - 

2018-11-02 19:56:00,060 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:56:01,267 - Epoch: [26][   50/  391]    Overall Loss 0.417416    Objective Loss 0.417416    Top1 85.578125    Top5 99.500000    LR 0.300000    Time 0.024108    
2018-11-02 19:56:02,418 - Epoch: [26][  100/  391]    Overall Loss 0.417940    Objective Loss 0.417940    Top1 85.703125    Top5 99.554688    LR 0.300000    Time 0.023548    
2018-11-02 19:56:03,568 - Epoch: [26][  150/  391]    Overall Loss 0.422377    Objective Loss 0.422377    Top1 85.458333    Top5 99.489583    LR 0.300000    Time 0.023356    
2018-11-02 19:56:04,719 - Epoch: [26][  200/  391]    Overall Loss 0.416953    Objective Loss 0.416953    Top1 85.652344    Top5 99.468750    LR 0.300000    Time 0.023267    
2018-11-02 19:56:05,872 - Epoch: [26][  250/  391]    Overall Loss 0.421263    Objective Loss 0.421263    Top1 85.484375    Top5 99.443750    LR 0.300000    Time 0.023219    
2018-11-02 19:56:07,025 - Epoch: [26][  300/  391]    Overall Loss 0.421681    Objective Loss 0.421681    Top1 85.505208    Top5 99.445312    LR 0.300000    Time 0.023188    
2018-11-02 19:56:08,178 - Epoch: [26][  350/  391]    Overall Loss 0.423767    Objective Loss 0.423767    Top1 85.437500    Top5 99.424107    LR 0.300000    Time 0.023167    
2018-11-02 19:56:09,206 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56443 | -0.01236 |    0.36893 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15407 |  0.00360 |    0.09396 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15561 | -0.00711 |    0.10610 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19233 | -0.01452 |    0.13666 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19109 | -0.01156 |    0.13982 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19049 | -0.02948 |    0.13886 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16756 |  0.00284 |    0.12074 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20597 | -0.00562 |    0.15008 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17441 | -0.00668 |    0.13364 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40020 | -0.02187 |    0.28941 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15475 | -0.01132 |    0.11846 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13643 | -0.01002 |    0.10732 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15129 | -0.02395 |    0.12015 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12222 | -0.00141 |    0.09585 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15090 | -0.01494 |    0.11964 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13456 | -0.01205 |    0.10620 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21358 | -0.02265 |    0.16770 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13123 | -0.01277 |    0.10301 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09704 |  0.00043 |    0.07314 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05684 | -0.00116 |    0.04245 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04653 | -0.00781 |    0.03420 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60335 | -0.00018 |    0.47215 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:56:09,206 - Total sparsity: 0.00

2018-11-02 19:56:09,206 - --- validate (epoch=26)-----------
2018-11-02 19:56:09,206 - 10000 samples (128 per mini-batch)
2018-11-02 19:56:09,932 - Epoch: [26][   50/   78]    Loss 0.667699    Top1 78.296875    Top5 98.421875    
2018-11-02 19:56:10,325 - ==> Top1: 77.740    Top5: 98.400    Loss: 0.690

2018-11-02 19:56:10,326 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 19:56:10,326 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:56:10,334 - 

2018-11-02 19:56:10,335 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:56:11,541 - Epoch: [27][   50/  391]    Overall Loss 0.425505    Objective Loss 0.425505    Top1 85.609375    Top5 99.437500    LR 0.300000    Time 0.024093    
2018-11-02 19:56:12,695 - Epoch: [27][  100/  391]    Overall Loss 0.423597    Objective Loss 0.423597    Top1 85.609375    Top5 99.453125    LR 0.300000    Time 0.023575    
2018-11-02 19:56:13,848 - Epoch: [27][  150/  391]    Overall Loss 0.416781    Objective Loss 0.416781    Top1 85.828125    Top5 99.479167    LR 0.300000    Time 0.023393    
2018-11-02 19:56:14,999 - Epoch: [27][  200/  391]    Overall Loss 0.415437    Objective Loss 0.415437    Top1 85.722656    Top5 99.468750    LR 0.300000    Time 0.023293    
2018-11-02 19:56:16,150 - Epoch: [27][  250/  391]    Overall Loss 0.417865    Objective Loss 0.417865    Top1 85.590625    Top5 99.446875    LR 0.300000    Time 0.023235    
2018-11-02 19:56:17,301 - Epoch: [27][  300/  391]    Overall Loss 0.413472    Objective Loss 0.413472    Top1 85.765625    Top5 99.445312    LR 0.300000    Time 0.023195    
2018-11-02 19:56:18,454 - Epoch: [27][  350/  391]    Overall Loss 0.415889    Objective Loss 0.415889    Top1 85.680804    Top5 99.428571    LR 0.300000    Time 0.023172    
2018-11-02 19:56:19,477 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56756 | -0.01378 |    0.36896 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15403 |  0.00238 |    0.09327 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15596 | -0.00637 |    0.10596 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19256 | -0.01275 |    0.13708 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19143 | -0.01183 |    0.13931 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19081 | -0.03152 |    0.13948 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16832 |  0.00377 |    0.12115 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20688 | -0.00751 |    0.15132 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17535 | -0.00563 |    0.13418 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40102 | -0.01897 |    0.29237 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15496 | -0.01057 |    0.11877 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13627 | -0.01023 |    0.10757 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15175 | -0.02513 |    0.12025 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12306 | -0.00073 |    0.09639 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15139 | -0.01419 |    0.12022 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13522 | -0.01116 |    0.10675 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21448 | -0.02257 |    0.16904 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13193 | -0.01317 |    0.10372 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09723 |  0.00011 |    0.07338 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05733 | -0.00201 |    0.04292 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04692 | -0.00738 |    0.03438 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60330 | -0.00016 |    0.47040 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:56:19,477 - Total sparsity: 0.00

2018-11-02 19:56:19,477 - --- validate (epoch=27)-----------
2018-11-02 19:56:19,477 - 10000 samples (128 per mini-batch)
2018-11-02 19:56:20,199 - Epoch: [27][   50/   78]    Loss 0.628523    Top1 79.921875    Top5 98.718750    
2018-11-02 19:56:20,592 - ==> Top1: 79.560    Top5: 98.830    Loss: 0.628

2018-11-02 19:56:20,592 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 19:56:20,593 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:56:20,601 - 

2018-11-02 19:56:20,601 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:56:21,808 - Epoch: [28][   50/  391]    Overall Loss 0.407176    Objective Loss 0.407176    Top1 85.515625    Top5 99.625000    LR 0.300000    Time 0.024119    
2018-11-02 19:56:22,961 - Epoch: [28][  100/  391]    Overall Loss 0.421477    Objective Loss 0.421477    Top1 85.375000    Top5 99.492188    LR 0.300000    Time 0.023573    
2018-11-02 19:56:24,115 - Epoch: [28][  150/  391]    Overall Loss 0.415005    Objective Loss 0.415005    Top1 85.677083    Top5 99.520833    LR 0.300000    Time 0.023397    
2018-11-02 19:56:25,268 - Epoch: [28][  200/  391]    Overall Loss 0.408802    Objective Loss 0.408802    Top1 85.914062    Top5 99.500000    LR 0.300000    Time 0.023308    
2018-11-02 19:56:26,421 - Epoch: [28][  250/  391]    Overall Loss 0.416891    Objective Loss 0.416891    Top1 85.693750    Top5 99.471875    LR 0.300000    Time 0.023254    
2018-11-02 19:56:27,573 - Epoch: [28][  300/  391]    Overall Loss 0.415789    Objective Loss 0.415789    Top1 85.747396    Top5 99.466146    LR 0.300000    Time 0.023213    
2018-11-02 19:56:28,726 - Epoch: [28][  350/  391]    Overall Loss 0.414076    Objective Loss 0.414076    Top1 85.814732    Top5 99.462054    LR 0.300000    Time 0.023187    
2018-11-02 19:56:29,751 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56534 |  0.00175 |    0.36423 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15336 | -0.00013 |    0.09260 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15473 | -0.00373 |    0.10536 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19110 | -0.01358 |    0.13533 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19134 | -0.01279 |    0.14054 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19145 | -0.02944 |    0.14004 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16814 |  0.00259 |    0.12023 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20778 | -0.00798 |    0.15183 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17584 | -0.00533 |    0.13467 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39968 | -0.02168 |    0.28785 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15456 | -0.01129 |    0.11844 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13616 | -0.00848 |    0.10708 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15215 | -0.02486 |    0.12057 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12318 | -0.00092 |    0.09633 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15141 | -0.01426 |    0.12004 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13530 | -0.01229 |    0.10681 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21424 | -0.02241 |    0.16739 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13237 | -0.01299 |    0.10401 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09738 | -0.00015 |    0.07349 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05790 | -0.00159 |    0.04335 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04728 | -0.00748 |    0.03475 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60446 | -0.00014 |    0.47241 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:56:29,751 - Total sparsity: 0.00

2018-11-02 19:56:29,752 - --- validate (epoch=28)-----------
2018-11-02 19:56:29,752 - 10000 samples (128 per mini-batch)
2018-11-02 19:56:30,503 - Epoch: [28][   50/   78]    Loss 0.640717    Top1 78.468750    Top5 98.781250    
2018-11-02 19:56:30,896 - ==> Top1: 78.290    Top5: 98.820    Loss: 0.644

2018-11-02 19:56:30,897 - ==> Best Top1: 82.470   On Epoch: 21

2018-11-02 19:56:30,897 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:56:30,905 - 

2018-11-02 19:56:30,905 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:56:32,117 - Epoch: [29][   50/  391]    Overall Loss 0.420074    Objective Loss 0.420074    Top1 85.515625    Top5 99.468750    LR 0.300000    Time 0.024198    
2018-11-02 19:56:33,273 - Epoch: [29][  100/  391]    Overall Loss 0.407547    Objective Loss 0.407547    Top1 85.859375    Top5 99.500000    LR 0.300000    Time 0.023650    
2018-11-02 19:56:34,425 - Epoch: [29][  150/  391]    Overall Loss 0.399170    Objective Loss 0.399170    Top1 86.218750    Top5 99.494792    LR 0.300000    Time 0.023433    
2018-11-02 19:56:35,576 - Epoch: [29][  200/  391]    Overall Loss 0.401598    Objective Loss 0.401598    Top1 86.121094    Top5 99.476562    LR 0.300000    Time 0.023326    
2018-11-02 19:56:36,729 - Epoch: [29][  250/  391]    Overall Loss 0.405417    Objective Loss 0.405417    Top1 86.034375    Top5 99.462500    LR 0.300000    Time 0.023266    
2018-11-02 19:56:37,882 - Epoch: [29][  300/  391]    Overall Loss 0.407054    Objective Loss 0.407054    Top1 85.976562    Top5 99.450521    LR 0.300000    Time 0.023216    
2018-11-02 19:56:39,034 - Epoch: [29][  350/  391]    Overall Loss 0.405368    Objective Loss 0.405368    Top1 85.955357    Top5 99.448661    LR 0.300000    Time 0.023185    
2018-11-02 19:56:40,062 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56299 | -0.00071 |    0.36565 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15466 |  0.00166 |    0.09423 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15454 | -0.00434 |    0.10587 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19180 | -0.01127 |    0.13597 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19111 | -0.01462 |    0.13930 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19227 | -0.02855 |    0.14010 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16867 |  0.00059 |    0.12142 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20857 | -0.00745 |    0.15291 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17627 | -0.00492 |    0.13544 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39798 | -0.02295 |    0.28737 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15473 | -0.01267 |    0.11860 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.00892 |    0.10703 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15212 | -0.02466 |    0.12038 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12285 | -0.00083 |    0.09638 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15138 | -0.01546 |    0.12051 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13555 | -0.01190 |    0.10688 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21331 | -0.02363 |    0.16755 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13255 | -0.01365 |    0.10429 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09732 | -0.00021 |    0.07345 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05816 | -0.00166 |    0.04355 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04740 | -0.00739 |    0.03482 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60213 | -0.00013 |    0.47056 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:56:40,062 - Total sparsity: 0.00

2018-11-02 19:56:40,062 - --- validate (epoch=29)-----------
2018-11-02 19:56:40,062 - 10000 samples (128 per mini-batch)
2018-11-02 19:56:40,792 - Epoch: [29][   50/   78]    Loss 0.514717    Top1 83.062500    Top5 99.015625    
2018-11-02 19:56:41,189 - ==> Top1: 82.480    Top5: 99.120    Loss: 0.525

2018-11-02 19:56:41,190 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 19:56:41,190 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:56:41,205 - 

2018-11-02 19:56:41,205 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:56:42,413 - Epoch: [30][   50/  391]    Overall Loss 0.381935    Objective Loss 0.381935    Top1 87.187500    Top5 99.484375    LR 0.300000    Time 0.024122    
2018-11-02 19:56:43,568 - Epoch: [30][  100/  391]    Overall Loss 0.392877    Objective Loss 0.392877    Top1 86.460938    Top5 99.460938    LR 0.300000    Time 0.023590    
2018-11-02 19:56:44,721 - Epoch: [30][  150/  391]    Overall Loss 0.397810    Objective Loss 0.397810    Top1 86.291667    Top5 99.505208    LR 0.300000    Time 0.023411    
2018-11-02 19:56:45,874 - Epoch: [30][  200/  391]    Overall Loss 0.400091    Objective Loss 0.400091    Top1 86.234375    Top5 99.527344    LR 0.300000    Time 0.023313    
2018-11-02 19:56:47,025 - Epoch: [30][  250/  391]    Overall Loss 0.403560    Objective Loss 0.403560    Top1 86.131250    Top5 99.493750    LR 0.300000    Time 0.023249    
2018-11-02 19:56:48,195 - Epoch: [30][  300/  391]    Overall Loss 0.403603    Objective Loss 0.403603    Top1 86.200521    Top5 99.473958    LR 0.300000    Time 0.023272    
2018-11-02 19:56:49,334 - Epoch: [30][  350/  391]    Overall Loss 0.406001    Objective Loss 0.406001    Top1 86.102679    Top5 99.466518    LR 0.300000    Time 0.023198    
2018-11-02 19:56:50,350 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56802 |  0.00096 |    0.36972 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15502 |  0.00082 |    0.09419 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15507 | -0.00204 |    0.10514 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19290 | -0.01663 |    0.13648 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19087 | -0.01211 |    0.13968 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19325 | -0.02811 |    0.14141 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16957 |  0.00180 |    0.12124 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20824 | -0.00736 |    0.15282 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17581 | -0.00609 |    0.13547 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39804 | -0.02685 |    0.28754 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15421 | -0.01126 |    0.11805 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13555 | -0.00803 |    0.10655 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15151 | -0.02543 |    0.12036 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12246 | -0.00040 |    0.09606 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15146 | -0.01562 |    0.12065 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13565 | -0.01184 |    0.10691 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21236 | -0.02408 |    0.16562 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13287 | -0.01336 |    0.10446 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09757 | -0.00066 |    0.07364 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05913 | -0.00205 |    0.04429 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04797 | -0.00727 |    0.03526 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60599 | -0.00011 |    0.47192 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:56:50,350 - Total sparsity: 0.00

2018-11-02 19:56:50,350 - --- validate (epoch=30)-----------
2018-11-02 19:56:50,350 - 10000 samples (128 per mini-batch)
2018-11-02 19:56:51,074 - Epoch: [30][   50/   78]    Loss 0.962153    Top1 73.031250    Top5 98.296875    
2018-11-02 19:56:51,466 - ==> Top1: 72.530    Top5: 98.200    Loss: 0.975

2018-11-02 19:56:51,467 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 19:56:51,468 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:56:51,476 - 

2018-11-02 19:56:51,476 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:56:52,672 - Epoch: [31][   50/  391]    Overall Loss 0.402150    Objective Loss 0.402150    Top1 85.593750    Top5 99.562500    LR 0.300000    Time 0.023886    
2018-11-02 19:56:53,808 - Epoch: [31][  100/  391]    Overall Loss 0.416433    Objective Loss 0.416433    Top1 85.429688    Top5 99.500000    LR 0.300000    Time 0.023291    
2018-11-02 19:56:54,945 - Epoch: [31][  150/  391]    Overall Loss 0.412316    Objective Loss 0.412316    Top1 85.536458    Top5 99.520833    LR 0.300000    Time 0.023096    
2018-11-02 19:56:56,083 - Epoch: [31][  200/  391]    Overall Loss 0.407614    Objective Loss 0.407614    Top1 85.847656    Top5 99.507812    LR 0.300000    Time 0.023003    
2018-11-02 19:56:57,294 - Epoch: [31][  250/  391]    Overall Loss 0.409778    Objective Loss 0.409778    Top1 85.734375    Top5 99.487500    LR 0.300000    Time 0.023245    
2018-11-02 19:56:58,544 - Epoch: [31][  300/  391]    Overall Loss 0.410372    Objective Loss 0.410372    Top1 85.760417    Top5 99.486979    LR 0.300000    Time 0.023532    
2018-11-02 19:56:59,804 - Epoch: [31][  350/  391]    Overall Loss 0.405058    Objective Loss 0.405058    Top1 85.984375    Top5 99.495536    LR 0.300000    Time 0.023767    
2018-11-02 19:57:00,909 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56883 | -0.00199 |    0.37146 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15442 |  0.00229 |    0.09356 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15591 | -0.00404 |    0.10635 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19401 | -0.01632 |    0.13700 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19136 | -0.01423 |    0.14094 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19421 | -0.02947 |    0.14194 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17046 |  0.00044 |    0.12188 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20782 | -0.00743 |    0.15244 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17592 | -0.00522 |    0.13529 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39851 | -0.02515 |    0.28525 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15420 | -0.01130 |    0.11824 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13573 | -0.01037 |    0.10660 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15229 | -0.02556 |    0.12095 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12275 | -0.00027 |    0.09601 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15184 | -0.01457 |    0.12064 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13611 | -0.01165 |    0.10732 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21259 | -0.02472 |    0.16531 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13328 | -0.01376 |    0.10482 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09767 | -0.00077 |    0.07373 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05960 | -0.00212 |    0.04473 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04829 | -0.00760 |    0.03552 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60139 | -0.00010 |    0.46912 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:57:00,909 - Total sparsity: 0.00

2018-11-02 19:57:00,909 - --- validate (epoch=31)-----------
2018-11-02 19:57:00,909 - 10000 samples (128 per mini-batch)
2018-11-02 19:57:01,638 - Epoch: [31][   50/   78]    Loss 0.700790    Top1 78.406250    Top5 98.921875    
2018-11-02 19:57:02,035 - ==> Top1: 78.070    Top5: 99.090    Loss: 0.697

2018-11-02 19:57:02,036 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 19:57:02,036 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:57:02,045 - 

2018-11-02 19:57:02,045 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:57:03,348 - Epoch: [32][   50/  391]    Overall Loss 0.390838    Objective Loss 0.390838    Top1 86.765625    Top5 99.484375    LR 0.300000    Time 0.026027    
2018-11-02 19:57:04,598 - Epoch: [32][  100/  391]    Overall Loss 0.398318    Objective Loss 0.398318    Top1 86.328125    Top5 99.507812    LR 0.300000    Time 0.025501    
2018-11-02 19:57:05,848 - Epoch: [32][  150/  391]    Overall Loss 0.402769    Objective Loss 0.402769    Top1 86.125000    Top5 99.463542    LR 0.300000    Time 0.025329    
2018-11-02 19:57:07,135 - Epoch: [32][  200/  391]    Overall Loss 0.409901    Objective Loss 0.409901    Top1 85.906250    Top5 99.441406    LR 0.300000    Time 0.025424    
2018-11-02 19:57:08,341 - Epoch: [32][  250/  391]    Overall Loss 0.406954    Objective Loss 0.406954    Top1 86.115625    Top5 99.478125    LR 0.300000    Time 0.025145    
2018-11-02 19:57:09,492 - Epoch: [32][  300/  391]    Overall Loss 0.405631    Objective Loss 0.405631    Top1 86.138021    Top5 99.479167    LR 0.300000    Time 0.024786    
2018-11-02 19:57:10,632 - Epoch: [32][  350/  391]    Overall Loss 0.408432    Objective Loss 0.408432    Top1 86.013393    Top5 99.479911    LR 0.300000    Time 0.024497    
2018-11-02 19:57:11,644 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57035 |  0.00419 |    0.37368 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15313 |  0.00144 |    0.09339 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15507 | -0.00346 |    0.10643 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19361 | -0.01678 |    0.13659 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19109 | -0.01378 |    0.14062 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19336 | -0.03119 |    0.14225 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17029 |  0.00236 |    0.12176 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20856 | -0.00592 |    0.15278 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17672 | -0.00363 |    0.13598 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39740 | -0.02309 |    0.28226 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15383 | -0.00943 |    0.11765 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13518 | -0.01129 |    0.10603 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15302 | -0.02401 |    0.12102 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12330 | -0.00144 |    0.09635 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15200 | -0.01456 |    0.12077 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13650 | -0.01147 |    0.10761 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21242 | -0.02465 |    0.16591 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13368 | -0.01364 |    0.10513 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09797 | -0.00052 |    0.07393 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06010 | -0.00166 |    0.04506 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04874 | -0.00752 |    0.03589 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60341 | -0.00009 |    0.47012 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:57:11,644 - Total sparsity: 0.00

2018-11-02 19:57:11,644 - --- validate (epoch=32)-----------
2018-11-02 19:57:11,644 - 10000 samples (128 per mini-batch)
2018-11-02 19:57:12,365 - Epoch: [32][   50/   78]    Loss 0.598514    Top1 81.046875    Top5 98.703125    
2018-11-02 19:57:12,754 - ==> Top1: 80.870    Top5: 98.760    Loss: 0.598

2018-11-02 19:57:12,754 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 19:57:12,754 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:57:12,763 - 

2018-11-02 19:57:12,763 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:57:13,958 - Epoch: [33][   50/  391]    Overall Loss 0.366076    Objective Loss 0.366076    Top1 87.109375    Top5 99.609375    LR 0.300000    Time 0.023860    
2018-11-02 19:57:15,095 - Epoch: [33][  100/  391]    Overall Loss 0.380934    Objective Loss 0.380934    Top1 86.687500    Top5 99.546875    LR 0.300000    Time 0.023292    
2018-11-02 19:57:16,234 - Epoch: [33][  150/  391]    Overall Loss 0.390445    Objective Loss 0.390445    Top1 86.541667    Top5 99.526042    LR 0.300000    Time 0.023112    
2018-11-02 19:57:17,375 - Epoch: [33][  200/  391]    Overall Loss 0.392527    Objective Loss 0.392527    Top1 86.488281    Top5 99.500000    LR 0.300000    Time 0.023034    
2018-11-02 19:57:18,513 - Epoch: [33][  250/  391]    Overall Loss 0.389035    Objective Loss 0.389035    Top1 86.603125    Top5 99.518750    LR 0.300000    Time 0.022971    
2018-11-02 19:57:19,651 - Epoch: [33][  300/  391]    Overall Loss 0.394350    Objective Loss 0.394350    Top1 86.377604    Top5 99.494792    LR 0.300000    Time 0.022932    
2018-11-02 19:57:20,789 - Epoch: [33][  350/  391]    Overall Loss 0.393709    Objective Loss 0.393709    Top1 86.401786    Top5 99.491071    LR 0.300000    Time 0.022905    
2018-11-02 19:57:21,803 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57201 | -0.01466 |    0.37845 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15310 |  0.00253 |    0.09360 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15397 | -0.00588 |    0.10614 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19363 | -0.01765 |    0.13763 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19121 | -0.01466 |    0.14168 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19406 | -0.02881 |    0.14153 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17147 |  0.00122 |    0.12227 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20813 | -0.00531 |    0.15270 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17628 | -0.00631 |    0.13550 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39574 | -0.02289 |    0.28436 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15354 | -0.00917 |    0.11786 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13536 | -0.01036 |    0.10637 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15278 | -0.02470 |    0.12125 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12305 | -0.00091 |    0.09595 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15207 | -0.01470 |    0.12074 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13675 | -0.01135 |    0.10773 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21151 | -0.02332 |    0.16461 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13347 | -0.01408 |    0.10508 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09782 | -0.00050 |    0.07393 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06041 | -0.00257 |    0.04535 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04879 | -0.00690 |    0.03575 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60438 | -0.00008 |    0.47149 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:57:21,803 - Total sparsity: 0.00

2018-11-02 19:57:21,804 - --- validate (epoch=33)-----------
2018-11-02 19:57:21,804 - 10000 samples (128 per mini-batch)
2018-11-02 19:57:22,523 - Epoch: [33][   50/   78]    Loss 0.703675    Top1 79.359375    Top5 98.812500    
2018-11-02 19:57:22,913 - ==> Top1: 78.780    Top5: 98.950    Loss: 0.717

2018-11-02 19:57:22,914 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 19:57:22,914 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:57:22,925 - 

2018-11-02 19:57:22,926 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:57:24,122 - Epoch: [34][   50/  391]    Overall Loss 0.382364    Objective Loss 0.382364    Top1 86.765625    Top5 99.625000    LR 0.300000    Time 0.023896    
2018-11-02 19:57:24,458 - Epoch: [34][  100/  391]    Overall Loss 0.392413    Objective Loss 0.392413    Top1 86.492188    Top5 99.421875    LR 0.300000    Time 0.015295    
2018-11-02 19:57:25,597 - Epoch: [34][  150/  391]    Overall Loss 0.393584    Objective Loss 0.393584    Top1 86.520833    Top5 99.380208    LR 0.300000    Time 0.017778    
2018-11-02 19:57:26,734 - Epoch: [34][  200/  391]    Overall Loss 0.392822    Objective Loss 0.392822    Top1 86.562500    Top5 99.421875    LR 0.300000    Time 0.019015    
2018-11-02 19:57:27,874 - Epoch: [34][  250/  391]    Overall Loss 0.394373    Objective Loss 0.394373    Top1 86.446875    Top5 99.421875    LR 0.300000    Time 0.019768    
2018-11-02 19:57:29,014 - Epoch: [34][  300/  391]    Overall Loss 0.395311    Objective Loss 0.395311    Top1 86.421875    Top5 99.421875    LR 0.300000    Time 0.020269    
2018-11-02 19:57:30,152 - Epoch: [34][  350/  391]    Overall Loss 0.394406    Objective Loss 0.394406    Top1 86.482143    Top5 99.419643    LR 0.300000    Time 0.020620    
2018-11-02 19:57:31,166 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57437 |  0.00190 |    0.37698 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15522 |  0.00137 |    0.09392 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15457 | -0.00124 |    0.10649 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19256 | -0.01482 |    0.13676 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19189 | -0.01424 |    0.14262 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19355 | -0.02655 |    0.14089 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17127 | -0.00031 |    0.12206 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20814 | -0.00504 |    0.15265 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17668 | -0.00450 |    0.13579 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39612 | -0.01742 |    0.28336 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15433 | -0.01113 |    0.11839 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13621 | -0.01051 |    0.10702 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15299 | -0.02269 |    0.12102 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12318 | -0.00128 |    0.09630 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15210 | -0.01504 |    0.12088 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13699 | -0.01127 |    0.10805 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21306 | -0.02368 |    0.16662 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13398 | -0.01376 |    0.10545 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09812 | -0.00095 |    0.07421 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06110 | -0.00198 |    0.04575 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04923 | -0.00666 |    0.03616 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60354 | -0.00007 |    0.47076 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:57:31,166 - Total sparsity: 0.00

2018-11-02 19:57:31,166 - --- validate (epoch=34)-----------
2018-11-02 19:57:31,166 - 10000 samples (128 per mini-batch)
2018-11-02 19:57:31,893 - Epoch: [34][   50/   78]    Loss 0.765296    Top1 77.546875    Top5 98.937500    
2018-11-02 19:57:32,286 - ==> Top1: 77.460    Top5: 99.030    Loss: 0.775

2018-11-02 19:57:32,287 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 19:57:32,287 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:57:32,295 - 

2018-11-02 19:57:32,296 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:57:33,490 - Epoch: [35][   50/  391]    Overall Loss 0.371675    Objective Loss 0.371675    Top1 86.921875    Top5 99.656250    LR 0.300000    Time 0.023861    
2018-11-02 19:57:34,629 - Epoch: [35][  100/  391]    Overall Loss 0.376777    Objective Loss 0.376777    Top1 86.812500    Top5 99.601562    LR 0.300000    Time 0.023306    
2018-11-02 19:57:35,767 - Epoch: [35][  150/  391]    Overall Loss 0.379723    Objective Loss 0.379723    Top1 86.656250    Top5 99.609375    LR 0.300000    Time 0.023112    
2018-11-02 19:57:36,905 - Epoch: [35][  200/  391]    Overall Loss 0.387552    Objective Loss 0.387552    Top1 86.492188    Top5 99.570312    LR 0.300000    Time 0.023021    
2018-11-02 19:57:38,046 - Epoch: [35][  250/  391]    Overall Loss 0.389706    Objective Loss 0.389706    Top1 86.431250    Top5 99.553125    LR 0.300000    Time 0.022975    
2018-11-02 19:57:39,186 - Epoch: [35][  300/  391]    Overall Loss 0.392868    Objective Loss 0.392868    Top1 86.408854    Top5 99.531250    LR 0.300000    Time 0.022941    
2018-11-02 19:57:40,327 - Epoch: [35][  350/  391]    Overall Loss 0.396108    Objective Loss 0.396108    Top1 86.314732    Top5 99.508929    LR 0.300000    Time 0.022919    
2018-11-02 19:57:41,339 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57221 | -0.01228 |    0.37818 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15586 |  0.00120 |    0.09524 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15561 | -0.00139 |    0.10756 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19364 | -0.01632 |    0.13831 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19143 | -0.01260 |    0.14146 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19368 | -0.02816 |    0.14175 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17117 |  0.00001 |    0.12170 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20815 | -0.00575 |    0.15275 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17705 | -0.00475 |    0.13596 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39603 | -0.01758 |    0.28404 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15386 | -0.01129 |    0.11806 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13581 | -0.01025 |    0.10619 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15226 | -0.02330 |    0.12019 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12301 | -0.00023 |    0.09599 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15228 | -0.01490 |    0.12081 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13731 | -0.01187 |    0.10833 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21422 | -0.02378 |    0.16770 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13456 | -0.01313 |    0.10598 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09848 | -0.00091 |    0.07431 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06160 | -0.00293 |    0.04635 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04950 | -0.00710 |    0.03643 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59911 | -0.00006 |    0.46704 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:57:41,340 - Total sparsity: 0.00

2018-11-02 19:57:41,340 - --- validate (epoch=35)-----------
2018-11-02 19:57:41,340 - 10000 samples (128 per mini-batch)
2018-11-02 19:57:42,060 - Epoch: [35][   50/   78]    Loss 0.584947    Top1 80.468750    Top5 99.125000    
2018-11-02 19:57:42,448 - ==> Top1: 80.750    Top5: 99.180    Loss: 0.582

2018-11-02 19:57:42,449 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 19:57:42,449 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:57:42,457 - 

2018-11-02 19:57:42,458 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:57:43,652 - Epoch: [36][   50/  391]    Overall Loss 0.381908    Objective Loss 0.381908    Top1 86.968750    Top5 99.578125    LR 0.300000    Time 0.023863    
2018-11-02 19:57:44,792 - Epoch: [36][  100/  391]    Overall Loss 0.383460    Objective Loss 0.383460    Top1 87.070312    Top5 99.507812    LR 0.300000    Time 0.023316    
2018-11-02 19:57:45,931 - Epoch: [36][  150/  391]    Overall Loss 0.382355    Objective Loss 0.382355    Top1 87.109375    Top5 99.505208    LR 0.300000    Time 0.023128    
2018-11-02 19:57:47,070 - Epoch: [36][  200/  391]    Overall Loss 0.385280    Objective Loss 0.385280    Top1 86.914062    Top5 99.519531    LR 0.300000    Time 0.023035    
2018-11-02 19:57:48,208 - Epoch: [36][  250/  391]    Overall Loss 0.388177    Objective Loss 0.388177    Top1 86.871875    Top5 99.471875    LR 0.300000    Time 0.022975    
2018-11-02 19:57:49,347 - Epoch: [36][  300/  391]    Overall Loss 0.390870    Objective Loss 0.390870    Top1 86.661458    Top5 99.486979    LR 0.300000    Time 0.022938    
2018-11-02 19:57:50,485 - Epoch: [36][  350/  391]    Overall Loss 0.393173    Objective Loss 0.393173    Top1 86.540179    Top5 99.493304    LR 0.300000    Time 0.022911    
2018-11-02 19:57:51,497 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57051 | -0.00490 |    0.37519 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15476 |  0.00286 |    0.09442 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15459 | -0.00175 |    0.10571 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19316 | -0.01221 |    0.13701 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19046 | -0.01325 |    0.14130 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19311 | -0.02961 |    0.14095 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17138 | -0.00269 |    0.12192 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20820 | -0.00655 |    0.15228 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17713 | -0.00486 |    0.13670 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39493 | -0.01528 |    0.28281 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15333 | -0.01052 |    0.11787 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13540 | -0.00962 |    0.10625 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15208 | -0.02387 |    0.12002 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12309 | -0.00027 |    0.09642 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15178 | -0.01430 |    0.12035 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13686 | -0.01192 |    0.10804 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21319 | -0.02403 |    0.16671 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13447 | -0.01363 |    0.10579 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09873 | -0.00104 |    0.07470 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06224 | -0.00186 |    0.04677 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05003 | -0.00665 |    0.03653 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60330 | -0.00006 |    0.46832 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:57:51,497 - Total sparsity: 0.00

2018-11-02 19:57:51,497 - --- validate (epoch=36)-----------
2018-11-02 19:57:51,497 - 10000 samples (128 per mini-batch)
2018-11-02 19:57:52,214 - Epoch: [36][   50/   78]    Loss 0.638649    Top1 80.640625    Top5 98.703125    
2018-11-02 19:57:52,601 - ==> Top1: 80.520    Top5: 98.850    Loss: 0.643

2018-11-02 19:57:52,602 - ==> Best Top1: 82.480   On Epoch: 29

2018-11-02 19:57:52,602 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:57:52,614 - 

2018-11-02 19:57:52,614 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:57:53,807 - Epoch: [37][   50/  391]    Overall Loss 0.386654    Objective Loss 0.386654    Top1 86.718750    Top5 99.500000    LR 0.300000    Time 0.023825    
2018-11-02 19:57:54,945 - Epoch: [37][  100/  391]    Overall Loss 0.391948    Objective Loss 0.391948    Top1 86.281250    Top5 99.523438    LR 0.300000    Time 0.023281    
2018-11-02 19:57:56,082 - Epoch: [37][  150/  391]    Overall Loss 0.394762    Objective Loss 0.394762    Top1 86.307292    Top5 99.552083    LR 0.300000    Time 0.023088    
2018-11-02 19:57:57,219 - Epoch: [37][  200/  391]    Overall Loss 0.397692    Objective Loss 0.397692    Top1 86.179688    Top5 99.562500    LR 0.300000    Time 0.022999    
2018-11-02 19:57:58,357 - Epoch: [37][  250/  391]    Overall Loss 0.395309    Objective Loss 0.395309    Top1 86.275000    Top5 99.571875    LR 0.300000    Time 0.022945    
2018-11-02 19:57:59,495 - Epoch: [37][  300/  391]    Overall Loss 0.395639    Objective Loss 0.395639    Top1 86.286458    Top5 99.520833    LR 0.300000    Time 0.022910    
2018-11-02 19:58:00,636 - Epoch: [37][  350/  391]    Overall Loss 0.390825    Objective Loss 0.390825    Top1 86.397321    Top5 99.526786    LR 0.300000    Time 0.022893    
2018-11-02 19:58:01,646 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57129 | -0.01010 |    0.37393 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15529 |  0.00043 |    0.09540 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15473 | -0.00511 |    0.10536 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19367 | -0.01462 |    0.13760 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19126 | -0.01200 |    0.14196 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19564 | -0.03049 |    0.14210 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17308 |  0.00023 |    0.12420 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20884 | -0.00562 |    0.15229 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17742 | -0.00566 |    0.13639 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39546 | -0.01447 |    0.28083 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15359 | -0.00978 |    0.11802 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13574 | -0.00975 |    0.10672 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15247 | -0.02374 |    0.12005 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12326 |  0.00001 |    0.09647 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15192 | -0.01547 |    0.12072 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13693 | -0.01170 |    0.10805 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21184 | -0.02565 |    0.16489 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13439 | -0.01343 |    0.10562 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09851 | -0.00124 |    0.07446 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06249 | -0.00171 |    0.04707 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04998 | -0.00657 |    0.03669 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60392 | -0.00005 |    0.46970 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:58:01,646 - Total sparsity: 0.00

2018-11-02 19:58:01,647 - --- validate (epoch=37)-----------
2018-11-02 19:58:01,647 - 10000 samples (128 per mini-batch)
2018-11-02 19:58:02,373 - Epoch: [37][   50/   78]    Loss 0.497753    Top1 84.187500    Top5 99.171875    
2018-11-02 19:58:02,767 - ==> Top1: 84.260    Top5: 99.300    Loss: 0.500

2018-11-02 19:58:02,768 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:58:02,768 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:58:02,779 - 

2018-11-02 19:58:02,779 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:58:03,975 - Epoch: [38][   50/  391]    Overall Loss 0.397983    Objective Loss 0.397983    Top1 86.406250    Top5 99.562500    LR 0.300000    Time 0.023881    
2018-11-02 19:58:05,116 - Epoch: [38][  100/  391]    Overall Loss 0.388733    Objective Loss 0.388733    Top1 86.898438    Top5 99.578125    LR 0.300000    Time 0.023331    
2018-11-02 19:58:06,258 - Epoch: [38][  150/  391]    Overall Loss 0.389110    Objective Loss 0.389110    Top1 86.869792    Top5 99.567708    LR 0.300000    Time 0.023162    
2018-11-02 19:58:07,396 - Epoch: [38][  200/  391]    Overall Loss 0.391187    Objective Loss 0.391187    Top1 86.652344    Top5 99.562500    LR 0.300000    Time 0.023056    
2018-11-02 19:58:08,535 - Epoch: [38][  250/  391]    Overall Loss 0.388206    Objective Loss 0.388206    Top1 86.721875    Top5 99.568750    LR 0.300000    Time 0.022996    
2018-11-02 19:58:09,673 - Epoch: [38][  300/  391]    Overall Loss 0.387472    Objective Loss 0.387472    Top1 86.739583    Top5 99.565104    LR 0.300000    Time 0.022953    
2018-11-02 19:58:10,813 - Epoch: [38][  350/  391]    Overall Loss 0.389868    Objective Loss 0.389868    Top1 86.613839    Top5 99.555804    LR 0.300000    Time 0.022926    
2018-11-02 19:58:11,825 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57448 |  0.00024 |    0.37410 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15565 |  0.00006 |    0.09618 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15506 | -0.00316 |    0.10618 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19355 | -0.01570 |    0.13769 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19166 | -0.01168 |    0.14240 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19684 | -0.02689 |    0.14312 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17388 |  0.00217 |    0.12384 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20838 | -0.00727 |    0.15252 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17704 | -0.00493 |    0.13602 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39669 | -0.01347 |    0.28242 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15379 | -0.01000 |    0.11862 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13581 | -0.00934 |    0.10659 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15209 | -0.02434 |    0.11968 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12323 | -0.00150 |    0.09630 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15208 | -0.01551 |    0.12123 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13687 | -0.01186 |    0.10788 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21300 | -0.02419 |    0.16592 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13443 | -0.01323 |    0.10585 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09854 | -0.00117 |    0.07445 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06314 | -0.00233 |    0.04758 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05036 | -0.00659 |    0.03705 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60145 | -0.00004 |    0.46797 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:58:11,825 - Total sparsity: 0.00

2018-11-02 19:58:11,825 - --- validate (epoch=38)-----------
2018-11-02 19:58:11,825 - 10000 samples (128 per mini-batch)
2018-11-02 19:58:12,547 - Epoch: [38][   50/   78]    Loss 0.666466    Top1 80.109375    Top5 98.656250    
2018-11-02 19:58:12,939 - ==> Top1: 80.020    Top5: 98.800    Loss: 0.652

2018-11-02 19:58:12,939 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:58:12,939 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:58:12,948 - 

2018-11-02 19:58:12,948 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:58:14,142 - Epoch: [39][   50/  391]    Overall Loss 0.383837    Objective Loss 0.383837    Top1 86.750000    Top5 99.687500    LR 0.300000    Time 0.023842    
2018-11-02 19:58:15,282 - Epoch: [39][  100/  391]    Overall Loss 0.391670    Objective Loss 0.391670    Top1 86.429688    Top5 99.523438    LR 0.300000    Time 0.023310    
2018-11-02 19:58:16,423 - Epoch: [39][  150/  391]    Overall Loss 0.392625    Objective Loss 0.392625    Top1 86.411458    Top5 99.505208    LR 0.300000    Time 0.023140    
2018-11-02 19:58:17,564 - Epoch: [39][  200/  391]    Overall Loss 0.396717    Objective Loss 0.396717    Top1 86.171875    Top5 99.488281    LR 0.300000    Time 0.023051    
2018-11-02 19:58:18,704 - Epoch: [39][  250/  391]    Overall Loss 0.392740    Objective Loss 0.392740    Top1 86.321875    Top5 99.509375    LR 0.300000    Time 0.022996    
2018-11-02 19:58:19,843 - Epoch: [39][  300/  391]    Overall Loss 0.392885    Objective Loss 0.392885    Top1 86.335938    Top5 99.502604    LR 0.300000    Time 0.022958    
2018-11-02 19:58:20,983 - Epoch: [39][  350/  391]    Overall Loss 0.396572    Objective Loss 0.396572    Top1 86.209821    Top5 99.491071    LR 0.300000    Time 0.022930    
2018-11-02 19:58:21,997 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57586 | -0.00231 |    0.37629 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15550 | -0.00043 |    0.09524 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15612 | -0.00284 |    0.10576 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19363 | -0.01922 |    0.13819 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19307 | -0.01191 |    0.14343 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19758 | -0.02916 |    0.14319 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17473 |  0.00089 |    0.12416 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20869 | -0.00565 |    0.15315 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17742 | -0.00541 |    0.13647 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39953 | -0.01929 |    0.28610 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15451 | -0.01017 |    0.11886 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13645 | -0.00903 |    0.10695 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15266 | -0.02395 |    0.12012 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12361 | -0.00047 |    0.09613 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15288 | -0.01479 |    0.12147 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13766 | -0.01187 |    0.10857 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21370 | -0.02638 |    0.16774 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13495 | -0.01322 |    0.10604 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09897 | -0.00101 |    0.07483 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06394 | -0.00270 |    0.04826 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05107 | -0.00682 |    0.03762 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60270 | -0.00004 |    0.46885 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:58:21,998 - Total sparsity: 0.00

2018-11-02 19:58:21,998 - --- validate (epoch=39)-----------
2018-11-02 19:58:21,998 - 10000 samples (128 per mini-batch)
2018-11-02 19:58:22,716 - Epoch: [39][   50/   78]    Loss 0.510502    Top1 83.500000    Top5 99.156250    
2018-11-02 19:58:23,107 - ==> Top1: 83.680    Top5: 99.300    Loss: 0.498

2018-11-02 19:58:23,107 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:58:23,107 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:58:23,116 - 

2018-11-02 19:58:23,116 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:58:24,310 - Epoch: [40][   50/  391]    Overall Loss 0.359594    Objective Loss 0.359594    Top1 87.703125    Top5 99.609375    LR 0.300000    Time 0.023858    
2018-11-02 19:58:25,448 - Epoch: [40][  100/  391]    Overall Loss 0.376621    Objective Loss 0.376621    Top1 87.062500    Top5 99.570312    LR 0.300000    Time 0.023285    
2018-11-02 19:58:26,586 - Epoch: [40][  150/  391]    Overall Loss 0.380616    Objective Loss 0.380616    Top1 86.848958    Top5 99.598958    LR 0.300000    Time 0.023107    
2018-11-02 19:58:27,723 - Epoch: [40][  200/  391]    Overall Loss 0.382799    Objective Loss 0.382799    Top1 86.792969    Top5 99.570312    LR 0.300000    Time 0.023007    
2018-11-02 19:58:28,859 - Epoch: [40][  250/  391]    Overall Loss 0.386505    Objective Loss 0.386505    Top1 86.681250    Top5 99.537500    LR 0.300000    Time 0.022946    
2018-11-02 19:58:29,998 - Epoch: [40][  300/  391]    Overall Loss 0.388464    Objective Loss 0.388464    Top1 86.591146    Top5 99.510417    LR 0.300000    Time 0.022914    
2018-11-02 19:58:31,138 - Epoch: [40][  350/  391]    Overall Loss 0.389417    Objective Loss 0.389417    Top1 86.562500    Top5 99.511161    LR 0.300000    Time 0.022893    
2018-11-02 19:58:32,148 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57914 | -0.00716 |    0.38283 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15572 | -0.00054 |    0.09513 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15605 | -0.00442 |    0.10622 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19404 | -0.01824 |    0.13733 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19343 | -0.01014 |    0.14370 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19694 | -0.03076 |    0.14253 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17379 |  0.00015 |    0.12390 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20963 | -0.00777 |    0.15381 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17784 | -0.00421 |    0.13665 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39772 | -0.01838 |    0.28802 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 | -0.01014 |    0.11895 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13686 | -0.01004 |    0.10730 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15283 | -0.02431 |    0.12027 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12351 | -0.00055 |    0.09615 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15289 | -0.01476 |    0.12185 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13771 | -0.01209 |    0.10867 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21410 | -0.02506 |    0.16844 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13527 | -0.01317 |    0.10624 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09909 | -0.00147 |    0.07476 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06418 | -0.00301 |    0.04852 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05129 | -0.00659 |    0.03772 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60034 | -0.00003 |    0.46704 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:58:32,148 - Total sparsity: 0.00

2018-11-02 19:58:32,148 - --- validate (epoch=40)-----------
2018-11-02 19:58:32,148 - 10000 samples (128 per mini-batch)
2018-11-02 19:58:32,871 - Epoch: [40][   50/   78]    Loss 0.608204    Top1 80.906250    Top5 99.062500    
2018-11-02 19:58:33,261 - ==> Top1: 80.890    Top5: 99.090    Loss: 0.617

2018-11-02 19:58:33,262 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:58:33,262 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:58:33,274 - 

2018-11-02 19:58:33,274 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:58:34,470 - Epoch: [41][   50/  391]    Overall Loss 0.385813    Objective Loss 0.385813    Top1 86.921875    Top5 99.531250    LR 0.300000    Time 0.023885    
2018-11-02 19:58:35,610 - Epoch: [41][  100/  391]    Overall Loss 0.391539    Objective Loss 0.391539    Top1 86.906250    Top5 99.531250    LR 0.300000    Time 0.023329    
2018-11-02 19:58:36,748 - Epoch: [41][  150/  391]    Overall Loss 0.384758    Objective Loss 0.384758    Top1 86.953125    Top5 99.541667    LR 0.300000    Time 0.023130    
2018-11-02 19:58:37,888 - Epoch: [41][  200/  391]    Overall Loss 0.387104    Objective Loss 0.387104    Top1 86.656250    Top5 99.554688    LR 0.300000    Time 0.023039    
2018-11-02 19:58:39,026 - Epoch: [41][  250/  391]    Overall Loss 0.386684    Objective Loss 0.386684    Top1 86.606250    Top5 99.550000    LR 0.300000    Time 0.022980    
2018-11-02 19:58:40,165 - Epoch: [41][  300/  391]    Overall Loss 0.391078    Objective Loss 0.391078    Top1 86.500000    Top5 99.523438    LR 0.300000    Time 0.022941    
2018-11-02 19:58:41,304 - Epoch: [41][  350/  391]    Overall Loss 0.389381    Objective Loss 0.389381    Top1 86.502232    Top5 99.508929    LR 0.300000    Time 0.022915    
2018-11-02 19:58:42,318 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57916 | -0.00482 |    0.38114 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.00169 |    0.09511 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15575 | -0.00359 |    0.10712 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19394 | -0.01556 |    0.13741 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19364 | -0.01149 |    0.14318 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19717 | -0.03201 |    0.14379 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17442 |  0.00155 |    0.12502 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21049 | -0.00742 |    0.15442 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17801 | -0.00586 |    0.13686 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39757 | -0.01891 |    0.28807 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15466 | -0.01055 |    0.11896 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13709 | -0.00925 |    0.10722 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15328 | -0.02264 |    0.12045 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12332 | -0.00227 |    0.09607 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15324 | -0.01404 |    0.12203 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13790 | -0.01214 |    0.10893 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21399 | -0.02593 |    0.16650 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13558 | -0.01358 |    0.10666 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09929 | -0.00141 |    0.07498 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06483 | -0.00275 |    0.04894 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05165 | -0.00651 |    0.03791 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60362 | -0.00003 |    0.46881 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:58:42,318 - Total sparsity: 0.00

2018-11-02 19:58:42,318 - --- validate (epoch=41)-----------
2018-11-02 19:58:42,318 - 10000 samples (128 per mini-batch)
2018-11-02 19:58:43,034 - Epoch: [41][   50/   78]    Loss 0.591298    Top1 80.515625    Top5 99.062500    
2018-11-02 19:58:43,421 - ==> Top1: 79.930    Top5: 99.150    Loss: 0.599

2018-11-02 19:58:43,422 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:58:43,422 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:58:43,430 - 

2018-11-02 19:58:43,430 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:58:44,630 - Epoch: [42][   50/  391]    Overall Loss 0.372359    Objective Loss 0.372359    Top1 87.203125    Top5 99.500000    LR 0.300000    Time 0.023960    
2018-11-02 19:58:45,770 - Epoch: [42][  100/  391]    Overall Loss 0.387696    Objective Loss 0.387696    Top1 86.695312    Top5 99.476562    LR 0.300000    Time 0.023364    
2018-11-02 19:58:46,911 - Epoch: [42][  150/  391]    Overall Loss 0.386491    Objective Loss 0.386491    Top1 86.692708    Top5 99.468750    LR 0.300000    Time 0.023178    
2018-11-02 19:58:48,052 - Epoch: [42][  200/  391]    Overall Loss 0.390770    Objective Loss 0.390770    Top1 86.535156    Top5 99.472656    LR 0.300000    Time 0.023081    
2018-11-02 19:58:49,193 - Epoch: [42][  250/  391]    Overall Loss 0.387877    Objective Loss 0.387877    Top1 86.775000    Top5 99.465625    LR 0.300000    Time 0.023022    
2018-11-02 19:58:50,333 - Epoch: [42][  300/  391]    Overall Loss 0.382643    Objective Loss 0.382643    Top1 86.924479    Top5 99.505208    LR 0.300000    Time 0.022983    
2018-11-02 19:58:51,472 - Epoch: [42][  350/  391]    Overall Loss 0.386288    Objective Loss 0.386288    Top1 86.810268    Top5 99.482143    LR 0.300000    Time 0.022951    
2018-11-02 19:58:52,488 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57800 | -0.00452 |    0.38257 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15433 | -0.00161 |    0.09481 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15470 | -0.00379 |    0.10585 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19418 | -0.01716 |    0.13734 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19384 | -0.01374 |    0.14393 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19718 | -0.03035 |    0.14398 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17421 | -0.00081 |    0.12530 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21041 | -0.00777 |    0.15386 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17821 | -0.00479 |    0.13689 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39769 | -0.01766 |    0.28687 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15406 | -0.01070 |    0.11888 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13596 | -0.01004 |    0.10654 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15274 | -0.02208 |    0.12012 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12310 | -0.00198 |    0.09566 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15337 | -0.01426 |    0.12192 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13796 | -0.01140 |    0.10874 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21366 | -0.02475 |    0.16664 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13564 | -0.01364 |    0.10681 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09945 | -0.00133 |    0.07509 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06550 | -0.00331 |    0.04944 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05211 | -0.00632 |    0.03829 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60314 | -0.00003 |    0.46886 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:58:52,488 - Total sparsity: 0.00

2018-11-02 19:58:52,488 - --- validate (epoch=42)-----------
2018-11-02 19:58:52,488 - 10000 samples (128 per mini-batch)
2018-11-02 19:58:53,213 - Epoch: [42][   50/   78]    Loss 0.623701    Top1 79.843750    Top5 99.015625    
2018-11-02 19:58:53,604 - ==> Top1: 79.800    Top5: 99.090    Loss: 0.620

2018-11-02 19:58:53,605 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:58:53,605 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:58:53,614 - 

2018-11-02 19:58:53,614 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:58:54,813 - Epoch: [43][   50/  391]    Overall Loss 0.361358    Objective Loss 0.361358    Top1 87.437500    Top5 99.546875    LR 0.300000    Time 0.023941    
2018-11-02 19:58:55,954 - Epoch: [43][  100/  391]    Overall Loss 0.367443    Objective Loss 0.367443    Top1 87.281250    Top5 99.554688    LR 0.300000    Time 0.023368    
2018-11-02 19:58:57,095 - Epoch: [43][  150/  391]    Overall Loss 0.372298    Objective Loss 0.372298    Top1 87.177083    Top5 99.552083    LR 0.300000    Time 0.023178    
2018-11-02 19:58:58,237 - Epoch: [43][  200/  391]    Overall Loss 0.371023    Objective Loss 0.371023    Top1 87.273438    Top5 99.542969    LR 0.300000    Time 0.023088    
2018-11-02 19:58:59,377 - Epoch: [43][  250/  391]    Overall Loss 0.373509    Objective Loss 0.373509    Top1 87.196875    Top5 99.540625    LR 0.300000    Time 0.023026    
2018-11-02 19:59:00,523 - Epoch: [43][  300/  391]    Overall Loss 0.378883    Objective Loss 0.378883    Top1 86.950521    Top5 99.536458    LR 0.300000    Time 0.023002    
2018-11-02 19:59:01,664 - Epoch: [43][  350/  391]    Overall Loss 0.381268    Objective Loss 0.381268    Top1 86.837054    Top5 99.520089    LR 0.300000    Time 0.022973    
2018-11-02 19:59:02,676 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57602 | -0.00250 |    0.37617 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15451 |  0.00070 |    0.09396 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15470 | -0.00603 |    0.10547 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19365 | -0.01487 |    0.13705 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19299 | -0.01080 |    0.14332 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19714 | -0.02908 |    0.14336 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17408 |  0.00020 |    0.12448 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20987 | -0.00616 |    0.15365 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17834 | -0.00440 |    0.13723 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39654 | -0.01830 |    0.28515 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15437 | -0.00816 |    0.11929 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13598 | -0.01037 |    0.10679 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15277 | -0.02285 |    0.12048 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12284 | -0.00132 |    0.09573 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.01411 |    0.12162 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13764 | -0.01162 |    0.10876 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21331 | -0.02612 |    0.16758 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13564 | -0.01360 |    0.10691 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09939 | -0.00145 |    0.07510 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06589 | -0.00320 |    0.04974 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05232 | -0.00567 |    0.03827 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60557 | -0.00002 |    0.47033 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:59:02,676 - Total sparsity: 0.00

2018-11-02 19:59:02,676 - --- validate (epoch=43)-----------
2018-11-02 19:59:02,677 - 10000 samples (128 per mini-batch)
2018-11-02 19:59:03,400 - Epoch: [43][   50/   78]    Loss 0.689158    Top1 78.437500    Top5 98.453125    
2018-11-02 19:59:03,785 - ==> Top1: 78.120    Top5: 98.640    Loss: 0.695

2018-11-02 19:59:03,786 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:59:03,786 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:59:03,795 - 

2018-11-02 19:59:03,795 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:59:04,993 - Epoch: [44][   50/  391]    Overall Loss 0.371445    Objective Loss 0.371445    Top1 87.125000    Top5 99.515625    LR 0.300000    Time 0.023933    
2018-11-02 19:59:06,136 - Epoch: [44][  100/  391]    Overall Loss 0.376731    Objective Loss 0.376731    Top1 86.859375    Top5 99.515625    LR 0.300000    Time 0.023381    
2018-11-02 19:59:07,273 - Epoch: [44][  150/  391]    Overall Loss 0.381376    Objective Loss 0.381376    Top1 86.723958    Top5 99.510417    LR 0.300000    Time 0.023160    
2018-11-02 19:59:08,411 - Epoch: [44][  200/  391]    Overall Loss 0.382487    Objective Loss 0.382487    Top1 86.742188    Top5 99.503906    LR 0.300000    Time 0.023051    
2018-11-02 19:59:09,549 - Epoch: [44][  250/  391]    Overall Loss 0.383288    Objective Loss 0.383288    Top1 86.715625    Top5 99.500000    LR 0.300000    Time 0.022989    
2018-11-02 19:59:10,689 - Epoch: [44][  300/  391]    Overall Loss 0.388891    Objective Loss 0.388891    Top1 86.557292    Top5 99.484375    LR 0.300000    Time 0.022951    
2018-11-02 19:59:11,826 - Epoch: [44][  350/  391]    Overall Loss 0.390324    Objective Loss 0.390324    Top1 86.502232    Top5 99.495536    LR 0.300000    Time 0.022919    
2018-11-02 19:59:12,837 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57293 |  0.00882 |    0.37848 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15479 | -0.00153 |    0.09500 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15584 | -0.00414 |    0.10723 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19354 | -0.02050 |    0.13728 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19270 | -0.01126 |    0.14233 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19647 | -0.03027 |    0.14300 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17507 |  0.00152 |    0.12640 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21078 | -0.00944 |    0.15487 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17885 | -0.00443 |    0.13757 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39775 | -0.01739 |    0.28346 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15503 | -0.01004 |    0.12002 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13652 | -0.01045 |    0.10702 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15267 | -0.02278 |    0.12066 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12264 | -0.00026 |    0.09554 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15355 | -0.01496 |    0.12217 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13807 | -0.01165 |    0.10930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21403 | -0.02531 |    0.16849 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13613 | -0.01371 |    0.10727 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09991 | -0.00193 |    0.07545 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06632 | -0.00335 |    0.05004 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05257 | -0.00557 |    0.03848 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60092 | -0.00002 |    0.46661 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:59:12,837 - Total sparsity: 0.00

2018-11-02 19:59:12,838 - --- validate (epoch=44)-----------
2018-11-02 19:59:12,838 - 10000 samples (128 per mini-batch)
2018-11-02 19:59:13,557 - Epoch: [44][   50/   78]    Loss 0.553985    Top1 83.015625    Top5 99.031250    
2018-11-02 19:59:13,947 - ==> Top1: 83.040    Top5: 99.070    Loss: 0.537

2018-11-02 19:59:13,947 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:59:13,948 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:59:13,956 - 

2018-11-02 19:59:13,957 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:59:15,154 - Epoch: [45][   50/  391]    Overall Loss 0.392768    Objective Loss 0.392768    Top1 86.343750    Top5 99.421875    LR 0.300000    Time 0.023916    
2018-11-02 19:59:16,292 - Epoch: [45][  100/  391]    Overall Loss 0.379527    Objective Loss 0.379527    Top1 86.906250    Top5 99.492188    LR 0.300000    Time 0.023323    
2018-11-02 19:59:17,431 - Epoch: [45][  150/  391]    Overall Loss 0.376538    Objective Loss 0.376538    Top1 87.171875    Top5 99.526042    LR 0.300000    Time 0.023137    
2018-11-02 19:59:18,572 - Epoch: [45][  200/  391]    Overall Loss 0.379741    Objective Loss 0.379741    Top1 86.960938    Top5 99.511719    LR 0.300000    Time 0.023048    
2018-11-02 19:59:19,712 - Epoch: [45][  250/  391]    Overall Loss 0.380488    Objective Loss 0.380488    Top1 86.796875    Top5 99.500000    LR 0.300000    Time 0.022995    
2018-11-02 19:59:20,852 - Epoch: [45][  300/  391]    Overall Loss 0.380243    Objective Loss 0.380243    Top1 86.817708    Top5 99.494792    LR 0.300000    Time 0.022958    
2018-11-02 19:59:21,993 - Epoch: [45][  350/  391]    Overall Loss 0.380104    Objective Loss 0.380104    Top1 86.828125    Top5 99.502232    LR 0.300000    Time 0.022933    
2018-11-02 19:59:23,005 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57586 |  0.00615 |    0.37847 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15523 | -0.00203 |    0.09484 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15612 | -0.00416 |    0.10770 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19395 | -0.01733 |    0.13784 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19250 | -0.01031 |    0.14256 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19596 | -0.02895 |    0.14301 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17466 |  0.00120 |    0.12579 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21133 | -0.00729 |    0.15555 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17910 | -0.00572 |    0.13799 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39339 | -0.01843 |    0.28362 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15494 | -0.00945 |    0.11938 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13634 | -0.01127 |    0.10696 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15211 | -0.02190 |    0.12005 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12218 | -0.00076 |    0.09536 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15340 | -0.01617 |    0.12218 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13802 | -0.01191 |    0.10932 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21253 | -0.02463 |    0.16768 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13592 | -0.01399 |    0.10717 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10005 | -0.00213 |    0.07578 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06687 | -0.00338 |    0.05041 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05268 | -0.00593 |    0.03862 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59779 | -0.00002 |    0.46684 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:59:23,005 - Total sparsity: 0.00

2018-11-02 19:59:23,005 - --- validate (epoch=45)-----------
2018-11-02 19:59:23,005 - 10000 samples (128 per mini-batch)
2018-11-02 19:59:23,726 - Epoch: [45][   50/   78]    Loss 0.530940    Top1 82.296875    Top5 99.062500    
2018-11-02 19:59:24,116 - ==> Top1: 82.370    Top5: 99.130    Loss: 0.538

2018-11-02 19:59:24,117 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:59:24,117 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:59:24,129 - 

2018-11-02 19:59:24,129 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:59:25,325 - Epoch: [46][   50/  391]    Overall Loss 0.350981    Objective Loss 0.350981    Top1 87.718750    Top5 99.640625    LR 0.300000    Time 0.023884    
2018-11-02 19:59:26,463 - Epoch: [46][  100/  391]    Overall Loss 0.366063    Objective Loss 0.366063    Top1 87.187500    Top5 99.601562    LR 0.300000    Time 0.023313    
2018-11-02 19:59:27,601 - Epoch: [46][  150/  391]    Overall Loss 0.366871    Objective Loss 0.366871    Top1 87.057292    Top5 99.593750    LR 0.300000    Time 0.023116    
2018-11-02 19:59:28,739 - Epoch: [46][  200/  391]    Overall Loss 0.373296    Objective Loss 0.373296    Top1 86.902344    Top5 99.578125    LR 0.300000    Time 0.023022    
2018-11-02 19:59:29,878 - Epoch: [46][  250/  391]    Overall Loss 0.382082    Objective Loss 0.382082    Top1 86.618750    Top5 99.528125    LR 0.300000    Time 0.022970    
2018-11-02 19:59:31,017 - Epoch: [46][  300/  391]    Overall Loss 0.377572    Objective Loss 0.377572    Top1 86.763021    Top5 99.546875    LR 0.300000    Time 0.022934    
2018-11-02 19:59:32,155 - Epoch: [46][  350/  391]    Overall Loss 0.376213    Objective Loss 0.376213    Top1 86.892857    Top5 99.535714    LR 0.300000    Time 0.022894    
2018-11-02 19:59:33,167 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57228 | -0.00900 |    0.37768 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15423 |  0.00176 |    0.09424 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15498 | -0.00205 |    0.10704 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19481 | -0.01856 |    0.13817 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19285 | -0.01091 |    0.14247 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19646 | -0.03086 |    0.14434 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17495 | -0.00051 |    0.12631 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21168 | -0.00666 |    0.15506 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17936 | -0.00546 |    0.13828 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39207 | -0.01240 |    0.28110 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15500 | -0.01097 |    0.11942 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13622 | -0.00938 |    0.10661 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15278 | -0.02182 |    0.12026 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12217 | -0.00034 |    0.09464 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15345 | -0.01617 |    0.12210 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13829 | -0.01230 |    0.10939 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21305 | -0.02253 |    0.16791 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13631 | -0.01368 |    0.10720 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10041 | -0.00194 |    0.07586 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06763 | -0.00334 |    0.05097 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05318 | -0.00547 |    0.03893 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.60135 | -0.00002 |    0.46864 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:59:33,167 - Total sparsity: 0.00

2018-11-02 19:59:33,167 - --- validate (epoch=46)-----------
2018-11-02 19:59:33,167 - 10000 samples (128 per mini-batch)
2018-11-02 19:59:33,887 - Epoch: [46][   50/   78]    Loss 0.875910    Top1 75.406250    Top5 98.156250    
2018-11-02 19:59:34,277 - ==> Top1: 75.310    Top5: 98.190    Loss: 0.881

2018-11-02 19:59:34,278 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:59:34,278 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:59:34,290 - 

2018-11-02 19:59:34,290 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:59:35,486 - Epoch: [47][   50/  391]    Overall Loss 0.388191    Objective Loss 0.388191    Top1 86.156250    Top5 99.484375    LR 0.300000    Time 0.023883    
2018-11-02 19:59:36,626 - Epoch: [47][  100/  391]    Overall Loss 0.395119    Objective Loss 0.395119    Top1 86.062500    Top5 99.476562    LR 0.300000    Time 0.023329    
2018-11-02 19:59:37,764 - Epoch: [47][  150/  391]    Overall Loss 0.387257    Objective Loss 0.387257    Top1 86.468750    Top5 99.494792    LR 0.300000    Time 0.023130    
2018-11-02 19:59:38,903 - Epoch: [47][  200/  391]    Overall Loss 0.387697    Objective Loss 0.387697    Top1 86.476562    Top5 99.492188    LR 0.300000    Time 0.023039    
2018-11-02 19:59:40,047 - Epoch: [47][  250/  391]    Overall Loss 0.387915    Objective Loss 0.387915    Top1 86.503125    Top5 99.493750    LR 0.300000    Time 0.022999    
2018-11-02 19:59:41,187 - Epoch: [47][  300/  391]    Overall Loss 0.385041    Objective Loss 0.385041    Top1 86.609375    Top5 99.505208    LR 0.300000    Time 0.022962    
2018-11-02 19:59:42,323 - Epoch: [47][  350/  391]    Overall Loss 0.385615    Objective Loss 0.385615    Top1 86.651786    Top5 99.495536    LR 0.300000    Time 0.022925    
2018-11-02 19:59:43,338 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57400 | -0.00680 |    0.38010 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 |  0.00047 |    0.09481 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15560 | -0.00201 |    0.10682 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19513 | -0.01835 |    0.13955 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19300 | -0.01199 |    0.14320 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19712 | -0.03126 |    0.14553 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17550 |  0.00033 |    0.12655 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21127 | -0.00486 |    0.15510 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17872 | -0.00536 |    0.13760 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39081 | -0.01206 |    0.27989 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15495 | -0.01048 |    0.11939 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13616 | -0.00973 |    0.10656 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15312 | -0.02324 |    0.12080 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12272 | -0.00114 |    0.09513 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15296 | -0.01649 |    0.12184 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13817 | -0.01238 |    0.10939 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21256 | -0.02300 |    0.16800 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13615 | -0.01365 |    0.10723 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10039 | -0.00213 |    0.07584 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06804 | -0.00354 |    0.05131 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05346 | -0.00529 |    0.03906 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59995 | -0.00002 |    0.46854 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:59:43,338 - Total sparsity: 0.00

2018-11-02 19:59:43,338 - --- validate (epoch=47)-----------
2018-11-02 19:59:43,338 - 10000 samples (128 per mini-batch)
2018-11-02 19:59:44,058 - Epoch: [47][   50/   78]    Loss 0.520898    Top1 82.718750    Top5 99.015625    
2018-11-02 19:59:44,448 - ==> Top1: 82.970    Top5: 99.170    Loss: 0.512

2018-11-02 19:59:44,449 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:59:44,449 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:59:44,460 - 

2018-11-02 19:59:44,460 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:59:45,657 - Epoch: [48][   50/  391]    Overall Loss 0.376542    Objective Loss 0.376542    Top1 86.843750    Top5 99.593750    LR 0.300000    Time 0.023901    
2018-11-02 19:59:46,798 - Epoch: [48][  100/  391]    Overall Loss 0.364992    Objective Loss 0.364992    Top1 87.210938    Top5 99.578125    LR 0.300000    Time 0.023340    
2018-11-02 19:59:47,936 - Epoch: [48][  150/  391]    Overall Loss 0.373912    Objective Loss 0.373912    Top1 87.046875    Top5 99.609375    LR 0.300000    Time 0.023138    
2018-11-02 19:59:49,077 - Epoch: [48][  200/  391]    Overall Loss 0.373364    Objective Loss 0.373364    Top1 87.007812    Top5 99.628906    LR 0.300000    Time 0.023054    
2018-11-02 19:59:50,217 - Epoch: [48][  250/  391]    Overall Loss 0.378693    Objective Loss 0.378693    Top1 86.818750    Top5 99.584375    LR 0.300000    Time 0.022998    
2018-11-02 19:59:51,359 - Epoch: [48][  300/  391]    Overall Loss 0.381495    Objective Loss 0.381495    Top1 86.763021    Top5 99.567708    LR 0.300000    Time 0.022969    
2018-11-02 19:59:52,502 - Epoch: [48][  350/  391]    Overall Loss 0.383118    Objective Loss 0.383118    Top1 86.787946    Top5 99.555804    LR 0.300000    Time 0.022947    
2018-11-02 19:59:53,519 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57283 |  0.00200 |    0.38067 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15492 | -0.00198 |    0.09527 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15592 | -0.00276 |    0.10719 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19488 | -0.01524 |    0.13955 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19336 | -0.01157 |    0.14301 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19671 | -0.02971 |    0.14474 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17644 |  0.00061 |    0.12705 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21125 | -0.00584 |    0.15547 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17910 | -0.00626 |    0.13755 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38993 | -0.01473 |    0.27703 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15498 | -0.00897 |    0.11948 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13625 | -0.00873 |    0.10667 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15308 | -0.02228 |    0.12066 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12251 | -0.00018 |    0.09502 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15281 | -0.01544 |    0.12137 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13807 | -0.01211 |    0.10930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21277 | -0.02363 |    0.16756 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13598 | -0.01356 |    0.10700 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10026 | -0.00191 |    0.07577 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06844 | -0.00430 |    0.05174 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05374 | -0.00479 |    0.03915 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59929 | -0.00001 |    0.46694 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 19:59:53,519 - Total sparsity: 0.00

2018-11-02 19:59:53,519 - --- validate (epoch=48)-----------
2018-11-02 19:59:53,520 - 10000 samples (128 per mini-batch)
2018-11-02 19:59:54,237 - Epoch: [48][   50/   78]    Loss 0.617054    Top1 81.234375    Top5 98.625000    
2018-11-02 19:59:54,624 - ==> Top1: 81.200    Top5: 98.770    Loss: 0.608

2018-11-02 19:59:54,625 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 19:59:54,625 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 19:59:54,633 - 

2018-11-02 19:59:54,633 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 19:59:55,829 - Epoch: [49][   50/  391]    Overall Loss 0.372690    Objective Loss 0.372690    Top1 86.937500    Top5 99.562500    LR 0.300000    Time 0.023883    
2018-11-02 19:59:56,970 - Epoch: [49][  100/  391]    Overall Loss 0.364726    Objective Loss 0.364726    Top1 87.234375    Top5 99.562500    LR 0.300000    Time 0.023331    
2018-11-02 19:59:58,109 - Epoch: [49][  150/  391]    Overall Loss 0.367160    Objective Loss 0.367160    Top1 87.135417    Top5 99.567708    LR 0.300000    Time 0.023141    
2018-11-02 19:59:59,248 - Epoch: [49][  200/  391]    Overall Loss 0.370724    Objective Loss 0.370724    Top1 87.089844    Top5 99.546875    LR 0.300000    Time 0.023045    
2018-11-02 20:00:00,390 - Epoch: [49][  250/  391]    Overall Loss 0.372558    Objective Loss 0.372558    Top1 87.040625    Top5 99.587500    LR 0.300000    Time 0.022998    
2018-11-02 20:00:01,527 - Epoch: [49][  300/  391]    Overall Loss 0.375494    Objective Loss 0.375494    Top1 86.963542    Top5 99.570312    LR 0.300000    Time 0.022952    
2018-11-02 20:00:02,665 - Epoch: [49][  350/  391]    Overall Loss 0.374240    Objective Loss 0.374240    Top1 87.049107    Top5 99.569196    LR 0.300000    Time 0.022921    
2018-11-02 20:00:03,677 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57668 |  0.00025 |    0.38141 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15566 |  0.00045 |    0.09537 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15611 | -0.00205 |    0.10672 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19605 | -0.01918 |    0.14109 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19444 | -0.00906 |    0.14326 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19685 | -0.03184 |    0.14535 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17653 |  0.00130 |    0.12577 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21188 | -0.00673 |    0.15606 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17944 | -0.00488 |    0.13762 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38968 | -0.01514 |    0.27448 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15568 | -0.00975 |    0.11975 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13685 | -0.00953 |    0.10739 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15299 | -0.02448 |    0.12098 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12276 | -0.00079 |    0.09562 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15307 | -0.01665 |    0.12171 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13817 | -0.01134 |    0.10944 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21272 | -0.02504 |    0.16722 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13597 | -0.01466 |    0.10720 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10031 | -0.00205 |    0.07589 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06918 | -0.00303 |    0.05211 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05417 | -0.00529 |    0.03954 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59709 | -0.00001 |    0.46394 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:00:03,677 - Total sparsity: 0.00

2018-11-02 20:00:03,677 - --- validate (epoch=49)-----------
2018-11-02 20:00:03,677 - 10000 samples (128 per mini-batch)
2018-11-02 20:00:04,394 - Epoch: [49][   50/   78]    Loss 0.588088    Top1 81.484375    Top5 98.859375    
2018-11-02 20:00:04,793 - ==> Top1: 81.340    Top5: 98.910    Loss: 0.583

2018-11-02 20:00:04,794 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:00:04,794 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:00:04,802 - 

2018-11-02 20:00:04,803 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:00:05,997 - Epoch: [50][   50/  391]    Overall Loss 0.366328    Objective Loss 0.366328    Top1 87.156250    Top5 99.671875    LR 0.300000    Time 0.023849    
2018-11-02 20:00:07,133 - Epoch: [50][  100/  391]    Overall Loss 0.378814    Objective Loss 0.378814    Top1 87.078125    Top5 99.609375    LR 0.300000    Time 0.023274    
2018-11-02 20:00:08,273 - Epoch: [50][  150/  391]    Overall Loss 0.374230    Objective Loss 0.374230    Top1 87.125000    Top5 99.567708    LR 0.300000    Time 0.023107    
2018-11-02 20:00:09,413 - Epoch: [50][  200/  391]    Overall Loss 0.376853    Objective Loss 0.376853    Top1 87.074219    Top5 99.558594    LR 0.300000    Time 0.023023    
2018-11-02 20:00:10,552 - Epoch: [50][  250/  391]    Overall Loss 0.380391    Objective Loss 0.380391    Top1 86.896875    Top5 99.565625    LR 0.300000    Time 0.022968    
2018-11-02 20:00:11,691 - Epoch: [50][  300/  391]    Overall Loss 0.376404    Objective Loss 0.376404    Top1 86.992188    Top5 99.570312    LR 0.300000    Time 0.022935    
2018-11-02 20:00:12,831 - Epoch: [50][  350/  391]    Overall Loss 0.379338    Objective Loss 0.379338    Top1 86.930804    Top5 99.571429    LR 0.300000    Time 0.022912    
2018-11-02 20:00:13,845 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57899 | -0.00663 |    0.38662 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15428 | -0.00316 |    0.09375 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15497 | -0.00261 |    0.10614 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19517 | -0.01668 |    0.13977 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19458 | -0.00964 |    0.14353 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19781 | -0.02957 |    0.14559 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17617 |  0.00047 |    0.12644 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21254 | -0.00543 |    0.15657 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17997 | -0.00436 |    0.13815 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39113 | -0.01489 |    0.27715 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15544 | -0.01050 |    0.11985 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13666 | -0.01011 |    0.10694 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15335 | -0.02457 |    0.12109 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12323 | -0.00137 |    0.09599 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15322 | -0.01593 |    0.12186 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13807 | -0.01104 |    0.10922 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21335 | -0.02494 |    0.16789 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13625 | -0.01432 |    0.10734 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10031 | -0.00235 |    0.07594 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06937 | -0.00339 |    0.05248 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05436 | -0.00511 |    0.03970 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59959 | -0.00001 |    0.46797 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:00:13,845 - Total sparsity: 0.00

2018-11-02 20:00:13,845 - --- validate (epoch=50)-----------
2018-11-02 20:00:13,845 - 10000 samples (128 per mini-batch)
2018-11-02 20:00:14,563 - Epoch: [50][   50/   78]    Loss 1.012070    Top1 74.281250    Top5 98.734375    
2018-11-02 20:00:14,954 - ==> Top1: 74.060    Top5: 98.750    Loss: 0.991

2018-11-02 20:00:14,954 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:00:14,954 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:00:14,966 - 

2018-11-02 20:00:14,967 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:00:16,162 - Epoch: [51][   50/  391]    Overall Loss 0.360550    Objective Loss 0.360550    Top1 87.328125    Top5 99.500000    LR 0.300000    Time 0.023870    
2018-11-02 20:00:17,298 - Epoch: [51][  100/  391]    Overall Loss 0.379422    Objective Loss 0.379422    Top1 86.585938    Top5 99.484375    LR 0.300000    Time 0.023285    
2018-11-02 20:00:18,433 - Epoch: [51][  150/  391]    Overall Loss 0.370344    Objective Loss 0.370344    Top1 87.015625    Top5 99.473958    LR 0.300000    Time 0.023080    
2018-11-02 20:00:19,570 - Epoch: [51][  200/  391]    Overall Loss 0.375459    Objective Loss 0.375459    Top1 86.761719    Top5 99.457031    LR 0.300000    Time 0.022991    
2018-11-02 20:00:20,706 - Epoch: [51][  250/  391]    Overall Loss 0.380871    Objective Loss 0.380871    Top1 86.665625    Top5 99.462500    LR 0.300000    Time 0.022931    
2018-11-02 20:00:21,845 - Epoch: [51][  300/  391]    Overall Loss 0.382398    Objective Loss 0.382398    Top1 86.606771    Top5 99.481771    LR 0.300000    Time 0.022902    
2018-11-02 20:00:22,982 - Epoch: [51][  350/  391]    Overall Loss 0.385634    Objective Loss 0.385634    Top1 86.555804    Top5 99.477679    LR 0.300000    Time 0.022875    
2018-11-02 20:00:23,995 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58062 |  0.00139 |    0.38734 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15506 |  0.00016 |    0.09383 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15583 | -0.00260 |    0.10718 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19586 | -0.01684 |    0.14017 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19576 | -0.00792 |    0.14593 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19778 | -0.03092 |    0.14463 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17665 |  0.00143 |    0.12689 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21345 | -0.00602 |    0.15623 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18032 | -0.00585 |    0.13854 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39230 | -0.01041 |    0.27821 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15603 | -0.00925 |    0.12008 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13727 | -0.00916 |    0.10711 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15397 | -0.02467 |    0.12131 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12378 | -0.00194 |    0.09680 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15380 | -0.01592 |    0.12241 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13843 | -0.01158 |    0.10964 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21361 | -0.02462 |    0.16675 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13648 | -0.01479 |    0.10785 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10059 | -0.00252 |    0.07629 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06975 | -0.00364 |    0.05263 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05463 | -0.00557 |    0.03984 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59531 | -0.00001 |    0.46337 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:00:23,995 - Total sparsity: 0.00

2018-11-02 20:00:23,995 - --- validate (epoch=51)-----------
2018-11-02 20:00:23,995 - 10000 samples (128 per mini-batch)
2018-11-02 20:00:24,717 - Epoch: [51][   50/   78]    Loss 0.541185    Top1 82.828125    Top5 99.421875    
2018-11-02 20:00:25,109 - ==> Top1: 82.900    Top5: 99.390    Loss: 0.534

2018-11-02 20:00:25,110 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:00:25,110 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:00:25,125 - 

2018-11-02 20:00:25,125 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:00:26,319 - Epoch: [52][   50/  391]    Overall Loss 0.352627    Objective Loss 0.352627    Top1 87.703125    Top5 99.578125    LR 0.300000    Time 0.023844    
2018-11-02 20:00:27,455 - Epoch: [52][  100/  391]    Overall Loss 0.367425    Objective Loss 0.367425    Top1 87.289062    Top5 99.593750    LR 0.300000    Time 0.023271    
2018-11-02 20:00:28,593 - Epoch: [52][  150/  391]    Overall Loss 0.369517    Objective Loss 0.369517    Top1 87.213542    Top5 99.552083    LR 0.300000    Time 0.023090    
2018-11-02 20:00:29,731 - Epoch: [52][  200/  391]    Overall Loss 0.367225    Objective Loss 0.367225    Top1 87.351562    Top5 99.558594    LR 0.300000    Time 0.023000    
2018-11-02 20:00:30,867 - Epoch: [52][  250/  391]    Overall Loss 0.372428    Objective Loss 0.372428    Top1 87.168750    Top5 99.515625    LR 0.300000    Time 0.022940    
2018-11-02 20:00:32,004 - Epoch: [52][  300/  391]    Overall Loss 0.373151    Objective Loss 0.373151    Top1 87.169271    Top5 99.523438    LR 0.300000    Time 0.022902    
2018-11-02 20:00:33,142 - Epoch: [52][  350/  391]    Overall Loss 0.375129    Objective Loss 0.375129    Top1 87.069196    Top5 99.511161    LR 0.300000    Time 0.022878    
2018-11-02 20:00:34,158 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58607 | -0.00506 |    0.38978 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15667 |  0.00063 |    0.09432 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15679 | -0.00034 |    0.10804 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19698 | -0.01968 |    0.14073 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19683 | -0.00992 |    0.14574 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19881 | -0.03028 |    0.14557 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17691 | -0.00150 |    0.12625 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21354 | -0.00756 |    0.15666 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18060 | -0.00464 |    0.13865 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39214 | -0.01122 |    0.27731 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15577 | -0.01107 |    0.12008 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13661 | -0.01020 |    0.10686 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15396 | -0.02416 |    0.12180 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12397 | -0.00288 |    0.09697 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15406 | -0.01546 |    0.12243 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13860 | -0.01108 |    0.10979 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21272 | -0.02458 |    0.16607 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13621 | -0.01552 |    0.10764 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10063 | -0.00195 |    0.07626 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06995 | -0.00374 |    0.05289 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05464 | -0.00561 |    0.03989 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59619 | -0.00001 |    0.46545 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:00:34,158 - Total sparsity: 0.00

2018-11-02 20:00:34,158 - --- validate (epoch=52)-----------
2018-11-02 20:00:34,158 - 10000 samples (128 per mini-batch)
2018-11-02 20:00:34,867 - Epoch: [52][   50/   78]    Loss 0.715978    Top1 77.781250    Top5 98.703125    
2018-11-02 20:00:35,251 - ==> Top1: 77.740    Top5: 98.660    Loss: 0.712

2018-11-02 20:00:35,251 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:00:35,252 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:00:35,260 - 

2018-11-02 20:00:35,260 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:00:36,453 - Epoch: [53][   50/  391]    Overall Loss 0.357944    Objective Loss 0.357944    Top1 87.671875    Top5 99.578125    LR 0.300000    Time 0.023813    
2018-11-02 20:00:37,592 - Epoch: [53][  100/  391]    Overall Loss 0.375973    Objective Loss 0.375973    Top1 86.765625    Top5 99.507812    LR 0.300000    Time 0.023291    
2018-11-02 20:00:38,731 - Epoch: [53][  150/  391]    Overall Loss 0.371998    Objective Loss 0.371998    Top1 87.041667    Top5 99.583333    LR 0.300000    Time 0.023113    
2018-11-02 20:00:39,872 - Epoch: [53][  200/  391]    Overall Loss 0.371352    Objective Loss 0.371352    Top1 87.050781    Top5 99.582031    LR 0.300000    Time 0.023033    
2018-11-02 20:00:41,013 - Epoch: [53][  250/  391]    Overall Loss 0.372533    Objective Loss 0.372533    Top1 87.046875    Top5 99.578125    LR 0.300000    Time 0.022983    
2018-11-02 20:00:42,152 - Epoch: [53][  300/  391]    Overall Loss 0.374327    Objective Loss 0.374327    Top1 87.065104    Top5 99.593750    LR 0.300000    Time 0.022947    
2018-11-02 20:00:43,290 - Epoch: [53][  350/  391]    Overall Loss 0.376050    Objective Loss 0.376050    Top1 87.008929    Top5 99.587054    LR 0.300000    Time 0.022916    
2018-11-02 20:00:44,307 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58201 |  0.00151 |    0.38881 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15648 |  0.00083 |    0.09404 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15602 | -0.00090 |    0.10569 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19657 | -0.02173 |    0.13997 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19548 | -0.01017 |    0.14415 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19799 | -0.03038 |    0.14475 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17601 | -0.00369 |    0.12532 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21328 | -0.00518 |    0.15579 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18044 | -0.00498 |    0.13841 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39160 | -0.01234 |    0.27428 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.01168 |    0.11959 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13678 | -0.00887 |    0.10734 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15358 | -0.02505 |    0.12165 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12402 | -0.00297 |    0.09676 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15388 | -0.01691 |    0.12236 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13849 | -0.01111 |    0.10961 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21174 | -0.02507 |    0.16513 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13599 | -0.01505 |    0.10736 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10066 | -0.00225 |    0.07627 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07070 | -0.00349 |    0.05337 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05515 | -0.00511 |    0.04022 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59753 | -0.00001 |    0.46609 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:00:44,308 - Total sparsity: 0.00

2018-11-02 20:00:44,308 - --- validate (epoch=53)-----------
2018-11-02 20:00:44,308 - 10000 samples (128 per mini-batch)
2018-11-02 20:00:45,031 - Epoch: [53][   50/   78]    Loss 0.523950    Top1 82.656250    Top5 99.156250    
2018-11-02 20:00:45,433 - ==> Top1: 82.490    Top5: 99.240    Loss: 0.525

2018-11-02 20:00:45,434 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:00:45,435 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:00:45,446 - 

2018-11-02 20:00:45,446 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:00:46,644 - Epoch: [54][   50/  391]    Overall Loss 0.350548    Objective Loss 0.350548    Top1 87.500000    Top5 99.687500    LR 0.300000    Time 0.023915    
2018-11-02 20:00:47,782 - Epoch: [54][  100/  391]    Overall Loss 0.370063    Objective Loss 0.370063    Top1 87.210938    Top5 99.601562    LR 0.300000    Time 0.023326    
2018-11-02 20:00:48,922 - Epoch: [54][  150/  391]    Overall Loss 0.368931    Objective Loss 0.368931    Top1 87.364583    Top5 99.578125    LR 0.300000    Time 0.023140    
2018-11-02 20:00:50,059 - Epoch: [54][  200/  391]    Overall Loss 0.370926    Objective Loss 0.370926    Top1 87.250000    Top5 99.613281    LR 0.300000    Time 0.023036    
2018-11-02 20:00:51,197 - Epoch: [54][  250/  391]    Overall Loss 0.371896    Objective Loss 0.371896    Top1 87.275000    Top5 99.568750    LR 0.300000    Time 0.022976    
2018-11-02 20:00:52,336 - Epoch: [54][  300/  391]    Overall Loss 0.369939    Objective Loss 0.369939    Top1 87.270833    Top5 99.565104    LR 0.300000    Time 0.022938    
2018-11-02 20:00:53,475 - Epoch: [54][  350/  391]    Overall Loss 0.372503    Objective Loss 0.372503    Top1 87.223214    Top5 99.560268    LR 0.300000    Time 0.022912    
2018-11-02 20:00:54,485 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58026 | -0.00532 |    0.38549 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15580 | -0.00089 |    0.09356 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15583 | -0.00309 |    0.10598 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19659 | -0.01888 |    0.13953 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19438 | -0.00876 |    0.14459 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19668 | -0.03166 |    0.14347 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17610 | -0.00252 |    0.12631 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21293 | -0.00980 |    0.15590 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18004 | -0.00527 |    0.13786 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39322 | -0.01491 |    0.27971 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15651 | -0.01054 |    0.12008 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13719 | -0.00919 |    0.10758 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15388 | -0.02418 |    0.12147 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12392 | -0.00146 |    0.09636 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15366 | -0.01602 |    0.12210 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13846 | -0.01151 |    0.10965 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21239 | -0.02584 |    0.16444 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13609 | -0.01462 |    0.10738 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10058 | -0.00204 |    0.07616 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07104 | -0.00344 |    0.05371 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05537 | -0.00508 |    0.04048 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59512 | -0.00001 |    0.46347 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:00:54,486 - Total sparsity: 0.00

2018-11-02 20:00:54,486 - --- validate (epoch=54)-----------
2018-11-02 20:00:54,486 - 10000 samples (128 per mini-batch)
2018-11-02 20:00:55,208 - Epoch: [54][   50/   78]    Loss 0.634381    Top1 80.484375    Top5 98.250000    
2018-11-02 20:00:55,601 - ==> Top1: 80.160    Top5: 98.240    Loss: 0.637

2018-11-02 20:00:55,602 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:00:55,602 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:00:55,610 - 

2018-11-02 20:00:55,611 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:00:56,803 - Epoch: [55][   50/  391]    Overall Loss 0.344069    Objective Loss 0.344069    Top1 88.000000    Top5 99.734375    LR 0.300000    Time 0.023825    
2018-11-02 20:00:57,940 - Epoch: [55][  100/  391]    Overall Loss 0.353645    Objective Loss 0.353645    Top1 87.750000    Top5 99.640625    LR 0.300000    Time 0.023267    
2018-11-02 20:00:59,079 - Epoch: [55][  150/  391]    Overall Loss 0.359416    Objective Loss 0.359416    Top1 87.640625    Top5 99.614583    LR 0.300000    Time 0.023092    
2018-11-02 20:01:00,221 - Epoch: [55][  200/  391]    Overall Loss 0.367123    Objective Loss 0.367123    Top1 87.347656    Top5 99.566406    LR 0.300000    Time 0.023024    
2018-11-02 20:01:01,361 - Epoch: [55][  250/  391]    Overall Loss 0.372761    Objective Loss 0.372761    Top1 87.225000    Top5 99.543750    LR 0.300000    Time 0.022975    
2018-11-02 20:01:02,499 - Epoch: [55][  300/  391]    Overall Loss 0.373435    Objective Loss 0.373435    Top1 87.247396    Top5 99.565104    LR 0.300000    Time 0.022935    
2018-11-02 20:01:03,637 - Epoch: [55][  350/  391]    Overall Loss 0.372927    Objective Loss 0.372927    Top1 87.196429    Top5 99.573661    LR 0.300000    Time 0.022908    
2018-11-02 20:01:04,653 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58290 | -0.01578 |    0.38976 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15425 |  0.00012 |    0.09302 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15431 | -0.00427 |    0.10545 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19716 | -0.01769 |    0.13968 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19442 | -0.00749 |    0.14399 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19651 | -0.02943 |    0.14368 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17541 |  0.00093 |    0.12568 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21275 | -0.00813 |    0.15505 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17964 | -0.00574 |    0.13774 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39230 | -0.01520 |    0.27312 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15623 | -0.01021 |    0.11970 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13680 | -0.00888 |    0.10705 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15312 | -0.02394 |    0.12038 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12291 | -0.00168 |    0.09583 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15329 | -0.01568 |    0.12190 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13806 | -0.01063 |    0.10908 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21229 | -0.02668 |    0.16420 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13535 | -0.01498 |    0.10689 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10020 | -0.00233 |    0.07590 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07101 | -0.00387 |    0.05376 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05540 | -0.00497 |    0.04047 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59626 | -0.00001 |    0.46540 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:01:04,653 - Total sparsity: 0.00

2018-11-02 20:01:04,653 - --- validate (epoch=55)-----------
2018-11-02 20:01:04,654 - 10000 samples (128 per mini-batch)
2018-11-02 20:01:05,379 - Epoch: [55][   50/   78]    Loss 0.594812    Top1 80.515625    Top5 98.671875    
2018-11-02 20:01:05,771 - ==> Top1: 80.610    Top5: 98.730    Loss: 0.601

2018-11-02 20:01:05,772 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:01:05,772 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:01:05,787 - 

2018-11-02 20:01:05,787 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:01:06,983 - Epoch: [56][   50/  391]    Overall Loss 0.345345    Objective Loss 0.345345    Top1 88.531250    Top5 99.500000    LR 0.300000    Time 0.023886    
2018-11-02 20:01:08,123 - Epoch: [56][  100/  391]    Overall Loss 0.357246    Objective Loss 0.357246    Top1 87.992188    Top5 99.578125    LR 0.300000    Time 0.023329    
2018-11-02 20:01:09,263 - Epoch: [56][  150/  391]    Overall Loss 0.361197    Objective Loss 0.361197    Top1 87.671875    Top5 99.604167    LR 0.300000    Time 0.023148    
2018-11-02 20:01:10,404 - Epoch: [56][  200/  391]    Overall Loss 0.360559    Objective Loss 0.360559    Top1 87.695312    Top5 99.628906    LR 0.300000    Time 0.023059    
2018-11-02 20:01:11,546 - Epoch: [56][  250/  391]    Overall Loss 0.363762    Objective Loss 0.363762    Top1 87.512500    Top5 99.621875    LR 0.300000    Time 0.023009    
2018-11-02 20:01:12,686 - Epoch: [56][  300/  391]    Overall Loss 0.368570    Objective Loss 0.368570    Top1 87.356771    Top5 99.604167    LR 0.300000    Time 0.022970    
2018-11-02 20:01:13,826 - Epoch: [56][  350/  391]    Overall Loss 0.373027    Objective Loss 0.373027    Top1 87.247768    Top5 99.569196    LR 0.300000    Time 0.022941    
2018-11-02 20:01:14,841 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58493 | -0.00745 |    0.39175 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15364 | -0.00065 |    0.09328 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15398 | -0.00522 |    0.10492 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19564 | -0.01976 |    0.13866 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19389 | -0.01288 |    0.14356 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19542 | -0.03003 |    0.14363 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17463 |  0.00003 |    0.12521 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21233 | -0.00883 |    0.15456 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17918 | -0.00427 |    0.13746 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39212 | -0.01523 |    0.27321 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15584 | -0.01022 |    0.11951 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13664 | -0.00837 |    0.10731 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15334 | -0.02241 |    0.12043 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12302 | -0.00176 |    0.09599 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15328 | -0.01576 |    0.12191 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13815 | -0.01068 |    0.10904 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21205 | -0.02649 |    0.16539 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13551 | -0.01466 |    0.10695 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10050 | -0.00255 |    0.07608 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07157 | -0.00435 |    0.05428 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05587 | -0.00520 |    0.04086 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59387 | -0.00001 |    0.46404 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:01:14,841 - Total sparsity: 0.00

2018-11-02 20:01:14,841 - --- validate (epoch=56)-----------
2018-11-02 20:01:14,841 - 10000 samples (128 per mini-batch)
2018-11-02 20:01:15,568 - Epoch: [56][   50/   78]    Loss 0.667247    Top1 80.812500    Top5 98.484375    
2018-11-02 20:01:15,963 - ==> Top1: 80.860    Top5: 98.560    Loss: 0.659

2018-11-02 20:01:15,964 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:01:15,964 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:01:15,976 - 

2018-11-02 20:01:15,976 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:01:17,172 - Epoch: [57][   50/  391]    Overall Loss 0.374834    Objective Loss 0.374834    Top1 86.968750    Top5 99.656250    LR 0.300000    Time 0.023884    
2018-11-02 20:01:18,314 - Epoch: [57][  100/  391]    Overall Loss 0.366924    Objective Loss 0.366924    Top1 87.250000    Top5 99.671875    LR 0.300000    Time 0.023345    
2018-11-02 20:01:19,453 - Epoch: [57][  150/  391]    Overall Loss 0.360865    Objective Loss 0.360865    Top1 87.421875    Top5 99.661458    LR 0.300000    Time 0.023149    
2018-11-02 20:01:20,595 - Epoch: [57][  200/  391]    Overall Loss 0.370653    Objective Loss 0.370653    Top1 87.117188    Top5 99.605469    LR 0.300000    Time 0.023069    
2018-11-02 20:01:21,737 - Epoch: [57][  250/  391]    Overall Loss 0.373476    Objective Loss 0.373476    Top1 87.034375    Top5 99.615625    LR 0.300000    Time 0.023018    
2018-11-02 20:01:22,877 - Epoch: [57][  300/  391]    Overall Loss 0.371497    Objective Loss 0.371497    Top1 87.140625    Top5 99.625000    LR 0.300000    Time 0.022975    
2018-11-02 20:01:24,018 - Epoch: [57][  350/  391]    Overall Loss 0.372047    Objective Loss 0.372047    Top1 87.203125    Top5 99.620536    LR 0.300000    Time 0.022948    
2018-11-02 20:01:25,030 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58860 | -0.00856 |    0.39534 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15290 | -0.00200 |    0.09341 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15349 | -0.00093 |    0.10533 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19505 | -0.02148 |    0.13889 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19367 | -0.01102 |    0.14433 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19486 | -0.03223 |    0.14379 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17462 |  0.00026 |    0.12558 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21151 | -0.00903 |    0.15380 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17920 | -0.00479 |    0.13802 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39201 | -0.01773 |    0.27659 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15553 | -0.01006 |    0.11918 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13661 | -0.00792 |    0.10731 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15286 | -0.02334 |    0.12024 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12275 | -0.00045 |    0.09565 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15340 | -0.01626 |    0.12185 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13813 | -0.01054 |    0.10902 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21244 | -0.02467 |    0.16594 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13545 | -0.01458 |    0.10685 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10069 | -0.00224 |    0.07638 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07219 | -0.00464 |    0.05466 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05608 | -0.00476 |    0.04093 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59699 | -0.00001 |    0.46728 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:01:25,030 - Total sparsity: 0.00

2018-11-02 20:01:25,030 - --- validate (epoch=57)-----------
2018-11-02 20:01:25,030 - 10000 samples (128 per mini-batch)
2018-11-02 20:01:25,754 - Epoch: [57][   50/   78]    Loss 0.468330    Top1 84.093750    Top5 99.359375    
2018-11-02 20:01:26,145 - ==> Top1: 84.230    Top5: 99.400    Loss: 0.459

2018-11-02 20:01:26,146 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:01:26,146 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:01:26,154 - 

2018-11-02 20:01:26,155 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:01:27,348 - Epoch: [58][   50/  391]    Overall Loss 0.355721    Objective Loss 0.355721    Top1 87.812500    Top5 99.703125    LR 0.300000    Time 0.023832    
2018-11-02 20:01:28,486 - Epoch: [58][  100/  391]    Overall Loss 0.365274    Objective Loss 0.365274    Top1 87.468750    Top5 99.656250    LR 0.300000    Time 0.023284    
2018-11-02 20:01:29,626 - Epoch: [58][  150/  391]    Overall Loss 0.371087    Objective Loss 0.371087    Top1 87.223958    Top5 99.625000    LR 0.300000    Time 0.023114    
2018-11-02 20:01:30,765 - Epoch: [58][  200/  391]    Overall Loss 0.367221    Objective Loss 0.367221    Top1 87.343750    Top5 99.605469    LR 0.300000    Time 0.023025    
2018-11-02 20:01:31,906 - Epoch: [58][  250/  391]    Overall Loss 0.368508    Objective Loss 0.368508    Top1 87.346875    Top5 99.615625    LR 0.300000    Time 0.022976    
2018-11-02 20:01:33,046 - Epoch: [58][  300/  391]    Overall Loss 0.370560    Objective Loss 0.370560    Top1 87.221354    Top5 99.604167    LR 0.300000    Time 0.022945    
2018-11-02 20:01:34,185 - Epoch: [58][  350/  391]    Overall Loss 0.370076    Objective Loss 0.370076    Top1 87.205357    Top5 99.593750    LR 0.300000    Time 0.022916    
2018-11-02 20:01:35,199 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58601 |  0.00227 |    0.39164 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15283 | -0.00046 |    0.09292 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15376 | -0.00237 |    0.10573 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19650 | -0.02139 |    0.14040 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19538 | -0.00702 |    0.14484 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19737 | -0.02944 |    0.14473 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17608 | -0.00003 |    0.12721 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21226 | -0.01006 |    0.15462 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17944 | -0.00349 |    0.13750 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39308 | -0.01717 |    0.27638 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15523 | -0.01102 |    0.11958 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13638 | -0.00758 |    0.10699 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15371 | -0.02291 |    0.12096 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12309 | -0.00188 |    0.09567 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15371 | -0.01514 |    0.12202 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13840 | -0.01075 |    0.10930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21287 | -0.02617 |    0.16606 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13577 | -0.01476 |    0.10723 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10090 | -0.00283 |    0.07649 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07259 | -0.00419 |    0.05503 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05651 | -0.00445 |    0.04126 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59401 | -0.00001 |    0.46442 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:01:35,199 - Total sparsity: 0.00

2018-11-02 20:01:35,199 - --- validate (epoch=58)-----------
2018-11-02 20:01:35,200 - 10000 samples (128 per mini-batch)
2018-11-02 20:01:35,917 - Epoch: [58][   50/   78]    Loss 0.710647    Top1 78.328125    Top5 98.359375    
2018-11-02 20:01:36,306 - ==> Top1: 78.290    Top5: 98.530    Loss: 0.711

2018-11-02 20:01:36,307 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:01:36,307 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:01:36,316 - 

2018-11-02 20:01:36,316 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:01:37,512 - Epoch: [59][   50/  391]    Overall Loss 0.356405    Objective Loss 0.356405    Top1 87.687500    Top5 99.546875    LR 0.300000    Time 0.023896    
2018-11-02 20:01:38,651 - Epoch: [59][  100/  391]    Overall Loss 0.350846    Objective Loss 0.350846    Top1 87.804688    Top5 99.578125    LR 0.300000    Time 0.023319    
2018-11-02 20:01:39,789 - Epoch: [59][  150/  391]    Overall Loss 0.356522    Objective Loss 0.356522    Top1 87.552083    Top5 99.609375    LR 0.300000    Time 0.023127    
2018-11-02 20:01:40,931 - Epoch: [59][  200/  391]    Overall Loss 0.359850    Objective Loss 0.359850    Top1 87.503906    Top5 99.570312    LR 0.300000    Time 0.023049    
2018-11-02 20:01:42,071 - Epoch: [59][  250/  391]    Overall Loss 0.364711    Objective Loss 0.364711    Top1 87.321875    Top5 99.575000    LR 0.300000    Time 0.022979    
2018-11-02 20:01:43,211 - Epoch: [59][  300/  391]    Overall Loss 0.368613    Objective Loss 0.368613    Top1 87.153646    Top5 99.562500    LR 0.300000    Time 0.022944    
2018-11-02 20:01:44,352 - Epoch: [59][  350/  391]    Overall Loss 0.370577    Objective Loss 0.370577    Top1 87.095982    Top5 99.564732    LR 0.300000    Time 0.022922    
2018-11-02 20:01:45,370 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58344 |  0.00197 |    0.38667 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15253 | -0.00129 |    0.09221 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15374 | -0.00296 |    0.10486 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19632 | -0.02156 |    0.14088 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19506 | -0.01051 |    0.14528 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19728 | -0.02951 |    0.14544 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17654 |  0.00275 |    0.12793 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21196 | -0.01159 |    0.15440 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17898 | -0.00589 |    0.13719 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39402 | -0.01477 |    0.27482 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15486 | -0.01103 |    0.11887 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13599 | -0.00892 |    0.10700 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15309 | -0.02448 |    0.12088 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12235 | -0.00141 |    0.09511 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15332 | -0.01507 |    0.12189 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13851 | -0.01052 |    0.10964 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21293 | -0.02691 |    0.16600 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13593 | -0.01473 |    0.10733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10105 | -0.00322 |    0.07668 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07292 | -0.00498 |    0.05542 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05678 | -0.00452 |    0.04148 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59524 | -0.00000 |    0.46574 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:01:45,370 - Total sparsity: 0.00

2018-11-02 20:01:45,370 - --- validate (epoch=59)-----------
2018-11-02 20:01:45,370 - 10000 samples (128 per mini-batch)
2018-11-02 20:01:46,088 - Epoch: [59][   50/   78]    Loss 0.567302    Top1 81.859375    Top5 98.968750    
2018-11-02 20:01:46,480 - ==> Top1: 81.570    Top5: 99.030    Loss: 0.575

2018-11-02 20:01:46,481 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:01:46,481 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:01:46,493 - 

2018-11-02 20:01:46,493 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:01:47,689 - Epoch: [60][   50/  391]    Overall Loss 0.358251    Objective Loss 0.358251    Top1 87.812500    Top5 99.546875    LR 0.300000    Time 0.023893    
2018-11-02 20:01:48,829 - Epoch: [60][  100/  391]    Overall Loss 0.360223    Objective Loss 0.360223    Top1 87.523438    Top5 99.617188    LR 0.300000    Time 0.023326    
2018-11-02 20:01:49,968 - Epoch: [60][  150/  391]    Overall Loss 0.363785    Objective Loss 0.363785    Top1 87.375000    Top5 99.526042    LR 0.300000    Time 0.023137    
2018-11-02 20:01:51,106 - Epoch: [60][  200/  391]    Overall Loss 0.370346    Objective Loss 0.370346    Top1 87.238281    Top5 99.535156    LR 0.300000    Time 0.023038    
2018-11-02 20:01:52,245 - Epoch: [60][  250/  391]    Overall Loss 0.369158    Objective Loss 0.369158    Top1 87.284375    Top5 99.556250    LR 0.300000    Time 0.022968    
2018-11-02 20:01:53,382 - Epoch: [60][  300/  391]    Overall Loss 0.368584    Objective Loss 0.368584    Top1 87.289062    Top5 99.554688    LR 0.300000    Time 0.022923    
2018-11-02 20:01:54,520 - Epoch: [60][  350/  391]    Overall Loss 0.371470    Objective Loss 0.371470    Top1 87.236607    Top5 99.540179    LR 0.300000    Time 0.022897    
2018-11-02 20:01:55,537 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58161 | -0.01213 |    0.38699 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15316 | -0.00009 |    0.09270 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15376 | -0.00047 |    0.10522 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19564 | -0.02223 |    0.13995 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19511 | -0.00664 |    0.14469 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19684 | -0.02817 |    0.14525 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17688 |  0.00130 |    0.12739 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21280 | -0.00733 |    0.15464 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17934 | -0.00562 |    0.13739 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39332 | -0.01627 |    0.27621 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15546 | -0.00892 |    0.11969 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13660 | -0.00718 |    0.10767 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15357 | -0.02341 |    0.12133 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12225 | -0.00272 |    0.09467 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15334 | -0.01424 |    0.12182 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13870 | -0.01040 |    0.10967 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21250 | -0.02545 |    0.16650 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13614 | -0.01477 |    0.10748 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10135 | -0.00318 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07348 | -0.00506 |    0.05575 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05710 | -0.00437 |    0.04169 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59472 | -0.00000 |    0.46563 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:01:55,537 - Total sparsity: 0.00

2018-11-02 20:01:55,538 - --- validate (epoch=60)-----------
2018-11-02 20:01:55,538 - 10000 samples (128 per mini-batch)
2018-11-02 20:01:56,308 - Epoch: [60][   50/   78]    Loss 0.611825    Top1 80.156250    Top5 99.062500    
2018-11-02 20:01:56,714 - ==> Top1: 80.160    Top5: 99.130    Loss: 0.613

2018-11-02 20:01:56,715 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:01:56,715 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:01:56,724 - 

2018-11-02 20:01:56,724 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:01:57,918 - Epoch: [61][   50/  391]    Overall Loss 0.377001    Objective Loss 0.377001    Top1 86.578125    Top5 99.546875    LR 0.300000    Time 0.023839    
2018-11-02 20:01:59,059 - Epoch: [61][  100/  391]    Overall Loss 0.370452    Objective Loss 0.370452    Top1 87.289062    Top5 99.578125    LR 0.300000    Time 0.023316    
2018-11-02 20:02:00,202 - Epoch: [61][  150/  391]    Overall Loss 0.373855    Objective Loss 0.373855    Top1 87.192708    Top5 99.578125    LR 0.300000    Time 0.023156    
2018-11-02 20:02:01,343 - Epoch: [61][  200/  391]    Overall Loss 0.372166    Objective Loss 0.372166    Top1 87.253906    Top5 99.578125    LR 0.300000    Time 0.023066    
2018-11-02 20:02:02,484 - Epoch: [61][  250/  391]    Overall Loss 0.376301    Objective Loss 0.376301    Top1 87.062500    Top5 99.553125    LR 0.300000    Time 0.023013    
2018-11-02 20:02:03,627 - Epoch: [61][  300/  391]    Overall Loss 0.374283    Objective Loss 0.374283    Top1 87.151042    Top5 99.562500    LR 0.300000    Time 0.022983    
2018-11-02 20:02:04,766 - Epoch: [61][  350/  391]    Overall Loss 0.370377    Objective Loss 0.370377    Top1 87.216518    Top5 99.584821    LR 0.300000    Time 0.022950    
2018-11-02 20:02:05,780 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58484 |  0.00306 |    0.39041 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15438 | -0.00197 |    0.09390 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15516 |  0.00211 |    0.10572 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19627 | -0.02331 |    0.14048 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19493 | -0.00851 |    0.14464 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19734 | -0.02749 |    0.14562 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17776 |  0.00351 |    0.12810 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21337 | -0.00699 |    0.15579 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17991 | -0.00590 |    0.13801 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39465 | -0.01665 |    0.27438 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15635 | -0.01039 |    0.11992 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13751 | -0.00751 |    0.10828 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15398 | -0.02410 |    0.12186 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12216 | -0.00302 |    0.09472 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15340 | -0.01565 |    0.12201 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13889 | -0.00989 |    0.10987 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21239 | -0.02359 |    0.16483 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13628 | -0.01419 |    0.10747 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10130 | -0.00335 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07382 | -0.00517 |    0.05610 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05715 | -0.00496 |    0.04178 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59633 | -0.00000 |    0.46609 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:02:05,780 - Total sparsity: 0.00

2018-11-02 20:02:05,780 - --- validate (epoch=61)-----------
2018-11-02 20:02:05,780 - 10000 samples (128 per mini-batch)
2018-11-02 20:02:06,502 - Epoch: [61][   50/   78]    Loss 0.530655    Top1 83.328125    Top5 99.187500    
2018-11-02 20:02:06,893 - ==> Top1: 83.450    Top5: 99.140    Loss: 0.526

2018-11-02 20:02:06,894 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:02:06,894 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:02:06,908 - 

2018-11-02 20:02:06,909 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:02:08,103 - Epoch: [62][   50/  391]    Overall Loss 0.373307    Objective Loss 0.373307    Top1 86.562500    Top5 99.671875    LR 0.300000    Time 0.023859    
2018-11-02 20:02:09,243 - Epoch: [62][  100/  391]    Overall Loss 0.370972    Objective Loss 0.370972    Top1 87.054688    Top5 99.593750    LR 0.300000    Time 0.023307    
2018-11-02 20:02:10,381 - Epoch: [62][  150/  391]    Overall Loss 0.371886    Objective Loss 0.371886    Top1 87.072917    Top5 99.583333    LR 0.300000    Time 0.023122    
2018-11-02 20:02:11,519 - Epoch: [62][  200/  391]    Overall Loss 0.369283    Objective Loss 0.369283    Top1 87.101562    Top5 99.582031    LR 0.300000    Time 0.023022    
2018-11-02 20:02:12,655 - Epoch: [62][  250/  391]    Overall Loss 0.371146    Objective Loss 0.371146    Top1 87.184375    Top5 99.534375    LR 0.300000    Time 0.022958    
2018-11-02 20:02:13,794 - Epoch: [62][  300/  391]    Overall Loss 0.372086    Objective Loss 0.372086    Top1 87.127604    Top5 99.531250    LR 0.300000    Time 0.022924    
2018-11-02 20:02:14,932 - Epoch: [62][  350/  391]    Overall Loss 0.372854    Objective Loss 0.372854    Top1 87.084821    Top5 99.533482    LR 0.300000    Time 0.022888    
2018-11-02 20:02:15,946 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59279 | -0.00416 |    0.39543 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15664 | -0.00021 |    0.09469 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15697 |  0.00057 |    0.10811 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19863 | -0.02190 |    0.14106 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19566 | -0.01049 |    0.14664 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19781 | -0.02713 |    0.14437 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17725 |  0.00078 |    0.12851 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21389 | -0.00631 |    0.15523 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18078 | -0.00671 |    0.13845 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39608 | -0.01538 |    0.27810 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15690 | -0.01063 |    0.12064 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13816 | -0.00734 |    0.10877 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15478 | -0.02166 |    0.12236 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12240 | -0.00249 |    0.09505 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15425 | -0.01538 |    0.12265 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13927 | -0.01058 |    0.11029 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21239 | -0.02372 |    0.16549 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13673 | -0.01400 |    0.10785 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10173 | -0.00305 |    0.07692 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07447 | -0.00526 |    0.05666 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05772 | -0.00441 |    0.04203 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58919 | -0.00000 |    0.46179 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:02:15,947 - Total sparsity: 0.00

2018-11-02 20:02:15,947 - --- validate (epoch=62)-----------
2018-11-02 20:02:15,947 - 10000 samples (128 per mini-batch)
2018-11-02 20:02:16,668 - Epoch: [62][   50/   78]    Loss 0.667681    Top1 78.562500    Top5 98.390625    
2018-11-02 20:02:17,057 - ==> Top1: 78.670    Top5: 98.500    Loss: 0.664

2018-11-02 20:02:17,058 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:02:17,058 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:02:17,070 - 

2018-11-02 20:02:17,071 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:02:18,265 - Epoch: [63][   50/  391]    Overall Loss 0.371705    Objective Loss 0.371705    Top1 87.250000    Top5 99.562500    LR 0.300000    Time 0.023864    
2018-11-02 20:02:19,402 - Epoch: [63][  100/  391]    Overall Loss 0.364246    Objective Loss 0.364246    Top1 87.367188    Top5 99.601562    LR 0.300000    Time 0.023290    
2018-11-02 20:02:20,542 - Epoch: [63][  150/  391]    Overall Loss 0.364779    Objective Loss 0.364779    Top1 87.348958    Top5 99.609375    LR 0.300000    Time 0.023114    
2018-11-02 20:02:21,681 - Epoch: [63][  200/  391]    Overall Loss 0.362288    Objective Loss 0.362288    Top1 87.441406    Top5 99.617188    LR 0.300000    Time 0.023024    
2018-11-02 20:02:22,817 - Epoch: [63][  250/  391]    Overall Loss 0.365628    Objective Loss 0.365628    Top1 87.362500    Top5 99.600000    LR 0.300000    Time 0.022958    
2018-11-02 20:02:23,955 - Epoch: [63][  300/  391]    Overall Loss 0.367478    Objective Loss 0.367478    Top1 87.348958    Top5 99.588542    LR 0.300000    Time 0.022922    
2018-11-02 20:02:25,096 - Epoch: [63][  350/  391]    Overall Loss 0.366994    Objective Loss 0.366994    Top1 87.323661    Top5 99.602679    LR 0.300000    Time 0.022903    
2018-11-02 20:02:26,112 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58696 |  0.00427 |    0.38815 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15527 | -0.00188 |    0.09359 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15630 | -0.00009 |    0.10842 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19729 | -0.02010 |    0.14061 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19380 | -0.01329 |    0.14408 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19730 | -0.02719 |    0.14424 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17679 |  0.00088 |    0.12888 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21322 | -0.00879 |    0.15530 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18059 | -0.00659 |    0.13775 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39379 | -0.02026 |    0.27939 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15639 | -0.01005 |    0.12032 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13790 | -0.00732 |    0.10867 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15428 | -0.02220 |    0.12197 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12252 | -0.00233 |    0.09501 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15402 | -0.01517 |    0.12249 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13897 | -0.01085 |    0.10990 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21218 | -0.02298 |    0.16580 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13623 | -0.01460 |    0.10758 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10163 | -0.00344 |    0.07687 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07472 | -0.00484 |    0.05687 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05797 | -0.00412 |    0.04226 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59121 | -0.00000 |    0.46438 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:02:26,112 - Total sparsity: 0.00

2018-11-02 20:02:26,112 - --- validate (epoch=63)-----------
2018-11-02 20:02:26,112 - 10000 samples (128 per mini-batch)
2018-11-02 20:02:26,835 - Epoch: [63][   50/   78]    Loss 0.523905    Top1 83.140625    Top5 99.281250    
2018-11-02 20:02:27,225 - ==> Top1: 83.170    Top5: 99.270    Loss: 0.518

2018-11-02 20:02:27,226 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:02:27,226 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:02:27,234 - 

2018-11-02 20:02:27,234 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:02:28,432 - Epoch: [64][   50/  391]    Overall Loss 0.349117    Objective Loss 0.349117    Top1 88.140625    Top5 99.640625    LR 0.300000    Time 0.023913    
2018-11-02 20:02:29,571 - Epoch: [64][  100/  391]    Overall Loss 0.355823    Objective Loss 0.355823    Top1 87.789062    Top5 99.585938    LR 0.300000    Time 0.023342    
2018-11-02 20:02:30,712 - Epoch: [64][  150/  391]    Overall Loss 0.362368    Objective Loss 0.362368    Top1 87.489583    Top5 99.583333    LR 0.300000    Time 0.023157    
2018-11-02 20:02:31,851 - Epoch: [64][  200/  391]    Overall Loss 0.362702    Objective Loss 0.362702    Top1 87.484375    Top5 99.566406    LR 0.300000    Time 0.023038    
2018-11-02 20:02:32,992 - Epoch: [64][  250/  391]    Overall Loss 0.360772    Objective Loss 0.360772    Top1 87.571875    Top5 99.568750    LR 0.300000    Time 0.022988    
2018-11-02 20:02:34,130 - Epoch: [64][  300/  391]    Overall Loss 0.359008    Objective Loss 0.359008    Top1 87.710938    Top5 99.567708    LR 0.300000    Time 0.022947    
2018-11-02 20:02:35,271 - Epoch: [64][  350/  391]    Overall Loss 0.359938    Objective Loss 0.359938    Top1 87.658482    Top5 99.587054    LR 0.300000    Time 0.022925    
2018-11-02 20:02:36,282 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58403 | -0.00430 |    0.38605 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15536 | -0.00443 |    0.09306 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15636 | -0.00287 |    0.10863 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19721 | -0.01954 |    0.13984 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19486 | -0.01028 |    0.14586 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19596 | -0.02777 |    0.14339 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17628 |  0.00273 |    0.12857 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21273 | -0.00765 |    0.15539 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18023 | -0.00716 |    0.13764 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39422 | -0.01831 |    0.27581 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15689 | -0.01028 |    0.12054 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13838 | -0.00780 |    0.10905 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15405 | -0.02323 |    0.12202 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12253 | -0.00241 |    0.09535 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15373 | -0.01541 |    0.12244 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13891 | -0.01078 |    0.10976 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21272 | -0.02371 |    0.16571 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13624 | -0.01406 |    0.10732 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10140 | -0.00283 |    0.07680 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07496 | -0.00533 |    0.05720 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05803 | -0.00439 |    0.04236 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59209 | -0.00000 |    0.46396 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:02:36,283 - Total sparsity: 0.00

2018-11-02 20:02:36,283 - --- validate (epoch=64)-----------
2018-11-02 20:02:36,283 - 10000 samples (128 per mini-batch)
2018-11-02 20:02:37,004 - Epoch: [64][   50/   78]    Loss 0.494399    Top1 84.093750    Top5 99.109375    
2018-11-02 20:02:37,393 - ==> Top1: 84.130    Top5: 99.180    Loss: 0.489

2018-11-02 20:02:37,394 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:02:37,394 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:02:37,402 - 

2018-11-02 20:02:37,403 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:02:38,600 - Epoch: [65][   50/  391]    Overall Loss 0.369167    Objective Loss 0.369167    Top1 87.437500    Top5 99.562500    LR 0.300000    Time 0.023904    
2018-11-02 20:02:39,739 - Epoch: [65][  100/  391]    Overall Loss 0.358091    Objective Loss 0.358091    Top1 87.851562    Top5 99.601562    LR 0.300000    Time 0.023333    
2018-11-02 20:02:40,878 - Epoch: [65][  150/  391]    Overall Loss 0.363735    Objective Loss 0.363735    Top1 87.541667    Top5 99.552083    LR 0.300000    Time 0.023142    
2018-11-02 20:02:42,018 - Epoch: [65][  200/  391]    Overall Loss 0.371441    Objective Loss 0.371441    Top1 87.304688    Top5 99.519531    LR 0.300000    Time 0.023046    
2018-11-02 20:02:43,157 - Epoch: [65][  250/  391]    Overall Loss 0.376880    Objective Loss 0.376880    Top1 87.128125    Top5 99.506250    LR 0.300000    Time 0.022991    
2018-11-02 20:02:44,298 - Epoch: [65][  300/  391]    Overall Loss 0.371513    Objective Loss 0.371513    Top1 87.320312    Top5 99.526042    LR 0.300000    Time 0.022955    
2018-11-02 20:02:45,439 - Epoch: [65][  350/  391]    Overall Loss 0.369808    Objective Loss 0.369808    Top1 87.383929    Top5 99.540179    LR 0.300000    Time 0.022934    
2018-11-02 20:02:46,453 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58278 | -0.00017 |    0.38461 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15441 | -0.00016 |    0.09280 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15647 | -0.00362 |    0.10858 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19668 | -0.02091 |    0.13850 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19537 | -0.00417 |    0.14638 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19648 | -0.02902 |    0.14515 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17652 |  0.00037 |    0.12823 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21266 | -0.00940 |    0.15447 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18001 | -0.00631 |    0.13764 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39523 | -0.01706 |    0.27385 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15665 | -0.00956 |    0.12003 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13864 | -0.00752 |    0.10931 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15428 | -0.02211 |    0.12170 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12220 | -0.00273 |    0.09483 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15350 | -0.01517 |    0.12217 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13878 | -0.01078 |    0.10976 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21219 | -0.02385 |    0.16689 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13605 | -0.01465 |    0.10737 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10137 | -0.00305 |    0.07692 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07509 | -0.00467 |    0.05714 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05790 | -0.00407 |    0.04218 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59140 | -0.00000 |    0.46487 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:02:46,453 - Total sparsity: 0.00

2018-11-02 20:02:46,453 - --- validate (epoch=65)-----------
2018-11-02 20:02:46,453 - 10000 samples (128 per mini-batch)
2018-11-02 20:02:47,172 - Epoch: [65][   50/   78]    Loss 0.601330    Top1 80.781250    Top5 98.281250    
2018-11-02 20:02:47,562 - ==> Top1: 80.290    Top5: 98.440    Loss: 0.608

2018-11-02 20:02:47,563 - ==> Best Top1: 84.260   On Epoch: 37

2018-11-02 20:02:47,563 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:02:47,571 - 

2018-11-02 20:02:47,572 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:02:48,765 - Epoch: [66][   50/  391]    Overall Loss 0.343766    Objective Loss 0.343766    Top1 88.125000    Top5 99.796875    LR 0.300000    Time 0.023841    
2018-11-02 20:02:49,902 - Epoch: [66][  100/  391]    Overall Loss 0.354052    Objective Loss 0.354052    Top1 87.835938    Top5 99.671875    LR 0.300000    Time 0.023276    
2018-11-02 20:02:51,043 - Epoch: [66][  150/  391]    Overall Loss 0.356267    Objective Loss 0.356267    Top1 87.807292    Top5 99.656250    LR 0.300000    Time 0.023117    
2018-11-02 20:02:52,186 - Epoch: [66][  200/  391]    Overall Loss 0.359005    Objective Loss 0.359005    Top1 87.675781    Top5 99.628906    LR 0.300000    Time 0.023042    
2018-11-02 20:02:53,325 - Epoch: [66][  250/  391]    Overall Loss 0.359086    Objective Loss 0.359086    Top1 87.615625    Top5 99.603125    LR 0.300000    Time 0.022987    
2018-11-02 20:02:54,466 - Epoch: [66][  300/  391]    Overall Loss 0.363042    Objective Loss 0.363042    Top1 87.432292    Top5 99.580729    LR 0.300000    Time 0.022954    
2018-11-02 20:02:55,606 - Epoch: [66][  350/  391]    Overall Loss 0.363990    Objective Loss 0.363990    Top1 87.363839    Top5 99.578125    LR 0.300000    Time 0.022930    
2018-11-02 20:02:56,617 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57975 |  0.00670 |    0.38739 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15473 | -0.00110 |    0.09408 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15663 | -0.00440 |    0.10921 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19591 | -0.02009 |    0.13862 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19543 | -0.01106 |    0.14594 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19800 | -0.02866 |    0.14625 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17718 | -0.00002 |    0.12798 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21229 | -0.00911 |    0.15536 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17920 | -0.00640 |    0.13706 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39750 | -0.01286 |    0.27647 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15665 | -0.00927 |    0.11985 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13856 | -0.00793 |    0.10893 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15342 | -0.02206 |    0.12130 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12187 | -0.00223 |    0.09468 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15328 | -0.01524 |    0.12195 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13849 | -0.01108 |    0.10969 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21296 | -0.02223 |    0.16632 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13585 | -0.01487 |    0.10723 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10152 | -0.00308 |    0.07696 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07539 | -0.00512 |    0.05735 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05818 | -0.00380 |    0.04237 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59186 | -0.00000 |    0.46510 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:02:56,618 - Total sparsity: 0.00

2018-11-02 20:02:56,618 - --- validate (epoch=66)-----------
2018-11-02 20:02:56,618 - 10000 samples (128 per mini-batch)
2018-11-02 20:02:57,342 - Epoch: [66][   50/   78]    Loss 0.458660    Top1 84.984375    Top5 99.125000    
2018-11-02 20:02:57,734 - ==> Top1: 84.880    Top5: 99.160    Loss: 0.453

2018-11-02 20:02:57,735 - ==> Best Top1: 84.880   On Epoch: 66

2018-11-02 20:02:57,735 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:02:57,750 - 

2018-11-02 20:02:57,750 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:02:58,920 - Epoch: [67][   50/  391]    Overall Loss 0.337491    Objective Loss 0.337491    Top1 88.375000    Top5 99.671875    LR 0.300000    Time 0.023350    
2018-11-02 20:03:00,059 - Epoch: [67][  100/  391]    Overall Loss 0.345358    Objective Loss 0.345358    Top1 88.218750    Top5 99.609375    LR 0.300000    Time 0.023054    
2018-11-02 20:03:01,204 - Epoch: [67][  150/  391]    Overall Loss 0.358755    Objective Loss 0.358755    Top1 87.807292    Top5 99.593750    LR 0.300000    Time 0.022994    
2018-11-02 20:03:02,344 - Epoch: [67][  200/  391]    Overall Loss 0.358570    Objective Loss 0.358570    Top1 87.761719    Top5 99.613281    LR 0.300000    Time 0.022938    
2018-11-02 20:03:03,483 - Epoch: [67][  250/  391]    Overall Loss 0.359954    Objective Loss 0.359954    Top1 87.659375    Top5 99.615625    LR 0.300000    Time 0.022905    
2018-11-02 20:03:04,624 - Epoch: [67][  300/  391]    Overall Loss 0.361223    Objective Loss 0.361223    Top1 87.601562    Top5 99.611979    LR 0.300000    Time 0.022885    
2018-11-02 20:03:05,762 - Epoch: [67][  350/  391]    Overall Loss 0.362151    Objective Loss 0.362151    Top1 87.589286    Top5 99.580357    LR 0.300000    Time 0.022852    
2018-11-02 20:03:06,775 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57514 | -0.00033 |    0.38347 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15476 | -0.00029 |    0.09466 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15626 | -0.00242 |    0.10964 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19468 | -0.02187 |    0.13805 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19475 | -0.01166 |    0.14604 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19899 | -0.02695 |    0.14585 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17768 | -0.00091 |    0.12841 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21260 | -0.01018 |    0.15446 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17897 | -0.00633 |    0.13672 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39581 | -0.00919 |    0.27439 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15646 | -0.00953 |    0.11971 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13804 | -0.00851 |    0.10829 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15311 | -0.02235 |    0.12107 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12229 | -0.00206 |    0.09517 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15316 | -0.01500 |    0.12163 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13846 | -0.01039 |    0.10939 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21248 | -0.02115 |    0.16607 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13564 | -0.01451 |    0.10704 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10150 | -0.00282 |    0.07712 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07566 | -0.00530 |    0.05755 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05826 | -0.00362 |    0.04230 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59383 | -0.00000 |    0.46723 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:03:06,775 - Total sparsity: 0.00

2018-11-02 20:03:06,775 - --- validate (epoch=67)-----------
2018-11-02 20:03:06,775 - 10000 samples (128 per mini-batch)
2018-11-02 20:03:07,491 - Epoch: [67][   50/   78]    Loss 0.662499    Top1 80.062500    Top5 98.593750    
2018-11-02 20:03:07,880 - ==> Top1: 80.080    Top5: 98.690    Loss: 0.653

2018-11-02 20:03:07,881 - ==> Best Top1: 84.880   On Epoch: 66

2018-11-02 20:03:07,881 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:03:07,889 - 

2018-11-02 20:03:07,890 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:03:09,083 - Epoch: [68][   50/  391]    Overall Loss 0.378479    Objective Loss 0.378479    Top1 86.640625    Top5 99.609375    LR 0.300000    Time 0.023834    
2018-11-02 20:03:10,220 - Epoch: [68][  100/  391]    Overall Loss 0.375701    Objective Loss 0.375701    Top1 86.976562    Top5 99.609375    LR 0.300000    Time 0.023276    
2018-11-02 20:03:11,359 - Epoch: [68][  150/  391]    Overall Loss 0.367333    Objective Loss 0.367333    Top1 87.390625    Top5 99.567708    LR 0.300000    Time 0.023098    
2018-11-02 20:03:12,503 - Epoch: [68][  200/  391]    Overall Loss 0.356960    Objective Loss 0.356960    Top1 87.738281    Top5 99.617188    LR 0.300000    Time 0.023038    
2018-11-02 20:03:13,644 - Epoch: [68][  250/  391]    Overall Loss 0.361419    Objective Loss 0.361419    Top1 87.596875    Top5 99.590625    LR 0.300000    Time 0.022990    
2018-11-02 20:03:14,783 - Epoch: [68][  300/  391]    Overall Loss 0.364162    Objective Loss 0.364162    Top1 87.518229    Top5 99.559896    LR 0.300000    Time 0.022950    
2018-11-02 20:03:15,920 - Epoch: [68][  350/  391]    Overall Loss 0.366617    Objective Loss 0.366617    Top1 87.430804    Top5 99.551339    LR 0.300000    Time 0.022915    
2018-11-02 20:03:16,938 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57644 | -0.00715 |    0.38454 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15504 | -0.00457 |    0.09465 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15627 | -0.00132 |    0.10911 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19362 | -0.02205 |    0.13696 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19504 | -0.00823 |    0.14563 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19860 | -0.02575 |    0.14620 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17696 |  0.00082 |    0.12832 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21274 | -0.00791 |    0.15393 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17929 | -0.00524 |    0.13740 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39388 | -0.00714 |    0.27033 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15675 | -0.01057 |    0.12063 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13827 | -0.00841 |    0.10898 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15268 | -0.02177 |    0.12010 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12187 | -0.00169 |    0.09508 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15333 | -0.01428 |    0.12197 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13872 | -0.01040 |    0.10984 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21372 | -0.02379 |    0.16716 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13600 | -0.01513 |    0.10734 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10195 | -0.00297 |    0.07737 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07641 | -0.00544 |    0.05817 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05881 | -0.00363 |    0.04272 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59265 | -0.00000 |    0.46500 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:03:16,938 - Total sparsity: 0.00

2018-11-02 20:03:16,938 - --- validate (epoch=68)-----------
2018-11-02 20:03:16,938 - 10000 samples (128 per mini-batch)
2018-11-02 20:03:17,658 - Epoch: [68][   50/   78]    Loss 0.687742    Top1 78.781250    Top5 98.593750    
2018-11-02 20:03:18,049 - ==> Top1: 78.560    Top5: 98.730    Loss: 0.691

2018-11-02 20:03:18,050 - ==> Best Top1: 84.880   On Epoch: 66

2018-11-02 20:03:18,050 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:03:18,062 - 

2018-11-02 20:03:18,062 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:03:19,258 - Epoch: [69][   50/  391]    Overall Loss 0.326471    Objective Loss 0.326471    Top1 88.640625    Top5 99.656250    LR 0.300000    Time 0.023892    
2018-11-02 20:03:20,395 - Epoch: [69][  100/  391]    Overall Loss 0.336309    Objective Loss 0.336309    Top1 88.414062    Top5 99.593750    LR 0.300000    Time 0.023301    
2018-11-02 20:03:21,534 - Epoch: [69][  150/  391]    Overall Loss 0.349757    Objective Loss 0.349757    Top1 87.989583    Top5 99.604167    LR 0.300000    Time 0.023114    
2018-11-02 20:03:22,673 - Epoch: [69][  200/  391]    Overall Loss 0.352988    Objective Loss 0.352988    Top1 87.804688    Top5 99.593750    LR 0.300000    Time 0.023025    
2018-11-02 20:03:23,811 - Epoch: [69][  250/  391]    Overall Loss 0.353973    Objective Loss 0.353973    Top1 87.771875    Top5 99.584375    LR 0.300000    Time 0.022969    
2018-11-02 20:03:24,950 - Epoch: [69][  300/  391]    Overall Loss 0.357665    Objective Loss 0.357665    Top1 87.718750    Top5 99.580729    LR 0.300000    Time 0.022934    
2018-11-02 20:03:26,090 - Epoch: [69][  350/  391]    Overall Loss 0.360153    Objective Loss 0.360153    Top1 87.660714    Top5 99.569196    LR 0.300000    Time 0.022910    
2018-11-02 20:03:27,106 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57501 |  0.00128 |    0.38394 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15465 | -0.00407 |    0.09430 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15573 | -0.00314 |    0.10886 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19269 | -0.02058 |    0.13592 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19492 | -0.01115 |    0.14576 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19840 | -0.02967 |    0.14578 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17718 |  0.00056 |    0.12795 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21220 | -0.00878 |    0.15411 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17931 | -0.00550 |    0.13743 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39264 | -0.01396 |    0.27146 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15701 | -0.01006 |    0.12049 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13836 | -0.00879 |    0.10873 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15281 | -0.02416 |    0.12061 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12218 | -0.00114 |    0.09550 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15325 | -0.01475 |    0.12178 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13862 | -0.01095 |    0.10982 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21459 | -0.02263 |    0.16713 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13601 | -0.01443 |    0.10724 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10195 | -0.00332 |    0.07739 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07656 | -0.00583 |    0.05848 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05866 | -0.00408 |    0.04266 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58703 | -0.00000 |    0.46267 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:03:27,106 - Total sparsity: 0.00

2018-11-02 20:03:27,106 - --- validate (epoch=69)-----------
2018-11-02 20:03:27,106 - 10000 samples (128 per mini-batch)
2018-11-02 20:03:27,831 - Epoch: [69][   50/   78]    Loss 0.458947    Top1 85.031250    Top5 99.375000    
2018-11-02 20:03:28,223 - ==> Top1: 85.230    Top5: 99.410    Loss: 0.453

2018-11-02 20:03:28,224 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 20:03:28,224 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:03:28,236 - 

2018-11-02 20:03:28,236 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:03:29,430 - Epoch: [70][   50/  391]    Overall Loss 0.325120    Objective Loss 0.325120    Top1 88.734375    Top5 99.578125    LR 0.300000    Time 0.023844    
2018-11-02 20:03:30,566 - Epoch: [70][  100/  391]    Overall Loss 0.337656    Objective Loss 0.337656    Top1 88.468750    Top5 99.648438    LR 0.300000    Time 0.023272    
2018-11-02 20:03:31,706 - Epoch: [70][  150/  391]    Overall Loss 0.350805    Objective Loss 0.350805    Top1 87.880208    Top5 99.598958    LR 0.300000    Time 0.023107    
2018-11-02 20:03:32,845 - Epoch: [70][  200/  391]    Overall Loss 0.355499    Objective Loss 0.355499    Top1 87.769531    Top5 99.578125    LR 0.300000    Time 0.023022    
2018-11-02 20:03:33,986 - Epoch: [70][  250/  391]    Overall Loss 0.355922    Objective Loss 0.355922    Top1 87.728125    Top5 99.575000    LR 0.300000    Time 0.022958    
2018-11-02 20:03:35,122 - Epoch: [70][  300/  391]    Overall Loss 0.355059    Objective Loss 0.355059    Top1 87.750000    Top5 99.562500    LR 0.300000    Time 0.022917    
2018-11-02 20:03:36,260 - Epoch: [70][  350/  391]    Overall Loss 0.358405    Objective Loss 0.358405    Top1 87.700893    Top5 99.555804    LR 0.300000    Time 0.022890    
2018-11-02 20:03:37,270 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57385 |  0.00725 |    0.38208 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15461 | -0.00234 |    0.09461 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15590 | -0.00279 |    0.10895 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19146 | -0.02221 |    0.13489 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19465 | -0.01383 |    0.14558 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19804 | -0.02797 |    0.14568 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17671 |  0.00098 |    0.12629 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21246 | -0.00873 |    0.15508 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17953 | -0.00551 |    0.13795 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39129 | -0.01571 |    0.27173 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15645 | -0.00895 |    0.11991 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13791 | -0.00769 |    0.10810 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15311 | -0.02373 |    0.12080 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12224 | -0.00195 |    0.09526 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15293 | -0.01448 |    0.12151 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13836 | -0.01073 |    0.10941 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21315 | -0.02434 |    0.16728 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13567 | -0.01477 |    0.10697 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10199 | -0.00369 |    0.07749 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07700 | -0.00591 |    0.05884 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05871 | -0.00364 |    0.04262 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58745 | -0.00000 |    0.46265 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:03:37,271 - Total sparsity: 0.00

2018-11-02 20:03:37,271 - --- validate (epoch=70)-----------
2018-11-02 20:03:37,271 - 10000 samples (128 per mini-batch)
2018-11-02 20:03:37,997 - Epoch: [70][   50/   78]    Loss 0.529082    Top1 83.062500    Top5 99.125000    
2018-11-02 20:03:38,391 - ==> Top1: 82.880    Top5: 99.160    Loss: 0.548

2018-11-02 20:03:38,391 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 20:03:38,392 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:03:38,400 - 

2018-11-02 20:03:38,400 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:03:39,596 - Epoch: [71][   50/  391]    Overall Loss 0.324568    Objective Loss 0.324568    Top1 88.437500    Top5 99.593750    LR 0.300000    Time 0.023882    
2018-11-02 20:03:40,736 - Epoch: [71][  100/  391]    Overall Loss 0.341827    Objective Loss 0.341827    Top1 88.023438    Top5 99.585938    LR 0.300000    Time 0.023329    
2018-11-02 20:03:41,879 - Epoch: [71][  150/  391]    Overall Loss 0.358082    Objective Loss 0.358082    Top1 87.562500    Top5 99.520833    LR 0.300000    Time 0.023159    
2018-11-02 20:03:43,020 - Epoch: [71][  200/  391]    Overall Loss 0.356161    Objective Loss 0.356161    Top1 87.609375    Top5 99.542969    LR 0.300000    Time 0.023070    
2018-11-02 20:03:44,158 - Epoch: [71][  250/  391]    Overall Loss 0.367224    Objective Loss 0.367224    Top1 87.256250    Top5 99.493750    LR 0.300000    Time 0.023001    
2018-11-02 20:03:45,299 - Epoch: [71][  300/  391]    Overall Loss 0.365446    Objective Loss 0.365446    Top1 87.309896    Top5 99.515625    LR 0.300000    Time 0.022967    
2018-11-02 20:03:46,437 - Epoch: [71][  350/  391]    Overall Loss 0.366375    Objective Loss 0.366375    Top1 87.339286    Top5 99.520089    LR 0.300000    Time 0.022935    
2018-11-02 20:03:47,453 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57406 |  0.00403 |    0.38070 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15404 | -0.00388 |    0.09330 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15581 | -0.00108 |    0.10828 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19116 | -0.02068 |    0.13523 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19466 | -0.01146 |    0.14642 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19880 | -0.03308 |    0.14700 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17707 |  0.00280 |    0.12699 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21237 | -0.00947 |    0.15477 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17905 | -0.00555 |    0.13781 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39311 | -0.01410 |    0.27385 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15653 | -0.01030 |    0.12007 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13738 | -0.00807 |    0.10780 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15272 | -0.02494 |    0.12080 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12236 | -0.00006 |    0.09532 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15275 | -0.01437 |    0.12158 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13829 | -0.01013 |    0.10944 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21407 | -0.02409 |    0.16866 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13600 | -0.01504 |    0.10717 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10221 | -0.00372 |    0.07783 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07766 | -0.00570 |    0.05937 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05920 | -0.00380 |    0.04302 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58744 | -0.00000 |    0.46199 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:03:47,453 - Total sparsity: 0.00

2018-11-02 20:03:47,453 - --- validate (epoch=71)-----------
2018-11-02 20:03:47,453 - 10000 samples (128 per mini-batch)
2018-11-02 20:03:48,174 - Epoch: [71][   50/   78]    Loss 0.791164    Top1 78.718750    Top5 98.218750    
2018-11-02 20:03:48,563 - ==> Top1: 78.440    Top5: 98.470    Loss: 0.784

2018-11-02 20:03:48,564 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 20:03:48,564 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:03:48,572 - 

2018-11-02 20:03:48,573 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:03:49,767 - Epoch: [72][   50/  391]    Overall Loss 0.349584    Objective Loss 0.349584    Top1 87.875000    Top5 99.562500    LR 0.300000    Time 0.023851    
2018-11-02 20:03:50,907 - Epoch: [72][  100/  391]    Overall Loss 0.355217    Objective Loss 0.355217    Top1 87.718750    Top5 99.578125    LR 0.300000    Time 0.023309    
2018-11-02 20:03:52,045 - Epoch: [72][  150/  391]    Overall Loss 0.358645    Objective Loss 0.358645    Top1 87.682292    Top5 99.583333    LR 0.300000    Time 0.023119    
2018-11-02 20:03:53,182 - Epoch: [72][  200/  391]    Overall Loss 0.364239    Objective Loss 0.364239    Top1 87.480469    Top5 99.535156    LR 0.300000    Time 0.023020    
2018-11-02 20:03:54,322 - Epoch: [72][  250/  391]    Overall Loss 0.362750    Objective Loss 0.362750    Top1 87.565625    Top5 99.556250    LR 0.300000    Time 0.022969    
2018-11-02 20:03:55,462 - Epoch: [72][  300/  391]    Overall Loss 0.359024    Objective Loss 0.359024    Top1 87.640625    Top5 99.580729    LR 0.300000    Time 0.022936    
2018-11-02 20:03:56,601 - Epoch: [72][  350/  391]    Overall Loss 0.360906    Objective Loss 0.360906    Top1 87.584821    Top5 99.573661    LR 0.300000    Time 0.022910    
2018-11-02 20:03:57,616 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57610 | -0.00670 |    0.38467 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15530 | -0.00328 |    0.09393 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15741 | -0.00066 |    0.10932 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19249 | -0.01963 |    0.13773 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19560 | -0.01332 |    0.14750 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19996 | -0.02826 |    0.14797 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17853 |  0.00154 |    0.12889 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21301 | -0.00844 |    0.15550 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17932 | -0.00613 |    0.13809 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39352 | -0.01773 |    0.27574 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15665 | -0.00958 |    0.11987 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13703 | -0.01024 |    0.10771 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15402 | -0.02459 |    0.12167 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12293 | -0.00050 |    0.09578 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15303 | -0.01510 |    0.12168 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13820 | -0.01032 |    0.10929 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21387 | -0.02425 |    0.16881 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01468 |    0.10707 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10225 | -0.00391 |    0.07785 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07814 | -0.00549 |    0.05975 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05936 | -0.00382 |    0.04307 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58326 | -0.00000 |    0.45963 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:03:57,616 - Total sparsity: 0.00

2018-11-02 20:03:57,617 - --- validate (epoch=72)-----------
2018-11-02 20:03:57,617 - 10000 samples (128 per mini-batch)
2018-11-02 20:03:58,339 - Epoch: [72][   50/   78]    Loss 0.530105    Top1 83.656250    Top5 98.828125    
2018-11-02 20:03:58,731 - ==> Top1: 83.680    Top5: 98.900    Loss: 0.528

2018-11-02 20:03:58,732 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 20:03:58,732 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:03:58,744 - 

2018-11-02 20:03:58,744 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:03:59,940 - Epoch: [73][   50/  391]    Overall Loss 0.353449    Objective Loss 0.353449    Top1 87.625000    Top5 99.609375    LR 0.300000    Time 0.023880    
2018-11-02 20:04:01,084 - Epoch: [73][  100/  391]    Overall Loss 0.363672    Objective Loss 0.363672    Top1 87.429688    Top5 99.601562    LR 0.300000    Time 0.023366    
2018-11-02 20:04:02,225 - Epoch: [73][  150/  391]    Overall Loss 0.366192    Objective Loss 0.366192    Top1 87.307292    Top5 99.588542    LR 0.300000    Time 0.023178    
2018-11-02 20:04:03,366 - Epoch: [73][  200/  391]    Overall Loss 0.368148    Objective Loss 0.368148    Top1 87.156250    Top5 99.613281    LR 0.300000    Time 0.023080    
2018-11-02 20:04:04,504 - Epoch: [73][  250/  391]    Overall Loss 0.368611    Objective Loss 0.368611    Top1 87.193750    Top5 99.587500    LR 0.300000    Time 0.023011    
2018-11-02 20:04:05,641 - Epoch: [73][  300/  391]    Overall Loss 0.372394    Objective Loss 0.372394    Top1 87.101562    Top5 99.567708    LR 0.300000    Time 0.022964    
2018-11-02 20:04:06,781 - Epoch: [73][  350/  391]    Overall Loss 0.372888    Objective Loss 0.372888    Top1 87.189732    Top5 99.562500    LR 0.300000    Time 0.022936    
2018-11-02 20:04:07,793 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57881 | -0.00347 |    0.38552 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15833 | -0.00077 |    0.09631 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15940 | -0.00048 |    0.11138 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19512 | -0.01890 |    0.14052 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19710 | -0.01235 |    0.14767 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19998 | -0.02794 |    0.14780 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17901 |  0.00203 |    0.12883 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21377 | -0.00915 |    0.15572 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17960 | -0.00612 |    0.13760 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39349 | -0.01861 |    0.27337 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15692 | -0.00932 |    0.11983 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13742 | -0.00987 |    0.10795 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15469 | -0.02396 |    0.12212 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12276 | -0.00085 |    0.09542 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15319 | -0.01473 |    0.12160 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13837 | -0.01090 |    0.10949 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21492 | -0.02411 |    0.16857 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13632 | -0.01478 |    0.10708 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10277 | -0.00376 |    0.07836 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07921 | -0.00572 |    0.06058 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06001 | -0.00383 |    0.04361 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58623 | -0.00000 |    0.46236 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:04:07,793 - Total sparsity: 0.00

2018-11-02 20:04:07,793 - --- validate (epoch=73)-----------
2018-11-02 20:04:07,793 - 10000 samples (128 per mini-batch)
2018-11-02 20:04:08,518 - Epoch: [73][   50/   78]    Loss 0.569891    Top1 82.406250    Top5 99.015625    
2018-11-02 20:04:08,909 - ==> Top1: 82.220    Top5: 99.060    Loss: 0.561

2018-11-02 20:04:08,910 - ==> Best Top1: 85.230   On Epoch: 69

2018-11-02 20:04:08,910 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:04:08,918 - 

2018-11-02 20:04:08,918 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:04:10,112 - Epoch: [74][   50/  391]    Overall Loss 0.344257    Objective Loss 0.344257    Top1 87.796875    Top5 99.562500    LR 0.300000    Time 0.023832    
2018-11-02 20:04:11,251 - Epoch: [74][  100/  391]    Overall Loss 0.353297    Objective Loss 0.353297    Top1 87.617188    Top5 99.554688    LR 0.300000    Time 0.023291    
2018-11-02 20:04:12,390 - Epoch: [74][  150/  391]    Overall Loss 0.352323    Objective Loss 0.352323    Top1 87.901042    Top5 99.526042    LR 0.300000    Time 0.023117    
2018-11-02 20:04:13,530 - Epoch: [74][  200/  391]    Overall Loss 0.353342    Objective Loss 0.353342    Top1 87.816406    Top5 99.546875    LR 0.300000    Time 0.023031    
2018-11-02 20:04:14,668 - Epoch: [74][  250/  391]    Overall Loss 0.359248    Objective Loss 0.359248    Top1 87.584375    Top5 99.553125    LR 0.300000    Time 0.022973    
2018-11-02 20:04:15,807 - Epoch: [74][  300/  391]    Overall Loss 0.361720    Objective Loss 0.361720    Top1 87.489583    Top5 99.567708    LR 0.300000    Time 0.022936    
2018-11-02 20:04:16,946 - Epoch: [74][  350/  391]    Overall Loss 0.368442    Objective Loss 0.368442    Top1 87.252232    Top5 99.569196    LR 0.300000    Time 0.022909    
2018-11-02 20:04:17,958 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58433 |  0.00515 |    0.38813 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16141 |  0.00051 |    0.09762 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16108 |  0.00274 |    0.11220 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19513 | -0.01765 |    0.13906 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19696 | -0.01302 |    0.14854 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19970 | -0.02870 |    0.14760 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17940 |  0.00114 |    0.12928 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21475 | -0.00962 |    0.15668 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17990 | -0.00557 |    0.13809 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39532 | -0.01415 |    0.27548 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15644 | -0.01022 |    0.11963 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13738 | -0.00869 |    0.10798 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15496 | -0.02378 |    0.12218 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12266 | -0.00025 |    0.09544 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15337 | -0.01454 |    0.12161 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13857 | -0.01082 |    0.10951 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21523 | -0.02323 |    0.16936 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13629 | -0.01497 |    0.10747 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10287 | -0.00354 |    0.07835 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07990 | -0.00603 |    0.06100 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06053 | -0.00408 |    0.04396 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58704 | -0.00000 |    0.46274 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:04:17,959 - Total sparsity: 0.00

2018-11-02 20:04:17,959 - --- validate (epoch=74)-----------
2018-11-02 20:04:17,959 - 10000 samples (128 per mini-batch)
2018-11-02 20:04:18,691 - Epoch: [74][   50/   78]    Loss 0.432354    Top1 85.656250    Top5 99.234375    
2018-11-02 20:04:19,076 - ==> Top1: 85.560    Top5: 99.280    Loss: 0.433

2018-11-02 20:04:19,077 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:04:19,077 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:04:19,089 - 

2018-11-02 20:04:19,089 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:04:20,282 - Epoch: [75][   50/  391]    Overall Loss 0.331911    Objective Loss 0.331911    Top1 88.671875    Top5 99.640625    LR 0.300000    Time 0.023822    
2018-11-02 20:04:21,418 - Epoch: [75][  100/  391]    Overall Loss 0.337037    Objective Loss 0.337037    Top1 88.414062    Top5 99.570312    LR 0.300000    Time 0.023263    
2018-11-02 20:04:22,554 - Epoch: [75][  150/  391]    Overall Loss 0.349491    Objective Loss 0.349491    Top1 88.104167    Top5 99.520833    LR 0.300000    Time 0.023071    
2018-11-02 20:04:23,689 - Epoch: [75][  200/  391]    Overall Loss 0.351721    Objective Loss 0.351721    Top1 88.101562    Top5 99.527344    LR 0.300000    Time 0.022972    
2018-11-02 20:04:24,826 - Epoch: [75][  250/  391]    Overall Loss 0.355358    Objective Loss 0.355358    Top1 87.946875    Top5 99.540625    LR 0.300000    Time 0.022919    
2018-11-02 20:04:25,964 - Epoch: [75][  300/  391]    Overall Loss 0.356682    Objective Loss 0.356682    Top1 87.856771    Top5 99.533854    LR 0.300000    Time 0.022889    
2018-11-02 20:04:27,103 - Epoch: [75][  350/  391]    Overall Loss 0.358344    Objective Loss 0.358344    Top1 87.810268    Top5 99.540179    LR 0.300000    Time 0.022870    
2018-11-02 20:04:28,117 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58032 | -0.01009 |    0.38514 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16190 | -0.00036 |    0.09785 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16170 | -0.00128 |    0.11247 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19531 | -0.01723 |    0.13994 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19738 | -0.00995 |    0.14855 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20022 | -0.03103 |    0.14813 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17922 |  0.00332 |    0.12921 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21408 | -0.01155 |    0.15763 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17924 | -0.00625 |    0.13771 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39389 | -0.01008 |    0.27173 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15585 | -0.00984 |    0.11896 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13683 | -0.00845 |    0.10759 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15492 | -0.02387 |    0.12215 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12309 | -0.00090 |    0.09559 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15318 | -0.01452 |    0.12150 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13858 | -0.01047 |    0.10963 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21375 | -0.02221 |    0.16738 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13598 | -0.01467 |    0.10717 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10266 | -0.00380 |    0.07824 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07990 | -0.00614 |    0.06103 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06040 | -0.00367 |    0.04381 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58471 | -0.00000 |    0.45890 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:04:28,117 - Total sparsity: 0.00

2018-11-02 20:04:28,117 - --- validate (epoch=75)-----------
2018-11-02 20:04:28,117 - 10000 samples (128 per mini-batch)
2018-11-02 20:04:28,841 - Epoch: [75][   50/   78]    Loss 0.589786    Top1 81.781250    Top5 98.796875    
2018-11-02 20:04:29,234 - ==> Top1: 81.830    Top5: 98.820    Loss: 0.585

2018-11-02 20:04:29,235 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:04:29,235 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:04:29,243 - 

2018-11-02 20:04:29,244 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:04:30,441 - Epoch: [76][   50/  391]    Overall Loss 0.361537    Objective Loss 0.361537    Top1 87.531250    Top5 99.640625    LR 0.300000    Time 0.023920    
2018-11-02 20:04:31,580 - Epoch: [76][  100/  391]    Overall Loss 0.360168    Objective Loss 0.360168    Top1 87.609375    Top5 99.484375    LR 0.300000    Time 0.023328    
2018-11-02 20:04:32,718 - Epoch: [76][  150/  391]    Overall Loss 0.364459    Objective Loss 0.364459    Top1 87.463542    Top5 99.531250    LR 0.300000    Time 0.023131    
2018-11-02 20:04:33,858 - Epoch: [76][  200/  391]    Overall Loss 0.361261    Objective Loss 0.361261    Top1 87.691406    Top5 99.523438    LR 0.300000    Time 0.023040    
2018-11-02 20:04:34,996 - Epoch: [76][  250/  391]    Overall Loss 0.362021    Objective Loss 0.362021    Top1 87.681250    Top5 99.509375    LR 0.300000    Time 0.022982    
2018-11-02 20:04:36,136 - Epoch: [76][  300/  391]    Overall Loss 0.366297    Objective Loss 0.366297    Top1 87.437500    Top5 99.507812    LR 0.300000    Time 0.022948    
2018-11-02 20:04:37,276 - Epoch: [76][  350/  391]    Overall Loss 0.362800    Objective Loss 0.362800    Top1 87.566964    Top5 99.500000    LR 0.300000    Time 0.022923    
2018-11-02 20:04:38,289 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58279 |  0.00175 |    0.38537 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16204 | -0.00176 |    0.09742 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16130 | -0.00379 |    0.11198 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19543 | -0.02010 |    0.13981 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19779 | -0.00854 |    0.14839 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20070 | -0.02928 |    0.14789 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17910 |  0.00454 |    0.12906 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21518 | -0.00948 |    0.15734 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18001 | -0.00674 |    0.13829 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39509 | -0.00887 |    0.27390 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15605 | -0.00902 |    0.11905 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.00944 |    0.10779 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15562 | -0.02253 |    0.12237 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12314 | -0.00207 |    0.09595 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15289 | -0.01498 |    0.12146 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13863 | -0.01055 |    0.10976 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21397 | -0.02355 |    0.16751 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13628 | -0.01469 |    0.10749 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10278 | -0.00373 |    0.07841 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07985 | -0.00675 |    0.06121 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06036 | -0.00347 |    0.04387 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58190 | -0.00000 |    0.45844 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:04:38,289 - Total sparsity: 0.00

2018-11-02 20:04:38,289 - --- validate (epoch=76)-----------
2018-11-02 20:04:38,289 - 10000 samples (128 per mini-batch)
2018-11-02 20:04:39,036 - Epoch: [76][   50/   78]    Loss 0.784544    Top1 75.343750    Top5 97.875000    
2018-11-02 20:04:39,427 - ==> Top1: 75.490    Top5: 98.030    Loss: 0.773

2018-11-02 20:04:39,428 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:04:39,428 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:04:39,439 - 

2018-11-02 20:04:39,439 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:04:40,636 - Epoch: [77][   50/  391]    Overall Loss 0.352298    Objective Loss 0.352298    Top1 87.750000    Top5 99.625000    LR 0.300000    Time 0.023891    
2018-11-02 20:04:41,774 - Epoch: [77][  100/  391]    Overall Loss 0.340547    Objective Loss 0.340547    Top1 88.304688    Top5 99.656250    LR 0.300000    Time 0.023312    
2018-11-02 20:04:42,911 - Epoch: [77][  150/  391]    Overall Loss 0.339013    Objective Loss 0.339013    Top1 88.322917    Top5 99.697917    LR 0.300000    Time 0.023114    
2018-11-02 20:04:44,049 - Epoch: [77][  200/  391]    Overall Loss 0.350968    Objective Loss 0.350968    Top1 87.914062    Top5 99.636719    LR 0.300000    Time 0.023020    
2018-11-02 20:04:45,187 - Epoch: [77][  250/  391]    Overall Loss 0.360900    Objective Loss 0.360900    Top1 87.543750    Top5 99.603125    LR 0.300000    Time 0.022961    
2018-11-02 20:04:46,325 - Epoch: [77][  300/  391]    Overall Loss 0.362733    Objective Loss 0.362733    Top1 87.445312    Top5 99.585938    LR 0.300000    Time 0.022926    
2018-11-02 20:04:47,463 - Epoch: [77][  350/  391]    Overall Loss 0.363929    Objective Loss 0.363929    Top1 87.462054    Top5 99.578125    LR 0.300000    Time 0.022898    
2018-11-02 20:04:48,476 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57909 |  0.00588 |    0.38460 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16078 | -0.00324 |    0.09643 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16005 |  0.00053 |    0.11204 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19398 | -0.02128 |    0.13931 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19666 | -0.00821 |    0.14832 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19956 | -0.02931 |    0.14701 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17884 |  0.00428 |    0.12889 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21496 | -0.00881 |    0.15696 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18020 | -0.00556 |    0.13845 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39341 | -0.01198 |    0.26840 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15554 | -0.00993 |    0.11890 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13619 | -0.00837 |    0.10702 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15481 | -0.02399 |    0.12207 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12271 | -0.00132 |    0.09549 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15287 | -0.01518 |    0.12144 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13867 | -0.01061 |    0.10971 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21379 | -0.02268 |    0.16666 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13626 | -0.01476 |    0.10769 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10316 | -0.00389 |    0.07879 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08063 | -0.00600 |    0.06167 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06087 | -0.00347 |    0.04422 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58469 | -0.00000 |    0.45912 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:04:48,476 - Total sparsity: 0.00

2018-11-02 20:04:48,476 - --- validate (epoch=77)-----------
2018-11-02 20:04:48,476 - 10000 samples (128 per mini-batch)
2018-11-02 20:04:49,194 - Epoch: [77][   50/   78]    Loss 0.486990    Top1 83.828125    Top5 99.078125    
2018-11-02 20:04:49,584 - ==> Top1: 83.970    Top5: 99.110    Loss: 0.489

2018-11-02 20:04:49,585 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:04:49,585 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:04:49,596 - 

2018-11-02 20:04:49,597 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:04:50,796 - Epoch: [78][   50/  391]    Overall Loss 0.337259    Objective Loss 0.337259    Top1 88.125000    Top5 99.656250    LR 0.300000    Time 0.023943    
2018-11-02 20:04:51,938 - Epoch: [78][  100/  391]    Overall Loss 0.338134    Objective Loss 0.338134    Top1 88.359375    Top5 99.632812    LR 0.300000    Time 0.023380    
2018-11-02 20:04:53,079 - Epoch: [78][  150/  391]    Overall Loss 0.346158    Objective Loss 0.346158    Top1 88.093750    Top5 99.593750    LR 0.300000    Time 0.023183    
2018-11-02 20:04:54,221 - Epoch: [78][  200/  391]    Overall Loss 0.355771    Objective Loss 0.355771    Top1 87.718750    Top5 99.593750    LR 0.300000    Time 0.023093    
2018-11-02 20:04:55,363 - Epoch: [78][  250/  391]    Overall Loss 0.357283    Objective Loss 0.357283    Top1 87.706250    Top5 99.615625    LR 0.300000    Time 0.023037    
2018-11-02 20:04:56,501 - Epoch: [78][  300/  391]    Overall Loss 0.356687    Objective Loss 0.356687    Top1 87.697917    Top5 99.609375    LR 0.300000    Time 0.022985    
2018-11-02 20:04:57,644 - Epoch: [78][  350/  391]    Overall Loss 0.358765    Objective Loss 0.358765    Top1 87.582589    Top5 99.609375    LR 0.300000    Time 0.022963    
2018-11-02 20:04:58,659 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58133 |  0.00431 |    0.38169 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15976 | -0.00231 |    0.09663 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15990 |  0.00086 |    0.11172 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19361 | -0.02239 |    0.13801 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19669 | -0.00758 |    0.14827 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19825 | -0.02991 |    0.14493 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17847 |  0.00601 |    0.12782 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21455 | -0.00971 |    0.15643 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18003 | -0.00610 |    0.13824 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39424 | -0.01082 |    0.27064 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15534 | -0.00822 |    0.11845 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01005 |    0.10677 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15505 | -0.02382 |    0.12221 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12298 | -0.00146 |    0.09558 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15325 | -0.01462 |    0.12149 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13847 | -0.01078 |    0.10955 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21453 | -0.02130 |    0.16752 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13625 | -0.01423 |    0.10771 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10335 | -0.00401 |    0.07907 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08116 | -0.00618 |    0.06229 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06109 | -0.00337 |    0.04436 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58166 | -0.00000 |    0.45887 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:04:58,659 - Total sparsity: 0.00

2018-11-02 20:04:58,659 - --- validate (epoch=78)-----------
2018-11-02 20:04:58,660 - 10000 samples (128 per mini-batch)
2018-11-02 20:04:59,382 - Epoch: [78][   50/   78]    Loss 0.496168    Top1 83.312500    Top5 99.203125    
2018-11-02 20:04:59,784 - ==> Top1: 83.300    Top5: 99.290    Loss: 0.490

2018-11-02 20:04:59,785 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:04:59,785 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:04:59,793 - 

2018-11-02 20:04:59,793 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:05:00,993 - Epoch: [79][   50/  391]    Overall Loss 0.349152    Objective Loss 0.349152    Top1 88.171875    Top5 99.640625    LR 0.300000    Time 0.023966    
2018-11-02 20:05:02,133 - Epoch: [79][  100/  391]    Overall Loss 0.343227    Objective Loss 0.343227    Top1 88.125000    Top5 99.671875    LR 0.300000    Time 0.023365    
2018-11-02 20:05:03,275 - Epoch: [79][  150/  391]    Overall Loss 0.345369    Objective Loss 0.345369    Top1 88.093750    Top5 99.692708    LR 0.300000    Time 0.023181    
2018-11-02 20:05:04,417 - Epoch: [79][  200/  391]    Overall Loss 0.347544    Objective Loss 0.347544    Top1 88.089844    Top5 99.664062    LR 0.300000    Time 0.023088    
2018-11-02 20:05:05,558 - Epoch: [79][  250/  391]    Overall Loss 0.351265    Objective Loss 0.351265    Top1 87.968750    Top5 99.653125    LR 0.300000    Time 0.023033    
2018-11-02 20:05:06,699 - Epoch: [79][  300/  391]    Overall Loss 0.358217    Objective Loss 0.358217    Top1 87.760417    Top5 99.617188    LR 0.300000    Time 0.022993    
2018-11-02 20:05:07,841 - Epoch: [79][  350/  391]    Overall Loss 0.358434    Objective Loss 0.358434    Top1 87.747768    Top5 99.595982    LR 0.300000    Time 0.022967    
2018-11-02 20:05:08,860 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57744 | -0.01124 |    0.38679 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15759 |  0.00015 |    0.09600 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15889 | -0.00138 |    0.11180 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19380 | -0.02106 |    0.13850 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19648 | -0.00569 |    0.14732 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19842 | -0.02844 |    0.14523 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17830 |  0.00317 |    0.12824 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21429 | -0.01100 |    0.15608 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17957 | -0.00537 |    0.13786 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39381 | -0.01135 |    0.27250 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15566 | -0.00765 |    0.11888 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13643 | -0.01046 |    0.10715 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15474 | -0.02416 |    0.12155 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12272 | -0.00147 |    0.09513 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15285 | -0.01493 |    0.12105 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13844 | -0.01047 |    0.10950 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21515 | -0.02145 |    0.16889 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01514 |    0.10725 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10328 | -0.00391 |    0.07905 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08158 | -0.00616 |    0.06259 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06128 | -0.00274 |    0.04458 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58594 | -0.00000 |    0.46207 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:05:08,860 - Total sparsity: 0.00

2018-11-02 20:05:08,860 - --- validate (epoch=79)-----------
2018-11-02 20:05:08,860 - 10000 samples (128 per mini-batch)
2018-11-02 20:05:09,589 - Epoch: [79][   50/   78]    Loss 0.585901    Top1 83.015625    Top5 98.828125    
2018-11-02 20:05:09,983 - ==> Top1: 82.700    Top5: 98.960    Loss: 0.582

2018-11-02 20:05:09,983 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:05:09,984 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:05:09,992 - 

2018-11-02 20:05:09,992 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:05:11,189 - Epoch: [80][   50/  391]    Overall Loss 0.358028    Objective Loss 0.358028    Top1 88.093750    Top5 99.546875    LR 0.300000    Time 0.023907    
2018-11-02 20:05:12,327 - Epoch: [80][  100/  391]    Overall Loss 0.352480    Objective Loss 0.352480    Top1 87.992188    Top5 99.609375    LR 0.300000    Time 0.023317    
2018-11-02 20:05:13,467 - Epoch: [80][  150/  391]    Overall Loss 0.359773    Objective Loss 0.359773    Top1 87.583333    Top5 99.609375    LR 0.300000    Time 0.023136    
2018-11-02 20:05:14,608 - Epoch: [80][  200/  391]    Overall Loss 0.358910    Objective Loss 0.358910    Top1 87.578125    Top5 99.613281    LR 0.300000    Time 0.023051    
2018-11-02 20:05:15,746 - Epoch: [80][  250/  391]    Overall Loss 0.360229    Objective Loss 0.360229    Top1 87.578125    Top5 99.565625    LR 0.300000    Time 0.022988    
2018-11-02 20:05:16,884 - Epoch: [80][  300/  391]    Overall Loss 0.363888    Objective Loss 0.363888    Top1 87.447917    Top5 99.557292    LR 0.300000    Time 0.022947    
2018-11-02 20:05:18,024 - Epoch: [80][  350/  391]    Overall Loss 0.365429    Objective Loss 0.365429    Top1 87.433036    Top5 99.558036    LR 0.300000    Time 0.022921    
2018-11-02 20:05:19,035 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58147 | -0.01100 |    0.38708 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15879 | -0.00095 |    0.09684 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15920 | -0.00343 |    0.11214 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19347 | -0.01986 |    0.13854 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19686 | -0.00631 |    0.14776 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19976 | -0.03175 |    0.14718 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17966 |  0.00272 |    0.12891 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21452 | -0.00892 |    0.15620 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18028 | -0.00578 |    0.13829 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39431 | -0.01013 |    0.27071 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15568 | -0.01044 |    0.11934 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13635 | -0.01083 |    0.10747 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15472 | -0.02394 |    0.12109 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12248 | -0.00197 |    0.09504 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15325 | -0.01421 |    0.12120 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13882 | -0.01022 |    0.10982 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21680 | -0.02169 |    0.17062 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13622 | -0.01508 |    0.10746 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10361 | -0.00403 |    0.07919 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08240 | -0.00667 |    0.06335 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06169 | -0.00307 |    0.04481 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58346 | -0.00000 |    0.46125 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:05:19,035 - Total sparsity: 0.00

2018-11-02 20:05:19,035 - --- validate (epoch=80)-----------
2018-11-02 20:05:19,035 - 10000 samples (128 per mini-batch)
2018-11-02 20:05:19,758 - Epoch: [80][   50/   78]    Loss 0.617419    Top1 80.734375    Top5 98.890625    
2018-11-02 20:05:20,148 - ==> Top1: 80.560    Top5: 98.860    Loss: 0.619

2018-11-02 20:05:20,149 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:05:20,149 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:05:20,158 - 

2018-11-02 20:05:20,158 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:05:21,353 - Epoch: [81][   50/  391]    Overall Loss 0.344466    Objective Loss 0.344466    Top1 88.281250    Top5 99.609375    LR 0.300000    Time 0.023867    
2018-11-02 20:05:22,493 - Epoch: [81][  100/  391]    Overall Loss 0.347940    Objective Loss 0.347940    Top1 88.179688    Top5 99.585938    LR 0.300000    Time 0.023323    
2018-11-02 20:05:23,636 - Epoch: [81][  150/  391]    Overall Loss 0.348988    Objective Loss 0.348988    Top1 88.062500    Top5 99.619792    LR 0.300000    Time 0.023155    
2018-11-02 20:05:24,777 - Epoch: [81][  200/  391]    Overall Loss 0.346437    Objective Loss 0.346437    Top1 88.132812    Top5 99.644531    LR 0.300000    Time 0.023067    
2018-11-02 20:05:25,915 - Epoch: [81][  250/  391]    Overall Loss 0.355752    Objective Loss 0.355752    Top1 87.875000    Top5 99.609375    LR 0.300000    Time 0.023001    
2018-11-02 20:05:27,052 - Epoch: [81][  300/  391]    Overall Loss 0.358641    Objective Loss 0.358641    Top1 87.742188    Top5 99.604167    LR 0.300000    Time 0.022953    
2018-11-02 20:05:28,192 - Epoch: [81][  350/  391]    Overall Loss 0.361226    Objective Loss 0.361226    Top1 87.587054    Top5 99.611607    LR 0.300000    Time 0.022926    
2018-11-02 20:05:29,207 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58378 | -0.01378 |    0.38808 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15760 | -0.00257 |    0.09508 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15961 | -0.00308 |    0.11154 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19260 | -0.02195 |    0.13868 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19661 | -0.00850 |    0.14691 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19962 | -0.03087 |    0.14702 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17864 |  0.00634 |    0.12917 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21392 | -0.01023 |    0.15663 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17951 | -0.00704 |    0.13809 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39447 | -0.00822 |    0.27018 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15491 | -0.01062 |    0.11834 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13525 | -0.01233 |    0.10665 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15409 | -0.02367 |    0.12080 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12188 | -0.00048 |    0.09440 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15291 | -0.01424 |    0.12107 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13855 | -0.01012 |    0.10931 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21719 | -0.02288 |    0.17159 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13596 | -0.01553 |    0.10737 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10349 | -0.00410 |    0.07913 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08265 | -0.00685 |    0.06354 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06174 | -0.00315 |    0.04481 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58690 | -0.00000 |    0.46500 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:05:29,208 - Total sparsity: 0.00

2018-11-02 20:05:29,208 - --- validate (epoch=81)-----------
2018-11-02 20:05:29,208 - 10000 samples (128 per mini-batch)
2018-11-02 20:05:29,927 - Epoch: [81][   50/   78]    Loss 0.578229    Top1 81.718750    Top5 99.156250    
2018-11-02 20:05:30,319 - ==> Top1: 81.330    Top5: 99.150    Loss: 0.579

2018-11-02 20:05:30,320 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:05:30,320 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:05:30,332 - 

2018-11-02 20:05:30,332 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:05:31,533 - Epoch: [82][   50/  391]    Overall Loss 0.328816    Objective Loss 0.328816    Top1 88.328125    Top5 99.640625    LR 0.300000    Time 0.023982    
2018-11-02 20:05:32,672 - Epoch: [82][  100/  391]    Overall Loss 0.342758    Objective Loss 0.342758    Top1 88.085938    Top5 99.585938    LR 0.300000    Time 0.023368    
2018-11-02 20:05:33,810 - Epoch: [82][  150/  391]    Overall Loss 0.343574    Objective Loss 0.343574    Top1 88.187500    Top5 99.546875    LR 0.300000    Time 0.023154    
2018-11-02 20:05:34,945 - Epoch: [82][  200/  391]    Overall Loss 0.351913    Objective Loss 0.351913    Top1 87.890625    Top5 99.574219    LR 0.300000    Time 0.023038    
2018-11-02 20:05:36,083 - Epoch: [82][  250/  391]    Overall Loss 0.353094    Objective Loss 0.353094    Top1 87.881250    Top5 99.593750    LR 0.300000    Time 0.022976    
2018-11-02 20:05:37,220 - Epoch: [82][  300/  391]    Overall Loss 0.355497    Objective Loss 0.355497    Top1 87.781250    Top5 99.580729    LR 0.300000    Time 0.022934    
2018-11-02 20:05:38,360 - Epoch: [82][  350/  391]    Overall Loss 0.356388    Objective Loss 0.356388    Top1 87.743304    Top5 99.551339    LR 0.300000    Time 0.022911    
2018-11-02 20:05:39,373 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58259 |  0.00283 |    0.38659 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15638 | -0.00214 |    0.09368 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15888 | -0.00414 |    0.11094 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19364 | -0.01969 |    0.13911 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19662 | -0.00511 |    0.14732 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19984 | -0.03197 |    0.14764 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17925 |  0.00084 |    0.12922 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21409 | -0.00848 |    0.15556 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17947 | -0.00542 |    0.13808 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39608 | -0.00497 |    0.27500 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15494 | -0.01107 |    0.11862 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13530 | -0.01090 |    0.10647 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15414 | -0.02331 |    0.12085 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12168 |  0.00018 |    0.09410 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15281 | -0.01516 |    0.12127 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13850 | -0.01083 |    0.10931 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21655 | -0.02262 |    0.17107 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01482 |    0.10725 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10338 | -0.00413 |    0.07900 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08276 | -0.00698 |    0.06344 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06170 | -0.00297 |    0.04484 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58236 | -0.00000 |    0.46129 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:05:39,373 - Total sparsity: 0.00

2018-11-02 20:05:39,373 - --- validate (epoch=82)-----------
2018-11-02 20:05:39,373 - 10000 samples (128 per mini-batch)
2018-11-02 20:05:40,093 - Epoch: [82][   50/   78]    Loss 0.547235    Top1 82.468750    Top5 99.187500    
2018-11-02 20:05:40,480 - ==> Top1: 82.280    Top5: 99.210    Loss: 0.549

2018-11-02 20:05:40,481 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:05:40,481 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:05:40,496 - 

2018-11-02 20:05:40,497 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:05:41,693 - Epoch: [83][   50/  391]    Overall Loss 0.340317    Objective Loss 0.340317    Top1 88.156250    Top5 99.609375    LR 0.300000    Time 0.023882    
2018-11-02 20:05:42,833 - Epoch: [83][  100/  391]    Overall Loss 0.352678    Objective Loss 0.352678    Top1 87.671875    Top5 99.523438    LR 0.300000    Time 0.023329    
2018-11-02 20:05:43,972 - Epoch: [83][  150/  391]    Overall Loss 0.356975    Objective Loss 0.356975    Top1 87.500000    Top5 99.588542    LR 0.300000    Time 0.023137    
2018-11-02 20:05:45,111 - Epoch: [83][  200/  391]    Overall Loss 0.351577    Objective Loss 0.351577    Top1 87.816406    Top5 99.625000    LR 0.300000    Time 0.023046    
2018-11-02 20:05:46,251 - Epoch: [83][  250/  391]    Overall Loss 0.354465    Objective Loss 0.354465    Top1 87.793750    Top5 99.603125    LR 0.300000    Time 0.022990    
2018-11-02 20:05:47,391 - Epoch: [83][  300/  391]    Overall Loss 0.356266    Objective Loss 0.356266    Top1 87.739583    Top5 99.578125    LR 0.300000    Time 0.022954    
2018-11-02 20:05:48,530 - Epoch: [83][  350/  391]    Overall Loss 0.357792    Objective Loss 0.357792    Top1 87.658482    Top5 99.562500    LR 0.300000    Time 0.022927    
2018-11-02 20:05:49,548 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57922 | -0.00905 |    0.38390 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15593 |  0.00025 |    0.09292 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15916 | -0.00356 |    0.11081 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19348 | -0.02239 |    0.13838 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19760 | -0.00333 |    0.14798 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20009 | -0.03115 |    0.14643 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17957 |  0.00310 |    0.12999 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21461 | -0.00939 |    0.15672 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17985 | -0.00684 |    0.13838 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39639 | -0.00716 |    0.27167 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15508 | -0.00948 |    0.11817 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13548 | -0.01114 |    0.10690 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15481 | -0.02268 |    0.12100 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12166 | -0.00002 |    0.09430 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15280 | -0.01504 |    0.12141 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13841 | -0.01024 |    0.10926 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21574 | -0.02126 |    0.16975 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13567 | -0.01452 |    0.10707 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10321 | -0.00502 |    0.07902 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08306 | -0.00663 |    0.06374 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06199 | -0.00282 |    0.04498 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58156 | -0.00000 |    0.46043 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:05:49,548 - Total sparsity: 0.00

2018-11-02 20:05:49,548 - --- validate (epoch=83)-----------
2018-11-02 20:05:49,548 - 10000 samples (128 per mini-batch)
2018-11-02 20:05:50,260 - Epoch: [83][   50/   78]    Loss 0.444961    Top1 85.125000    Top5 99.187500    
2018-11-02 20:05:50,646 - ==> Top1: 85.450    Top5: 99.290    Loss: 0.440

2018-11-02 20:05:50,647 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:05:50,647 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:05:50,655 - 

2018-11-02 20:05:50,656 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:05:51,854 - Epoch: [84][   50/  391]    Overall Loss 0.345773    Objective Loss 0.345773    Top1 87.843750    Top5 99.671875    LR 0.300000    Time 0.023925    
2018-11-02 20:05:52,993 - Epoch: [84][  100/  391]    Overall Loss 0.351027    Objective Loss 0.351027    Top1 87.851562    Top5 99.585938    LR 0.300000    Time 0.023343    
2018-11-02 20:05:54,131 - Epoch: [84][  150/  391]    Overall Loss 0.351747    Objective Loss 0.351747    Top1 87.734375    Top5 99.640625    LR 0.300000    Time 0.023143    
2018-11-02 20:05:55,270 - Epoch: [84][  200/  391]    Overall Loss 0.351929    Objective Loss 0.351929    Top1 87.703125    Top5 99.621094    LR 0.300000    Time 0.023043    
2018-11-02 20:05:56,409 - Epoch: [84][  250/  391]    Overall Loss 0.353502    Objective Loss 0.353502    Top1 87.671875    Top5 99.618750    LR 0.300000    Time 0.022987    
2018-11-02 20:05:57,548 - Epoch: [84][  300/  391]    Overall Loss 0.360440    Objective Loss 0.360440    Top1 87.476562    Top5 99.596354    LR 0.300000    Time 0.022948    
2018-11-02 20:05:58,685 - Epoch: [84][  350/  391]    Overall Loss 0.362630    Objective Loss 0.362630    Top1 87.437500    Top5 99.595982    LR 0.300000    Time 0.022915    
2018-11-02 20:05:59,699 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58040 | -0.00230 |    0.38366 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15511 |  0.00050 |    0.09268 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15925 | -0.00055 |    0.11144 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19365 | -0.02172 |    0.13843 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19785 | -0.00321 |    0.14869 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20131 | -0.03288 |    0.14735 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18160 |  0.00062 |    0.13072 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21554 | -0.00899 |    0.15641 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18046 | -0.00712 |    0.13871 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39756 | -0.00693 |    0.27635 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15497 | -0.01041 |    0.11801 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13557 | -0.00975 |    0.10690 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15448 | -0.02336 |    0.12105 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12205 | -0.00185 |    0.09465 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15384 | -0.01494 |    0.12211 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13894 | -0.00992 |    0.10974 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21601 | -0.02188 |    0.16980 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13619 | -0.01446 |    0.10740 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10410 | -0.00535 |    0.07977 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08434 | -0.00599 |    0.06469 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06281 | -0.00305 |    0.04560 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57973 | -0.00000 |    0.45888 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:05:59,699 - Total sparsity: 0.00

2018-11-02 20:05:59,699 - --- validate (epoch=84)-----------
2018-11-02 20:05:59,699 - 10000 samples (128 per mini-batch)
2018-11-02 20:06:00,425 - Epoch: [84][   50/   78]    Loss 0.698327    Top1 78.500000    Top5 98.484375    
2018-11-02 20:06:00,815 - ==> Top1: 79.010    Top5: 98.580    Loss: 0.680

2018-11-02 20:06:00,816 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:06:00,816 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:06:00,827 - 

2018-11-02 20:06:00,828 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:06:02,022 - Epoch: [85][   50/  391]    Overall Loss 0.347180    Objective Loss 0.347180    Top1 88.093750    Top5 99.593750    LR 0.300000    Time 0.023854    
2018-11-02 20:06:03,159 - Epoch: [85][  100/  391]    Overall Loss 0.355327    Objective Loss 0.355327    Top1 87.500000    Top5 99.570312    LR 0.300000    Time 0.023283    
2018-11-02 20:06:04,298 - Epoch: [85][  150/  391]    Overall Loss 0.355847    Objective Loss 0.355847    Top1 87.661458    Top5 99.562500    LR 0.300000    Time 0.023102    
2018-11-02 20:06:05,435 - Epoch: [85][  200/  391]    Overall Loss 0.353425    Objective Loss 0.353425    Top1 87.761719    Top5 99.578125    LR 0.300000    Time 0.023009    
2018-11-02 20:06:06,575 - Epoch: [85][  250/  391]    Overall Loss 0.351074    Objective Loss 0.351074    Top1 87.903125    Top5 99.593750    LR 0.300000    Time 0.022961    
2018-11-02 20:06:07,714 - Epoch: [85][  300/  391]    Overall Loss 0.353246    Objective Loss 0.353246    Top1 87.867188    Top5 99.591146    LR 0.300000    Time 0.022925    
2018-11-02 20:06:08,851 - Epoch: [85][  350/  391]    Overall Loss 0.356855    Objective Loss 0.356855    Top1 87.761161    Top5 99.598214    LR 0.300000    Time 0.022898    
2018-11-02 20:06:09,870 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57506 | -0.00008 |    0.38006 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15469 | -0.00289 |    0.09258 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15783 | -0.00323 |    0.10987 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19458 | -0.02172 |    0.13957 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19775 | -0.00917 |    0.14888 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20130 | -0.03172 |    0.14779 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18125 |  0.00007 |    0.13074 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21569 | -0.00887 |    0.15599 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18080 | -0.00510 |    0.13855 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39714 | -0.00685 |    0.27435 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15494 | -0.01121 |    0.11804 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13526 | -0.01096 |    0.10692 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15471 | -0.02176 |    0.12133 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12204 | -0.00086 |    0.09483 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15409 | -0.01506 |    0.12212 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13893 | -0.01031 |    0.10978 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21690 | -0.02049 |    0.17011 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13610 | -0.01462 |    0.10733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10428 | -0.00528 |    0.07981 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08481 | -0.00643 |    0.06541 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06295 | -0.00302 |    0.04564 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57755 | -0.00000 |    0.45679 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:06:09,870 - Total sparsity: 0.00

2018-11-02 20:06:09,870 - --- validate (epoch=85)-----------
2018-11-02 20:06:09,871 - 10000 samples (128 per mini-batch)
2018-11-02 20:06:10,601 - Epoch: [85][   50/   78]    Loss 0.470824    Top1 84.703125    Top5 99.125000    
2018-11-02 20:06:10,991 - ==> Top1: 84.620    Top5: 99.220    Loss: 0.474

2018-11-02 20:06:10,992 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:06:10,992 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:06:11,000 - 

2018-11-02 20:06:11,000 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:06:12,198 - Epoch: [86][   50/  391]    Overall Loss 0.359602    Objective Loss 0.359602    Top1 87.625000    Top5 99.500000    LR 0.300000    Time 0.023914    
2018-11-02 20:06:13,338 - Epoch: [86][  100/  391]    Overall Loss 0.365388    Objective Loss 0.365388    Top1 87.375000    Top5 99.562500    LR 0.300000    Time 0.023344    
2018-11-02 20:06:14,479 - Epoch: [86][  150/  391]    Overall Loss 0.364516    Objective Loss 0.364516    Top1 87.427083    Top5 99.588542    LR 0.300000    Time 0.023166    
2018-11-02 20:06:15,617 - Epoch: [86][  200/  391]    Overall Loss 0.359842    Objective Loss 0.359842    Top1 87.628906    Top5 99.613281    LR 0.300000    Time 0.023058    
2018-11-02 20:06:16,756 - Epoch: [86][  250/  391]    Overall Loss 0.359473    Objective Loss 0.359473    Top1 87.712500    Top5 99.584375    LR 0.300000    Time 0.022997    
2018-11-02 20:06:17,895 - Epoch: [86][  300/  391]    Overall Loss 0.361632    Objective Loss 0.361632    Top1 87.635417    Top5 99.591146    LR 0.300000    Time 0.022941    
2018-11-02 20:06:19,033 - Epoch: [86][  350/  391]    Overall Loss 0.357555    Objective Loss 0.357555    Top1 87.796875    Top5 99.604911    LR 0.300000    Time 0.022913    
2018-11-02 20:06:20,049 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57843 |  0.01086 |    0.38115 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15442 | -0.00138 |    0.09276 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15752 | -0.00175 |    0.11010 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19303 | -0.02157 |    0.13814 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19640 | -0.00930 |    0.14796 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19885 | -0.03701 |    0.14732 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18074 | -0.00117 |    0.12988 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21499 | -0.00717 |    0.15518 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18049 | -0.00422 |    0.13884 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39596 | -0.00795 |    0.27365 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15536 | -0.00930 |    0.11827 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13536 | -0.00989 |    0.10689 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15428 | -0.02226 |    0.12084 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12169 | -0.00227 |    0.09446 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15379 | -0.01433 |    0.12178 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13875 | -0.01035 |    0.10992 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21616 | -0.02110 |    0.17011 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13607 | -0.01483 |    0.10722 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10421 | -0.00478 |    0.07958 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08507 | -0.00684 |    0.06559 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06299 | -0.00233 |    0.04562 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57903 | -0.00000 |    0.45782 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:06:20,049 - Total sparsity: 0.00

2018-11-02 20:06:20,049 - --- validate (epoch=86)-----------
2018-11-02 20:06:20,050 - 10000 samples (128 per mini-batch)
2018-11-02 20:06:20,768 - Epoch: [86][   50/   78]    Loss 0.794246    Top1 76.718750    Top5 98.390625    
2018-11-02 20:06:21,150 - ==> Top1: 76.790    Top5: 98.440    Loss: 0.790

2018-11-02 20:06:21,151 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:06:21,151 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:06:21,159 - 

2018-11-02 20:06:21,159 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:06:22,355 - Epoch: [87][   50/  391]    Overall Loss 0.330018    Objective Loss 0.330018    Top1 88.687500    Top5 99.609375    LR 0.300000    Time 0.023877    
2018-11-02 20:06:23,495 - Epoch: [87][  100/  391]    Overall Loss 0.344887    Objective Loss 0.344887    Top1 88.109375    Top5 99.562500    LR 0.300000    Time 0.023325    
2018-11-02 20:06:24,634 - Epoch: [87][  150/  391]    Overall Loss 0.345845    Objective Loss 0.345845    Top1 87.973958    Top5 99.562500    LR 0.300000    Time 0.023137    
2018-11-02 20:06:25,774 - Epoch: [87][  200/  391]    Overall Loss 0.351426    Objective Loss 0.351426    Top1 87.882812    Top5 99.558594    LR 0.300000    Time 0.023044    
2018-11-02 20:06:26,911 - Epoch: [87][  250/  391]    Overall Loss 0.353999    Objective Loss 0.353999    Top1 87.821875    Top5 99.575000    LR 0.300000    Time 0.022979    
2018-11-02 20:06:28,051 - Epoch: [87][  300/  391]    Overall Loss 0.353605    Objective Loss 0.353605    Top1 87.786458    Top5 99.575521    LR 0.300000    Time 0.022946    
2018-11-02 20:06:29,193 - Epoch: [87][  350/  391]    Overall Loss 0.356574    Objective Loss 0.356574    Top1 87.725446    Top5 99.551339    LR 0.300000    Time 0.022916    
2018-11-02 20:06:30,212 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58516 | -0.00712 |    0.38592 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15506 | -0.00327 |    0.09347 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15755 |  0.00009 |    0.10856 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19434 | -0.02160 |    0.13972 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19688 | -0.00760 |    0.14773 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19985 | -0.03383 |    0.14747 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18137 |  0.00193 |    0.13074 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21397 | -0.00981 |    0.15492 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17985 | -0.00550 |    0.13802 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39663 | -0.01124 |    0.26880 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15529 | -0.00944 |    0.11846 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13556 | -0.00977 |    0.10694 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15477 | -0.02250 |    0.12141 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12167 | -0.00167 |    0.09440 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15366 | -0.01459 |    0.12166 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13876 | -0.01039 |    0.10979 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21499 | -0.02140 |    0.16892 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13575 | -0.01461 |    0.10674 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10414 | -0.00505 |    0.07965 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08550 | -0.00645 |    0.06584 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06315 | -0.00234 |    0.04579 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57686 | -0.00000 |    0.45707 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:06:30,212 - Total sparsity: 0.00

2018-11-02 20:06:30,212 - --- validate (epoch=87)-----------
2018-11-02 20:06:30,213 - 10000 samples (128 per mini-batch)
2018-11-02 20:06:30,930 - Epoch: [87][   50/   78]    Loss 0.597173    Top1 81.718750    Top5 98.906250    
2018-11-02 20:06:31,312 - ==> Top1: 81.600    Top5: 98.960    Loss: 0.588

2018-11-02 20:06:31,313 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:06:31,313 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:06:31,325 - 

2018-11-02 20:06:31,325 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:06:32,523 - Epoch: [88][   50/  391]    Overall Loss 0.349058    Objective Loss 0.349058    Top1 87.640625    Top5 99.671875    LR 0.300000    Time 0.023934    
2018-11-02 20:06:33,661 - Epoch: [88][  100/  391]    Overall Loss 0.345193    Objective Loss 0.345193    Top1 87.875000    Top5 99.671875    LR 0.300000    Time 0.023333    
2018-11-02 20:06:34,798 - Epoch: [88][  150/  391]    Overall Loss 0.338443    Objective Loss 0.338443    Top1 88.213542    Top5 99.666667    LR 0.300000    Time 0.023126    
2018-11-02 20:06:35,934 - Epoch: [88][  200/  391]    Overall Loss 0.344477    Objective Loss 0.344477    Top1 88.027344    Top5 99.636719    LR 0.300000    Time 0.023017    
2018-11-02 20:06:37,070 - Epoch: [88][  250/  391]    Overall Loss 0.355100    Objective Loss 0.355100    Top1 87.737500    Top5 99.618750    LR 0.300000    Time 0.022953    
2018-11-02 20:06:38,206 - Epoch: [88][  300/  391]    Overall Loss 0.361594    Objective Loss 0.361594    Top1 87.572917    Top5 99.617188    LR 0.300000    Time 0.022911    
2018-11-02 20:06:39,343 - Epoch: [88][  350/  391]    Overall Loss 0.364307    Objective Loss 0.364307    Top1 87.491071    Top5 99.595982    LR 0.300000    Time 0.022882    
2018-11-02 20:06:40,356 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58842 | -0.00691 |    0.38938 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15415 | -0.00042 |    0.09283 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15724 | -0.00018 |    0.10857 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19511 | -0.02058 |    0.14035 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19792 | -0.00666 |    0.14901 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20083 | -0.03200 |    0.14794 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18088 |  0.00259 |    0.13031 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21387 | -0.01000 |    0.15477 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18002 | -0.00503 |    0.13791 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39654 | -0.01008 |    0.27228 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15525 | -0.01010 |    0.11859 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13530 | -0.01105 |    0.10685 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15511 | -0.02213 |    0.12123 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12192 | -0.00284 |    0.09459 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15406 | -0.01453 |    0.12199 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13930 | -0.01078 |    0.11017 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21486 | -0.02225 |    0.16906 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13614 | -0.01530 |    0.10752 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10460 | -0.00536 |    0.08009 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08591 | -0.00712 |    0.06637 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06354 | -0.00298 |    0.04617 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57756 | -0.00000 |    0.45716 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:06:40,357 - Total sparsity: 0.00

2018-11-02 20:06:40,357 - --- validate (epoch=88)-----------
2018-11-02 20:06:40,357 - 10000 samples (128 per mini-batch)
2018-11-02 20:06:41,083 - Epoch: [88][   50/   78]    Loss 0.478435    Top1 83.875000    Top5 99.109375    
2018-11-02 20:06:41,475 - ==> Top1: 83.820    Top5: 99.240    Loss: 0.482

2018-11-02 20:06:41,475 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:06:41,476 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:06:41,484 - 

2018-11-02 20:06:41,484 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:06:42,678 - Epoch: [89][   50/  391]    Overall Loss 0.345961    Objective Loss 0.345961    Top1 87.515625    Top5 99.640625    LR 0.300000    Time 0.023838    
2018-11-02 20:06:43,818 - Epoch: [89][  100/  391]    Overall Loss 0.342799    Objective Loss 0.342799    Top1 87.992188    Top5 99.664062    LR 0.300000    Time 0.023310    
2018-11-02 20:06:44,957 - Epoch: [89][  150/  391]    Overall Loss 0.343193    Objective Loss 0.343193    Top1 87.958333    Top5 99.666667    LR 0.300000    Time 0.023128    
2018-11-02 20:06:46,099 - Epoch: [89][  200/  391]    Overall Loss 0.346132    Objective Loss 0.346132    Top1 87.832031    Top5 99.621094    LR 0.300000    Time 0.023030    
2018-11-02 20:06:47,239 - Epoch: [89][  250/  391]    Overall Loss 0.346025    Objective Loss 0.346025    Top1 87.871875    Top5 99.631250    LR 0.300000    Time 0.022977    
2018-11-02 20:06:48,380 - Epoch: [89][  300/  391]    Overall Loss 0.351546    Objective Loss 0.351546    Top1 87.679688    Top5 99.638021    LR 0.300000    Time 0.022948    
2018-11-02 20:06:49,520 - Epoch: [89][  350/  391]    Overall Loss 0.353608    Objective Loss 0.353608    Top1 87.687500    Top5 99.627232    LR 0.300000    Time 0.022923    
2018-11-02 20:06:50,536 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58596 | -0.00273 |    0.38768 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15296 | -0.00208 |    0.09138 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15674 | -0.00123 |    0.10831 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19476 | -0.01876 |    0.13917 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19852 | -0.00571 |    0.15042 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20144 | -0.03410 |    0.14900 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18169 |  0.00209 |    0.13089 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21470 | -0.01068 |    0.15558 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17996 | -0.00602 |    0.13798 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39578 | -0.00939 |    0.26991 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15554 | -0.00827 |    0.11865 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13582 | -0.01086 |    0.10748 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15576 | -0.02329 |    0.12198 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12187 | -0.00253 |    0.09441 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15361 | -0.01518 |    0.12204 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13919 | -0.01062 |    0.10988 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21409 | -0.02383 |    0.16867 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13622 | -0.01482 |    0.10757 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10464 | -0.00513 |    0.07989 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08626 | -0.00621 |    0.06646 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06376 | -0.00224 |    0.04619 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58254 | -0.00000 |    0.46250 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:06:50,536 - Total sparsity: 0.00

2018-11-02 20:06:50,536 - --- validate (epoch=89)-----------
2018-11-02 20:06:50,536 - 10000 samples (128 per mini-batch)
2018-11-02 20:06:51,257 - Epoch: [89][   50/   78]    Loss 0.504838    Top1 84.046875    Top5 99.015625    
2018-11-02 20:06:51,647 - ==> Top1: 84.070    Top5: 99.100    Loss: 0.500

2018-11-02 20:06:51,648 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:06:51,648 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:06:51,656 - 

2018-11-02 20:06:51,656 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:06:52,849 - Epoch: [90][   50/  391]    Overall Loss 0.328805    Objective Loss 0.328805    Top1 88.625000    Top5 99.640625    LR 0.300000    Time 0.023827    
2018-11-02 20:06:53,985 - Epoch: [90][  100/  391]    Overall Loss 0.348147    Objective Loss 0.348147    Top1 87.867188    Top5 99.585938    LR 0.300000    Time 0.023259    
2018-11-02 20:06:55,123 - Epoch: [90][  150/  391]    Overall Loss 0.349156    Objective Loss 0.349156    Top1 87.973958    Top5 99.588542    LR 0.300000    Time 0.023080    
2018-11-02 20:06:56,259 - Epoch: [90][  200/  391]    Overall Loss 0.356440    Objective Loss 0.356440    Top1 87.664062    Top5 99.562500    LR 0.300000    Time 0.022987    
2018-11-02 20:06:57,398 - Epoch: [90][  250/  391]    Overall Loss 0.355889    Objective Loss 0.355889    Top1 87.796875    Top5 99.565625    LR 0.300000    Time 0.022940    
2018-11-02 20:06:58,536 - Epoch: [90][  300/  391]    Overall Loss 0.355555    Objective Loss 0.355555    Top1 87.825521    Top5 99.588542    LR 0.300000    Time 0.022905    
2018-11-02 20:06:59,678 - Epoch: [90][  350/  391]    Overall Loss 0.357536    Objective Loss 0.357536    Top1 87.758929    Top5 99.600446    LR 0.300000    Time 0.022891    
2018-11-02 20:07:00,695 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58394 | -0.00335 |    0.38568 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15264 | -0.00164 |    0.09129 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15571 | -0.00232 |    0.10648 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19439 | -0.01995 |    0.13874 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19798 | -0.00649 |    0.14945 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20081 | -0.03513 |    0.14775 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18109 |  0.00128 |    0.13021 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21472 | -0.00902 |    0.15598 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18023 | -0.00483 |    0.13802 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39458 | -0.00689 |    0.27080 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15546 | -0.00734 |    0.11842 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13604 | -0.01133 |    0.10727 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15604 | -0.02200 |    0.12216 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12178 | -0.00185 |    0.09422 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15383 | -0.01324 |    0.12183 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13917 | -0.01058 |    0.10990 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21372 | -0.02233 |    0.16843 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13596 | -0.01485 |    0.10733 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10465 | -0.00548 |    0.07988 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08651 | -0.00666 |    0.06657 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06387 | -0.00239 |    0.04630 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58177 | -0.00000 |    0.45718 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:07:00,696 - Total sparsity: 0.00

2018-11-02 20:07:00,696 - --- validate (epoch=90)-----------
2018-11-02 20:07:00,696 - 10000 samples (128 per mini-batch)
2018-11-02 20:07:01,419 - Epoch: [90][   50/   78]    Loss 0.544479    Top1 83.015625    Top5 99.171875    
2018-11-02 20:07:01,808 - ==> Top1: 83.060    Top5: 99.260    Loss: 0.535

2018-11-02 20:07:01,809 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:07:01,809 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:07:01,818 - 

2018-11-02 20:07:01,818 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:07:03,014 - Epoch: [91][   50/  391]    Overall Loss 0.358869    Objective Loss 0.358869    Top1 87.250000    Top5 99.593750    LR 0.300000    Time 0.023878    
2018-11-02 20:07:04,153 - Epoch: [91][  100/  391]    Overall Loss 0.353461    Objective Loss 0.353461    Top1 87.523438    Top5 99.609375    LR 0.300000    Time 0.023317    
2018-11-02 20:07:05,294 - Epoch: [91][  150/  391]    Overall Loss 0.362057    Objective Loss 0.362057    Top1 87.296875    Top5 99.625000    LR 0.300000    Time 0.023144    
2018-11-02 20:07:06,434 - Epoch: [91][  200/  391]    Overall Loss 0.359222    Objective Loss 0.359222    Top1 87.500000    Top5 99.597656    LR 0.300000    Time 0.023054    
2018-11-02 20:07:07,574 - Epoch: [91][  250/  391]    Overall Loss 0.357766    Objective Loss 0.357766    Top1 87.609375    Top5 99.590625    LR 0.300000    Time 0.022998    
2018-11-02 20:07:08,716 - Epoch: [91][  300/  391]    Overall Loss 0.357559    Objective Loss 0.357559    Top1 87.700521    Top5 99.596354    LR 0.300000    Time 0.022965    
2018-11-02 20:07:09,856 - Epoch: [91][  350/  391]    Overall Loss 0.356270    Objective Loss 0.356270    Top1 87.736607    Top5 99.607143    LR 0.300000    Time 0.022938    
2018-11-02 20:07:10,870 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58445 |  0.00651 |    0.38503 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15293 | -0.00144 |    0.09174 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15531 | -0.00381 |    0.10651 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19502 | -0.02283 |    0.13778 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19908 | -0.00687 |    0.15024 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20172 | -0.03229 |    0.14788 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18041 | -0.00144 |    0.12970 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21450 | -0.00775 |    0.15529 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17996 | -0.00530 |    0.13767 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39481 | -0.01225 |    0.27223 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15559 | -0.00750 |    0.11863 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13626 | -0.01206 |    0.10764 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15585 | -0.02149 |    0.12193 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12181 | -0.00307 |    0.09438 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15349 | -0.01456 |    0.12170 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13915 | -0.01055 |    0.10984 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21450 | -0.02076 |    0.16964 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13615 | -0.01490 |    0.10761 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10493 | -0.00549 |    0.08024 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08696 | -0.00688 |    0.06700 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06414 | -0.00239 |    0.04643 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57947 | -0.00000 |    0.45937 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:07:10,870 - Total sparsity: 0.00

2018-11-02 20:07:10,870 - --- validate (epoch=91)-----------
2018-11-02 20:07:10,870 - 10000 samples (128 per mini-batch)
2018-11-02 20:07:11,593 - Epoch: [91][   50/   78]    Loss 0.626094    Top1 80.687500    Top5 98.406250    
2018-11-02 20:07:11,985 - ==> Top1: 80.420    Top5: 98.440    Loss: 0.619

2018-11-02 20:07:11,985 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:07:11,985 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:07:11,997 - 

2018-11-02 20:07:11,998 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:07:13,194 - Epoch: [92][   50/  391]    Overall Loss 0.346163    Objective Loss 0.346163    Top1 87.843750    Top5 99.656250    LR 0.300000    Time 0.023905    
2018-11-02 20:07:14,336 - Epoch: [92][  100/  391]    Overall Loss 0.338359    Objective Loss 0.338359    Top1 88.148438    Top5 99.703125    LR 0.300000    Time 0.023354    
2018-11-02 20:07:15,478 - Epoch: [92][  150/  391]    Overall Loss 0.349338    Objective Loss 0.349338    Top1 87.937500    Top5 99.671875    LR 0.300000    Time 0.023171    
2018-11-02 20:07:16,619 - Epoch: [92][  200/  391]    Overall Loss 0.353174    Objective Loss 0.353174    Top1 87.820312    Top5 99.644531    LR 0.300000    Time 0.023078    
2018-11-02 20:07:17,755 - Epoch: [92][  250/  391]    Overall Loss 0.354473    Objective Loss 0.354473    Top1 87.771875    Top5 99.628125    LR 0.300000    Time 0.023003    
2018-11-02 20:07:18,896 - Epoch: [92][  300/  391]    Overall Loss 0.354508    Objective Loss 0.354508    Top1 87.700521    Top5 99.617188    LR 0.300000    Time 0.022968    
2018-11-02 20:07:20,034 - Epoch: [92][  350/  391]    Overall Loss 0.355530    Objective Loss 0.355530    Top1 87.705357    Top5 99.616071    LR 0.300000    Time 0.022925    
2018-11-02 20:07:21,049 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58344 |  0.00078 |    0.38077 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15364 | -0.00155 |    0.09154 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15599 | -0.00174 |    0.10588 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19509 | -0.01733 |    0.13847 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19885 | -0.00897 |    0.15020 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20286 | -0.03222 |    0.14819 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18165 |  0.00158 |    0.13040 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21441 | -0.00967 |    0.15562 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17982 | -0.00543 |    0.13793 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39432 | -0.00842 |    0.27226 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15461 | -0.00912 |    0.11806 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13538 | -0.01036 |    0.10660 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15556 | -0.02272 |    0.12210 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12197 | -0.00274 |    0.09427 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15347 | -0.01475 |    0.12173 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13909 | -0.00995 |    0.10984 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21406 | -0.02095 |    0.16871 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13636 | -0.01493 |    0.10771 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10519 | -0.00619 |    0.08062 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08749 | -0.00684 |    0.06754 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06437 | -0.00237 |    0.04675 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57826 | -0.00000 |    0.45865 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:07:21,049 - Total sparsity: 0.00

2018-11-02 20:07:21,050 - --- validate (epoch=92)-----------
2018-11-02 20:07:21,050 - 10000 samples (128 per mini-batch)
2018-11-02 20:07:21,769 - Epoch: [92][   50/   78]    Loss 0.783357    Top1 75.953125    Top5 98.687500    
2018-11-02 20:07:22,161 - ==> Top1: 75.660    Top5: 98.690    Loss: 0.790

2018-11-02 20:07:22,161 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:07:22,161 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:07:22,173 - 

2018-11-02 20:07:22,174 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:07:23,368 - Epoch: [93][   50/  391]    Overall Loss 0.356770    Objective Loss 0.356770    Top1 87.312500    Top5 99.625000    LR 0.300000    Time 0.023863    
2018-11-02 20:07:24,508 - Epoch: [93][  100/  391]    Overall Loss 0.341466    Objective Loss 0.341466    Top1 87.906250    Top5 99.656250    LR 0.300000    Time 0.023315    
2018-11-02 20:07:25,646 - Epoch: [93][  150/  391]    Overall Loss 0.347631    Objective Loss 0.347631    Top1 87.875000    Top5 99.671875    LR 0.300000    Time 0.023123    
2018-11-02 20:07:26,787 - Epoch: [93][  200/  391]    Overall Loss 0.347856    Objective Loss 0.347856    Top1 87.804688    Top5 99.652344    LR 0.300000    Time 0.023041    
2018-11-02 20:07:27,929 - Epoch: [93][  250/  391]    Overall Loss 0.350547    Objective Loss 0.350547    Top1 87.709375    Top5 99.650000    LR 0.300000    Time 0.022993    
2018-11-02 20:07:29,070 - Epoch: [93][  300/  391]    Overall Loss 0.354421    Objective Loss 0.354421    Top1 87.643229    Top5 99.635417    LR 0.300000    Time 0.022961    
2018-11-02 20:07:30,208 - Epoch: [93][  350/  391]    Overall Loss 0.354831    Objective Loss 0.354831    Top1 87.642857    Top5 99.631696    LR 0.300000    Time 0.022929    
2018-11-02 20:07:31,223 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58862 | -0.00180 |    0.38711 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15349 |  0.00104 |    0.09198 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15572 | -0.00254 |    0.10657 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19499 | -0.02016 |    0.13936 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19963 | -0.01022 |    0.15055 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20281 | -0.03243 |    0.14820 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18244 | -0.00122 |    0.13075 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21338 | -0.01184 |    0.15586 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17939 | -0.00566 |    0.13759 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39465 | -0.01055 |    0.27165 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15471 | -0.00804 |    0.11766 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13513 | -0.01021 |    0.10670 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15518 | -0.02234 |    0.12151 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12172 | -0.00186 |    0.09422 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15314 | -0.01435 |    0.12127 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13867 | -0.01048 |    0.10963 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21348 | -0.01960 |    0.16772 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13592 | -0.01464 |    0.10724 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10516 | -0.00632 |    0.08052 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08790 | -0.00716 |    0.06787 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06441 | -0.00253 |    0.04697 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57898 | -0.00000 |    0.45808 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:07:31,223 - Total sparsity: 0.00

2018-11-02 20:07:31,223 - --- validate (epoch=93)-----------
2018-11-02 20:07:31,224 - 10000 samples (128 per mini-batch)
2018-11-02 20:07:31,948 - Epoch: [93][   50/   78]    Loss 0.551857    Top1 81.828125    Top5 98.984375    
2018-11-02 20:07:32,330 - ==> Top1: 81.930    Top5: 99.030    Loss: 0.552

2018-11-02 20:07:32,331 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:07:32,331 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:07:32,339 - 

2018-11-02 20:07:32,339 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:07:33,537 - Epoch: [94][   50/  391]    Overall Loss 0.323947    Objective Loss 0.323947    Top1 88.562500    Top5 99.765625    LR 0.300000    Time 0.023927    
2018-11-02 20:07:34,675 - Epoch: [94][  100/  391]    Overall Loss 0.337933    Objective Loss 0.337933    Top1 88.421875    Top5 99.710938    LR 0.300000    Time 0.023320    
2018-11-02 20:07:35,809 - Epoch: [94][  150/  391]    Overall Loss 0.337792    Objective Loss 0.337792    Top1 88.526042    Top5 99.692708    LR 0.300000    Time 0.023103    
2018-11-02 20:07:36,951 - Epoch: [94][  200/  391]    Overall Loss 0.342728    Objective Loss 0.342728    Top1 88.308594    Top5 99.695312    LR 0.300000    Time 0.023027    
2018-11-02 20:07:38,092 - Epoch: [94][  250/  391]    Overall Loss 0.344948    Objective Loss 0.344948    Top1 88.190625    Top5 99.665625    LR 0.300000    Time 0.022981    
2018-11-02 20:07:39,231 - Epoch: [94][  300/  391]    Overall Loss 0.346149    Objective Loss 0.346149    Top1 88.143229    Top5 99.640625    LR 0.300000    Time 0.022943    
2018-11-02 20:07:40,370 - Epoch: [94][  350/  391]    Overall Loss 0.349596    Objective Loss 0.349596    Top1 87.979911    Top5 99.631696    LR 0.300000    Time 0.022918    
2018-11-02 20:07:41,385 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58341 | -0.00654 |    0.38384 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15288 | -0.00080 |    0.09139 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15601 | -0.00163 |    0.10707 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19385 | -0.01946 |    0.13905 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19820 | -0.00842 |    0.14982 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20249 | -0.03384 |    0.14769 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18279 | -0.00020 |    0.13091 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21281 | -0.01056 |    0.15503 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17923 | -0.00502 |    0.13751 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39473 | -0.01372 |    0.27023 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15435 | -0.00758 |    0.11769 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13496 | -0.01134 |    0.10595 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15460 | -0.02291 |    0.12136 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12117 | -0.00116 |    0.09360 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15259 | -0.01528 |    0.12090 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13834 | -0.01008 |    0.10927 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21281 | -0.02135 |    0.16635 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13562 | -0.01486 |    0.10702 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10512 | -0.00666 |    0.08068 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08795 | -0.00709 |    0.06783 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06454 | -0.00249 |    0.04689 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58008 | -0.00000 |    0.45911 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:07:41,385 - Total sparsity: 0.00

2018-11-02 20:07:41,385 - --- validate (epoch=94)-----------
2018-11-02 20:07:41,385 - 10000 samples (128 per mini-batch)
2018-11-02 20:07:42,132 - Epoch: [94][   50/   78]    Loss 0.532411    Top1 82.453125    Top5 99.250000    
2018-11-02 20:07:42,524 - ==> Top1: 82.420    Top5: 99.310    Loss: 0.525

2018-11-02 20:07:42,525 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:07:42,525 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:07:42,534 - 

2018-11-02 20:07:42,534 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:07:43,729 - Epoch: [95][   50/  391]    Overall Loss 0.335700    Objective Loss 0.335700    Top1 88.078125    Top5 99.656250    LR 0.300000    Time 0.023861    
2018-11-02 20:07:44,868 - Epoch: [95][  100/  391]    Overall Loss 0.338746    Objective Loss 0.338746    Top1 88.046875    Top5 99.601562    LR 0.300000    Time 0.023306    
2018-11-02 20:07:46,008 - Epoch: [95][  150/  391]    Overall Loss 0.349044    Objective Loss 0.349044    Top1 87.869792    Top5 99.598958    LR 0.300000    Time 0.023130    
2018-11-02 20:07:47,147 - Epoch: [95][  200/  391]    Overall Loss 0.353322    Objective Loss 0.353322    Top1 87.726562    Top5 99.566406    LR 0.300000    Time 0.023035    
2018-11-02 20:07:48,285 - Epoch: [95][  250/  391]    Overall Loss 0.354421    Objective Loss 0.354421    Top1 87.771875    Top5 99.562500    LR 0.300000    Time 0.022962    
2018-11-02 20:07:49,425 - Epoch: [95][  300/  391]    Overall Loss 0.356142    Objective Loss 0.356142    Top1 87.799479    Top5 99.565104    LR 0.300000    Time 0.022929    
2018-11-02 20:07:50,564 - Epoch: [95][  350/  391]    Overall Loss 0.355077    Objective Loss 0.355077    Top1 87.861607    Top5 99.569196    LR 0.300000    Time 0.022904    
2018-11-02 20:07:51,577 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58202 | -0.00157 |    0.38078 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15391 |  0.00059 |    0.09148 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15690 | -0.00081 |    0.10691 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19538 | -0.01766 |    0.13976 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19934 | -0.00735 |    0.14948 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20378 | -0.03116 |    0.14831 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18355 | -0.00040 |    0.13179 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21287 | -0.01132 |    0.15540 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17895 | -0.00406 |    0.13705 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39622 | -0.00902 |    0.26997 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15378 | -0.00818 |    0.11710 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13496 | -0.01126 |    0.10635 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15490 | -0.02360 |    0.12173 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12190 | -0.00104 |    0.09447 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15259 | -0.01518 |    0.12097 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13837 | -0.01037 |    0.10934 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21259 | -0.02018 |    0.16598 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13548 | -0.01477 |    0.10697 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10509 | -0.00632 |    0.08042 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08811 | -0.00734 |    0.06799 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06461 | -0.00174 |    0.04690 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57569 | -0.00000 |    0.45712 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:07:51,577 - Total sparsity: 0.00

2018-11-02 20:07:51,577 - --- validate (epoch=95)-----------
2018-11-02 20:07:51,577 - 10000 samples (128 per mini-batch)
2018-11-02 20:07:52,295 - Epoch: [95][   50/   78]    Loss 0.655224    Top1 79.828125    Top5 99.000000    
2018-11-02 20:07:52,686 - ==> Top1: 79.800    Top5: 99.020    Loss: 0.643

2018-11-02 20:07:52,687 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:07:52,687 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:07:52,695 - 

2018-11-02 20:07:52,695 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:07:53,888 - Epoch: [96][   50/  391]    Overall Loss 0.353573    Objective Loss 0.353573    Top1 87.859375    Top5 99.625000    LR 0.300000    Time 0.023827    
2018-11-02 20:07:55,029 - Epoch: [96][  100/  391]    Overall Loss 0.350237    Objective Loss 0.350237    Top1 87.945312    Top5 99.609375    LR 0.300000    Time 0.023303    
2018-11-02 20:07:56,168 - Epoch: [96][  150/  391]    Overall Loss 0.350138    Objective Loss 0.350138    Top1 87.958333    Top5 99.666667    LR 0.300000    Time 0.023125    
2018-11-02 20:07:57,305 - Epoch: [96][  200/  391]    Overall Loss 0.349772    Objective Loss 0.349772    Top1 87.992188    Top5 99.648438    LR 0.300000    Time 0.023021    
2018-11-02 20:07:58,443 - Epoch: [96][  250/  391]    Overall Loss 0.354892    Objective Loss 0.354892    Top1 87.859375    Top5 99.634375    LR 0.300000    Time 0.022963    
2018-11-02 20:07:59,583 - Epoch: [96][  300/  391]    Overall Loss 0.357295    Objective Loss 0.357295    Top1 87.789062    Top5 99.625000    LR 0.300000    Time 0.022931    
2018-11-02 20:08:00,729 - Epoch: [96][  350/  391]    Overall Loss 0.357161    Objective Loss 0.357161    Top1 87.779018    Top5 99.604911    LR 0.300000    Time 0.022926    
2018-11-02 20:08:01,744 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58285 |  0.00291 |    0.37977 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15470 |  0.00310 |    0.09255 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15765 | -0.00334 |    0.10797 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19543 | -0.02060 |    0.14019 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19951 | -0.00643 |    0.14977 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20329 | -0.03268 |    0.14885 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18331 |  0.00228 |    0.13158 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21431 | -0.01007 |    0.15653 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17933 | -0.00466 |    0.13727 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39554 | -0.01332 |    0.27091 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15400 | -0.00794 |    0.11690 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13504 | -0.01008 |    0.10635 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.02239 |    0.12198 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12240 | -0.00208 |    0.09476 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15258 | -0.01421 |    0.12127 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13823 | -0.00998 |    0.10916 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21390 | -0.02210 |    0.16741 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13541 | -0.01462 |    0.10681 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10502 | -0.00622 |    0.08055 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08831 | -0.00718 |    0.06803 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06467 | -0.00222 |    0.04689 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57855 | -0.00000 |    0.45868 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:08:01,744 - Total sparsity: 0.00

2018-11-02 20:08:01,744 - --- validate (epoch=96)-----------
2018-11-02 20:08:01,744 - 10000 samples (128 per mini-batch)
2018-11-02 20:08:02,467 - Epoch: [96][   50/   78]    Loss 0.506718    Top1 83.875000    Top5 99.156250    
2018-11-02 20:08:02,860 - ==> Top1: 84.120    Top5: 99.270    Loss: 0.484

2018-11-02 20:08:02,861 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:08:02,861 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:08:02,873 - 

2018-11-02 20:08:02,873 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:08:04,069 - Epoch: [97][   50/  391]    Overall Loss 0.332719    Objective Loss 0.332719    Top1 88.437500    Top5 99.531250    LR 0.300000    Time 0.023878    
2018-11-02 20:08:05,205 - Epoch: [97][  100/  391]    Overall Loss 0.347201    Objective Loss 0.347201    Top1 88.023438    Top5 99.562500    LR 0.300000    Time 0.023290    
2018-11-02 20:08:06,342 - Epoch: [97][  150/  391]    Overall Loss 0.347562    Objective Loss 0.347562    Top1 87.921875    Top5 99.598958    LR 0.300000    Time 0.023097    
2018-11-02 20:08:07,483 - Epoch: [97][  200/  391]    Overall Loss 0.348140    Objective Loss 0.348140    Top1 87.925781    Top5 99.570312    LR 0.300000    Time 0.023020    
2018-11-02 20:08:08,623 - Epoch: [97][  250/  391]    Overall Loss 0.348274    Objective Loss 0.348274    Top1 87.884375    Top5 99.581250    LR 0.300000    Time 0.022972    
2018-11-02 20:08:09,764 - Epoch: [97][  300/  391]    Overall Loss 0.352051    Objective Loss 0.352051    Top1 87.789062    Top5 99.554688    LR 0.300000    Time 0.022941    
2018-11-02 20:08:10,903 - Epoch: [97][  350/  391]    Overall Loss 0.350634    Objective Loss 0.350634    Top1 87.843750    Top5 99.578125    LR 0.300000    Time 0.022914    
2018-11-02 20:08:11,917 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57876 | -0.00857 |    0.37859 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15378 |  0.00186 |    0.09228 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15724 | -0.00344 |    0.10729 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19518 | -0.01859 |    0.13982 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19840 | -0.00746 |    0.14903 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20268 | -0.03296 |    0.14849 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18236 |  0.00276 |    0.13076 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21406 | -0.00970 |    0.15638 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17912 | -0.00507 |    0.13744 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39354 | -0.00653 |    0.27055 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15377 | -0.00853 |    0.11702 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13531 | -0.00943 |    0.10648 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15510 | -0.02218 |    0.12174 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12208 | -0.00223 |    0.09445 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15210 | -0.01475 |    0.12077 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13773 | -0.01004 |    0.10870 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21473 | -0.02292 |    0.16846 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13483 | -0.01462 |    0.10639 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10482 | -0.00693 |    0.08036 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08842 | -0.00700 |    0.06819 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06470 | -0.00175 |    0.04703 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57553 | -0.00000 |    0.45596 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:08:11,918 - Total sparsity: 0.00

2018-11-02 20:08:11,918 - --- validate (epoch=97)-----------
2018-11-02 20:08:11,918 - 10000 samples (128 per mini-batch)
2018-11-02 20:08:12,640 - Epoch: [97][   50/   78]    Loss 0.590262    Top1 81.906250    Top5 98.937500    
2018-11-02 20:08:13,031 - ==> Top1: 82.020    Top5: 99.020    Loss: 0.579

2018-11-02 20:08:13,032 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:08:13,032 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:08:13,044 - 

2018-11-02 20:08:13,044 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:08:14,237 - Epoch: [98][   50/  391]    Overall Loss 0.358343    Objective Loss 0.358343    Top1 87.781250    Top5 99.593750    LR 0.300000    Time 0.023825    
2018-11-02 20:08:15,377 - Epoch: [98][  100/  391]    Overall Loss 0.342274    Objective Loss 0.342274    Top1 88.226562    Top5 99.625000    LR 0.300000    Time 0.023302    
2018-11-02 20:08:16,515 - Epoch: [98][  150/  391]    Overall Loss 0.349137    Objective Loss 0.349137    Top1 88.041667    Top5 99.635417    LR 0.300000    Time 0.023114    
2018-11-02 20:08:17,654 - Epoch: [98][  200/  391]    Overall Loss 0.345941    Objective Loss 0.345941    Top1 88.136719    Top5 99.648438    LR 0.300000    Time 0.023021    
2018-11-02 20:08:18,795 - Epoch: [98][  250/  391]    Overall Loss 0.345141    Objective Loss 0.345141    Top1 88.025000    Top5 99.668750    LR 0.300000    Time 0.022975    
2018-11-02 20:08:19,933 - Epoch: [98][  300/  391]    Overall Loss 0.347952    Objective Loss 0.347952    Top1 87.937500    Top5 99.653646    LR 0.300000    Time 0.022937    
2018-11-02 20:08:21,072 - Epoch: [98][  350/  391]    Overall Loss 0.352269    Objective Loss 0.352269    Top1 87.779018    Top5 99.640625    LR 0.300000    Time 0.022910    
2018-11-02 20:08:22,091 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57688 | -0.01609 |    0.37451 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15276 |  0.00201 |    0.09127 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15628 | -0.00065 |    0.10618 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19432 | -0.02056 |    0.13884 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19822 | -0.00905 |    0.14917 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20272 | -0.03229 |    0.14912 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18214 |  0.00036 |    0.13040 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21414 | -0.01188 |    0.15717 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17942 | -0.00663 |    0.13748 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39238 | -0.00594 |    0.26836 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15395 | -0.00845 |    0.11685 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13540 | -0.01132 |    0.10662 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15575 | -0.02237 |    0.12220 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12272 | -0.00231 |    0.09485 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15244 | -0.01385 |    0.12116 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13793 | -0.01007 |    0.10896 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21560 | -0.02066 |    0.16847 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13502 | -0.01481 |    0.10660 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10502 | -0.00688 |    0.08053 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08878 | -0.00705 |    0.06847 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06506 | -0.00173 |    0.04711 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57734 | -0.00000 |    0.45728 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:08:22,091 - Total sparsity: 0.00

2018-11-02 20:08:22,092 - --- validate (epoch=98)-----------
2018-11-02 20:08:22,092 - 10000 samples (128 per mini-batch)
2018-11-02 20:08:22,808 - Epoch: [98][   50/   78]    Loss 0.637701    Top1 80.390625    Top5 98.656250    
2018-11-02 20:08:23,197 - ==> Top1: 80.080    Top5: 98.690    Loss: 0.637

2018-11-02 20:08:23,197 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:08:23,197 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:08:23,206 - 

2018-11-02 20:08:23,206 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:08:24,400 - Epoch: [99][   50/  391]    Overall Loss 0.340450    Objective Loss 0.340450    Top1 88.046875    Top5 99.453125    LR 0.300000    Time 0.023835    
2018-11-02 20:08:25,540 - Epoch: [99][  100/  391]    Overall Loss 0.341834    Objective Loss 0.341834    Top1 88.226562    Top5 99.585938    LR 0.300000    Time 0.023313    
2018-11-02 20:08:26,680 - Epoch: [99][  150/  391]    Overall Loss 0.348524    Objective Loss 0.348524    Top1 88.062500    Top5 99.572917    LR 0.300000    Time 0.023130    
2018-11-02 20:08:27,819 - Epoch: [99][  200/  391]    Overall Loss 0.354018    Objective Loss 0.354018    Top1 87.820312    Top5 99.582031    LR 0.300000    Time 0.023017    
2018-11-02 20:08:28,958 - Epoch: [99][  250/  391]    Overall Loss 0.357502    Objective Loss 0.357502    Top1 87.668750    Top5 99.581250    LR 0.300000    Time 0.022964    
2018-11-02 20:08:30,097 - Epoch: [99][  300/  391]    Overall Loss 0.357957    Objective Loss 0.357957    Top1 87.546875    Top5 99.593750    LR 0.300000    Time 0.022931    
2018-11-02 20:08:31,238 - Epoch: [99][  350/  391]    Overall Loss 0.356599    Objective Loss 0.356599    Top1 87.607143    Top5 99.609375    LR 0.300000    Time 0.022910    
2018-11-02 20:08:32,254 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58184 | -0.00510 |    0.37792 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15341 |  0.00300 |    0.09123 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15680 | -0.00243 |    0.10700 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19354 | -0.01653 |    0.13778 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19733 | -0.00576 |    0.14821 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20280 | -0.03422 |    0.14847 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18160 | -0.00062 |    0.12993 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21431 | -0.00985 |    0.15665 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17934 | -0.00560 |    0.13754 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39397 | -0.01344 |    0.26790 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15414 | -0.00874 |    0.11666 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13588 | -0.01053 |    0.10710 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15530 | -0.02345 |    0.12211 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12266 | -0.00170 |    0.09463 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15276 | -0.01501 |    0.12128 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13809 | -0.01047 |    0.10917 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21665 | -0.02037 |    0.16895 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13528 | -0.01460 |    0.10678 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10516 | -0.00706 |    0.08076 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08914 | -0.00741 |    0.06879 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06517 | -0.00229 |    0.04731 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57210 | -0.00000 |    0.45287 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:08:32,254 - Total sparsity: 0.00

2018-11-02 20:08:32,254 - --- validate (epoch=99)-----------
2018-11-02 20:08:32,254 - 10000 samples (128 per mini-batch)
2018-11-02 20:08:32,980 - Epoch: [99][   50/   78]    Loss 0.582730    Top1 81.953125    Top5 98.968750    
2018-11-02 20:08:33,364 - ==> Top1: 81.280    Top5: 99.070    Loss: 0.598

2018-11-02 20:08:33,365 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:08:33,365 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:08:33,377 - 

2018-11-02 20:08:33,377 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:08:34,575 - Epoch: [100][   50/  391]    Overall Loss 0.362207    Objective Loss 0.362207    Top1 87.609375    Top5 99.562500    LR 0.300000    Time 0.023916    
2018-11-02 20:08:35,715 - Epoch: [100][  100/  391]    Overall Loss 0.342985    Objective Loss 0.342985    Top1 88.382812    Top5 99.601562    LR 0.300000    Time 0.023339    
2018-11-02 20:08:36,856 - Epoch: [100][  150/  391]    Overall Loss 0.351201    Objective Loss 0.351201    Top1 88.072917    Top5 99.614583    LR 0.300000    Time 0.023161    
2018-11-02 20:08:37,993 - Epoch: [100][  200/  391]    Overall Loss 0.347222    Objective Loss 0.347222    Top1 88.218750    Top5 99.609375    LR 0.300000    Time 0.023051    
2018-11-02 20:08:39,130 - Epoch: [100][  250/  391]    Overall Loss 0.349192    Objective Loss 0.349192    Top1 87.990625    Top5 99.625000    LR 0.300000    Time 0.022966    
2018-11-02 20:08:40,268 - Epoch: [100][  300/  391]    Overall Loss 0.353833    Objective Loss 0.353833    Top1 87.841146    Top5 99.622396    LR 0.300000    Time 0.022927    
2018-11-02 20:08:41,407 - Epoch: [100][  350/  391]    Overall Loss 0.358260    Objective Loss 0.358260    Top1 87.712054    Top5 99.611607    LR 0.300000    Time 0.022903    
2018-11-02 20:08:42,425 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58271 |  0.00324 |    0.37557 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15351 | -0.00186 |    0.09054 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15798 | -0.00311 |    0.10761 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19286 | -0.01734 |    0.13760 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19728 | -0.00637 |    0.14841 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20305 | -0.03294 |    0.14779 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18183 |  0.00020 |    0.12942 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21400 | -0.01148 |    0.15600 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17948 | -0.00657 |    0.13738 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39644 | -0.01078 |    0.26978 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15421 | -0.00856 |    0.11652 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13577 | -0.01042 |    0.10699 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15515 | -0.02359 |    0.12164 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12241 | -0.00430 |    0.09475 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15313 | -0.01464 |    0.12144 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13813 | -0.01016 |    0.10905 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21678 | -0.01860 |    0.16923 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13538 | -0.01466 |    0.10682 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10533 | -0.00674 |    0.08084 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08936 | -0.00669 |    0.06871 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06546 | -0.00211 |    0.04747 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57220 | -0.00000 |    0.45544 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:08:42,425 - Total sparsity: 0.00

2018-11-02 20:08:42,425 - --- validate (epoch=100)-----------
2018-11-02 20:08:42,425 - 10000 samples (128 per mini-batch)
2018-11-02 20:08:43,147 - Epoch: [100][   50/   78]    Loss 0.656440    Top1 79.796875    Top5 98.859375    
2018-11-02 20:08:43,535 - ==> Top1: 79.300    Top5: 98.960    Loss: 0.667

2018-11-02 20:08:43,535 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:08:43,535 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:08:43,544 - 

2018-11-02 20:08:43,544 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:08:44,741 - Epoch: [101][   50/  391]    Overall Loss 0.369313    Objective Loss 0.369313    Top1 87.656250    Top5 99.578125    LR 0.300000    Time 0.023911    
2018-11-02 20:08:45,882 - Epoch: [101][  100/  391]    Overall Loss 0.338917    Objective Loss 0.338917    Top1 88.468750    Top5 99.601562    LR 0.300000    Time 0.023349    
2018-11-02 20:08:47,021 - Epoch: [101][  150/  391]    Overall Loss 0.353874    Objective Loss 0.353874    Top1 87.968750    Top5 99.578125    LR 0.300000    Time 0.023150    
2018-11-02 20:08:48,158 - Epoch: [101][  200/  391]    Overall Loss 0.356370    Objective Loss 0.356370    Top1 87.976562    Top5 99.550781    LR 0.300000    Time 0.023041    
2018-11-02 20:08:49,297 - Epoch: [101][  250/  391]    Overall Loss 0.355124    Objective Loss 0.355124    Top1 87.903125    Top5 99.565625    LR 0.300000    Time 0.022985    
2018-11-02 20:08:50,435 - Epoch: [101][  300/  391]    Overall Loss 0.353080    Objective Loss 0.353080    Top1 88.007812    Top5 99.539062    LR 0.300000    Time 0.022943    
2018-11-02 20:08:51,574 - Epoch: [101][  350/  391]    Overall Loss 0.352084    Objective Loss 0.352084    Top1 88.024554    Top5 99.553571    LR 0.300000    Time 0.022915    
2018-11-02 20:08:52,585 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58263 | -0.01133 |    0.37890 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15374 | -0.00125 |    0.09116 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15830 | -0.00280 |    0.10867 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19439 | -0.01687 |    0.13959 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19789 | -0.00951 |    0.14987 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20338 | -0.03003 |    0.14801 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18197 | -0.00057 |    0.12966 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21440 | -0.00912 |    0.15561 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17966 | -0.00589 |    0.13771 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39564 | -0.01260 |    0.27050 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15418 | -0.00772 |    0.11616 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13518 | -0.01163 |    0.10666 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15548 | -0.02299 |    0.12252 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12268 | -0.00180 |    0.09458 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15255 | -0.01483 |    0.12140 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13769 | -0.00975 |    0.10864 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21704 | -0.01949 |    0.17012 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13507 | -0.01566 |    0.10658 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10537 | -0.00678 |    0.08095 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08978 | -0.00694 |    0.06914 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06569 | -0.00213 |    0.04762 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57866 | -0.00000 |    0.45772 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:08:52,586 - Total sparsity: 0.00

2018-11-02 20:08:52,586 - --- validate (epoch=101)-----------
2018-11-02 20:08:52,586 - 10000 samples (128 per mini-batch)
2018-11-02 20:08:53,306 - Epoch: [101][   50/   78]    Loss 0.771993    Top1 76.921875    Top5 99.171875    
2018-11-02 20:08:53,701 - ==> Top1: 77.260    Top5: 99.190    Loss: 0.754

2018-11-02 20:08:53,701 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:08:53,702 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:08:53,716 - 

2018-11-02 20:08:53,716 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:08:54,912 - Epoch: [102][   50/  391]    Overall Loss 0.374033    Objective Loss 0.374033    Top1 87.234375    Top5 99.781250    LR 0.300000    Time 0.023875    
2018-11-02 20:08:56,049 - Epoch: [102][  100/  391]    Overall Loss 0.359457    Objective Loss 0.359457    Top1 87.609375    Top5 99.718750    LR 0.300000    Time 0.023293    
2018-11-02 20:08:57,188 - Epoch: [102][  150/  391]    Overall Loss 0.353071    Objective Loss 0.353071    Top1 87.750000    Top5 99.682292    LR 0.300000    Time 0.023117    
2018-11-02 20:08:58,328 - Epoch: [102][  200/  391]    Overall Loss 0.347527    Objective Loss 0.347527    Top1 88.062500    Top5 99.691406    LR 0.300000    Time 0.023031    
2018-11-02 20:08:59,467 - Epoch: [102][  250/  391]    Overall Loss 0.350590    Objective Loss 0.350590    Top1 87.965625    Top5 99.634375    LR 0.300000    Time 0.022975    
2018-11-02 20:09:00,611 - Epoch: [102][  300/  391]    Overall Loss 0.353320    Objective Loss 0.353320    Top1 87.861979    Top5 99.632812    LR 0.300000    Time 0.022955    
2018-11-02 20:09:01,754 - Epoch: [102][  350/  391]    Overall Loss 0.353162    Objective Loss 0.353162    Top1 87.901786    Top5 99.598214    LR 0.300000    Time 0.022936    
2018-11-02 20:09:02,769 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58401 |  0.00099 |    0.37840 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15455 | -0.00288 |    0.09065 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15792 |  0.00126 |    0.10800 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19345 | -0.02034 |    0.13811 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19661 | -0.00866 |    0.14850 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20245 | -0.03479 |    0.14689 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18165 |  0.00053 |    0.12998 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21428 | -0.00945 |    0.15566 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17980 | -0.00490 |    0.13794 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39645 | -0.01068 |    0.26816 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15442 | -0.00841 |    0.11682 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13546 | -0.01159 |    0.10708 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15589 | -0.02253 |    0.12287 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12273 | -0.00226 |    0.09449 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15274 | -0.01469 |    0.12088 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13801 | -0.00930 |    0.10889 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21573 | -0.02139 |    0.16749 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13527 | -0.01512 |    0.10669 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10545 | -0.00702 |    0.08114 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09017 | -0.00739 |    0.06952 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06578 | -0.00238 |    0.04763 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57466 | -0.00000 |    0.45542 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:09:02,769 - Total sparsity: 0.00

2018-11-02 20:09:02,770 - --- validate (epoch=102)-----------
2018-11-02 20:09:02,770 - 10000 samples (128 per mini-batch)
2018-11-02 20:09:03,499 - Epoch: [102][   50/   78]    Loss 0.557152    Top1 83.109375    Top5 98.859375    
2018-11-02 20:09:03,892 - ==> Top1: 83.170    Top5: 98.940    Loss: 0.551

2018-11-02 20:09:03,893 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:09:03,893 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:09:03,905 - 

2018-11-02 20:09:03,905 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:09:05,100 - Epoch: [103][   50/  391]    Overall Loss 0.321332    Objective Loss 0.321332    Top1 88.609375    Top5 99.812500    LR 0.300000    Time 0.023878    
2018-11-02 20:09:06,236 - Epoch: [103][  100/  391]    Overall Loss 0.334604    Objective Loss 0.334604    Top1 88.242188    Top5 99.710938    LR 0.300000    Time 0.023286    
2018-11-02 20:09:07,375 - Epoch: [103][  150/  391]    Overall Loss 0.348860    Objective Loss 0.348860    Top1 87.864583    Top5 99.677083    LR 0.300000    Time 0.023107    
2018-11-02 20:09:08,514 - Epoch: [103][  200/  391]    Overall Loss 0.355423    Objective Loss 0.355423    Top1 87.718750    Top5 99.648438    LR 0.300000    Time 0.023018    
2018-11-02 20:09:09,653 - Epoch: [103][  250/  391]    Overall Loss 0.351467    Objective Loss 0.351467    Top1 87.825000    Top5 99.625000    LR 0.300000    Time 0.022965    
2018-11-02 20:09:10,792 - Epoch: [103][  300/  391]    Overall Loss 0.353965    Objective Loss 0.353965    Top1 87.799479    Top5 99.627604    LR 0.300000    Time 0.022933    
2018-11-02 20:09:11,932 - Epoch: [103][  350/  391]    Overall Loss 0.355429    Objective Loss 0.355429    Top1 87.761161    Top5 99.620536    LR 0.300000    Time 0.022908    
2018-11-02 20:09:12,944 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58782 |  0.00128 |    0.37600 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15541 | -0.00142 |    0.09133 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15921 |  0.00068 |    0.10892 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19435 | -0.01826 |    0.13957 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19782 | -0.00706 |    0.14938 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20296 | -0.03256 |    0.14785 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18193 | -0.00070 |    0.13168 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21470 | -0.00925 |    0.15576 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18042 | -0.00726 |    0.13855 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39739 | -0.01643 |    0.26957 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15445 | -0.00781 |    0.11721 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13559 | -0.01116 |    0.10689 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15607 | -0.02230 |    0.12246 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12295 | -0.00263 |    0.09486 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15280 | -0.01468 |    0.12104 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13815 | -0.00967 |    0.10918 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21619 | -0.02331 |    0.16762 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13573 | -0.01414 |    0.10689 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10560 | -0.00637 |    0.08115 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09055 | -0.00775 |    0.06988 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06613 | -0.00161 |    0.04783 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57566 | -0.00000 |    0.45731 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:09:12,945 - Total sparsity: 0.00

2018-11-02 20:09:12,945 - --- validate (epoch=103)-----------
2018-11-02 20:09:12,945 - 10000 samples (128 per mini-batch)
2018-11-02 20:09:13,702 - Epoch: [103][   50/   78]    Loss 0.504865    Top1 83.765625    Top5 99.140625    
2018-11-02 20:09:14,083 - ==> Top1: 83.780    Top5: 99.160    Loss: 0.503

2018-11-02 20:09:14,084 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:09:14,084 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:09:14,095 - 

2018-11-02 20:09:14,096 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:09:15,292 - Epoch: [104][   50/  391]    Overall Loss 0.342914    Objective Loss 0.342914    Top1 87.671875    Top5 99.531250    LR 0.300000    Time 0.023900    
2018-11-02 20:09:16,431 - Epoch: [104][  100/  391]    Overall Loss 0.335250    Objective Loss 0.335250    Top1 88.054688    Top5 99.585938    LR 0.300000    Time 0.023328    
2018-11-02 20:09:17,572 - Epoch: [104][  150/  391]    Overall Loss 0.340706    Objective Loss 0.340706    Top1 88.020833    Top5 99.557292    LR 0.300000    Time 0.023146    
2018-11-02 20:09:18,711 - Epoch: [104][  200/  391]    Overall Loss 0.343939    Objective Loss 0.343939    Top1 87.906250    Top5 99.574219    LR 0.300000    Time 0.023050    
2018-11-02 20:09:19,850 - Epoch: [104][  250/  391]    Overall Loss 0.348246    Objective Loss 0.348246    Top1 87.781250    Top5 99.562500    LR 0.300000    Time 0.022992    
2018-11-02 20:09:20,990 - Epoch: [104][  300/  391]    Overall Loss 0.354621    Objective Loss 0.354621    Top1 87.578125    Top5 99.562500    LR 0.300000    Time 0.022955    
2018-11-02 20:09:22,131 - Epoch: [104][  350/  391]    Overall Loss 0.352662    Objective Loss 0.352662    Top1 87.687500    Top5 99.578125    LR 0.300000    Time 0.022931    
2018-11-02 20:09:23,148 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58509 | -0.01241 |    0.37488 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15504 | -0.00212 |    0.09036 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15869 | -0.00174 |    0.10886 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19340 | -0.02019 |    0.13765 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19671 | -0.00658 |    0.14756 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20105 | -0.03277 |    0.14690 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18103 |  0.00306 |    0.13014 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21482 | -0.01122 |    0.15638 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18060 | -0.00651 |    0.13873 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39611 | -0.01514 |    0.26925 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15414 | -0.00951 |    0.11673 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13527 | -0.01251 |    0.10679 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15610 | -0.02191 |    0.12278 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12350 | -0.00140 |    0.09535 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15293 | -0.01446 |    0.12097 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13802 | -0.00966 |    0.10894 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21544 | -0.02241 |    0.16710 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13521 | -0.01474 |    0.10661 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10558 | -0.00793 |    0.08133 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09103 | -0.00773 |    0.07021 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06654 | -0.00169 |    0.04805 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57288 | -0.00000 |    0.45573 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:09:23,148 - Total sparsity: 0.00

2018-11-02 20:09:23,149 - --- validate (epoch=104)-----------
2018-11-02 20:09:23,149 - 10000 samples (128 per mini-batch)
2018-11-02 20:09:23,875 - Epoch: [104][   50/   78]    Loss 0.498030    Top1 83.828125    Top5 98.953125    
2018-11-02 20:09:24,269 - ==> Top1: 83.760    Top5: 99.090    Loss: 0.508

2018-11-02 20:09:24,269 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:09:24,270 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:09:24,281 - 

2018-11-02 20:09:24,282 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:09:25,477 - Epoch: [105][   50/  391]    Overall Loss 0.340362    Objective Loss 0.340362    Top1 87.781250    Top5 99.796875    LR 0.300000    Time 0.023866    
2018-11-02 20:09:26,613 - Epoch: [105][  100/  391]    Overall Loss 0.356266    Objective Loss 0.356266    Top1 87.375000    Top5 99.718750    LR 0.300000    Time 0.023279    
2018-11-02 20:09:27,751 - Epoch: [105][  150/  391]    Overall Loss 0.355210    Objective Loss 0.355210    Top1 87.494792    Top5 99.687500    LR 0.300000    Time 0.023095    
2018-11-02 20:09:28,888 - Epoch: [105][  200/  391]    Overall Loss 0.352537    Objective Loss 0.352537    Top1 87.660156    Top5 99.695312    LR 0.300000    Time 0.023002    
2018-11-02 20:09:30,027 - Epoch: [105][  250/  391]    Overall Loss 0.356633    Objective Loss 0.356633    Top1 87.571875    Top5 99.653125    LR 0.300000    Time 0.022951    
2018-11-02 20:09:31,165 - Epoch: [105][  300/  391]    Overall Loss 0.354547    Objective Loss 0.354547    Top1 87.661458    Top5 99.638021    LR 0.300000    Time 0.022916    
2018-11-02 20:09:32,305 - Epoch: [105][  350/  391]    Overall Loss 0.357720    Objective Loss 0.357720    Top1 87.555804    Top5 99.627232    LR 0.300000    Time 0.022897    
2018-11-02 20:09:33,314 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58664 | -0.00370 |    0.37428 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15595 | -0.00215 |    0.09123 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15931 |  0.00005 |    0.10922 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19462 | -0.01824 |    0.13908 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19851 | -0.00641 |    0.14930 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20120 | -0.02969 |    0.14724 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18158 |  0.00139 |    0.13064 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21467 | -0.01049 |    0.15664 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18018 | -0.00736 |    0.13858 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39447 | -0.01410 |    0.26910 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15332 | -0.00852 |    0.11593 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13510 | -0.01092 |    0.10665 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15617 | -0.02185 |    0.12292 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12346 | -0.00092 |    0.09502 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.01461 |    0.12109 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13790 | -0.00962 |    0.10898 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21458 | -0.02317 |    0.16752 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13482 | -0.01489 |    0.10635 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10567 | -0.00736 |    0.08125 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09119 | -0.00692 |    0.07027 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06646 | -0.00167 |    0.04805 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57628 | -0.00000 |    0.45762 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:09:33,314 - Total sparsity: 0.00

2018-11-02 20:09:33,315 - --- validate (epoch=105)-----------
2018-11-02 20:09:33,315 - 10000 samples (128 per mini-batch)
2018-11-02 20:09:34,032 - Epoch: [105][   50/   78]    Loss 0.519521    Top1 83.578125    Top5 98.921875    
2018-11-02 20:09:34,419 - ==> Top1: 83.390    Top5: 99.120    Loss: 0.513

2018-11-02 20:09:34,420 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:09:34,420 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:09:34,431 - 

2018-11-02 20:09:34,431 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:09:35,629 - Epoch: [106][   50/  391]    Overall Loss 0.328931    Objective Loss 0.328931    Top1 88.125000    Top5 99.703125    LR 0.300000    Time 0.023914    
2018-11-02 20:09:36,768 - Epoch: [106][  100/  391]    Overall Loss 0.339039    Objective Loss 0.339039    Top1 87.992188    Top5 99.601562    LR 0.300000    Time 0.023334    
2018-11-02 20:09:37,911 - Epoch: [106][  150/  391]    Overall Loss 0.353001    Objective Loss 0.353001    Top1 87.666667    Top5 99.598958    LR 0.300000    Time 0.023169    
2018-11-02 20:09:39,056 - Epoch: [106][  200/  391]    Overall Loss 0.350162    Objective Loss 0.350162    Top1 87.796875    Top5 99.617188    LR 0.300000    Time 0.023093    
2018-11-02 20:09:40,193 - Epoch: [106][  250/  391]    Overall Loss 0.347743    Objective Loss 0.347743    Top1 87.918750    Top5 99.606250    LR 0.300000    Time 0.023005    
2018-11-02 20:09:41,331 - Epoch: [106][  300/  391]    Overall Loss 0.349309    Objective Loss 0.349309    Top1 87.854167    Top5 99.591146    LR 0.300000    Time 0.022961    
2018-11-02 20:09:42,469 - Epoch: [106][  350/  391]    Overall Loss 0.355795    Objective Loss 0.355795    Top1 87.620536    Top5 99.575893    LR 0.300000    Time 0.022928    
2018-11-02 20:09:43,482 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58549 | -0.00678 |    0.37474 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15585 |  0.00069 |    0.09108 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15947 | -0.00165 |    0.10762 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19520 | -0.01591 |    0.13839 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19913 | -0.00720 |    0.15056 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20150 | -0.03146 |    0.14754 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18195 |  0.00404 |    0.13085 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21554 | -0.00948 |    0.15657 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18070 | -0.00787 |    0.13944 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39572 | -0.01855 |    0.26798 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15373 | -0.00913 |    0.11635 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13536 | -0.01151 |    0.10678 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15667 | -0.02136 |    0.12283 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12371 | -0.00258 |    0.09537 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15330 | -0.01501 |    0.12175 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13832 | -0.01023 |    0.10908 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21492 | -0.02294 |    0.16790 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13495 | -0.01458 |    0.10645 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10610 | -0.00745 |    0.08161 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09182 | -0.00697 |    0.07083 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06688 | -0.00137 |    0.04825 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57195 | -0.00000 |    0.45442 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:09:43,483 - Total sparsity: 0.00

2018-11-02 20:09:43,483 - --- validate (epoch=106)-----------
2018-11-02 20:09:43,483 - 10000 samples (128 per mini-batch)
2018-11-02 20:09:44,209 - Epoch: [106][   50/   78]    Loss 0.552547    Top1 81.343750    Top5 99.000000    
2018-11-02 20:09:44,600 - ==> Top1: 81.560    Top5: 99.120    Loss: 0.558

2018-11-02 20:09:44,601 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:09:44,601 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:09:44,610 - 

2018-11-02 20:09:44,610 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:09:45,807 - Epoch: [107][   50/  391]    Overall Loss 0.339420    Objective Loss 0.339420    Top1 88.359375    Top5 99.671875    LR 0.300000    Time 0.023900    
2018-11-02 20:09:46,947 - Epoch: [107][  100/  391]    Overall Loss 0.349706    Objective Loss 0.349706    Top1 87.984375    Top5 99.632812    LR 0.300000    Time 0.023342    
2018-11-02 20:09:48,087 - Epoch: [107][  150/  391]    Overall Loss 0.349439    Objective Loss 0.349439    Top1 88.020833    Top5 99.625000    LR 0.300000    Time 0.023155    
2018-11-02 20:09:49,229 - Epoch: [107][  200/  391]    Overall Loss 0.344409    Objective Loss 0.344409    Top1 88.187500    Top5 99.648438    LR 0.300000    Time 0.023067    
2018-11-02 20:09:50,370 - Epoch: [107][  250/  391]    Overall Loss 0.349776    Objective Loss 0.349776    Top1 88.000000    Top5 99.640625    LR 0.300000    Time 0.023012    
2018-11-02 20:09:51,509 - Epoch: [107][  300/  391]    Overall Loss 0.351161    Objective Loss 0.351161    Top1 87.958333    Top5 99.617188    LR 0.300000    Time 0.022971    
2018-11-02 20:09:52,649 - Epoch: [107][  350/  391]    Overall Loss 0.349670    Objective Loss 0.349670    Top1 87.986607    Top5 99.611607    LR 0.300000    Time 0.022943    
2018-11-02 20:09:53,666 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58103 | -0.00581 |    0.37173 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15484 |  0.00014 |    0.09066 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15813 | -0.00594 |    0.10895 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19305 | -0.01850 |    0.13809 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19816 | -0.00676 |    0.14969 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20239 | -0.03295 |    0.14751 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18137 |  0.00111 |    0.12906 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21479 | -0.00765 |    0.15573 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18009 | -0.00730 |    0.13847 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39576 | -0.01222 |    0.26557 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15371 | -0.00837 |    0.11628 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13549 | -0.01383 |    0.10724 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15674 | -0.02127 |    0.12316 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12331 |  0.00007 |    0.09494 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15334 | -0.01548 |    0.12162 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13819 | -0.00972 |    0.10896 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21433 | -0.02358 |    0.16758 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13445 | -0.01446 |    0.10602 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10591 | -0.00744 |    0.08150 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09207 | -0.00749 |    0.07103 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06686 | -0.00108 |    0.04816 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57496 | -0.00000 |    0.45375 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:09:53,667 - Total sparsity: 0.00

2018-11-02 20:09:53,667 - --- validate (epoch=107)-----------
2018-11-02 20:09:53,667 - 10000 samples (128 per mini-batch)
2018-11-02 20:09:54,393 - Epoch: [107][   50/   78]    Loss 0.624793    Top1 81.093750    Top5 98.250000    
2018-11-02 20:09:54,785 - ==> Top1: 80.960    Top5: 98.280    Loss: 0.626

2018-11-02 20:09:54,785 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:09:54,785 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:09:54,797 - 

2018-11-02 20:09:54,797 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:09:55,997 - Epoch: [108][   50/  391]    Overall Loss 0.337892    Objective Loss 0.337892    Top1 88.125000    Top5 99.734375    LR 0.300000    Time 0.023957    
2018-11-02 20:09:57,139 - Epoch: [108][  100/  391]    Overall Loss 0.345541    Objective Loss 0.345541    Top1 88.164062    Top5 99.656250    LR 0.300000    Time 0.023384    
2018-11-02 20:09:58,282 - Epoch: [108][  150/  391]    Overall Loss 0.342308    Objective Loss 0.342308    Top1 88.156250    Top5 99.671875    LR 0.300000    Time 0.023200    
2018-11-02 20:09:59,423 - Epoch: [108][  200/  391]    Overall Loss 0.342360    Objective Loss 0.342360    Top1 88.144531    Top5 99.679688    LR 0.300000    Time 0.023098    
2018-11-02 20:10:00,569 - Epoch: [108][  250/  391]    Overall Loss 0.344009    Objective Loss 0.344009    Top1 88.109375    Top5 99.662500    LR 0.300000    Time 0.023059    
2018-11-02 20:10:01,708 - Epoch: [108][  300/  391]    Overall Loss 0.348853    Objective Loss 0.348853    Top1 87.877604    Top5 99.632812    LR 0.300000    Time 0.023009    
2018-11-02 20:10:02,848 - Epoch: [108][  350/  391]    Overall Loss 0.349322    Objective Loss 0.349322    Top1 87.924107    Top5 99.616071    LR 0.300000    Time 0.022975    
2018-11-02 20:10:03,864 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58040 | -0.01065 |    0.37174 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15425 |  0.00041 |    0.09040 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15770 | -0.00346 |    0.10823 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19305 | -0.02028 |    0.13854 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19905 | -0.00806 |    0.15058 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20251 | -0.03125 |    0.14680 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18033 | -0.00022 |    0.12963 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21403 | -0.00843 |    0.15583 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17957 | -0.00686 |    0.13772 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39445 | -0.00797 |    0.26677 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15359 | -0.00770 |    0.11609 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13551 | -0.01221 |    0.10685 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15600 | -0.02034 |    0.12268 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12249 | -0.00073 |    0.09468 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.01533 |    0.12114 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13800 | -0.01050 |    0.10900 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21436 | -0.02169 |    0.16779 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13425 | -0.01527 |    0.10589 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10608 | -0.00736 |    0.08150 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09244 | -0.00768 |    0.07146 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06705 | -0.00121 |    0.04833 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57280 | -0.00000 |    0.45132 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:10:03,864 - Total sparsity: 0.00

2018-11-02 20:10:03,864 - --- validate (epoch=108)-----------
2018-11-02 20:10:03,864 - 10000 samples (128 per mini-batch)
2018-11-02 20:10:04,582 - Epoch: [108][   50/   78]    Loss 0.608294    Top1 81.093750    Top5 98.703125    
2018-11-02 20:10:04,971 - ==> Top1: 81.190    Top5: 98.690    Loss: 0.611

2018-11-02 20:10:04,972 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:10:04,972 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:10:04,983 - 

2018-11-02 20:10:04,984 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:10:06,182 - Epoch: [109][   50/  391]    Overall Loss 0.340455    Objective Loss 0.340455    Top1 88.218750    Top5 99.484375    LR 0.300000    Time 0.023939    
2018-11-02 20:10:07,322 - Epoch: [109][  100/  391]    Overall Loss 0.342588    Objective Loss 0.342588    Top1 88.046875    Top5 99.523438    LR 0.300000    Time 0.023351    
2018-11-02 20:10:08,463 - Epoch: [109][  150/  391]    Overall Loss 0.347271    Objective Loss 0.347271    Top1 87.796875    Top5 99.572917    LR 0.300000    Time 0.023165    
2018-11-02 20:10:09,603 - Epoch: [109][  200/  391]    Overall Loss 0.341829    Objective Loss 0.341829    Top1 88.042969    Top5 99.601562    LR 0.300000    Time 0.023066    
2018-11-02 20:10:10,741 - Epoch: [109][  250/  391]    Overall Loss 0.343134    Objective Loss 0.343134    Top1 87.928125    Top5 99.596875    LR 0.300000    Time 0.023001    
2018-11-02 20:10:11,881 - Epoch: [109][  300/  391]    Overall Loss 0.344584    Objective Loss 0.344584    Top1 87.895833    Top5 99.604167    LR 0.300000    Time 0.022962    
2018-11-02 20:10:13,023 - Epoch: [109][  350/  391]    Overall Loss 0.351023    Objective Loss 0.351023    Top1 87.763393    Top5 99.595982    LR 0.300000    Time 0.022942    
2018-11-02 20:10:14,040 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57687 | -0.00382 |    0.36851 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15517 |  0.00031 |    0.09160 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15741 | -0.00131 |    0.10794 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19383 | -0.02170 |    0.13857 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19921 | -0.00825 |    0.15030 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20275 | -0.03163 |    0.14723 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18109 | -0.00166 |    0.12949 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21477 | -0.00956 |    0.15632 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17986 | -0.00626 |    0.13807 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39516 | -0.01155 |    0.26754 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15435 | -0.00756 |    0.11683 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13587 | -0.01367 |    0.10712 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15625 | -0.02221 |    0.12320 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12295 | -0.00176 |    0.09494 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15331 | -0.01559 |    0.12136 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13846 | -0.01062 |    0.10932 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21566 | -0.02091 |    0.16726 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13460 | -0.01538 |    0.10620 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10639 | -0.00782 |    0.08190 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09295 | -0.00773 |    0.07196 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06733 | -0.00109 |    0.04846 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56743 | -0.00000 |    0.44620 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:10:14,040 - Total sparsity: 0.00

2018-11-02 20:10:14,040 - --- validate (epoch=109)-----------
2018-11-02 20:10:14,040 - 10000 samples (128 per mini-batch)
2018-11-02 20:10:14,773 - Epoch: [109][   50/   78]    Loss 0.476690    Top1 85.031250    Top5 99.078125    
2018-11-02 20:10:15,160 - ==> Top1: 85.240    Top5: 99.110    Loss: 0.465

2018-11-02 20:10:15,161 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:10:15,161 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:10:15,169 - 

2018-11-02 20:10:15,169 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:10:16,367 - Epoch: [110][   50/  391]    Overall Loss 0.331856    Objective Loss 0.331856    Top1 88.546875    Top5 99.625000    LR 0.300000    Time 0.023920    
2018-11-02 20:10:17,507 - Epoch: [110][  100/  391]    Overall Loss 0.350157    Objective Loss 0.350157    Top1 87.992188    Top5 99.539062    LR 0.300000    Time 0.023349    
2018-11-02 20:10:18,646 - Epoch: [110][  150/  391]    Overall Loss 0.344926    Objective Loss 0.344926    Top1 88.192708    Top5 99.552083    LR 0.300000    Time 0.023152    
2018-11-02 20:10:19,785 - Epoch: [110][  200/  391]    Overall Loss 0.347423    Objective Loss 0.347423    Top1 88.082031    Top5 99.558594    LR 0.300000    Time 0.023032    
2018-11-02 20:10:20,928 - Epoch: [110][  250/  391]    Overall Loss 0.346988    Objective Loss 0.346988    Top1 88.059375    Top5 99.587500    LR 0.300000    Time 0.022991    
2018-11-02 20:10:22,069 - Epoch: [110][  300/  391]    Overall Loss 0.349999    Objective Loss 0.349999    Top1 87.903646    Top5 99.588542    LR 0.300000    Time 0.022961    
2018-11-02 20:10:23,209 - Epoch: [110][  350/  391]    Overall Loss 0.350810    Objective Loss 0.350810    Top1 87.917411    Top5 99.591518    LR 0.300000    Time 0.022934    
2018-11-02 20:10:24,224 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58126 | -0.00060 |    0.37017 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15480 |  0.00167 |    0.09137 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15686 | -0.00187 |    0.10692 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19435 | -0.02066 |    0.13878 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19949 | -0.00644 |    0.15050 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20306 | -0.03424 |    0.14810 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18155 |  0.00346 |    0.12859 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21420 | -0.01000 |    0.15582 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17977 | -0.00674 |    0.13818 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39472 | -0.01139 |    0.26680 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15439 | -0.00638 |    0.11658 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13597 | -0.01280 |    0.10721 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15631 | -0.02268 |    0.12314 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12292 | -0.00070 |    0.09456 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15311 | -0.01563 |    0.12136 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13852 | -0.01009 |    0.10945 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21527 | -0.02130 |    0.16650 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13457 | -0.01537 |    0.10632 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10655 | -0.00791 |    0.08207 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09331 | -0.00704 |    0.07211 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06754 | -0.00081 |    0.04854 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57276 | -0.00000 |    0.45260 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:10:24,224 - Total sparsity: 0.00

2018-11-02 20:10:24,224 - --- validate (epoch=110)-----------
2018-11-02 20:10:24,224 - 10000 samples (128 per mini-batch)
2018-11-02 20:10:24,948 - Epoch: [110][   50/   78]    Loss 0.524308    Top1 83.281250    Top5 98.843750    
2018-11-02 20:10:25,341 - ==> Top1: 83.050    Top5: 99.000    Loss: 0.527

2018-11-02 20:10:25,342 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:10:25,342 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:10:25,350 - 

2018-11-02 20:10:25,350 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:10:26,546 - Epoch: [111][   50/  391]    Overall Loss 0.325063    Objective Loss 0.325063    Top1 88.828125    Top5 99.609375    LR 0.300000    Time 0.023878    
2018-11-02 20:10:27,686 - Epoch: [111][  100/  391]    Overall Loss 0.338124    Objective Loss 0.338124    Top1 88.421875    Top5 99.585938    LR 0.300000    Time 0.023321    
2018-11-02 20:10:28,822 - Epoch: [111][  150/  391]    Overall Loss 0.332669    Objective Loss 0.332669    Top1 88.463542    Top5 99.588542    LR 0.300000    Time 0.023116    
2018-11-02 20:10:29,958 - Epoch: [111][  200/  391]    Overall Loss 0.339950    Objective Loss 0.339950    Top1 88.214844    Top5 99.554688    LR 0.300000    Time 0.023012    
2018-11-02 20:10:31,094 - Epoch: [111][  250/  391]    Overall Loss 0.339644    Objective Loss 0.339644    Top1 88.278125    Top5 99.562500    LR 0.300000    Time 0.022947    
2018-11-02 20:10:32,234 - Epoch: [111][  300/  391]    Overall Loss 0.344177    Objective Loss 0.344177    Top1 88.164062    Top5 99.559896    LR 0.300000    Time 0.022916    
2018-11-02 20:10:33,374 - Epoch: [111][  350/  391]    Overall Loss 0.344297    Objective Loss 0.344297    Top1 88.125000    Top5 99.575893    LR 0.300000    Time 0.022899    
2018-11-02 20:10:34,389 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58126 | -0.00962 |    0.36999 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15372 |  0.00329 |    0.09029 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15667 | -0.00109 |    0.10678 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19400 | -0.02224 |    0.13820 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19871 | -0.00839 |    0.14897 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20309 | -0.03028 |    0.14723 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18065 |  0.00259 |    0.12779 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21466 | -0.00858 |    0.15656 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17996 | -0.00756 |    0.13848 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39361 | -0.01692 |    0.26697 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15420 | -0.00912 |    0.11701 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13573 | -0.01185 |    0.10713 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15631 | -0.02121 |    0.12260 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12297 | -0.00272 |    0.09431 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15340 | -0.01491 |    0.12151 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13868 | -0.01018 |    0.10969 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21569 | -0.01995 |    0.16678 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13439 | -0.01485 |    0.10617 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10658 | -0.00824 |    0.08228 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09314 | -0.00848 |    0.07227 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06737 | -0.00138 |    0.04862 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56560 | -0.00000 |    0.44692 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:10:34,389 - Total sparsity: 0.00

2018-11-02 20:10:34,389 - --- validate (epoch=111)-----------
2018-11-02 20:10:34,389 - 10000 samples (128 per mini-batch)
2018-11-02 20:10:35,109 - Epoch: [111][   50/   78]    Loss 0.537423    Top1 82.859375    Top5 99.093750    
2018-11-02 20:10:35,502 - ==> Top1: 83.090    Top5: 99.210    Loss: 0.528

2018-11-02 20:10:35,502 - ==> Best Top1: 85.560   On Epoch: 74

2018-11-02 20:10:35,503 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:10:35,513 - 

2018-11-02 20:10:35,514 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:10:36,712 - Epoch: [112][   50/  391]    Overall Loss 0.352962    Objective Loss 0.352962    Top1 87.750000    Top5 99.593750    LR 0.300000    Time 0.023934    
2018-11-02 20:10:37,853 - Epoch: [112][  100/  391]    Overall Loss 0.348732    Objective Loss 0.348732    Top1 87.843750    Top5 99.570312    LR 0.300000    Time 0.023352    
2018-11-02 20:10:38,991 - Epoch: [112][  150/  391]    Overall Loss 0.355258    Objective Loss 0.355258    Top1 87.666667    Top5 99.578125    LR 0.300000    Time 0.023145    
2018-11-02 20:10:40,129 - Epoch: [112][  200/  391]    Overall Loss 0.352599    Objective Loss 0.352599    Top1 87.828125    Top5 99.589844    LR 0.300000    Time 0.023047    
2018-11-02 20:10:41,268 - Epoch: [112][  250/  391]    Overall Loss 0.353798    Objective Loss 0.353798    Top1 87.762500    Top5 99.565625    LR 0.300000    Time 0.022986    
2018-11-02 20:10:42,404 - Epoch: [112][  300/  391]    Overall Loss 0.356517    Objective Loss 0.356517    Top1 87.671875    Top5 99.567708    LR 0.300000    Time 0.022939    
2018-11-02 20:10:43,542 - Epoch: [112][  350/  391]    Overall Loss 0.357931    Objective Loss 0.357931    Top1 87.616071    Top5 99.564732    LR 0.300000    Time 0.022909    
2018-11-02 20:10:44,558 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58329 |  0.00039 |    0.36892 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15181 |  0.00138 |    0.08893 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15547 |  0.00042 |    0.10651 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19338 | -0.02269 |    0.13850 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19852 | -0.00927 |    0.14912 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20277 | -0.03224 |    0.14687 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18076 |  0.00234 |    0.12795 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21485 | -0.01123 |    0.15747 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18012 | -0.00584 |    0.13772 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39286 | -0.00815 |    0.26417 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15365 | -0.00669 |    0.11624 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13513 | -0.01157 |    0.10647 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15621 | -0.02277 |    0.12262 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12342 | -0.00335 |    0.09499 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15352 | -0.01439 |    0.12167 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13882 | -0.00945 |    0.10964 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21584 | -0.02013 |    0.16681 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13402 | -0.01550 |    0.10574 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10674 | -0.00810 |    0.08243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09382 | -0.00811 |    0.07278 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06768 | -0.00120 |    0.04881 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56664 | -0.00000 |    0.44768 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:10:44,558 - Total sparsity: 0.00

2018-11-02 20:10:44,558 - --- validate (epoch=112)-----------
2018-11-02 20:10:44,558 - 10000 samples (128 per mini-batch)
2018-11-02 20:10:45,282 - Epoch: [112][   50/   78]    Loss 0.412460    Top1 86.078125    Top5 99.375000    
2018-11-02 20:10:45,672 - ==> Top1: 86.340    Top5: 99.430    Loss: 0.398

2018-11-02 20:10:45,672 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:10:45,672 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:10:45,688 - 

2018-11-02 20:10:45,688 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:10:46,855 - Epoch: [113][   50/  391]    Overall Loss 0.329004    Objective Loss 0.329004    Top1 88.703125    Top5 99.671875    LR 0.300000    Time 0.023306    
2018-11-02 20:10:47,993 - Epoch: [113][  100/  391]    Overall Loss 0.334383    Objective Loss 0.334383    Top1 88.414062    Top5 99.687500    LR 0.300000    Time 0.023020    
2018-11-02 20:10:49,134 - Epoch: [113][  150/  391]    Overall Loss 0.338987    Objective Loss 0.338987    Top1 88.250000    Top5 99.687500    LR 0.300000    Time 0.022943    
2018-11-02 20:10:50,274 - Epoch: [113][  200/  391]    Overall Loss 0.345576    Objective Loss 0.345576    Top1 88.156250    Top5 99.636719    LR 0.300000    Time 0.022904    
2018-11-02 20:10:51,416 - Epoch: [113][  250/  391]    Overall Loss 0.346628    Objective Loss 0.346628    Top1 88.075000    Top5 99.621875    LR 0.300000    Time 0.022884    
2018-11-02 20:10:52,556 - Epoch: [113][  300/  391]    Overall Loss 0.346236    Objective Loss 0.346236    Top1 88.111979    Top5 99.609375    LR 0.300000    Time 0.022868    
2018-11-02 20:10:53,697 - Epoch: [113][  350/  391]    Overall Loss 0.346581    Objective Loss 0.346581    Top1 88.107143    Top5 99.611607    LR 0.300000    Time 0.022856    
2018-11-02 20:10:54,710 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58394 |  0.00303 |    0.36760 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15197 |  0.00019 |    0.08911 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15545 |  0.00127 |    0.10662 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19078 | -0.02379 |    0.13671 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19649 | -0.00850 |    0.14823 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20239 | -0.03193 |    0.14801 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18115 |  0.00234 |    0.12704 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21489 | -0.00982 |    0.15693 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17968 | -0.00461 |    0.13778 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39198 | -0.00769 |    0.26831 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15341 | -0.00913 |    0.11632 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13518 | -0.01161 |    0.10656 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15560 | -0.02367 |    0.12199 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12332 | -0.00276 |    0.09464 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15299 | -0.01534 |    0.12111 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13833 | -0.00995 |    0.10938 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21613 | -0.02137 |    0.16688 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13412 | -0.01395 |    0.10565 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10681 | -0.00781 |    0.08232 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09380 | -0.00780 |    0.07274 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06758 | -0.00126 |    0.04868 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56476 | -0.00000 |    0.44689 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:10:54,710 - Total sparsity: 0.00

2018-11-02 20:10:54,710 - --- validate (epoch=113)-----------
2018-11-02 20:10:54,711 - 10000 samples (128 per mini-batch)
2018-11-02 20:10:55,430 - Epoch: [113][   50/   78]    Loss 0.551884    Top1 82.312500    Top5 99.250000    
2018-11-02 20:10:55,824 - ==> Top1: 82.780    Top5: 99.270    Loss: 0.543

2018-11-02 20:10:55,825 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:10:55,825 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:10:55,833 - 

2018-11-02 20:10:55,833 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:10:57,031 - Epoch: [114][   50/  391]    Overall Loss 0.319302    Objective Loss 0.319302    Top1 88.953125    Top5 99.703125    LR 0.300000    Time 0.023917    
2018-11-02 20:10:58,170 - Epoch: [114][  100/  391]    Overall Loss 0.328264    Objective Loss 0.328264    Top1 88.476562    Top5 99.734375    LR 0.300000    Time 0.023338    
2018-11-02 20:10:59,309 - Epoch: [114][  150/  391]    Overall Loss 0.331718    Objective Loss 0.331718    Top1 88.223958    Top5 99.723958    LR 0.300000    Time 0.023144    
2018-11-02 20:11:00,448 - Epoch: [114][  200/  391]    Overall Loss 0.341509    Objective Loss 0.341509    Top1 88.015625    Top5 99.652344    LR 0.300000    Time 0.023043    
2018-11-02 20:11:01,586 - Epoch: [114][  250/  391]    Overall Loss 0.344195    Objective Loss 0.344195    Top1 87.959375    Top5 99.637500    LR 0.300000    Time 0.022982    
2018-11-02 20:11:02,726 - Epoch: [114][  300/  391]    Overall Loss 0.344113    Objective Loss 0.344113    Top1 87.989583    Top5 99.648438    LR 0.300000    Time 0.022948    
2018-11-02 20:11:03,863 - Epoch: [114][  350/  391]    Overall Loss 0.343726    Objective Loss 0.343726    Top1 87.993304    Top5 99.629464    LR 0.300000    Time 0.022915    
2018-11-02 20:11:04,879 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58249 | -0.00812 |    0.36653 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15252 |  0.00414 |    0.08901 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15537 | -0.00121 |    0.10638 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19117 | -0.02168 |    0.13587 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19654 | -0.01242 |    0.14862 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20185 | -0.03193 |    0.14722 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18014 | -0.00019 |    0.12699 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21453 | -0.00983 |    0.15627 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17967 | -0.00630 |    0.13743 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39075 | -0.01339 |    0.26512 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.00967 |    0.11607 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13480 | -0.01093 |    0.10607 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15555 | -0.02285 |    0.12157 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12278 | -0.00208 |    0.09446 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15305 | -0.01408 |    0.12093 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13808 | -0.01015 |    0.10921 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21549 | -0.02123 |    0.16738 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13357 | -0.01426 |    0.10512 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10655 | -0.00786 |    0.08219 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09398 | -0.00804 |    0.07279 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06762 | -0.00077 |    0.04862 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56711 | -0.00000 |    0.44668 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:11:04,880 - Total sparsity: 0.00

2018-11-02 20:11:04,880 - --- validate (epoch=114)-----------
2018-11-02 20:11:04,880 - 10000 samples (128 per mini-batch)
2018-11-02 20:11:05,592 - Epoch: [114][   50/   78]    Loss 0.645550    Top1 80.015625    Top5 99.000000    
2018-11-02 20:11:05,981 - ==> Top1: 80.550    Top5: 99.110    Loss: 0.626

2018-11-02 20:11:05,981 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:11:05,981 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:11:05,990 - 

2018-11-02 20:11:05,990 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:11:07,186 - Epoch: [115][   50/  391]    Overall Loss 0.350901    Objective Loss 0.350901    Top1 87.953125    Top5 99.687500    LR 0.300000    Time 0.023882    
2018-11-02 20:11:08,322 - Epoch: [115][  100/  391]    Overall Loss 0.339238    Objective Loss 0.339238    Top1 88.281250    Top5 99.671875    LR 0.300000    Time 0.023292    
2018-11-02 20:11:09,458 - Epoch: [115][  150/  391]    Overall Loss 0.346118    Objective Loss 0.346118    Top1 87.916667    Top5 99.619792    LR 0.300000    Time 0.023087    
2018-11-02 20:11:10,595 - Epoch: [115][  200/  391]    Overall Loss 0.348559    Objective Loss 0.348559    Top1 87.710938    Top5 99.613281    LR 0.300000    Time 0.022994    
2018-11-02 20:11:11,731 - Epoch: [115][  250/  391]    Overall Loss 0.356639    Objective Loss 0.356639    Top1 87.556250    Top5 99.618750    LR 0.300000    Time 0.022935    
2018-11-02 20:11:12,872 - Epoch: [115][  300/  391]    Overall Loss 0.357339    Objective Loss 0.357339    Top1 87.494792    Top5 99.614583    LR 0.300000    Time 0.022911    
2018-11-02 20:11:14,011 - Epoch: [115][  350/  391]    Overall Loss 0.355854    Objective Loss 0.355854    Top1 87.526786    Top5 99.616071    LR 0.300000    Time 0.022890    
2018-11-02 20:11:15,024 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58391 | -0.00485 |    0.36713 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15260 |  0.00690 |    0.08952 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15623 | -0.00173 |    0.10704 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19175 | -0.02364 |    0.13786 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19721 | -0.00930 |    0.14840 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20354 | -0.02988 |    0.14816 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18091 | -0.00067 |    0.12838 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21527 | -0.00878 |    0.15615 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18076 | -0.00645 |    0.13875 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39216 | -0.01462 |    0.26767 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15336 | -0.00726 |    0.11581 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13499 | -0.01215 |    0.10593 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15589 | -0.02373 |    0.12244 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12286 | -0.00220 |    0.09457 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15394 | -0.01444 |    0.12154 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13881 | -0.01014 |    0.10958 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21652 | -0.02221 |    0.16899 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13400 | -0.01419 |    0.10550 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10691 | -0.00849 |    0.08243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09478 | -0.00752 |    0.07348 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06806 | -0.00051 |    0.04888 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56539 | -0.00000 |    0.44555 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:11:15,024 - Total sparsity: 0.00

2018-11-02 20:11:15,024 - --- validate (epoch=115)-----------
2018-11-02 20:11:15,025 - 10000 samples (128 per mini-batch)
2018-11-02 20:11:15,744 - Epoch: [115][   50/   78]    Loss 0.564161    Top1 82.671875    Top5 99.062500    
2018-11-02 20:11:16,130 - ==> Top1: 82.670    Top5: 99.060    Loss: 0.557

2018-11-02 20:11:16,131 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:11:16,131 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:11:16,139 - 

2018-11-02 20:11:16,140 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:11:17,333 - Epoch: [116][   50/  391]    Overall Loss 0.333288    Objective Loss 0.333288    Top1 88.625000    Top5 99.671875    LR 0.300000    Time 0.023828    
2018-11-02 20:11:18,470 - Epoch: [116][  100/  391]    Overall Loss 0.340168    Objective Loss 0.340168    Top1 88.453125    Top5 99.585938    LR 0.300000    Time 0.023265    
2018-11-02 20:11:19,607 - Epoch: [116][  150/  391]    Overall Loss 0.346464    Objective Loss 0.346464    Top1 88.286458    Top5 99.546875    LR 0.300000    Time 0.023082    
2018-11-02 20:11:20,744 - Epoch: [116][  200/  391]    Overall Loss 0.349537    Objective Loss 0.349537    Top1 88.191406    Top5 99.542969    LR 0.300000    Time 0.022992    
2018-11-02 20:11:21,884 - Epoch: [116][  250/  391]    Overall Loss 0.347111    Objective Loss 0.347111    Top1 88.156250    Top5 99.559375    LR 0.300000    Time 0.022949    
2018-11-02 20:11:23,022 - Epoch: [116][  300/  391]    Overall Loss 0.351174    Objective Loss 0.351174    Top1 88.028646    Top5 99.554688    LR 0.300000    Time 0.022902    
2018-11-02 20:11:24,161 - Epoch: [116][  350/  391]    Overall Loss 0.353172    Objective Loss 0.353172    Top1 87.973214    Top5 99.544643    LR 0.300000    Time 0.022881    
2018-11-02 20:11:25,179 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57833 | -0.00580 |    0.36492 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15165 |  0.00039 |    0.08817 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15500 |  0.00057 |    0.10524 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19126 | -0.02335 |    0.13749 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19575 | -0.01136 |    0.14738 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20261 | -0.03085 |    0.14676 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18117 | -0.00058 |    0.12866 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21453 | -0.01235 |    0.15577 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17998 | -0.00635 |    0.13777 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39335 | -0.01207 |    0.26745 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15326 | -0.00815 |    0.11598 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13526 | -0.01287 |    0.10618 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15567 | -0.02536 |    0.12248 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12266 | -0.00094 |    0.09433 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15309 | -0.01396 |    0.12094 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13835 | -0.00983 |    0.10910 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21742 | -0.02221 |    0.16994 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13391 | -0.01398 |    0.10529 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10691 | -0.00772 |    0.08243 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09498 | -0.00759 |    0.07374 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06790 | -0.00053 |    0.04880 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56341 | -0.00000 |    0.44179 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:11:25,179 - Total sparsity: 0.00

2018-11-02 20:11:25,179 - --- validate (epoch=116)-----------
2018-11-02 20:11:25,179 - 10000 samples (128 per mini-batch)
2018-11-02 20:11:25,903 - Epoch: [116][   50/   78]    Loss 0.512306    Top1 83.734375    Top5 99.234375    
2018-11-02 20:11:26,295 - ==> Top1: 83.680    Top5: 99.340    Loss: 0.510

2018-11-02 20:11:26,296 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:11:26,296 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:11:26,308 - 

2018-11-02 20:11:26,308 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:11:27,504 - Epoch: [117][   50/  391]    Overall Loss 0.354314    Objective Loss 0.354314    Top1 88.156250    Top5 99.687500    LR 0.300000    Time 0.023873    
2018-11-02 20:11:28,645 - Epoch: [117][  100/  391]    Overall Loss 0.338712    Objective Loss 0.338712    Top1 88.640625    Top5 99.640625    LR 0.300000    Time 0.023336    
2018-11-02 20:11:29,784 - Epoch: [117][  150/  391]    Overall Loss 0.339697    Objective Loss 0.339697    Top1 88.541667    Top5 99.645833    LR 0.300000    Time 0.023144    
2018-11-02 20:11:30,926 - Epoch: [117][  200/  391]    Overall Loss 0.340104    Objective Loss 0.340104    Top1 88.406250    Top5 99.667969    LR 0.300000    Time 0.023061    
2018-11-02 20:11:32,067 - Epoch: [117][  250/  391]    Overall Loss 0.345998    Objective Loss 0.345998    Top1 88.278125    Top5 99.650000    LR 0.300000    Time 0.023008    
2018-11-02 20:11:33,205 - Epoch: [117][  300/  391]    Overall Loss 0.350432    Objective Loss 0.350432    Top1 88.101562    Top5 99.651042    LR 0.300000    Time 0.022961    
2018-11-02 20:11:34,342 - Epoch: [117][  350/  391]    Overall Loss 0.352743    Objective Loss 0.352743    Top1 87.970982    Top5 99.625000    LR 0.300000    Time 0.022926    
2018-11-02 20:11:35,355 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58168 | -0.00096 |    0.36212 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15336 |  0.00013 |    0.08960 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15599 |  0.00162 |    0.10554 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19108 | -0.02520 |    0.13854 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19617 | -0.00665 |    0.14747 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20291 | -0.03033 |    0.14651 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18189 |  0.00261 |    0.12951 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21528 | -0.00932 |    0.15659 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18014 | -0.00646 |    0.13762 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39365 | -0.00715 |    0.26851 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15391 | -0.00665 |    0.11600 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13609 | -0.01250 |    0.10680 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15596 | -0.02606 |    0.12268 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12285 | -0.00077 |    0.09445 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15333 | -0.01448 |    0.12123 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13877 | -0.01026 |    0.10970 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21763 | -0.02141 |    0.16868 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13407 | -0.01418 |    0.10558 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10720 | -0.00784 |    0.08271 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09550 | -0.00809 |    0.07407 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06804 | -0.00092 |    0.04888 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56466 | -0.00000 |    0.44450 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:11:35,355 - Total sparsity: 0.00

2018-11-02 20:11:35,356 - --- validate (epoch=117)-----------
2018-11-02 20:11:35,356 - 10000 samples (128 per mini-batch)
2018-11-02 20:11:36,123 - Epoch: [117][   50/   78]    Loss 0.577824    Top1 83.203125    Top5 99.093750    
2018-11-02 20:11:36,536 - ==> Top1: 83.090    Top5: 99.140    Loss: 0.571

2018-11-02 20:11:36,537 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:11:36,537 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:11:36,549 - 

2018-11-02 20:11:36,549 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:11:37,745 - Epoch: [118][   50/  391]    Overall Loss 0.317889    Objective Loss 0.317889    Top1 89.109375    Top5 99.640625    LR 0.300000    Time 0.023898    
2018-11-02 20:11:38,883 - Epoch: [118][  100/  391]    Overall Loss 0.327573    Objective Loss 0.327573    Top1 88.726562    Top5 99.671875    LR 0.300000    Time 0.023313    
2018-11-02 20:11:40,022 - Epoch: [118][  150/  391]    Overall Loss 0.337918    Objective Loss 0.337918    Top1 88.520833    Top5 99.651042    LR 0.300000    Time 0.023126    
2018-11-02 20:11:41,160 - Epoch: [118][  200/  391]    Overall Loss 0.340188    Objective Loss 0.340188    Top1 88.359375    Top5 99.640625    LR 0.300000    Time 0.023027    
2018-11-02 20:11:42,297 - Epoch: [118][  250/  391]    Overall Loss 0.341165    Objective Loss 0.341165    Top1 88.362500    Top5 99.615625    LR 0.300000    Time 0.022965    
2018-11-02 20:11:43,437 - Epoch: [118][  300/  391]    Overall Loss 0.346346    Objective Loss 0.346346    Top1 88.132812    Top5 99.598958    LR 0.300000    Time 0.022933    
2018-11-02 20:11:44,575 - Epoch: [118][  350/  391]    Overall Loss 0.346611    Objective Loss 0.346611    Top1 88.082589    Top5 99.602679    LR 0.300000    Time 0.022907    
2018-11-02 20:11:45,588 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57764 | -0.00714 |    0.35942 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15153 |  0.00229 |    0.08797 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15465 | -0.00299 |    0.10538 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19093 | -0.02345 |    0.13721 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19584 | -0.00948 |    0.14760 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20190 | -0.02966 |    0.14614 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18130 | -0.00095 |    0.12838 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21470 | -0.00928 |    0.15622 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17945 | -0.00734 |    0.13713 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39284 | -0.00246 |    0.26815 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15321 | -0.00746 |    0.11531 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13568 | -0.01102 |    0.10612 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15613 | -0.02508 |    0.12262 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12312 | -0.00119 |    0.09521 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15286 | -0.01420 |    0.12092 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13852 | -0.00973 |    0.10931 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21755 | -0.02177 |    0.16912 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13396 | -0.01352 |    0.10541 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10728 | -0.00799 |    0.08279 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09590 | -0.00811 |    0.07428 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06828 | -0.00055 |    0.04903 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56432 | -0.00000 |    0.44360 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:11:45,589 - Total sparsity: 0.00

2018-11-02 20:11:45,589 - --- validate (epoch=118)-----------
2018-11-02 20:11:45,589 - 10000 samples (128 per mini-batch)
2018-11-02 20:11:46,311 - Epoch: [118][   50/   78]    Loss 0.581377    Top1 81.562500    Top5 99.062500    
2018-11-02 20:11:46,701 - ==> Top1: 81.410    Top5: 99.160    Loss: 0.579

2018-11-02 20:11:46,702 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:11:46,702 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:11:46,710 - 

2018-11-02 20:11:46,711 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:11:47,904 - Epoch: [119][   50/  391]    Overall Loss 0.309591    Objective Loss 0.309591    Top1 88.953125    Top5 99.656250    LR 0.300000    Time 0.023834    
2018-11-02 20:11:49,045 - Epoch: [119][  100/  391]    Overall Loss 0.336421    Objective Loss 0.336421    Top1 88.117188    Top5 99.625000    LR 0.300000    Time 0.023312    
2018-11-02 20:11:50,186 - Epoch: [119][  150/  391]    Overall Loss 0.338255    Objective Loss 0.338255    Top1 88.140625    Top5 99.593750    LR 0.300000    Time 0.023141    
2018-11-02 20:11:51,329 - Epoch: [119][  200/  391]    Overall Loss 0.340081    Objective Loss 0.340081    Top1 88.164062    Top5 99.593750    LR 0.300000    Time 0.023063    
2018-11-02 20:11:52,470 - Epoch: [119][  250/  391]    Overall Loss 0.342082    Objective Loss 0.342082    Top1 88.100000    Top5 99.593750    LR 0.300000    Time 0.023008    
2018-11-02 20:11:53,610 - Epoch: [119][  300/  391]    Overall Loss 0.346321    Objective Loss 0.346321    Top1 87.981771    Top5 99.578125    LR 0.300000    Time 0.022971    
2018-11-02 20:11:54,751 - Epoch: [119][  350/  391]    Overall Loss 0.348946    Objective Loss 0.348946    Top1 87.982143    Top5 99.546875    LR 0.300000    Time 0.022945    
2018-11-02 20:11:55,767 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57777 |  0.00078 |    0.35939 |
|  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15192 |  0.00155 |    0.08958 |
|  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15485 | -0.00370 |    0.10626 |
|  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19196 | -0.02280 |    0.13791 |
|  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19633 | -0.00874 |    0.14696 |
|  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20034 | -0.03112 |    0.14515 |
|  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18018 |  0.00153 |    0.12741 |
|  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21419 | -0.01013 |    0.15614 |
|  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17952 | -0.00627 |    0.13746 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39319 | -0.00925 |    0.26537 |
| 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15336 | -0.00728 |    0.11512 |
| 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13582 | -0.01148 |    0.10625 |
| 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15587 | -0.02451 |    0.12208 |
| 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12295 | -0.00033 |    0.09485 |
| 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15320 | -0.01436 |    0.12106 |
| 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13854 | -0.00967 |    0.10930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21729 | -0.02137 |    0.16877 |
| 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13373 | -0.01340 |    0.10536 |
| 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10744 | -0.00804 |    0.08292 |
| 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09627 | -0.00827 |    0.07450 |
| 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06862 | -0.00046 |    0.04929 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56709 | -0.00000 |    0.44440 |
| 22 | Total sparsity:                     | -              |        270896 |         270896 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:11:55,768 - Total sparsity: 0.00

2018-11-02 20:11:55,768 - --- validate (epoch=119)-----------
2018-11-02 20:11:55,768 - 10000 samples (128 per mini-batch)
2018-11-02 20:11:56,488 - Epoch: [119][   50/   78]    Loss 0.726162    Top1 79.078125    Top5 98.500000    
2018-11-02 20:11:56,879 - ==> Top1: 79.380    Top5: 98.500    Loss: 0.712

2018-11-02 20:11:56,879 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:11:56,879 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:11:56,887 - 

2018-11-02 20:11:56,900 - L1RankedStructureParameterPruner - param: module.layer1.0.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-02 20:11:56,900 - L1RankedStructureParameterPruner - param: module.layer1.1.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-02 20:11:56,901 - L1RankedStructureParameterPruner - param: module.layer1.2.conv1.weight pruned=0.562 goal=0.600 (9/16)
2018-11-02 20:11:56,901 - L1RankedStructureParameterPruner - param: module.layer2.0.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-02 20:11:56,902 - L1RankedStructureParameterPruner - param: module.layer2.1.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-02 20:11:56,902 - L1RankedStructureParameterPruner - param: module.layer2.2.conv1.weight pruned=0.594 goal=0.600 (19/32)
2018-11-02 20:11:56,903 - L1RankedStructureParameterPruner - param: module.layer3.0.conv1.weight pruned=0.594 goal=0.600 (38/64)
2018-11-02 20:11:56,904 - L1RankedStructureParameterPruner - param: module.layer3.1.conv1.weight pruned=0.594 goal=0.600 (38/64)
2018-11-02 20:11:56,905 - L1RankedStructureParameterPruner - param: module.layer3.2.conv1.weight pruned=0.594 goal=0.600 (38/64)
2018-11-02 20:11:56,905 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:11:56,946 - ==> using cifar10 dataset
2018-11-02 20:11:56,947 - => creating resnet20_cifar model for CIFAR10
2018-11-02 20:11:56,983 - Invoking create_thinning_recipe_filters
2018-11-02 20:11:56,984 - In tensor module.layer1.0.conv1.weight found 9/16 zero filters
2018-11-02 20:11:56,985 - In tensor module.layer1.1.conv1.weight found 9/16 zero filters
2018-11-02 20:11:56,986 - In tensor module.layer1.2.conv1.weight found 9/16 zero filters
2018-11-02 20:11:56,987 - In tensor module.layer2.0.conv1.weight found 19/32 zero filters
2018-11-02 20:11:56,989 - In tensor module.layer2.1.conv1.weight found 19/32 zero filters
2018-11-02 20:11:56,990 - In tensor module.layer2.2.conv1.weight found 19/32 zero filters
2018-11-02 20:11:56,990 - In tensor module.layer3.0.conv1.weight found 38/64 zero filters
2018-11-02 20:11:56,991 - In tensor module.layer3.1.conv1.weight found 38/64 zero filters
2018-11-02 20:11:56,992 - In tensor module.layer3.2.conv1.weight found 38/64 zero filters
2018-11-02 20:11:57,000 - Created, applied and saved a thinning recipe
2018-11-02 20:11:57,973 - Epoch: [120][   50/  391]    Overall Loss 0.860110    Objective Loss 0.860110    Top1 70.843750    Top5 97.718750    LR 0.300000    Time 0.021326    
2018-11-02 20:11:58,954 - Epoch: [120][  100/  391]    Overall Loss 0.741686    Objective Loss 0.741686    Top1 74.812500    Top5 98.203125    LR 0.300000    Time 0.020466    
2018-11-02 20:11:59,936 - Epoch: [120][  150/  391]    Overall Loss 0.697492    Objective Loss 0.697492    Top1 76.333333    Top5 98.416667    LR 0.300000    Time 0.020181    
2018-11-02 20:12:00,920 - Epoch: [120][  200/  391]    Overall Loss 0.665044    Objective Loss 0.665044    Top1 77.429688    Top5 98.609375    LR 0.300000    Time 0.020048    
2018-11-02 20:12:01,901 - Epoch: [120][  250/  391]    Overall Loss 0.644770    Objective Loss 0.644770    Top1 78.100000    Top5 98.700000    LR 0.300000    Time 0.019945    
2018-11-02 20:12:02,881 - Epoch: [120][  300/  391]    Overall Loss 0.629657    Objective Loss 0.629657    Top1 78.541667    Top5 98.763021    LR 0.300000    Time 0.019881    
2018-11-02 20:12:03,863 - Epoch: [120][  350/  391]    Overall Loss 0.615319    Objective Loss 0.615319    Top1 78.950893    Top5 98.810268    LR 0.300000    Time 0.019844    
2018-11-02 20:12:04,747 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59210 | -0.00500 |    0.37316 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20971 |  0.00253 |    0.12876 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22027 | -0.00560 |    0.16314 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25626 | -0.04720 |    0.19470 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26422 |  0.00355 |    0.20596 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25053 | -0.04022 |    0.18987 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25014 | -0.00085 |    0.18522 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27703 | -0.01800 |    0.20943 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22874 | -0.01165 |    0.17563 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41809 | -0.01630 |    0.28716 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19225 | -0.00606 |    0.14596 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16450 | -0.01607 |    0.12972 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20086 | -0.03178 |    0.15945 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15159 | -0.00626 |    0.11600 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18769 | -0.02963 |    0.15138 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17170 | -0.00312 |    0.13492 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23561 | -0.02479 |    0.18390 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16165 | -0.01833 |    0.12762 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12921 | -0.00644 |    0.09882 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12741 | -0.01447 |    0.09974 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08873 |  0.00282 |    0.06278 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57172 | -0.00000 |    0.44580 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:12:04,747 - Total sparsity: 0.00

2018-11-02 20:12:04,747 - --- validate (epoch=120)-----------
2018-11-02 20:12:04,747 - 10000 samples (128 per mini-batch)
2018-11-02 20:12:05,460 - Epoch: [120][   50/   78]    Loss 0.743985    Top1 77.203125    Top5 98.796875    
2018-11-02 20:12:05,841 - ==> Top1: 77.240    Top5: 98.880    Loss: 0.732

2018-11-02 20:12:05,842 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:12:05,842 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:12:05,853 - 

2018-11-02 20:12:05,854 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:12:06,873 - Epoch: [121][   50/  391]    Overall Loss 0.487368    Objective Loss 0.487368    Top1 83.390625    Top5 99.453125    LR 0.300000    Time 0.020352    
2018-11-02 20:12:07,832 - Epoch: [121][  100/  391]    Overall Loss 0.507348    Objective Loss 0.507348    Top1 82.976562    Top5 99.218750    LR 0.300000    Time 0.019755    
2018-11-02 20:12:08,789 - Epoch: [121][  150/  391]    Overall Loss 0.507077    Objective Loss 0.507077    Top1 82.854167    Top5 99.156250    LR 0.300000    Time 0.019545    
2018-11-02 20:12:09,747 - Epoch: [121][  200/  391]    Overall Loss 0.508570    Objective Loss 0.508570    Top1 82.765625    Top5 99.152344    LR 0.300000    Time 0.019442    
2018-11-02 20:12:10,707 - Epoch: [121][  250/  391]    Overall Loss 0.511338    Objective Loss 0.511338    Top1 82.584375    Top5 99.159375    LR 0.300000    Time 0.019388    
2018-11-02 20:12:11,666 - Epoch: [121][  300/  391]    Overall Loss 0.510033    Objective Loss 0.510033    Top1 82.606771    Top5 99.148438    LR 0.300000    Time 0.019351    
2018-11-02 20:12:12,627 - Epoch: [121][  350/  391]    Overall Loss 0.508311    Objective Loss 0.508311    Top1 82.671875    Top5 99.169643    LR 0.300000    Time 0.019329    
2018-11-02 20:12:13,504 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59544 | -0.00246 |    0.37487 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21785 |  0.00060 |    0.13350 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22832 | -0.00576 |    0.16864 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26355 | -0.05077 |    0.19911 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27380 |  0.00510 |    0.21329 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25809 | -0.04095 |    0.19588 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25750 | -0.00235 |    0.19039 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29419 | -0.01488 |    0.22179 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24193 | -0.01244 |    0.18522 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42759 | -0.01664 |    0.29785 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20079 | -0.00454 |    0.15125 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17174 | -0.01546 |    0.13578 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20825 | -0.03274 |    0.16583 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15614 | -0.00680 |    0.12021 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19605 | -0.02799 |    0.15819 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17990 | -0.00298 |    0.14168 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24399 | -0.02901 |    0.19141 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16794 | -0.01762 |    0.13255 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13506 | -0.00599 |    0.10311 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13417 | -0.01690 |    0.10504 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09313 |  0.00395 |    0.06579 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57594 | -0.00000 |    0.44980 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:12:13,504 - Total sparsity: 0.00

2018-11-02 20:12:13,505 - --- validate (epoch=121)-----------
2018-11-02 20:12:13,505 - 10000 samples (128 per mini-batch)
2018-11-02 20:12:14,218 - Epoch: [121][   50/   78]    Loss 0.699906    Top1 78.062500    Top5 98.265625    
2018-11-02 20:12:14,607 - ==> Top1: 77.450    Top5: 98.240    Loss: 0.718

2018-11-02 20:12:14,607 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:12:14,608 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:12:14,618 - 

2018-11-02 20:12:14,618 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:12:15,687 - Epoch: [122][   50/  391]    Overall Loss 0.471242    Objective Loss 0.471242    Top1 83.765625    Top5 99.234375    LR 0.285000    Time 0.021341    
2018-11-02 20:12:16,723 - Epoch: [122][  100/  391]    Overall Loss 0.481796    Objective Loss 0.481796    Top1 83.320312    Top5 99.148438    LR 0.285000    Time 0.021024    
2018-11-02 20:12:17,743 - Epoch: [122][  150/  391]    Overall Loss 0.476261    Objective Loss 0.476261    Top1 83.421875    Top5 99.203125    LR 0.285000    Time 0.020809    
2018-11-02 20:12:18,703 - Epoch: [122][  200/  391]    Overall Loss 0.476562    Objective Loss 0.476562    Top1 83.414062    Top5 99.214844    LR 0.285000    Time 0.020382    
2018-11-02 20:12:19,662 - Epoch: [122][  250/  391]    Overall Loss 0.473832    Objective Loss 0.473832    Top1 83.575000    Top5 99.212500    LR 0.285000    Time 0.020135    
2018-11-02 20:12:20,623 - Epoch: [122][  300/  391]    Overall Loss 0.473713    Objective Loss 0.473713    Top1 83.669271    Top5 99.229167    LR 0.285000    Time 0.019980    
2018-11-02 20:12:21,581 - Epoch: [122][  350/  391]    Overall Loss 0.473935    Objective Loss 0.473935    Top1 83.627232    Top5 99.245536    LR 0.285000    Time 0.019860    
2018-11-02 20:12:22,447 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59280 | -0.00924 |    0.37112 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22269 |  0.00154 |    0.13622 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22890 | -0.00953 |    0.16732 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26478 | -0.05491 |    0.20041 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27821 |  0.00434 |    0.21786 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26204 | -0.04523 |    0.19860 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26049 |  0.00071 |    0.19156 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30103 | -0.01330 |    0.22603 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24677 | -0.01367 |    0.18924 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43276 | -0.01775 |    0.30389 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20478 | -0.00523 |    0.15505 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17433 | -0.01374 |    0.13769 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21044 | -0.03330 |    0.16719 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15752 | -0.00614 |    0.12179 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19960 | -0.03000 |    0.16056 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18388 | -0.00448 |    0.14499 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24647 | -0.02920 |    0.19241 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17043 | -0.01741 |    0.13436 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13769 | -0.00800 |    0.10513 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13717 | -0.01653 |    0.10721 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09476 |  0.00517 |    0.06704 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57827 | -0.00000 |    0.45041 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:12:22,448 - Total sparsity: 0.00

2018-11-02 20:12:22,448 - --- validate (epoch=122)-----------
2018-11-02 20:12:22,448 - 10000 samples (128 per mini-batch)
2018-11-02 20:12:23,168 - Epoch: [122][   50/   78]    Loss 0.725063    Top1 76.890625    Top5 98.562500    
2018-11-02 20:12:23,559 - ==> Top1: 76.850    Top5: 98.680    Loss: 0.725

2018-11-02 20:12:23,560 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:12:23,560 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:12:23,567 - 

2018-11-02 20:12:23,567 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:12:24,594 - Epoch: [123][   50/  391]    Overall Loss 0.444530    Objective Loss 0.444530    Top1 84.359375    Top5 99.500000    LR 0.270750    Time 0.020503    
2018-11-02 20:12:25,558 - Epoch: [123][  100/  391]    Overall Loss 0.438166    Objective Loss 0.438166    Top1 84.726562    Top5 99.429688    LR 0.270750    Time 0.019878    
2018-11-02 20:12:26,541 - Epoch: [123][  150/  391]    Overall Loss 0.446541    Objective Loss 0.446541    Top1 84.354167    Top5 99.411458    LR 0.270750    Time 0.019801    
2018-11-02 20:12:27,637 - Epoch: [123][  200/  391]    Overall Loss 0.448151    Objective Loss 0.448151    Top1 84.398438    Top5 99.363281    LR 0.270750    Time 0.020322    
2018-11-02 20:12:28,699 - Epoch: [123][  250/  391]    Overall Loss 0.451514    Objective Loss 0.451514    Top1 84.325000    Top5 99.381250    LR 0.270750    Time 0.020502    
2018-11-02 20:12:29,659 - Epoch: [123][  300/  391]    Overall Loss 0.448192    Objective Loss 0.448192    Top1 84.484375    Top5 99.385417    LR 0.270750    Time 0.020281    
2018-11-02 20:12:30,620 - Epoch: [123][  350/  391]    Overall Loss 0.447179    Objective Loss 0.447179    Top1 84.504464    Top5 99.366071    LR 0.270750    Time 0.020125    
2018-11-02 20:12:31,487 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.59140 | -0.00460 |    0.37209 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22362 |  0.00327 |    0.13784 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22937 | -0.01155 |    0.16875 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26708 | -0.05451 |    0.20100 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28188 |  0.00631 |    0.21984 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26337 | -0.04528 |    0.19827 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26016 | -0.00128 |    0.19128 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30384 | -0.01580 |    0.22880 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24907 | -0.01185 |    0.19106 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43269 | -0.01755 |    0.30141 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20612 | -0.00663 |    0.15593 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17544 | -0.01345 |    0.13841 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21161 | -0.03279 |    0.16886 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15844 | -0.00585 |    0.12215 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20114 | -0.02942 |    0.16107 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18599 | -0.00485 |    0.14633 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24628 | -0.03037 |    0.19283 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17164 | -0.01665 |    0.13527 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13942 | -0.00869 |    0.10701 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13946 | -0.01631 |    0.10933 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09616 |  0.00429 |    0.06812 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58023 | -0.00000 |    0.45109 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:12:31,487 - Total sparsity: 0.00

2018-11-02 20:12:31,488 - --- validate (epoch=123)-----------
2018-11-02 20:12:31,488 - 10000 samples (128 per mini-batch)
2018-11-02 20:12:32,191 - Epoch: [123][   50/   78]    Loss 0.770202    Top1 75.015625    Top5 98.609375    
2018-11-02 20:12:32,573 - ==> Top1: 74.980    Top5: 98.670    Loss: 0.766

2018-11-02 20:12:32,574 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:12:32,574 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:12:32,584 - 

2018-11-02 20:12:32,585 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:12:33,604 - Epoch: [124][   50/  391]    Overall Loss 0.419402    Objective Loss 0.419402    Top1 85.828125    Top5 99.406250    LR 0.257212    Time 0.020339    
2018-11-02 20:12:34,564 - Epoch: [124][  100/  391]    Overall Loss 0.428875    Objective Loss 0.428875    Top1 85.421875    Top5 99.312500    LR 0.257212    Time 0.019758    
2018-11-02 20:12:35,578 - Epoch: [124][  150/  391]    Overall Loss 0.425783    Objective Loss 0.425783    Top1 85.239583    Top5 99.333333    LR 0.257212    Time 0.019923    
2018-11-02 20:12:36,545 - Epoch: [124][  200/  391]    Overall Loss 0.425229    Objective Loss 0.425229    Top1 85.234375    Top5 99.367188    LR 0.257212    Time 0.019772    
2018-11-02 20:12:37,516 - Epoch: [124][  250/  391]    Overall Loss 0.430302    Objective Loss 0.430302    Top1 85.096875    Top5 99.353125    LR 0.257212    Time 0.019699    
2018-11-02 20:12:38,499 - Epoch: [124][  300/  391]    Overall Loss 0.431413    Objective Loss 0.431413    Top1 85.013021    Top5 99.372396    LR 0.257212    Time 0.019689    
2018-11-02 20:12:39,456 - Epoch: [124][  350/  391]    Overall Loss 0.434166    Objective Loss 0.434166    Top1 84.964286    Top5 99.359375    LR 0.257212    Time 0.019606    
2018-11-02 20:12:40,324 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58885 | -0.01002 |    0.37199 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22251 |  0.00346 |    0.13650 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22844 | -0.01134 |    0.16935 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26677 | -0.05395 |    0.20176 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28117 |  0.00381 |    0.21825 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26311 | -0.04517 |    0.19775 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25900 |  0.00110 |    0.18920 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30501 | -0.01495 |    0.22839 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24938 | -0.01240 |    0.19201 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42876 | -0.01448 |    0.30016 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20617 | -0.00463 |    0.15542 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17574 | -0.01483 |    0.13899 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21117 | -0.03163 |    0.16796 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15892 | -0.00788 |    0.12257 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20071 | -0.03125 |    0.16128 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18681 | -0.00374 |    0.14721 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24614 | -0.03118 |    0.19274 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17180 | -0.01834 |    0.13577 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13998 | -0.00758 |    0.10757 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14106 | -0.01768 |    0.11032 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09680 |  0.00398 |    0.06853 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57857 | -0.00000 |    0.45099 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:12:40,324 - Total sparsity: 0.00

2018-11-02 20:12:40,324 - --- validate (epoch=124)-----------
2018-11-02 20:12:40,324 - 10000 samples (128 per mini-batch)
2018-11-02 20:12:41,048 - Epoch: [124][   50/   78]    Loss 0.664002    Top1 77.906250    Top5 98.703125    
2018-11-02 20:12:41,439 - ==> Top1: 77.670    Top5: 98.750    Loss: 0.666

2018-11-02 20:12:41,440 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:12:41,440 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:12:41,450 - 

2018-11-02 20:12:41,451 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:12:42,471 - Epoch: [125][   50/  391]    Overall Loss 0.424844    Objective Loss 0.424844    Top1 85.484375    Top5 99.390625    LR 0.244352    Time 0.020365    
2018-11-02 20:12:43,430 - Epoch: [125][  100/  391]    Overall Loss 0.412425    Objective Loss 0.412425    Top1 85.773438    Top5 99.445312    LR 0.244352    Time 0.019760    
2018-11-02 20:12:44,388 - Epoch: [125][  150/  391]    Overall Loss 0.412677    Objective Loss 0.412677    Top1 85.927083    Top5 99.421875    LR 0.244352    Time 0.019552    
2018-11-02 20:12:45,352 - Epoch: [125][  200/  391]    Overall Loss 0.414750    Objective Loss 0.414750    Top1 85.789062    Top5 99.429688    LR 0.244352    Time 0.019479    
2018-11-02 20:12:46,326 - Epoch: [125][  250/  391]    Overall Loss 0.416298    Objective Loss 0.416298    Top1 85.715625    Top5 99.434375    LR 0.244352    Time 0.019459    
2018-11-02 20:12:47,299 - Epoch: [125][  300/  391]    Overall Loss 0.419446    Objective Loss 0.419446    Top1 85.570312    Top5 99.432292    LR 0.244352    Time 0.019454    
2018-11-02 20:12:48,280 - Epoch: [125][  350/  391]    Overall Loss 0.421038    Objective Loss 0.421038    Top1 85.520089    Top5 99.419643    LR 0.244352    Time 0.019475    
2018-11-02 20:12:49,170 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58201 | -0.00121 |    0.36053 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22118 |  0.00684 |    0.13505 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22823 | -0.01035 |    0.16970 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26620 | -0.05260 |    0.20097 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27940 |  0.00226 |    0.21978 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26141 | -0.04606 |    0.19779 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25746 | -0.00360 |    0.18706 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30434 | -0.01321 |    0.22699 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24873 | -0.01157 |    0.19188 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42402 | -0.02087 |    0.29383 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20531 | -0.00355 |    0.15484 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17484 | -0.01399 |    0.13878 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21085 | -0.03336 |    0.16829 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15957 | -0.00526 |    0.12322 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20017 | -0.03172 |    0.16124 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18653 | -0.00392 |    0.14692 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24468 | -0.02775 |    0.19135 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17146 | -0.01695 |    0.13516 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13971 | -0.00735 |    0.10724 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14151 | -0.01814 |    0.11095 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09675 |  0.00513 |    0.06875 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58085 | -0.00000 |    0.45324 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:12:49,170 - Total sparsity: 0.00

2018-11-02 20:12:49,170 - --- validate (epoch=125)-----------
2018-11-02 20:12:49,170 - 10000 samples (128 per mini-batch)
2018-11-02 20:12:49,897 - Epoch: [125][   50/   78]    Loss 0.478613    Top1 84.734375    Top5 99.234375    
2018-11-02 20:12:50,298 - ==> Top1: 84.540    Top5: 99.290    Loss: 0.485

2018-11-02 20:12:50,299 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:12:50,299 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:12:50,310 - 

2018-11-02 20:12:50,310 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:12:51,392 - Epoch: [126][   50/  391]    Overall Loss 0.358052    Objective Loss 0.358052    Top1 87.593750    Top5 99.406250    LR 0.232134    Time 0.021607    
2018-11-02 20:12:52,428 - Epoch: [126][  100/  391]    Overall Loss 0.376616    Objective Loss 0.376616    Top1 86.859375    Top5 99.460938    LR 0.232134    Time 0.021153    
2018-11-02 20:12:53,416 - Epoch: [126][  150/  391]    Overall Loss 0.388508    Objective Loss 0.388508    Top1 86.442708    Top5 99.494792    LR 0.232134    Time 0.020677    
2018-11-02 20:12:54,372 - Epoch: [126][  200/  391]    Overall Loss 0.394033    Objective Loss 0.394033    Top1 86.312500    Top5 99.476562    LR 0.232134    Time 0.020285    
2018-11-02 20:12:55,329 - Epoch: [126][  250/  391]    Overall Loss 0.398668    Objective Loss 0.398668    Top1 86.178125    Top5 99.465625    LR 0.232134    Time 0.020053    
2018-11-02 20:12:56,288 - Epoch: [126][  300/  391]    Overall Loss 0.399295    Objective Loss 0.399295    Top1 86.117188    Top5 99.494792    LR 0.232134    Time 0.019902    
2018-11-02 20:12:57,257 - Epoch: [126][  350/  391]    Overall Loss 0.402018    Objective Loss 0.402018    Top1 86.026786    Top5 99.475446    LR 0.232134    Time 0.019825    
2018-11-02 20:12:58,119 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57255 | -0.00207 |    0.35516 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22001 |  0.00491 |    0.13451 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22749 | -0.00603 |    0.16910 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26482 | -0.05261 |    0.19953 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27798 |  0.00407 |    0.21822 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26093 | -0.04399 |    0.19894 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25609 | -0.00818 |    0.18697 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30382 | -0.01308 |    0.22629 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24778 | -0.01331 |    0.19119 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41883 | -0.02144 |    0.29051 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20534 | -0.00561 |    0.15462 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17443 | -0.01270 |    0.13774 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21012 | -0.03301 |    0.16746 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15845 | -0.00532 |    0.12134 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19959 | -0.03009 |    0.16004 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18600 | -0.00472 |    0.14691 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24241 | -0.02706 |    0.18964 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17057 | -0.01593 |    0.13435 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13909 | -0.00916 |    0.10712 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14159 | -0.01811 |    0.11122 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09655 |  0.00454 |    0.06867 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58101 | -0.00000 |    0.45411 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:12:58,120 - Total sparsity: 0.00

2018-11-02 20:12:58,120 - --- validate (epoch=126)-----------
2018-11-02 20:12:58,120 - 10000 samples (128 per mini-batch)
2018-11-02 20:12:58,849 - Epoch: [126][   50/   78]    Loss 0.503549    Top1 83.406250    Top5 99.250000    
2018-11-02 20:12:59,241 - ==> Top1: 83.580    Top5: 99.270    Loss: 0.501

2018-11-02 20:12:59,242 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:12:59,242 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:12:59,249 - 

2018-11-02 20:12:59,250 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:13:00,333 - Epoch: [127][   50/  391]    Overall Loss 0.388054    Objective Loss 0.388054    Top1 86.890625    Top5 99.500000    LR 0.220528    Time 0.021631    
2018-11-02 20:13:01,290 - Epoch: [127][  100/  391]    Overall Loss 0.390134    Objective Loss 0.390134    Top1 86.828125    Top5 99.484375    LR 0.220528    Time 0.020377    
2018-11-02 20:13:02,248 - Epoch: [127][  150/  391]    Overall Loss 0.387214    Objective Loss 0.387214    Top1 87.010417    Top5 99.484375    LR 0.220528    Time 0.019961    
2018-11-02 20:13:03,205 - Epoch: [127][  200/  391]    Overall Loss 0.391405    Objective Loss 0.391405    Top1 86.835938    Top5 99.546875    LR 0.220528    Time 0.019747    
2018-11-02 20:13:04,161 - Epoch: [127][  250/  391]    Overall Loss 0.396294    Objective Loss 0.396294    Top1 86.671875    Top5 99.525000    LR 0.220528    Time 0.019619    
2018-11-02 20:13:05,131 - Epoch: [127][  300/  391]    Overall Loss 0.395024    Objective Loss 0.395024    Top1 86.627604    Top5 99.505208    LR 0.220528    Time 0.019576    
2018-11-02 20:13:06,092 - Epoch: [127][  350/  391]    Overall Loss 0.390307    Objective Loss 0.390307    Top1 86.828125    Top5 99.488839    LR 0.220528    Time 0.019523    
2018-11-02 20:13:06,959 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56658 | -0.01279 |    0.35673 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21842 |  0.00218 |    0.13348 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22593 | -0.01189 |    0.16689 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26338 | -0.04910 |    0.19812 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27456 |  0.00461 |    0.21564 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25805 | -0.04209 |    0.19555 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25280 | -0.00581 |    0.18285 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30184 | -0.00845 |    0.22522 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24659 | -0.01089 |    0.18915 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41365 | -0.01904 |    0.28888 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20400 | -0.00653 |    0.15453 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17326 | -0.01467 |    0.13676 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20841 | -0.03232 |    0.16552 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15746 | -0.00618 |    0.12153 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19813 | -0.02928 |    0.15843 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18515 | -0.00436 |    0.14593 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23982 | -0.02644 |    0.18775 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16923 | -0.01526 |    0.13366 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13818 | -0.00916 |    0.10635 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14153 | -0.01727 |    0.11088 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09610 |  0.00487 |    0.06867 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57714 | -0.00000 |    0.44830 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:13:06,959 - Total sparsity: 0.00

2018-11-02 20:13:06,959 - --- validate (epoch=127)-----------
2018-11-02 20:13:06,959 - 10000 samples (128 per mini-batch)
2018-11-02 20:13:07,680 - Epoch: [127][   50/   78]    Loss 0.557462    Top1 81.531250    Top5 98.562500    
2018-11-02 20:13:08,074 - ==> Top1: 81.610    Top5: 98.640    Loss: 0.552

2018-11-02 20:13:08,075 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:13:08,075 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:13:08,081 - 

2018-11-02 20:13:08,082 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:13:09,097 - Epoch: [128][   50/  391]    Overall Loss 0.381063    Objective Loss 0.381063    Top1 86.937500    Top5 99.546875    LR 0.209501    Time 0.020272    
2018-11-02 20:13:10,052 - Epoch: [128][  100/  391]    Overall Loss 0.379303    Objective Loss 0.379303    Top1 87.023438    Top5 99.515625    LR 0.209501    Time 0.019674    
2018-11-02 20:13:11,079 - Epoch: [128][  150/  391]    Overall Loss 0.382091    Objective Loss 0.382091    Top1 86.807292    Top5 99.520833    LR 0.209501    Time 0.019952    
2018-11-02 20:13:12,106 - Epoch: [128][  200/  391]    Overall Loss 0.383504    Objective Loss 0.383504    Top1 86.746094    Top5 99.519531    LR 0.209501    Time 0.020094    
2018-11-02 20:13:13,137 - Epoch: [128][  250/  391]    Overall Loss 0.385464    Objective Loss 0.385464    Top1 86.762500    Top5 99.525000    LR 0.209501    Time 0.020197    
2018-11-02 20:13:14,097 - Epoch: [128][  300/  391]    Overall Loss 0.381551    Objective Loss 0.381551    Top1 86.895833    Top5 99.528646    LR 0.209501    Time 0.020026    
2018-11-02 20:13:15,062 - Epoch: [128][  350/  391]    Overall Loss 0.384981    Objective Loss 0.384981    Top1 86.796875    Top5 99.515625    LR 0.209501    Time 0.019919    
2018-11-02 20:13:15,959 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56417 | -0.00992 |    0.35186 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21829 |  0.00246 |    0.13450 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22480 | -0.00810 |    0.16615 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26154 | -0.05205 |    0.19659 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27172 |  0.00382 |    0.21245 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25562 | -0.04521 |    0.19539 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25137 | -0.00807 |    0.18378 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30065 | -0.00744 |    0.22467 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24589 | -0.01233 |    0.18861 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40751 | -0.01938 |    0.28342 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20351 | -0.00545 |    0.15381 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17274 | -0.01357 |    0.13666 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20724 | -0.03257 |    0.16423 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15721 | -0.00708 |    0.12152 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19689 | -0.02795 |    0.15835 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18421 | -0.00351 |    0.14513 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23734 | -0.02628 |    0.18532 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16768 | -0.01600 |    0.13251 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13771 | -0.00876 |    0.10623 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14162 | -0.01724 |    0.11090 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09584 |  0.00468 |    0.06854 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58036 | -0.00000 |    0.45122 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:13:15,959 - Total sparsity: 0.00

2018-11-02 20:13:15,959 - --- validate (epoch=128)-----------
2018-11-02 20:13:15,960 - 10000 samples (128 per mini-batch)
2018-11-02 20:13:16,669 - Epoch: [128][   50/   78]    Loss 0.532851    Top1 82.781250    Top5 99.203125    
2018-11-02 20:13:17,055 - ==> Top1: 82.360    Top5: 99.230    Loss: 0.549

2018-11-02 20:13:17,056 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:13:17,056 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:13:17,067 - 

2018-11-02 20:13:17,068 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:13:18,084 - Epoch: [129][   50/  391]    Overall Loss 0.373742    Objective Loss 0.373742    Top1 87.171875    Top5 99.390625    LR 0.199026    Time 0.020295    
2018-11-02 20:13:19,051 - Epoch: [129][  100/  391]    Overall Loss 0.373043    Objective Loss 0.373043    Top1 87.203125    Top5 99.445312    LR 0.199026    Time 0.019804    
2018-11-02 20:13:20,043 - Epoch: [129][  150/  391]    Overall Loss 0.370874    Objective Loss 0.370874    Top1 87.286458    Top5 99.484375    LR 0.199026    Time 0.019806    
2018-11-02 20:13:21,058 - Epoch: [129][  200/  391]    Overall Loss 0.368848    Objective Loss 0.368848    Top1 87.222656    Top5 99.503906    LR 0.199026    Time 0.019922    
2018-11-02 20:13:22,033 - Epoch: [129][  250/  391]    Overall Loss 0.372244    Objective Loss 0.372244    Top1 87.068750    Top5 99.509375    LR 0.199026    Time 0.019834    
2018-11-02 20:13:23,000 - Epoch: [129][  300/  391]    Overall Loss 0.370618    Objective Loss 0.370618    Top1 87.161458    Top5 99.520833    LR 0.199026    Time 0.019747    
2018-11-02 20:13:23,963 - Epoch: [129][  350/  391]    Overall Loss 0.373062    Objective Loss 0.373062    Top1 87.102679    Top5 99.526786    LR 0.199026    Time 0.019665    
2018-11-02 20:13:24,832 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56146 | -0.00008 |    0.35090 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21552 | -0.00007 |    0.13272 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22230 | -0.01112 |    0.16439 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26047 | -0.05328 |    0.19629 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27066 | -0.00074 |    0.21332 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25495 | -0.03835 |    0.19202 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24981 | -0.00172 |    0.18084 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29904 | -0.00888 |    0.22380 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24511 | -0.01086 |    0.18854 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40364 | -0.02180 |    0.27998 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20311 | -0.00450 |    0.15389 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17248 | -0.01510 |    0.13648 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20607 | -0.03168 |    0.16267 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15681 | -0.00834 |    0.12188 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19516 | -0.02850 |    0.15692 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18327 | -0.00368 |    0.14472 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23519 | -0.02657 |    0.18365 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16691 | -0.01626 |    0.13198 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13721 | -0.00922 |    0.10602 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14154 | -0.01636 |    0.11102 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09536 |  0.00544 |    0.06825 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57665 | -0.00000 |    0.44655 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:13:24,833 - Total sparsity: 0.00

2018-11-02 20:13:24,833 - --- validate (epoch=129)-----------
2018-11-02 20:13:24,833 - 10000 samples (128 per mini-batch)
2018-11-02 20:13:25,545 - Epoch: [129][   50/   78]    Loss 0.515601    Top1 83.156250    Top5 99.062500    
2018-11-02 20:13:25,938 - ==> Top1: 82.930    Top5: 99.150    Loss: 0.509

2018-11-02 20:13:25,938 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:13:25,938 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:13:25,946 - 

2018-11-02 20:13:25,946 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:13:27,014 - Epoch: [130][   50/  391]    Overall Loss 0.342259    Objective Loss 0.342259    Top1 87.984375    Top5 99.484375    LR 0.189075    Time 0.021330    
2018-11-02 20:13:27,974 - Epoch: [130][  100/  391]    Overall Loss 0.344821    Objective Loss 0.344821    Top1 88.031250    Top5 99.554688    LR 0.189075    Time 0.020249    
2018-11-02 20:13:28,932 - Epoch: [130][  150/  391]    Overall Loss 0.364230    Objective Loss 0.364230    Top1 87.364583    Top5 99.557292    LR 0.189075    Time 0.019880    
2018-11-02 20:13:29,890 - Epoch: [130][  200/  391]    Overall Loss 0.363523    Objective Loss 0.363523    Top1 87.371094    Top5 99.554688    LR 0.189075    Time 0.019696    
2018-11-02 20:13:30,887 - Epoch: [130][  250/  391]    Overall Loss 0.365309    Objective Loss 0.365309    Top1 87.334375    Top5 99.528125    LR 0.189075    Time 0.019741    
2018-11-02 20:13:31,862 - Epoch: [130][  300/  391]    Overall Loss 0.365708    Objective Loss 0.365708    Top1 87.302083    Top5 99.520833    LR 0.189075    Time 0.019695    
2018-11-02 20:13:32,896 - Epoch: [130][  350/  391]    Overall Loss 0.367125    Objective Loss 0.367125    Top1 87.232143    Top5 99.500000    LR 0.189075    Time 0.019832    
2018-11-02 20:13:33,819 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.55302 | -0.01051 |    0.34695 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21229 |  0.00026 |    0.13182 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22010 | -0.01404 |    0.16364 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25830 | -0.04895 |    0.19502 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26804 |  0.00174 |    0.21029 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25288 | -0.04031 |    0.19292 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24840 | -0.00350 |    0.17973 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29725 | -0.01116 |    0.22180 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24353 | -0.01033 |    0.18713 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40088 | -0.01574 |    0.28203 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20268 | -0.00719 |    0.15378 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17158 | -0.01682 |    0.13623 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20471 | -0.03105 |    0.16251 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15573 | -0.00624 |    0.12117 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19394 | -0.02870 |    0.15615 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18224 | -0.00301 |    0.14371 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23292 | -0.02789 |    0.18297 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16590 | -0.01622 |    0.13107 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13629 | -0.00974 |    0.10541 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14122 | -0.01705 |    0.11093 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09490 |  0.00559 |    0.06798 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57497 | -0.00000 |    0.44504 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:13:33,819 - Total sparsity: 0.00

2018-11-02 20:13:33,819 - --- validate (epoch=130)-----------
2018-11-02 20:13:33,820 - 10000 samples (128 per mini-batch)
2018-11-02 20:13:34,538 - Epoch: [130][   50/   78]    Loss 0.460634    Top1 84.328125    Top5 99.265625    
2018-11-02 20:13:34,927 - ==> Top1: 84.200    Top5: 99.290    Loss: 0.458

2018-11-02 20:13:34,928 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:13:34,928 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:13:34,936 - 

2018-11-02 20:13:34,936 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:13:36,020 - Epoch: [131][   50/  391]    Overall Loss 0.328182    Objective Loss 0.328182    Top1 88.671875    Top5 99.656250    LR 0.179621    Time 0.021646    
2018-11-02 20:13:36,983 - Epoch: [131][  100/  391]    Overall Loss 0.338302    Objective Loss 0.338302    Top1 88.414062    Top5 99.593750    LR 0.179621    Time 0.020445    
2018-11-02 20:13:37,942 - Epoch: [131][  150/  391]    Overall Loss 0.342825    Objective Loss 0.342825    Top1 88.244792    Top5 99.609375    LR 0.179621    Time 0.020015    
2018-11-02 20:13:38,904 - Epoch: [131][  200/  391]    Overall Loss 0.347106    Objective Loss 0.347106    Top1 88.160156    Top5 99.593750    LR 0.179621    Time 0.019812    
2018-11-02 20:13:39,865 - Epoch: [131][  250/  391]    Overall Loss 0.348942    Objective Loss 0.348942    Top1 87.968750    Top5 99.581250    LR 0.179621    Time 0.019691    
2018-11-02 20:13:40,825 - Epoch: [131][  300/  391]    Overall Loss 0.353524    Objective Loss 0.353524    Top1 87.822917    Top5 99.570312    LR 0.179621    Time 0.019603    
2018-11-02 20:13:41,785 - Epoch: [131][  350/  391]    Overall Loss 0.356945    Objective Loss 0.356945    Top1 87.625000    Top5 99.593750    LR 0.179621    Time 0.019545    
2018-11-02 20:13:42,652 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54800 | -0.00630 |    0.34333 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21070 |  0.00601 |    0.13065 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21841 | -0.01100 |    0.16187 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25690 | -0.04957 |    0.19563 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26521 |  0.00603 |    0.20718 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24976 | -0.04242 |    0.19027 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24603 | -0.00018 |    0.17866 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29468 | -0.00968 |    0.21906 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24183 | -0.00993 |    0.18547 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39614 | -0.02001 |    0.28133 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20069 | -0.00655 |    0.15222 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17027 | -0.01376 |    0.13506 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20372 | -0.02838 |    0.16122 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15436 | -0.00744 |    0.12010 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19253 | -0.02784 |    0.15472 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18079 | -0.00288 |    0.14270 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23024 | -0.02554 |    0.18029 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16450 | -0.01629 |    0.12991 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13542 | -0.00909 |    0.10453 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14065 | -0.01641 |    0.11039 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09431 |  0.00512 |    0.06769 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57160 | -0.00000 |    0.44170 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:13:42,652 - Total sparsity: 0.00

2018-11-02 20:13:42,653 - --- validate (epoch=131)-----------
2018-11-02 20:13:42,653 - 10000 samples (128 per mini-batch)
2018-11-02 20:13:43,372 - Epoch: [131][   50/   78]    Loss 0.509516    Top1 83.875000    Top5 99.312500    
2018-11-02 20:13:43,763 - ==> Top1: 83.630    Top5: 99.300    Loss: 0.508

2018-11-02 20:13:43,764 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:13:43,764 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:13:43,778 - 

2018-11-02 20:13:43,778 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:13:44,795 - Epoch: [132][   50/  391]    Overall Loss 0.338981    Objective Loss 0.338981    Top1 88.218750    Top5 99.671875    LR 0.170640    Time 0.020311    
2018-11-02 20:13:45,758 - Epoch: [132][  100/  391]    Overall Loss 0.342405    Objective Loss 0.342405    Top1 87.953125    Top5 99.648438    LR 0.170640    Time 0.019765    
2018-11-02 20:13:46,734 - Epoch: [132][  150/  391]    Overall Loss 0.336797    Objective Loss 0.336797    Top1 88.192708    Top5 99.640625    LR 0.170640    Time 0.019677    
2018-11-02 20:13:47,704 - Epoch: [132][  200/  391]    Overall Loss 0.338115    Objective Loss 0.338115    Top1 88.140625    Top5 99.640625    LR 0.170640    Time 0.019603    
2018-11-02 20:13:48,712 - Epoch: [132][  250/  391]    Overall Loss 0.341196    Objective Loss 0.341196    Top1 87.981250    Top5 99.615625    LR 0.170640    Time 0.019707    
2018-11-02 20:13:49,674 - Epoch: [132][  300/  391]    Overall Loss 0.341665    Objective Loss 0.341665    Top1 87.976562    Top5 99.614583    LR 0.170640    Time 0.019628    
2018-11-02 20:13:50,635 - Epoch: [132][  350/  391]    Overall Loss 0.344394    Objective Loss 0.344394    Top1 87.935268    Top5 99.607143    LR 0.170640    Time 0.019566    
2018-11-02 20:13:51,518 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.54013 | -0.01081 |    0.33948 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20821 |  0.00175 |    0.12887 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21706 | -0.00799 |    0.16180 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25493 | -0.04922 |    0.19279 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26292 |  0.00449 |    0.20567 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24735 | -0.03923 |    0.18679 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24337 | -0.00224 |    0.17674 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29197 | -0.00894 |    0.21648 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23991 | -0.01071 |    0.18486 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39169 | -0.02119 |    0.27699 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19866 | -0.00731 |    0.15091 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16894 | -0.01396 |    0.13407 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20221 | -0.03049 |    0.16133 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15357 | -0.00641 |    0.11933 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19070 | -0.02762 |    0.15281 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17911 | -0.00247 |    0.14155 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22789 | -0.02552 |    0.17898 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16327 | -0.01533 |    0.12892 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13443 | -0.00906 |    0.10397 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14015 | -0.01630 |    0.11005 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09359 |  0.00475 |    0.06735 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57168 | -0.00000 |    0.44181 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:13:51,518 - Total sparsity: 0.00

2018-11-02 20:13:51,518 - --- validate (epoch=132)-----------
2018-11-02 20:13:51,519 - 10000 samples (128 per mini-batch)
2018-11-02 20:13:52,240 - Epoch: [132][   50/   78]    Loss 0.480430    Top1 83.937500    Top5 99.140625    
2018-11-02 20:13:52,632 - ==> Top1: 83.920    Top5: 99.270    Loss: 0.486

2018-11-02 20:13:52,632 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:13:52,633 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:13:52,640 - 

2018-11-02 20:13:52,640 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:13:53,658 - Epoch: [133][   50/  391]    Overall Loss 0.328808    Objective Loss 0.328808    Top1 88.859375    Top5 99.750000    LR 0.162108    Time 0.020323    
2018-11-02 20:13:54,622 - Epoch: [133][  100/  391]    Overall Loss 0.332670    Objective Loss 0.332670    Top1 88.703125    Top5 99.656250    LR 0.162108    Time 0.019786    
2018-11-02 20:13:55,584 - Epoch: [133][  150/  391]    Overall Loss 0.338765    Objective Loss 0.338765    Top1 88.593750    Top5 99.598958    LR 0.162108    Time 0.019598    
2018-11-02 20:13:56,608 - Epoch: [133][  200/  391]    Overall Loss 0.336545    Objective Loss 0.336545    Top1 88.542969    Top5 99.601562    LR 0.162108    Time 0.019811    
2018-11-02 20:13:57,634 - Epoch: [133][  250/  391]    Overall Loss 0.340728    Objective Loss 0.340728    Top1 88.287500    Top5 99.600000    LR 0.162108    Time 0.019951    
2018-11-02 20:13:58,595 - Epoch: [133][  300/  391]    Overall Loss 0.337902    Objective Loss 0.337902    Top1 88.390625    Top5 99.614583    LR 0.162108    Time 0.019825    
2018-11-02 20:13:59,557 - Epoch: [133][  350/  391]    Overall Loss 0.340348    Objective Loss 0.340348    Top1 88.337054    Top5 99.589286    LR 0.162108    Time 0.019737    
2018-11-02 20:14:00,425 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53457 | -0.00515 |    0.33813 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20660 |  0.00257 |    0.12814 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21500 | -0.01146 |    0.16003 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25098 | -0.05169 |    0.19101 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25950 |  0.00481 |    0.20398 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24554 | -0.03798 |    0.18706 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24130 | -0.00208 |    0.17606 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28902 | -0.01124 |    0.21447 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23782 | -0.01010 |    0.18347 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38618 | -0.01822 |    0.27478 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19666 | -0.00463 |    0.14917 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16766 | -0.01275 |    0.13276 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20056 | -0.02997 |    0.16010 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15199 | -0.00718 |    0.11811 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18898 | -0.02787 |    0.15136 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17762 | -0.00277 |    0.14036 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22480 | -0.02567 |    0.17651 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16188 | -0.01501 |    0.12768 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13352 | -0.00922 |    0.10343 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13947 | -0.01602 |    0.10961 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09285 |  0.00533 |    0.06684 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57107 | -0.00000 |    0.44182 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:14:00,425 - Total sparsity: 0.00

2018-11-02 20:14:00,425 - --- validate (epoch=133)-----------
2018-11-02 20:14:00,426 - 10000 samples (128 per mini-batch)
2018-11-02 20:14:01,152 - Epoch: [133][   50/   78]    Loss 0.516108    Top1 83.781250    Top5 99.265625    
2018-11-02 20:14:01,540 - ==> Top1: 83.720    Top5: 99.300    Loss: 0.520

2018-11-02 20:14:01,540 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:14:01,540 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:14:01,548 - 

2018-11-02 20:14:01,548 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:14:02,567 - Epoch: [134][   50/  391]    Overall Loss 0.334272    Objective Loss 0.334272    Top1 88.515625    Top5 99.593750    LR 0.154003    Time 0.020338    
2018-11-02 20:14:03,531 - Epoch: [134][  100/  391]    Overall Loss 0.326676    Objective Loss 0.326676    Top1 88.906250    Top5 99.648438    LR 0.154003    Time 0.019800    
2018-11-02 20:14:04,496 - Epoch: [134][  150/  391]    Overall Loss 0.331358    Objective Loss 0.331358    Top1 88.656250    Top5 99.583333    LR 0.154003    Time 0.019625    
2018-11-02 20:14:05,458 - Epoch: [134][  200/  391]    Overall Loss 0.334632    Objective Loss 0.334632    Top1 88.578125    Top5 99.562500    LR 0.154003    Time 0.019524    
2018-11-02 20:14:06,421 - Epoch: [134][  250/  391]    Overall Loss 0.329862    Objective Loss 0.329862    Top1 88.678125    Top5 99.600000    LR 0.154003    Time 0.019467    
2018-11-02 20:14:07,386 - Epoch: [134][  300/  391]    Overall Loss 0.332889    Objective Loss 0.332889    Top1 88.546875    Top5 99.598958    LR 0.154003    Time 0.019434    
2018-11-02 20:14:08,351 - Epoch: [134][  350/  391]    Overall Loss 0.332792    Objective Loss 0.332792    Top1 88.482143    Top5 99.609375    LR 0.154003    Time 0.019411    
2018-11-02 20:14:09,223 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.53132 | -0.00432 |    0.33347 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20589 |  0.00248 |    0.12744 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21357 | -0.01252 |    0.15996 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25033 | -0.04863 |    0.19069 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25745 |  0.00143 |    0.20267 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24498 | -0.03680 |    0.18667 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23968 | -0.00286 |    0.17630 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28598 | -0.00996 |    0.21236 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23603 | -0.01041 |    0.18168 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38219 | -0.01733 |    0.26834 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19492 | -0.00557 |    0.14812 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16667 | -0.01231 |    0.13205 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19908 | -0.02827 |    0.15872 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15088 | -0.00775 |    0.11794 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18765 | -0.02687 |    0.15041 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17641 | -0.00261 |    0.13956 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22212 | -0.02556 |    0.17470 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16076 | -0.01470 |    0.12672 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13296 | -0.00941 |    0.10284 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13898 | -0.01600 |    0.10945 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09235 |  0.00487 |    0.06668 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57023 | -0.00000 |    0.44273 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:14:09,223 - Total sparsity: 0.00

2018-11-02 20:14:09,223 - --- validate (epoch=134)-----------
2018-11-02 20:14:09,223 - 10000 samples (128 per mini-batch)
2018-11-02 20:14:09,949 - Epoch: [134][   50/   78]    Loss 0.469854    Top1 84.328125    Top5 99.281250    
2018-11-02 20:14:10,344 - ==> Top1: 84.220    Top5: 99.350    Loss: 0.478

2018-11-02 20:14:10,344 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:14:10,345 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:14:10,359 - 

2018-11-02 20:14:10,359 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:14:11,377 - Epoch: [135][   50/  391]    Overall Loss 0.317454    Objective Loss 0.317454    Top1 89.140625    Top5 99.656250    LR 0.146302    Time 0.020314    
2018-11-02 20:14:12,338 - Epoch: [135][  100/  391]    Overall Loss 0.323094    Objective Loss 0.323094    Top1 88.781250    Top5 99.632812    LR 0.146302    Time 0.019756    
2018-11-02 20:14:13,298 - Epoch: [135][  150/  391]    Overall Loss 0.321541    Objective Loss 0.321541    Top1 88.817708    Top5 99.625000    LR 0.146302    Time 0.019565    
2018-11-02 20:14:14,259 - Epoch: [135][  200/  391]    Overall Loss 0.319558    Objective Loss 0.319558    Top1 88.964844    Top5 99.652344    LR 0.146302    Time 0.019474    
2018-11-02 20:14:15,222 - Epoch: [135][  250/  391]    Overall Loss 0.323131    Objective Loss 0.323131    Top1 88.734375    Top5 99.631250    LR 0.146302    Time 0.019425    
2018-11-02 20:14:16,266 - Epoch: [135][  300/  391]    Overall Loss 0.323475    Objective Loss 0.323475    Top1 88.752604    Top5 99.622396    LR 0.146302    Time 0.019664    
2018-11-02 20:14:17,291 - Epoch: [135][  350/  391]    Overall Loss 0.324434    Objective Loss 0.324434    Top1 88.736607    Top5 99.611607    LR 0.146302    Time 0.019782    
2018-11-02 20:14:18,212 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.52606 | -0.00280 |    0.33260 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20355 |  0.00349 |    0.12646 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21204 | -0.00843 |    0.15892 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24900 | -0.04689 |    0.18887 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25579 |  0.00051 |    0.20005 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24344 | -0.03414 |    0.18520 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23744 | -0.00479 |    0.17270 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28336 | -0.01024 |    0.20936 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23412 | -0.00889 |    0.17985 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37797 | -0.01846 |    0.26471 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19325 | -0.00542 |    0.14620 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16551 | -0.01162 |    0.13100 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19771 | -0.02950 |    0.15819 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14973 | -0.00718 |    0.11690 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18608 | -0.02688 |    0.14904 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17523 | -0.00290 |    0.13858 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21998 | -0.02345 |    0.17195 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15952 | -0.01426 |    0.12567 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13227 | -0.00851 |    0.10223 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13840 | -0.01601 |    0.10906 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09162 |  0.00515 |    0.06647 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56963 | -0.00000 |    0.44112 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:14:18,212 - Total sparsity: 0.00

2018-11-02 20:14:18,212 - --- validate (epoch=135)-----------
2018-11-02 20:14:18,213 - 10000 samples (128 per mini-batch)
2018-11-02 20:14:18,932 - Epoch: [135][   50/   78]    Loss 0.518218    Top1 83.296875    Top5 99.359375    
2018-11-02 20:14:19,320 - ==> Top1: 82.730    Top5: 99.330    Loss: 0.538

2018-11-02 20:14:19,320 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:14:19,320 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:14:19,327 - 

2018-11-02 20:14:19,327 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:14:20,345 - Epoch: [136][   50/  391]    Overall Loss 0.305726    Objective Loss 0.305726    Top1 89.593750    Top5 99.671875    LR 0.138987    Time 0.020330    
2018-11-02 20:14:21,308 - Epoch: [136][  100/  391]    Overall Loss 0.310774    Objective Loss 0.310774    Top1 89.367188    Top5 99.656250    LR 0.138987    Time 0.019774    
2018-11-02 20:14:22,272 - Epoch: [136][  150/  391]    Overall Loss 0.308341    Objective Loss 0.308341    Top1 89.338542    Top5 99.687500    LR 0.138987    Time 0.019605    
2018-11-02 20:14:23,302 - Epoch: [136][  200/  391]    Overall Loss 0.312058    Objective Loss 0.312058    Top1 89.203125    Top5 99.683594    LR 0.138987    Time 0.019849    
2018-11-02 20:14:24,346 - Epoch: [136][  250/  391]    Overall Loss 0.311229    Objective Loss 0.311229    Top1 89.215625    Top5 99.687500    LR 0.138987    Time 0.020051    
2018-11-02 20:14:25,383 - Epoch: [136][  300/  391]    Overall Loss 0.314778    Objective Loss 0.314778    Top1 89.088542    Top5 99.679688    LR 0.138987    Time 0.020150    
2018-11-02 20:14:26,431 - Epoch: [136][  350/  391]    Overall Loss 0.315828    Objective Loss 0.315828    Top1 89.051339    Top5 99.687500    LR 0.138987    Time 0.020263    
2018-11-02 20:14:27,360 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.52106 | -0.01207 |    0.32856 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20151 |  0.00674 |    0.12528 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21062 | -0.01098 |    0.15844 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24681 | -0.04442 |    0.18693 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25394 |  0.00455 |    0.19979 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24112 | -0.03698 |    0.18435 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23561 | -0.00514 |    0.17160 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28117 | -0.00897 |    0.20749 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23234 | -0.00818 |    0.17830 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37370 | -0.01573 |    0.26163 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19172 | -0.00438 |    0.14521 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16460 | -0.01301 |    0.13028 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19617 | -0.02957 |    0.15698 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14828 | -0.00632 |    0.11499 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18447 | -0.02635 |    0.14789 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17393 | -0.00321 |    0.13748 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21755 | -0.02249 |    0.16930 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15834 | -0.01459 |    0.12498 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13146 | -0.00884 |    0.10160 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13768 | -0.01542 |    0.10860 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09084 |  0.00519 |    0.06620 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56721 | -0.00000 |    0.44038 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:14:27,361 - Total sparsity: 0.00

2018-11-02 20:14:27,361 - --- validate (epoch=136)-----------
2018-11-02 20:14:27,361 - 10000 samples (128 per mini-batch)
2018-11-02 20:14:28,069 - Epoch: [136][   50/   78]    Loss 0.477091    Top1 84.546875    Top5 99.031250    
2018-11-02 20:14:28,452 - ==> Top1: 84.480    Top5: 99.170    Loss: 0.477

2018-11-02 20:14:28,453 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:14:28,453 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:14:28,461 - 

2018-11-02 20:14:28,461 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:14:29,478 - Epoch: [137][   50/  391]    Overall Loss 0.300632    Objective Loss 0.300632    Top1 89.578125    Top5 99.671875    LR 0.132038    Time 0.020308    
2018-11-02 20:14:30,439 - Epoch: [137][  100/  391]    Overall Loss 0.301086    Objective Loss 0.301086    Top1 89.492188    Top5 99.703125    LR 0.132038    Time 0.019750    
2018-11-02 20:14:31,402 - Epoch: [137][  150/  391]    Overall Loss 0.305802    Objective Loss 0.305802    Top1 89.250000    Top5 99.671875    LR 0.132038    Time 0.019583    
2018-11-02 20:14:32,362 - Epoch: [137][  200/  391]    Overall Loss 0.309355    Objective Loss 0.309355    Top1 89.125000    Top5 99.699219    LR 0.132038    Time 0.019482    
2018-11-02 20:14:33,322 - Epoch: [137][  250/  391]    Overall Loss 0.311627    Objective Loss 0.311627    Top1 89.071875    Top5 99.687500    LR 0.132038    Time 0.019420    
2018-11-02 20:14:34,282 - Epoch: [137][  300/  391]    Overall Loss 0.313557    Objective Loss 0.313557    Top1 88.992188    Top5 99.682292    LR 0.132038    Time 0.019381    
2018-11-02 20:14:35,242 - Epoch: [137][  350/  391]    Overall Loss 0.313928    Objective Loss 0.313928    Top1 88.970982    Top5 99.665179    LR 0.132038    Time 0.019351    
2018-11-02 20:14:36,109 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.51681 | -0.01274 |    0.32467 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20048 |  0.00354 |    0.12422 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20939 | -0.01309 |    0.15770 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24474 | -0.04386 |    0.18647 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25215 |  0.00430 |    0.19891 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23991 | -0.03684 |    0.18473 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23390 | -0.00433 |    0.17007 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27899 | -0.00859 |    0.20552 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23076 | -0.00841 |    0.17738 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37015 | -0.01688 |    0.25815 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19042 | -0.00348 |    0.14397 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16373 | -0.01220 |    0.12999 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19526 | -0.02871 |    0.15585 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14728 | -0.00477 |    0.11469 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18294 | -0.02624 |    0.14680 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17281 | -0.00254 |    0.13630 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21552 | -0.02232 |    0.16835 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15724 | -0.01476 |    0.12404 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13077 | -0.00901 |    0.10116 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13721 | -0.01562 |    0.10818 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09030 |  0.00516 |    0.06584 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56689 | -0.00000 |    0.43988 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:14:36,109 - Total sparsity: 0.00

2018-11-02 20:14:36,109 - --- validate (epoch=137)-----------
2018-11-02 20:14:36,109 - 10000 samples (128 per mini-batch)
2018-11-02 20:14:36,830 - Epoch: [137][   50/   78]    Loss 0.397911    Top1 86.390625    Top5 99.453125    
2018-11-02 20:14:37,222 - ==> Top1: 86.310    Top5: 99.490    Loss: 0.399

2018-11-02 20:14:37,222 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:14:37,223 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:14:37,230 - 

2018-11-02 20:14:37,230 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:14:38,249 - Epoch: [138][   50/  391]    Overall Loss 0.283256    Objective Loss 0.283256    Top1 89.984375    Top5 99.765625    LR 0.125436    Time 0.020349    
2018-11-02 20:14:39,210 - Epoch: [138][  100/  391]    Overall Loss 0.292524    Objective Loss 0.292524    Top1 89.890625    Top5 99.765625    LR 0.125436    Time 0.019770    
2018-11-02 20:14:40,172 - Epoch: [138][  150/  391]    Overall Loss 0.302281    Objective Loss 0.302281    Top1 89.598958    Top5 99.734375    LR 0.125436    Time 0.019586    
2018-11-02 20:14:41,132 - Epoch: [138][  200/  391]    Overall Loss 0.305226    Objective Loss 0.305226    Top1 89.500000    Top5 99.734375    LR 0.125436    Time 0.019484    
2018-11-02 20:14:42,092 - Epoch: [138][  250/  391]    Overall Loss 0.308387    Objective Loss 0.308387    Top1 89.362500    Top5 99.731250    LR 0.125436    Time 0.019408    
2018-11-02 20:14:43,053 - Epoch: [138][  300/  391]    Overall Loss 0.308780    Objective Loss 0.308780    Top1 89.325521    Top5 99.721354    LR 0.125436    Time 0.019373    
2018-11-02 20:14:44,014 - Epoch: [138][  350/  391]    Overall Loss 0.307186    Objective Loss 0.307186    Top1 89.397321    Top5 99.723214    LR 0.125436    Time 0.019349    
2018-11-02 20:14:44,885 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.51425 | -0.00752 |    0.32256 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19937 |  0.00193 |    0.12371 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20817 | -0.01007 |    0.15586 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24174 | -0.04395 |    0.18327 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25005 |  0.00444 |    0.19651 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23861 | -0.03311 |    0.18401 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23195 | -0.00516 |    0.16844 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27691 | -0.00848 |    0.20369 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22901 | -0.00871 |    0.17573 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36645 | -0.01924 |    0.25650 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18900 | -0.00487 |    0.14250 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16273 | -0.01194 |    0.12876 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19416 | -0.02843 |    0.15540 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14640 | -0.00581 |    0.11421 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18142 | -0.02523 |    0.14542 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17164 | -0.00289 |    0.13547 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21336 | -0.02223 |    0.16629 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15610 | -0.01431 |    0.12321 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12998 | -0.00834 |    0.10093 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13663 | -0.01521 |    0.10775 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08945 |  0.00551 |    0.06536 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56590 | -0.00000 |    0.43986 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:14:44,885 - Total sparsity: 0.00

2018-11-02 20:14:44,885 - --- validate (epoch=138)-----------
2018-11-02 20:14:44,885 - 10000 samples (128 per mini-batch)
2018-11-02 20:14:45,604 - Epoch: [138][   50/   78]    Loss 0.472496    Top1 84.890625    Top5 99.187500    
2018-11-02 20:14:45,995 - ==> Top1: 84.910    Top5: 99.240    Loss: 0.470

2018-11-02 20:14:45,996 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:14:45,996 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:14:46,007 - 

2018-11-02 20:14:46,007 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:14:47,107 - Epoch: [139][   50/  391]    Overall Loss 0.291973    Objective Loss 0.291973    Top1 90.046875    Top5 99.671875    LR 0.119164    Time 0.021965    
2018-11-02 20:14:48,127 - Epoch: [139][  100/  391]    Overall Loss 0.301234    Objective Loss 0.301234    Top1 89.656250    Top5 99.726562    LR 0.119164    Time 0.021169    
2018-11-02 20:14:49,089 - Epoch: [139][  150/  391]    Overall Loss 0.292373    Objective Loss 0.292373    Top1 89.802083    Top5 99.765625    LR 0.119164    Time 0.020518    
2018-11-02 20:14:50,095 - Epoch: [139][  200/  391]    Overall Loss 0.290042    Objective Loss 0.290042    Top1 89.941406    Top5 99.746094    LR 0.119164    Time 0.020411    
2018-11-02 20:14:51,128 - Epoch: [139][  250/  391]    Overall Loss 0.294644    Objective Loss 0.294644    Top1 89.812500    Top5 99.759375    LR 0.119164    Time 0.020457    
2018-11-02 20:14:52,158 - Epoch: [139][  300/  391]    Overall Loss 0.297573    Objective Loss 0.297573    Top1 89.640625    Top5 99.770833    LR 0.119164    Time 0.020477    
2018-11-02 20:14:53,125 - Epoch: [139][  350/  391]    Overall Loss 0.297429    Objective Loss 0.297429    Top1 89.660714    Top5 99.761161    LR 0.119164    Time 0.020303    
2018-11-02 20:14:53,996 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.51075 | -0.00417 |    0.32007 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19768 |  0.00529 |    0.12287 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20674 | -0.00730 |    0.15486 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23914 | -0.04670 |    0.18197 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24819 |  0.00300 |    0.19512 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23680 | -0.03581 |    0.18205 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23026 | -0.00519 |    0.16637 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27452 | -0.00970 |    0.20186 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22713 | -0.00914 |    0.17424 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36292 | -0.01387 |    0.25292 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18745 | -0.00309 |    0.14167 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16156 | -0.01246 |    0.12740 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19299 | -0.02817 |    0.15439 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14550 | -0.00572 |    0.11356 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18007 | -0.02456 |    0.14459 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17051 | -0.00231 |    0.13457 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21103 | -0.02169 |    0.16500 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15510 | -0.01366 |    0.12242 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12917 | -0.00885 |    0.10046 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13604 | -0.01513 |    0.10723 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08878 |  0.00552 |    0.06503 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56471 | -0.00000 |    0.43805 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:14:53,996 - Total sparsity: 0.00

2018-11-02 20:14:53,996 - --- validate (epoch=139)-----------
2018-11-02 20:14:53,996 - 10000 samples (128 per mini-batch)
2018-11-02 20:14:54,711 - Epoch: [139][   50/   78]    Loss 0.450448    Top1 85.343750    Top5 99.437500    
2018-11-02 20:14:55,105 - ==> Top1: 85.210    Top5: 99.510    Loss: 0.452

2018-11-02 20:14:55,106 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:14:55,106 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:14:55,117 - 

2018-11-02 20:14:55,117 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:14:56,183 - Epoch: [140][   50/  391]    Overall Loss 0.297504    Objective Loss 0.297504    Top1 90.093750    Top5 99.765625    LR 0.113206    Time 0.021285    
2018-11-02 20:14:57,178 - Epoch: [140][  100/  391]    Overall Loss 0.296614    Objective Loss 0.296614    Top1 89.906250    Top5 99.718750    LR 0.113206    Time 0.020577    
2018-11-02 20:14:58,140 - Epoch: [140][  150/  391]    Overall Loss 0.296123    Objective Loss 0.296123    Top1 89.875000    Top5 99.723958    LR 0.113206    Time 0.020130    
2018-11-02 20:14:59,102 - Epoch: [140][  200/  391]    Overall Loss 0.298688    Objective Loss 0.298688    Top1 89.875000    Top5 99.710938    LR 0.113206    Time 0.019900    
2018-11-02 20:15:00,065 - Epoch: [140][  250/  391]    Overall Loss 0.297606    Objective Loss 0.297606    Top1 89.815625    Top5 99.700000    LR 0.113206    Time 0.019767    
2018-11-02 20:15:01,085 - Epoch: [140][  300/  391]    Overall Loss 0.294721    Objective Loss 0.294721    Top1 89.898438    Top5 99.700521    LR 0.113206    Time 0.019869    
2018-11-02 20:15:02,058 - Epoch: [140][  350/  391]    Overall Loss 0.294954    Objective Loss 0.294954    Top1 89.866071    Top5 99.694196    LR 0.113206    Time 0.019805    
2018-11-02 20:15:02,928 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.50687 | -0.01207 |    0.31856 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19624 |  0.00573 |    0.12244 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20512 | -0.00991 |    0.15288 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23790 | -0.04544 |    0.18156 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24626 | -0.00019 |    0.19386 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23394 | -0.03856 |    0.18061 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22754 | -0.00616 |    0.16612 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27238 | -0.00566 |    0.20027 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22525 | -0.00969 |    0.17294 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35865 | -0.01570 |    0.25110 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18565 | -0.00350 |    0.14074 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16006 | -0.01309 |    0.12698 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19144 | -0.02717 |    0.15302 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14430 | -0.00533 |    0.11234 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17839 | -0.02422 |    0.14294 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16920 | -0.00253 |    0.13354 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20861 | -0.02269 |    0.16328 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15391 | -0.01347 |    0.12151 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12836 | -0.00882 |    0.09966 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13518 | -0.01529 |    0.10677 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08814 |  0.00477 |    0.06469 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56584 | -0.00000 |    0.43956 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:15:02,928 - Total sparsity: 0.00

2018-11-02 20:15:02,928 - --- validate (epoch=140)-----------
2018-11-02 20:15:02,928 - 10000 samples (128 per mini-batch)
2018-11-02 20:15:03,669 - Epoch: [140][   50/   78]    Loss 0.552990    Top1 83.718750    Top5 98.906250    
2018-11-02 20:15:04,059 - ==> Top1: 83.590    Top5: 99.000    Loss: 0.563

2018-11-02 20:15:04,060 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:15:04,060 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:15:04,067 - 

2018-11-02 20:15:04,067 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:15:05,085 - Epoch: [141][   50/  391]    Overall Loss 0.277828    Objective Loss 0.277828    Top1 90.062500    Top5 99.781250    LR 0.107546    Time 0.020327    
2018-11-02 20:15:06,045 - Epoch: [141][  100/  391]    Overall Loss 0.266636    Objective Loss 0.266636    Top1 90.609375    Top5 99.757812    LR 0.107546    Time 0.019751    
2018-11-02 20:15:07,007 - Epoch: [141][  150/  391]    Overall Loss 0.278374    Objective Loss 0.278374    Top1 90.296875    Top5 99.750000    LR 0.107546    Time 0.019570    
2018-11-02 20:15:08,037 - Epoch: [141][  200/  391]    Overall Loss 0.276277    Objective Loss 0.276277    Top1 90.328125    Top5 99.769531    LR 0.107546    Time 0.019824    
2018-11-02 20:15:09,028 - Epoch: [141][  250/  391]    Overall Loss 0.280511    Objective Loss 0.280511    Top1 90.287500    Top5 99.753125    LR 0.107546    Time 0.019803    
2018-11-02 20:15:09,993 - Epoch: [141][  300/  391]    Overall Loss 0.278263    Objective Loss 0.278263    Top1 90.348958    Top5 99.744792    LR 0.107546    Time 0.019714    
2018-11-02 20:15:10,955 - Epoch: [141][  350/  391]    Overall Loss 0.281008    Objective Loss 0.281008    Top1 90.191964    Top5 99.747768    LR 0.107546    Time 0.019644    
2018-11-02 20:15:11,820 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.50237 | -0.00410 |    0.31634 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19511 |  0.00326 |    0.12243 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20386 | -0.01053 |    0.15285 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23511 | -0.04619 |    0.17870 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24381 |  0.00069 |    0.19060 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23232 | -0.03626 |    0.17937 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22562 | -0.00727 |    0.16437 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26989 | -0.00678 |    0.19894 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22341 | -0.00883 |    0.17203 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35481 | -0.01235 |    0.24888 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18423 | -0.00382 |    0.14006 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15909 | -0.01322 |    0.12615 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18998 | -0.02690 |    0.15220 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14336 | -0.00567 |    0.11167 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17691 | -0.02217 |    0.14153 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16792 | -0.00148 |    0.13251 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20662 | -0.02180 |    0.16114 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15275 | -0.01295 |    0.12048 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12765 | -0.00880 |    0.09920 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13454 | -0.01526 |    0.10642 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08749 |  0.00512 |    0.06410 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56554 | -0.00000 |    0.43939 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:15:11,820 - Total sparsity: 0.00

2018-11-02 20:15:11,820 - --- validate (epoch=141)-----------
2018-11-02 20:15:11,821 - 10000 samples (128 per mini-batch)
2018-11-02 20:15:12,541 - Epoch: [141][   50/   78]    Loss 0.477837    Top1 85.312500    Top5 99.312500    
2018-11-02 20:15:12,935 - ==> Top1: 85.120    Top5: 99.300    Loss: 0.484

2018-11-02 20:15:12,936 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:15:12,936 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:15:12,947 - 

2018-11-02 20:15:12,947 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:15:14,042 - Epoch: [142][   50/  391]    Overall Loss 0.285292    Objective Loss 0.285292    Top1 90.359375    Top5 99.750000    LR 0.102168    Time 0.021872    
2018-11-02 20:15:15,081 - Epoch: [142][  100/  391]    Overall Loss 0.282710    Objective Loss 0.282710    Top1 90.320312    Top5 99.742188    LR 0.102168    Time 0.021313    
2018-11-02 20:15:16,121 - Epoch: [142][  150/  391]    Overall Loss 0.284034    Objective Loss 0.284034    Top1 90.265625    Top5 99.776042    LR 0.102168    Time 0.021133    
2018-11-02 20:15:17,103 - Epoch: [142][  200/  391]    Overall Loss 0.281032    Objective Loss 0.281032    Top1 90.328125    Top5 99.753906    LR 0.102168    Time 0.020756    
2018-11-02 20:15:18,075 - Epoch: [142][  250/  391]    Overall Loss 0.281509    Objective Loss 0.281509    Top1 90.331250    Top5 99.753125    LR 0.102168    Time 0.020488    
2018-11-02 20:15:19,047 - Epoch: [142][  300/  391]    Overall Loss 0.280818    Objective Loss 0.280818    Top1 90.302083    Top5 99.755208    LR 0.102168    Time 0.020311    
2018-11-02 20:15:20,019 - Epoch: [142][  350/  391]    Overall Loss 0.280437    Objective Loss 0.280437    Top1 90.296875    Top5 99.754464    LR 0.102168    Time 0.020173    
2018-11-02 20:15:20,894 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.49719 | -0.00664 |    0.31382 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19392 |  0.00182 |    0.12159 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20255 | -0.01001 |    0.15164 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23270 | -0.04762 |    0.17675 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24121 |  0.00128 |    0.18866 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23036 | -0.03600 |    0.17703 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22312 | -0.01125 |    0.16264 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26716 | -0.00696 |    0.19714 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22149 | -0.00987 |    0.17052 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35099 | -0.01296 |    0.24370 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18270 | -0.00417 |    0.13896 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15777 | -0.01376 |    0.12503 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18857 | -0.02632 |    0.15147 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14225 | -0.00511 |    0.11121 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17531 | -0.02242 |    0.14057 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16666 | -0.00175 |    0.13160 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20467 | -0.02195 |    0.15905 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15164 | -0.01317 |    0.11952 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12681 | -0.00825 |    0.09847 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13372 | -0.01547 |    0.10578 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08675 |  0.00456 |    0.06366 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56463 | -0.00000 |    0.43862 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:15:20,895 - Total sparsity: 0.00

2018-11-02 20:15:20,895 - --- validate (epoch=142)-----------
2018-11-02 20:15:20,895 - 10000 samples (128 per mini-batch)
2018-11-02 20:15:21,621 - Epoch: [142][   50/   78]    Loss 0.505310    Top1 84.203125    Top5 99.375000    
2018-11-02 20:15:22,013 - ==> Top1: 84.200    Top5: 99.420    Loss: 0.499

2018-11-02 20:15:22,014 - ==> Best Top1: 86.340   On Epoch: 112

2018-11-02 20:15:22,014 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:15:22,022 - 

2018-11-02 20:15:22,022 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:15:23,038 - Epoch: [143][   50/  391]    Overall Loss 0.268980    Objective Loss 0.268980    Top1 90.796875    Top5 99.765625    LR 0.097060    Time 0.020297    
2018-11-02 20:15:24,000 - Epoch: [143][  100/  391]    Overall Loss 0.271480    Objective Loss 0.271480    Top1 90.656250    Top5 99.781250    LR 0.097060    Time 0.019748    
2018-11-02 20:15:24,962 - Epoch: [143][  150/  391]    Overall Loss 0.274101    Objective Loss 0.274101    Top1 90.515625    Top5 99.786458    LR 0.097060    Time 0.019573    
2018-11-02 20:15:25,923 - Epoch: [143][  200/  391]    Overall Loss 0.274869    Objective Loss 0.274869    Top1 90.519531    Top5 99.792969    LR 0.097060    Time 0.019481    
2018-11-02 20:15:26,885 - Epoch: [143][  250/  391]    Overall Loss 0.276759    Objective Loss 0.276759    Top1 90.406250    Top5 99.784375    LR 0.097060    Time 0.019429    
2018-11-02 20:15:27,848 - Epoch: [143][  300/  391]    Overall Loss 0.276786    Objective Loss 0.276786    Top1 90.330729    Top5 99.786458    LR 0.097060    Time 0.019397    
2018-11-02 20:15:28,818 - Epoch: [143][  350/  391]    Overall Loss 0.279173    Objective Loss 0.279173    Top1 90.303571    Top5 99.770089    LR 0.097060    Time 0.019392    
2018-11-02 20:15:29,690 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.49431 | -0.00746 |    0.31178 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19251 |  0.00126 |    0.12011 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20142 | -0.01112 |    0.15152 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23151 | -0.04594 |    0.17544 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23930 |  0.00390 |    0.18769 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22805 | -0.03825 |    0.17650 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22138 | -0.00746 |    0.16102 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26493 | -0.00703 |    0.19544 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21972 | -0.00945 |    0.16917 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34750 | -0.01260 |    0.24367 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18143 | -0.00583 |    0.13780 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15694 | -0.01299 |    0.12379 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18682 | -0.02646 |    0.15012 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14119 | -0.00596 |    0.11042 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17390 | -0.02271 |    0.13923 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16558 | -0.00220 |    0.13068 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20294 | -0.02193 |    0.15772 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15080 | -0.01286 |    0.11888 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12614 | -0.00874 |    0.09804 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13320 | -0.01553 |    0.10530 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08610 |  0.00506 |    0.06322 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56345 | -0.00000 |    0.43717 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:15:29,690 - Total sparsity: 0.00

2018-11-02 20:15:29,691 - --- validate (epoch=143)-----------
2018-11-02 20:15:29,691 - 10000 samples (128 per mini-batch)
2018-11-02 20:15:30,416 - Epoch: [143][   50/   78]    Loss 0.395943    Top1 87.000000    Top5 99.453125    
2018-11-02 20:15:30,810 - ==> Top1: 86.930    Top5: 99.480    Loss: 0.401

2018-11-02 20:15:30,810 - ==> Best Top1: 86.930   On Epoch: 143

2018-11-02 20:15:30,811 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:15:30,819 - 

2018-11-02 20:15:30,819 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:15:31,834 - Epoch: [144][   50/  391]    Overall Loss 0.258705    Objective Loss 0.258705    Top1 90.937500    Top5 99.703125    LR 0.092207    Time 0.020277    
2018-11-02 20:15:32,795 - Epoch: [144][  100/  391]    Overall Loss 0.260398    Objective Loss 0.260398    Top1 90.984375    Top5 99.734375    LR 0.092207    Time 0.019735    
2018-11-02 20:15:33,757 - Epoch: [144][  150/  391]    Overall Loss 0.259526    Objective Loss 0.259526    Top1 91.104167    Top5 99.770833    LR 0.092207    Time 0.019563    
2018-11-02 20:15:34,718 - Epoch: [144][  200/  391]    Overall Loss 0.264103    Objective Loss 0.264103    Top1 90.777344    Top5 99.750000    LR 0.092207    Time 0.019471    
2018-11-02 20:15:35,680 - Epoch: [144][  250/  391]    Overall Loss 0.268358    Objective Loss 0.268358    Top1 90.568750    Top5 99.759375    LR 0.092207    Time 0.019419    
2018-11-02 20:15:36,704 - Epoch: [144][  300/  391]    Overall Loss 0.265620    Objective Loss 0.265620    Top1 90.703125    Top5 99.763021    LR 0.092207    Time 0.019591    
2018-11-02 20:15:37,664 - Epoch: [144][  350/  391]    Overall Loss 0.269682    Objective Loss 0.269682    Top1 90.589286    Top5 99.752232    LR 0.092207    Time 0.019532    
2018-11-02 20:15:38,536 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.48865 | -0.00837 |    0.30619 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19096 |  0.00201 |    0.11920 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19977 | -0.00788 |    0.15007 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23007 | -0.04399 |    0.17467 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23728 |  0.00313 |    0.18626 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22710 | -0.03655 |    0.17529 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21917 | -0.00817 |    0.15929 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26297 | -0.00562 |    0.19360 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21801 | -0.00906 |    0.16802 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34435 | -0.01006 |    0.24284 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18028 | -0.00452 |    0.13673 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15596 | -0.01302 |    0.12300 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18552 | -0.02567 |    0.14857 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14008 | -0.00482 |    0.10931 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17232 | -0.02271 |    0.13799 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16428 | -0.00233 |    0.12981 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20100 | -0.02176 |    0.15646 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14954 | -0.01302 |    0.11794 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12522 | -0.00857 |    0.09722 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13235 | -0.01567 |    0.10479 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08542 |  0.00498 |    0.06286 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56138 | -0.00000 |    0.43638 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:15:38,536 - Total sparsity: 0.00

2018-11-02 20:15:38,537 - --- validate (epoch=144)-----------
2018-11-02 20:15:38,537 - 10000 samples (128 per mini-batch)
2018-11-02 20:15:39,254 - Epoch: [144][   50/   78]    Loss 0.447298    Top1 85.593750    Top5 99.296875    
2018-11-02 20:15:39,645 - ==> Top1: 85.540    Top5: 99.310    Loss: 0.446

2018-11-02 20:15:39,646 - ==> Best Top1: 86.930   On Epoch: 143

2018-11-02 20:15:39,646 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:15:39,657 - 

2018-11-02 20:15:39,658 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:15:40,677 - Epoch: [145][   50/  391]    Overall Loss 0.259969    Objective Loss 0.259969    Top1 91.468750    Top5 99.781250    LR 0.087597    Time 0.020349    
2018-11-02 20:15:41,637 - Epoch: [145][  100/  391]    Overall Loss 0.257262    Objective Loss 0.257262    Top1 91.320312    Top5 99.773438    LR 0.087597    Time 0.019765    
2018-11-02 20:15:42,599 - Epoch: [145][  150/  391]    Overall Loss 0.258751    Objective Loss 0.258751    Top1 91.062500    Top5 99.791667    LR 0.087597    Time 0.019584    
2018-11-02 20:15:43,563 - Epoch: [145][  200/  391]    Overall Loss 0.259660    Objective Loss 0.259660    Top1 90.937500    Top5 99.789062    LR 0.087597    Time 0.019500    
2018-11-02 20:15:44,525 - Epoch: [145][  250/  391]    Overall Loss 0.261296    Objective Loss 0.261296    Top1 90.850000    Top5 99.796875    LR 0.087597    Time 0.019445    
2018-11-02 20:15:45,489 - Epoch: [145][  300/  391]    Overall Loss 0.263502    Objective Loss 0.263502    Top1 90.802083    Top5 99.791667    LR 0.087597    Time 0.019413    
2018-11-02 20:15:46,452 - Epoch: [145][  350/  391]    Overall Loss 0.264779    Objective Loss 0.264779    Top1 90.745536    Top5 99.792411    LR 0.087597    Time 0.019388    
2018-11-02 20:15:47,322 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.48452 | -0.00656 |    0.30391 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18948 | -0.00023 |    0.11816 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19826 | -0.00772 |    0.14828 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22788 | -0.04544 |    0.17338 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23522 |  0.00246 |    0.18412 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22523 | -0.03565 |    0.17289 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21683 | -0.00827 |    0.15816 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26061 | -0.00639 |    0.19185 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21616 | -0.00884 |    0.16612 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.34088 | -0.01150 |    0.23866 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17880 | -0.00338 |    0.13566 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15480 | -0.01238 |    0.12175 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18417 | -0.02454 |    0.14700 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13908 | -0.00454 |    0.10845 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17081 | -0.02212 |    0.13661 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16297 | -0.00243 |    0.12884 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19894 | -0.02135 |    0.15475 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14848 | -0.01224 |    0.11707 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12446 | -0.00867 |    0.09681 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13155 | -0.01586 |    0.10421 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08468 |  0.00565 |    0.06237 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56304 | -0.00000 |    0.43751 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:15:47,322 - Total sparsity: 0.00

2018-11-02 20:15:47,322 - --- validate (epoch=145)-----------
2018-11-02 20:15:47,322 - 10000 samples (128 per mini-batch)
2018-11-02 20:15:48,042 - Epoch: [145][   50/   78]    Loss 0.499421    Top1 84.156250    Top5 99.375000    
2018-11-02 20:15:48,462 - ==> Top1: 84.100    Top5: 99.430    Loss: 0.490

2018-11-02 20:15:48,462 - ==> Best Top1: 86.930   On Epoch: 143

2018-11-02 20:15:48,462 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:15:48,469 - 

2018-11-02 20:15:48,470 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:15:49,486 - Epoch: [146][   50/  391]    Overall Loss 0.247691    Objective Loss 0.247691    Top1 91.421875    Top5 99.812500    LR 0.083217    Time 0.020296    
2018-11-02 20:15:50,445 - Epoch: [146][  100/  391]    Overall Loss 0.246287    Objective Loss 0.246287    Top1 91.507812    Top5 99.796875    LR 0.083217    Time 0.019722    
2018-11-02 20:15:51,406 - Epoch: [146][  150/  391]    Overall Loss 0.249165    Objective Loss 0.249165    Top1 91.395833    Top5 99.770833    LR 0.083217    Time 0.019550    
2018-11-02 20:15:52,366 - Epoch: [146][  200/  391]    Overall Loss 0.249324    Objective Loss 0.249324    Top1 91.382812    Top5 99.785156    LR 0.083217    Time 0.019454    
2018-11-02 20:15:53,327 - Epoch: [146][  250/  391]    Overall Loss 0.251963    Objective Loss 0.251963    Top1 91.309375    Top5 99.790625    LR 0.083217    Time 0.019403    
2018-11-02 20:15:54,287 - Epoch: [146][  300/  391]    Overall Loss 0.256246    Objective Loss 0.256246    Top1 91.106771    Top5 99.791667    LR 0.083217    Time 0.019365    
2018-11-02 20:15:55,246 - Epoch: [146][  350/  391]    Overall Loss 0.259387    Objective Loss 0.259387    Top1 90.955357    Top5 99.781250    LR 0.083217    Time 0.019337    
2018-11-02 20:15:56,119 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.48152 | -0.00695 |    0.30380 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18819 |  0.00046 |    0.11770 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19725 | -0.00987 |    0.14736 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22700 | -0.04347 |    0.17218 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23384 |  0.00184 |    0.18301 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22413 | -0.03422 |    0.17235 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21556 | -0.00779 |    0.15616 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25864 | -0.00768 |    0.18987 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21472 | -0.00916 |    0.16517 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33794 | -0.01280 |    0.23651 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17765 | -0.00344 |    0.13458 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15399 | -0.01228 |    0.12129 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18287 | -0.02484 |    0.14633 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13830 | -0.00482 |    0.10821 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16956 | -0.02254 |    0.13569 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16201 | -0.00252 |    0.12812 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19721 | -0.02118 |    0.15344 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14751 | -0.01252 |    0.11625 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12380 | -0.00823 |    0.09625 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13105 | -0.01541 |    0.10381 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08412 |  0.00556 |    0.06216 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56098 | -0.00000 |    0.43632 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:15:56,119 - Total sparsity: 0.00

2018-11-02 20:15:56,119 - --- validate (epoch=146)-----------
2018-11-02 20:15:56,119 - 10000 samples (128 per mini-batch)
2018-11-02 20:15:56,847 - Epoch: [146][   50/   78]    Loss 0.419739    Top1 86.671875    Top5 99.515625    
2018-11-02 20:15:57,239 - ==> Top1: 86.580    Top5: 99.550    Loss: 0.417

2018-11-02 20:15:57,240 - ==> Best Top1: 86.930   On Epoch: 143

2018-11-02 20:15:57,240 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:15:57,251 - 

2018-11-02 20:15:57,251 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:15:58,307 - Epoch: [147][   50/  391]    Overall Loss 0.253255    Objective Loss 0.253255    Top1 91.343750    Top5 99.796875    LR 0.079056    Time 0.021073    
2018-11-02 20:15:59,267 - Epoch: [147][  100/  391]    Overall Loss 0.249642    Objective Loss 0.249642    Top1 91.531250    Top5 99.804688    LR 0.079056    Time 0.020124    
2018-11-02 20:16:00,226 - Epoch: [147][  150/  391]    Overall Loss 0.251347    Objective Loss 0.251347    Top1 91.411458    Top5 99.812500    LR 0.079056    Time 0.019805    
2018-11-02 20:16:01,187 - Epoch: [147][  200/  391]    Overall Loss 0.255706    Objective Loss 0.255706    Top1 91.246094    Top5 99.816406    LR 0.079056    Time 0.019650    
2018-11-02 20:16:02,211 - Epoch: [147][  250/  391]    Overall Loss 0.254990    Objective Loss 0.254990    Top1 91.175000    Top5 99.809375    LR 0.079056    Time 0.019811    
2018-11-02 20:16:03,259 - Epoch: [147][  300/  391]    Overall Loss 0.250621    Objective Loss 0.250621    Top1 91.320312    Top5 99.807292    LR 0.079056    Time 0.020001    
2018-11-02 20:16:04,305 - Epoch: [147][  350/  391]    Overall Loss 0.248979    Objective Loss 0.248979    Top1 91.372768    Top5 99.814732    LR 0.079056    Time 0.020128    
2018-11-02 20:16:05,231 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.47788 | -0.00402 |    0.29976 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18665 |  0.00279 |    0.11736 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19571 | -0.00870 |    0.14653 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22530 | -0.04091 |    0.17119 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23148 |  0.00235 |    0.18121 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22203 | -0.03505 |    0.17069 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21351 | -0.00522 |    0.15439 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25647 | -0.00652 |    0.18899 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21311 | -0.00821 |    0.16400 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33466 | -0.01161 |    0.23314 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17634 | -0.00353 |    0.13330 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15283 | -0.01301 |    0.12025 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18146 | -0.02477 |    0.14519 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13732 | -0.00472 |    0.10726 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16808 | -0.02190 |    0.13440 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16082 | -0.00225 |    0.12718 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19552 | -0.02044 |    0.15199 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14641 | -0.01251 |    0.11543 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12300 | -0.00857 |    0.09579 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13031 | -0.01530 |    0.10343 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08348 |  0.00518 |    0.06179 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56256 | -0.00000 |    0.43834 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:16:05,231 - Total sparsity: 0.00

2018-11-02 20:16:05,231 - --- validate (epoch=147)-----------
2018-11-02 20:16:05,231 - 10000 samples (128 per mini-batch)
2018-11-02 20:16:05,950 - Epoch: [147][   50/   78]    Loss 0.417013    Top1 86.359375    Top5 99.562500    
2018-11-02 20:16:06,340 - ==> Top1: 86.310    Top5: 99.590    Loss: 0.413

2018-11-02 20:16:06,341 - ==> Best Top1: 86.930   On Epoch: 143

2018-11-02 20:16:06,341 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:16:06,348 - 

2018-11-02 20:16:06,348 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:16:07,367 - Epoch: [148][   50/  391]    Overall Loss 0.236609    Objective Loss 0.236609    Top1 91.843750    Top5 99.812500    LR 0.075103    Time 0.020333    
2018-11-02 20:16:08,329 - Epoch: [148][  100/  391]    Overall Loss 0.240095    Objective Loss 0.240095    Top1 91.492188    Top5 99.812500    LR 0.075103    Time 0.019776    
2018-11-02 20:16:09,292 - Epoch: [148][  150/  391]    Overall Loss 0.241230    Objective Loss 0.241230    Top1 91.406250    Top5 99.828125    LR 0.075103    Time 0.019597    
2018-11-02 20:16:10,253 - Epoch: [148][  200/  391]    Overall Loss 0.244270    Objective Loss 0.244270    Top1 91.335938    Top5 99.820312    LR 0.075103    Time 0.019498    
2018-11-02 20:16:11,215 - Epoch: [148][  250/  391]    Overall Loss 0.245816    Objective Loss 0.245816    Top1 91.393750    Top5 99.818750    LR 0.075103    Time 0.019442    
2018-11-02 20:16:12,178 - Epoch: [148][  300/  391]    Overall Loss 0.247753    Objective Loss 0.247753    Top1 91.325521    Top5 99.820312    LR 0.075103    Time 0.019408    
2018-11-02 20:16:13,139 - Epoch: [148][  350/  391]    Overall Loss 0.248774    Objective Loss 0.248774    Top1 91.281250    Top5 99.808036    LR 0.075103    Time 0.019375    
2018-11-02 20:16:14,009 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.47410 | -0.00567 |    0.29684 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18540 |  0.00222 |    0.11646 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19448 | -0.00783 |    0.14550 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22323 | -0.04375 |    0.17009 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22956 |  0.00286 |    0.18003 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22031 | -0.03620 |    0.16955 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21185 | -0.00670 |    0.15366 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25446 | -0.00513 |    0.18817 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21160 | -0.00743 |    0.16249 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.33163 | -0.01209 |    0.23052 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17503 | -0.00390 |    0.13236 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15184 | -0.01235 |    0.11930 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18040 | -0.02452 |    0.14415 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13651 | -0.00463 |    0.10662 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16682 | -0.02156 |    0.13346 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15978 | -0.00280 |    0.12640 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19381 | -0.02057 |    0.15054 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14550 | -0.01209 |    0.11463 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12230 | -0.00814 |    0.09502 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12967 | -0.01470 |    0.10285 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08280 |  0.00523 |    0.06124 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56222 | -0.00000 |    0.43734 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:16:14,009 - Total sparsity: 0.00

2018-11-02 20:16:14,010 - --- validate (epoch=148)-----------
2018-11-02 20:16:14,010 - 10000 samples (128 per mini-batch)
2018-11-02 20:16:14,728 - Epoch: [148][   50/   78]    Loss 0.383690    Top1 87.781250    Top5 99.578125    
2018-11-02 20:16:15,116 - ==> Top1: 87.530    Top5: 99.590    Loss: 0.390

2018-11-02 20:16:15,117 - ==> Best Top1: 87.530   On Epoch: 148

2018-11-02 20:16:15,117 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:16:15,130 - 

2018-11-02 20:16:15,130 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:16:16,222 - Epoch: [149][   50/  391]    Overall Loss 0.233036    Objective Loss 0.233036    Top1 91.921875    Top5 99.812500    LR 0.071348    Time 0.021805    
2018-11-02 20:16:17,185 - Epoch: [149][  100/  391]    Overall Loss 0.236307    Objective Loss 0.236307    Top1 91.843750    Top5 99.835938    LR 0.071348    Time 0.020512    
2018-11-02 20:16:18,145 - Epoch: [149][  150/  391]    Overall Loss 0.239276    Objective Loss 0.239276    Top1 91.718750    Top5 99.817708    LR 0.071348    Time 0.020072    
2018-11-02 20:16:19,107 - Epoch: [149][  200/  391]    Overall Loss 0.240047    Objective Loss 0.240047    Top1 91.757812    Top5 99.800781    LR 0.071348    Time 0.019856    
2018-11-02 20:16:20,068 - Epoch: [149][  250/  391]    Overall Loss 0.239504    Objective Loss 0.239504    Top1 91.681250    Top5 99.815625    LR 0.071348    Time 0.019725    
2018-11-02 20:16:21,030 - Epoch: [149][  300/  391]    Overall Loss 0.240914    Objective Loss 0.240914    Top1 91.585938    Top5 99.807292    LR 0.071348    Time 0.019640    
2018-11-02 20:16:21,993 - Epoch: [149][  350/  391]    Overall Loss 0.240746    Objective Loss 0.240746    Top1 91.595982    Top5 99.803571    LR 0.071348    Time 0.019583    
2018-11-02 20:16:22,861 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.47045 | -0.00345 |    0.29427 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18402 | -0.00006 |    0.11546 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19317 | -0.00535 |    0.14444 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22160 | -0.04231 |    0.16874 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22780 |  0.00213 |    0.17921 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21901 | -0.03544 |    0.16860 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21018 | -0.00694 |    0.15262 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25237 | -0.00552 |    0.18626 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20994 | -0.00845 |    0.16128 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32861 | -0.01077 |    0.22484 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17368 | -0.00494 |    0.13156 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15088 | -0.01131 |    0.11889 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17914 | -0.02397 |    0.14309 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13555 | -0.00480 |    0.10598 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16563 | -0.02118 |    0.13228 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15876 | -0.00242 |    0.12555 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19202 | -0.02071 |    0.14932 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14454 | -0.01249 |    0.11419 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12165 | -0.00804 |    0.09458 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12901 | -0.01477 |    0.10238 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08216 |  0.00537 |    0.06085 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56243 | -0.00000 |    0.43800 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:16:22,861 - Total sparsity: 0.00

2018-11-02 20:16:22,861 - --- validate (epoch=149)-----------
2018-11-02 20:16:22,861 - 10000 samples (128 per mini-batch)
2018-11-02 20:16:23,587 - Epoch: [149][   50/   78]    Loss 0.408660    Top1 87.234375    Top5 99.531250    
2018-11-02 20:16:23,982 - ==> Top1: 87.210    Top5: 99.510    Loss: 0.410

2018-11-02 20:16:23,983 - ==> Best Top1: 87.530   On Epoch: 148

2018-11-02 20:16:23,983 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:16:23,990 - 

2018-11-02 20:16:23,991 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:16:25,008 - Epoch: [150][   50/  391]    Overall Loss 0.225031    Objective Loss 0.225031    Top1 92.359375    Top5 99.875000    LR 0.067781    Time 0.020317    
2018-11-02 20:16:25,982 - Epoch: [150][  100/  391]    Overall Loss 0.218385    Objective Loss 0.218385    Top1 92.570312    Top5 99.898438    LR 0.067781    Time 0.019888    
2018-11-02 20:16:26,943 - Epoch: [150][  150/  391]    Overall Loss 0.230216    Objective Loss 0.230216    Top1 92.072917    Top5 99.848958    LR 0.067781    Time 0.019656    
2018-11-02 20:16:27,905 - Epoch: [150][  200/  391]    Overall Loss 0.230251    Objective Loss 0.230251    Top1 91.992188    Top5 99.843750    LR 0.067781    Time 0.019545    
2018-11-02 20:16:28,868 - Epoch: [150][  250/  391]    Overall Loss 0.230944    Objective Loss 0.230944    Top1 92.012500    Top5 99.825000    LR 0.067781    Time 0.019470    
2018-11-02 20:16:29,831 - Epoch: [150][  300/  391]    Overall Loss 0.232096    Objective Loss 0.232096    Top1 92.000000    Top5 99.828125    LR 0.067781    Time 0.019432    
2018-11-02 20:16:30,795 - Epoch: [150][  350/  391]    Overall Loss 0.234653    Objective Loss 0.234653    Top1 91.917411    Top5 99.814732    LR 0.067781    Time 0.019406    
2018-11-02 20:16:31,662 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.46639 | -0.00293 |    0.29256 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18279 | -0.00050 |    0.11518 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19200 | -0.00654 |    0.14386 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21969 | -0.04296 |    0.16708 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22592 |  0.00348 |    0.17766 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21727 | -0.03630 |    0.16805 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20865 | -0.00869 |    0.15092 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25047 | -0.00629 |    0.18473 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20850 | -0.00833 |    0.16003 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32547 | -0.00970 |    0.22547 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17256 | -0.00328 |    0.13084 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14990 | -0.01245 |    0.11837 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17792 | -0.02370 |    0.14215 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13476 | -0.00480 |    0.10532 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16432 | -0.02137 |    0.13116 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15775 | -0.00255 |    0.12475 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19047 | -0.01984 |    0.14826 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14368 | -0.01236 |    0.11352 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12093 | -0.00873 |    0.09407 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12836 | -0.01412 |    0.10174 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08155 |  0.00519 |    0.06034 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56135 | -0.00000 |    0.43720 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:16:31,662 - Total sparsity: 0.00

2018-11-02 20:16:31,662 - --- validate (epoch=150)-----------
2018-11-02 20:16:31,663 - 10000 samples (128 per mini-batch)
2018-11-02 20:16:32,379 - Epoch: [150][   50/   78]    Loss 0.414255    Top1 87.203125    Top5 99.437500    
2018-11-02 20:16:32,769 - ==> Top1: 87.370    Top5: 99.480    Loss: 0.403

2018-11-02 20:16:32,770 - ==> Best Top1: 87.530   On Epoch: 148

2018-11-02 20:16:32,770 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:16:32,781 - 

2018-11-02 20:16:32,781 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:16:33,800 - Epoch: [151][   50/  391]    Overall Loss 0.225838    Objective Loss 0.225838    Top1 92.312500    Top5 99.890625    LR 0.064392    Time 0.020337    
2018-11-02 20:16:34,762 - Epoch: [151][  100/  391]    Overall Loss 0.230639    Objective Loss 0.230639    Top1 92.015625    Top5 99.906250    LR 0.064392    Time 0.019776    
2018-11-02 20:16:35,730 - Epoch: [151][  150/  391]    Overall Loss 0.222560    Objective Loss 0.222560    Top1 92.156250    Top5 99.880208    LR 0.064392    Time 0.019633    
2018-11-02 20:16:36,694 - Epoch: [151][  200/  391]    Overall Loss 0.225469    Objective Loss 0.225469    Top1 92.156250    Top5 99.855469    LR 0.064392    Time 0.019536    
2018-11-02 20:16:37,655 - Epoch: [151][  250/  391]    Overall Loss 0.228133    Objective Loss 0.228133    Top1 92.053125    Top5 99.834375    LR 0.064392    Time 0.019470    
2018-11-02 20:16:38,618 - Epoch: [151][  300/  391]    Overall Loss 0.227903    Objective Loss 0.227903    Top1 92.080729    Top5 99.830729    LR 0.064392    Time 0.019430    
2018-11-02 20:16:39,580 - Epoch: [151][  350/  391]    Overall Loss 0.229920    Objective Loss 0.229920    Top1 91.991071    Top5 99.830357    LR 0.064392    Time 0.019400    
2018-11-02 20:16:40,451 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.46404 | -0.00696 |    0.29144 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18154 | -0.00032 |    0.11463 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19082 | -0.00870 |    0.14284 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21856 | -0.04102 |    0.16642 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22432 |  0.00340 |    0.17598 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21605 | -0.03500 |    0.16680 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20714 | -0.00979 |    0.15035 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24881 | -0.00624 |    0.18349 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20729 | -0.00658 |    0.15901 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32271 | -0.00839 |    0.22279 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17142 | -0.00319 |    0.12960 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14895 | -0.01280 |    0.11755 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17673 | -0.02322 |    0.14099 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13388 | -0.00446 |    0.10456 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16311 | -0.02139 |    0.13022 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15679 | -0.00217 |    0.12401 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18894 | -0.01939 |    0.14738 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14286 | -0.01227 |    0.11279 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12037 | -0.00796 |    0.09365 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12769 | -0.01411 |    0.10129 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08098 |  0.00509 |    0.05997 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56085 | -0.00000 |    0.43662 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:16:40,451 - Total sparsity: 0.00

2018-11-02 20:16:40,451 - --- validate (epoch=151)-----------
2018-11-02 20:16:40,451 - 10000 samples (128 per mini-batch)
2018-11-02 20:16:41,174 - Epoch: [151][   50/   78]    Loss 0.405286    Top1 87.328125    Top5 99.484375    
2018-11-02 20:16:41,569 - ==> Top1: 87.240    Top5: 99.530    Loss: 0.399

2018-11-02 20:16:41,569 - ==> Best Top1: 87.530   On Epoch: 148

2018-11-02 20:16:41,570 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:16:41,580 - 

2018-11-02 20:16:41,580 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:16:42,692 - Epoch: [152][   50/  391]    Overall Loss 0.213055    Objective Loss 0.213055    Top1 92.500000    Top5 99.875000    LR 0.061172    Time 0.022204    
2018-11-02 20:16:43,722 - Epoch: [152][  100/  391]    Overall Loss 0.216757    Objective Loss 0.216757    Top1 92.328125    Top5 99.851562    LR 0.061172    Time 0.021388    
2018-11-02 20:16:44,686 - Epoch: [152][  150/  391]    Overall Loss 0.220851    Objective Loss 0.220851    Top1 92.239583    Top5 99.817708    LR 0.061172    Time 0.020677    
2018-11-02 20:16:45,649 - Epoch: [152][  200/  391]    Overall Loss 0.220793    Objective Loss 0.220793    Top1 92.203125    Top5 99.839844    LR 0.061172    Time 0.020300    
2018-11-02 20:16:46,611 - Epoch: [152][  250/  391]    Overall Loss 0.221737    Objective Loss 0.221737    Top1 92.196875    Top5 99.846875    LR 0.061172    Time 0.020084    
2018-11-02 20:16:47,574 - Epoch: [152][  300/  391]    Overall Loss 0.220862    Objective Loss 0.220862    Top1 92.179688    Top5 99.838542    LR 0.061172    Time 0.019944    
2018-11-02 20:16:48,535 - Epoch: [152][  350/  391]    Overall Loss 0.221147    Objective Loss 0.221147    Top1 92.194196    Top5 99.848214    LR 0.061172    Time 0.019837    
2018-11-02 20:16:49,409 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.45983 | -0.00342 |    0.28814 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17990 |  0.00000 |    0.11345 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18935 | -0.00803 |    0.14279 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21644 | -0.04240 |    0.16552 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22258 |  0.00173 |    0.17455 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21451 | -0.03602 |    0.16516 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20538 | -0.00907 |    0.14892 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24712 | -0.00567 |    0.18223 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20583 | -0.00777 |    0.15802 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31974 | -0.00932 |    0.22091 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17012 | -0.00331 |    0.12858 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14798 | -0.01172 |    0.11685 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17539 | -0.02345 |    0.14008 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13288 | -0.00489 |    0.10368 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16182 | -0.02155 |    0.12918 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15574 | -0.00194 |    0.12315 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18746 | -0.01863 |    0.14592 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14194 | -0.01230 |    0.11212 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11963 | -0.00789 |    0.09298 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12690 | -0.01459 |    0.10073 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08032 |  0.00515 |    0.05953 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56159 | -0.00000 |    0.43748 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:16:49,409 - Total sparsity: 0.00

2018-11-02 20:16:49,409 - --- validate (epoch=152)-----------
2018-11-02 20:16:49,409 - 10000 samples (128 per mini-batch)
2018-11-02 20:16:50,125 - Epoch: [152][   50/   78]    Loss 0.444709    Top1 85.984375    Top5 99.296875    
2018-11-02 20:16:50,519 - ==> Top1: 85.610    Top5: 99.330    Loss: 0.449

2018-11-02 20:16:50,520 - ==> Best Top1: 87.530   On Epoch: 148

2018-11-02 20:16:50,520 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:16:50,527 - 

2018-11-02 20:16:50,527 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:16:51,545 - Epoch: [153][   50/  391]    Overall Loss 0.210013    Objective Loss 0.210013    Top1 92.578125    Top5 99.875000    LR 0.058113    Time 0.020338    
2018-11-02 20:16:52,506 - Epoch: [153][  100/  391]    Overall Loss 0.215910    Objective Loss 0.215910    Top1 92.328125    Top5 99.851562    LR 0.058113    Time 0.019762    
2018-11-02 20:16:53,467 - Epoch: [153][  150/  391]    Overall Loss 0.216945    Objective Loss 0.216945    Top1 92.380208    Top5 99.822917    LR 0.058113    Time 0.019577    
2018-11-02 20:16:54,428 - Epoch: [153][  200/  391]    Overall Loss 0.217513    Objective Loss 0.217513    Top1 92.386719    Top5 99.828125    LR 0.058113    Time 0.019480    
2018-11-02 20:16:55,390 - Epoch: [153][  250/  391]    Overall Loss 0.217118    Objective Loss 0.217118    Top1 92.393750    Top5 99.818750    LR 0.058113    Time 0.019426    
2018-11-02 20:16:56,351 - Epoch: [153][  300/  391]    Overall Loss 0.217297    Objective Loss 0.217297    Top1 92.393229    Top5 99.817708    LR 0.058113    Time 0.019390    
2018-11-02 20:16:57,314 - Epoch: [153][  350/  391]    Overall Loss 0.218162    Objective Loss 0.218162    Top1 92.392857    Top5 99.814732    LR 0.058113    Time 0.019367    
2018-11-02 20:16:58,185 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.45678 | -0.00473 |    0.28578 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17862 |  0.00028 |    0.11217 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18808 | -0.00950 |    0.14106 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21486 | -0.04322 |    0.16487 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22113 |  0.00376 |    0.17395 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21330 | -0.03578 |    0.16438 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20394 | -0.00916 |    0.14753 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24544 | -0.00495 |    0.18091 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20447 | -0.00756 |    0.15688 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31734 | -0.00901 |    0.21954 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16914 | -0.00394 |    0.12781 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14705 | -0.01226 |    0.11598 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17431 | -0.02308 |    0.13898 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13203 | -0.00551 |    0.10315 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16076 | -0.02070 |    0.12822 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15478 | -0.00210 |    0.12240 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18599 | -0.01810 |    0.14476 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14111 | -0.01233 |    0.11142 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00781 |    0.09245 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12627 | -0.01415 |    0.10021 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07975 |  0.00500 |    0.05919 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56133 | -0.00000 |    0.43737 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:16:58,185 - Total sparsity: 0.00

2018-11-02 20:16:58,186 - --- validate (epoch=153)-----------
2018-11-02 20:16:58,186 - 10000 samples (128 per mini-batch)
2018-11-02 20:16:58,906 - Epoch: [153][   50/   78]    Loss 0.415462    Top1 87.109375    Top5 99.531250    
2018-11-02 20:16:59,301 - ==> Top1: 87.020    Top5: 99.560    Loss: 0.418

2018-11-02 20:16:59,302 - ==> Best Top1: 87.530   On Epoch: 148

2018-11-02 20:16:59,302 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:16:59,313 - 

2018-11-02 20:16:59,313 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:17:00,333 - Epoch: [154][   50/  391]    Overall Loss 0.197954    Objective Loss 0.197954    Top1 93.031250    Top5 99.812500    LR 0.055208    Time 0.020358    
2018-11-02 20:17:01,294 - Epoch: [154][  100/  391]    Overall Loss 0.206881    Objective Loss 0.206881    Top1 92.703125    Top5 99.796875    LR 0.055208    Time 0.019783    
2018-11-02 20:17:02,257 - Epoch: [154][  150/  391]    Overall Loss 0.212916    Objective Loss 0.212916    Top1 92.510417    Top5 99.796875    LR 0.055208    Time 0.019603    
2018-11-02 20:17:03,219 - Epoch: [154][  200/  391]    Overall Loss 0.215135    Objective Loss 0.215135    Top1 92.496094    Top5 99.808594    LR 0.055208    Time 0.019507    
2018-11-02 20:17:04,184 - Epoch: [154][  250/  391]    Overall Loss 0.216898    Objective Loss 0.216898    Top1 92.418750    Top5 99.818750    LR 0.055208    Time 0.019459    
2018-11-02 20:17:05,147 - Epoch: [154][  300/  391]    Overall Loss 0.218377    Objective Loss 0.218377    Top1 92.354167    Top5 99.822917    LR 0.055208    Time 0.019424    
2018-11-02 20:17:06,109 - Epoch: [154][  350/  391]    Overall Loss 0.217728    Objective Loss 0.217728    Top1 92.366071    Top5 99.834821    LR 0.055208    Time 0.019394    
2018-11-02 20:17:06,979 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.45340 | -0.00674 |    0.28384 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17722 | -0.00040 |    0.11171 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18686 | -0.00953 |    0.14011 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21369 | -0.04192 |    0.16334 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21963 |  0.00331 |    0.17243 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21225 | -0.03448 |    0.16342 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20267 | -0.00573 |    0.14695 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24379 | -0.00436 |    0.17904 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20311 | -0.00677 |    0.15608 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31499 | -0.00846 |    0.21768 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16831 | -0.00363 |    0.12713 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14625 | -0.01244 |    0.11541 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17321 | -0.02325 |    0.13825 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13129 | -0.00546 |    0.10272 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15969 | -0.02000 |    0.12747 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15386 | -0.00248 |    0.12166 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18456 | -0.01789 |    0.14376 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14035 | -0.01200 |    0.11078 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11831 | -0.00823 |    0.09209 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12567 | -0.01387 |    0.09978 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07922 |  0.00498 |    0.05880 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56022 | -0.00000 |    0.43637 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:17:06,979 - Total sparsity: 0.00

2018-11-02 20:17:06,979 - --- validate (epoch=154)-----------
2018-11-02 20:17:06,979 - 10000 samples (128 per mini-batch)
2018-11-02 20:17:07,695 - Epoch: [154][   50/   78]    Loss 0.379521    Top1 88.609375    Top5 99.562500    
2018-11-02 20:17:08,084 - ==> Top1: 88.440    Top5: 99.600    Loss: 0.376

2018-11-02 20:17:08,085 - ==> Best Top1: 88.440   On Epoch: 154

2018-11-02 20:17:08,085 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:17:08,096 - 

2018-11-02 20:17:08,097 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:17:09,116 - Epoch: [155][   50/  391]    Overall Loss 0.214542    Objective Loss 0.214542    Top1 92.812500    Top5 99.828125    LR 0.052447    Time 0.020346    
2018-11-02 20:17:10,076 - Epoch: [155][  100/  391]    Overall Loss 0.211013    Objective Loss 0.211013    Top1 92.992188    Top5 99.859375    LR 0.052447    Time 0.019761    
2018-11-02 20:17:11,036 - Epoch: [155][  150/  391]    Overall Loss 0.202204    Objective Loss 0.202204    Top1 93.125000    Top5 99.859375    LR 0.052447    Time 0.019570    
2018-11-02 20:17:11,997 - Epoch: [155][  200/  391]    Overall Loss 0.206870    Objective Loss 0.206870    Top1 92.898438    Top5 99.851562    LR 0.052447    Time 0.019475    
2018-11-02 20:17:12,959 - Epoch: [155][  250/  391]    Overall Loss 0.207317    Objective Loss 0.207317    Top1 92.859375    Top5 99.859375    LR 0.052447    Time 0.019423    
2018-11-02 20:17:14,001 - Epoch: [155][  300/  391]    Overall Loss 0.208982    Objective Loss 0.208982    Top1 92.815104    Top5 99.846354    LR 0.052447    Time 0.019657    
2018-11-02 20:17:15,007 - Epoch: [155][  350/  391]    Overall Loss 0.209579    Objective Loss 0.209579    Top1 92.779018    Top5 99.850446    LR 0.052447    Time 0.019709    
2018-11-02 20:17:15,876 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44960 | -0.00912 |    0.28137 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17577 | -0.00066 |    0.11107 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18565 | -0.01013 |    0.13887 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21196 | -0.04204 |    0.16238 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21804 |  0.00414 |    0.17126 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21092 | -0.03327 |    0.16276 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20124 | -0.00580 |    0.14550 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24202 | -0.00356 |    0.17817 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20168 | -0.00656 |    0.15479 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31271 | -0.00749 |    0.21664 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16731 | -0.00287 |    0.12671 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14542 | -0.01226 |    0.11483 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17226 | -0.02273 |    0.13758 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13049 | -0.00642 |    0.10219 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15851 | -0.01953 |    0.12660 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15286 | -0.00235 |    0.12084 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18303 | -0.01805 |    0.14245 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13950 | -0.01173 |    0.11026 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11760 | -0.00858 |    0.09155 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12495 | -0.01408 |    0.09931 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07863 |  0.00487 |    0.05842 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56002 | -0.00000 |    0.43640 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:17:15,877 - Total sparsity: 0.00

2018-11-02 20:17:15,877 - --- validate (epoch=155)-----------
2018-11-02 20:17:15,877 - 10000 samples (128 per mini-batch)
2018-11-02 20:17:16,601 - Epoch: [155][   50/   78]    Loss 0.357633    Top1 88.703125    Top5 99.640625    
2018-11-02 20:17:16,993 - ==> Top1: 88.500    Top5: 99.630    Loss: 0.367

2018-11-02 20:17:16,993 - ==> Best Top1: 88.500   On Epoch: 155

2018-11-02 20:17:16,994 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:17:17,003 - 

2018-11-02 20:17:17,004 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:17:18,021 - Epoch: [156][   50/  391]    Overall Loss 0.195399    Objective Loss 0.195399    Top1 93.265625    Top5 99.921875    LR 0.049825    Time 0.020316    
2018-11-02 20:17:18,982 - Epoch: [156][  100/  391]    Overall Loss 0.204647    Objective Loss 0.204647    Top1 92.992188    Top5 99.906250    LR 0.049825    Time 0.019755    
2018-11-02 20:17:19,943 - Epoch: [156][  150/  391]    Overall Loss 0.202267    Objective Loss 0.202267    Top1 92.958333    Top5 99.906250    LR 0.049825    Time 0.019574    
2018-11-02 20:17:20,906 - Epoch: [156][  200/  391]    Overall Loss 0.202379    Objective Loss 0.202379    Top1 92.964844    Top5 99.898438    LR 0.049825    Time 0.019489    
2018-11-02 20:17:21,869 - Epoch: [156][  250/  391]    Overall Loss 0.203309    Objective Loss 0.203309    Top1 92.925000    Top5 99.890625    LR 0.049825    Time 0.019436    
2018-11-02 20:17:22,830 - Epoch: [156][  300/  391]    Overall Loss 0.204533    Objective Loss 0.204533    Top1 92.835938    Top5 99.888021    LR 0.049825    Time 0.019397    
2018-11-02 20:17:23,792 - Epoch: [156][  350/  391]    Overall Loss 0.203490    Objective Loss 0.203490    Top1 92.895089    Top5 99.875000    LR 0.049825    Time 0.019372    
2018-11-02 20:17:24,723 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44644 | -0.00368 |    0.27975 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17455 | -0.00007 |    0.11060 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18474 | -0.00749 |    0.13802 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21057 | -0.04140 |    0.16105 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21652 |  0.00433 |    0.17021 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20941 | -0.03394 |    0.16241 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19981 | -0.00642 |    0.14511 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24035 | -0.00523 |    0.17631 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20037 | -0.00731 |    0.15339 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.31032 | -0.00789 |    0.21465 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16631 | -0.00220 |    0.12573 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14459 | -0.01218 |    0.11409 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17129 | -0.02208 |    0.13672 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12979 | -0.00573 |    0.10200 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15749 | -0.01875 |    0.12557 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15191 | -0.00194 |    0.12023 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18166 | -0.01740 |    0.14096 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13873 | -0.01110 |    0.10965 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11697 | -0.00843 |    0.09112 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12429 | -0.01371 |    0.09866 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07806 |  0.00472 |    0.05806 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56149 | -0.00000 |    0.43782 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:17:24,723 - Total sparsity: 0.00

2018-11-02 20:17:24,723 - --- validate (epoch=156)-----------
2018-11-02 20:17:24,724 - 10000 samples (128 per mini-batch)
2018-11-02 20:17:25,430 - Epoch: [156][   50/   78]    Loss 0.391999    Top1 88.312500    Top5 99.656250    
2018-11-02 20:17:25,822 - ==> Top1: 88.140    Top5: 99.640    Loss: 0.391

2018-11-02 20:17:25,823 - ==> Best Top1: 88.500   On Epoch: 155

2018-11-02 20:17:25,823 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:17:25,830 - 

2018-11-02 20:17:25,830 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:17:26,850 - Epoch: [157][   50/  391]    Overall Loss 0.188770    Objective Loss 0.188770    Top1 93.500000    Top5 99.953125    LR 0.047334    Time 0.020369    
2018-11-02 20:17:27,811 - Epoch: [157][  100/  391]    Overall Loss 0.199938    Objective Loss 0.199938    Top1 93.156250    Top5 99.890625    LR 0.047334    Time 0.019780    
2018-11-02 20:17:28,771 - Epoch: [157][  150/  391]    Overall Loss 0.197280    Objective Loss 0.197280    Top1 93.213542    Top5 99.895833    LR 0.047334    Time 0.019574    
2018-11-02 20:17:29,735 - Epoch: [157][  200/  391]    Overall Loss 0.198025    Objective Loss 0.198025    Top1 93.148438    Top5 99.890625    LR 0.047334    Time 0.019497    
2018-11-02 20:17:30,699 - Epoch: [157][  250/  391]    Overall Loss 0.203004    Objective Loss 0.203004    Top1 92.931250    Top5 99.871875    LR 0.047334    Time 0.019449    
2018-11-02 20:17:31,663 - Epoch: [157][  300/  391]    Overall Loss 0.202443    Objective Loss 0.202443    Top1 92.950521    Top5 99.875000    LR 0.047334    Time 0.019415    
2018-11-02 20:17:32,626 - Epoch: [157][  350/  391]    Overall Loss 0.204288    Objective Loss 0.204288    Top1 92.877232    Top5 99.879464    LR 0.047334    Time 0.019390    
2018-11-02 20:17:33,494 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44306 | -0.00183 |    0.27726 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17346 | -0.00132 |    0.10957 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18374 | -0.00726 |    0.13792 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20933 | -0.04082 |    0.16056 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21527 |  0.00173 |    0.16906 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20823 | -0.03380 |    0.16078 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19851 | -0.00699 |    0.14362 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23894 | -0.00412 |    0.17534 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19916 | -0.00796 |    0.15263 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30814 | -0.00852 |    0.21330 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16535 | -0.00306 |    0.12503 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14370 | -0.01309 |    0.11332 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17031 | -0.02221 |    0.13619 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12914 | -0.00546 |    0.10189 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15645 | -0.01895 |    0.12485 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15108 | -0.00180 |    0.11964 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18032 | -0.01756 |    0.14002 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13802 | -0.01076 |    0.10902 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11643 | -0.00819 |    0.09078 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12374 | -0.01347 |    0.09823 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07754 |  0.00477 |    0.05775 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56004 | -0.00000 |    0.43673 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:17:33,494 - Total sparsity: 0.00

2018-11-02 20:17:33,495 - --- validate (epoch=157)-----------
2018-11-02 20:17:33,495 - 10000 samples (128 per mini-batch)
2018-11-02 20:17:34,214 - Epoch: [157][   50/   78]    Loss 0.366888    Top1 88.968750    Top5 99.500000    
2018-11-02 20:17:34,604 - ==> Top1: 88.780    Top5: 99.510    Loss: 0.363

2018-11-02 20:17:34,605 - ==> Best Top1: 88.780   On Epoch: 157

2018-11-02 20:17:34,605 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:17:34,617 - 

2018-11-02 20:17:34,618 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:17:35,635 - Epoch: [158][   50/  391]    Overall Loss 0.181119    Objective Loss 0.181119    Top1 93.421875    Top5 99.906250    LR 0.044967    Time 0.020300    
2018-11-02 20:17:36,595 - Epoch: [158][  100/  391]    Overall Loss 0.190083    Objective Loss 0.190083    Top1 93.125000    Top5 99.906250    LR 0.044967    Time 0.019738    
2018-11-02 20:17:37,555 - Epoch: [158][  150/  391]    Overall Loss 0.191636    Objective Loss 0.191636    Top1 93.171875    Top5 99.921875    LR 0.044967    Time 0.019554    
2018-11-02 20:17:38,516 - Epoch: [158][  200/  391]    Overall Loss 0.191047    Objective Loss 0.191047    Top1 93.261719    Top5 99.914062    LR 0.044967    Time 0.019466    
2018-11-02 20:17:39,476 - Epoch: [158][  250/  391]    Overall Loss 0.194180    Objective Loss 0.194180    Top1 93.218750    Top5 99.890625    LR 0.044967    Time 0.019406    
2018-11-02 20:17:40,435 - Epoch: [158][  300/  391]    Overall Loss 0.195540    Objective Loss 0.195540    Top1 93.197917    Top5 99.872396    LR 0.044967    Time 0.019367    
2018-11-02 20:17:41,404 - Epoch: [158][  350/  391]    Overall Loss 0.195718    Objective Loss 0.195718    Top1 93.169643    Top5 99.879464    LR 0.044967    Time 0.019363    
2018-11-02 20:17:42,276 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43990 | -0.00418 |    0.27485 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17233 | -0.00164 |    0.10910 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18258 | -0.00795 |    0.13763 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20789 | -0.04050 |    0.15958 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21374 |  0.00353 |    0.16803 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20631 | -0.03621 |    0.15956 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19706 | -0.00650 |    0.14262 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23738 | -0.00335 |    0.17415 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19799 | -0.00735 |    0.15159 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30580 | -0.00888 |    0.21093 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16435 | -0.00287 |    0.12408 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14287 | -0.01302 |    0.11285 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16933 | -0.02156 |    0.13512 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12847 | -0.00447 |    0.10089 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15534 | -0.01943 |    0.12406 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15015 | -0.00113 |    0.11887 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17901 | -0.01673 |    0.13887 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13712 | -0.01111 |    0.10830 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11583 | -0.00781 |    0.09031 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12310 | -0.01341 |    0.09773 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07698 |  0.00476 |    0.05736 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56172 | -0.00000 |    0.43794 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:17:42,276 - Total sparsity: 0.00

2018-11-02 20:17:42,276 - --- validate (epoch=158)-----------
2018-11-02 20:17:42,276 - 10000 samples (128 per mini-batch)
2018-11-02 20:17:42,981 - Epoch: [158][   50/   78]    Loss 0.355843    Top1 89.000000    Top5 99.500000    
2018-11-02 20:17:43,373 - ==> Top1: 88.820    Top5: 99.590    Loss: 0.360

2018-11-02 20:17:43,374 - ==> Best Top1: 88.820   On Epoch: 158

2018-11-02 20:17:43,374 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:17:43,383 - 

2018-11-02 20:17:43,384 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:17:44,488 - Epoch: [159][   50/  391]    Overall Loss 0.179222    Objective Loss 0.179222    Top1 93.656250    Top5 99.906250    LR 0.042719    Time 0.022062    
2018-11-02 20:17:45,535 - Epoch: [159][  100/  391]    Overall Loss 0.178431    Objective Loss 0.178431    Top1 93.679688    Top5 99.929688    LR 0.042719    Time 0.021489    
2018-11-02 20:17:46,498 - Epoch: [159][  150/  391]    Overall Loss 0.188362    Objective Loss 0.188362    Top1 93.260417    Top5 99.890625    LR 0.042719    Time 0.020734    
2018-11-02 20:17:47,461 - Epoch: [159][  200/  391]    Overall Loss 0.187954    Objective Loss 0.187954    Top1 93.335938    Top5 99.867188    LR 0.042719    Time 0.020362    
2018-11-02 20:17:48,424 - Epoch: [159][  250/  391]    Overall Loss 0.189068    Objective Loss 0.189068    Top1 93.203125    Top5 99.881250    LR 0.042719    Time 0.020136    
2018-11-02 20:17:49,387 - Epoch: [159][  300/  391]    Overall Loss 0.190103    Objective Loss 0.190103    Top1 93.130208    Top5 99.882812    LR 0.042719    Time 0.019973    
2018-11-02 20:17:50,350 - Epoch: [159][  350/  391]    Overall Loss 0.189063    Objective Loss 0.189063    Top1 93.180804    Top5 99.886161    LR 0.042719    Time 0.019870    
2018-11-02 20:17:51,217 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43710 | -0.00557 |    0.27262 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17132 | -0.00001 |    0.10865 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18164 | -0.00726 |    0.13643 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20681 | -0.03906 |    0.15848 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21243 |  0.00418 |    0.16712 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20540 | -0.03385 |    0.15865 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19564 | -0.00513 |    0.14240 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23588 | -0.00315 |    0.17338 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19681 | -0.00663 |    0.15075 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30351 | -0.00709 |    0.20909 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16336 | -0.00286 |    0.12339 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14206 | -0.01266 |    0.11210 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16829 | -0.02129 |    0.13403 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12778 | -0.00408 |    0.10042 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15435 | -0.01922 |    0.12336 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14926 | -0.00137 |    0.11811 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17765 | -0.01670 |    0.13803 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13633 | -0.01113 |    0.10767 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11524 | -0.00775 |    0.08993 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12250 | -0.01335 |    0.09732 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07648 |  0.00462 |    0.05697 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56228 | -0.00000 |    0.43862 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:17:51,217 - Total sparsity: 0.00

2018-11-02 20:17:51,217 - --- validate (epoch=159)-----------
2018-11-02 20:17:51,217 - 10000 samples (128 per mini-batch)
2018-11-02 20:17:51,944 - Epoch: [159][   50/   78]    Loss 0.369894    Top1 88.218750    Top5 99.515625    
2018-11-02 20:17:52,339 - ==> Top1: 88.090    Top5: 99.540    Loss: 0.380

2018-11-02 20:17:52,340 - ==> Best Top1: 88.820   On Epoch: 158

2018-11-02 20:17:52,340 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:17:52,351 - 

2018-11-02 20:17:52,351 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:17:53,369 - Epoch: [160][   50/  391]    Overall Loss 0.189582    Objective Loss 0.189582    Top1 93.281250    Top5 99.906250    LR 0.040583    Time 0.020328    
2018-11-02 20:17:54,331 - Epoch: [160][  100/  391]    Overall Loss 0.182215    Objective Loss 0.182215    Top1 93.703125    Top5 99.921875    LR 0.040583    Time 0.019766    
2018-11-02 20:17:55,292 - Epoch: [160][  150/  391]    Overall Loss 0.181638    Objective Loss 0.181638    Top1 93.661458    Top5 99.921875    LR 0.040583    Time 0.019576    
2018-11-02 20:17:56,273 - Epoch: [160][  200/  391]    Overall Loss 0.183027    Objective Loss 0.183027    Top1 93.574219    Top5 99.921875    LR 0.040583    Time 0.019584    
2018-11-02 20:17:57,297 - Epoch: [160][  250/  391]    Overall Loss 0.187383    Objective Loss 0.187383    Top1 93.487500    Top5 99.912500    LR 0.040583    Time 0.019758    
2018-11-02 20:17:58,258 - Epoch: [160][  300/  391]    Overall Loss 0.188440    Objective Loss 0.188440    Top1 93.445312    Top5 99.895833    LR 0.040583    Time 0.019664    
2018-11-02 20:17:59,220 - Epoch: [160][  350/  391]    Overall Loss 0.188427    Objective Loss 0.188427    Top1 93.397321    Top5 99.895089    LR 0.040583    Time 0.019599    
2018-11-02 20:18:00,135 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43434 | -0.00189 |    0.27065 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17016 | -0.00100 |    0.10788 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18055 | -0.00725 |    0.13611 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20561 | -0.03813 |    0.15730 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21107 |  0.00472 |    0.16602 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20390 | -0.03518 |    0.15728 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19431 | -0.00616 |    0.14121 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23451 | -0.00332 |    0.17275 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19569 | -0.00657 |    0.15008 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.30135 | -0.00819 |    0.20687 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16242 | -0.00225 |    0.12278 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14137 | -0.01148 |    0.11154 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16735 | -0.02133 |    0.13356 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12712 | -0.00369 |    0.09991 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15343 | -0.01904 |    0.12266 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14841 | -0.00158 |    0.11751 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17637 | -0.01681 |    0.13680 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13560 | -0.01092 |    0.10710 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11470 | -0.00769 |    0.08942 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12192 | -0.01329 |    0.09690 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07597 |  0.00465 |    0.05667 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56177 | -0.00000 |    0.43815 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:18:00,135 - Total sparsity: 0.00

2018-11-02 20:18:00,135 - --- validate (epoch=160)-----------
2018-11-02 20:18:00,135 - 10000 samples (128 per mini-batch)
2018-11-02 20:18:00,849 - Epoch: [160][   50/   78]    Loss 0.383612    Top1 88.578125    Top5 99.546875    
2018-11-02 20:18:01,235 - ==> Top1: 88.370    Top5: 99.560    Loss: 0.381

2018-11-02 20:18:01,236 - ==> Best Top1: 88.820   On Epoch: 158

2018-11-02 20:18:01,236 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:18:01,244 - 

2018-11-02 20:18:01,244 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:18:02,259 - Epoch: [161][   50/  391]    Overall Loss 0.175465    Objective Loss 0.175465    Top1 93.859375    Top5 99.890625    LR 0.038554    Time 0.020272    
2018-11-02 20:18:03,220 - Epoch: [161][  100/  391]    Overall Loss 0.173558    Objective Loss 0.173558    Top1 93.898438    Top5 99.906250    LR 0.038554    Time 0.019732    
2018-11-02 20:18:04,181 - Epoch: [161][  150/  391]    Overall Loss 0.177995    Objective Loss 0.177995    Top1 93.854167    Top5 99.895833    LR 0.038554    Time 0.019551    
2018-11-02 20:18:05,143 - Epoch: [161][  200/  391]    Overall Loss 0.182971    Objective Loss 0.182971    Top1 93.722656    Top5 99.910156    LR 0.038554    Time 0.019467    
2018-11-02 20:18:06,109 - Epoch: [161][  250/  391]    Overall Loss 0.184444    Objective Loss 0.184444    Top1 93.653125    Top5 99.912500    LR 0.038554    Time 0.019419    
2018-11-02 20:18:07,072 - Epoch: [161][  300/  391]    Overall Loss 0.184235    Objective Loss 0.184235    Top1 93.627604    Top5 99.916667    LR 0.038554    Time 0.019389    
2018-11-02 20:18:08,034 - Epoch: [161][  350/  391]    Overall Loss 0.183738    Objective Loss 0.183738    Top1 93.651786    Top5 99.919643    LR 0.038554    Time 0.019365    
2018-11-02 20:18:08,901 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43151 | -0.00128 |    0.26943 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16901 | -0.00116 |    0.10693 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17948 | -0.00748 |    0.13514 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20426 | -0.03788 |    0.15652 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20965 |  0.00410 |    0.16463 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20280 | -0.03449 |    0.15636 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19295 | -0.00774 |    0.14021 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23307 | -0.00237 |    0.17154 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19456 | -0.00639 |    0.14921 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29926 | -0.00884 |    0.20536 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16156 | -0.00176 |    0.12228 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14054 | -0.01205 |    0.11078 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16648 | -0.02084 |    0.13307 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12647 | -0.00403 |    0.09946 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15246 | -0.01920 |    0.12198 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14759 | -0.00141 |    0.11685 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17513 | -0.01640 |    0.13567 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13486 | -0.01077 |    0.10654 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11414 | -0.00792 |    0.08902 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12131 | -0.01363 |    0.09654 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07549 |  0.00446 |    0.05634 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56197 | -0.00000 |    0.43855 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:18:08,901 - Total sparsity: 0.00

2018-11-02 20:18:08,901 - --- validate (epoch=161)-----------
2018-11-02 20:18:08,901 - 10000 samples (128 per mini-batch)
2018-11-02 20:18:09,627 - Epoch: [161][   50/   78]    Loss 0.386249    Top1 88.250000    Top5 99.453125    
2018-11-02 20:18:10,021 - ==> Top1: 88.200    Top5: 99.530    Loss: 0.385

2018-11-02 20:18:10,022 - ==> Best Top1: 88.820   On Epoch: 158

2018-11-02 20:18:10,022 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:18:10,029 - 

2018-11-02 20:18:10,030 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:18:11,127 - Epoch: [162][   50/  391]    Overall Loss 0.157530    Objective Loss 0.157530    Top1 94.640625    Top5 99.875000    LR 0.036626    Time 0.021924    
2018-11-02 20:18:12,088 - Epoch: [162][  100/  391]    Overall Loss 0.167193    Objective Loss 0.167193    Top1 94.140625    Top5 99.906250    LR 0.036626    Time 0.020555    
2018-11-02 20:18:13,049 - Epoch: [162][  150/  391]    Overall Loss 0.167713    Objective Loss 0.167713    Top1 94.156250    Top5 99.906250    LR 0.036626    Time 0.020107    
2018-11-02 20:18:14,013 - Epoch: [162][  200/  391]    Overall Loss 0.171469    Objective Loss 0.171469    Top1 94.000000    Top5 99.914062    LR 0.036626    Time 0.019892    
2018-11-02 20:18:14,974 - Epoch: [162][  250/  391]    Overall Loss 0.173009    Objective Loss 0.173009    Top1 93.953125    Top5 99.909375    LR 0.036626    Time 0.019757    
2018-11-02 20:18:15,938 - Epoch: [162][  300/  391]    Overall Loss 0.174738    Objective Loss 0.174738    Top1 93.898438    Top5 99.914062    LR 0.036626    Time 0.019673    
2018-11-02 20:18:16,899 - Epoch: [162][  350/  391]    Overall Loss 0.175484    Objective Loss 0.175484    Top1 93.803571    Top5 99.910714    LR 0.036626    Time 0.019602    
2018-11-02 20:18:17,769 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42853 | -0.00040 |    0.26818 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16798 | -0.00134 |    0.10598 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17843 | -0.00771 |    0.13439 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20295 | -0.03771 |    0.15564 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20839 |  0.00339 |    0.16382 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20177 | -0.03382 |    0.15533 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19186 | -0.00676 |    0.13953 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23168 | -0.00294 |    0.17067 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19342 | -0.00668 |    0.14812 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29738 | -0.00734 |    0.20423 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16078 | -0.00208 |    0.12161 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13991 | -0.01162 |    0.11032 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16559 | -0.02104 |    0.13243 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12583 | -0.00410 |    0.09886 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15156 | -0.01887 |    0.12106 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14677 | -0.00178 |    0.11628 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17397 | -0.01583 |    0.13488 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13413 | -0.01088 |    0.10592 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11360 | -0.00795 |    0.08860 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12074 | -0.01334 |    0.09608 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07498 |  0.00446 |    0.05601 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56180 | -0.00000 |    0.43852 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:18:17,769 - Total sparsity: 0.00

2018-11-02 20:18:17,769 - --- validate (epoch=162)-----------
2018-11-02 20:18:17,770 - 10000 samples (128 per mini-batch)
2018-11-02 20:18:18,481 - Epoch: [162][   50/   78]    Loss 0.359885    Top1 88.796875    Top5 99.656250    
2018-11-02 20:18:18,867 - ==> Top1: 88.760    Top5: 99.650    Loss: 0.360

2018-11-02 20:18:18,868 - ==> Best Top1: 88.820   On Epoch: 158

2018-11-02 20:18:18,868 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:18:18,876 - 

2018-11-02 20:18:18,876 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:18:19,892 - Epoch: [163][   50/  391]    Overall Loss 0.169581    Objective Loss 0.169581    Top1 93.703125    Top5 99.953125    LR 0.034795    Time 0.020290    
2018-11-02 20:18:20,854 - Epoch: [163][  100/  391]    Overall Loss 0.174341    Objective Loss 0.174341    Top1 93.734375    Top5 99.937500    LR 0.034795    Time 0.019753    
2018-11-02 20:18:21,815 - Epoch: [163][  150/  391]    Overall Loss 0.171767    Objective Loss 0.171767    Top1 93.968750    Top5 99.932292    LR 0.034795    Time 0.019571    
2018-11-02 20:18:22,778 - Epoch: [163][  200/  391]    Overall Loss 0.171469    Objective Loss 0.171469    Top1 94.000000    Top5 99.933594    LR 0.034795    Time 0.019485    
2018-11-02 20:18:23,761 - Epoch: [163][  250/  391]    Overall Loss 0.172764    Objective Loss 0.172764    Top1 93.987500    Top5 99.937500    LR 0.034795    Time 0.019515    
2018-11-02 20:18:24,803 - Epoch: [163][  300/  391]    Overall Loss 0.175554    Objective Loss 0.175554    Top1 93.835938    Top5 99.932292    LR 0.034795    Time 0.019731    
2018-11-02 20:18:25,845 - Epoch: [163][  350/  391]    Overall Loss 0.176745    Objective Loss 0.176745    Top1 93.810268    Top5 99.919643    LR 0.034795    Time 0.019885    
2018-11-02 20:18:26,786 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42587 | -0.00386 |    0.26600 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16700 | -0.00085 |    0.10551 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17747 | -0.00721 |    0.13425 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20202 | -0.03606 |    0.15444 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20725 |  0.00038 |    0.16282 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20079 | -0.03349 |    0.15454 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19073 | -0.00732 |    0.13856 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.23028 | -0.00277 |    0.16936 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19230 | -0.00612 |    0.14690 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29541 | -0.00686 |    0.20180 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15997 | -0.00227 |    0.12101 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13921 | -0.01142 |    0.10975 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16465 | -0.02131 |    0.13155 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12519 | -0.00401 |    0.09846 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15068 | -0.01866 |    0.12027 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14601 | -0.00145 |    0.11578 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17280 | -0.01556 |    0.13381 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13343 | -0.01101 |    0.10541 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11306 | -0.00825 |    0.08821 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12024 | -0.01298 |    0.09562 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07452 |  0.00445 |    0.05575 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56168 | -0.00000 |    0.43821 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:18:26,787 - Total sparsity: 0.00

2018-11-02 20:18:26,787 - --- validate (epoch=163)-----------
2018-11-02 20:18:26,787 - 10000 samples (128 per mini-batch)
2018-11-02 20:18:27,516 - Epoch: [163][   50/   78]    Loss 0.363447    Top1 89.015625    Top5 99.593750    
2018-11-02 20:18:27,906 - ==> Top1: 88.910    Top5: 99.640    Loss: 0.366

2018-11-02 20:18:27,910 - ==> Best Top1: 88.910   On Epoch: 163

2018-11-02 20:18:27,910 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:18:27,919 - 

2018-11-02 20:18:27,919 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:18:29,017 - Epoch: [164][   50/  391]    Overall Loss 0.162365    Objective Loss 0.162365    Top1 94.437500    Top5 99.921875    LR 0.033055    Time 0.021921    
2018-11-02 20:18:30,054 - Epoch: [164][  100/  391]    Overall Loss 0.160911    Objective Loss 0.160911    Top1 94.265625    Top5 99.929688    LR 0.033055    Time 0.021317    
2018-11-02 20:18:31,093 - Epoch: [164][  150/  391]    Overall Loss 0.164007    Objective Loss 0.164007    Top1 94.197917    Top5 99.901042    LR 0.033055    Time 0.021126    
2018-11-02 20:18:32,135 - Epoch: [164][  200/  391]    Overall Loss 0.164364    Objective Loss 0.164364    Top1 94.187500    Top5 99.906250    LR 0.033055    Time 0.021051    
2018-11-02 20:18:33,175 - Epoch: [164][  250/  391]    Overall Loss 0.167209    Objective Loss 0.167209    Top1 94.050000    Top5 99.918750    LR 0.033055    Time 0.020993    
2018-11-02 20:18:34,218 - Epoch: [164][  300/  391]    Overall Loss 0.168215    Objective Loss 0.168215    Top1 94.020833    Top5 99.911458    LR 0.033055    Time 0.020966    
2018-11-02 20:18:35,340 - Epoch: [164][  350/  391]    Overall Loss 0.170015    Objective Loss 0.170015    Top1 93.997768    Top5 99.901786    LR 0.033055    Time 0.021172    
2018-11-02 20:18:36,260 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42318 | -0.00374 |    0.26383 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16598 | -0.00199 |    0.10536 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17641 | -0.00728 |    0.13331 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20111 | -0.03463 |    0.15361 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20611 |  0.00227 |    0.16154 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19970 | -0.03342 |    0.15361 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18970 | -0.00686 |    0.13755 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22899 | -0.00202 |    0.16805 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19124 | -0.00602 |    0.14626 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29354 | -0.00674 |    0.20100 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15916 | -0.00224 |    0.12061 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13848 | -0.01152 |    0.10925 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16382 | -0.02115 |    0.13092 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00427 |    0.09798 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14979 | -0.01874 |    0.11953 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14527 | -0.00145 |    0.11509 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17165 | -0.01545 |    0.13295 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13283 | -0.01060 |    0.10504 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11258 | -0.00803 |    0.08788 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11970 | -0.01307 |    0.09533 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07404 |  0.00449 |    0.05540 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56212 | -0.00000 |    0.43869 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:18:36,260 - Total sparsity: 0.00

2018-11-02 20:18:36,260 - --- validate (epoch=164)-----------
2018-11-02 20:18:36,260 - 10000 samples (128 per mini-batch)
2018-11-02 20:18:36,985 - Epoch: [164][   50/   78]    Loss 0.357626    Top1 89.421875    Top5 99.625000    
2018-11-02 20:18:37,379 - ==> Top1: 89.110    Top5: 99.680    Loss: 0.361

2018-11-02 20:18:37,380 - ==> Best Top1: 89.110   On Epoch: 164

2018-11-02 20:18:37,380 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:18:37,396 - 

2018-11-02 20:18:37,396 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:18:38,387 - Epoch: [165][   50/  391]    Overall Loss 0.156391    Objective Loss 0.156391    Top1 94.515625    Top5 99.953125    LR 0.031402    Time 0.019791    
2018-11-02 20:18:39,349 - Epoch: [165][  100/  391]    Overall Loss 0.159829    Objective Loss 0.159829    Top1 94.328125    Top5 99.937500    LR 0.031402    Time 0.019506    
2018-11-02 20:18:40,312 - Epoch: [165][  150/  391]    Overall Loss 0.159751    Objective Loss 0.159751    Top1 94.328125    Top5 99.932292    LR 0.031402    Time 0.019410    
2018-11-02 20:18:41,276 - Epoch: [165][  200/  391]    Overall Loss 0.162297    Objective Loss 0.162297    Top1 94.230469    Top5 99.917969    LR 0.031402    Time 0.019375    
2018-11-02 20:18:42,241 - Epoch: [165][  250/  391]    Overall Loss 0.165108    Objective Loss 0.165108    Top1 94.081250    Top5 99.909375    LR 0.031402    Time 0.019355    
2018-11-02 20:18:43,203 - Epoch: [165][  300/  391]    Overall Loss 0.166830    Objective Loss 0.166830    Top1 94.002604    Top5 99.919271    LR 0.031402    Time 0.019327    
2018-11-02 20:18:44,163 - Epoch: [165][  350/  391]    Overall Loss 0.167144    Objective Loss 0.167144    Top1 94.026786    Top5 99.919643    LR 0.031402    Time 0.019308    
2018-11-02 20:18:45,034 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.42076 | -0.00499 |    0.26270 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16507 | -0.00106 |    0.10482 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17540 | -0.00723 |    0.13244 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19986 | -0.03566 |    0.15307 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20496 |  0.00023 |    0.16061 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19865 | -0.03334 |    0.15271 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18853 | -0.00774 |    0.13661 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22764 | -0.00256 |    0.16735 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19017 | -0.00653 |    0.14541 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.29165 | -0.00760 |    0.20071 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15831 | -0.00275 |    0.12024 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13781 | -0.01106 |    0.10862 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16306 | -0.02050 |    0.13040 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12394 | -0.00464 |    0.09723 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14892 | -0.01884 |    0.11895 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14452 | -0.00169 |    0.11446 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17057 | -0.01544 |    0.13194 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13221 | -0.01017 |    0.10455 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11210 | -0.00810 |    0.08758 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11920 | -0.01300 |    0.09497 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07360 |  0.00436 |    0.05511 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56240 | -0.00000 |    0.43875 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:18:45,034 - Total sparsity: 0.00

2018-11-02 20:18:45,034 - --- validate (epoch=165)-----------
2018-11-02 20:18:45,034 - 10000 samples (128 per mini-batch)
2018-11-02 20:18:45,760 - Epoch: [165][   50/   78]    Loss 0.382109    Top1 88.312500    Top5 99.765625    
2018-11-02 20:18:46,153 - ==> Top1: 88.450    Top5: 99.780    Loss: 0.379

2018-11-02 20:18:46,154 - ==> Best Top1: 89.110   On Epoch: 164

2018-11-02 20:18:46,154 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:18:46,161 - 

2018-11-02 20:18:46,162 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:18:47,263 - Epoch: [166][   50/  391]    Overall Loss 0.147407    Objective Loss 0.147407    Top1 95.203125    Top5 99.906250    LR 0.029832    Time 0.021998    
2018-11-02 20:18:48,307 - Epoch: [166][  100/  391]    Overall Loss 0.158392    Objective Loss 0.158392    Top1 94.570312    Top5 99.898438    LR 0.029832    Time 0.021424    
2018-11-02 20:18:49,299 - Epoch: [166][  150/  391]    Overall Loss 0.157451    Objective Loss 0.157451    Top1 94.546875    Top5 99.916667    LR 0.029832    Time 0.020887    
2018-11-02 20:18:50,271 - Epoch: [166][  200/  391]    Overall Loss 0.162538    Objective Loss 0.162538    Top1 94.269531    Top5 99.925781    LR 0.029832    Time 0.020521    
2018-11-02 20:18:51,256 - Epoch: [166][  250/  391]    Overall Loss 0.164038    Objective Loss 0.164038    Top1 94.168750    Top5 99.921875    LR 0.029832    Time 0.020352    
2018-11-02 20:18:52,268 - Epoch: [166][  300/  391]    Overall Loss 0.165158    Objective Loss 0.165158    Top1 94.132812    Top5 99.916667    LR 0.029832    Time 0.020330    
2018-11-02 20:18:53,234 - Epoch: [166][  350/  391]    Overall Loss 0.164765    Objective Loss 0.164765    Top1 94.171875    Top5 99.924107    LR 0.029832    Time 0.020181    
2018-11-02 20:18:54,108 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41822 | -0.00731 |    0.26101 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16412 | -0.00133 |    0.10398 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17444 | -0.00727 |    0.13138 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19899 | -0.03449 |    0.15214 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20383 |  0.00222 |    0.15984 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19745 | -0.03410 |    0.15215 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18747 | -0.00675 |    0.13558 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22642 | -0.00097 |    0.16626 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18914 | -0.00678 |    0.14442 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28980 | -0.00842 |    0.19868 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15751 | -0.00315 |    0.11945 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13718 | -0.01031 |    0.10809 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16230 | -0.02018 |    0.12975 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12335 | -0.00475 |    0.09684 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14810 | -0.01850 |    0.11827 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14379 | -0.00177 |    0.11393 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16951 | -0.01544 |    0.13129 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13158 | -0.01022 |    0.10412 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11162 | -0.00808 |    0.08727 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11867 | -0.01320 |    0.09454 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07317 |  0.00440 |    0.05479 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56292 | -0.00000 |    0.43911 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:18:54,109 - Total sparsity: 0.00

2018-11-02 20:18:54,109 - --- validate (epoch=166)-----------
2018-11-02 20:18:54,109 - 10000 samples (128 per mini-batch)
2018-11-02 20:18:54,831 - Epoch: [166][   50/   78]    Loss 0.357953    Top1 89.125000    Top5 99.671875    
2018-11-02 20:18:55,220 - ==> Top1: 89.020    Top5: 99.710    Loss: 0.356

2018-11-02 20:18:55,221 - ==> Best Top1: 89.110   On Epoch: 164

2018-11-02 20:18:55,221 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:18:55,228 - 

2018-11-02 20:18:55,228 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:18:56,245 - Epoch: [167][   50/  391]    Overall Loss 0.147291    Objective Loss 0.147291    Top1 94.625000    Top5 99.953125    LR 0.028340    Time 0.020306    
2018-11-02 20:18:57,207 - Epoch: [167][  100/  391]    Overall Loss 0.148927    Objective Loss 0.148927    Top1 94.718750    Top5 99.929688    LR 0.028340    Time 0.019754    
2018-11-02 20:18:58,169 - Epoch: [167][  150/  391]    Overall Loss 0.149925    Objective Loss 0.149925    Top1 94.671875    Top5 99.921875    LR 0.028340    Time 0.019580    
2018-11-02 20:18:59,130 - Epoch: [167][  200/  391]    Overall Loss 0.152081    Objective Loss 0.152081    Top1 94.566406    Top5 99.921875    LR 0.028340    Time 0.019486    
2018-11-02 20:19:00,094 - Epoch: [167][  250/  391]    Overall Loss 0.156767    Objective Loss 0.156767    Top1 94.387500    Top5 99.928125    LR 0.028340    Time 0.019437    
2018-11-02 20:19:01,056 - Epoch: [167][  300/  391]    Overall Loss 0.158792    Objective Loss 0.158792    Top1 94.346354    Top5 99.932292    LR 0.028340    Time 0.019402    
2018-11-02 20:19:02,018 - Epoch: [167][  350/  391]    Overall Loss 0.158190    Objective Loss 0.158190    Top1 94.361607    Top5 99.933036    LR 0.028340    Time 0.019376    
2018-11-02 20:19:02,902 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41608 | -0.00392 |    0.25932 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16332 | -0.00102 |    0.10347 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17360 | -0.00657 |    0.13083 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19827 | -0.03321 |    0.15110 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20278 |  0.00183 |    0.15929 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19682 | -0.03176 |    0.15154 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18647 | -0.00594 |    0.13506 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22522 | -0.00115 |    0.16565 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18817 | -0.00709 |    0.14371 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28803 | -0.00723 |    0.19671 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15674 | -0.00354 |    0.11880 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13654 | -0.01023 |    0.10752 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16143 | -0.02048 |    0.12905 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12277 | -0.00476 |    0.09613 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14734 | -0.01810 |    0.11761 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14307 | -0.00186 |    0.11339 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16847 | -0.01552 |    0.13052 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13096 | -0.01018 |    0.10359 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11114 | -0.00804 |    0.08689 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11812 | -0.01335 |    0.09421 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07274 |  0.00443 |    0.05448 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56328 | -0.00000 |    0.43959 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:19:02,902 - Total sparsity: 0.00

2018-11-02 20:19:02,902 - --- validate (epoch=167)-----------
2018-11-02 20:19:02,903 - 10000 samples (128 per mini-batch)
2018-11-02 20:19:03,623 - Epoch: [167][   50/   78]    Loss 0.366741    Top1 89.203125    Top5 99.671875    
2018-11-02 20:19:04,012 - ==> Top1: 89.100    Top5: 99.660    Loss: 0.364

2018-11-02 20:19:04,013 - ==> Best Top1: 89.110   On Epoch: 164

2018-11-02 20:19:04,013 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:19:04,024 - 

2018-11-02 20:19:04,025 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:19:05,045 - Epoch: [168][   50/  391]    Overall Loss 0.150858    Objective Loss 0.150858    Top1 94.796875    Top5 99.921875    LR 0.026923    Time 0.020358    
2018-11-02 20:19:06,065 - Epoch: [168][  100/  391]    Overall Loss 0.150703    Objective Loss 0.150703    Top1 94.828125    Top5 99.914062    LR 0.026923    Time 0.020377    
2018-11-02 20:19:07,027 - Epoch: [168][  150/  391]    Overall Loss 0.150094    Objective Loss 0.150094    Top1 94.781250    Top5 99.927083    LR 0.026923    Time 0.019985    
2018-11-02 20:19:07,987 - Epoch: [168][  200/  391]    Overall Loss 0.151315    Objective Loss 0.151315    Top1 94.718750    Top5 99.925781    LR 0.026923    Time 0.019782    
2018-11-02 20:19:08,947 - Epoch: [168][  250/  391]    Overall Loss 0.153450    Objective Loss 0.153450    Top1 94.590625    Top5 99.925000    LR 0.026923    Time 0.019662    
2018-11-02 20:19:09,908 - Epoch: [168][  300/  391]    Overall Loss 0.155430    Objective Loss 0.155430    Top1 94.552083    Top5 99.927083    LR 0.026923    Time 0.019583    
2018-11-02 20:19:10,878 - Epoch: [168][  350/  391]    Overall Loss 0.155362    Objective Loss 0.155362    Top1 94.560268    Top5 99.930804    LR 0.026923    Time 0.019552    
2018-11-02 20:19:11,745 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41352 | -0.00528 |    0.25788 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16247 | -0.00156 |    0.10297 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17273 | -0.00676 |    0.13070 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19714 | -0.03356 |    0.14974 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20169 |  0.00241 |    0.15867 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19581 | -0.03185 |    0.15084 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18544 | -0.00556 |    0.13394 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22402 | -0.00143 |    0.16434 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18723 | -0.00691 |    0.14295 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28632 | -0.00719 |    0.19474 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15598 | -0.00293 |    0.11832 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13588 | -0.01033 |    0.10711 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16066 | -0.02036 |    0.12826 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12222 | -0.00446 |    0.09566 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14661 | -0.01765 |    0.11700 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14240 | -0.00194 |    0.11293 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16747 | -0.01554 |    0.12995 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13036 | -0.01011 |    0.10308 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11071 | -0.00769 |    0.08659 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11764 | -0.01313 |    0.09382 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07233 |  0.00447 |    0.05424 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56334 | -0.00000 |    0.43978 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:19:11,745 - Total sparsity: 0.00

2018-11-02 20:19:11,746 - --- validate (epoch=168)-----------
2018-11-02 20:19:11,746 - 10000 samples (128 per mini-batch)
2018-11-02 20:19:12,469 - Epoch: [168][   50/   78]    Loss 0.370676    Top1 89.281250    Top5 99.578125    
2018-11-02 20:19:12,862 - ==> Top1: 89.040    Top5: 99.610    Loss: 0.375

2018-11-02 20:19:12,863 - ==> Best Top1: 89.110   On Epoch: 164

2018-11-02 20:19:12,863 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:19:12,870 - 

2018-11-02 20:19:12,871 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:19:13,889 - Epoch: [169][   50/  391]    Overall Loss 0.148092    Objective Loss 0.148092    Top1 94.906250    Top5 99.921875    LR 0.025577    Time 0.020334    
2018-11-02 20:19:14,849 - Epoch: [169][  100/  391]    Overall Loss 0.148649    Objective Loss 0.148649    Top1 94.898438    Top5 99.921875    LR 0.025577    Time 0.019750    
2018-11-02 20:19:15,850 - Epoch: [169][  150/  391]    Overall Loss 0.151195    Objective Loss 0.151195    Top1 94.687500    Top5 99.927083    LR 0.025577    Time 0.019834    
2018-11-02 20:19:16,810 - Epoch: [169][  200/  391]    Overall Loss 0.153014    Objective Loss 0.153014    Top1 94.589844    Top5 99.937500    LR 0.025577    Time 0.019668    
2018-11-02 20:19:17,771 - Epoch: [169][  250/  391]    Overall Loss 0.151254    Objective Loss 0.151254    Top1 94.618750    Top5 99.937500    LR 0.025577    Time 0.019561    
2018-11-02 20:19:18,734 - Epoch: [169][  300/  391]    Overall Loss 0.150576    Objective Loss 0.150576    Top1 94.645833    Top5 99.934896    LR 0.025577    Time 0.019507    
2018-11-02 20:19:19,695 - Epoch: [169][  350/  391]    Overall Loss 0.151067    Objective Loss 0.151067    Top1 94.593750    Top5 99.939732    LR 0.025577    Time 0.019463    
2018-11-02 20:19:20,564 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.41132 | -0.00347 |    0.25620 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16162 | -0.00062 |    0.10233 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17183 | -0.00681 |    0.12989 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19599 | -0.03420 |    0.14926 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20064 |  0.00238 |    0.15724 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19489 | -0.03163 |    0.15007 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18444 | -0.00602 |    0.13347 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22286 | -0.00161 |    0.16382 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18630 | -0.00647 |    0.14224 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28471 | -0.00653 |    0.19443 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15524 | -0.00260 |    0.11771 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13523 | -0.01038 |    0.10641 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15998 | -0.01970 |    0.12744 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12168 | -0.00402 |    0.09536 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14580 | -0.01799 |    0.11655 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14174 | -0.00191 |    0.11236 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16654 | -0.01526 |    0.12927 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12978 | -0.00993 |    0.10265 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11025 | -0.00787 |    0.08632 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11717 | -0.01305 |    0.09340 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07193 |  0.00445 |    0.05395 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56378 | -0.00000 |    0.44013 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:19:20,564 - Total sparsity: 0.00

2018-11-02 20:19:20,565 - --- validate (epoch=169)-----------
2018-11-02 20:19:20,565 - 10000 samples (128 per mini-batch)
2018-11-02 20:19:21,289 - Epoch: [169][   50/   78]    Loss 0.364811    Top1 89.265625    Top5 99.671875    
2018-11-02 20:19:21,683 - ==> Top1: 89.040    Top5: 99.700    Loss: 0.358

2018-11-02 20:19:21,684 - ==> Best Top1: 89.110   On Epoch: 164

2018-11-02 20:19:21,684 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:19:21,695 - 

2018-11-02 20:19:21,695 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:19:22,713 - Epoch: [170][   50/  391]    Overall Loss 0.144845    Objective Loss 0.144845    Top1 94.687500    Top5 99.921875    LR 0.024298    Time 0.020316    
2018-11-02 20:19:23,674 - Epoch: [170][  100/  391]    Overall Loss 0.149917    Objective Loss 0.149917    Top1 94.609375    Top5 99.937500    LR 0.024298    Time 0.019759    
2018-11-02 20:19:24,636 - Epoch: [170][  150/  391]    Overall Loss 0.146303    Objective Loss 0.146303    Top1 94.786458    Top5 99.921875    LR 0.024298    Time 0.019579    
2018-11-02 20:19:25,599 - Epoch: [170][  200/  391]    Overall Loss 0.148145    Objective Loss 0.148145    Top1 94.675781    Top5 99.917969    LR 0.024298    Time 0.019494    
2018-11-02 20:19:26,562 - Epoch: [170][  250/  391]    Overall Loss 0.148356    Objective Loss 0.148356    Top1 94.693750    Top5 99.925000    LR 0.024298    Time 0.019440    
2018-11-02 20:19:27,525 - Epoch: [170][  300/  391]    Overall Loss 0.148456    Objective Loss 0.148456    Top1 94.682292    Top5 99.924479    LR 0.024298    Time 0.019407    
2018-11-02 20:19:28,487 - Epoch: [170][  350/  391]    Overall Loss 0.148782    Objective Loss 0.148782    Top1 94.640625    Top5 99.933036    LR 0.024298    Time 0.019380    
2018-11-02 20:19:29,360 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40917 | -0.00399 |    0.25505 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16078 | -0.00032 |    0.10188 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17095 | -0.00792 |    0.12941 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19502 | -0.03410 |    0.14864 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19965 |  0.00168 |    0.15653 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19382 | -0.03272 |    0.14919 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18358 | -0.00585 |    0.13253 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22179 | -0.00172 |    0.16353 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18540 | -0.00709 |    0.14168 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28316 | -0.00762 |    0.19313 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15458 | -0.00278 |    0.11734 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13461 | -0.01078 |    0.10597 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15929 | -0.01940 |    0.12685 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12115 | -0.00383 |    0.09498 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14510 | -0.01777 |    0.11602 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14111 | -0.00193 |    0.11190 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16568 | -0.01487 |    0.12853 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12922 | -0.00981 |    0.10221 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10980 | -0.00783 |    0.08596 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11668 | -0.01310 |    0.09296 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07154 |  0.00443 |    0.05370 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56416 | -0.00000 |    0.44035 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:19:29,360 - Total sparsity: 0.00

2018-11-02 20:19:29,360 - --- validate (epoch=170)-----------
2018-11-02 20:19:29,360 - 10000 samples (128 per mini-batch)
2018-11-02 20:19:30,076 - Epoch: [170][   50/   78]    Loss 0.352468    Top1 89.562500    Top5 99.718750    
2018-11-02 20:19:30,461 - ==> Top1: 89.330    Top5: 99.730    Loss: 0.356

2018-11-02 20:19:30,462 - ==> Best Top1: 89.330   On Epoch: 170

2018-11-02 20:19:30,462 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:19:30,472 - 

2018-11-02 20:19:30,472 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:19:31,492 - Epoch: [171][   50/  391]    Overall Loss 0.140149    Objective Loss 0.140149    Top1 95.250000    Top5 99.890625    LR 0.023083    Time 0.020375    
2018-11-02 20:19:32,454 - Epoch: [171][  100/  391]    Overall Loss 0.133755    Objective Loss 0.133755    Top1 95.351562    Top5 99.929688    LR 0.023083    Time 0.019794    
2018-11-02 20:19:33,415 - Epoch: [171][  150/  391]    Overall Loss 0.134414    Objective Loss 0.134414    Top1 95.260417    Top5 99.921875    LR 0.023083    Time 0.019594    
2018-11-02 20:19:34,378 - Epoch: [171][  200/  391]    Overall Loss 0.137441    Objective Loss 0.137441    Top1 95.183594    Top5 99.941406    LR 0.023083    Time 0.019507    
2018-11-02 20:19:35,341 - Epoch: [171][  250/  391]    Overall Loss 0.139285    Objective Loss 0.139285    Top1 95.118750    Top5 99.940625    LR 0.023083    Time 0.019454    
2018-11-02 20:19:36,301 - Epoch: [171][  300/  391]    Overall Loss 0.141029    Objective Loss 0.141029    Top1 95.065104    Top5 99.940104    LR 0.023083    Time 0.019406    
2018-11-02 20:19:37,262 - Epoch: [171][  350/  391]    Overall Loss 0.142158    Objective Loss 0.142158    Top1 94.991071    Top5 99.935268    LR 0.023083    Time 0.019375    
2018-11-02 20:19:38,127 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40706 | -0.00262 |    0.25411 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16006 | -0.00050 |    0.10127 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17019 | -0.00767 |    0.12845 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19385 | -0.03538 |    0.14800 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19867 |  0.00188 |    0.15567 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19296 | -0.03248 |    0.14874 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18272 | -0.00483 |    0.13194 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.22071 | -0.00111 |    0.16263 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18456 | -0.00623 |    0.14103 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28167 | -0.00572 |    0.19183 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15390 | -0.00290 |    0.11689 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13402 | -0.01065 |    0.10551 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15862 | -0.01886 |    0.12623 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12062 | -0.00398 |    0.09453 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14440 | -0.01759 |    0.11544 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14047 | -0.00208 |    0.11142 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16478 | -0.01514 |    0.12759 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12865 | -0.01000 |    0.10177 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10938 | -0.00771 |    0.08568 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11622 | -0.01302 |    0.09266 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07117 |  0.00439 |    0.05343 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56454 | -0.00000 |    0.44078 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:19:38,127 - Total sparsity: 0.00

2018-11-02 20:19:38,127 - --- validate (epoch=171)-----------
2018-11-02 20:19:38,127 - 10000 samples (128 per mini-batch)
2018-11-02 20:19:38,851 - Epoch: [171][   50/   78]    Loss 0.375471    Top1 89.015625    Top5 99.453125    
2018-11-02 20:19:39,247 - ==> Top1: 88.710    Top5: 99.550    Loss: 0.380

2018-11-02 20:19:39,248 - ==> Best Top1: 89.330   On Epoch: 170

2018-11-02 20:19:39,248 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:19:39,259 - 

2018-11-02 20:19:39,260 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:19:40,281 - Epoch: [172][   50/  391]    Overall Loss 0.129532    Objective Loss 0.129532    Top1 95.406250    Top5 99.921875    LR 0.021929    Time 0.020395    
2018-11-02 20:19:41,243 - Epoch: [172][  100/  391]    Overall Loss 0.132820    Objective Loss 0.132820    Top1 95.250000    Top5 99.937500    LR 0.021929    Time 0.019808    
2018-11-02 20:19:42,206 - Epoch: [172][  150/  391]    Overall Loss 0.131606    Objective Loss 0.131606    Top1 95.354167    Top5 99.958333    LR 0.021929    Time 0.019612    
2018-11-02 20:19:43,167 - Epoch: [172][  200/  391]    Overall Loss 0.136429    Objective Loss 0.136429    Top1 95.218750    Top5 99.953125    LR 0.021929    Time 0.019512    
2018-11-02 20:19:44,130 - Epoch: [172][  250/  391]    Overall Loss 0.138167    Objective Loss 0.138167    Top1 95.112500    Top5 99.950000    LR 0.021929    Time 0.019454    
2018-11-02 20:19:45,091 - Epoch: [172][  300/  391]    Overall Loss 0.139046    Objective Loss 0.139046    Top1 95.104167    Top5 99.945312    LR 0.021929    Time 0.019411    
2018-11-02 20:19:46,051 - Epoch: [172][  350/  391]    Overall Loss 0.138907    Objective Loss 0.138907    Top1 95.111607    Top5 99.953125    LR 0.021929    Time 0.019380    
2018-11-02 20:19:46,923 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40498 | -0.00373 |    0.25278 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15930 | -0.00127 |    0.10051 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16940 | -0.00703 |    0.12791 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19308 | -0.03467 |    0.14713 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19776 |  0.00059 |    0.15476 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19211 | -0.03194 |    0.14812 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18183 | -0.00624 |    0.13151 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21968 | -0.00083 |    0.16160 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18371 | -0.00640 |    0.14015 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.28020 | -0.00622 |    0.19151 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15324 | -0.00284 |    0.11662 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13348 | -0.01027 |    0.10507 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15789 | -0.01905 |    0.12575 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12011 | -0.00424 |    0.09415 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14368 | -0.01774 |    0.11472 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13986 | -0.00205 |    0.11092 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16396 | -0.01473 |    0.12704 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12811 | -0.00996 |    0.10127 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10897 | -0.00760 |    0.08542 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11575 | -0.01302 |    0.09226 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07080 |  0.00428 |    0.05317 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56519 | -0.00000 |    0.44128 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:19:46,923 - Total sparsity: 0.00

2018-11-02 20:19:46,923 - --- validate (epoch=172)-----------
2018-11-02 20:19:46,923 - 10000 samples (128 per mini-batch)
2018-11-02 20:19:47,644 - Epoch: [172][   50/   78]    Loss 0.385629    Top1 88.593750    Top5 99.578125    
2018-11-02 20:19:48,035 - ==> Top1: 88.640    Top5: 99.630    Loss: 0.376

2018-11-02 20:19:48,036 - ==> Best Top1: 89.330   On Epoch: 170

2018-11-02 20:19:48,036 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:19:48,044 - 

2018-11-02 20:19:48,044 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:19:49,067 - Epoch: [173][   50/  391]    Overall Loss 0.119300    Objective Loss 0.119300    Top1 95.968750    Top5 100.000000    LR 0.020833    Time 0.020430    
2018-11-02 20:19:50,029 - Epoch: [173][  100/  391]    Overall Loss 0.126170    Objective Loss 0.126170    Top1 95.867188    Top5 99.984375    LR 0.020833    Time 0.019818    
2018-11-02 20:19:50,991 - Epoch: [173][  150/  391]    Overall Loss 0.131603    Objective Loss 0.131603    Top1 95.604167    Top5 99.973958    LR 0.020833    Time 0.019620    
2018-11-02 20:19:51,951 - Epoch: [173][  200/  391]    Overall Loss 0.135226    Objective Loss 0.135226    Top1 95.406250    Top5 99.964844    LR 0.020833    Time 0.019506    
2018-11-02 20:19:52,915 - Epoch: [173][  250/  391]    Overall Loss 0.136512    Objective Loss 0.136512    Top1 95.340625    Top5 99.962500    LR 0.020833    Time 0.019444    
2018-11-02 20:19:53,878 - Epoch: [173][  300/  391]    Overall Loss 0.136606    Objective Loss 0.136606    Top1 95.354167    Top5 99.953125    LR 0.020833    Time 0.019410    
2018-11-02 20:19:54,842 - Epoch: [173][  350/  391]    Overall Loss 0.138585    Objective Loss 0.138585    Top1 95.303571    Top5 99.946429    LR 0.020833    Time 0.019387    
2018-11-02 20:19:55,710 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40306 | -0.00080 |    0.25096 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15856 | -0.00179 |    0.10047 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16869 | -0.00569 |    0.12722 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19207 | -0.03553 |    0.14643 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19686 |  0.00209 |    0.15425 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19109 | -0.03292 |    0.14728 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18102 | -0.00566 |    0.13079 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21870 | -0.00112 |    0.16080 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18290 | -0.00658 |    0.13975 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27878 | -0.00559 |    0.19032 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15263 | -0.00258 |    0.11603 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13294 | -0.00998 |    0.10472 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15723 | -0.01885 |    0.12512 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11960 | -0.00456 |    0.09383 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14304 | -0.01760 |    0.11423 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13929 | -0.00186 |    0.11042 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16318 | -0.01436 |    0.12641 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12758 | -0.01014 |    0.10095 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10859 | -0.00755 |    0.08510 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11530 | -0.01317 |    0.09194 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07046 |  0.00426 |    0.05296 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56531 | -0.00000 |    0.44131 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:19:55,711 - Total sparsity: 0.00

2018-11-02 20:19:55,711 - --- validate (epoch=173)-----------
2018-11-02 20:19:55,711 - 10000 samples (128 per mini-batch)
2018-11-02 20:19:56,431 - Epoch: [173][   50/   78]    Loss 0.363825    Top1 89.546875    Top5 99.656250    
2018-11-02 20:19:56,825 - ==> Top1: 89.360    Top5: 99.690    Loss: 0.363

2018-11-02 20:19:56,826 - ==> Best Top1: 89.360   On Epoch: 173

2018-11-02 20:19:56,826 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:19:56,839 - 

2018-11-02 20:19:56,839 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:19:57,856 - Epoch: [174][   50/  391]    Overall Loss 0.124403    Objective Loss 0.124403    Top1 95.625000    Top5 99.968750    LR 0.019791    Time 0.020302    
2018-11-02 20:19:58,901 - Epoch: [174][  100/  391]    Overall Loss 0.126863    Objective Loss 0.126863    Top1 95.609375    Top5 99.953125    LR 0.019791    Time 0.020594    
2018-11-02 20:19:59,945 - Epoch: [174][  150/  391]    Overall Loss 0.129875    Objective Loss 0.129875    Top1 95.520833    Top5 99.947917    LR 0.019791    Time 0.020680    
2018-11-02 20:20:00,989 - Epoch: [174][  200/  391]    Overall Loss 0.130049    Objective Loss 0.130049    Top1 95.500000    Top5 99.953125    LR 0.019791    Time 0.020724    
2018-11-02 20:20:02,036 - Epoch: [174][  250/  391]    Overall Loss 0.132525    Objective Loss 0.132525    Top1 95.378125    Top5 99.946875    LR 0.019791    Time 0.020764    
2018-11-02 20:20:03,080 - Epoch: [174][  300/  391]    Overall Loss 0.134788    Objective Loss 0.134788    Top1 95.257812    Top5 99.950521    LR 0.019791    Time 0.020779    
2018-11-02 20:20:04,120 - Epoch: [174][  350/  391]    Overall Loss 0.136616    Objective Loss 0.136616    Top1 95.227679    Top5 99.953125    LR 0.019791    Time 0.020778    
2018-11-02 20:20:04,990 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.40118 | -0.00260 |    0.24927 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15785 | -0.00168 |    0.10003 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16798 | -0.00541 |    0.12697 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19123 | -0.03544 |    0.14595 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19599 |  0.00146 |    0.15321 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19049 | -0.03169 |    0.14666 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18020 | -0.00663 |    0.13034 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21775 | -0.00131 |    0.16017 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18212 | -0.00628 |    0.13912 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27742 | -0.00527 |    0.18935 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15203 | -0.00275 |    0.11541 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13242 | -0.00968 |    0.10438 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15661 | -0.01850 |    0.12458 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11912 | -0.00448 |    0.09329 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14249 | -0.01683 |    0.11376 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13872 | -0.00184 |    0.10992 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16240 | -0.01405 |    0.12591 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12708 | -0.00990 |    0.10050 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10819 | -0.00762 |    0.08475 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11489 | -0.01296 |    0.09162 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07012 |  0.00419 |    0.05275 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56511 | -0.00001 |    0.44147 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:20:04,990 - Total sparsity: 0.00

2018-11-02 20:20:04,990 - --- validate (epoch=174)-----------
2018-11-02 20:20:04,991 - 10000 samples (128 per mini-batch)
2018-11-02 20:20:05,710 - Epoch: [174][   50/   78]    Loss 0.356883    Top1 89.750000    Top5 99.609375    
2018-11-02 20:20:06,102 - ==> Top1: 89.580    Top5: 99.650    Loss: 0.353

2018-11-02 20:20:06,102 - ==> Best Top1: 89.580   On Epoch: 174

2018-11-02 20:20:06,102 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:20:06,117 - 

2018-11-02 20:20:06,117 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:20:07,107 - Epoch: [175][   50/  391]    Overall Loss 0.121611    Objective Loss 0.121611    Top1 95.578125    Top5 99.968750    LR 0.018802    Time 0.019770    
2018-11-02 20:20:08,068 - Epoch: [175][  100/  391]    Overall Loss 0.128011    Objective Loss 0.128011    Top1 95.421875    Top5 99.968750    LR 0.018802    Time 0.019477    
2018-11-02 20:20:09,031 - Epoch: [175][  150/  391]    Overall Loss 0.127774    Objective Loss 0.127774    Top1 95.463542    Top5 99.963542    LR 0.018802    Time 0.019397    
2018-11-02 20:20:09,989 - Epoch: [175][  200/  391]    Overall Loss 0.127657    Objective Loss 0.127657    Top1 95.457031    Top5 99.968750    LR 0.018802    Time 0.019331    
2018-11-02 20:20:10,954 - Epoch: [175][  250/  391]    Overall Loss 0.128199    Objective Loss 0.128199    Top1 95.475000    Top5 99.968750    LR 0.018802    Time 0.019322    
2018-11-02 20:20:11,916 - Epoch: [175][  300/  391]    Overall Loss 0.127485    Objective Loss 0.127485    Top1 95.476562    Top5 99.971354    LR 0.018802    Time 0.019305    
2018-11-02 20:20:12,879 - Epoch: [175][  350/  391]    Overall Loss 0.128631    Objective Loss 0.128631    Top1 95.412946    Top5 99.970982    LR 0.018802    Time 0.019295    
2018-11-02 20:20:13,746 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39929 | -0.00315 |    0.24846 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15711 | -0.00146 |    0.09939 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16721 | -0.00620 |    0.12645 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19047 | -0.03479 |    0.14516 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19509 |  0.00171 |    0.15227 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18983 | -0.03055 |    0.14601 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17940 | -0.00653 |    0.12950 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21679 | -0.00138 |    0.15921 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18133 | -0.00630 |    0.13850 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27602 | -0.00585 |    0.18847 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15139 | -0.00321 |    0.11496 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13187 | -0.00964 |    0.10387 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15597 | -0.01845 |    0.12410 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11865 | -0.00378 |    0.09291 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14181 | -0.01699 |    0.11314 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13813 | -0.00206 |    0.10952 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16162 | -0.01383 |    0.12551 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12657 | -0.00983 |    0.10007 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10779 | -0.00761 |    0.08449 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11442 | -0.01309 |    0.09129 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06978 |  0.00420 |    0.05248 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56615 | -0.00001 |    0.44223 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:20:13,747 - Total sparsity: 0.00

2018-11-02 20:20:13,747 - --- validate (epoch=175)-----------
2018-11-02 20:20:13,747 - 10000 samples (128 per mini-batch)
2018-11-02 20:20:14,469 - Epoch: [175][   50/   78]    Loss 0.353536    Top1 89.593750    Top5 99.703125    
2018-11-02 20:20:14,858 - ==> Top1: 89.660    Top5: 99.660    Loss: 0.352

2018-11-02 20:20:14,859 - ==> Best Top1: 89.660   On Epoch: 175

2018-11-02 20:20:14,859 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:20:14,868 - 

2018-11-02 20:20:14,868 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:20:15,887 - Epoch: [176][   50/  391]    Overall Loss 0.123230    Objective Loss 0.123230    Top1 95.718750    Top5 100.000000    LR 0.017862    Time 0.020355    
2018-11-02 20:20:16,848 - Epoch: [176][  100/  391]    Overall Loss 0.131346    Objective Loss 0.131346    Top1 95.281250    Top5 99.968750    LR 0.017862    Time 0.019774    
2018-11-02 20:20:17,809 - Epoch: [176][  150/  391]    Overall Loss 0.131046    Objective Loss 0.131046    Top1 95.338542    Top5 99.958333    LR 0.017862    Time 0.019583    
2018-11-02 20:20:18,772 - Epoch: [176][  200/  391]    Overall Loss 0.131037    Objective Loss 0.131037    Top1 95.324219    Top5 99.957031    LR 0.017862    Time 0.019496    
2018-11-02 20:20:19,736 - Epoch: [176][  250/  391]    Overall Loss 0.132092    Objective Loss 0.132092    Top1 95.271875    Top5 99.953125    LR 0.017862    Time 0.019433    
2018-11-02 20:20:20,702 - Epoch: [176][  300/  391]    Overall Loss 0.131839    Objective Loss 0.131839    Top1 95.273438    Top5 99.950521    LR 0.017862    Time 0.019410    
2018-11-02 20:20:21,667 - Epoch: [176][  350/  391]    Overall Loss 0.132975    Objective Loss 0.132975    Top1 95.247768    Top5 99.948661    LR 0.017862    Time 0.019391    
2018-11-02 20:20:22,534 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39766 | -0.00287 |    0.24764 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15645 | -0.00170 |    0.09918 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16657 | -0.00630 |    0.12610 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18974 | -0.03452 |    0.14487 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19427 |  0.00205 |    0.15164 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18900 | -0.03105 |    0.14559 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17872 | -0.00565 |    0.12890 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21591 | -0.00136 |    0.15862 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18060 | -0.00663 |    0.13808 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27474 | -0.00629 |    0.18736 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15083 | -0.00285 |    0.11469 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13135 | -0.01006 |    0.10345 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.01812 |    0.12376 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11822 | -0.00378 |    0.09274 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14124 | -0.01690 |    0.11276 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13761 | -0.00210 |    0.10911 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16087 | -0.01396 |    0.12514 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12612 | -0.00956 |    0.09968 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10743 | -0.00749 |    0.08414 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11404 | -0.01295 |    0.09100 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06948 |  0.00418 |    0.05225 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56628 | -0.00001 |    0.44246 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:20:22,535 - Total sparsity: 0.00

2018-11-02 20:20:22,535 - --- validate (epoch=176)-----------
2018-11-02 20:20:22,535 - 10000 samples (128 per mini-batch)
2018-11-02 20:20:23,259 - Epoch: [176][   50/   78]    Loss 0.355503    Top1 89.750000    Top5 99.718750    
2018-11-02 20:20:23,651 - ==> Top1: 89.690    Top5: 99.710    Loss: 0.356

2018-11-02 20:20:23,652 - ==> Best Top1: 89.690   On Epoch: 176

2018-11-02 20:20:23,652 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:20:23,667 - 

2018-11-02 20:20:23,667 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:20:24,685 - Epoch: [177][   50/  391]    Overall Loss 0.117328    Objective Loss 0.117328    Top1 95.937500    Top5 99.953125    LR 0.016968    Time 0.020320    
2018-11-02 20:20:25,647 - Epoch: [177][  100/  391]    Overall Loss 0.114729    Objective Loss 0.114729    Top1 95.984375    Top5 99.968750    LR 0.016968    Time 0.019767    
2018-11-02 20:20:26,609 - Epoch: [177][  150/  391]    Overall Loss 0.119352    Objective Loss 0.119352    Top1 95.786458    Top5 99.968750    LR 0.016968    Time 0.019584    
2018-11-02 20:20:27,571 - Epoch: [177][  200/  391]    Overall Loss 0.119511    Objective Loss 0.119511    Top1 95.746094    Top5 99.968750    LR 0.016968    Time 0.019494    
2018-11-02 20:20:28,533 - Epoch: [177][  250/  391]    Overall Loss 0.122019    Objective Loss 0.122019    Top1 95.662500    Top5 99.971875    LR 0.016968    Time 0.019436    
2018-11-02 20:20:29,495 - Epoch: [177][  300/  391]    Overall Loss 0.122140    Objective Loss 0.122140    Top1 95.674479    Top5 99.968750    LR 0.016968    Time 0.019401    
2018-11-02 20:20:30,458 - Epoch: [177][  350/  391]    Overall Loss 0.124655    Objective Loss 0.124655    Top1 95.589286    Top5 99.962054    LR 0.016968    Time 0.019377    
2018-11-02 20:20:31,322 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39599 | -0.00367 |    0.24634 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15581 | -0.00202 |    0.09862 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16596 | -0.00583 |    0.12558 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18893 | -0.03473 |    0.14423 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19347 |  0.00273 |    0.15147 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18836 | -0.03044 |    0.14507 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17800 | -0.00663 |    0.12827 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21504 | -0.00131 |    0.15813 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17987 | -0.00705 |    0.13748 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27352 | -0.00585 |    0.18638 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15026 | -0.00318 |    0.11435 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13082 | -0.01050 |    0.10307 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15486 | -0.01800 |    0.12332 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11778 | -0.00358 |    0.09243 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14064 | -0.01701 |    0.11224 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13709 | -0.00205 |    0.10873 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16016 | -0.01385 |    0.12440 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12567 | -0.00937 |    0.09935 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10707 | -0.00749 |    0.08393 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11362 | -0.01309 |    0.09072 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06916 |  0.00426 |    0.05201 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56672 | -0.00001 |    0.44286 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:20:31,322 - Total sparsity: 0.00

2018-11-02 20:20:31,322 - --- validate (epoch=177)-----------
2018-11-02 20:20:31,322 - 10000 samples (128 per mini-batch)
2018-11-02 20:20:32,045 - Epoch: [177][   50/   78]    Loss 0.344576    Top1 89.812500    Top5 99.765625    
2018-11-02 20:20:32,441 - ==> Top1: 89.850    Top5: 99.710    Loss: 0.345

2018-11-02 20:20:32,442 - ==> Best Top1: 89.850   On Epoch: 177

2018-11-02 20:20:32,442 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:20:32,451 - 

2018-11-02 20:20:32,451 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:20:33,469 - Epoch: [178][   50/  391]    Overall Loss 0.116289    Objective Loss 0.116289    Top1 95.953125    Top5 99.984375    LR 0.016120    Time 0.020331    
2018-11-02 20:20:34,452 - Epoch: [178][  100/  391]    Overall Loss 0.118179    Objective Loss 0.118179    Top1 95.953125    Top5 99.976562    LR 0.016120    Time 0.019984    
2018-11-02 20:20:35,415 - Epoch: [178][  150/  391]    Overall Loss 0.117496    Objective Loss 0.117496    Top1 95.916667    Top5 99.968750    LR 0.016120    Time 0.019730    
2018-11-02 20:20:36,375 - Epoch: [178][  200/  391]    Overall Loss 0.118803    Objective Loss 0.118803    Top1 95.820312    Top5 99.972656    LR 0.016120    Time 0.019595    
2018-11-02 20:20:37,342 - Epoch: [178][  250/  391]    Overall Loss 0.118419    Objective Loss 0.118419    Top1 95.796875    Top5 99.978125    LR 0.016120    Time 0.019537    
2018-11-02 20:20:38,306 - Epoch: [178][  300/  391]    Overall Loss 0.119143    Objective Loss 0.119143    Top1 95.781250    Top5 99.971354    LR 0.016120    Time 0.019490    
2018-11-02 20:20:39,268 - Epoch: [178][  350/  391]    Overall Loss 0.121282    Objective Loss 0.121282    Top1 95.671875    Top5 99.970982    LR 0.016120    Time 0.019453    
2018-11-02 20:20:40,139 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39447 | -0.00108 |    0.24536 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15517 | -0.00250 |    0.09832 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16527 | -0.00724 |    0.12516 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18827 | -0.03424 |    0.14377 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19268 |  0.00314 |    0.15061 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18775 | -0.02963 |    0.14450 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17729 | -0.00674 |    0.12795 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21417 | -0.00171 |    0.15770 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17917 | -0.00673 |    0.13694 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27234 | -0.00486 |    0.18587 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14968 | -0.00307 |    0.11393 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13034 | -0.01026 |    0.10265 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15427 | -0.01803 |    0.12297 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11735 | -0.00340 |    0.09207 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14009 | -0.01677 |    0.11190 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13657 | -0.00209 |    0.10830 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15947 | -0.01373 |    0.12385 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12522 | -0.00924 |    0.09897 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10669 | -0.00763 |    0.08366 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11324 | -0.01286 |    0.09040 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06887 |  0.00416 |    0.05177 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56750 | -0.00001 |    0.44357 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:20:40,139 - Total sparsity: 0.00

2018-11-02 20:20:40,139 - --- validate (epoch=178)-----------
2018-11-02 20:20:40,139 - 10000 samples (128 per mini-batch)
2018-11-02 20:20:40,863 - Epoch: [178][   50/   78]    Loss 0.367793    Top1 89.812500    Top5 99.718750    
2018-11-02 20:20:41,253 - ==> Top1: 89.400    Top5: 99.750    Loss: 0.371

2018-11-02 20:20:41,254 - ==> Best Top1: 89.850   On Epoch: 177

2018-11-02 20:20:41,254 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:20:41,269 - 

2018-11-02 20:20:41,269 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:20:42,287 - Epoch: [179][   50/  391]    Overall Loss 0.118250    Objective Loss 0.118250    Top1 95.718750    Top5 99.984375    LR 0.015314    Time 0.020314    
2018-11-02 20:20:43,315 - Epoch: [179][  100/  391]    Overall Loss 0.118299    Objective Loss 0.118299    Top1 95.765625    Top5 99.984375    LR 0.015314    Time 0.020433    
2018-11-02 20:20:44,329 - Epoch: [179][  150/  391]    Overall Loss 0.115798    Objective Loss 0.115798    Top1 95.953125    Top5 99.979167    LR 0.015314    Time 0.020374    
2018-11-02 20:20:45,292 - Epoch: [179][  200/  391]    Overall Loss 0.117457    Objective Loss 0.117457    Top1 95.890625    Top5 99.968750    LR 0.015314    Time 0.020086    
2018-11-02 20:20:46,254 - Epoch: [179][  250/  391]    Overall Loss 0.117702    Objective Loss 0.117702    Top1 95.859375    Top5 99.971875    LR 0.015314    Time 0.019912    
2018-11-02 20:20:47,215 - Epoch: [179][  300/  391]    Overall Loss 0.117542    Objective Loss 0.117542    Top1 95.851562    Top5 99.971354    LR 0.015314    Time 0.019796    
2018-11-02 20:20:48,179 - Epoch: [179][  350/  391]    Overall Loss 0.118730    Objective Loss 0.118730    Top1 95.805804    Top5 99.966518    LR 0.015314    Time 0.019716    
2018-11-02 20:20:49,049 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39283 | -0.00325 |    0.24451 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15457 | -0.00217 |    0.09793 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16467 | -0.00692 |    0.12487 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18755 | -0.03412 |    0.14351 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19195 |  0.00306 |    0.15029 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18701 | -0.02985 |    0.14389 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17664 | -0.00652 |    0.12747 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21335 | -0.00143 |    0.15692 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17850 | -0.00656 |    0.13635 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27121 | -0.00463 |    0.18510 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14914 | -0.00271 |    0.11353 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12984 | -0.01053 |    0.10217 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15377 | -0.01756 |    0.12244 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11693 | -0.00339 |    0.09165 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13957 | -0.01641 |    0.11140 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13608 | -0.00186 |    0.10791 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15881 | -0.01358 |    0.12340 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12476 | -0.00940 |    0.09859 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10636 | -0.00755 |    0.08346 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11282 | -0.01319 |    0.09013 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06859 |  0.00423 |    0.05157 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56809 | -0.00001 |    0.44403 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:20:49,049 - Total sparsity: 0.00

2018-11-02 20:20:49,049 - --- validate (epoch=179)-----------
2018-11-02 20:20:49,049 - 10000 samples (128 per mini-batch)
2018-11-02 20:20:49,770 - Epoch: [179][   50/   78]    Loss 0.358839    Top1 90.187500    Top5 99.656250    
2018-11-02 20:20:50,157 - ==> Top1: 89.940    Top5: 99.720    Loss: 0.356

2018-11-02 20:20:50,158 - ==> Best Top1: 89.940   On Epoch: 179

2018-11-02 20:20:50,158 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:20:50,166 - 

2018-11-02 20:20:50,166 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:20:51,183 - Epoch: [180][   50/  391]    Overall Loss 0.098384    Objective Loss 0.098384    Top1 96.625000    Top5 99.984375    LR 0.014548    Time 0.020312    
2018-11-02 20:20:52,144 - Epoch: [180][  100/  391]    Overall Loss 0.104510    Objective Loss 0.104510    Top1 96.335938    Top5 99.992188    LR 0.014548    Time 0.019748    
2018-11-02 20:20:53,104 - Epoch: [180][  150/  391]    Overall Loss 0.109531    Objective Loss 0.109531    Top1 96.114583    Top5 99.968750    LR 0.014548    Time 0.019563    
2018-11-02 20:20:54,069 - Epoch: [180][  200/  391]    Overall Loss 0.111036    Objective Loss 0.111036    Top1 96.089844    Top5 99.972656    LR 0.014548    Time 0.019487    
2018-11-02 20:20:55,030 - Epoch: [180][  250/  391]    Overall Loss 0.111754    Objective Loss 0.111754    Top1 96.081250    Top5 99.975000    LR 0.014548    Time 0.019418    
2018-11-02 20:20:55,992 - Epoch: [180][  300/  391]    Overall Loss 0.113151    Objective Loss 0.113151    Top1 96.059896    Top5 99.976562    LR 0.014548    Time 0.019384    
2018-11-02 20:20:56,955 - Epoch: [180][  350/  391]    Overall Loss 0.113966    Objective Loss 0.113966    Top1 96.022321    Top5 99.979911    LR 0.014548    Time 0.019362    
2018-11-02 20:20:57,826 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.39132 | -0.00435 |    0.24302 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15399 | -0.00209 |    0.09753 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16415 | -0.00556 |    0.12447 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18692 | -0.03373 |    0.14271 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19124 |  0.00281 |    0.14966 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18627 | -0.03020 |    0.14312 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17598 | -0.00669 |    0.12725 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21256 | -0.00177 |    0.15614 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17786 | -0.00624 |    0.13600 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.27013 | -0.00428 |    0.18407 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14863 | -0.00259 |    0.11314 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12938 | -0.01054 |    0.10183 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15319 | -0.01785 |    0.12213 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11653 | -0.00329 |    0.09135 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13906 | -0.01624 |    0.11101 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13560 | -0.00187 |    0.10753 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15817 | -0.01348 |    0.12282 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12435 | -0.00922 |    0.09832 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10603 | -0.00747 |    0.08321 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11244 | -0.01325 |    0.08986 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06831 |  0.00414 |    0.05140 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56871 | -0.00001 |    0.44454 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:20:57,826 - Total sparsity: 0.00

2018-11-02 20:20:57,826 - --- validate (epoch=180)-----------
2018-11-02 20:20:57,826 - 10000 samples (128 per mini-batch)
2018-11-02 20:20:58,556 - Epoch: [180][   50/   78]    Loss 0.368048    Top1 89.687500    Top5 99.718750    
2018-11-02 20:20:58,948 - ==> Top1: 89.490    Top5: 99.750    Loss: 0.368

2018-11-02 20:20:58,949 - ==> Best Top1: 89.940   On Epoch: 179

2018-11-02 20:20:58,949 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:20:58,960 - 

2018-11-02 20:20:58,960 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:20:59,979 - Epoch: [181][   50/  391]    Overall Loss 0.105639    Objective Loss 0.105639    Top1 96.531250    Top5 99.968750    LR 0.013821    Time 0.020331    
2018-11-02 20:21:00,942 - Epoch: [181][  100/  391]    Overall Loss 0.108672    Objective Loss 0.108672    Top1 96.398438    Top5 99.968750    LR 0.013821    Time 0.019790    
2018-11-02 20:21:01,905 - Epoch: [181][  150/  391]    Overall Loss 0.110605    Objective Loss 0.110605    Top1 96.239583    Top5 99.958333    LR 0.013821    Time 0.019603    
2018-11-02 20:21:02,867 - Epoch: [181][  200/  391]    Overall Loss 0.110828    Objective Loss 0.110828    Top1 96.160156    Top5 99.960938    LR 0.013821    Time 0.019508    
2018-11-02 20:21:03,829 - Epoch: [181][  250/  391]    Overall Loss 0.111031    Objective Loss 0.111031    Top1 96.090625    Top5 99.968750    LR 0.013821    Time 0.019449    
2018-11-02 20:21:04,790 - Epoch: [181][  300/  391]    Overall Loss 0.113214    Objective Loss 0.113214    Top1 96.028646    Top5 99.968750    LR 0.013821    Time 0.019409    
2018-11-02 20:21:05,753 - Epoch: [181][  350/  391]    Overall Loss 0.115303    Objective Loss 0.115303    Top1 95.937500    Top5 99.968750    LR 0.013821    Time 0.019383    
2018-11-02 20:21:06,626 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38996 | -0.00342 |    0.24243 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15344 | -0.00135 |    0.09719 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16356 | -0.00639 |    0.12407 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18631 | -0.03349 |    0.14241 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19055 |  0.00268 |    0.14911 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18557 | -0.03054 |    0.14291 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17537 | -0.00637 |    0.12662 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21180 | -0.00164 |    0.15560 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17723 | -0.00631 |    0.13550 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26907 | -0.00478 |    0.18322 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14814 | -0.00219 |    0.11277 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12896 | -0.01042 |    0.10145 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15272 | -0.01744 |    0.12169 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11613 | -0.00334 |    0.09100 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13864 | -0.01556 |    0.11057 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13515 | -0.00174 |    0.10716 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15754 | -0.01354 |    0.12232 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12394 | -0.00912 |    0.09798 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10570 | -0.00748 |    0.08296 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11213 | -0.01285 |    0.08958 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06805 |  0.00417 |    0.05121 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56900 | -0.00001 |    0.44478 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:21:06,626 - Total sparsity: 0.00

2018-11-02 20:21:06,627 - --- validate (epoch=181)-----------
2018-11-02 20:21:06,627 - 10000 samples (128 per mini-batch)
2018-11-02 20:21:07,334 - Epoch: [181][   50/   78]    Loss 0.373697    Top1 89.562500    Top5 99.765625    
2018-11-02 20:21:07,721 - ==> Top1: 89.470    Top5: 99.740    Loss: 0.373

2018-11-02 20:21:07,722 - ==> Best Top1: 89.940   On Epoch: 179

2018-11-02 20:21:07,722 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:21:07,730 - 

2018-11-02 20:21:07,730 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:21:08,748 - Epoch: [182][   50/  391]    Overall Loss 0.109202    Objective Loss 0.109202    Top1 96.265625    Top5 99.968750    LR 0.013130    Time 0.020333    
2018-11-02 20:21:09,726 - Epoch: [182][  100/  391]    Overall Loss 0.106670    Objective Loss 0.106670    Top1 96.335938    Top5 99.968750    LR 0.013130    Time 0.019934    
2018-11-02 20:21:10,765 - Epoch: [182][  150/  391]    Overall Loss 0.110267    Objective Loss 0.110267    Top1 96.135417    Top5 99.979167    LR 0.013130    Time 0.020208    
2018-11-02 20:21:11,805 - Epoch: [182][  200/  391]    Overall Loss 0.111512    Objective Loss 0.111512    Top1 96.085938    Top5 99.980469    LR 0.013130    Time 0.020348    
2018-11-02 20:21:12,784 - Epoch: [182][  250/  391]    Overall Loss 0.113703    Objective Loss 0.113703    Top1 95.925000    Top5 99.981250    LR 0.013130    Time 0.020192    
2018-11-02 20:21:13,746 - Epoch: [182][  300/  391]    Overall Loss 0.113398    Objective Loss 0.113398    Top1 95.976562    Top5 99.981771    LR 0.013130    Time 0.020028    
2018-11-02 20:21:14,707 - Epoch: [182][  350/  391]    Overall Loss 0.113170    Objective Loss 0.113170    Top1 95.975446    Top5 99.984375    LR 0.013130    Time 0.019909    
2018-11-02 20:21:15,577 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38854 | -0.00306 |    0.24153 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15290 | -0.00167 |    0.09695 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16304 | -0.00562 |    0.12379 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18571 | -0.03322 |    0.14170 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18990 |  0.00284 |    0.14887 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18502 | -0.02997 |    0.14224 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17476 | -0.00668 |    0.12623 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21108 | -0.00096 |    0.15514 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17664 | -0.00604 |    0.13501 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26805 | -0.00549 |    0.18242 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14767 | -0.00233 |    0.11241 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12857 | -0.01003 |    0.10113 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15220 | -0.01754 |    0.12132 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11576 | -0.00349 |    0.09075 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13815 | -0.01554 |    0.11021 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13471 | -0.00180 |    0.10682 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15698 | -0.01325 |    0.12184 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12355 | -0.00914 |    0.09766 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10540 | -0.00739 |    0.08269 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11179 | -0.01278 |    0.08933 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06779 |  0.00413 |    0.05107 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.56942 | -0.00001 |    0.44503 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:21:15,578 - Total sparsity: 0.00

2018-11-02 20:21:15,578 - --- validate (epoch=182)-----------
2018-11-02 20:21:15,578 - 10000 samples (128 per mini-batch)
2018-11-02 20:21:16,299 - Epoch: [182][   50/   78]    Loss 0.356927    Top1 89.968750    Top5 99.781250    
2018-11-02 20:21:16,694 - ==> Top1: 89.730    Top5: 99.770    Loss: 0.365

2018-11-02 20:21:16,694 - ==> Best Top1: 89.940   On Epoch: 179

2018-11-02 20:21:16,695 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:21:16,701 - 

2018-11-02 20:21:16,702 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:21:17,721 - Epoch: [183][   50/  391]    Overall Loss 0.097911    Objective Loss 0.097911    Top1 96.484375    Top5 99.984375    LR 0.012473    Time 0.020351    
2018-11-02 20:21:18,682 - Epoch: [183][  100/  391]    Overall Loss 0.100108    Objective Loss 0.100108    Top1 96.562500    Top5 99.976562    LR 0.012473    Time 0.019772    
2018-11-02 20:21:19,643 - Epoch: [183][  150/  391]    Overall Loss 0.102864    Objective Loss 0.102864    Top1 96.406250    Top5 99.963542    LR 0.012473    Time 0.019580    
2018-11-02 20:21:20,606 - Epoch: [183][  200/  391]    Overall Loss 0.102701    Objective Loss 0.102701    Top1 96.406250    Top5 99.960938    LR 0.012473    Time 0.019495    
2018-11-02 20:21:21,569 - Epoch: [183][  250/  391]    Overall Loss 0.103260    Objective Loss 0.103260    Top1 96.393750    Top5 99.962500    LR 0.012473    Time 0.019444    
2018-11-02 20:21:22,532 - Epoch: [183][  300/  391]    Overall Loss 0.102739    Objective Loss 0.102739    Top1 96.408854    Top5 99.966146    LR 0.012473    Time 0.019398    
2018-11-02 20:21:23,495 - Epoch: [183][  350/  391]    Overall Loss 0.104612    Objective Loss 0.104612    Top1 96.332589    Top5 99.966518    LR 0.012473    Time 0.019374    
2018-11-02 20:21:24,367 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38718 | -0.00273 |    0.24055 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15237 | -0.00180 |    0.09660 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16250 | -0.00579 |    0.12348 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18508 | -0.03320 |    0.14121 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18926 |  0.00239 |    0.14856 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18452 | -0.02924 |    0.14172 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17416 | -0.00669 |    0.12580 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.21035 | -0.00184 |    0.15454 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17604 | -0.00611 |    0.13456 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26706 | -0.00592 |    0.18148 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14720 | -0.00238 |    0.11214 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12814 | -0.01027 |    0.10081 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15173 | -0.01736 |    0.12090 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11540 | -0.00341 |    0.09032 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13764 | -0.01573 |    0.10981 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13427 | -0.00197 |    0.10647 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15640 | -0.01327 |    0.12140 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12317 | -0.00884 |    0.09734 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10509 | -0.00739 |    0.08246 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11143 | -0.01289 |    0.08908 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06755 |  0.00407 |    0.05090 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57023 | -0.00001 |    0.44588 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:21:24,367 - Total sparsity: 0.00

2018-11-02 20:21:24,367 - --- validate (epoch=183)-----------
2018-11-02 20:21:24,368 - 10000 samples (128 per mini-batch)
2018-11-02 20:21:25,083 - Epoch: [183][   50/   78]    Loss 0.363479    Top1 90.140625    Top5 99.718750    
2018-11-02 20:21:25,472 - ==> Top1: 89.990    Top5: 99.710    Loss: 0.363

2018-11-02 20:21:25,473 - ==> Best Top1: 89.990   On Epoch: 183

2018-11-02 20:21:25,473 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:21:25,487 - 

2018-11-02 20:21:25,488 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:21:26,479 - Epoch: [184][   50/  391]    Overall Loss 0.104408    Objective Loss 0.104408    Top1 96.218750    Top5 100.000000    LR 0.011850    Time 0.019803    
2018-11-02 20:21:27,452 - Epoch: [184][  100/  391]    Overall Loss 0.106332    Objective Loss 0.106332    Top1 96.203125    Top5 99.984375    LR 0.011850    Time 0.019615    
2018-11-02 20:21:28,484 - Epoch: [184][  150/  391]    Overall Loss 0.109033    Objective Loss 0.109033    Top1 96.093750    Top5 99.984375    LR 0.011850    Time 0.019953    
2018-11-02 20:21:29,487 - Epoch: [184][  200/  391]    Overall Loss 0.107997    Objective Loss 0.107997    Top1 96.082031    Top5 99.984375    LR 0.011850    Time 0.019974    
2018-11-02 20:21:30,448 - Epoch: [184][  250/  391]    Overall Loss 0.108703    Objective Loss 0.108703    Top1 96.162500    Top5 99.968750    LR 0.011850    Time 0.019816    
2018-11-02 20:21:31,409 - Epoch: [184][  300/  391]    Overall Loss 0.106888    Objective Loss 0.106888    Top1 96.260417    Top5 99.971354    LR 0.011850    Time 0.019715    
2018-11-02 20:21:32,370 - Epoch: [184][  350/  391]    Overall Loss 0.106807    Objective Loss 0.106807    Top1 96.247768    Top5 99.968750    LR 0.011850    Time 0.019640    
2018-11-02 20:21:33,237 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38591 | -0.00349 |    0.24018 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15188 | -0.00165 |    0.09629 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16197 | -0.00647 |    0.12294 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18442 | -0.03349 |    0.14091 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18864 |  0.00239 |    0.14781 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18390 | -0.02948 |    0.14126 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17362 | -0.00652 |    0.12523 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20966 | -0.00206 |    0.15417 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17549 | -0.00590 |    0.13418 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26615 | -0.00510 |    0.18056 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14676 | -0.00237 |    0.11174 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12777 | -0.00997 |    0.10051 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15123 | -0.01779 |    0.12051 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11505 | -0.00324 |    0.09020 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13719 | -0.01575 |    0.10944 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13386 | -0.00188 |    0.10613 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15585 | -0.01329 |    0.12074 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12280 | -0.00885 |    0.09703 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10480 | -0.00724 |    0.08223 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11110 | -0.01289 |    0.08887 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06731 |  0.00411 |    0.05075 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57065 | -0.00001 |    0.44616 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:21:33,237 - Total sparsity: 0.00

2018-11-02 20:21:33,237 - --- validate (epoch=184)-----------
2018-11-02 20:21:33,237 - 10000 samples (128 per mini-batch)
2018-11-02 20:21:33,955 - Epoch: [184][   50/   78]    Loss 0.360861    Top1 89.750000    Top5 99.640625    
2018-11-02 20:21:34,343 - ==> Top1: 89.610    Top5: 99.670    Loss: 0.367

2018-11-02 20:21:34,344 - ==> Best Top1: 89.990   On Epoch: 183

2018-11-02 20:21:34,344 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:21:34,352 - 

2018-11-02 20:21:34,352 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:21:35,369 - Epoch: [185][   50/  391]    Overall Loss 0.107876    Objective Loss 0.107876    Top1 96.093750    Top5 99.953125    LR 0.011257    Time 0.020307    
2018-11-02 20:21:36,331 - Epoch: [185][  100/  391]    Overall Loss 0.105600    Objective Loss 0.105600    Top1 96.093750    Top5 99.968750    LR 0.011257    Time 0.019761    
2018-11-02 20:21:37,294 - Epoch: [185][  150/  391]    Overall Loss 0.103445    Objective Loss 0.103445    Top1 96.213542    Top5 99.968750    LR 0.011257    Time 0.019585    
2018-11-02 20:21:38,256 - Epoch: [185][  200/  391]    Overall Loss 0.103271    Objective Loss 0.103271    Top1 96.222656    Top5 99.976562    LR 0.011257    Time 0.019496    
2018-11-02 20:21:39,223 - Epoch: [185][  250/  391]    Overall Loss 0.105806    Objective Loss 0.105806    Top1 96.168750    Top5 99.965625    LR 0.011257    Time 0.019445    
2018-11-02 20:21:40,192 - Epoch: [185][  300/  391]    Overall Loss 0.105916    Objective Loss 0.105916    Top1 96.244792    Top5 99.960938    LR 0.011257    Time 0.019432    
2018-11-02 20:21:41,160 - Epoch: [185][  350/  391]    Overall Loss 0.106694    Objective Loss 0.106694    Top1 96.218750    Top5 99.959821    LR 0.011257    Time 0.019416    
2018-11-02 20:21:42,030 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38467 | -0.00383 |    0.23883 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15141 | -0.00205 |    0.09611 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16150 | -0.00621 |    0.12270 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18396 | -0.03292 |    0.14058 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18806 |  0.00241 |    0.14735 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18334 | -0.02952 |    0.14099 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17309 | -0.00656 |    0.12489 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20903 | -0.00099 |    0.15361 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17496 | -0.00576 |    0.13369 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26528 | -0.00479 |    0.18016 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14633 | -0.00238 |    0.11150 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12742 | -0.00969 |    0.10013 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15078 | -0.01789 |    0.12025 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11473 | -0.00305 |    0.09007 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13675 | -0.01570 |    0.10913 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13346 | -0.00181 |    0.10582 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15534 | -0.01302 |    0.12038 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12246 | -0.00866 |    0.09673 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10452 | -0.00731 |    0.08200 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11081 | -0.01273 |    0.08860 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06709 |  0.00407 |    0.05061 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57081 | -0.00001 |    0.44638 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:21:42,030 - Total sparsity: 0.00

2018-11-02 20:21:42,030 - --- validate (epoch=185)-----------
2018-11-02 20:21:42,030 - 10000 samples (128 per mini-batch)
2018-11-02 20:21:42,749 - Epoch: [185][   50/   78]    Loss 0.355109    Top1 89.718750    Top5 99.765625    
2018-11-02 20:21:43,142 - ==> Top1: 89.680    Top5: 99.790    Loss: 0.354

2018-11-02 20:21:43,143 - ==> Best Top1: 89.990   On Epoch: 183

2018-11-02 20:21:43,143 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:21:43,154 - 

2018-11-02 20:21:43,155 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:21:44,252 - Epoch: [186][   50/  391]    Overall Loss 0.092357    Objective Loss 0.092357    Top1 96.812500    Top5 100.000000    LR 0.010694    Time 0.021905    
2018-11-02 20:21:45,293 - Epoch: [186][  100/  391]    Overall Loss 0.095900    Objective Loss 0.095900    Top1 96.640625    Top5 99.992188    LR 0.010694    Time 0.021354    
2018-11-02 20:21:46,329 - Epoch: [186][  150/  391]    Overall Loss 0.096319    Objective Loss 0.096319    Top1 96.635417    Top5 99.989583    LR 0.010694    Time 0.021135    
2018-11-02 20:21:47,360 - Epoch: [186][  200/  391]    Overall Loss 0.099674    Objective Loss 0.099674    Top1 96.488281    Top5 99.988281    LR 0.010694    Time 0.021001    
2018-11-02 20:21:48,396 - Epoch: [186][  250/  391]    Overall Loss 0.099806    Objective Loss 0.099806    Top1 96.450000    Top5 99.990625    LR 0.010694    Time 0.020939    
2018-11-02 20:21:49,431 - Epoch: [186][  300/  391]    Overall Loss 0.100829    Objective Loss 0.100829    Top1 96.406250    Top5 99.979167    LR 0.010694    Time 0.020898    
2018-11-02 20:21:50,398 - Epoch: [186][  350/  391]    Overall Loss 0.101375    Objective Loss 0.101375    Top1 96.381696    Top5 99.982143    LR 0.010694    Time 0.020662    
2018-11-02 20:21:51,263 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38347 | -0.00279 |    0.23807 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15097 | -0.00141 |    0.09580 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16104 | -0.00581 |    0.12249 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18349 | -0.03239 |    0.14027 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18749 |  0.00247 |    0.14697 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18269 | -0.03027 |    0.14055 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17255 | -0.00691 |    0.12452 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20839 | -0.00136 |    0.15313 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17444 | -0.00576 |    0.13329 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26441 | -0.00506 |    0.17886 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14592 | -0.00196 |    0.11117 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12706 | -0.00953 |    0.09978 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15038 | -0.01756 |    0.11986 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11440 | -0.00314 |    0.08976 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13637 | -0.01537 |    0.10880 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13308 | -0.00176 |    0.10553 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15485 | -0.01290 |    0.12001 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12212 | -0.00849 |    0.09646 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10424 | -0.00720 |    0.08181 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11049 | -0.01283 |    0.08836 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06688 |  0.00399 |    0.05047 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57124 | -0.00001 |    0.44684 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:21:51,264 - Total sparsity: 0.00

2018-11-02 20:21:51,264 - --- validate (epoch=186)-----------
2018-11-02 20:21:51,264 - 10000 samples (128 per mini-batch)
2018-11-02 20:21:51,989 - Epoch: [186][   50/   78]    Loss 0.359670    Top1 90.031250    Top5 99.687500    
2018-11-02 20:21:52,379 - ==> Top1: 89.960    Top5: 99.720    Loss: 0.363

2018-11-02 20:21:52,380 - ==> Best Top1: 89.990   On Epoch: 183

2018-11-02 20:21:52,380 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:21:52,391 - 

2018-11-02 20:21:52,391 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:21:53,409 - Epoch: [187][   50/  391]    Overall Loss 0.089518    Objective Loss 0.089518    Top1 96.718750    Top5 99.968750    LR 0.010160    Time 0.020330    
2018-11-02 20:21:54,370 - Epoch: [187][  100/  391]    Overall Loss 0.097597    Objective Loss 0.097597    Top1 96.632812    Top5 99.968750    LR 0.010160    Time 0.019755    
2018-11-02 20:21:55,331 - Epoch: [187][  150/  391]    Overall Loss 0.100127    Objective Loss 0.100127    Top1 96.489583    Top5 99.958333    LR 0.010160    Time 0.019573    
2018-11-02 20:21:56,294 - Epoch: [187][  200/  391]    Overall Loss 0.099675    Objective Loss 0.099675    Top1 96.449219    Top5 99.968750    LR 0.010160    Time 0.019486    
2018-11-02 20:21:57,257 - Epoch: [187][  250/  391]    Overall Loss 0.099457    Objective Loss 0.099457    Top1 96.487500    Top5 99.975000    LR 0.010160    Time 0.019439    
2018-11-02 20:21:58,219 - Epoch: [187][  300/  391]    Overall Loss 0.100372    Objective Loss 0.100372    Top1 96.401042    Top5 99.968750    LR 0.010160    Time 0.019399    
2018-11-02 20:21:59,181 - Epoch: [187][  350/  391]    Overall Loss 0.099494    Objective Loss 0.099494    Top1 96.439732    Top5 99.970982    LR 0.010160    Time 0.019373    
2018-11-02 20:22:00,050 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38235 | -0.00236 |    0.23746 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15054 | -0.00158 |    0.09556 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16059 | -0.00587 |    0.12209 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18293 | -0.03254 |    0.14012 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18696 |  0.00226 |    0.14655 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18217 | -0.03025 |    0.14015 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17207 | -0.00639 |    0.12422 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20779 | -0.00128 |    0.15270 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17394 | -0.00586 |    0.13300 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26360 | -0.00516 |    0.17838 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14553 | -0.00167 |    0.11090 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12671 | -0.00948 |    0.09956 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14996 | -0.01762 |    0.11960 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11408 | -0.00330 |    0.08953 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13595 | -0.01544 |    0.10850 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13271 | -0.00185 |    0.10529 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15439 | -0.01255 |    0.11966 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12178 | -0.00847 |    0.09619 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10397 | -0.00716 |    0.08156 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11020 | -0.01277 |    0.08812 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06667 |  0.00397 |    0.05032 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57173 | -0.00001 |    0.44715 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:22:00,050 - Total sparsity: 0.00

2018-11-02 20:22:00,050 - --- validate (epoch=187)-----------
2018-11-02 20:22:00,051 - 10000 samples (128 per mini-batch)
2018-11-02 20:22:00,773 - Epoch: [187][   50/   78]    Loss 0.355541    Top1 89.890625    Top5 99.640625    
2018-11-02 20:22:01,165 - ==> Top1: 89.720    Top5: 99.690    Loss: 0.357

2018-11-02 20:22:01,166 - ==> Best Top1: 89.990   On Epoch: 183

2018-11-02 20:22:01,166 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:22:01,173 - 

2018-11-02 20:22:01,173 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:22:02,195 - Epoch: [188][   50/  391]    Overall Loss 0.087608    Objective Loss 0.087608    Top1 96.953125    Top5 99.968750    LR 0.009652    Time 0.020413    
2018-11-02 20:22:03,157 - Epoch: [188][  100/  391]    Overall Loss 0.095903    Objective Loss 0.095903    Top1 96.468750    Top5 99.976562    LR 0.009652    Time 0.019812    
2018-11-02 20:22:04,119 - Epoch: [188][  150/  391]    Overall Loss 0.095807    Objective Loss 0.095807    Top1 96.442708    Top5 99.979167    LR 0.009652    Time 0.019610    
2018-11-02 20:22:05,079 - Epoch: [188][  200/  391]    Overall Loss 0.097354    Objective Loss 0.097354    Top1 96.441406    Top5 99.980469    LR 0.009652    Time 0.019505    
2018-11-02 20:22:06,041 - Epoch: [188][  250/  391]    Overall Loss 0.097435    Objective Loss 0.097435    Top1 96.496875    Top5 99.978125    LR 0.009652    Time 0.019447    
2018-11-02 20:22:07,045 - Epoch: [188][  300/  391]    Overall Loss 0.098982    Objective Loss 0.098982    Top1 96.424479    Top5 99.971354    LR 0.009652    Time 0.019548    
2018-11-02 20:22:08,088 - Epoch: [188][  350/  391]    Overall Loss 0.099317    Objective Loss 0.099317    Top1 96.448661    Top5 99.975446    LR 0.009652    Time 0.019732    
2018-11-02 20:22:09,025 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38121 | -0.00374 |    0.23628 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15014 | -0.00154 |    0.09531 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16013 | -0.00672 |    0.12187 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18244 | -0.03233 |    0.13961 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18644 |  0.00147 |    0.14620 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18167 | -0.03021 |    0.13974 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17158 | -0.00657 |    0.12387 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20721 | -0.00066 |    0.15219 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17346 | -0.00573 |    0.13257 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26282 | -0.00481 |    0.17809 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14514 | -0.00200 |    0.11068 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12637 | -0.00955 |    0.09928 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14961 | -0.01715 |    0.11927 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11379 | -0.00317 |    0.08936 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13556 | -0.01545 |    0.10818 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13235 | -0.00175 |    0.10499 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15393 | -0.01243 |    0.11937 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12146 | -0.00851 |    0.09594 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10371 | -0.00725 |    0.08136 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10993 | -0.01261 |    0.08793 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06647 |  0.00400 |    0.05017 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57212 | -0.00001 |    0.44745 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:22:09,025 - Total sparsity: 0.00

2018-11-02 20:22:09,025 - --- validate (epoch=188)-----------
2018-11-02 20:22:09,025 - 10000 samples (128 per mini-batch)
2018-11-02 20:22:09,748 - Epoch: [188][   50/   78]    Loss 0.362618    Top1 90.062500    Top5 99.656250    
2018-11-02 20:22:10,139 - ==> Top1: 90.030    Top5: 99.690    Loss: 0.360

2018-11-02 20:22:10,140 - ==> Best Top1: 90.030   On Epoch: 188

2018-11-02 20:22:10,140 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:22:10,153 - 

2018-11-02 20:22:10,153 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:22:11,174 - Epoch: [189][   50/  391]    Overall Loss 0.089723    Objective Loss 0.089723    Top1 96.718750    Top5 99.984375    LR 0.009169    Time 0.020380    
2018-11-02 20:22:12,134 - Epoch: [189][  100/  391]    Overall Loss 0.095710    Objective Loss 0.095710    Top1 96.546875    Top5 99.968750    LR 0.009169    Time 0.019775    
2018-11-02 20:22:13,097 - Epoch: [189][  150/  391]    Overall Loss 0.095379    Objective Loss 0.095379    Top1 96.609375    Top5 99.973958    LR 0.009169    Time 0.019599    
2018-11-02 20:22:14,060 - Epoch: [189][  200/  391]    Overall Loss 0.096033    Objective Loss 0.096033    Top1 96.648438    Top5 99.976562    LR 0.009169    Time 0.019506    
2018-11-02 20:22:15,023 - Epoch: [189][  250/  391]    Overall Loss 0.096844    Objective Loss 0.096844    Top1 96.612500    Top5 99.981250    LR 0.009169    Time 0.019455    
2018-11-02 20:22:15,987 - Epoch: [189][  300/  391]    Overall Loss 0.098500    Objective Loss 0.098500    Top1 96.531250    Top5 99.979167    LR 0.009169    Time 0.019422    
2018-11-02 20:22:16,951 - Epoch: [189][  350/  391]    Overall Loss 0.098724    Objective Loss 0.098724    Top1 96.488839    Top5 99.979911    LR 0.009169    Time 0.019398    
2018-11-02 20:22:17,821 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.38021 | -0.00183 |    0.23558 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14975 | -0.00188 |    0.09519 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15977 | -0.00560 |    0.12166 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18193 | -0.03246 |    0.13928 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18594 |  0.00141 |    0.14581 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18119 | -0.03025 |    0.13945 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17113 | -0.00638 |    0.12359 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20665 | -0.00184 |    0.15169 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17301 | -0.00553 |    0.13218 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26207 | -0.00437 |    0.17770 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14478 | -0.00173 |    0.11040 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12605 | -0.00949 |    0.09903 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14925 | -0.01689 |    0.11900 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11350 | -0.00316 |    0.08908 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13522 | -0.01525 |    0.10789 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13201 | -0.00173 |    0.10471 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15350 | -0.01238 |    0.11909 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12114 | -0.00852 |    0.09569 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10346 | -0.00724 |    0.08117 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10966 | -0.01258 |    0.08773 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06628 |  0.00396 |    0.05003 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57240 | -0.00001 |    0.44770 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:22:17,821 - Total sparsity: 0.00

2018-11-02 20:22:17,821 - --- validate (epoch=189)-----------
2018-11-02 20:22:17,822 - 10000 samples (128 per mini-batch)
2018-11-02 20:22:18,547 - Epoch: [189][   50/   78]    Loss 0.359957    Top1 89.812500    Top5 99.750000    
2018-11-02 20:22:18,942 - ==> Top1: 89.820    Top5: 99.740    Loss: 0.364

2018-11-02 20:22:18,943 - ==> Best Top1: 90.030   On Epoch: 188

2018-11-02 20:22:18,943 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:22:18,950 - 

2018-11-02 20:22:18,950 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:22:19,967 - Epoch: [190][   50/  391]    Overall Loss 0.086594    Objective Loss 0.086594    Top1 97.125000    Top5 100.000000    LR 0.008711    Time 0.020313    
2018-11-02 20:22:20,929 - Epoch: [190][  100/  391]    Overall Loss 0.091189    Objective Loss 0.091189    Top1 96.804688    Top5 99.976562    LR 0.008711    Time 0.019758    
2018-11-02 20:22:21,889 - Epoch: [190][  150/  391]    Overall Loss 0.092416    Objective Loss 0.092416    Top1 96.729167    Top5 99.973958    LR 0.008711    Time 0.019569    
2018-11-02 20:22:22,850 - Epoch: [190][  200/  391]    Overall Loss 0.093732    Objective Loss 0.093732    Top1 96.722656    Top5 99.976562    LR 0.008711    Time 0.019473    
2018-11-02 20:22:23,812 - Epoch: [190][  250/  391]    Overall Loss 0.095121    Objective Loss 0.095121    Top1 96.678125    Top5 99.978125    LR 0.008711    Time 0.019407    
2018-11-02 20:22:24,775 - Epoch: [190][  300/  391]    Overall Loss 0.095441    Objective Loss 0.095441    Top1 96.648438    Top5 99.973958    LR 0.008711    Time 0.019380    
2018-11-02 20:22:25,738 - Epoch: [190][  350/  391]    Overall Loss 0.095078    Objective Loss 0.095078    Top1 96.674107    Top5 99.968750    LR 0.008711    Time 0.019358    
2018-11-02 20:22:26,603 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37921 | -0.00454 |    0.23507 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14938 | -0.00136 |    0.09491 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15937 | -0.00601 |    0.12134 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18157 | -0.03180 |    0.13913 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18545 |  0.00137 |    0.14550 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18077 | -0.03001 |    0.13921 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17069 | -0.00660 |    0.12322 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20612 | -0.00127 |    0.15123 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17257 | -0.00559 |    0.13191 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26136 | -0.00422 |    0.17702 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14442 | -0.00215 |    0.11010 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12573 | -0.00962 |    0.09884 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14889 | -0.01688 |    0.11874 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11322 | -0.00325 |    0.08878 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13486 | -0.01520 |    0.10763 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13169 | -0.00171 |    0.10448 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15307 | -0.01235 |    0.11873 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12084 | -0.00860 |    0.09543 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10321 | -0.00725 |    0.08094 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10940 | -0.01257 |    0.08752 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06610 |  0.00388 |    0.04993 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57265 | -0.00001 |    0.44794 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:22:26,603 - Total sparsity: 0.00

2018-11-02 20:22:26,603 - --- validate (epoch=190)-----------
2018-11-02 20:22:26,603 - 10000 samples (128 per mini-batch)
2018-11-02 20:22:27,325 - Epoch: [190][   50/   78]    Loss 0.366181    Top1 89.859375    Top5 99.765625    
2018-11-02 20:22:27,719 - ==> Top1: 89.850    Top5: 99.770    Loss: 0.365

2018-11-02 20:22:27,720 - ==> Best Top1: 90.030   On Epoch: 188

2018-11-02 20:22:27,720 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:22:27,726 - 

2018-11-02 20:22:27,727 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:22:28,744 - Epoch: [191][   50/  391]    Overall Loss 0.086073    Objective Loss 0.086073    Top1 96.984375    Top5 100.000000    LR 0.008275    Time 0.020306    
2018-11-02 20:22:29,704 - Epoch: [191][  100/  391]    Overall Loss 0.085260    Objective Loss 0.085260    Top1 97.015625    Top5 100.000000    LR 0.008275    Time 0.019745    
2018-11-02 20:22:30,666 - Epoch: [191][  150/  391]    Overall Loss 0.086539    Objective Loss 0.086539    Top1 96.984375    Top5 99.994792    LR 0.008275    Time 0.019569    
2018-11-02 20:22:31,628 - Epoch: [191][  200/  391]    Overall Loss 0.087456    Objective Loss 0.087456    Top1 96.980469    Top5 99.992188    LR 0.008275    Time 0.019480    
2018-11-02 20:22:32,589 - Epoch: [191][  250/  391]    Overall Loss 0.087811    Objective Loss 0.087811    Top1 96.981250    Top5 99.981250    LR 0.008275    Time 0.019423    
2018-11-02 20:22:33,551 - Epoch: [191][  300/  391]    Overall Loss 0.088174    Objective Loss 0.088174    Top1 96.979167    Top5 99.981771    LR 0.008275    Time 0.019388    
2018-11-02 20:22:34,512 - Epoch: [191][  350/  391]    Overall Loss 0.090378    Objective Loss 0.090378    Top1 96.886161    Top5 99.979911    LR 0.008275    Time 0.019362    
2018-11-02 20:22:35,378 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37825 | -0.00368 |    0.23466 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14902 | -0.00176 |    0.09472 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15898 | -0.00631 |    0.12108 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18113 | -0.03169 |    0.13887 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18499 |  0.00162 |    0.14502 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18035 | -0.02979 |    0.13878 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17026 | -0.00640 |    0.12283 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20560 | -0.00090 |    0.15097 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17214 | -0.00539 |    0.13158 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26067 | -0.00442 |    0.17654 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14407 | -0.00214 |    0.10985 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12541 | -0.00981 |    0.09864 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14852 | -0.01693 |    0.11844 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11294 | -0.00349 |    0.08856 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13451 | -0.01524 |    0.10736 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13137 | -0.00143 |    0.10421 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15267 | -0.01225 |    0.11840 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12055 | -0.00855 |    0.09520 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10298 | -0.00712 |    0.08075 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10912 | -0.01275 |    0.08731 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06592 |  0.00379 |    0.04978 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57314 | -0.00001 |    0.44832 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:22:35,378 - Total sparsity: 0.00

2018-11-02 20:22:35,379 - --- validate (epoch=191)-----------
2018-11-02 20:22:35,379 - 10000 samples (128 per mini-batch)
2018-11-02 20:22:36,103 - Epoch: [191][   50/   78]    Loss 0.363057    Top1 90.125000    Top5 99.609375    
2018-11-02 20:22:36,497 - ==> Top1: 89.890    Top5: 99.680    Loss: 0.362

2018-11-02 20:22:36,498 - ==> Best Top1: 90.030   On Epoch: 188

2018-11-02 20:22:36,498 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:22:36,505 - 

2018-11-02 20:22:36,505 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:22:37,602 - Epoch: [192][   50/  391]    Overall Loss 0.082364    Objective Loss 0.082364    Top1 97.125000    Top5 99.984375    LR 0.007861    Time 0.021896    
2018-11-02 20:22:38,564 - Epoch: [192][  100/  391]    Overall Loss 0.083376    Objective Loss 0.083376    Top1 97.000000    Top5 99.992188    LR 0.007861    Time 0.020560    
2018-11-02 20:22:39,527 - Epoch: [192][  150/  391]    Overall Loss 0.085272    Objective Loss 0.085272    Top1 96.994792    Top5 99.989583    LR 0.007861    Time 0.020117    
2018-11-02 20:22:40,490 - Epoch: [192][  200/  391]    Overall Loss 0.087426    Objective Loss 0.087426    Top1 96.878906    Top5 99.984375    LR 0.007861    Time 0.019898    
2018-11-02 20:22:41,453 - Epoch: [192][  250/  391]    Overall Loss 0.088149    Objective Loss 0.088149    Top1 96.853125    Top5 99.984375    LR 0.007861    Time 0.019766    
2018-11-02 20:22:42,417 - Epoch: [192][  300/  391]    Overall Loss 0.088760    Objective Loss 0.088760    Top1 96.807292    Top5 99.981771    LR 0.007861    Time 0.019681    
2018-11-02 20:22:43,380 - Epoch: [192][  350/  391]    Overall Loss 0.089932    Objective Loss 0.089932    Top1 96.754464    Top5 99.979911    LR 0.007861    Time 0.019617    
2018-11-02 20:22:44,247 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37732 | -0.00370 |    0.23388 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14868 | -0.00191 |    0.09453 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15862 | -0.00626 |    0.12093 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18070 | -0.03165 |    0.13850 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18454 |  0.00159 |    0.14469 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17999 | -0.02943 |    0.13853 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16985 | -0.00651 |    0.12248 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20510 | -0.00094 |    0.15080 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17173 | -0.00532 |    0.13118 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.26001 | -0.00461 |    0.17617 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14374 | -0.00224 |    0.10960 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12513 | -0.00972 |    0.09841 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14823 | -0.01646 |    0.11807 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11269 | -0.00339 |    0.08836 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13419 | -0.01520 |    0.10708 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13106 | -0.00168 |    0.10397 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15229 | -0.01214 |    0.11801 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12028 | -0.00839 |    0.09498 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10276 | -0.00705 |    0.08055 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10888 | -0.01267 |    0.08712 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06575 |  0.00386 |    0.04966 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57345 | -0.00001 |    0.44857 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:22:44,247 - Total sparsity: 0.00

2018-11-02 20:22:44,247 - --- validate (epoch=192)-----------
2018-11-02 20:22:44,248 - 10000 samples (128 per mini-batch)
2018-11-02 20:22:44,971 - Epoch: [192][   50/   78]    Loss 0.359651    Top1 90.250000    Top5 99.750000    
2018-11-02 20:22:45,365 - ==> Top1: 90.160    Top5: 99.770    Loss: 0.359

2018-11-02 20:22:45,365 - ==> Best Top1: 90.160   On Epoch: 192

2018-11-02 20:22:45,365 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:22:45,373 - 

2018-11-02 20:22:45,374 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:22:46,391 - Epoch: [193][   50/  391]    Overall Loss 0.083857    Objective Loss 0.083857    Top1 97.093750    Top5 100.000000    LR 0.007468    Time 0.020318    
2018-11-02 20:22:47,352 - Epoch: [193][  100/  391]    Overall Loss 0.084644    Objective Loss 0.084644    Top1 97.000000    Top5 99.992188    LR 0.007468    Time 0.019751    
2018-11-02 20:22:48,313 - Epoch: [193][  150/  391]    Overall Loss 0.085485    Objective Loss 0.085485    Top1 96.875000    Top5 99.989583    LR 0.007468    Time 0.019571    
2018-11-02 20:22:49,276 - Epoch: [193][  200/  391]    Overall Loss 0.087102    Objective Loss 0.087102    Top1 96.878906    Top5 99.992188    LR 0.007468    Time 0.019484    
2018-11-02 20:22:50,237 - Epoch: [193][  250/  391]    Overall Loss 0.087767    Objective Loss 0.087767    Top1 96.856250    Top5 99.993750    LR 0.007468    Time 0.019429    
2018-11-02 20:22:51,208 - Epoch: [193][  300/  391]    Overall Loss 0.089074    Objective Loss 0.089074    Top1 96.815104    Top5 99.986979    LR 0.007468    Time 0.019422    
2018-11-02 20:22:52,189 - Epoch: [193][  350/  391]    Overall Loss 0.089146    Objective Loss 0.089146    Top1 96.832589    Top5 99.982143    LR 0.007468    Time 0.019447    
2018-11-02 20:22:53,055 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37645 | -0.00313 |    0.23331 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14834 | -0.00194 |    0.09419 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15825 | -0.00666 |    0.12036 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18028 | -0.03163 |    0.13821 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18412 |  0.00116 |    0.14449 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17964 | -0.02910 |    0.13827 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16946 | -0.00647 |    0.12213 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20462 | -0.00047 |    0.15040 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17135 | -0.00500 |    0.13090 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25939 | -0.00413 |    0.17575 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14343 | -0.00202 |    0.10941 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12484 | -0.00977 |    0.09821 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14791 | -0.01635 |    0.11782 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11245 | -0.00312 |    0.08818 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13388 | -0.01514 |    0.10681 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13077 | -0.00145 |    0.10375 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15192 | -0.01205 |    0.11776 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12002 | -0.00841 |    0.09477 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10254 | -0.00710 |    0.08040 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10864 | -0.01265 |    0.08691 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06559 |  0.00387 |    0.04954 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57367 | -0.00001 |    0.44877 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:22:53,056 - Total sparsity: 0.00

2018-11-02 20:22:53,056 - --- validate (epoch=193)-----------
2018-11-02 20:22:53,056 - 10000 samples (128 per mini-batch)
2018-11-02 20:22:53,769 - Epoch: [193][   50/   78]    Loss 0.365575    Top1 90.125000    Top5 99.734375    
2018-11-02 20:22:54,156 - ==> Top1: 89.920    Top5: 99.750    Loss: 0.367

2018-11-02 20:22:54,157 - ==> Best Top1: 90.160   On Epoch: 192

2018-11-02 20:22:54,157 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:22:54,165 - 

2018-11-02 20:22:54,165 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:22:55,184 - Epoch: [194][   50/  391]    Overall Loss 0.086047    Objective Loss 0.086047    Top1 97.171875    Top5 99.953125    LR 0.007095    Time 0.020350    
2018-11-02 20:22:56,146 - Epoch: [194][  100/  391]    Overall Loss 0.086731    Objective Loss 0.086731    Top1 97.195312    Top5 99.968750    LR 0.007095    Time 0.019774    
2018-11-02 20:22:57,109 - Epoch: [194][  150/  391]    Overall Loss 0.086812    Objective Loss 0.086812    Top1 97.098958    Top5 99.979167    LR 0.007095    Time 0.019599    
2018-11-02 20:22:58,074 - Epoch: [194][  200/  391]    Overall Loss 0.087529    Objective Loss 0.087529    Top1 96.996094    Top5 99.976562    LR 0.007095    Time 0.019517    
2018-11-02 20:22:59,037 - Epoch: [194][  250/  391]    Overall Loss 0.087943    Objective Loss 0.087943    Top1 96.975000    Top5 99.978125    LR 0.007095    Time 0.019463    
2018-11-02 20:23:00,001 - Epoch: [194][  300/  391]    Overall Loss 0.087605    Objective Loss 0.087605    Top1 96.971354    Top5 99.979167    LR 0.007095    Time 0.019427    
2018-11-02 20:23:00,966 - Epoch: [194][  350/  391]    Overall Loss 0.087216    Objective Loss 0.087216    Top1 97.008929    Top5 99.979911    LR 0.007095    Time 0.019405    
2018-11-02 20:23:01,839 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37560 | -0.00339 |    0.23297 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14802 | -0.00227 |    0.09397 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15793 | -0.00630 |    0.12003 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17985 | -0.03182 |    0.13789 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18372 |  0.00057 |    0.14426 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17934 | -0.02855 |    0.13825 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16908 | -0.00659 |    0.12182 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20417 | -0.00076 |    0.15011 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17097 | -0.00509 |    0.13049 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25878 | -0.00466 |    0.17535 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14312 | -0.00205 |    0.10914 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00978 |    0.09805 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14757 | -0.01650 |    0.11753 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11221 | -0.00298 |    0.08800 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13358 | -0.01508 |    0.10657 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13049 | -0.00132 |    0.10353 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15155 | -0.01216 |    0.11751 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11977 | -0.00833 |    0.09454 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10233 | -0.00707 |    0.08025 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10841 | -0.01267 |    0.08672 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06543 |  0.00386 |    0.04944 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57387 | -0.00001 |    0.44891 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:23:01,839 - Total sparsity: 0.00

2018-11-02 20:23:01,839 - --- validate (epoch=194)-----------
2018-11-02 20:23:01,840 - 10000 samples (128 per mini-batch)
2018-11-02 20:23:02,562 - Epoch: [194][   50/   78]    Loss 0.367653    Top1 90.312500    Top5 99.671875    
2018-11-02 20:23:02,953 - ==> Top1: 90.300    Top5: 99.710    Loss: 0.365

2018-11-02 20:23:02,954 - ==> Best Top1: 90.300   On Epoch: 194

2018-11-02 20:23:02,954 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:23:02,968 - 

2018-11-02 20:23:02,969 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:23:03,987 - Epoch: [195][   50/  391]    Overall Loss 0.084445    Objective Loss 0.084445    Top1 97.218750    Top5 99.968750    LR 0.006740    Time 0.020324    
2018-11-02 20:23:04,952 - Epoch: [195][  100/  391]    Overall Loss 0.080000    Objective Loss 0.080000    Top1 97.351562    Top5 99.976562    LR 0.006740    Time 0.019802    
2018-11-02 20:23:05,918 - Epoch: [195][  150/  391]    Overall Loss 0.082149    Objective Loss 0.082149    Top1 97.296875    Top5 99.979167    LR 0.006740    Time 0.019635    
2018-11-02 20:23:06,881 - Epoch: [195][  200/  391]    Overall Loss 0.082829    Objective Loss 0.082829    Top1 97.171875    Top5 99.980469    LR 0.006740    Time 0.019537    
2018-11-02 20:23:07,843 - Epoch: [195][  250/  391]    Overall Loss 0.084343    Objective Loss 0.084343    Top1 97.100000    Top5 99.984375    LR 0.006740    Time 0.019473    
2018-11-02 20:23:08,845 - Epoch: [195][  300/  391]    Overall Loss 0.084993    Objective Loss 0.084993    Top1 97.067708    Top5 99.981771    LR 0.006740    Time 0.019562    
2018-11-02 20:23:09,887 - Epoch: [195][  350/  391]    Overall Loss 0.085141    Objective Loss 0.085141    Top1 97.055804    Top5 99.982143    LR 0.006740    Time 0.019730    
2018-11-02 20:23:10,812 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37478 | -0.00349 |    0.23230 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14772 | -0.00206 |    0.09385 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15758 | -0.00673 |    0.11981 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17943 | -0.03194 |    0.13759 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18332 |  0.00099 |    0.14388 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17888 | -0.02898 |    0.13790 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16873 | -0.00640 |    0.12164 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20373 | -0.00098 |    0.14994 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17062 | -0.00486 |    0.13022 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25820 | -0.00447 |    0.17507 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14283 | -0.00203 |    0.10892 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12431 | -0.00976 |    0.09780 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14725 | -0.01664 |    0.11726 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11198 | -0.00315 |    0.08778 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13329 | -0.01510 |    0.10633 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13022 | -0.00126 |    0.10331 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15122 | -0.01205 |    0.11722 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11952 | -0.00831 |    0.09436 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10214 | -0.00700 |    0.08009 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10819 | -0.01270 |    0.08656 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06529 |  0.00383 |    0.04933 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57425 | -0.00001 |    0.44921 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:23:10,813 - Total sparsity: 0.00

2018-11-02 20:23:10,813 - --- validate (epoch=195)-----------
2018-11-02 20:23:10,813 - 10000 samples (128 per mini-batch)
2018-11-02 20:23:11,535 - Epoch: [195][   50/   78]    Loss 0.364710    Top1 90.437500    Top5 99.531250    
2018-11-02 20:23:11,927 - ==> Top1: 90.330    Top5: 99.590    Loss: 0.364

2018-11-02 20:23:11,928 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:23:11,928 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:23:11,942 - 

2018-11-02 20:23:11,943 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:23:13,041 - Epoch: [196][   50/  391]    Overall Loss 0.084382    Objective Loss 0.084382    Top1 97.203125    Top5 100.000000    LR 0.006403    Time 0.021925    
2018-11-02 20:23:14,081 - Epoch: [196][  100/  391]    Overall Loss 0.082556    Objective Loss 0.082556    Top1 97.179688    Top5 100.000000    LR 0.006403    Time 0.021357    
2018-11-02 20:23:15,125 - Epoch: [196][  150/  391]    Overall Loss 0.082993    Objective Loss 0.082993    Top1 97.255208    Top5 99.994792    LR 0.006403    Time 0.021192    
2018-11-02 20:23:16,150 - Epoch: [196][  200/  391]    Overall Loss 0.080852    Objective Loss 0.080852    Top1 97.312500    Top5 99.996094    LR 0.006403    Time 0.021013    
2018-11-02 20:23:17,173 - Epoch: [196][  250/  391]    Overall Loss 0.080547    Objective Loss 0.080547    Top1 97.321875    Top5 99.993750    LR 0.006403    Time 0.020897    
2018-11-02 20:23:18,200 - Epoch: [196][  300/  391]    Overall Loss 0.082038    Objective Loss 0.082038    Top1 97.213542    Top5 99.994792    LR 0.006403    Time 0.020833    
2018-11-02 20:23:19,220 - Epoch: [196][  350/  391]    Overall Loss 0.083550    Objective Loss 0.083550    Top1 97.142857    Top5 99.993304    LR 0.006403    Time 0.020770    
2018-11-02 20:23:20,131 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37400 | -0.00246 |    0.23178 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14742 | -0.00212 |    0.09367 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15727 | -0.00669 |    0.11960 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17907 | -0.03182 |    0.13744 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18294 |  0.00088 |    0.14367 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17853 | -0.02894 |    0.13765 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16838 | -0.00654 |    0.12144 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20331 | -0.00102 |    0.14960 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17027 | -0.00495 |    0.13005 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25765 | -0.00450 |    0.17441 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14254 | -0.00216 |    0.10880 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12407 | -0.00968 |    0.09758 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14698 | -0.01644 |    0.11699 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11176 | -0.00307 |    0.08760 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13302 | -0.01503 |    0.10613 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12996 | -0.00140 |    0.10311 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15090 | -0.01197 |    0.11691 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11929 | -0.00821 |    0.09415 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10195 | -0.00695 |    0.07994 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10797 | -0.01276 |    0.08641 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06515 |  0.00381 |    0.04923 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57452 | -0.00001 |    0.44952 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:23:20,131 - Total sparsity: 0.00

2018-11-02 20:23:20,131 - --- validate (epoch=196)-----------
2018-11-02 20:23:20,131 - 10000 samples (128 per mini-batch)
2018-11-02 20:23:20,854 - Epoch: [196][   50/   78]    Loss 0.370465    Top1 90.203125    Top5 99.718750    
2018-11-02 20:23:21,245 - ==> Top1: 90.100    Top5: 99.740    Loss: 0.370

2018-11-02 20:23:21,246 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:23:21,246 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:23:21,254 - 

2018-11-02 20:23:21,254 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:23:22,271 - Epoch: [197][   50/  391]    Overall Loss 0.085172    Objective Loss 0.085172    Top1 97.062500    Top5 99.984375    LR 0.006083    Time 0.020315    
2018-11-02 20:23:23,231 - Epoch: [197][  100/  391]    Overall Loss 0.085575    Objective Loss 0.085575    Top1 97.062500    Top5 99.984375    LR 0.006083    Time 0.019742    
2018-11-02 20:23:24,194 - Epoch: [197][  150/  391]    Overall Loss 0.081427    Objective Loss 0.081427    Top1 97.213542    Top5 99.989583    LR 0.006083    Time 0.019575    
2018-11-02 20:23:25,156 - Epoch: [197][  200/  391]    Overall Loss 0.082576    Objective Loss 0.082576    Top1 97.218750    Top5 99.992188    LR 0.006083    Time 0.019486    
2018-11-02 20:23:26,119 - Epoch: [197][  250/  391]    Overall Loss 0.083320    Objective Loss 0.083320    Top1 97.171875    Top5 99.993750    LR 0.006083    Time 0.019435    
2018-11-02 20:23:27,080 - Epoch: [197][  300/  391]    Overall Loss 0.083287    Objective Loss 0.083287    Top1 97.117188    Top5 99.992188    LR 0.006083    Time 0.019395    
2018-11-02 20:23:28,042 - Epoch: [197][  350/  391]    Overall Loss 0.083508    Objective Loss 0.083508    Top1 97.071429    Top5 99.991071    LR 0.006083    Time 0.019368    
2018-11-02 20:23:28,908 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37323 | -0.00465 |    0.23152 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14714 | -0.00199 |    0.09354 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15699 | -0.00631 |    0.11942 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17876 | -0.03164 |    0.13716 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18259 |  0.00069 |    0.14330 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17812 | -0.02935 |    0.13733 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16805 | -0.00649 |    0.12119 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20291 | -0.00111 |    0.14944 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16993 | -0.00502 |    0.12981 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25712 | -0.00444 |    0.17408 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14227 | -0.00203 |    0.10853 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12383 | -0.00970 |    0.09743 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14669 | -0.01646 |    0.11677 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11155 | -0.00311 |    0.08744 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13275 | -0.01503 |    0.10595 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12972 | -0.00138 |    0.10293 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15059 | -0.01196 |    0.11666 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11907 | -0.00817 |    0.09397 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10176 | -0.00700 |    0.07979 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10778 | -0.01261 |    0.08625 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06501 |  0.00381 |    0.04914 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57482 | -0.00001 |    0.44971 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:23:28,909 - Total sparsity: 0.00

2018-11-02 20:23:28,909 - --- validate (epoch=197)-----------
2018-11-02 20:23:28,909 - 10000 samples (128 per mini-batch)
2018-11-02 20:23:29,633 - Epoch: [197][   50/   78]    Loss 0.368616    Top1 90.109375    Top5 99.671875    
2018-11-02 20:23:30,026 - ==> Top1: 90.070    Top5: 99.690    Loss: 0.373

2018-11-02 20:23:30,027 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:23:30,027 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:23:30,034 - 

2018-11-02 20:23:30,034 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:23:31,053 - Epoch: [198][   50/  391]    Overall Loss 0.081036    Objective Loss 0.081036    Top1 97.453125    Top5 99.984375    LR 0.005779    Time 0.020346    
2018-11-02 20:23:32,015 - Epoch: [198][  100/  391]    Overall Loss 0.084174    Objective Loss 0.084174    Top1 97.140625    Top5 99.976562    LR 0.005779    Time 0.019782    
2018-11-02 20:23:32,976 - Epoch: [198][  150/  391]    Overall Loss 0.081870    Objective Loss 0.081870    Top1 97.187500    Top5 99.984375    LR 0.005779    Time 0.019581    
2018-11-02 20:23:33,938 - Epoch: [198][  200/  391]    Overall Loss 0.081697    Objective Loss 0.081697    Top1 97.203125    Top5 99.988281    LR 0.005779    Time 0.019493    
2018-11-02 20:23:34,901 - Epoch: [198][  250/  391]    Overall Loss 0.081389    Objective Loss 0.081389    Top1 97.156250    Top5 99.990625    LR 0.005779    Time 0.019442    
2018-11-02 20:23:35,863 - Epoch: [198][  300/  391]    Overall Loss 0.081577    Objective Loss 0.081577    Top1 97.151042    Top5 99.992188    LR 0.005779    Time 0.019404    
2018-11-02 20:23:36,831 - Epoch: [198][  350/  391]    Overall Loss 0.082168    Objective Loss 0.082168    Top1 97.129464    Top5 99.988839    LR 0.005779    Time 0.019395    
2018-11-02 20:23:37,700 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37253 | -0.00433 |    0.23112 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14688 | -0.00156 |    0.09324 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15671 | -0.00612 |    0.11933 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17841 | -0.03168 |    0.13690 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18225 |  0.00086 |    0.14306 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17786 | -0.02886 |    0.13709 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16775 | -0.00604 |    0.12102 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20253 | -0.00172 |    0.14907 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16961 | -0.00508 |    0.12949 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25661 | -0.00467 |    0.17362 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14201 | -0.00209 |    0.10834 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12361 | -0.00962 |    0.09724 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14643 | -0.01640 |    0.11661 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11135 | -0.00294 |    0.08728 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13251 | -0.01496 |    0.10578 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12948 | -0.00148 |    0.10277 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15029 | -0.01189 |    0.11646 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11886 | -0.00811 |    0.09380 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10158 | -0.00697 |    0.07967 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10759 | -0.01258 |    0.08608 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06489 |  0.00377 |    0.04905 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57517 | -0.00001 |    0.45003 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:23:37,700 - Total sparsity: 0.00

2018-11-02 20:23:37,700 - --- validate (epoch=198)-----------
2018-11-02 20:23:37,701 - 10000 samples (128 per mini-batch)
2018-11-02 20:23:38,425 - Epoch: [198][   50/   78]    Loss 0.363481    Top1 90.328125    Top5 99.687500    
2018-11-02 20:23:38,816 - ==> Top1: 90.090    Top5: 99.720    Loss: 0.373

2018-11-02 20:23:38,816 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:23:38,817 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:23:38,824 - 

2018-11-02 20:23:38,824 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:23:39,842 - Epoch: [199][   50/  391]    Overall Loss 0.077683    Objective Loss 0.077683    Top1 97.187500    Top5 100.000000    LR 0.005490    Time 0.020318    
2018-11-02 20:23:40,805 - Epoch: [199][  100/  391]    Overall Loss 0.082013    Objective Loss 0.082013    Top1 97.015625    Top5 99.992188    LR 0.005490    Time 0.019781    
2018-11-02 20:23:41,767 - Epoch: [199][  150/  391]    Overall Loss 0.079454    Objective Loss 0.079454    Top1 97.140625    Top5 99.994792    LR 0.005490    Time 0.019593    
2018-11-02 20:23:42,732 - Epoch: [199][  200/  391]    Overall Loss 0.078299    Objective Loss 0.078299    Top1 97.234375    Top5 99.992188    LR 0.005490    Time 0.019510    
2018-11-02 20:23:43,696 - Epoch: [199][  250/  391]    Overall Loss 0.078593    Objective Loss 0.078593    Top1 97.265625    Top5 99.993750    LR 0.005490    Time 0.019463    
2018-11-02 20:23:44,662 - Epoch: [199][  300/  391]    Overall Loss 0.079204    Objective Loss 0.079204    Top1 97.192708    Top5 99.992188    LR 0.005490    Time 0.019435    
2018-11-02 20:23:45,625 - Epoch: [199][  350/  391]    Overall Loss 0.079540    Objective Loss 0.079540    Top1 97.183036    Top5 99.991071    LR 0.005490    Time 0.019406    
2018-11-02 20:23:46,497 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37185 | -0.00384 |    0.23061 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14662 | -0.00189 |    0.09307 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15642 | -0.00633 |    0.11903 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17811 | -0.03150 |    0.13666 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18192 |  0.00066 |    0.14283 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17755 | -0.02882 |    0.13688 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16745 | -0.00602 |    0.12069 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20216 | -0.00139 |    0.14880 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16931 | -0.00516 |    0.12928 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25614 | -0.00452 |    0.17328 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14177 | -0.00208 |    0.10817 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12339 | -0.00961 |    0.09700 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14615 | -0.01653 |    0.11647 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11115 | -0.00303 |    0.08712 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13228 | -0.01481 |    0.10559 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12925 | -0.00148 |    0.10258 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15001 | -0.01185 |    0.11618 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11864 | -0.00815 |    0.09364 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10141 | -0.00690 |    0.07952 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10740 | -0.01263 |    0.08595 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06476 |  0.00373 |    0.04897 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57543 | -0.00001 |    0.45022 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:23:46,497 - Total sparsity: 0.00

2018-11-02 20:23:46,498 - --- validate (epoch=199)-----------
2018-11-02 20:23:46,498 - 10000 samples (128 per mini-batch)
2018-11-02 20:23:47,220 - Epoch: [199][   50/   78]    Loss 0.374713    Top1 90.265625    Top5 99.718750    
2018-11-02 20:23:47,609 - ==> Top1: 90.160    Top5: 99.720    Loss: 0.378

2018-11-02 20:23:47,610 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:23:47,610 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:23:47,620 - 

2018-11-02 20:23:47,621 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:23:48,642 - Epoch: [200][   50/  391]    Overall Loss 0.085043    Objective Loss 0.085043    Top1 97.000000    Top5 99.984375    LR 0.005215    Time 0.020387    
2018-11-02 20:23:49,604 - Epoch: [200][  100/  391]    Overall Loss 0.075386    Objective Loss 0.075386    Top1 97.351562    Top5 99.984375    LR 0.005215    Time 0.019799    
2018-11-02 20:23:50,567 - Epoch: [200][  150/  391]    Overall Loss 0.076147    Objective Loss 0.076147    Top1 97.338542    Top5 99.984375    LR 0.005215    Time 0.019616    
2018-11-02 20:23:51,574 - Epoch: [200][  200/  391]    Overall Loss 0.076638    Objective Loss 0.076638    Top1 97.292969    Top5 99.980469    LR 0.005215    Time 0.019739    
2018-11-02 20:23:52,609 - Epoch: [200][  250/  391]    Overall Loss 0.078026    Objective Loss 0.078026    Top1 97.237500    Top5 99.984375    LR 0.005215    Time 0.019925    
2018-11-02 20:23:53,648 - Epoch: [200][  300/  391]    Overall Loss 0.078941    Objective Loss 0.078941    Top1 97.239583    Top5 99.986979    LR 0.005215    Time 0.020063    
2018-11-02 20:23:54,688 - Epoch: [200][  350/  391]    Overall Loss 0.078353    Objective Loss 0.078353    Top1 97.265625    Top5 99.984375    LR 0.005215    Time 0.020156    
2018-11-02 20:23:55,632 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37120 | -0.00369 |    0.23004 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14637 | -0.00186 |    0.09286 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15616 | -0.00629 |    0.11879 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17779 | -0.03153 |    0.13656 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18161 |  0.00065 |    0.14266 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17718 | -0.02923 |    0.13665 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16715 | -0.00622 |    0.12054 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20182 | -0.00157 |    0.14851 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16901 | -0.00528 |    0.12904 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25567 | -0.00485 |    0.17285 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14153 | -0.00224 |    0.10805 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12318 | -0.00972 |    0.09685 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14591 | -0.01654 |    0.11624 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11097 | -0.00305 |    0.08695 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13205 | -0.01475 |    0.10538 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12903 | -0.00146 |    0.10242 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14974 | -0.01181 |    0.11596 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11845 | -0.00813 |    0.09348 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10125 | -0.00682 |    0.07940 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10721 | -0.01265 |    0.08583 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06465 |  0.00374 |    0.04888 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57568 | -0.00001 |    0.45044 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:23:55,632 - Total sparsity: 0.00

2018-11-02 20:23:55,632 - --- validate (epoch=200)-----------
2018-11-02 20:23:55,632 - 10000 samples (128 per mini-batch)
2018-11-02 20:23:56,359 - Epoch: [200][   50/   78]    Loss 0.378340    Top1 89.984375    Top5 99.671875    
2018-11-02 20:23:56,751 - ==> Top1: 89.900    Top5: 99.670    Loss: 0.380

2018-11-02 20:23:56,752 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:23:56,752 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:23:56,760 - 

2018-11-02 20:23:56,760 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:23:57,858 - Epoch: [201][   50/  391]    Overall Loss 0.075123    Objective Loss 0.075123    Top1 97.375000    Top5 100.000000    LR 0.004955    Time 0.021919    
2018-11-02 20:23:58,899 - Epoch: [201][  100/  391]    Overall Loss 0.080561    Objective Loss 0.080561    Top1 97.195312    Top5 100.000000    LR 0.004955    Time 0.021352    
2018-11-02 20:23:59,936 - Epoch: [201][  150/  391]    Overall Loss 0.079199    Objective Loss 0.079199    Top1 97.260417    Top5 100.000000    LR 0.004955    Time 0.021142    
2018-11-02 20:24:00,976 - Epoch: [201][  200/  391]    Overall Loss 0.079234    Objective Loss 0.079234    Top1 97.253906    Top5 99.996094    LR 0.004955    Time 0.021050    
2018-11-02 20:24:02,008 - Epoch: [201][  250/  391]    Overall Loss 0.079895    Objective Loss 0.079895    Top1 97.240625    Top5 99.996875    LR 0.004955    Time 0.020963    
2018-11-02 20:24:03,069 - Epoch: [201][  300/  391]    Overall Loss 0.080433    Objective Loss 0.080433    Top1 97.184896    Top5 99.997396    LR 0.004955    Time 0.021002    
2018-11-02 20:24:04,075 - Epoch: [201][  350/  391]    Overall Loss 0.079739    Objective Loss 0.079739    Top1 97.220982    Top5 99.995536    LR 0.004955    Time 0.020871    
2018-11-02 20:24:04,948 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.37057 | -0.00288 |    0.22981 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14613 | -0.00172 |    0.09275 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15591 | -0.00613 |    0.11861 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17752 | -0.03138 |    0.13628 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18131 |  0.00071 |    0.14245 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17693 | -0.02901 |    0.13647 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16688 | -0.00614 |    0.12035 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20148 | -0.00097 |    0.14834 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16874 | -0.00512 |    0.12878 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25524 | -0.00464 |    0.17244 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14131 | -0.00211 |    0.10789 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12298 | -0.00965 |    0.09668 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14568 | -0.01646 |    0.11603 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11079 | -0.00306 |    0.08682 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13184 | -0.01466 |    0.10521 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12882 | -0.00153 |    0.10226 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14948 | -0.01187 |    0.11576 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11826 | -0.00810 |    0.09333 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10110 | -0.00677 |    0.07927 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10704 | -0.01265 |    0.08568 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06453 |  0.00373 |    0.04880 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57594 | -0.00001 |    0.45069 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:24:04,948 - Total sparsity: 0.00

2018-11-02 20:24:04,948 - --- validate (epoch=201)-----------
2018-11-02 20:24:04,948 - 10000 samples (128 per mini-batch)
2018-11-02 20:24:05,668 - Epoch: [201][   50/   78]    Loss 0.380437    Top1 90.390625    Top5 99.687500    
2018-11-02 20:24:06,084 - ==> Top1: 90.240    Top5: 99.700    Loss: 0.380

2018-11-02 20:24:06,084 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:24:06,085 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:24:06,092 - 

2018-11-02 20:24:06,092 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:24:07,189 - Epoch: [202][   50/  391]    Overall Loss 0.076123    Objective Loss 0.076123    Top1 97.203125    Top5 99.984375    LR 0.004707    Time 0.021897    
2018-11-02 20:24:08,225 - Epoch: [202][  100/  391]    Overall Loss 0.078038    Objective Loss 0.078038    Top1 97.132812    Top5 99.984375    LR 0.004707    Time 0.021303    
2018-11-02 20:24:09,198 - Epoch: [202][  150/  391]    Overall Loss 0.076327    Objective Loss 0.076327    Top1 97.234375    Top5 99.989583    LR 0.004707    Time 0.020681    
2018-11-02 20:24:10,159 - Epoch: [202][  200/  391]    Overall Loss 0.075794    Objective Loss 0.075794    Top1 97.285156    Top5 99.988281    LR 0.004707    Time 0.020291    
2018-11-02 20:24:11,122 - Epoch: [202][  250/  391]    Overall Loss 0.076264    Objective Loss 0.076264    Top1 97.256250    Top5 99.987500    LR 0.004707    Time 0.020082    
2018-11-02 20:24:12,085 - Epoch: [202][  300/  391]    Overall Loss 0.076385    Objective Loss 0.076385    Top1 97.257812    Top5 99.986979    LR 0.004707    Time 0.019941    
2018-11-02 20:24:13,047 - Epoch: [202][  350/  391]    Overall Loss 0.076518    Objective Loss 0.076518    Top1 97.256696    Top5 99.988839    LR 0.004707    Time 0.019836    
2018-11-02 20:24:13,915 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36998 | -0.00293 |    0.22961 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14591 | -0.00156 |    0.09261 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15565 | -0.00652 |    0.11846 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17722 | -0.03143 |    0.13611 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18102 |  0.00061 |    0.14229 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17673 | -0.02853 |    0.13625 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16661 | -0.00617 |    0.12013 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20116 | -0.00104 |    0.14807 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16848 | -0.00511 |    0.12861 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25483 | -0.00433 |    0.17228 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14109 | -0.00231 |    0.10769 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12279 | -0.00967 |    0.09648 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14546 | -0.01642 |    0.11586 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11062 | -0.00307 |    0.08670 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13163 | -0.01462 |    0.10504 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12862 | -0.00149 |    0.10210 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14924 | -0.01176 |    0.11555 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11808 | -0.00808 |    0.09317 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10094 | -0.00680 |    0.07916 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10688 | -0.01261 |    0.08554 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06442 |  0.00378 |    0.04872 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57615 | -0.00001 |    0.45084 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:24:13,915 - Total sparsity: 0.00

2018-11-02 20:24:13,915 - --- validate (epoch=202)-----------
2018-11-02 20:24:13,916 - 10000 samples (128 per mini-batch)
2018-11-02 20:24:14,630 - Epoch: [202][   50/   78]    Loss 0.375702    Top1 90.328125    Top5 99.656250    
2018-11-02 20:24:15,019 - ==> Top1: 90.070    Top5: 99.690    Loss: 0.378

2018-11-02 20:24:15,020 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:24:15,020 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:24:15,030 - 

2018-11-02 20:24:15,030 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:24:16,050 - Epoch: [203][   50/  391]    Overall Loss 0.069753    Objective Loss 0.069753    Top1 97.625000    Top5 100.000000    LR 0.004472    Time 0.020348    
2018-11-02 20:24:17,010 - Epoch: [203][  100/  391]    Overall Loss 0.070400    Objective Loss 0.070400    Top1 97.539062    Top5 99.984375    LR 0.004472    Time 0.019769    
2018-11-02 20:24:17,971 - Epoch: [203][  150/  391]    Overall Loss 0.071619    Objective Loss 0.071619    Top1 97.479167    Top5 99.984375    LR 0.004472    Time 0.019580    
2018-11-02 20:24:18,931 - Epoch: [203][  200/  391]    Overall Loss 0.073032    Objective Loss 0.073032    Top1 97.476562    Top5 99.984375    LR 0.004472    Time 0.019478    
2018-11-02 20:24:19,890 - Epoch: [203][  250/  391]    Overall Loss 0.072775    Objective Loss 0.072775    Top1 97.506250    Top5 99.984375    LR 0.004472    Time 0.019415    
2018-11-02 20:24:20,852 - Epoch: [203][  300/  391]    Overall Loss 0.072986    Objective Loss 0.072986    Top1 97.486979    Top5 99.984375    LR 0.004472    Time 0.019369    
2018-11-02 20:24:21,814 - Epoch: [203][  350/  391]    Overall Loss 0.073294    Objective Loss 0.073294    Top1 97.484375    Top5 99.986607    LR 0.004472    Time 0.019348    
2018-11-02 20:24:22,687 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36940 | -0.00361 |    0.22935 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14569 | -0.00147 |    0.09255 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15543 | -0.00629 |    0.11827 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17696 | -0.03134 |    0.13578 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18074 |  0.00072 |    0.14212 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17646 | -0.02845 |    0.13607 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16636 | -0.00611 |    0.11997 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20086 | -0.00107 |    0.14794 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16822 | -0.00495 |    0.12843 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25443 | -0.00424 |    0.17201 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14088 | -0.00230 |    0.10748 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12262 | -0.00957 |    0.09632 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14523 | -0.01651 |    0.11571 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11046 | -0.00310 |    0.08658 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13143 | -0.01455 |    0.10488 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12843 | -0.00145 |    0.10193 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14900 | -0.01172 |    0.11533 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11790 | -0.00804 |    0.09302 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10080 | -0.00675 |    0.07905 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10672 | -0.01265 |    0.08541 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06432 |  0.00376 |    0.04865 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57644 | -0.00001 |    0.45115 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:24:22,688 - Total sparsity: 0.00

2018-11-02 20:24:22,688 - --- validate (epoch=203)-----------
2018-11-02 20:24:22,688 - 10000 samples (128 per mini-batch)
2018-11-02 20:24:23,408 - Epoch: [203][   50/   78]    Loss 0.372555    Top1 90.406250    Top5 99.687500    
2018-11-02 20:24:23,799 - ==> Top1: 90.310    Top5: 99.720    Loss: 0.374

2018-11-02 20:24:23,800 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:24:23,800 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:24:23,807 - 

2018-11-02 20:24:23,807 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:24:24,835 - Epoch: [204][   50/  391]    Overall Loss 0.075567    Objective Loss 0.075567    Top1 97.421875    Top5 100.000000    LR 0.004248    Time 0.020539    
2018-11-02 20:24:25,797 - Epoch: [204][  100/  391]    Overall Loss 0.075808    Objective Loss 0.075808    Top1 97.390625    Top5 99.984375    LR 0.004248    Time 0.019876    
2018-11-02 20:24:26,760 - Epoch: [204][  150/  391]    Overall Loss 0.075167    Objective Loss 0.075167    Top1 97.401042    Top5 99.984375    LR 0.004248    Time 0.019664    
2018-11-02 20:24:27,725 - Epoch: [204][  200/  391]    Overall Loss 0.074393    Objective Loss 0.074393    Top1 97.441406    Top5 99.984375    LR 0.004248    Time 0.019563    
2018-11-02 20:24:28,685 - Epoch: [204][  250/  391]    Overall Loss 0.074044    Objective Loss 0.074044    Top1 97.468750    Top5 99.978125    LR 0.004248    Time 0.019486    
2018-11-02 20:24:29,648 - Epoch: [204][  300/  391]    Overall Loss 0.074236    Objective Loss 0.074236    Top1 97.458333    Top5 99.981771    LR 0.004248    Time 0.019444    
2018-11-02 20:24:30,609 - Epoch: [204][  350/  391]    Overall Loss 0.076130    Objective Loss 0.076130    Top1 97.359375    Top5 99.977679    LR 0.004248    Time 0.019410    
2018-11-02 20:24:31,489 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36886 | -0.00375 |    0.22894 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14548 | -0.00197 |    0.09238 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15521 | -0.00633 |    0.11807 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17668 | -0.03146 |    0.13563 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18048 |  0.00087 |    0.14186 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17619 | -0.02856 |    0.13573 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16613 | -0.00599 |    0.11987 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20057 | -0.00082 |    0.14766 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16798 | -0.00485 |    0.12824 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25405 | -0.00417 |    0.17160 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14069 | -0.00214 |    0.10731 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12245 | -0.00945 |    0.09620 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14503 | -0.01637 |    0.11553 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11030 | -0.00303 |    0.08647 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13124 | -0.01453 |    0.10473 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12825 | -0.00141 |    0.10178 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14879 | -0.01160 |    0.11520 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11774 | -0.00801 |    0.09289 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10066 | -0.00671 |    0.07895 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10658 | -0.01254 |    0.08529 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06423 |  0.00377 |    0.04858 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57662 | -0.00001 |    0.45126 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:24:31,489 - Total sparsity: 0.00

2018-11-02 20:24:31,490 - --- validate (epoch=204)-----------
2018-11-02 20:24:31,490 - 10000 samples (128 per mini-batch)
2018-11-02 20:24:32,205 - Epoch: [204][   50/   78]    Loss 0.373323    Top1 90.171875    Top5 99.640625    
2018-11-02 20:24:32,586 - ==> Top1: 90.140    Top5: 99.690    Loss: 0.376

2018-11-02 20:24:32,587 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:24:32,587 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:24:32,595 - 

2018-11-02 20:24:32,595 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:24:33,614 - Epoch: [205][   50/  391]    Overall Loss 0.074892    Objective Loss 0.074892    Top1 97.312500    Top5 99.968750    LR 0.004036    Time 0.020351    
2018-11-02 20:24:34,576 - Epoch: [205][  100/  391]    Overall Loss 0.071739    Objective Loss 0.071739    Top1 97.492188    Top5 99.984375    LR 0.004036    Time 0.019781    
2018-11-02 20:24:35,537 - Epoch: [205][  150/  391]    Overall Loss 0.071577    Objective Loss 0.071577    Top1 97.562500    Top5 99.979167    LR 0.004036    Time 0.019586    
2018-11-02 20:24:36,499 - Epoch: [205][  200/  391]    Overall Loss 0.071766    Objective Loss 0.071766    Top1 97.578125    Top5 99.984375    LR 0.004036    Time 0.019493    
2018-11-02 20:24:37,463 - Epoch: [205][  250/  391]    Overall Loss 0.072969    Objective Loss 0.072969    Top1 97.518750    Top5 99.981250    LR 0.004036    Time 0.019429    
2018-11-02 20:24:38,453 - Epoch: [205][  300/  391]    Overall Loss 0.074200    Objective Loss 0.074200    Top1 97.484375    Top5 99.981771    LR 0.004036    Time 0.019488    
2018-11-02 20:24:39,416 - Epoch: [205][  350/  391]    Overall Loss 0.073184    Objective Loss 0.073184    Top1 97.517857    Top5 99.984375    LR 0.004036    Time 0.019453    
2018-11-02 20:24:40,287 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36834 | -0.00357 |    0.22866 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14528 | -0.00187 |    0.09226 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15499 | -0.00639 |    0.11796 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17640 | -0.03157 |    0.13544 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18022 |  0.00105 |    0.14163 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17595 | -0.02851 |    0.13559 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16590 | -0.00579 |    0.11970 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20029 | -0.00101 |    0.14737 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16775 | -0.00496 |    0.12810 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25368 | -0.00409 |    0.17123 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14049 | -0.00209 |    0.10721 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12229 | -0.00932 |    0.09610 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14485 | -0.01626 |    0.11538 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11015 | -0.00292 |    0.08632 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13107 | -0.01440 |    0.10456 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12807 | -0.00143 |    0.10165 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14857 | -0.01158 |    0.11505 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11758 | -0.00800 |    0.09277 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10053 | -0.00669 |    0.07884 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10644 | -0.01249 |    0.08517 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06413 |  0.00376 |    0.04852 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57684 | -0.00001 |    0.45146 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:24:40,287 - Total sparsity: 0.00

2018-11-02 20:24:40,287 - --- validate (epoch=205)-----------
2018-11-02 20:24:40,288 - 10000 samples (128 per mini-batch)
2018-11-02 20:24:41,008 - Epoch: [205][   50/   78]    Loss 0.379651    Top1 90.328125    Top5 99.640625    
2018-11-02 20:24:41,399 - ==> Top1: 90.130    Top5: 99.640    Loss: 0.382

2018-11-02 20:24:41,400 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:24:41,400 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:24:41,407 - 

2018-11-02 20:24:41,408 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:24:42,429 - Epoch: [206][   50/  391]    Overall Loss 0.065751    Objective Loss 0.065751    Top1 97.656250    Top5 99.984375    LR 0.003834    Time 0.020390    
2018-11-02 20:24:43,392 - Epoch: [206][  100/  391]    Overall Loss 0.068175    Objective Loss 0.068175    Top1 97.570312    Top5 99.992188    LR 0.003834    Time 0.019814    
2018-11-02 20:24:44,354 - Epoch: [206][  150/  391]    Overall Loss 0.069551    Objective Loss 0.069551    Top1 97.552083    Top5 99.984375    LR 0.003834    Time 0.019617    
2018-11-02 20:24:45,317 - Epoch: [206][  200/  391]    Overall Loss 0.069798    Objective Loss 0.069798    Top1 97.621094    Top5 99.984375    LR 0.003834    Time 0.019522    
2018-11-02 20:24:46,278 - Epoch: [206][  250/  391]    Overall Loss 0.069901    Objective Loss 0.069901    Top1 97.609375    Top5 99.987500    LR 0.003834    Time 0.019459    
2018-11-02 20:24:47,241 - Epoch: [206][  300/  391]    Overall Loss 0.070932    Objective Loss 0.070932    Top1 97.575521    Top5 99.986979    LR 0.003834    Time 0.019420    
2018-11-02 20:24:48,203 - Epoch: [206][  350/  391]    Overall Loss 0.071860    Objective Loss 0.071860    Top1 97.546875    Top5 99.984375    LR 0.003834    Time 0.019389    
2018-11-02 20:24:49,070 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36784 | -0.00360 |    0.22842 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14509 | -0.00173 |    0.09218 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15477 | -0.00677 |    0.11776 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17622 | -0.03123 |    0.13539 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17999 |  0.00089 |    0.14146 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17571 | -0.02859 |    0.13545 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16567 | -0.00602 |    0.11951 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.20002 | -0.00097 |    0.14714 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16752 | -0.00496 |    0.12791 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25334 | -0.00417 |    0.17113 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14032 | -0.00192 |    0.10709 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12212 | -0.00951 |    0.09597 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14465 | -0.01634 |    0.11523 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11001 | -0.00296 |    0.08620 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13089 | -0.01443 |    0.10441 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12790 | -0.00153 |    0.10152 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14838 | -0.01151 |    0.11486 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11743 | -0.00794 |    0.09264 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10040 | -0.00664 |    0.07874 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10630 | -0.01251 |    0.08507 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06405 |  0.00372 |    0.04845 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57706 | -0.00001 |    0.45161 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:24:49,071 - Total sparsity: 0.00

2018-11-02 20:24:49,071 - --- validate (epoch=206)-----------
2018-11-02 20:24:49,071 - 10000 samples (128 per mini-batch)
2018-11-02 20:24:49,793 - Epoch: [206][   50/   78]    Loss 0.371366    Top1 90.343750    Top5 99.687500    
2018-11-02 20:24:50,189 - ==> Top1: 90.210    Top5: 99.720    Loss: 0.371

2018-11-02 20:24:50,190 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:24:50,191 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:24:50,200 - 

2018-11-02 20:24:50,201 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:24:51,219 - Epoch: [207][   50/  391]    Overall Loss 0.077956    Objective Loss 0.077956    Top1 97.093750    Top5 99.984375    LR 0.003642    Time 0.020337    
2018-11-02 20:24:52,179 - Epoch: [207][  100/  391]    Overall Loss 0.070965    Objective Loss 0.070965    Top1 97.414062    Top5 99.992188    LR 0.003642    Time 0.019756    
2018-11-02 20:24:53,143 - Epoch: [207][  150/  391]    Overall Loss 0.071275    Objective Loss 0.071275    Top1 97.473958    Top5 99.994792    LR 0.003642    Time 0.019586    
2018-11-02 20:24:54,106 - Epoch: [207][  200/  391]    Overall Loss 0.070898    Objective Loss 0.070898    Top1 97.554688    Top5 99.992188    LR 0.003642    Time 0.019499    
2018-11-02 20:24:55,067 - Epoch: [207][  250/  391]    Overall Loss 0.071794    Objective Loss 0.071794    Top1 97.456250    Top5 99.993750    LR 0.003642    Time 0.019438    
2018-11-02 20:24:56,031 - Epoch: [207][  300/  391]    Overall Loss 0.073105    Objective Loss 0.073105    Top1 97.427083    Top5 99.992188    LR 0.003642    Time 0.019404    
2018-11-02 20:24:56,990 - Epoch: [207][  350/  391]    Overall Loss 0.073317    Objective Loss 0.073317    Top1 97.426339    Top5 99.991071    LR 0.003642    Time 0.019369    
2018-11-02 20:24:57,862 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36738 | -0.00239 |    0.22798 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14491 | -0.00170 |    0.09210 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15458 | -0.00660 |    0.11760 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17599 | -0.03124 |    0.13522 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17976 |  0.00118 |    0.14124 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17548 | -0.02857 |    0.13525 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16547 | -0.00596 |    0.11934 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19977 | -0.00104 |    0.14699 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16731 | -0.00494 |    0.12776 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25301 | -0.00408 |    0.17094 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14014 | -0.00179 |    0.10693 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12197 | -0.00941 |    0.09585 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14447 | -0.01629 |    0.11510 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10987 | -0.00303 |    0.08611 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13072 | -0.01443 |    0.10427 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12774 | -0.00147 |    0.10139 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14818 | -0.01148 |    0.11472 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11728 | -0.00792 |    0.09253 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10028 | -0.00664 |    0.07865 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10617 | -0.01250 |    0.08496 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06396 |  0.00374 |    0.04839 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57722 | -0.00001 |    0.45174 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:24:57,862 - Total sparsity: 0.00

2018-11-02 20:24:57,862 - --- validate (epoch=207)-----------
2018-11-02 20:24:57,862 - 10000 samples (128 per mini-batch)
2018-11-02 20:24:58,585 - Epoch: [207][   50/   78]    Loss 0.378927    Top1 90.531250    Top5 99.625000    
2018-11-02 20:24:58,979 - ==> Top1: 90.290    Top5: 99.640    Loss: 0.375

2018-11-02 20:24:58,980 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:24:58,980 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:24:58,991 - 

2018-11-02 20:24:58,992 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:25:00,010 - Epoch: [208][   50/  391]    Overall Loss 0.069557    Objective Loss 0.069557    Top1 97.765625    Top5 100.000000    LR 0.003460    Time 0.020329    
2018-11-02 20:25:00,973 - Epoch: [208][  100/  391]    Overall Loss 0.069134    Objective Loss 0.069134    Top1 97.796875    Top5 100.000000    LR 0.003460    Time 0.019784    
2018-11-02 20:25:01,931 - Epoch: [208][  150/  391]    Overall Loss 0.067771    Objective Loss 0.067771    Top1 97.750000    Top5 99.994792    LR 0.003460    Time 0.019569    
2018-11-02 20:25:02,892 - Epoch: [208][  200/  391]    Overall Loss 0.068899    Objective Loss 0.068899    Top1 97.640625    Top5 99.996094    LR 0.003460    Time 0.019475    
2018-11-02 20:25:03,852 - Epoch: [208][  250/  391]    Overall Loss 0.069502    Objective Loss 0.069502    Top1 97.609375    Top5 99.996875    LR 0.003460    Time 0.019416    
2018-11-02 20:25:04,812 - Epoch: [208][  300/  391]    Overall Loss 0.070593    Objective Loss 0.070593    Top1 97.544271    Top5 99.992188    LR 0.003460    Time 0.019374    
2018-11-02 20:25:05,773 - Epoch: [208][  350/  391]    Overall Loss 0.070066    Objective Loss 0.070066    Top1 97.551339    Top5 99.993304    LR 0.003460    Time 0.019350    
2018-11-02 20:25:06,640 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36693 | -0.00268 |    0.22785 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14474 | -0.00173 |    0.09196 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15440 | -0.00652 |    0.11752 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17582 | -0.03102 |    0.13496 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17954 |  0.00091 |    0.14115 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17526 | -0.02865 |    0.13503 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16527 | -0.00585 |    0.11917 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19952 | -0.00126 |    0.14685 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16711 | -0.00501 |    0.12758 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25269 | -0.00406 |    0.17091 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13998 | -0.00181 |    0.10681 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12183 | -0.00936 |    0.09571 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14431 | -0.01622 |    0.11498 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10975 | -0.00291 |    0.08601 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13056 | -0.01441 |    0.10413 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12759 | -0.00148 |    0.10128 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14800 | -0.01144 |    0.11456 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11714 | -0.00800 |    0.09244 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10017 | -0.00664 |    0.07856 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10604 | -0.01251 |    0.08487 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06388 |  0.00373 |    0.04833 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57741 | -0.00001 |    0.45192 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:25:06,641 - Total sparsity: 0.00

2018-11-02 20:25:06,641 - --- validate (epoch=208)-----------
2018-11-02 20:25:06,641 - 10000 samples (128 per mini-batch)
2018-11-02 20:25:07,365 - Epoch: [208][   50/   78]    Loss 0.383550    Top1 90.031250    Top5 99.687500    
2018-11-02 20:25:07,756 - ==> Top1: 90.040    Top5: 99.700    Loss: 0.380

2018-11-02 20:25:07,757 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:25:07,757 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:25:07,765 - 

2018-11-02 20:25:07,765 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:25:08,786 - Epoch: [209][   50/  391]    Overall Loss 0.066078    Objective Loss 0.066078    Top1 97.843750    Top5 99.984375    LR 0.003287    Time 0.020385    
2018-11-02 20:25:09,758 - Epoch: [209][  100/  391]    Overall Loss 0.068642    Objective Loss 0.068642    Top1 97.687500    Top5 99.984375    LR 0.003287    Time 0.019903    
2018-11-02 20:25:10,719 - Epoch: [209][  150/  391]    Overall Loss 0.070020    Objective Loss 0.070020    Top1 97.630208    Top5 99.984375    LR 0.003287    Time 0.019663    
2018-11-02 20:25:11,680 - Epoch: [209][  200/  391]    Overall Loss 0.069598    Objective Loss 0.069598    Top1 97.605469    Top5 99.984375    LR 0.003287    Time 0.019548    
2018-11-02 20:25:12,640 - Epoch: [209][  250/  391]    Overall Loss 0.070283    Objective Loss 0.070283    Top1 97.584375    Top5 99.984375    LR 0.003287    Time 0.019474    
2018-11-02 20:25:13,604 - Epoch: [209][  300/  391]    Overall Loss 0.070831    Objective Loss 0.070831    Top1 97.583333    Top5 99.986979    LR 0.003287    Time 0.019437    
2018-11-02 20:25:14,566 - Epoch: [209][  350/  391]    Overall Loss 0.070717    Objective Loss 0.070717    Top1 97.582589    Top5 99.988839    LR 0.003287    Time 0.019406    
2018-11-02 20:25:15,435 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36649 | -0.00312 |    0.22759 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14457 | -0.00175 |    0.09188 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15422 | -0.00657 |    0.11736 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17558 | -0.03119 |    0.13488 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17933 |  0.00104 |    0.14094 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17506 | -0.02863 |    0.13491 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16508 | -0.00594 |    0.11908 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19929 | -0.00135 |    0.14675 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16691 | -0.00505 |    0.12743 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25239 | -0.00413 |    0.17062 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13982 | -0.00186 |    0.10667 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12169 | -0.00936 |    0.09561 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14415 | -0.01616 |    0.11484 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10962 | -0.00289 |    0.08591 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13041 | -0.01439 |    0.10402 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12744 | -0.00151 |    0.10116 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14783 | -0.01139 |    0.11439 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11701 | -0.00793 |    0.09233 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10005 | -0.00666 |    0.07847 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10592 | -0.01251 |    0.08476 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06381 |  0.00371 |    0.04828 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57761 | -0.00001 |    0.45208 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:25:15,435 - Total sparsity: 0.00

2018-11-02 20:25:15,435 - --- validate (epoch=209)-----------
2018-11-02 20:25:15,436 - 10000 samples (128 per mini-batch)
2018-11-02 20:25:16,155 - Epoch: [209][   50/   78]    Loss 0.373614    Top1 90.531250    Top5 99.703125    
2018-11-02 20:25:16,545 - ==> Top1: 90.310    Top5: 99.720    Loss: 0.378

2018-11-02 20:25:16,546 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:25:16,546 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:25:16,552 - 

2018-11-02 20:25:16,553 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:25:17,568 - Epoch: [210][   50/  391]    Overall Loss 0.066826    Objective Loss 0.066826    Top1 97.625000    Top5 99.984375    LR 0.003123    Time 0.020278    
2018-11-02 20:25:18,531 - Epoch: [210][  100/  391]    Overall Loss 0.066937    Objective Loss 0.066937    Top1 97.671875    Top5 99.984375    LR 0.003123    Time 0.019757    
2018-11-02 20:25:19,494 - Epoch: [210][  150/  391]    Overall Loss 0.068095    Objective Loss 0.068095    Top1 97.625000    Top5 99.984375    LR 0.003123    Time 0.019584    
2018-11-02 20:25:20,457 - Epoch: [210][  200/  391]    Overall Loss 0.068185    Objective Loss 0.068185    Top1 97.621094    Top5 99.988281    LR 0.003123    Time 0.019495    
2018-11-02 20:25:21,425 - Epoch: [210][  250/  391]    Overall Loss 0.068946    Objective Loss 0.068946    Top1 97.609375    Top5 99.990625    LR 0.003123    Time 0.019464    
2018-11-02 20:25:22,473 - Epoch: [210][  300/  391]    Overall Loss 0.069197    Objective Loss 0.069197    Top1 97.606771    Top5 99.989583    LR 0.003123    Time 0.019707    
2018-11-02 20:25:23,517 - Epoch: [210][  350/  391]    Overall Loss 0.070051    Objective Loss 0.070051    Top1 97.571429    Top5 99.988839    LR 0.003123    Time 0.019873    
2018-11-02 20:25:24,451 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36608 | -0.00353 |    0.22738 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14441 | -0.00168 |    0.09180 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15406 | -0.00637 |    0.11718 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17535 | -0.03135 |    0.13469 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17913 |  0.00079 |    0.14078 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17488 | -0.02855 |    0.13467 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16490 | -0.00571 |    0.11901 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19907 | -0.00134 |    0.14653 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16672 | -0.00514 |    0.12730 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25210 | -0.00412 |    0.17056 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13967 | -0.00190 |    0.10657 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12155 | -0.00942 |    0.09552 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14400 | -0.01604 |    0.11473 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10950 | -0.00293 |    0.08582 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13026 | -0.01436 |    0.10391 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12730 | -0.00152 |    0.10105 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14766 | -0.01141 |    0.11430 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11688 | -0.00794 |    0.09224 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09995 | -0.00657 |    0.07840 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10580 | -0.01253 |    0.08468 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06373 |  0.00368 |    0.04823 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57780 | -0.00001 |    0.45223 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:25:24,451 - Total sparsity: 0.00

2018-11-02 20:25:24,451 - --- validate (epoch=210)-----------
2018-11-02 20:25:24,452 - 10000 samples (128 per mini-batch)
2018-11-02 20:25:25,177 - Epoch: [210][   50/   78]    Loss 0.380652    Top1 90.281250    Top5 99.671875    
2018-11-02 20:25:25,571 - ==> Top1: 90.140    Top5: 99.670    Loss: 0.379

2018-11-02 20:25:25,572 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:25:25,572 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:25:25,583 - 

2018-11-02 20:25:25,583 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:25:26,635 - Epoch: [211][   50/  391]    Overall Loss 0.067791    Objective Loss 0.067791    Top1 97.734375    Top5 99.984375    LR 0.002967    Time 0.021004    
2018-11-02 20:25:27,595 - Epoch: [211][  100/  391]    Overall Loss 0.067097    Objective Loss 0.067097    Top1 97.781250    Top5 99.984375    LR 0.002967    Time 0.020090    
2018-11-02 20:25:28,558 - Epoch: [211][  150/  391]    Overall Loss 0.066476    Objective Loss 0.066476    Top1 97.708333    Top5 99.989583    LR 0.002967    Time 0.019806    
2018-11-02 20:25:29,520 - Epoch: [211][  200/  391]    Overall Loss 0.067052    Objective Loss 0.067052    Top1 97.742188    Top5 99.988281    LR 0.002967    Time 0.019656    
2018-11-02 20:25:30,482 - Epoch: [211][  250/  391]    Overall Loss 0.066076    Objective Loss 0.066076    Top1 97.737500    Top5 99.987500    LR 0.002967    Time 0.019569    
2018-11-02 20:25:31,443 - Epoch: [211][  300/  391]    Overall Loss 0.066447    Objective Loss 0.066447    Top1 97.729167    Top5 99.989583    LR 0.002967    Time 0.019506    
2018-11-02 20:25:32,409 - Epoch: [211][  350/  391]    Overall Loss 0.066495    Objective Loss 0.066495    Top1 97.736607    Top5 99.988839    LR 0.002967    Time 0.019477    
2018-11-02 20:25:33,276 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36569 | -0.00361 |    0.22710 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14426 | -0.00175 |    0.09175 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15390 | -0.00630 |    0.11703 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17518 | -0.03126 |    0.13457 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17894 |  0.00106 |    0.14069 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17471 | -0.02845 |    0.13450 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16472 | -0.00577 |    0.11882 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19886 | -0.00139 |    0.14641 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16655 | -0.00507 |    0.12719 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25184 | -0.00387 |    0.17019 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13952 | -0.00192 |    0.10643 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12143 | -0.00937 |    0.09544 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14385 | -0.01600 |    0.11461 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10939 | -0.00296 |    0.08576 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13013 | -0.01432 |    0.10380 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12717 | -0.00148 |    0.10093 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14750 | -0.01136 |    0.11416 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11676 | -0.00792 |    0.09213 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09985 | -0.00654 |    0.07831 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10569 | -0.01256 |    0.08460 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06367 |  0.00366 |    0.04818 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57804 | -0.00001 |    0.45241 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:25:33,276 - Total sparsity: 0.00

2018-11-02 20:25:33,276 - --- validate (epoch=211)-----------
2018-11-02 20:25:33,276 - 10000 samples (128 per mini-batch)
2018-11-02 20:25:33,993 - Epoch: [211][   50/   78]    Loss 0.381022    Top1 90.390625    Top5 99.687500    
2018-11-02 20:25:34,383 - ==> Top1: 90.260    Top5: 99.710    Loss: 0.379

2018-11-02 20:25:34,383 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:25:34,384 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:25:34,394 - 

2018-11-02 20:25:34,394 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:25:35,416 - Epoch: [212][   50/  391]    Overall Loss 0.064031    Objective Loss 0.064031    Top1 97.828125    Top5 99.984375    LR 0.002818    Time 0.020391    
2018-11-02 20:25:36,378 - Epoch: [212][  100/  391]    Overall Loss 0.062603    Objective Loss 0.062603    Top1 97.851562    Top5 99.992188    LR 0.002818    Time 0.019801    
2018-11-02 20:25:37,340 - Epoch: [212][  150/  391]    Overall Loss 0.064991    Objective Loss 0.064991    Top1 97.687500    Top5 99.994792    LR 0.002818    Time 0.019606    
2018-11-02 20:25:38,300 - Epoch: [212][  200/  391]    Overall Loss 0.067271    Objective Loss 0.067271    Top1 97.613281    Top5 99.996094    LR 0.002818    Time 0.019500    
2018-11-02 20:25:39,260 - Epoch: [212][  250/  391]    Overall Loss 0.067194    Objective Loss 0.067194    Top1 97.612500    Top5 99.993750    LR 0.002818    Time 0.019432    
2018-11-02 20:25:40,222 - Epoch: [212][  300/  391]    Overall Loss 0.068398    Objective Loss 0.068398    Top1 97.604167    Top5 99.992188    LR 0.002818    Time 0.019396    
2018-11-02 20:25:41,181 - Epoch: [212][  350/  391]    Overall Loss 0.068791    Objective Loss 0.068791    Top1 97.582589    Top5 99.991071    LR 0.002818    Time 0.019362    
2018-11-02 20:25:42,046 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36532 | -0.00339 |    0.22690 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14412 | -0.00164 |    0.09169 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15374 | -0.00651 |    0.11690 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17504 | -0.03102 |    0.13437 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17876 |  0.00118 |    0.14046 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17452 | -0.02849 |    0.13437 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16456 | -0.00566 |    0.11867 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19866 | -0.00133 |    0.14630 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16639 | -0.00499 |    0.12705 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25158 | -0.00384 |    0.17007 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13939 | -0.00184 |    0.10634 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12132 | -0.00927 |    0.09534 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14371 | -0.01599 |    0.11450 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10928 | -0.00297 |    0.08567 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13000 | -0.01429 |    0.10372 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12705 | -0.00142 |    0.10084 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14735 | -0.01131 |    0.11402 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11664 | -0.00791 |    0.09205 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09976 | -0.00648 |    0.07824 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10559 | -0.01254 |    0.08451 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06360 |  0.00366 |    0.04813 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57817 | -0.00001 |    0.45254 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:25:42,047 - Total sparsity: 0.00

2018-11-02 20:25:42,047 - --- validate (epoch=212)-----------
2018-11-02 20:25:42,047 - 10000 samples (128 per mini-batch)
2018-11-02 20:25:42,763 - Epoch: [212][   50/   78]    Loss 0.379163    Top1 90.500000    Top5 99.687500    
2018-11-02 20:25:43,147 - ==> Top1: 90.290    Top5: 99.690    Loss: 0.380

2018-11-02 20:25:43,148 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:25:43,148 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:25:43,158 - 

2018-11-02 20:25:43,159 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:25:44,177 - Epoch: [213][   50/  391]    Overall Loss 0.055645    Objective Loss 0.055645    Top1 98.187500    Top5 100.000000    LR 0.002677    Time 0.020339    
2018-11-02 20:25:45,138 - Epoch: [213][  100/  391]    Overall Loss 0.061855    Objective Loss 0.061855    Top1 97.882812    Top5 100.000000    LR 0.002677    Time 0.019764    
2018-11-02 20:25:46,101 - Epoch: [213][  150/  391]    Overall Loss 0.062263    Objective Loss 0.062263    Top1 97.822917    Top5 100.000000    LR 0.002677    Time 0.019590    
2018-11-02 20:25:47,061 - Epoch: [213][  200/  391]    Overall Loss 0.064340    Objective Loss 0.064340    Top1 97.761719    Top5 100.000000    LR 0.002677    Time 0.019485    
2018-11-02 20:25:48,022 - Epoch: [213][  250/  391]    Overall Loss 0.064392    Objective Loss 0.064392    Top1 97.800000    Top5 100.000000    LR 0.002677    Time 0.019427    
2018-11-02 20:25:48,984 - Epoch: [213][  300/  391]    Overall Loss 0.064868    Objective Loss 0.064868    Top1 97.812500    Top5 99.997396    LR 0.002677    Time 0.019393    
2018-11-02 20:25:49,945 - Epoch: [213][  350/  391]    Overall Loss 0.063992    Objective Loss 0.063992    Top1 97.859375    Top5 99.995536    LR 0.002677    Time 0.019364    
2018-11-02 20:25:50,816 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36496 | -0.00285 |    0.22649 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14398 | -0.00165 |    0.09160 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15359 | -0.00664 |    0.11680 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17488 | -0.03093 |    0.13425 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17859 |  0.00102 |    0.14038 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17437 | -0.02837 |    0.13425 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16440 | -0.00574 |    0.11856 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19846 | -0.00139 |    0.14615 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16622 | -0.00501 |    0.12694 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25133 | -0.00373 |    0.16987 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13925 | -0.00177 |    0.10624 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12120 | -0.00922 |    0.09524 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14358 | -0.01591 |    0.11441 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10918 | -0.00291 |    0.08560 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12988 | -0.01421 |    0.10362 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12693 | -0.00139 |    0.10074 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14720 | -0.01128 |    0.11391 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11654 | -0.00782 |    0.09195 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09966 | -0.00647 |    0.07816 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10549 | -0.01254 |    0.08444 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06354 |  0.00366 |    0.04808 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57835 | -0.00001 |    0.45268 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:25:50,816 - Total sparsity: 0.00

2018-11-02 20:25:50,816 - --- validate (epoch=213)-----------
2018-11-02 20:25:50,816 - 10000 samples (128 per mini-batch)
2018-11-02 20:25:51,537 - Epoch: [213][   50/   78]    Loss 0.376504    Top1 90.343750    Top5 99.703125    
2018-11-02 20:25:51,923 - ==> Top1: 90.140    Top5: 99.740    Loss: 0.380

2018-11-02 20:25:51,924 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:25:51,924 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:25:51,934 - 

2018-11-02 20:25:51,935 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:25:52,956 - Epoch: [214][   50/  391]    Overall Loss 0.063588    Objective Loss 0.063588    Top1 97.906250    Top5 100.000000    LR 0.002543    Time 0.020376    
2018-11-02 20:25:53,916 - Epoch: [214][  100/  391]    Overall Loss 0.066473    Objective Loss 0.066473    Top1 97.843750    Top5 100.000000    LR 0.002543    Time 0.019779    
2018-11-02 20:25:54,877 - Epoch: [214][  150/  391]    Overall Loss 0.066743    Objective Loss 0.066743    Top1 97.828125    Top5 99.994792    LR 0.002543    Time 0.019583    
2018-11-02 20:25:55,839 - Epoch: [214][  200/  391]    Overall Loss 0.065471    Objective Loss 0.065471    Top1 97.882812    Top5 99.996094    LR 0.002543    Time 0.019493    
2018-11-02 20:25:56,800 - Epoch: [214][  250/  391]    Overall Loss 0.065670    Objective Loss 0.065670    Top1 97.837500    Top5 99.993750    LR 0.002543    Time 0.019420    
2018-11-02 20:25:57,761 - Epoch: [214][  300/  391]    Overall Loss 0.064657    Objective Loss 0.064657    Top1 97.893229    Top5 99.992188    LR 0.002543    Time 0.019379    
2018-11-02 20:25:58,722 - Epoch: [214][  350/  391]    Overall Loss 0.065379    Objective Loss 0.065379    Top1 97.823661    Top5 99.993304    LR 0.002543    Time 0.019354    
2018-11-02 20:25:59,593 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36463 | -0.00276 |    0.22626 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14385 | -0.00177 |    0.09149 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15345 | -0.00657 |    0.11673 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17471 | -0.03098 |    0.13409 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17843 |  0.00086 |    0.14024 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17421 | -0.02835 |    0.13412 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16424 | -0.00584 |    0.11847 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19828 | -0.00132 |    0.14600 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16607 | -0.00496 |    0.12681 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25109 | -0.00382 |    0.16960 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13913 | -0.00175 |    0.10613 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12109 | -0.00932 |    0.09515 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14346 | -0.01586 |    0.11429 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10908 | -0.00292 |    0.08551 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12976 | -0.01420 |    0.10351 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12681 | -0.00139 |    0.10066 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14707 | -0.01121 |    0.11381 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11644 | -0.00780 |    0.09188 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09957 | -0.00646 |    0.07809 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10539 | -0.01255 |    0.08437 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06348 |  0.00365 |    0.04803 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57849 | -0.00001 |    0.45281 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:25:59,594 - Total sparsity: 0.00

2018-11-02 20:25:59,594 - --- validate (epoch=214)-----------
2018-11-02 20:25:59,594 - 10000 samples (128 per mini-batch)
2018-11-02 20:26:00,317 - Epoch: [214][   50/   78]    Loss 0.378122    Top1 90.421875    Top5 99.625000    
2018-11-02 20:26:00,709 - ==> Top1: 90.180    Top5: 99.670    Loss: 0.381

2018-11-02 20:26:00,710 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:26:00,710 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:26:00,721 - 

2018-11-02 20:26:00,721 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:26:01,740 - Epoch: [215][   50/  391]    Overall Loss 0.066648    Objective Loss 0.066648    Top1 97.578125    Top5 99.984375    LR 0.002416    Time 0.020342    
2018-11-02 20:26:02,703 - Epoch: [215][  100/  391]    Overall Loss 0.066297    Objective Loss 0.066297    Top1 97.718750    Top5 99.992188    LR 0.002416    Time 0.019783    
2018-11-02 20:26:03,664 - Epoch: [215][  150/  391]    Overall Loss 0.064563    Objective Loss 0.064563    Top1 97.807292    Top5 99.989583    LR 0.002416    Time 0.019588    
2018-11-02 20:26:04,629 - Epoch: [215][  200/  391]    Overall Loss 0.064032    Objective Loss 0.064032    Top1 97.804688    Top5 99.992188    LR 0.002416    Time 0.019514    
2018-11-02 20:26:05,591 - Epoch: [215][  250/  391]    Overall Loss 0.063510    Objective Loss 0.063510    Top1 97.821875    Top5 99.993750    LR 0.002416    Time 0.019455    
2018-11-02 20:26:06,553 - Epoch: [215][  300/  391]    Overall Loss 0.064889    Objective Loss 0.064889    Top1 97.781250    Top5 99.992188    LR 0.002416    Time 0.019413    
2018-11-02 20:26:07,513 - Epoch: [215][  350/  391]    Overall Loss 0.064078    Objective Loss 0.064078    Top1 97.808036    Top5 99.993304    LR 0.002416    Time 0.019380    
2018-11-02 20:26:08,382 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36430 | -0.00295 |    0.22602 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14373 | -0.00165 |    0.09138 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15331 | -0.00669 |    0.11664 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17454 | -0.03104 |    0.13394 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17827 |  0.00069 |    0.14010 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17403 | -0.02855 |    0.13402 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16410 | -0.00577 |    0.11838 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19811 | -0.00132 |    0.14593 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16593 | -0.00496 |    0.12669 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25087 | -0.00388 |    0.16953 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13901 | -0.00171 |    0.10606 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12098 | -0.00931 |    0.09504 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14334 | -0.01576 |    0.11415 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10898 | -0.00289 |    0.08546 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12965 | -0.01415 |    0.10341 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12670 | -0.00144 |    0.10057 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14694 | -0.01117 |    0.11372 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11634 | -0.00777 |    0.09179 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09949 | -0.00643 |    0.07802 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10529 | -0.01257 |    0.08431 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06342 |  0.00365 |    0.04799 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57863 | -0.00001 |    0.45292 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:26:08,382 - Total sparsity: 0.00

2018-11-02 20:26:08,382 - --- validate (epoch=215)-----------
2018-11-02 20:26:08,382 - 10000 samples (128 per mini-batch)
2018-11-02 20:26:09,099 - Epoch: [215][   50/   78]    Loss 0.376532    Top1 90.453125    Top5 99.640625    
2018-11-02 20:26:09,490 - ==> Top1: 90.240    Top5: 99.660    Loss: 0.380

2018-11-02 20:26:09,491 - ==> Best Top1: 90.330   On Epoch: 195

2018-11-02 20:26:09,491 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:26:09,499 - 

2018-11-02 20:26:09,499 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:26:10,516 - Epoch: [216][   50/  391]    Overall Loss 0.064691    Objective Loss 0.064691    Top1 97.937500    Top5 100.000000    LR 0.002295    Time 0.020319    
2018-11-02 20:26:11,480 - Epoch: [216][  100/  391]    Overall Loss 0.064757    Objective Loss 0.064757    Top1 97.929688    Top5 99.992188    LR 0.002295    Time 0.019781    
2018-11-02 20:26:12,443 - Epoch: [216][  150/  391]    Overall Loss 0.064227    Objective Loss 0.064227    Top1 97.937500    Top5 99.994792    LR 0.002295    Time 0.019603    
2018-11-02 20:26:13,406 - Epoch: [216][  200/  391]    Overall Loss 0.064435    Objective Loss 0.064435    Top1 97.906250    Top5 99.992188    LR 0.002295    Time 0.019510    
2018-11-02 20:26:14,366 - Epoch: [216][  250/  391]    Overall Loss 0.063696    Objective Loss 0.063696    Top1 97.918750    Top5 99.993750    LR 0.002295    Time 0.019446    
2018-11-02 20:26:15,325 - Epoch: [216][  300/  391]    Overall Loss 0.064617    Objective Loss 0.064617    Top1 97.864583    Top5 99.992188    LR 0.002295    Time 0.019396    
2018-11-02 20:26:16,327 - Epoch: [216][  350/  391]    Overall Loss 0.065265    Objective Loss 0.065265    Top1 97.823661    Top5 99.993304    LR 0.002295    Time 0.019486    
2018-11-02 20:26:17,234 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36399 | -0.00335 |    0.22591 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14361 | -0.00164 |    0.09126 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15318 | -0.00677 |    0.11655 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17437 | -0.03115 |    0.13385 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17812 |  0.00079 |    0.14000 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17389 | -0.02846 |    0.13402 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16396 | -0.00582 |    0.11828 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19794 | -0.00117 |    0.14575 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16579 | -0.00503 |    0.12659 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25065 | -0.00393 |    0.16931 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13890 | -0.00166 |    0.10598 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12088 | -0.00935 |    0.09496 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14322 | -0.01577 |    0.11404 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10889 | -0.00292 |    0.08540 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12954 | -0.01411 |    0.10333 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12659 | -0.00140 |    0.10048 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14682 | -0.01115 |    0.11363 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11624 | -0.00779 |    0.09172 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09941 | -0.00646 |    0.07797 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10521 | -0.01257 |    0.08423 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06337 |  0.00365 |    0.04795 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57875 | -0.00001 |    0.45302 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:26:17,234 - Total sparsity: 0.00

2018-11-02 20:26:17,235 - --- validate (epoch=216)-----------
2018-11-02 20:26:17,235 - 10000 samples (128 per mini-batch)
2018-11-02 20:26:17,951 - Epoch: [216][   50/   78]    Loss 0.373697    Top1 90.562500    Top5 99.640625    
2018-11-02 20:26:18,335 - ==> Top1: 90.370    Top5: 99.690    Loss: 0.375

2018-11-02 20:26:18,335 - ==> Best Top1: 90.370   On Epoch: 216

2018-11-02 20:26:18,335 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:26:18,348 - 

2018-11-02 20:26:18,349 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:26:19,407 - Epoch: [217][   50/  391]    Overall Loss 0.061087    Objective Loss 0.061087    Top1 98.015625    Top5 99.984375    LR 0.002181    Time 0.021128    
2018-11-02 20:26:20,369 - Epoch: [217][  100/  391]    Overall Loss 0.060907    Objective Loss 0.060907    Top1 98.023438    Top5 99.992188    LR 0.002181    Time 0.020172    
2018-11-02 20:26:21,329 - Epoch: [217][  150/  391]    Overall Loss 0.062609    Objective Loss 0.062609    Top1 97.968750    Top5 99.994792    LR 0.002181    Time 0.019840    
2018-11-02 20:26:22,294 - Epoch: [217][  200/  391]    Overall Loss 0.063419    Objective Loss 0.063419    Top1 97.917969    Top5 99.992188    LR 0.002181    Time 0.019698    
2018-11-02 20:26:23,286 - Epoch: [217][  250/  391]    Overall Loss 0.064366    Objective Loss 0.064366    Top1 97.878125    Top5 99.990625    LR 0.002181    Time 0.019721    
2018-11-02 20:26:24,320 - Epoch: [217][  300/  391]    Overall Loss 0.063860    Objective Loss 0.063860    Top1 97.906250    Top5 99.992188    LR 0.002181    Time 0.019878    
2018-11-02 20:26:25,344 - Epoch: [217][  350/  391]    Overall Loss 0.064335    Objective Loss 0.064335    Top1 97.857143    Top5 99.991071    LR 0.002181    Time 0.019962    
2018-11-02 20:26:26,258 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36370 | -0.00351 |    0.22578 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14349 | -0.00169 |    0.09123 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15306 | -0.00675 |    0.11645 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17426 | -0.03098 |    0.13373 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17798 |  0.00076 |    0.13995 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17377 | -0.02837 |    0.13383 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16383 | -0.00589 |    0.11824 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19779 | -0.00110 |    0.14568 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16566 | -0.00494 |    0.12648 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25045 | -0.00391 |    0.16912 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13879 | -0.00160 |    0.10587 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12078 | -0.00933 |    0.09489 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14311 | -0.01570 |    0.11397 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10881 | -0.00291 |    0.08535 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12944 | -0.01409 |    0.10325 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12649 | -0.00142 |    0.10040 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14670 | -0.01112 |    0.11352 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11615 | -0.00775 |    0.09165 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09933 | -0.00643 |    0.07791 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10512 | -0.01257 |    0.08416 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06331 |  0.00364 |    0.04791 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57887 | -0.00001 |    0.45312 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:26:26,258 - Total sparsity: 0.00

2018-11-02 20:26:26,259 - --- validate (epoch=217)-----------
2018-11-02 20:26:26,259 - 10000 samples (128 per mini-batch)
2018-11-02 20:26:26,980 - Epoch: [217][   50/   78]    Loss 0.374532    Top1 90.609375    Top5 99.656250    
2018-11-02 20:26:27,375 - ==> Top1: 90.400    Top5: 99.680    Loss: 0.379

2018-11-02 20:26:27,376 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:26:27,376 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:26:27,393 - 

2018-11-02 20:26:27,393 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:26:28,385 - Epoch: [218][   50/  391]    Overall Loss 0.065150    Objective Loss 0.065150    Top1 97.562500    Top5 100.000000    LR 0.002072    Time 0.019797    
2018-11-02 20:26:29,346 - Epoch: [218][  100/  391]    Overall Loss 0.064979    Objective Loss 0.064979    Top1 97.703125    Top5 99.984375    LR 0.002072    Time 0.019500    
2018-11-02 20:26:30,308 - Epoch: [218][  150/  391]    Overall Loss 0.064353    Objective Loss 0.064353    Top1 97.776042    Top5 99.989583    LR 0.002072    Time 0.019406    
2018-11-02 20:26:31,268 - Epoch: [218][  200/  391]    Overall Loss 0.065124    Objective Loss 0.065124    Top1 97.789062    Top5 99.992188    LR 0.002072    Time 0.019351    
2018-11-02 20:26:32,229 - Epoch: [218][  250/  391]    Overall Loss 0.064880    Objective Loss 0.064880    Top1 97.825000    Top5 99.993750    LR 0.002072    Time 0.019319    
2018-11-02 20:26:33,188 - Epoch: [218][  300/  391]    Overall Loss 0.064387    Objective Loss 0.064387    Top1 97.835938    Top5 99.994792    LR 0.002072    Time 0.019289    
2018-11-02 20:26:34,148 - Epoch: [218][  350/  391]    Overall Loss 0.064943    Objective Loss 0.064943    Top1 97.812500    Top5 99.995536    LR 0.002072    Time 0.019273    
2018-11-02 20:26:35,017 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36342 | -0.00310 |    0.22540 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14338 | -0.00183 |    0.09116 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15295 | -0.00660 |    0.11640 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17411 | -0.03105 |    0.13365 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17784 |  0.00089 |    0.13984 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17363 | -0.02840 |    0.13376 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16371 | -0.00594 |    0.11812 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19763 | -0.00121 |    0.14554 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16553 | -0.00499 |    0.12642 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25026 | -0.00377 |    0.16914 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13868 | -0.00177 |    0.10580 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12070 | -0.00924 |    0.09478 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14300 | -0.01576 |    0.11388 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10873 | -0.00292 |    0.08529 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12935 | -0.01404 |    0.10318 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12640 | -0.00140 |    0.10032 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14659 | -0.01111 |    0.11344 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11606 | -0.00772 |    0.09158 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09926 | -0.00643 |    0.07785 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10504 | -0.01258 |    0.08411 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06327 |  0.00365 |    0.04787 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57898 | -0.00001 |    0.45322 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:26:35,018 - Total sparsity: 0.00

2018-11-02 20:26:35,018 - --- validate (epoch=218)-----------
2018-11-02 20:26:35,018 - 10000 samples (128 per mini-batch)
2018-11-02 20:26:35,725 - Epoch: [218][   50/   78]    Loss 0.378826    Top1 90.500000    Top5 99.656250    
2018-11-02 20:26:36,117 - ==> Top1: 90.350    Top5: 99.680    Loss: 0.382

2018-11-02 20:26:36,118 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:26:36,118 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:26:36,125 - 

2018-11-02 20:26:36,126 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:26:37,203 - Epoch: [219][   50/  391]    Overall Loss 0.059937    Objective Loss 0.059937    Top1 98.046875    Top5 100.000000    LR 0.001968    Time 0.021516    
2018-11-02 20:26:38,165 - Epoch: [219][  100/  391]    Overall Loss 0.061684    Objective Loss 0.061684    Top1 98.015625    Top5 99.984375    LR 0.001968    Time 0.020370    
2018-11-02 20:26:39,126 - Epoch: [219][  150/  391]    Overall Loss 0.061504    Objective Loss 0.061504    Top1 97.968750    Top5 99.989583    LR 0.001968    Time 0.019981    
2018-11-02 20:26:40,093 - Epoch: [219][  200/  391]    Overall Loss 0.062254    Objective Loss 0.062254    Top1 97.945312    Top5 99.988281    LR 0.001968    Time 0.019816    
2018-11-02 20:26:41,056 - Epoch: [219][  250/  391]    Overall Loss 0.062433    Objective Loss 0.062433    Top1 97.893750    Top5 99.987500    LR 0.001968    Time 0.019699    
2018-11-02 20:26:42,016 - Epoch: [219][  300/  391]    Overall Loss 0.062497    Objective Loss 0.062497    Top1 97.903646    Top5 99.986979    LR 0.001968    Time 0.019612    
2018-11-02 20:26:42,976 - Epoch: [219][  350/  391]    Overall Loss 0.062376    Objective Loss 0.062376    Top1 97.915179    Top5 99.988839    LR 0.001968    Time 0.019551    
2018-11-02 20:26:43,844 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36316 | -0.00306 |    0.22531 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14328 | -0.00180 |    0.09108 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15284 | -0.00674 |    0.11633 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17400 | -0.03098 |    0.13359 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17772 |  0.00073 |    0.13971 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17350 | -0.02840 |    0.13372 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16359 | -0.00589 |    0.11802 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19749 | -0.00113 |    0.14543 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16541 | -0.00504 |    0.12635 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.25008 | -0.00370 |    0.16899 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13858 | -0.00180 |    0.10572 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12061 | -0.00926 |    0.09470 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14290 | -0.01574 |    0.11381 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10865 | -0.00288 |    0.08523 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12925 | -0.01406 |    0.10310 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12631 | -0.00138 |    0.10025 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14648 | -0.01111 |    0.11336 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11598 | -0.00774 |    0.09152 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09919 | -0.00639 |    0.07779 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10497 | -0.01260 |    0.08404 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06322 |  0.00366 |    0.04784 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57910 | -0.00001 |    0.45331 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:26:43,844 - Total sparsity: 0.00

2018-11-02 20:26:43,845 - --- validate (epoch=219)-----------
2018-11-02 20:26:43,845 - 10000 samples (128 per mini-batch)
2018-11-02 20:26:44,569 - Epoch: [219][   50/   78]    Loss 0.383101    Top1 90.406250    Top5 99.640625    
2018-11-02 20:26:44,962 - ==> Top1: 90.340    Top5: 99.680    Loss: 0.384

2018-11-02 20:26:44,963 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:26:44,963 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:26:44,970 - 

2018-11-02 20:26:44,971 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:26:45,990 - Epoch: [220][   50/  391]    Overall Loss 0.065519    Objective Loss 0.065519    Top1 97.812500    Top5 100.000000    LR 0.001870    Time 0.020358    
2018-11-02 20:26:46,948 - Epoch: [220][  100/  391]    Overall Loss 0.059145    Objective Loss 0.059145    Top1 97.992188    Top5 100.000000    LR 0.001870    Time 0.019742    
2018-11-02 20:26:47,908 - Epoch: [220][  150/  391]    Overall Loss 0.059495    Objective Loss 0.059495    Top1 98.026042    Top5 100.000000    LR 0.001870    Time 0.019560    
2018-11-02 20:26:48,900 - Epoch: [220][  200/  391]    Overall Loss 0.059951    Objective Loss 0.059951    Top1 97.992188    Top5 100.000000    LR 0.001870    Time 0.019623    
2018-11-02 20:26:49,862 - Epoch: [220][  250/  391]    Overall Loss 0.060165    Objective Loss 0.060165    Top1 97.984375    Top5 100.000000    LR 0.001870    Time 0.019540    
2018-11-02 20:26:50,824 - Epoch: [220][  300/  391]    Overall Loss 0.061118    Objective Loss 0.061118    Top1 97.932292    Top5 100.000000    LR 0.001870    Time 0.019485    
2018-11-02 20:26:51,790 - Epoch: [220][  350/  391]    Overall Loss 0.061567    Objective Loss 0.061567    Top1 97.919643    Top5 100.000000    LR 0.001870    Time 0.019458    
2018-11-02 20:26:52,683 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36291 | -0.00311 |    0.22513 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14318 | -0.00181 |    0.09102 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15274 | -0.00654 |    0.11622 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17388 | -0.03095 |    0.13355 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17759 |  0.00096 |    0.13958 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17343 | -0.02810 |    0.13363 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16348 | -0.00587 |    0.11795 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19736 | -0.00116 |    0.14535 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16530 | -0.00504 |    0.12628 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24990 | -0.00375 |    0.16882 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13849 | -0.00180 |    0.10565 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12053 | -0.00921 |    0.09463 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14280 | -0.01572 |    0.11372 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10857 | -0.00285 |    0.08518 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12916 | -0.01403 |    0.10303 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12622 | -0.00135 |    0.10019 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14638 | -0.01107 |    0.11329 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11590 | -0.00773 |    0.09147 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09913 | -0.00637 |    0.07775 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10490 | -0.01256 |    0.08398 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06317 |  0.00365 |    0.04780 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57923 | -0.00001 |    0.45341 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:26:52,684 - Total sparsity: 0.00

2018-11-02 20:26:52,684 - --- validate (epoch=220)-----------
2018-11-02 20:26:52,684 - 10000 samples (128 per mini-batch)
2018-11-02 20:26:53,407 - Epoch: [220][   50/   78]    Loss 0.385476    Top1 90.281250    Top5 99.656250    
2018-11-02 20:26:53,799 - ==> Top1: 90.150    Top5: 99.680    Loss: 0.385

2018-11-02 20:26:53,800 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:26:53,800 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:26:53,810 - 

2018-11-02 20:26:53,811 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:26:54,831 - Epoch: [221][   50/  391]    Overall Loss 0.058884    Objective Loss 0.058884    Top1 98.140625    Top5 99.968750    LR 0.001776    Time 0.020375    
2018-11-02 20:26:55,793 - Epoch: [221][  100/  391]    Overall Loss 0.060393    Objective Loss 0.060393    Top1 98.140625    Top5 99.984375    LR 0.001776    Time 0.019788    
2018-11-02 20:26:56,753 - Epoch: [221][  150/  391]    Overall Loss 0.060431    Objective Loss 0.060431    Top1 98.093750    Top5 99.984375    LR 0.001776    Time 0.019581    
2018-11-02 20:26:57,712 - Epoch: [221][  200/  391]    Overall Loss 0.061755    Objective Loss 0.061755    Top1 98.058594    Top5 99.988281    LR 0.001776    Time 0.019479    
2018-11-02 20:26:58,674 - Epoch: [221][  250/  391]    Overall Loss 0.061822    Objective Loss 0.061822    Top1 98.040625    Top5 99.987500    LR 0.001776    Time 0.019425    
2018-11-02 20:26:59,635 - Epoch: [221][  300/  391]    Overall Loss 0.061690    Objective Loss 0.061690    Top1 98.039062    Top5 99.986979    LR 0.001776    Time 0.019387    
2018-11-02 20:27:00,601 - Epoch: [221][  350/  391]    Overall Loss 0.061659    Objective Loss 0.061659    Top1 97.995536    Top5 99.988839    LR 0.001776    Time 0.019375    
2018-11-02 20:27:01,472 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36266 | -0.00337 |    0.22503 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14309 | -0.00185 |    0.09098 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15264 | -0.00658 |    0.11617 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17376 | -0.03092 |    0.13344 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17747 |  0.00110 |    0.13950 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17331 | -0.02814 |    0.13352 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16337 | -0.00585 |    0.11790 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19723 | -0.00114 |    0.14522 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16519 | -0.00505 |    0.12618 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24973 | -0.00375 |    0.16871 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13840 | -0.00188 |    0.10558 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12046 | -0.00916 |    0.09456 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14271 | -0.01570 |    0.11364 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10850 | -0.00285 |    0.08511 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12908 | -0.01400 |    0.10295 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12614 | -0.00135 |    0.10013 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14628 | -0.01107 |    0.11321 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11583 | -0.00772 |    0.09141 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09906 | -0.00637 |    0.07770 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10483 | -0.01255 |    0.08393 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06313 |  0.00363 |    0.04778 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57935 | -0.00001 |    0.45354 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:27:01,473 - Total sparsity: 0.00

2018-11-02 20:27:01,473 - --- validate (epoch=221)-----------
2018-11-02 20:27:01,473 - 10000 samples (128 per mini-batch)
2018-11-02 20:27:02,190 - Epoch: [221][   50/   78]    Loss 0.387274    Top1 90.421875    Top5 99.671875    
2018-11-02 20:27:02,580 - ==> Top1: 90.140    Top5: 99.690    Loss: 0.388

2018-11-02 20:27:02,581 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:27:02,581 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:27:02,592 - 

2018-11-02 20:27:02,593 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:27:03,616 - Epoch: [222][   50/  391]    Overall Loss 0.057202    Objective Loss 0.057202    Top1 98.062500    Top5 100.000000    LR 0.001687    Time 0.020442    
2018-11-02 20:27:04,605 - Epoch: [222][  100/  391]    Overall Loss 0.057551    Objective Loss 0.057551    Top1 98.085938    Top5 100.000000    LR 0.001687    Time 0.020099    
2018-11-02 20:27:05,568 - Epoch: [222][  150/  391]    Overall Loss 0.055922    Objective Loss 0.055922    Top1 98.114583    Top5 99.989583    LR 0.001687    Time 0.019808    
2018-11-02 20:27:06,529 - Epoch: [222][  200/  391]    Overall Loss 0.058453    Objective Loss 0.058453    Top1 98.046875    Top5 99.992188    LR 0.001687    Time 0.019656    
2018-11-02 20:27:07,492 - Epoch: [222][  250/  391]    Overall Loss 0.059522    Objective Loss 0.059522    Top1 97.978125    Top5 99.990625    LR 0.001687    Time 0.019574    
2018-11-02 20:27:08,520 - Epoch: [222][  300/  391]    Overall Loss 0.059813    Objective Loss 0.059813    Top1 97.955729    Top5 99.992188    LR 0.001687    Time 0.019735    
2018-11-02 20:27:09,559 - Epoch: [222][  350/  391]    Overall Loss 0.060012    Objective Loss 0.060012    Top1 97.953125    Top5 99.991071    LR 0.001687    Time 0.019879    
2018-11-02 20:27:10,483 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36243 | -0.00345 |    0.22493 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14300 | -0.00180 |    0.09094 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15254 | -0.00652 |    0.11609 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17367 | -0.03083 |    0.13340 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17736 |  0.00115 |    0.13942 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17321 | -0.02807 |    0.13348 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16327 | -0.00583 |    0.11776 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19710 | -0.00115 |    0.14514 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16508 | -0.00502 |    0.12609 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24958 | -0.00373 |    0.16862 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13831 | -0.00193 |    0.10552 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12039 | -0.00907 |    0.09451 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14262 | -0.01568 |    0.11357 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10844 | -0.00278 |    0.08506 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12900 | -0.01396 |    0.10289 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12606 | -0.00135 |    0.10007 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14619 | -0.01104 |    0.11314 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11575 | -0.00771 |    0.09135 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09900 | -0.00636 |    0.07766 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10477 | -0.01253 |    0.08388 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06309 |  0.00363 |    0.04775 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57947 | -0.00001 |    0.45364 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:27:10,484 - Total sparsity: 0.00

2018-11-02 20:27:10,484 - --- validate (epoch=222)-----------
2018-11-02 20:27:10,484 - 10000 samples (128 per mini-batch)
2018-11-02 20:27:11,201 - Epoch: [222][   50/   78]    Loss 0.382454    Top1 90.234375    Top5 99.671875    
2018-11-02 20:27:11,591 - ==> Top1: 90.110    Top5: 99.680    Loss: 0.383

2018-11-02 20:27:11,592 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:27:11,592 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:27:11,600 - 

2018-11-02 20:27:11,600 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:27:12,619 - Epoch: [223][   50/  391]    Overall Loss 0.054283    Objective Loss 0.054283    Top1 98.125000    Top5 100.000000    LR 0.001603    Time 0.020359    
2018-11-02 20:27:13,583 - Epoch: [223][  100/  391]    Overall Loss 0.054872    Objective Loss 0.054872    Top1 98.164062    Top5 99.992188    LR 0.001603    Time 0.019802    
2018-11-02 20:27:14,545 - Epoch: [223][  150/  391]    Overall Loss 0.058900    Objective Loss 0.058900    Top1 97.989583    Top5 99.989583    LR 0.001603    Time 0.019608    
2018-11-02 20:27:15,508 - Epoch: [223][  200/  391]    Overall Loss 0.058552    Objective Loss 0.058552    Top1 97.972656    Top5 99.988281    LR 0.001603    Time 0.019517    
2018-11-02 20:27:16,471 - Epoch: [223][  250/  391]    Overall Loss 0.058949    Objective Loss 0.058949    Top1 97.965625    Top5 99.990625    LR 0.001603    Time 0.019460    
2018-11-02 20:27:17,435 - Epoch: [223][  300/  391]    Overall Loss 0.059709    Objective Loss 0.059709    Top1 97.950521    Top5 99.992188    LR 0.001603    Time 0.019425    
2018-11-02 20:27:18,400 - Epoch: [223][  350/  391]    Overall Loss 0.059939    Objective Loss 0.059939    Top1 97.962054    Top5 99.988839    LR 0.001603    Time 0.019404    
2018-11-02 20:27:19,268 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36222 | -0.00339 |    0.22480 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14291 | -0.00190 |    0.09086 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15245 | -0.00652 |    0.11600 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17354 | -0.03096 |    0.13329 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17726 |  0.00101 |    0.13936 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17310 | -0.02808 |    0.13338 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16317 | -0.00594 |    0.11772 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19698 | -0.00115 |    0.14505 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16498 | -0.00506 |    0.12601 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24942 | -0.00375 |    0.16847 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13823 | -0.00196 |    0.10546 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12031 | -0.00913 |    0.09445 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14254 | -0.01567 |    0.11351 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10837 | -0.00280 |    0.08501 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12893 | -0.01392 |    0.10284 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12599 | -0.00139 |    0.10001 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14610 | -0.01101 |    0.11309 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11569 | -0.00767 |    0.09130 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09894 | -0.00637 |    0.07761 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10470 | -0.01253 |    0.08383 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06305 |  0.00365 |    0.04771 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57957 | -0.00001 |    0.45371 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:27:19,269 - Total sparsity: 0.00

2018-11-02 20:27:19,269 - --- validate (epoch=223)-----------
2018-11-02 20:27:19,269 - 10000 samples (128 per mini-batch)
2018-11-02 20:27:19,992 - Epoch: [223][   50/   78]    Loss 0.380574    Top1 90.546875    Top5 99.593750    
2018-11-02 20:27:20,382 - ==> Top1: 90.330    Top5: 99.640    Loss: 0.383

2018-11-02 20:27:20,382 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:27:20,383 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:27:20,397 - 

2018-11-02 20:27:20,397 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:27:21,494 - Epoch: [224][   50/  391]    Overall Loss 0.061512    Objective Loss 0.061512    Top1 97.937500    Top5 99.984375    LR 0.001523    Time 0.021892    
2018-11-02 20:27:22,540 - Epoch: [224][  100/  391]    Overall Loss 0.060754    Objective Loss 0.060754    Top1 98.039062    Top5 99.992188    LR 0.001523    Time 0.021396    
2018-11-02 20:27:23,570 - Epoch: [224][  150/  391]    Overall Loss 0.060605    Objective Loss 0.060605    Top1 98.000000    Top5 99.984375    LR 0.001523    Time 0.021121    
2018-11-02 20:27:24,600 - Epoch: [224][  200/  391]    Overall Loss 0.060650    Objective Loss 0.060650    Top1 97.937500    Top5 99.988281    LR 0.001523    Time 0.020987    
2018-11-02 20:27:25,584 - Epoch: [224][  250/  391]    Overall Loss 0.060755    Objective Loss 0.060755    Top1 97.903125    Top5 99.990625    LR 0.001523    Time 0.020721    
2018-11-02 20:27:26,545 - Epoch: [224][  300/  391]    Overall Loss 0.060893    Objective Loss 0.060893    Top1 97.893229    Top5 99.989583    LR 0.001523    Time 0.020466    
2018-11-02 20:27:27,505 - Epoch: [224][  350/  391]    Overall Loss 0.061267    Objective Loss 0.061267    Top1 97.872768    Top5 99.988839    LR 0.001523    Time 0.020272    
2018-11-02 20:27:28,376 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36201 | -0.00345 |    0.22457 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14283 | -0.00186 |    0.09082 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15237 | -0.00636 |    0.11593 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17345 | -0.03088 |    0.13319 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17716 |  0.00107 |    0.13927 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17301 | -0.02805 |    0.13333 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16308 | -0.00587 |    0.11765 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19687 | -0.00114 |    0.14497 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16489 | -0.00505 |    0.12594 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24928 | -0.00371 |    0.16834 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13815 | -0.00194 |    0.10541 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12024 | -0.00918 |    0.09439 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14246 | -0.01566 |    0.11344 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10831 | -0.00280 |    0.08497 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12886 | -0.01389 |    0.10278 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12592 | -0.00139 |    0.09996 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14602 | -0.01099 |    0.11302 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11562 | -0.00766 |    0.09124 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09889 | -0.00636 |    0.07756 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10465 | -0.01250 |    0.08379 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06302 |  0.00364 |    0.04769 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57966 | -0.00001 |    0.45378 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:27:28,376 - Total sparsity: 0.00

2018-11-02 20:27:28,376 - --- validate (epoch=224)-----------
2018-11-02 20:27:28,376 - 10000 samples (128 per mini-batch)
2018-11-02 20:27:29,094 - Epoch: [224][   50/   78]    Loss 0.385931    Top1 90.375000    Top5 99.640625    
2018-11-02 20:27:29,482 - ==> Top1: 90.290    Top5: 99.660    Loss: 0.385

2018-11-02 20:27:29,483 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:27:29,483 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:27:29,491 - 

2018-11-02 20:27:29,491 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:27:30,509 - Epoch: [225][   50/  391]    Overall Loss 0.059992    Objective Loss 0.059992    Top1 98.015625    Top5 99.984375    LR 0.001447    Time 0.020319    
2018-11-02 20:27:31,468 - Epoch: [225][  100/  391]    Overall Loss 0.062621    Objective Loss 0.062621    Top1 97.820312    Top5 99.992188    LR 0.001447    Time 0.019743    
2018-11-02 20:27:32,429 - Epoch: [225][  150/  391]    Overall Loss 0.062269    Objective Loss 0.062269    Top1 97.796875    Top5 99.994792    LR 0.001447    Time 0.019560    
2018-11-02 20:27:33,390 - Epoch: [225][  200/  391]    Overall Loss 0.062782    Objective Loss 0.062782    Top1 97.789062    Top5 99.996094    LR 0.001447    Time 0.019467    
2018-11-02 20:27:34,352 - Epoch: [225][  250/  391]    Overall Loss 0.061594    Objective Loss 0.061594    Top1 97.843750    Top5 99.993750    LR 0.001447    Time 0.019420    
2018-11-02 20:27:35,313 - Epoch: [225][  300/  391]    Overall Loss 0.061208    Objective Loss 0.061208    Top1 97.861979    Top5 99.994792    LR 0.001447    Time 0.019382    
2018-11-02 20:27:36,273 - Epoch: [225][  350/  391]    Overall Loss 0.061281    Objective Loss 0.061281    Top1 97.857143    Top5 99.995536    LR 0.001447    Time 0.019351    
2018-11-02 20:27:37,140 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36181 | -0.00349 |    0.22439 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14276 | -0.00178 |    0.09079 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15229 | -0.00648 |    0.11588 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17336 | -0.03085 |    0.13311 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17706 |  0.00107 |    0.13920 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17292 | -0.02801 |    0.13327 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16299 | -0.00594 |    0.11755 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19677 | -0.00109 |    0.14490 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16480 | -0.00507 |    0.12586 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24915 | -0.00368 |    0.16824 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13808 | -0.00196 |    0.10537 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12018 | -0.00914 |    0.09433 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14237 | -0.01571 |    0.11337 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10825 | -0.00283 |    0.08491 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12879 | -0.01388 |    0.10271 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12585 | -0.00140 |    0.09991 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14594 | -0.01097 |    0.11296 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11556 | -0.00765 |    0.09120 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09883 | -0.00637 |    0.07752 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10459 | -0.01254 |    0.08375 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06298 |  0.00364 |    0.04766 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57974 | -0.00001 |    0.45384 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:27:37,140 - Total sparsity: 0.00

2018-11-02 20:27:37,140 - --- validate (epoch=225)-----------
2018-11-02 20:27:37,140 - 10000 samples (128 per mini-batch)
2018-11-02 20:27:37,863 - Epoch: [225][   50/   78]    Loss 0.387478    Top1 90.265625    Top5 99.640625    
2018-11-02 20:27:38,259 - ==> Top1: 90.170    Top5: 99.650    Loss: 0.387

2018-11-02 20:27:38,260 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:27:38,260 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:27:38,267 - 

2018-11-02 20:27:38,268 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:27:39,285 - Epoch: [226][   50/  391]    Overall Loss 0.052909    Objective Loss 0.052909    Top1 98.281250    Top5 100.000000    LR 0.001374    Time 0.020324    
2018-11-02 20:27:40,247 - Epoch: [226][  100/  391]    Overall Loss 0.056825    Objective Loss 0.056825    Top1 98.085938    Top5 99.992188    LR 0.001374    Time 0.019769    
2018-11-02 20:27:41,209 - Epoch: [226][  150/  391]    Overall Loss 0.057302    Objective Loss 0.057302    Top1 98.104167    Top5 99.994792    LR 0.001374    Time 0.019583    
2018-11-02 20:27:42,169 - Epoch: [226][  200/  391]    Overall Loss 0.058431    Objective Loss 0.058431    Top1 98.035156    Top5 99.996094    LR 0.001374    Time 0.019483    
2018-11-02 20:27:43,130 - Epoch: [226][  250/  391]    Overall Loss 0.058216    Objective Loss 0.058216    Top1 98.028125    Top5 99.996875    LR 0.001374    Time 0.019424    
2018-11-02 20:27:44,088 - Epoch: [226][  300/  391]    Overall Loss 0.058432    Objective Loss 0.058432    Top1 98.023438    Top5 99.997396    LR 0.001374    Time 0.019378    
2018-11-02 20:27:45,053 - Epoch: [226][  350/  391]    Overall Loss 0.058031    Objective Loss 0.058031    Top1 98.044643    Top5 99.997768    LR 0.001374    Time 0.019364    
2018-11-02 20:27:45,924 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36162 | -0.00390 |    0.22436 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14268 | -0.00174 |    0.09075 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15221 | -0.00650 |    0.11583 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17326 | -0.03090 |    0.13300 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17697 |  0.00110 |    0.13913 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17283 | -0.02798 |    0.13317 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16290 | -0.00603 |    0.11749 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19666 | -0.00109 |    0.14485 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16472 | -0.00507 |    0.12578 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24901 | -0.00377 |    0.16812 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13800 | -0.00196 |    0.10530 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12012 | -0.00916 |    0.09428 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14230 | -0.01570 |    0.11330 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10820 | -0.00284 |    0.08487 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12872 | -0.01388 |    0.10266 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12578 | -0.00139 |    0.09986 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14586 | -0.01098 |    0.11289 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11550 | -0.00763 |    0.09116 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09879 | -0.00636 |    0.07748 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10453 | -0.01254 |    0.08371 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06295 |  0.00363 |    0.04763 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57986 | -0.00001 |    0.45394 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:27:45,925 - Total sparsity: 0.00

2018-11-02 20:27:45,925 - --- validate (epoch=226)-----------
2018-11-02 20:27:45,925 - 10000 samples (128 per mini-batch)
2018-11-02 20:27:46,646 - Epoch: [226][   50/   78]    Loss 0.383019    Top1 90.546875    Top5 99.687500    
2018-11-02 20:27:47,038 - ==> Top1: 90.330    Top5: 99.690    Loss: 0.385

2018-11-02 20:27:47,038 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:27:47,039 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:27:47,053 - 

2018-11-02 20:27:47,053 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:27:48,149 - Epoch: [227][   50/  391]    Overall Loss 0.054214    Objective Loss 0.054214    Top1 98.046875    Top5 100.000000    LR 0.001306    Time 0.021887    
2018-11-02 20:27:49,143 - Epoch: [227][  100/  391]    Overall Loss 0.058903    Objective Loss 0.058903    Top1 97.882812    Top5 100.000000    LR 0.001306    Time 0.020868    
2018-11-02 20:27:50,104 - Epoch: [227][  150/  391]    Overall Loss 0.058419    Objective Loss 0.058419    Top1 97.979167    Top5 99.994792    LR 0.001306    Time 0.020309    
2018-11-02 20:27:51,067 - Epoch: [227][  200/  391]    Overall Loss 0.057882    Objective Loss 0.057882    Top1 97.988281    Top5 99.996094    LR 0.001306    Time 0.020041    
2018-11-02 20:27:52,030 - Epoch: [227][  250/  391]    Overall Loss 0.057567    Objective Loss 0.057567    Top1 98.015625    Top5 99.996875    LR 0.001306    Time 0.019882    
2018-11-02 20:27:52,991 - Epoch: [227][  300/  391]    Overall Loss 0.058340    Objective Loss 0.058340    Top1 97.986979    Top5 99.994792    LR 0.001306    Time 0.019768    
2018-11-02 20:27:53,954 - Epoch: [227][  350/  391]    Overall Loss 0.058682    Objective Loss 0.058682    Top1 97.964286    Top5 99.995536    LR 0.001306    Time 0.019692    
2018-11-02 20:27:54,828 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36145 | -0.00352 |    0.22422 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14261 | -0.00171 |    0.09072 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15214 | -0.00644 |    0.11577 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17316 | -0.03096 |    0.13296 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17688 |  0.00118 |    0.13908 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17274 | -0.02799 |    0.13310 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16282 | -0.00599 |    0.11743 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19657 | -0.00107 |    0.14476 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16464 | -0.00506 |    0.12571 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24889 | -0.00377 |    0.16799 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13794 | -0.00198 |    0.10526 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12006 | -0.00914 |    0.09424 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14223 | -0.01567 |    0.11325 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10815 | -0.00285 |    0.08482 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12865 | -0.01387 |    0.10261 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12572 | -0.00140 |    0.09981 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14579 | -0.01095 |    0.11282 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11545 | -0.00761 |    0.09111 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09874 | -0.00636 |    0.07746 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10448 | -0.01255 |    0.08367 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06292 |  0.00364 |    0.04761 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57993 | -0.00001 |    0.45398 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:27:54,828 - Total sparsity: 0.00

2018-11-02 20:27:54,828 - --- validate (epoch=227)-----------
2018-11-02 20:27:54,828 - 10000 samples (128 per mini-batch)
2018-11-02 20:27:55,546 - Epoch: [227][   50/   78]    Loss 0.388486    Top1 90.312500    Top5 99.671875    
2018-11-02 20:27:55,933 - ==> Top1: 90.190    Top5: 99.670    Loss: 0.391

2018-11-02 20:27:55,934 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:27:55,934 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:27:55,944 - 

2018-11-02 20:27:55,944 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:27:56,964 - Epoch: [228][   50/  391]    Overall Loss 0.058837    Objective Loss 0.058837    Top1 97.984375    Top5 100.000000    LR 0.001240    Time 0.020345    
2018-11-02 20:27:57,927 - Epoch: [228][  100/  391]    Overall Loss 0.059294    Objective Loss 0.059294    Top1 97.992188    Top5 100.000000    LR 0.001240    Time 0.019792    
2018-11-02 20:27:58,890 - Epoch: [228][  150/  391]    Overall Loss 0.060394    Objective Loss 0.060394    Top1 97.911458    Top5 99.994792    LR 0.001240    Time 0.019606    
2018-11-02 20:27:59,849 - Epoch: [228][  200/  391]    Overall Loss 0.059948    Objective Loss 0.059948    Top1 97.960938    Top5 99.996094    LR 0.001240    Time 0.019498    
2018-11-02 20:28:00,813 - Epoch: [228][  250/  391]    Overall Loss 0.060924    Objective Loss 0.060924    Top1 97.950000    Top5 99.996875    LR 0.001240    Time 0.019434    
2018-11-02 20:28:01,774 - Epoch: [228][  300/  391]    Overall Loss 0.060945    Objective Loss 0.060945    Top1 97.924479    Top5 99.997396    LR 0.001240    Time 0.019394    
2018-11-02 20:28:02,733 - Epoch: [228][  350/  391]    Overall Loss 0.061095    Objective Loss 0.061095    Top1 97.926339    Top5 99.997768    LR 0.001240    Time 0.019360    
2018-11-02 20:28:03,601 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36128 | -0.00368 |    0.22416 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14255 | -0.00181 |    0.09068 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15207 | -0.00632 |    0.11574 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17306 | -0.03108 |    0.13292 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17680 |  0.00120 |    0.13902 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17265 | -0.02805 |    0.13305 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16274 | -0.00601 |    0.11737 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19648 | -0.00119 |    0.14467 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16456 | -0.00507 |    0.12567 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24878 | -0.00366 |    0.16795 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13787 | -0.00201 |    0.10521 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12000 | -0.00913 |    0.09420 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14217 | -0.01567 |    0.11320 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10809 | -0.00287 |    0.08478 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12860 | -0.01386 |    0.10256 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12566 | -0.00139 |    0.09976 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14572 | -0.01096 |    0.11277 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11540 | -0.00760 |    0.09107 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09869 | -0.00635 |    0.07742 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10443 | -0.01253 |    0.08362 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06289 |  0.00364 |    0.04759 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.57998 | -0.00001 |    0.45402 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:28:03,601 - Total sparsity: 0.00

2018-11-02 20:28:03,601 - --- validate (epoch=228)-----------
2018-11-02 20:28:03,601 - 10000 samples (128 per mini-batch)
2018-11-02 20:28:04,323 - Epoch: [228][   50/   78]    Loss 0.385642    Top1 90.437500    Top5 99.640625    
2018-11-02 20:28:04,713 - ==> Top1: 90.310    Top5: 99.660    Loss: 0.389

2018-11-02 20:28:04,714 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:28:04,714 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:28:04,721 - 

2018-11-02 20:28:04,721 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:28:05,769 - Epoch: [229][   50/  391]    Overall Loss 0.057987    Objective Loss 0.057987    Top1 98.031250    Top5 100.000000    LR 0.001178    Time 0.020915    
2018-11-02 20:28:06,730 - Epoch: [229][  100/  391]    Overall Loss 0.056967    Objective Loss 0.056967    Top1 98.078125    Top5 100.000000    LR 0.001178    Time 0.020061    
2018-11-02 20:28:07,694 - Epoch: [229][  150/  391]    Overall Loss 0.056860    Objective Loss 0.056860    Top1 98.015625    Top5 99.989583    LR 0.001178    Time 0.019792    
2018-11-02 20:28:08,653 - Epoch: [229][  200/  391]    Overall Loss 0.057533    Objective Loss 0.057533    Top1 97.996094    Top5 99.992188    LR 0.001178    Time 0.019631    
2018-11-02 20:28:09,613 - Epoch: [229][  250/  391]    Overall Loss 0.058482    Objective Loss 0.058482    Top1 97.971875    Top5 99.993750    LR 0.001178    Time 0.019540    
2018-11-02 20:28:10,575 - Epoch: [229][  300/  391]    Overall Loss 0.059546    Objective Loss 0.059546    Top1 97.958333    Top5 99.994792    LR 0.001178    Time 0.019486    
2018-11-02 20:28:11,536 - Epoch: [229][  350/  391]    Overall Loss 0.058530    Objective Loss 0.058530    Top1 97.993304    Top5 99.995536    LR 0.001178    Time 0.019445    
2018-11-02 20:28:12,403 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36112 | -0.00359 |    0.22401 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14248 | -0.00178 |    0.09064 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15200 | -0.00634 |    0.11566 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17298 | -0.03107 |    0.13286 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17672 |  0.00119 |    0.13895 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17258 | -0.02801 |    0.13300 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16267 | -0.00599 |    0.11729 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19639 | -0.00113 |    0.14461 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16449 | -0.00506 |    0.12560 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24866 | -0.00371 |    0.16787 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13781 | -0.00202 |    0.10516 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11995 | -0.00914 |    0.09415 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14211 | -0.01561 |    0.11315 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10805 | -0.00287 |    0.08475 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12854 | -0.01385 |    0.10250 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12561 | -0.00138 |    0.09971 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14566 | -0.01094 |    0.11273 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11534 | -0.00761 |    0.09103 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09865 | -0.00635 |    0.07738 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10439 | -0.01251 |    0.08359 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06286 |  0.00362 |    0.04757 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58005 | -0.00001 |    0.45407 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:28:12,403 - Total sparsity: 0.00

2018-11-02 20:28:12,404 - --- validate (epoch=229)-----------
2018-11-02 20:28:12,404 - 10000 samples (128 per mini-batch)
2018-11-02 20:28:13,123 - Epoch: [229][   50/   78]    Loss 0.383905    Top1 90.484375    Top5 99.671875    
2018-11-02 20:28:13,515 - ==> Top1: 90.280    Top5: 99.690    Loss: 0.386

2018-11-02 20:28:13,516 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:28:13,516 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:28:13,523 - 

2018-11-02 20:28:13,524 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:28:14,543 - Epoch: [230][   50/  391]    Overall Loss 0.061237    Objective Loss 0.061237    Top1 98.015625    Top5 100.000000    LR 0.001119    Time 0.020349    
2018-11-02 20:28:15,505 - Epoch: [230][  100/  391]    Overall Loss 0.061191    Objective Loss 0.061191    Top1 97.945312    Top5 100.000000    LR 0.001119    Time 0.019785    
2018-11-02 20:28:16,469 - Epoch: [230][  150/  391]    Overall Loss 0.060630    Objective Loss 0.060630    Top1 97.968750    Top5 100.000000    LR 0.001119    Time 0.019613    
2018-11-02 20:28:17,431 - Epoch: [230][  200/  391]    Overall Loss 0.060899    Objective Loss 0.060899    Top1 97.960938    Top5 100.000000    LR 0.001119    Time 0.019511    
2018-11-02 20:28:18,394 - Epoch: [230][  250/  391]    Overall Loss 0.059282    Objective Loss 0.059282    Top1 97.981250    Top5 100.000000    LR 0.001119    Time 0.019458    
2018-11-02 20:28:19,354 - Epoch: [230][  300/  391]    Overall Loss 0.058648    Objective Loss 0.058648    Top1 98.015625    Top5 100.000000    LR 0.001119    Time 0.019411    
2018-11-02 20:28:20,314 - Epoch: [230][  350/  391]    Overall Loss 0.058670    Objective Loss 0.058670    Top1 97.997768    Top5 99.997768    LR 0.001119    Time 0.019377    
2018-11-02 20:28:21,183 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36096 | -0.00362 |    0.22397 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14242 | -0.00181 |    0.09060 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15194 | -0.00635 |    0.11560 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17290 | -0.03107 |    0.13284 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17665 |  0.00121 |    0.13890 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17251 | -0.02798 |    0.13295 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16261 | -0.00592 |    0.11723 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19631 | -0.00112 |    0.14455 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16442 | -0.00504 |    0.12554 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24856 | -0.00366 |    0.16778 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13775 | -0.00199 |    0.10512 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11990 | -0.00916 |    0.09412 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14206 | -0.01556 |    0.11311 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10800 | -0.00290 |    0.08472 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12848 | -0.01385 |    0.10246 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12556 | -0.00137 |    0.09967 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14560 | -0.01092 |    0.11268 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11530 | -0.00759 |    0.09100 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09861 | -0.00635 |    0.07735 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10435 | -0.01250 |    0.08355 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06283 |  0.00363 |    0.04755 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58012 | -0.00001 |    0.45414 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:28:21,183 - Total sparsity: 0.00

2018-11-02 20:28:21,184 - --- validate (epoch=230)-----------
2018-11-02 20:28:21,184 - 10000 samples (128 per mini-batch)
2018-11-02 20:28:21,905 - Epoch: [230][   50/   78]    Loss 0.383822    Top1 90.359375    Top5 99.625000    
2018-11-02 20:28:22,298 - ==> Top1: 90.290    Top5: 99.650    Loss: 0.385

2018-11-02 20:28:22,298 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:28:22,298 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:28:22,306 - 

2018-11-02 20:28:22,306 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:28:23,325 - Epoch: [231][   50/  391]    Overall Loss 0.060151    Objective Loss 0.060151    Top1 98.125000    Top5 99.984375    LR 0.001063    Time 0.020339    
2018-11-02 20:28:24,285 - Epoch: [231][  100/  391]    Overall Loss 0.060194    Objective Loss 0.060194    Top1 98.085938    Top5 99.992188    LR 0.001063    Time 0.019757    
2018-11-02 20:28:25,247 - Epoch: [231][  150/  391]    Overall Loss 0.058898    Objective Loss 0.058898    Top1 98.114583    Top5 99.989583    LR 0.001063    Time 0.019578    
2018-11-02 20:28:26,205 - Epoch: [231][  200/  391]    Overall Loss 0.058046    Objective Loss 0.058046    Top1 98.066406    Top5 99.988281    LR 0.001063    Time 0.019466    
2018-11-02 20:28:27,167 - Epoch: [231][  250/  391]    Overall Loss 0.058873    Objective Loss 0.058873    Top1 98.028125    Top5 99.990625    LR 0.001063    Time 0.019415    
2018-11-02 20:28:28,128 - Epoch: [231][  300/  391]    Overall Loss 0.057860    Objective Loss 0.057860    Top1 98.033854    Top5 99.992188    LR 0.001063    Time 0.019378    
2018-11-02 20:28:29,092 - Epoch: [231][  350/  391]    Overall Loss 0.058537    Objective Loss 0.058537    Top1 98.017857    Top5 99.993304    LR 0.001063    Time 0.019351    
2018-11-02 20:28:29,956 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36082 | -0.00359 |    0.22391 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14237 | -0.00182 |    0.09056 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15187 | -0.00646 |    0.11555 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17284 | -0.03104 |    0.13277 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17658 |  0.00122 |    0.13885 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17243 | -0.02803 |    0.13288 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16253 | -0.00605 |    0.11718 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19623 | -0.00118 |    0.14452 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16435 | -0.00500 |    0.12549 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24846 | -0.00368 |    0.16774 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13770 | -0.00199 |    0.10509 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11985 | -0.00915 |    0.09408 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14200 | -0.01558 |    0.11306 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10796 | -0.00287 |    0.08467 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12843 | -0.01384 |    0.10242 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12551 | -0.00134 |    0.09963 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14554 | -0.01091 |    0.11263 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11525 | -0.00760 |    0.09096 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09857 | -0.00634 |    0.07732 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10431 | -0.01249 |    0.08352 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06281 |  0.00363 |    0.04753 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58019 | -0.00001 |    0.45420 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:28:29,957 - Total sparsity: 0.00

2018-11-02 20:28:29,957 - --- validate (epoch=231)-----------
2018-11-02 20:28:29,957 - 10000 samples (128 per mini-batch)
2018-11-02 20:28:30,676 - Epoch: [231][   50/   78]    Loss 0.387146    Top1 90.515625    Top5 99.687500    
2018-11-02 20:28:31,065 - ==> Top1: 90.370    Top5: 99.690    Loss: 0.389

2018-11-02 20:28:31,066 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:28:31,066 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:28:31,073 - 

2018-11-02 20:28:31,073 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:28:32,092 - Epoch: [232][   50/  391]    Overall Loss 0.060053    Objective Loss 0.060053    Top1 97.843750    Top5 100.000000    LR 0.001010    Time 0.020346    
2018-11-02 20:28:33,055 - Epoch: [232][  100/  391]    Overall Loss 0.058726    Objective Loss 0.058726    Top1 97.984375    Top5 99.992188    LR 0.001010    Time 0.019787    
2018-11-02 20:28:34,015 - Epoch: [232][  150/  391]    Overall Loss 0.059264    Objective Loss 0.059264    Top1 97.963542    Top5 99.994792    LR 0.001010    Time 0.019588    
2018-11-02 20:28:34,980 - Epoch: [232][  200/  391]    Overall Loss 0.058018    Objective Loss 0.058018    Top1 98.046875    Top5 99.996094    LR 0.001010    Time 0.019490    
2018-11-02 20:28:35,937 - Epoch: [232][  250/  391]    Overall Loss 0.058266    Objective Loss 0.058266    Top1 98.056250    Top5 99.996875    LR 0.001010    Time 0.019413    
2018-11-02 20:28:36,962 - Epoch: [232][  300/  391]    Overall Loss 0.058409    Objective Loss 0.058409    Top1 98.057292    Top5 99.994792    LR 0.001010    Time 0.019592    
2018-11-02 20:28:37,923 - Epoch: [232][  350/  391]    Overall Loss 0.058661    Objective Loss 0.058661    Top1 98.064732    Top5 99.991071    LR 0.001010    Time 0.019536    
2018-11-02 20:28:38,795 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36068 | -0.00327 |    0.22382 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14231 | -0.00185 |    0.09052 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15181 | -0.00653 |    0.11550 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17276 | -0.03110 |    0.13274 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17651 |  0.00121 |    0.13878 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17237 | -0.02802 |    0.13284 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16247 | -0.00603 |    0.11716 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19615 | -0.00115 |    0.14446 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16429 | -0.00501 |    0.12544 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24836 | -0.00359 |    0.16762 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13765 | -0.00197 |    0.10505 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11981 | -0.00911 |    0.09404 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14194 | -0.01557 |    0.11302 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10792 | -0.00285 |    0.08465 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12838 | -0.01384 |    0.10238 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12546 | -0.00133 |    0.09960 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14548 | -0.01091 |    0.11258 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11521 | -0.00760 |    0.09093 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09853 | -0.00632 |    0.07729 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10427 | -0.01248 |    0.08349 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06278 |  0.00363 |    0.04751 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58024 | -0.00001 |    0.45425 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:28:38,795 - Total sparsity: 0.00

2018-11-02 20:28:38,795 - --- validate (epoch=232)-----------
2018-11-02 20:28:38,795 - 10000 samples (128 per mini-batch)
2018-11-02 20:28:39,512 - Epoch: [232][   50/   78]    Loss 0.383536    Top1 90.328125    Top5 99.671875    
2018-11-02 20:28:39,902 - ==> Top1: 90.210    Top5: 99.680    Loss: 0.386

2018-11-02 20:28:39,903 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:28:39,903 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:28:39,914 - 

2018-11-02 20:28:39,914 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:28:40,945 - Epoch: [233][   50/  391]    Overall Loss 0.057839    Objective Loss 0.057839    Top1 98.015625    Top5 99.968750    LR 0.000960    Time 0.020589    
2018-11-02 20:28:41,906 - Epoch: [233][  100/  391]    Overall Loss 0.056766    Objective Loss 0.056766    Top1 98.101562    Top5 99.976562    LR 0.000960    Time 0.019887    
2018-11-02 20:28:42,869 - Epoch: [233][  150/  391]    Overall Loss 0.056847    Objective Loss 0.056847    Top1 98.135417    Top5 99.984375    LR 0.000960    Time 0.019674    
2018-11-02 20:28:43,833 - Epoch: [233][  200/  391]    Overall Loss 0.056842    Objective Loss 0.056842    Top1 98.085938    Top5 99.988281    LR 0.000960    Time 0.019566    
2018-11-02 20:28:44,797 - Epoch: [233][  250/  391]    Overall Loss 0.057825    Objective Loss 0.057825    Top1 98.037500    Top5 99.990625    LR 0.000960    Time 0.019506    
2018-11-02 20:28:45,761 - Epoch: [233][  300/  391]    Overall Loss 0.058222    Objective Loss 0.058222    Top1 98.026042    Top5 99.992188    LR 0.000960    Time 0.019466    
2018-11-02 20:28:46,726 - Epoch: [233][  350/  391]    Overall Loss 0.057669    Objective Loss 0.057669    Top1 98.053571    Top5 99.993304    LR 0.000960    Time 0.019427    
2018-11-02 20:28:47,597 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36055 | -0.00339 |    0.22371 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14226 | -0.00183 |    0.09049 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15175 | -0.00657 |    0.11546 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17269 | -0.03112 |    0.13267 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17644 |  0.00118 |    0.13872 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17231 | -0.02798 |    0.13277 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16241 | -0.00607 |    0.11712 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19608 | -0.00112 |    0.14441 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16423 | -0.00503 |    0.12540 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24827 | -0.00356 |    0.16754 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13760 | -0.00198 |    0.10501 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11976 | -0.00914 |    0.09400 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14189 | -0.01557 |    0.11298 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10788 | -0.00285 |    0.08461 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12834 | -0.01382 |    0.10235 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12541 | -0.00132 |    0.09956 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14543 | -0.01090 |    0.11254 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11516 | -0.00760 |    0.09089 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09850 | -0.00632 |    0.07726 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10423 | -0.01248 |    0.08346 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06276 |  0.00363 |    0.04749 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58029 | -0.00001 |    0.45429 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:28:47,597 - Total sparsity: 0.00

2018-11-02 20:28:47,597 - --- validate (epoch=233)-----------
2018-11-02 20:28:47,598 - 10000 samples (128 per mini-batch)
2018-11-02 20:28:48,321 - Epoch: [233][   50/   78]    Loss 0.389322    Top1 90.359375    Top5 99.687500    
2018-11-02 20:28:48,713 - ==> Top1: 90.280    Top5: 99.710    Loss: 0.390

2018-11-02 20:28:48,714 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:28:48,714 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:28:48,721 - 

2018-11-02 20:28:48,722 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:28:49,813 - Epoch: [234][   50/  391]    Overall Loss 0.054694    Objective Loss 0.054694    Top1 98.218750    Top5 100.000000    LR 0.000912    Time 0.021795    
2018-11-02 20:28:50,860 - Epoch: [234][  100/  391]    Overall Loss 0.056414    Objective Loss 0.056414    Top1 98.101562    Top5 100.000000    LR 0.000912    Time 0.021355    
2018-11-02 20:28:51,821 - Epoch: [234][  150/  391]    Overall Loss 0.056422    Objective Loss 0.056422    Top1 98.130208    Top5 100.000000    LR 0.000912    Time 0.020633    
2018-11-02 20:28:52,781 - Epoch: [234][  200/  391]    Overall Loss 0.056918    Objective Loss 0.056918    Top1 98.121094    Top5 100.000000    LR 0.000912    Time 0.020274    
2018-11-02 20:28:53,743 - Epoch: [234][  250/  391]    Overall Loss 0.057729    Objective Loss 0.057729    Top1 98.084375    Top5 100.000000    LR 0.000912    Time 0.020063    
2018-11-02 20:28:54,707 - Epoch: [234][  300/  391]    Overall Loss 0.058190    Objective Loss 0.058190    Top1 98.044271    Top5 100.000000    LR 0.000912    Time 0.019927    
2018-11-02 20:28:55,669 - Epoch: [234][  350/  391]    Overall Loss 0.058666    Objective Loss 0.058666    Top1 98.026786    Top5 100.000000    LR 0.000912    Time 0.019824    
2018-11-02 20:28:56,537 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36043 | -0.00304 |    0.22364 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14221 | -0.00179 |    0.09046 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15170 | -0.00663 |    0.11542 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17264 | -0.03108 |    0.13264 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17638 |  0.00122 |    0.13869 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17225 | -0.02796 |    0.13272 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16235 | -0.00614 |    0.11707 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19601 | -0.00116 |    0.14437 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16417 | -0.00502 |    0.12535 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24819 | -0.00354 |    0.16746 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13755 | -0.00196 |    0.10497 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11972 | -0.00912 |    0.09396 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14184 | -0.01553 |    0.11293 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10784 | -0.00288 |    0.08459 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12829 | -0.01382 |    0.10231 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12537 | -0.00133 |    0.09952 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14538 | -0.01089 |    0.11250 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11512 | -0.00759 |    0.09086 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09846 | -0.00632 |    0.07723 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10419 | -0.01250 |    0.08343 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06274 |  0.00363 |    0.04748 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58033 | -0.00001 |    0.45432 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:28:56,538 - Total sparsity: 0.00

2018-11-02 20:28:56,538 - --- validate (epoch=234)-----------
2018-11-02 20:28:56,538 - 10000 samples (128 per mini-batch)
2018-11-02 20:28:57,257 - Epoch: [234][   50/   78]    Loss 0.391984    Top1 90.375000    Top5 99.687500    
2018-11-02 20:28:57,649 - ==> Top1: 90.190    Top5: 99.720    Loss: 0.392

2018-11-02 20:28:57,650 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:28:57,650 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:28:57,661 - 

2018-11-02 20:28:57,661 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:28:58,680 - Epoch: [235][   50/  391]    Overall Loss 0.054564    Objective Loss 0.054564    Top1 98.140625    Top5 100.000000    LR 0.000866    Time 0.020351    
2018-11-02 20:28:59,642 - Epoch: [235][  100/  391]    Overall Loss 0.055687    Objective Loss 0.055687    Top1 98.101562    Top5 100.000000    LR 0.000866    Time 0.019782    
2018-11-02 20:29:00,609 - Epoch: [235][  150/  391]    Overall Loss 0.056074    Objective Loss 0.056074    Top1 98.083333    Top5 100.000000    LR 0.000866    Time 0.019626    
2018-11-02 20:29:01,569 - Epoch: [235][  200/  391]    Overall Loss 0.056606    Objective Loss 0.056606    Top1 98.074219    Top5 100.000000    LR 0.000866    Time 0.019514    
2018-11-02 20:29:02,532 - Epoch: [235][  250/  391]    Overall Loss 0.057369    Objective Loss 0.057369    Top1 98.078125    Top5 99.996875    LR 0.000866    Time 0.019445    
2018-11-02 20:29:03,494 - Epoch: [235][  300/  391]    Overall Loss 0.057810    Objective Loss 0.057810    Top1 98.072917    Top5 99.994792    LR 0.000866    Time 0.019406    
2018-11-02 20:29:04,455 - Epoch: [235][  350/  391]    Overall Loss 0.057426    Objective Loss 0.057426    Top1 98.084821    Top5 99.993304    LR 0.000866    Time 0.019378    
2018-11-02 20:29:05,323 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36030 | -0.00339 |    0.22358 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14216 | -0.00177 |    0.09043 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15165 | -0.00660 |    0.11540 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17259 | -0.03099 |    0.13261 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17632 |  0.00119 |    0.13864 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17220 | -0.02789 |    0.13269 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16230 | -0.00611 |    0.11704 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19595 | -0.00117 |    0.14431 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16412 | -0.00504 |    0.12530 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24810 | -0.00356 |    0.16739 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13750 | -0.00199 |    0.10494 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11968 | -0.00912 |    0.09393 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14180 | -0.01553 |    0.11288 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10781 | -0.00289 |    0.08457 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12825 | -0.01384 |    0.10228 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12533 | -0.00134 |    0.09949 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14533 | -0.01089 |    0.11247 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11509 | -0.00757 |    0.09083 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09843 | -0.00631 |    0.07721 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10416 | -0.01248 |    0.08340 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06272 |  0.00363 |    0.04746 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58038 | -0.00001 |    0.45437 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:29:05,323 - Total sparsity: 0.00

2018-11-02 20:29:05,323 - --- validate (epoch=235)-----------
2018-11-02 20:29:05,323 - 10000 samples (128 per mini-batch)
2018-11-02 20:29:06,042 - Epoch: [235][   50/   78]    Loss 0.385804    Top1 90.515625    Top5 99.671875    
2018-11-02 20:29:06,434 - ==> Top1: 90.400    Top5: 99.680    Loss: 0.388

2018-11-02 20:29:06,435 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:29:06,435 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:29:06,446 - 

2018-11-02 20:29:06,446 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:29:07,466 - Epoch: [236][   50/  391]    Overall Loss 0.055131    Objective Loss 0.055131    Top1 98.125000    Top5 99.984375    LR 0.000823    Time 0.020359    
2018-11-02 20:29:08,427 - Epoch: [236][  100/  391]    Overall Loss 0.057227    Objective Loss 0.057227    Top1 98.070312    Top5 99.992188    LR 0.000823    Time 0.019776    
2018-11-02 20:29:09,389 - Epoch: [236][  150/  391]    Overall Loss 0.058534    Objective Loss 0.058534    Top1 98.057292    Top5 99.994792    LR 0.000823    Time 0.019588    
2018-11-02 20:29:10,351 - Epoch: [236][  200/  391]    Overall Loss 0.057997    Objective Loss 0.057997    Top1 98.058594    Top5 99.996094    LR 0.000823    Time 0.019494    
2018-11-02 20:29:11,312 - Epoch: [236][  250/  391]    Overall Loss 0.058398    Objective Loss 0.058398    Top1 98.021875    Top5 99.993750    LR 0.000823    Time 0.019434    
2018-11-02 20:29:12,269 - Epoch: [236][  300/  391]    Overall Loss 0.058489    Objective Loss 0.058489    Top1 98.039062    Top5 99.992188    LR 0.000823    Time 0.019383    
2018-11-02 20:29:13,228 - Epoch: [236][  350/  391]    Overall Loss 0.058435    Objective Loss 0.058435    Top1 98.035714    Top5 99.991071    LR 0.000823    Time 0.019351    
2018-11-02 20:29:14,096 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36019 | -0.00338 |    0.22348 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14212 | -0.00179 |    0.09041 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15161 | -0.00653 |    0.11538 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17253 | -0.03101 |    0.13257 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17627 |  0.00116 |    0.13859 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17214 | -0.02794 |    0.13265 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16225 | -0.00609 |    0.11700 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19589 | -0.00112 |    0.14426 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16407 | -0.00501 |    0.12526 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24802 | -0.00355 |    0.16732 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13746 | -0.00199 |    0.10491 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11965 | -0.00909 |    0.09391 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14175 | -0.01554 |    0.11285 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10777 | -0.00288 |    0.08454 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12821 | -0.01384 |    0.10225 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12529 | -0.00132 |    0.09946 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14528 | -0.01087 |    0.11243 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11505 | -0.00757 |    0.09080 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09840 | -0.00630 |    0.07719 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10412 | -0.01249 |    0.08337 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06270 |  0.00363 |    0.04745 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58041 | -0.00001 |    0.45438 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:29:14,096 - Total sparsity: 0.00

2018-11-02 20:29:14,096 - --- validate (epoch=236)-----------
2018-11-02 20:29:14,096 - 10000 samples (128 per mini-batch)
2018-11-02 20:29:14,817 - Epoch: [236][   50/   78]    Loss 0.386154    Top1 90.406250    Top5 99.703125    
2018-11-02 20:29:15,211 - ==> Top1: 90.280    Top5: 99.720    Loss: 0.390

2018-11-02 20:29:15,212 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:29:15,212 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:29:15,220 - 

2018-11-02 20:29:15,220 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:29:16,239 - Epoch: [237][   50/  391]    Overall Loss 0.060481    Objective Loss 0.060481    Top1 98.031250    Top5 100.000000    LR 0.000782    Time 0.020348    
2018-11-02 20:29:17,200 - Epoch: [237][  100/  391]    Overall Loss 0.055127    Objective Loss 0.055127    Top1 98.140625    Top5 100.000000    LR 0.000782    Time 0.019771    
2018-11-02 20:29:18,163 - Epoch: [237][  150/  391]    Overall Loss 0.056503    Objective Loss 0.056503    Top1 98.104167    Top5 100.000000    LR 0.000782    Time 0.019593    
2018-11-02 20:29:19,121 - Epoch: [237][  200/  391]    Overall Loss 0.059084    Objective Loss 0.059084    Top1 97.980469    Top5 99.996094    LR 0.000782    Time 0.019475    
2018-11-02 20:29:20,082 - Epoch: [237][  250/  391]    Overall Loss 0.058118    Objective Loss 0.058118    Top1 98.031250    Top5 99.996875    LR 0.000782    Time 0.019420    
2018-11-02 20:29:21,041 - Epoch: [237][  300/  391]    Overall Loss 0.057019    Objective Loss 0.057019    Top1 98.080729    Top5 99.997396    LR 0.000782    Time 0.019376    
2018-11-02 20:29:21,998 - Epoch: [237][  350/  391]    Overall Loss 0.057108    Objective Loss 0.057108    Top1 98.078125    Top5 99.997768    LR 0.000782    Time 0.019339    
2018-11-02 20:29:22,870 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.36008 | -0.00336 |    0.22343 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14208 | -0.00171 |    0.09037 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15156 | -0.00646 |    0.11533 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17248 | -0.03100 |    0.13255 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17622 |  0.00110 |    0.13857 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17209 | -0.02793 |    0.13260 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16220 | -0.00615 |    0.11696 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19583 | -0.00113 |    0.14423 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16402 | -0.00502 |    0.12522 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24795 | -0.00353 |    0.16730 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13742 | -0.00197 |    0.10487 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11961 | -0.00912 |    0.09388 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14171 | -0.01551 |    0.11281 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10774 | -0.00289 |    0.08451 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12817 | -0.01382 |    0.10222 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12525 | -0.00132 |    0.09943 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14524 | -0.01087 |    0.11240 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11502 | -0.00756 |    0.09077 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09837 | -0.00629 |    0.07716 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10409 | -0.01250 |    0.08334 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06268 |  0.00362 |    0.04744 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58045 | -0.00001 |    0.45442 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:29:22,870 - Total sparsity: 0.00

2018-11-02 20:29:22,870 - --- validate (epoch=237)-----------
2018-11-02 20:29:22,871 - 10000 samples (128 per mini-batch)
2018-11-02 20:29:23,592 - Epoch: [237][   50/   78]    Loss 0.390133    Top1 90.468750    Top5 99.656250    
2018-11-02 20:29:23,978 - ==> Top1: 90.290    Top5: 99.670    Loss: 0.392

2018-11-02 20:29:23,979 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:29:23,979 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:29:23,989 - 

2018-11-02 20:29:23,990 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:29:25,014 - Epoch: [238][   50/  391]    Overall Loss 0.055938    Objective Loss 0.055938    Top1 98.031250    Top5 100.000000    LR 0.000743    Time 0.020455    
2018-11-02 20:29:25,977 - Epoch: [238][  100/  391]    Overall Loss 0.057290    Objective Loss 0.057290    Top1 98.062500    Top5 99.992188    LR 0.000743    Time 0.019847    
2018-11-02 20:29:26,941 - Epoch: [238][  150/  391]    Overall Loss 0.055674    Objective Loss 0.055674    Top1 98.182292    Top5 99.994792    LR 0.000743    Time 0.019646    
2018-11-02 20:29:27,903 - Epoch: [238][  200/  391]    Overall Loss 0.056898    Objective Loss 0.056898    Top1 98.101562    Top5 99.992188    LR 0.000743    Time 0.019542    
2018-11-02 20:29:28,896 - Epoch: [238][  250/  391]    Overall Loss 0.056465    Objective Loss 0.056465    Top1 98.134375    Top5 99.993750    LR 0.000743    Time 0.019601    
2018-11-02 20:29:29,858 - Epoch: [238][  300/  391]    Overall Loss 0.055621    Objective Loss 0.055621    Top1 98.166667    Top5 99.994792    LR 0.000743    Time 0.019523    
2018-11-02 20:29:30,820 - Epoch: [238][  350/  391]    Overall Loss 0.055549    Objective Loss 0.055549    Top1 98.160714    Top5 99.993304    LR 0.000743    Time 0.019481    
2018-11-02 20:29:31,688 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35998 | -0.00360 |    0.22334 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14204 | -0.00180 |    0.09035 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15152 | -0.00637 |    0.11529 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17242 | -0.03106 |    0.13251 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17617 |  0.00104 |    0.13852 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17205 | -0.02789 |    0.13255 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16215 | -0.00616 |    0.11693 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19577 | -0.00115 |    0.14418 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16397 | -0.00506 |    0.12519 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24788 | -0.00356 |    0.16724 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13738 | -0.00198 |    0.10484 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11957 | -0.00914 |    0.09385 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14167 | -0.01552 |    0.11279 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10771 | -0.00292 |    0.08449 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12813 | -0.01381 |    0.10219 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12522 | -0.00136 |    0.09940 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14520 | -0.01086 |    0.11236 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11499 | -0.00755 |    0.09075 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09834 | -0.00631 |    0.07714 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10406 | -0.01250 |    0.08332 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06266 |  0.00362 |    0.04742 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58050 | -0.00001 |    0.45445 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:29:31,688 - Total sparsity: 0.00

2018-11-02 20:29:31,689 - --- validate (epoch=238)-----------
2018-11-02 20:29:31,689 - 10000 samples (128 per mini-batch)
2018-11-02 20:29:32,407 - Epoch: [238][   50/   78]    Loss 0.387255    Top1 90.421875    Top5 99.656250    
2018-11-02 20:29:32,798 - ==> Top1: 90.320    Top5: 99.690    Loss: 0.390

2018-11-02 20:29:32,798 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:29:32,799 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:29:32,810 - 

2018-11-02 20:29:32,810 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:29:33,828 - Epoch: [239][   50/  391]    Overall Loss 0.054747    Objective Loss 0.054747    Top1 98.375000    Top5 100.000000    LR 0.000706    Time 0.020326    
2018-11-02 20:29:34,787 - Epoch: [239][  100/  391]    Overall Loss 0.054123    Objective Loss 0.054123    Top1 98.375000    Top5 100.000000    LR 0.000706    Time 0.019746    
2018-11-02 20:29:35,749 - Epoch: [239][  150/  391]    Overall Loss 0.053116    Objective Loss 0.053116    Top1 98.380208    Top5 100.000000    LR 0.000706    Time 0.019565    
2018-11-02 20:29:36,714 - Epoch: [239][  200/  391]    Overall Loss 0.053675    Objective Loss 0.053675    Top1 98.339844    Top5 99.996094    LR 0.000706    Time 0.019494    
2018-11-02 20:29:37,675 - Epoch: [239][  250/  391]    Overall Loss 0.053872    Objective Loss 0.053872    Top1 98.268750    Top5 99.996875    LR 0.000706    Time 0.019434    
2018-11-02 20:29:38,637 - Epoch: [239][  300/  391]    Overall Loss 0.054389    Objective Loss 0.054389    Top1 98.239583    Top5 99.997396    LR 0.000706    Time 0.019398    
2018-11-02 20:29:39,598 - Epoch: [239][  350/  391]    Overall Loss 0.055857    Objective Loss 0.055857    Top1 98.185268    Top5 99.991071    LR 0.000706    Time 0.019371    
2018-11-02 20:29:40,471 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35988 | -0.00318 |    0.22329 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14200 | -0.00185 |    0.09034 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15149 | -0.00634 |    0.11526 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17238 | -0.03104 |    0.13250 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17612 |  0.00103 |    0.13848 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17200 | -0.02788 |    0.13253 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16211 | -0.00615 |    0.11691 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19572 | -0.00112 |    0.14414 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16393 | -0.00506 |    0.12516 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24781 | -0.00351 |    0.16717 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13735 | -0.00198 |    0.10481 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11954 | -0.00913 |    0.09383 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14163 | -0.01554 |    0.11275 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10768 | -0.00291 |    0.08446 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12810 | -0.01380 |    0.10216 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12518 | -0.00135 |    0.09938 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14516 | -0.01086 |    0.11233 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11495 | -0.00755 |    0.09072 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09832 | -0.00631 |    0.07712 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10403 | -0.01250 |    0.08330 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06264 |  0.00362 |    0.04741 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58054 | -0.00001 |    0.45449 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:29:40,471 - Total sparsity: 0.00

2018-11-02 20:29:40,472 - --- validate (epoch=239)-----------
2018-11-02 20:29:40,472 - 10000 samples (128 per mini-batch)
2018-11-02 20:29:41,180 - Epoch: [239][   50/   78]    Loss 0.390912    Top1 90.390625    Top5 99.656250    
2018-11-02 20:29:41,564 - ==> Top1: 90.280    Top5: 99.690    Loss: 0.393

2018-11-02 20:29:41,565 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:29:41,565 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:29:41,572 - 

2018-11-02 20:29:41,573 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:29:42,595 - Epoch: [240][   50/  391]    Overall Loss 0.055806    Objective Loss 0.055806    Top1 98.156250    Top5 99.984375    LR 0.000670    Time 0.020407    
2018-11-02 20:29:43,556 - Epoch: [240][  100/  391]    Overall Loss 0.055772    Objective Loss 0.055772    Top1 98.156250    Top5 99.992188    LR 0.000670    Time 0.019799    
2018-11-02 20:29:44,516 - Epoch: [240][  150/  391]    Overall Loss 0.058974    Objective Loss 0.058974    Top1 98.036458    Top5 99.989583    LR 0.000670    Time 0.019593    
2018-11-02 20:29:45,478 - Epoch: [240][  200/  391]    Overall Loss 0.058388    Objective Loss 0.058388    Top1 98.046875    Top5 99.988281    LR 0.000670    Time 0.019498    
2018-11-02 20:29:46,440 - Epoch: [240][  250/  391]    Overall Loss 0.057607    Objective Loss 0.057607    Top1 98.050000    Top5 99.990625    LR 0.000670    Time 0.019426    
2018-11-02 20:29:47,401 - Epoch: [240][  300/  391]    Overall Loss 0.057005    Objective Loss 0.057005    Top1 98.093750    Top5 99.992188    LR 0.000670    Time 0.019387    
2018-11-02 20:29:48,360 - Epoch: [240][  350/  391]    Overall Loss 0.056872    Objective Loss 0.056872    Top1 98.136161    Top5 99.993304    LR 0.000670    Time 0.019355    
2018-11-02 20:29:49,227 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35979 | -0.00325 |    0.22320 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14196 | -0.00184 |    0.09032 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15144 | -0.00638 |    0.11523 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17234 | -0.03102 |    0.13248 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17608 |  0.00098 |    0.13843 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17195 | -0.02791 |    0.13248 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16207 | -0.00614 |    0.11687 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19567 | -0.00112 |    0.14411 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16388 | -0.00503 |    0.12513 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24775 | -0.00350 |    0.16712 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13731 | -0.00199 |    0.10479 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11951 | -0.00910 |    0.09380 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14160 | -0.01552 |    0.11272 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10765 | -0.00289 |    0.08445 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12807 | -0.01381 |    0.10214 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12515 | -0.00134 |    0.09935 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14512 | -0.01086 |    0.11230 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11493 | -0.00753 |    0.09070 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09829 | -0.00632 |    0.07710 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10401 | -0.01249 |    0.08328 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06263 |  0.00362 |    0.04740 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58058 | -0.00001 |    0.45452 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:29:49,228 - Total sparsity: 0.00

2018-11-02 20:29:49,228 - --- validate (epoch=240)-----------
2018-11-02 20:29:49,228 - 10000 samples (128 per mini-batch)
2018-11-02 20:29:49,949 - Epoch: [240][   50/   78]    Loss 0.389785    Top1 90.281250    Top5 99.687500    
2018-11-02 20:29:50,346 - ==> Top1: 90.200    Top5: 99.700    Loss: 0.392

2018-11-02 20:29:50,347 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:29:50,347 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:29:50,361 - 

2018-11-02 20:29:50,361 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:29:51,392 - Epoch: [241][   50/  391]    Overall Loss 0.054751    Objective Loss 0.054751    Top1 98.328125    Top5 100.000000    LR 0.000637    Time 0.020583    
2018-11-02 20:29:52,354 - Epoch: [241][  100/  391]    Overall Loss 0.051511    Objective Loss 0.051511    Top1 98.421875    Top5 100.000000    LR 0.000637    Time 0.019897    
2018-11-02 20:29:53,313 - Epoch: [241][  150/  391]    Overall Loss 0.053034    Objective Loss 0.053034    Top1 98.406250    Top5 100.000000    LR 0.000637    Time 0.019649    
2018-11-02 20:29:54,276 - Epoch: [241][  200/  391]    Overall Loss 0.053709    Objective Loss 0.053709    Top1 98.324219    Top5 100.000000    LR 0.000637    Time 0.019544    
2018-11-02 20:29:55,236 - Epoch: [241][  250/  391]    Overall Loss 0.053962    Objective Loss 0.053962    Top1 98.278125    Top5 100.000000    LR 0.000637    Time 0.019473    
2018-11-02 20:29:56,198 - Epoch: [241][  300/  391]    Overall Loss 0.053456    Objective Loss 0.053456    Top1 98.296875    Top5 99.997396    LR 0.000637    Time 0.019427    
2018-11-02 20:29:57,159 - Epoch: [241][  350/  391]    Overall Loss 0.053376    Objective Loss 0.053376    Top1 98.305804    Top5 99.997768    LR 0.000637    Time 0.019394    
2018-11-02 20:29:58,028 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35970 | -0.00346 |    0.22315 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14193 | -0.00181 |    0.09031 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15141 | -0.00636 |    0.11521 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17230 | -0.03099 |    0.13245 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17603 |  0.00099 |    0.13840 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17191 | -0.02792 |    0.13244 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16203 | -0.00614 |    0.11683 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19562 | -0.00115 |    0.14408 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16384 | -0.00503 |    0.12510 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24769 | -0.00350 |    0.16711 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13728 | -0.00199 |    0.10476 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11948 | -0.00912 |    0.09378 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14156 | -0.01553 |    0.11269 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10763 | -0.00288 |    0.08443 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12803 | -0.01381 |    0.10211 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12512 | -0.00135 |    0.09933 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14509 | -0.01085 |    0.11228 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11490 | -0.00753 |    0.09068 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09827 | -0.00629 |    0.07708 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10398 | -0.01249 |    0.08326 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06261 |  0.00362 |    0.04739 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58064 | -0.00001 |    0.45456 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:29:58,029 - Total sparsity: 0.00

2018-11-02 20:29:58,029 - --- validate (epoch=241)-----------
2018-11-02 20:29:58,029 - 10000 samples (128 per mini-batch)
2018-11-02 20:29:58,751 - Epoch: [241][   50/   78]    Loss 0.388777    Top1 90.359375    Top5 99.687500    
2018-11-02 20:29:59,143 - ==> Top1: 90.230    Top5: 99.700    Loss: 0.392

2018-11-02 20:29:59,144 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:29:59,144 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:29:59,151 - 

2018-11-02 20:29:59,151 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:30:00,171 - Epoch: [242][   50/  391]    Overall Loss 0.054977    Objective Loss 0.054977    Top1 98.078125    Top5 99.984375    LR 0.000605    Time 0.020370    
2018-11-02 20:30:01,136 - Epoch: [242][  100/  391]    Overall Loss 0.054764    Objective Loss 0.054764    Top1 98.117188    Top5 99.984375    LR 0.000605    Time 0.019820    
2018-11-02 20:30:02,098 - Epoch: [242][  150/  391]    Overall Loss 0.057368    Objective Loss 0.057368    Top1 98.026042    Top5 99.984375    LR 0.000605    Time 0.019619    
2018-11-02 20:30:03,061 - Epoch: [242][  200/  391]    Overall Loss 0.057804    Objective Loss 0.057804    Top1 98.062500    Top5 99.988281    LR 0.000605    Time 0.019521    
2018-11-02 20:30:04,021 - Epoch: [242][  250/  391]    Overall Loss 0.056934    Objective Loss 0.056934    Top1 98.090625    Top5 99.987500    LR 0.000605    Time 0.019454    
2018-11-02 20:30:04,985 - Epoch: [242][  300/  391]    Overall Loss 0.055744    Objective Loss 0.055744    Top1 98.119792    Top5 99.986979    LR 0.000605    Time 0.019419    
2018-11-02 20:30:05,945 - Epoch: [242][  350/  391]    Overall Loss 0.056024    Objective Loss 0.056024    Top1 98.109375    Top5 99.988839    LR 0.000605    Time 0.019384    
2018-11-02 20:30:06,825 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35962 | -0.00343 |    0.22310 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14189 | -0.00186 |    0.09029 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15137 | -0.00639 |    0.11518 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17226 | -0.03099 |    0.13242 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17599 |  0.00101 |    0.13837 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17186 | -0.02797 |    0.13239 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16199 | -0.00610 |    0.11681 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19557 | -0.00117 |    0.14405 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16381 | -0.00504 |    0.12507 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24763 | -0.00349 |    0.16707 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13724 | -0.00199 |    0.10474 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11945 | -0.00911 |    0.09376 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14153 | -0.01552 |    0.11266 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10760 | -0.00289 |    0.08441 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12800 | -0.01381 |    0.10209 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12509 | -0.00135 |    0.09930 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14505 | -0.01085 |    0.11225 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11487 | -0.00753 |    0.09066 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09825 | -0.00629 |    0.07706 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10396 | -0.01250 |    0.08324 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06260 |  0.00362 |    0.04738 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58067 | -0.00001 |    0.45459 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:30:06,825 - Total sparsity: 0.00

2018-11-02 20:30:06,826 - --- validate (epoch=242)-----------
2018-11-02 20:30:06,826 - 10000 samples (128 per mini-batch)
2018-11-02 20:30:07,583 - Epoch: [242][   50/   78]    Loss 0.388722    Top1 90.484375    Top5 99.656250    
2018-11-02 20:30:07,976 - ==> Top1: 90.350    Top5: 99.680    Loss: 0.391

2018-11-02 20:30:07,977 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:30:07,977 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:30:07,984 - 

2018-11-02 20:30:07,985 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:30:09,005 - Epoch: [243][   50/  391]    Overall Loss 0.058593    Objective Loss 0.058593    Top1 98.125000    Top5 100.000000    LR 0.000575    Time 0.020388    
2018-11-02 20:30:09,967 - Epoch: [243][  100/  391]    Overall Loss 0.058831    Objective Loss 0.058831    Top1 98.125000    Top5 100.000000    LR 0.000575    Time 0.019791    
2018-11-02 20:30:10,925 - Epoch: [243][  150/  391]    Overall Loss 0.058814    Objective Loss 0.058814    Top1 98.140625    Top5 99.994792    LR 0.000575    Time 0.019574    
2018-11-02 20:30:11,885 - Epoch: [243][  200/  391]    Overall Loss 0.057869    Objective Loss 0.057869    Top1 98.160156    Top5 99.996094    LR 0.000575    Time 0.019478    
2018-11-02 20:30:12,847 - Epoch: [243][  250/  391]    Overall Loss 0.057632    Objective Loss 0.057632    Top1 98.137500    Top5 99.996875    LR 0.000575    Time 0.019426    
2018-11-02 20:30:13,811 - Epoch: [243][  300/  391]    Overall Loss 0.058266    Objective Loss 0.058266    Top1 98.101562    Top5 99.997396    LR 0.000575    Time 0.019398    
2018-11-02 20:30:14,773 - Epoch: [243][  350/  391]    Overall Loss 0.058038    Objective Loss 0.058038    Top1 98.104911    Top5 99.997768    LR 0.000575    Time 0.019372    
2018-11-02 20:30:15,644 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35954 | -0.00361 |    0.22305 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14186 | -0.00187 |    0.09027 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15134 | -0.00633 |    0.11516 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17222 | -0.03099 |    0.13241 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17595 |  0.00097 |    0.13834 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17182 | -0.02798 |    0.13237 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16196 | -0.00611 |    0.11677 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19553 | -0.00116 |    0.14401 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16377 | -0.00502 |    0.12505 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24758 | -0.00346 |    0.16705 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13722 | -0.00196 |    0.10472 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11943 | -0.00913 |    0.09373 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14150 | -0.01551 |    0.11264 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10758 | -0.00289 |    0.08439 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12798 | -0.01379 |    0.10207 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12506 | -0.00133 |    0.09929 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14502 | -0.01084 |    0.11223 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11485 | -0.00754 |    0.09064 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09823 | -0.00629 |    0.07704 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10393 | -0.01249 |    0.08322 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06258 |  0.00362 |    0.04737 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58069 | -0.00001 |    0.45461 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:30:15,644 - Total sparsity: 0.00

2018-11-02 20:30:15,644 - --- validate (epoch=243)-----------
2018-11-02 20:30:15,644 - 10000 samples (128 per mini-batch)
2018-11-02 20:30:16,353 - Epoch: [243][   50/   78]    Loss 0.386128    Top1 90.375000    Top5 99.656250    
2018-11-02 20:30:16,736 - ==> Top1: 90.230    Top5: 99.690    Loss: 0.390

2018-11-02 20:30:16,737 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:30:16,737 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:30:16,745 - 

2018-11-02 20:30:16,745 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:30:17,763 - Epoch: [244][   50/  391]    Overall Loss 0.050099    Objective Loss 0.050099    Top1 98.500000    Top5 100.000000    LR 0.000546    Time 0.020332    
2018-11-02 20:30:18,724 - Epoch: [244][  100/  391]    Overall Loss 0.055844    Objective Loss 0.055844    Top1 98.164062    Top5 100.000000    LR 0.000546    Time 0.019762    
2018-11-02 20:30:19,684 - Epoch: [244][  150/  391]    Overall Loss 0.055780    Objective Loss 0.055780    Top1 98.161458    Top5 100.000000    LR 0.000546    Time 0.019567    
2018-11-02 20:30:20,645 - Epoch: [244][  200/  391]    Overall Loss 0.057080    Objective Loss 0.057080    Top1 98.093750    Top5 100.000000    LR 0.000546    Time 0.019477    
2018-11-02 20:30:21,605 - Epoch: [244][  250/  391]    Overall Loss 0.056444    Objective Loss 0.056444    Top1 98.109375    Top5 99.996875    LR 0.000546    Time 0.019417    
2018-11-02 20:30:22,564 - Epoch: [244][  300/  391]    Overall Loss 0.056767    Objective Loss 0.056767    Top1 98.085938    Top5 99.994792    LR 0.000546    Time 0.019374    
2018-11-02 20:30:23,524 - Epoch: [244][  350/  391]    Overall Loss 0.056769    Objective Loss 0.056769    Top1 98.062500    Top5 99.995536    LR 0.000546    Time 0.019343    
2018-11-02 20:30:24,390 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35946 | -0.00348 |    0.22297 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14183 | -0.00189 |    0.09026 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15131 | -0.00636 |    0.11513 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17218 | -0.03101 |    0.13240 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17592 |  0.00095 |    0.13831 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17178 | -0.02798 |    0.13234 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16192 | -0.00613 |    0.11674 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19549 | -0.00115 |    0.14398 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16374 | -0.00501 |    0.12502 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24752 | -0.00346 |    0.16703 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13719 | -0.00196 |    0.10469 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11940 | -0.00915 |    0.09371 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14147 | -0.01550 |    0.11262 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10756 | -0.00287 |    0.08438 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12795 | -0.01379 |    0.10205 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12504 | -0.00135 |    0.09927 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14499 | -0.01084 |    0.11221 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11482 | -0.00754 |    0.09062 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09820 | -0.00629 |    0.07703 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10391 | -0.01249 |    0.08320 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06257 |  0.00362 |    0.04736 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58072 | -0.00001 |    0.45463 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:30:24,390 - Total sparsity: 0.00

2018-11-02 20:30:24,390 - --- validate (epoch=244)-----------
2018-11-02 20:30:24,390 - 10000 samples (128 per mini-batch)
2018-11-02 20:30:25,104 - Epoch: [244][   50/   78]    Loss 0.390491    Top1 90.375000    Top5 99.703125    
2018-11-02 20:30:25,487 - ==> Top1: 90.310    Top5: 99.710    Loss: 0.392

2018-11-02 20:30:25,488 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:30:25,488 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:30:25,499 - 

2018-11-02 20:30:25,499 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:30:26,516 - Epoch: [245][   50/  391]    Overall Loss 0.054142    Objective Loss 0.054142    Top1 98.203125    Top5 100.000000    LR 0.000519    Time 0.020306    
2018-11-02 20:30:27,476 - Epoch: [245][  100/  391]    Overall Loss 0.056279    Objective Loss 0.056279    Top1 98.164062    Top5 100.000000    LR 0.000519    Time 0.019740    
2018-11-02 20:30:28,437 - Epoch: [245][  150/  391]    Overall Loss 0.054928    Objective Loss 0.054928    Top1 98.229167    Top5 100.000000    LR 0.000519    Time 0.019558    
2018-11-02 20:30:29,397 - Epoch: [245][  200/  391]    Overall Loss 0.054137    Objective Loss 0.054137    Top1 98.246094    Top5 100.000000    LR 0.000519    Time 0.019460    
2018-11-02 20:30:30,358 - Epoch: [245][  250/  391]    Overall Loss 0.055999    Objective Loss 0.055999    Top1 98.171875    Top5 100.000000    LR 0.000519    Time 0.019408    
2018-11-02 20:30:31,318 - Epoch: [245][  300/  391]    Overall Loss 0.055543    Objective Loss 0.055543    Top1 98.197917    Top5 99.997396    LR 0.000519    Time 0.019370    
2018-11-02 20:30:32,277 - Epoch: [245][  350/  391]    Overall Loss 0.055519    Objective Loss 0.055519    Top1 98.205357    Top5 99.997768    LR 0.000519    Time 0.019339    
2018-11-02 20:30:33,141 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35939 | -0.00349 |    0.22298 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14181 | -0.00186 |    0.09024 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15128 | -0.00636 |    0.11511 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17214 | -0.03103 |    0.13237 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17588 |  0.00094 |    0.13828 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17175 | -0.02794 |    0.13231 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16189 | -0.00610 |    0.11672 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19545 | -0.00113 |    0.14395 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16370 | -0.00500 |    0.12499 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24747 | -0.00344 |    0.16700 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13716 | -0.00197 |    0.10467 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11938 | -0.00911 |    0.09370 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14144 | -0.01549 |    0.11260 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10753 | -0.00286 |    0.08436 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12792 | -0.01379 |    0.10202 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12501 | -0.00134 |    0.09924 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14496 | -0.01084 |    0.11218 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11480 | -0.00755 |    0.09060 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09819 | -0.00629 |    0.07702 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10389 | -0.01249 |    0.08319 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06256 |  0.00362 |    0.04735 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58075 | -0.00001 |    0.45467 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:30:33,141 - Total sparsity: 0.00

2018-11-02 20:30:33,141 - --- validate (epoch=245)-----------
2018-11-02 20:30:33,141 - 10000 samples (128 per mini-batch)
2018-11-02 20:30:33,861 - Epoch: [245][   50/   78]    Loss 0.382213    Top1 90.312500    Top5 99.734375    
2018-11-02 20:30:34,254 - ==> Top1: 90.210    Top5: 99.740    Loss: 0.386

2018-11-02 20:30:34,255 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:30:34,255 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:30:34,262 - 

2018-11-02 20:30:34,263 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:30:35,280 - Epoch: [246][   50/  391]    Overall Loss 0.054075    Objective Loss 0.054075    Top1 98.140625    Top5 100.000000    LR 0.000493    Time 0.020317    
2018-11-02 20:30:36,243 - Epoch: [246][  100/  391]    Overall Loss 0.053555    Objective Loss 0.053555    Top1 98.117188    Top5 99.992188    LR 0.000493    Time 0.019774    
2018-11-02 20:30:37,204 - Epoch: [246][  150/  391]    Overall Loss 0.054263    Objective Loss 0.054263    Top1 98.125000    Top5 99.989583    LR 0.000493    Time 0.019579    
2018-11-02 20:30:38,166 - Epoch: [246][  200/  391]    Overall Loss 0.053849    Objective Loss 0.053849    Top1 98.191406    Top5 99.984375    LR 0.000493    Time 0.019490    
2018-11-02 20:30:39,128 - Epoch: [246][  250/  391]    Overall Loss 0.055307    Objective Loss 0.055307    Top1 98.165625    Top5 99.987500    LR 0.000493    Time 0.019434    
2018-11-02 20:30:40,088 - Epoch: [246][  300/  391]    Overall Loss 0.055299    Objective Loss 0.055299    Top1 98.145833    Top5 99.986979    LR 0.000493    Time 0.019392    
2018-11-02 20:30:41,050 - Epoch: [246][  350/  391]    Overall Loss 0.055115    Objective Loss 0.055115    Top1 98.160714    Top5 99.984375    LR 0.000493    Time 0.019366    
2018-11-02 20:30:41,921 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35932 | -0.00329 |    0.22290 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14178 | -0.00190 |    0.09022 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15125 | -0.00640 |    0.11510 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17209 | -0.03108 |    0.13236 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17585 |  0.00090 |    0.13825 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17173 | -0.02790 |    0.13229 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16186 | -0.00611 |    0.11669 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19541 | -0.00121 |    0.14392 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16367 | -0.00500 |    0.12497 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24743 | -0.00343 |    0.16695 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13713 | -0.00198 |    0.10465 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11936 | -0.00910 |    0.09368 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14141 | -0.01549 |    0.11258 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10751 | -0.00285 |    0.08434 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12790 | -0.01378 |    0.10200 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12499 | -0.00132 |    0.09923 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14493 | -0.01085 |    0.11216 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11478 | -0.00754 |    0.09058 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09817 | -0.00627 |    0.07700 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10387 | -0.01250 |    0.08317 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06254 |  0.00362 |    0.04734 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58078 | -0.00001 |    0.45468 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:30:41,921 - Total sparsity: 0.00

2018-11-02 20:30:41,921 - --- validate (epoch=246)-----------
2018-11-02 20:30:41,921 - 10000 samples (128 per mini-batch)
2018-11-02 20:30:42,632 - Epoch: [246][   50/   78]    Loss 0.391497    Top1 90.390625    Top5 99.656250    
2018-11-02 20:30:43,016 - ==> Top1: 90.310    Top5: 99.670    Loss: 0.392

2018-11-02 20:30:43,017 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:30:43,017 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:30:43,025 - 

2018-11-02 20:30:43,025 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:30:44,045 - Epoch: [247][   50/  391]    Overall Loss 0.050233    Objective Loss 0.050233    Top1 98.437500    Top5 100.000000    LR 0.000468    Time 0.020370    
2018-11-02 20:30:45,006 - Epoch: [247][  100/  391]    Overall Loss 0.053510    Objective Loss 0.053510    Top1 98.273438    Top5 99.992188    LR 0.000468    Time 0.019780    
2018-11-02 20:30:45,968 - Epoch: [247][  150/  391]    Overall Loss 0.055741    Objective Loss 0.055741    Top1 98.171875    Top5 99.989583    LR 0.000468    Time 0.019596    
2018-11-02 20:30:46,966 - Epoch: [247][  200/  391]    Overall Loss 0.056465    Objective Loss 0.056465    Top1 98.140625    Top5 99.988281    LR 0.000468    Time 0.019679    
2018-11-02 20:30:47,931 - Epoch: [247][  250/  391]    Overall Loss 0.055676    Objective Loss 0.055676    Top1 98.178125    Top5 99.990625    LR 0.000468    Time 0.019599    
2018-11-02 20:30:48,891 - Epoch: [247][  300/  391]    Overall Loss 0.056232    Objective Loss 0.056232    Top1 98.132812    Top5 99.992188    LR 0.000468    Time 0.019517    
2018-11-02 20:30:49,850 - Epoch: [247][  350/  391]    Overall Loss 0.056315    Objective Loss 0.056315    Top1 98.109375    Top5 99.993304    LR 0.000468    Time 0.019465    
2018-11-02 20:30:50,718 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35926 | -0.00342 |    0.22287 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14175 | -0.00184 |    0.09020 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15122 | -0.00644 |    0.11508 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17206 | -0.03108 |    0.13233 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17582 |  0.00087 |    0.13822 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17169 | -0.02791 |    0.13227 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16183 | -0.00610 |    0.11666 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19538 | -0.00124 |    0.14390 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16364 | -0.00501 |    0.12494 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24738 | -0.00344 |    0.16692 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13711 | -0.00198 |    0.10463 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11934 | -0.00909 |    0.09367 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14139 | -0.01548 |    0.11256 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10750 | -0.00284 |    0.08433 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12788 | -0.01378 |    0.10199 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12497 | -0.00131 |    0.09921 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14491 | -0.01084 |    0.11214 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11476 | -0.00753 |    0.09057 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09815 | -0.00627 |    0.07698 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10385 | -0.01250 |    0.08315 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06253 |  0.00362 |    0.04733 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58080 | -0.00001 |    0.45470 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:30:50,718 - Total sparsity: 0.00

2018-11-02 20:30:50,718 - --- validate (epoch=247)-----------
2018-11-02 20:30:50,718 - 10000 samples (128 per mini-batch)
2018-11-02 20:30:51,437 - Epoch: [247][   50/   78]    Loss 0.387518    Top1 90.343750    Top5 99.671875    
2018-11-02 20:30:51,827 - ==> Top1: 90.270    Top5: 99.690    Loss: 0.389

2018-11-02 20:30:51,828 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:30:51,828 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:30:51,839 - 

2018-11-02 20:30:51,839 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:30:52,889 - Epoch: [248][   50/  391]    Overall Loss 0.059195    Objective Loss 0.059195    Top1 98.140625    Top5 99.984375    LR 0.000445    Time 0.020963    
2018-11-02 20:30:53,851 - Epoch: [248][  100/  391]    Overall Loss 0.055040    Objective Loss 0.055040    Top1 98.148438    Top5 99.992188    LR 0.000445    Time 0.020091    
2018-11-02 20:30:54,814 - Epoch: [248][  150/  391]    Overall Loss 0.053711    Objective Loss 0.053711    Top1 98.218750    Top5 99.994792    LR 0.000445    Time 0.019802    
2018-11-02 20:30:55,776 - Epoch: [248][  200/  391]    Overall Loss 0.054591    Objective Loss 0.054591    Top1 98.164062    Top5 99.996094    LR 0.000445    Time 0.019658    
2018-11-02 20:30:56,739 - Epoch: [248][  250/  391]    Overall Loss 0.055510    Objective Loss 0.055510    Top1 98.146875    Top5 99.996875    LR 0.000445    Time 0.019575    
2018-11-02 20:30:57,701 - Epoch: [248][  300/  391]    Overall Loss 0.055447    Objective Loss 0.055447    Top1 98.153646    Top5 99.997396    LR 0.000445    Time 0.019514    
2018-11-02 20:30:58,665 - Epoch: [248][  350/  391]    Overall Loss 0.056048    Objective Loss 0.056048    Top1 98.142857    Top5 99.995536    LR 0.000445    Time 0.019476    
2018-11-02 20:30:59,530 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35920 | -0.00333 |    0.22283 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14173 | -0.00183 |    0.09018 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15119 | -0.00645 |    0.11507 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17204 | -0.03106 |    0.13230 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17579 |  0.00087 |    0.13820 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17167 | -0.02789 |    0.13224 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16180 | -0.00611 |    0.11665 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19534 | -0.00124 |    0.14387 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16362 | -0.00499 |    0.12492 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24734 | -0.00343 |    0.16690 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13708 | -0.00197 |    0.10462 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11932 | -0.00909 |    0.09365 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14137 | -0.01547 |    0.11254 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10748 | -0.00282 |    0.08432 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12786 | -0.01378 |    0.10197 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12494 | -0.00129 |    0.09919 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14488 | -0.01084 |    0.11212 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11474 | -0.00753 |    0.09055 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09813 | -0.00627 |    0.07697 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10383 | -0.01251 |    0.08314 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06252 |  0.00362 |    0.04732 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58082 | -0.00001 |    0.45473 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:30:59,530 - Total sparsity: 0.00

2018-11-02 20:30:59,530 - --- validate (epoch=248)-----------
2018-11-02 20:30:59,530 - 10000 samples (128 per mini-batch)
2018-11-02 20:31:00,248 - Epoch: [248][   50/   78]    Loss 0.388667    Top1 90.328125    Top5 99.703125    
2018-11-02 20:31:00,638 - ==> Top1: 90.220    Top5: 99.710    Loss: 0.392

2018-11-02 20:31:00,639 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:31:00,639 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:31:00,649 - 

2018-11-02 20:31:00,650 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:31:01,674 - Epoch: [249][   50/  391]    Overall Loss 0.056239    Objective Loss 0.056239    Top1 98.156250    Top5 100.000000    LR 0.000422    Time 0.020442    
2018-11-02 20:31:02,636 - Epoch: [249][  100/  391]    Overall Loss 0.055746    Objective Loss 0.055746    Top1 98.085938    Top5 99.992188    LR 0.000422    Time 0.019833    
2018-11-02 20:31:03,600 - Epoch: [249][  150/  391]    Overall Loss 0.056022    Objective Loss 0.056022    Top1 98.130208    Top5 99.994792    LR 0.000422    Time 0.019639    
2018-11-02 20:31:04,562 - Epoch: [249][  200/  391]    Overall Loss 0.056773    Objective Loss 0.056773    Top1 98.140625    Top5 99.996094    LR 0.000422    Time 0.019537    
2018-11-02 20:31:05,524 - Epoch: [249][  250/  391]    Overall Loss 0.056947    Objective Loss 0.056947    Top1 98.078125    Top5 99.996875    LR 0.000422    Time 0.019457    
2018-11-02 20:31:06,484 - Epoch: [249][  300/  391]    Overall Loss 0.056835    Objective Loss 0.056835    Top1 98.109375    Top5 99.997396    LR 0.000422    Time 0.019410    
2018-11-02 20:31:07,445 - Epoch: [249][  350/  391]    Overall Loss 0.056371    Objective Loss 0.056371    Top1 98.116071    Top5 99.997768    LR 0.000422    Time 0.019380    
2018-11-02 20:31:08,316 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35914 | -0.00328 |    0.22277 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14171 | -0.00185 |    0.09017 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15117 | -0.00642 |    0.11505 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17201 | -0.03102 |    0.13228 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17576 |  0.00088 |    0.13817 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17163 | -0.02793 |    0.13222 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16178 | -0.00612 |    0.11664 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19531 | -0.00125 |    0.14385 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16359 | -0.00498 |    0.12490 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24730 | -0.00345 |    0.16688 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13706 | -0.00197 |    0.10460 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11930 | -0.00908 |    0.09364 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14134 | -0.01546 |    0.11252 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10746 | -0.00282 |    0.08431 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12783 | -0.01377 |    0.10195 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12492 | -0.00130 |    0.09917 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14486 | -0.01084 |    0.11210 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11472 | -0.00753 |    0.09054 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09812 | -0.00627 |    0.07696 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10382 | -0.01250 |    0.08313 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06251 |  0.00363 |    0.04732 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58084 | -0.00001 |    0.45474 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:31:08,316 - Total sparsity: 0.00

2018-11-02 20:31:08,316 - --- validate (epoch=249)-----------
2018-11-02 20:31:08,316 - 10000 samples (128 per mini-batch)
2018-11-02 20:31:09,048 - Epoch: [249][   50/   78]    Loss 0.385737    Top1 90.203125    Top5 99.656250    
2018-11-02 20:31:09,439 - ==> Top1: 90.140    Top5: 99.670    Loss: 0.389

2018-11-02 20:31:09,440 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:31:09,440 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:31:09,447 - 

2018-11-02 20:31:09,447 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:31:10,536 - Epoch: [250][   50/  391]    Overall Loss 0.051014    Objective Loss 0.051014    Top1 98.343750    Top5 100.000000    LR 0.000401    Time 0.021751    
2018-11-02 20:31:11,558 - Epoch: [250][  100/  391]    Overall Loss 0.051584    Objective Loss 0.051584    Top1 98.234375    Top5 100.000000    LR 0.000401    Time 0.021079    
2018-11-02 20:31:12,540 - Epoch: [250][  150/  391]    Overall Loss 0.053955    Objective Loss 0.053955    Top1 98.182292    Top5 99.994792    LR 0.000401    Time 0.020595    
2018-11-02 20:31:13,498 - Epoch: [250][  200/  391]    Overall Loss 0.055817    Objective Loss 0.055817    Top1 98.078125    Top5 99.996094    LR 0.000401    Time 0.020230    
2018-11-02 20:31:14,462 - Epoch: [250][  250/  391]    Overall Loss 0.055595    Objective Loss 0.055595    Top1 98.090625    Top5 99.993750    LR 0.000401    Time 0.020035    
2018-11-02 20:31:15,426 - Epoch: [250][  300/  391]    Overall Loss 0.055284    Objective Loss 0.055284    Top1 98.109375    Top5 99.994792    LR 0.000401    Time 0.019904    
2018-11-02 20:31:16,389 - Epoch: [250][  350/  391]    Overall Loss 0.055675    Objective Loss 0.055675    Top1 98.098214    Top5 99.995536    LR 0.000401    Time 0.019808    
2018-11-02 20:31:17,258 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35908 | -0.00320 |    0.22274 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14168 | -0.00191 |    0.09015 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15114 | -0.00646 |    0.11503 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17198 | -0.03103 |    0.13227 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17573 |  0.00092 |    0.13816 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17161 | -0.02791 |    0.13220 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16175 | -0.00609 |    0.11662 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19528 | -0.00123 |    0.14383 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16356 | -0.00496 |    0.12488 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24726 | -0.00342 |    0.16684 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13704 | -0.00197 |    0.10458 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11928 | -0.00906 |    0.09363 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14132 | -0.01545 |    0.11250 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10744 | -0.00281 |    0.08429 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12781 | -0.01378 |    0.10193 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12491 | -0.00129 |    0.09916 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14484 | -0.01084 |    0.11208 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11470 | -0.00753 |    0.09052 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09810 | -0.00626 |    0.07695 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10380 | -0.01250 |    0.08311 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06250 |  0.00363 |    0.04731 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58086 | -0.00001 |    0.45475 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:31:17,258 - Total sparsity: 0.00

2018-11-02 20:31:17,258 - --- validate (epoch=250)-----------
2018-11-02 20:31:17,258 - 10000 samples (128 per mini-batch)
2018-11-02 20:31:17,962 - Epoch: [250][   50/   78]    Loss 0.387532    Top1 90.296875    Top5 99.687500    
2018-11-02 20:31:18,344 - ==> Top1: 90.230    Top5: 99.690    Loss: 0.389

2018-11-02 20:31:18,345 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:31:18,345 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:31:18,352 - 

2018-11-02 20:31:18,353 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:31:19,370 - Epoch: [251][   50/  391]    Overall Loss 0.056353    Objective Loss 0.056353    Top1 98.156250    Top5 99.984375    LR 0.000381    Time 0.020307    
2018-11-02 20:31:20,332 - Epoch: [251][  100/  391]    Overall Loss 0.051736    Objective Loss 0.051736    Top1 98.304688    Top5 99.992188    LR 0.000381    Time 0.019765    
2018-11-02 20:31:21,292 - Epoch: [251][  150/  391]    Overall Loss 0.052139    Objective Loss 0.052139    Top1 98.239583    Top5 99.994792    LR 0.000381    Time 0.019571    
2018-11-02 20:31:22,270 - Epoch: [251][  200/  391]    Overall Loss 0.052569    Objective Loss 0.052569    Top1 98.269531    Top5 99.996094    LR 0.000381    Time 0.019558    
2018-11-02 20:31:23,234 - Epoch: [251][  250/  391]    Overall Loss 0.053271    Objective Loss 0.053271    Top1 98.250000    Top5 99.996875    LR 0.000381    Time 0.019500    
2018-11-02 20:31:24,197 - Epoch: [251][  300/  391]    Overall Loss 0.053065    Objective Loss 0.053065    Top1 98.270833    Top5 99.994792    LR 0.000381    Time 0.019455    
2018-11-02 20:31:25,163 - Epoch: [251][  350/  391]    Overall Loss 0.053904    Objective Loss 0.053904    Top1 98.243304    Top5 99.995536    LR 0.000381    Time 0.019434    
2018-11-02 20:31:26,058 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35903 | -0.00328 |    0.22271 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14166 | -0.00191 |    0.09014 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15112 | -0.00647 |    0.11501 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17197 | -0.03099 |    0.13224 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17570 |  0.00092 |    0.13813 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17159 | -0.02786 |    0.13218 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16173 | -0.00611 |    0.11660 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19525 | -0.00120 |    0.14380 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16354 | -0.00496 |    0.12486 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24722 | -0.00341 |    0.16681 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13702 | -0.00197 |    0.10457 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11926 | -0.00906 |    0.09361 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14130 | -0.01544 |    0.11248 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10743 | -0.00281 |    0.08428 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12780 | -0.01378 |    0.10192 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12489 | -0.00129 |    0.09915 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14481 | -0.01084 |    0.11206 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11468 | -0.00753 |    0.09051 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09809 | -0.00627 |    0.07694 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10378 | -0.01250 |    0.08310 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06249 |  0.00362 |    0.04730 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58089 | -0.00001 |    0.45477 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:31:26,059 - Total sparsity: 0.00

2018-11-02 20:31:26,059 - --- validate (epoch=251)-----------
2018-11-02 20:31:26,059 - 10000 samples (128 per mini-batch)
2018-11-02 20:31:26,781 - Epoch: [251][   50/   78]    Loss 0.391134    Top1 90.265625    Top5 99.687500    
2018-11-02 20:31:27,168 - ==> Top1: 90.170    Top5: 99.690    Loss: 0.392

2018-11-02 20:31:27,169 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:31:27,169 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:31:27,180 - 

2018-11-02 20:31:27,180 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:31:28,198 - Epoch: [252][   50/  391]    Overall Loss 0.058264    Objective Loss 0.058264    Top1 97.875000    Top5 99.984375    LR 0.000362    Time 0.020325    
2018-11-02 20:31:29,159 - Epoch: [252][  100/  391]    Overall Loss 0.055343    Objective Loss 0.055343    Top1 98.101562    Top5 99.984375    LR 0.000362    Time 0.019759    
2018-11-02 20:31:30,119 - Epoch: [252][  150/  391]    Overall Loss 0.053708    Objective Loss 0.053708    Top1 98.166667    Top5 99.984375    LR 0.000362    Time 0.019565    
2018-11-02 20:31:31,150 - Epoch: [252][  200/  391]    Overall Loss 0.054161    Objective Loss 0.054161    Top1 98.175781    Top5 99.984375    LR 0.000362    Time 0.019822    
2018-11-02 20:31:32,112 - Epoch: [252][  250/  391]    Overall Loss 0.054427    Objective Loss 0.054427    Top1 98.140625    Top5 99.987500    LR 0.000362    Time 0.019701    
2018-11-02 20:31:33,073 - Epoch: [252][  300/  391]    Overall Loss 0.054759    Objective Loss 0.054759    Top1 98.132812    Top5 99.989583    LR 0.000362    Time 0.019617    
2018-11-02 20:31:34,036 - Epoch: [252][  350/  391]    Overall Loss 0.054575    Objective Loss 0.054575    Top1 98.147321    Top5 99.991071    LR 0.000362    Time 0.019563    
2018-11-02 20:31:34,904 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35898 | -0.00327 |    0.22268 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14164 | -0.00192 |    0.09013 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15110 | -0.00641 |    0.11499 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17195 | -0.03096 |    0.13222 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17568 |  0.00091 |    0.13811 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17156 | -0.02786 |    0.13217 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16171 | -0.00610 |    0.11659 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19523 | -0.00119 |    0.14378 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16352 | -0.00496 |    0.12485 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24719 | -0.00343 |    0.16679 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13700 | -0.00195 |    0.10455 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11925 | -0.00906 |    0.09360 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14128 | -0.01543 |    0.11246 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10741 | -0.00281 |    0.08427 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12778 | -0.01377 |    0.10190 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12487 | -0.00129 |    0.09913 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14479 | -0.01084 |    0.11205 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11467 | -0.00753 |    0.09050 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09807 | -0.00626 |    0.07693 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10377 | -0.01250 |    0.08309 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06248 |  0.00362 |    0.04730 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58091 | -0.00001 |    0.45479 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:31:34,905 - Total sparsity: 0.00

2018-11-02 20:31:34,905 - --- validate (epoch=252)-----------
2018-11-02 20:31:34,905 - 10000 samples (128 per mini-batch)
2018-11-02 20:31:35,620 - Epoch: [252][   50/   78]    Loss 0.387329    Top1 90.265625    Top5 99.640625    
2018-11-02 20:31:36,006 - ==> Top1: 90.140    Top5: 99.670    Loss: 0.391

2018-11-02 20:31:36,006 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:31:36,007 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:31:36,013 - 

2018-11-02 20:31:36,014 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:31:37,034 - Epoch: [253][   50/  391]    Overall Loss 0.052360    Objective Loss 0.052360    Top1 98.250000    Top5 100.000000    LR 0.000344    Time 0.020380    
2018-11-02 20:31:38,000 - Epoch: [253][  100/  391]    Overall Loss 0.054689    Objective Loss 0.054689    Top1 98.132812    Top5 99.992188    LR 0.000344    Time 0.019830    
2018-11-02 20:31:38,961 - Epoch: [253][  150/  391]    Overall Loss 0.055773    Objective Loss 0.055773    Top1 98.057292    Top5 99.989583    LR 0.000344    Time 0.019620    
2018-11-02 20:31:39,922 - Epoch: [253][  200/  391]    Overall Loss 0.056022    Objective Loss 0.056022    Top1 98.050781    Top5 99.992188    LR 0.000344    Time 0.019514    
2018-11-02 20:31:40,884 - Epoch: [253][  250/  391]    Overall Loss 0.055458    Objective Loss 0.055458    Top1 98.112500    Top5 99.984375    LR 0.000344    Time 0.019441    
2018-11-02 20:31:41,845 - Epoch: [253][  300/  391]    Overall Loss 0.055492    Objective Loss 0.055492    Top1 98.104167    Top5 99.986979    LR 0.000344    Time 0.019401    
2018-11-02 20:31:42,810 - Epoch: [253][  350/  391]    Overall Loss 0.055332    Objective Loss 0.055332    Top1 98.107143    Top5 99.988839    LR 0.000344    Time 0.019383    
2018-11-02 20:31:43,678 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35893 | -0.00336 |    0.22268 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14162 | -0.00191 |    0.09012 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15108 | -0.00641 |    0.11498 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17193 | -0.03094 |    0.13220 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17566 |  0.00092 |    0.13809 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17154 | -0.02785 |    0.13215 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16169 | -0.00607 |    0.11657 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19520 | -0.00119 |    0.14376 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16349 | -0.00496 |    0.12483 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24716 | -0.00344 |    0.16676 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13698 | -0.00196 |    0.10454 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11923 | -0.00906 |    0.09358 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14126 | -0.01544 |    0.11245 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10740 | -0.00282 |    0.08426 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12776 | -0.01377 |    0.10189 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12485 | -0.00129 |    0.09912 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14477 | -0.01085 |    0.11203 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11465 | -0.00753 |    0.09048 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09806 | -0.00625 |    0.07692 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10375 | -0.01251 |    0.08308 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06248 |  0.00362 |    0.04729 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58093 | -0.00001 |    0.45480 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:31:43,678 - Total sparsity: 0.00

2018-11-02 20:31:43,678 - --- validate (epoch=253)-----------
2018-11-02 20:31:43,678 - 10000 samples (128 per mini-batch)
2018-11-02 20:31:44,404 - Epoch: [253][   50/   78]    Loss 0.386183    Top1 90.281250    Top5 99.687500    
2018-11-02 20:31:44,799 - ==> Top1: 90.170    Top5: 99.700    Loss: 0.389

2018-11-02 20:31:44,800 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:31:44,800 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:31:44,814 - 

2018-11-02 20:31:44,815 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:31:45,830 - Epoch: [254][   50/  391]    Overall Loss 0.055043    Objective Loss 0.055043    Top1 98.265625    Top5 99.968750    LR 0.000327    Time 0.020280    
2018-11-02 20:31:46,791 - Epoch: [254][  100/  391]    Overall Loss 0.053592    Objective Loss 0.053592    Top1 98.273438    Top5 99.976562    LR 0.000327    Time 0.019735    
2018-11-02 20:31:47,752 - Epoch: [254][  150/  391]    Overall Loss 0.053688    Objective Loss 0.053688    Top1 98.265625    Top5 99.984375    LR 0.000327    Time 0.019556    
2018-11-02 20:31:48,712 - Epoch: [254][  200/  391]    Overall Loss 0.054234    Objective Loss 0.054234    Top1 98.265625    Top5 99.984375    LR 0.000327    Time 0.019460    
2018-11-02 20:31:49,675 - Epoch: [254][  250/  391]    Overall Loss 0.055440    Objective Loss 0.055440    Top1 98.196875    Top5 99.987500    LR 0.000327    Time 0.019417    
2018-11-02 20:31:50,637 - Epoch: [254][  300/  391]    Overall Loss 0.055927    Objective Loss 0.055927    Top1 98.179688    Top5 99.986979    LR 0.000327    Time 0.019382    
2018-11-02 20:31:51,600 - Epoch: [254][  350/  391]    Overall Loss 0.056131    Objective Loss 0.056131    Top1 98.187500    Top5 99.986607    LR 0.000327    Time 0.019361    
2018-11-02 20:31:52,470 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35889 | -0.00324 |    0.22264 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14161 | -0.00191 |    0.09011 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15106 | -0.00640 |    0.11497 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17190 | -0.03093 |    0.13219 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17563 |  0.00092 |    0.13807 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17152 | -0.02783 |    0.13213 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16167 | -0.00605 |    0.11656 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19518 | -0.00119 |    0.14374 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16347 | -0.00497 |    0.12481 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24712 | -0.00344 |    0.16675 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13697 | -0.00196 |    0.10453 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11921 | -0.00907 |    0.09357 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14125 | -0.01543 |    0.11243 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10738 | -0.00283 |    0.08425 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12774 | -0.01377 |    0.10187 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12484 | -0.00129 |    0.09911 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14475 | -0.01084 |    0.11202 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11464 | -0.00753 |    0.09047 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09805 | -0.00625 |    0.07691 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10374 | -0.01251 |    0.08307 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06247 |  0.00362 |    0.04728 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58095 | -0.00001 |    0.45482 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:31:52,470 - Total sparsity: 0.00

2018-11-02 20:31:52,470 - --- validate (epoch=254)-----------
2018-11-02 20:31:52,470 - 10000 samples (128 per mini-batch)
2018-11-02 20:31:53,189 - Epoch: [254][   50/   78]    Loss 0.385471    Top1 90.281250    Top5 99.640625    
2018-11-02 20:31:53,580 - ==> Top1: 90.160    Top5: 99.660    Loss: 0.389

2018-11-02 20:31:53,581 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:31:53,581 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:31:53,588 - 

2018-11-02 20:31:53,589 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:31:54,607 - Epoch: [255][   50/  391]    Overall Loss 0.049545    Objective Loss 0.049545    Top1 98.359375    Top5 100.000000    LR 0.000311    Time 0.020332    
2018-11-02 20:31:55,568 - Epoch: [255][  100/  391]    Overall Loss 0.053605    Objective Loss 0.053605    Top1 98.242188    Top5 100.000000    LR 0.000311    Time 0.019763    
2018-11-02 20:31:56,529 - Epoch: [255][  150/  391]    Overall Loss 0.054658    Objective Loss 0.054658    Top1 98.161458    Top5 100.000000    LR 0.000311    Time 0.019572    
2018-11-02 20:31:57,492 - Epoch: [255][  200/  391]    Overall Loss 0.055077    Objective Loss 0.055077    Top1 98.164062    Top5 99.996094    LR 0.000311    Time 0.019492    
2018-11-02 20:31:58,454 - Epoch: [255][  250/  391]    Overall Loss 0.054499    Objective Loss 0.054499    Top1 98.200000    Top5 99.996875    LR 0.000311    Time 0.019437    
2018-11-02 20:31:59,415 - Epoch: [255][  300/  391]    Overall Loss 0.054226    Objective Loss 0.054226    Top1 98.213542    Top5 99.994792    LR 0.000311    Time 0.019396    
2018-11-02 20:32:00,380 - Epoch: [255][  350/  391]    Overall Loss 0.053310    Objective Loss 0.053310    Top1 98.258929    Top5 99.995536    LR 0.000311    Time 0.019378    
2018-11-02 20:32:01,249 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35884 | -0.00329 |    0.22261 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14159 | -0.00192 |    0.09010 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15105 | -0.00640 |    0.11496 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17188 | -0.03095 |    0.13217 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17561 |  0.00088 |    0.13806 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17150 | -0.02784 |    0.13212 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16165 | -0.00605 |    0.11655 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19515 | -0.00116 |    0.14372 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16345 | -0.00498 |    0.12480 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24709 | -0.00345 |    0.16673 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13695 | -0.00196 |    0.10452 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11920 | -0.00907 |    0.09356 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14123 | -0.01543 |    0.11241 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10737 | -0.00283 |    0.08424 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12773 | -0.01377 |    0.10186 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12482 | -0.00130 |    0.09909 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14474 | -0.01084 |    0.11201 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11462 | -0.00753 |    0.09046 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09804 | -0.00624 |    0.07689 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10373 | -0.01251 |    0.08306 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06246 |  0.00362 |    0.04728 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58097 | -0.00001 |    0.45483 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:32:01,249 - Total sparsity: 0.00

2018-11-02 20:32:01,250 - --- validate (epoch=255)-----------
2018-11-02 20:32:01,250 - 10000 samples (128 per mini-batch)
2018-11-02 20:32:01,970 - Epoch: [255][   50/   78]    Loss 0.385737    Top1 90.359375    Top5 99.671875    
2018-11-02 20:32:02,360 - ==> Top1: 90.250    Top5: 99.680    Loss: 0.388

2018-11-02 20:32:02,360 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:32:02,361 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:32:02,368 - 

2018-11-02 20:32:02,368 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:32:03,388 - Epoch: [256][   50/  391]    Overall Loss 0.056232    Objective Loss 0.056232    Top1 98.234375    Top5 100.000000    LR 0.000295    Time 0.020363    
2018-11-02 20:32:04,349 - Epoch: [256][  100/  391]    Overall Loss 0.056301    Objective Loss 0.056301    Top1 98.132812    Top5 99.984375    LR 0.000295    Time 0.019775    
2018-11-02 20:32:05,327 - Epoch: [256][  150/  391]    Overall Loss 0.056586    Objective Loss 0.056586    Top1 98.125000    Top5 99.984375    LR 0.000295    Time 0.019699    
2018-11-02 20:32:06,336 - Epoch: [256][  200/  391]    Overall Loss 0.055986    Objective Loss 0.055986    Top1 98.136719    Top5 99.988281    LR 0.000295    Time 0.019812    
2018-11-02 20:32:07,334 - Epoch: [256][  250/  391]    Overall Loss 0.056644    Objective Loss 0.056644    Top1 98.050000    Top5 99.990625    LR 0.000295    Time 0.019836    
2018-11-02 20:32:08,297 - Epoch: [256][  300/  391]    Overall Loss 0.056574    Objective Loss 0.056574    Top1 98.057292    Top5 99.992188    LR 0.000295    Time 0.019736    
2018-11-02 20:32:09,259 - Epoch: [256][  350/  391]    Overall Loss 0.055663    Objective Loss 0.055663    Top1 98.091518    Top5 99.993304    LR 0.000295    Time 0.019663    
2018-11-02 20:32:10,127 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35880 | -0.00327 |    0.22258 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14157 | -0.00193 |    0.09009 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15103 | -0.00639 |    0.11495 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17186 | -0.03096 |    0.13216 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17559 |  0.00090 |    0.13805 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17148 | -0.02782 |    0.13209 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16163 | -0.00604 |    0.11654 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19513 | -0.00115 |    0.14371 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16344 | -0.00498 |    0.12479 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24707 | -0.00345 |    0.16671 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13693 | -0.00198 |    0.10451 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11919 | -0.00907 |    0.09355 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14121 | -0.01543 |    0.11239 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10736 | -0.00283 |    0.08423 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12771 | -0.01377 |    0.10185 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12481 | -0.00130 |    0.09908 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14472 | -0.01084 |    0.11200 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11461 | -0.00753 |    0.09045 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09803 | -0.00624 |    0.07689 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10372 | -0.01252 |    0.08305 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06245 |  0.00362 |    0.04727 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58099 | -0.00001 |    0.45485 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:32:10,127 - Total sparsity: 0.00

2018-11-02 20:32:10,127 - --- validate (epoch=256)-----------
2018-11-02 20:32:10,127 - 10000 samples (128 per mini-batch)
2018-11-02 20:32:10,851 - Epoch: [256][   50/   78]    Loss 0.388201    Top1 90.265625    Top5 99.671875    
2018-11-02 20:32:11,245 - ==> Top1: 90.120    Top5: 99.680    Loss: 0.393

2018-11-02 20:32:11,246 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:32:11,246 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:32:11,258 - 

2018-11-02 20:32:11,258 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:32:12,351 - Epoch: [257][   50/  391]    Overall Loss 0.050475    Objective Loss 0.050475    Top1 98.390625    Top5 100.000000    LR 0.000280    Time 0.021823    
2018-11-02 20:32:13,384 - Epoch: [257][  100/  391]    Overall Loss 0.052633    Objective Loss 0.052633    Top1 98.226562    Top5 100.000000    LR 0.000280    Time 0.021234    
2018-11-02 20:32:14,431 - Epoch: [257][  150/  391]    Overall Loss 0.055608    Objective Loss 0.055608    Top1 98.109375    Top5 100.000000    LR 0.000280    Time 0.021128    
2018-11-02 20:32:15,468 - Epoch: [257][  200/  391]    Overall Loss 0.056296    Objective Loss 0.056296    Top1 98.148438    Top5 99.996094    LR 0.000280    Time 0.021022    
2018-11-02 20:32:16,505 - Epoch: [257][  250/  391]    Overall Loss 0.055458    Objective Loss 0.055458    Top1 98.159375    Top5 99.996875    LR 0.000280    Time 0.020964    
2018-11-02 20:32:17,518 - Epoch: [257][  300/  391]    Overall Loss 0.055600    Objective Loss 0.055600    Top1 98.171875    Top5 99.997396    LR 0.000280    Time 0.020841    
2018-11-02 20:32:18,478 - Epoch: [257][  350/  391]    Overall Loss 0.056044    Objective Loss 0.056044    Top1 98.158482    Top5 99.997768    LR 0.000280    Time 0.020604    
2018-11-02 20:32:19,347 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35876 | -0.00322 |    0.22257 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14156 | -0.00191 |    0.09009 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15101 | -0.00639 |    0.11493 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17184 | -0.03096 |    0.13215 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17557 |  0.00092 |    0.13803 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17146 | -0.02782 |    0.13208 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16161 | -0.00600 |    0.11653 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19511 | -0.00112 |    0.14370 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16342 | -0.00498 |    0.12478 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24704 | -0.00344 |    0.16669 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13692 | -0.00198 |    0.10450 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11917 | -0.00907 |    0.09353 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14120 | -0.01541 |    0.11238 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10735 | -0.00284 |    0.08422 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12770 | -0.01376 |    0.10184 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12479 | -0.00129 |    0.09907 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14471 | -0.01083 |    0.11199 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11460 | -0.00753 |    0.09044 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09802 | -0.00623 |    0.07688 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10370 | -0.01252 |    0.08304 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06245 |  0.00362 |    0.04727 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58100 | -0.00001 |    0.45486 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:32:19,347 - Total sparsity: 0.00

2018-11-02 20:32:19,347 - --- validate (epoch=257)-----------
2018-11-02 20:32:19,347 - 10000 samples (128 per mini-batch)
2018-11-02 20:32:20,064 - Epoch: [257][   50/   78]    Loss 0.389465    Top1 90.328125    Top5 99.687500    
2018-11-02 20:32:20,467 - ==> Top1: 90.200    Top5: 99.700    Loss: 0.395

2018-11-02 20:32:20,468 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:32:20,468 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:32:20,475 - 

2018-11-02 20:32:20,476 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:32:21,495 - Epoch: [258][   50/  391]    Overall Loss 0.051153    Objective Loss 0.051153    Top1 98.359375    Top5 99.984375    LR 0.000266    Time 0.020353    
2018-11-02 20:32:22,455 - Epoch: [258][  100/  391]    Overall Loss 0.052126    Objective Loss 0.052126    Top1 98.296875    Top5 99.984375    LR 0.000266    Time 0.019767    
2018-11-02 20:32:23,414 - Epoch: [258][  150/  391]    Overall Loss 0.053078    Objective Loss 0.053078    Top1 98.255208    Top5 99.984375    LR 0.000266    Time 0.019568    
2018-11-02 20:32:24,375 - Epoch: [258][  200/  391]    Overall Loss 0.054240    Objective Loss 0.054240    Top1 98.226562    Top5 99.988281    LR 0.000266    Time 0.019468    
2018-11-02 20:32:25,341 - Epoch: [258][  250/  391]    Overall Loss 0.053498    Objective Loss 0.053498    Top1 98.265625    Top5 99.990625    LR 0.000266    Time 0.019437    
2018-11-02 20:32:26,306 - Epoch: [258][  300/  391]    Overall Loss 0.053930    Objective Loss 0.053930    Top1 98.252604    Top5 99.992188    LR 0.000266    Time 0.019409    
2018-11-02 20:32:27,331 - Epoch: [258][  350/  391]    Overall Loss 0.053322    Objective Loss 0.053322    Top1 98.258929    Top5 99.993304    LR 0.000266    Time 0.019560    
2018-11-02 20:32:28,245 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35872 | -0.00335 |    0.22254 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14154 | -0.00191 |    0.09007 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15100 | -0.00637 |    0.11492 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17182 | -0.03095 |    0.13214 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17556 |  0.00092 |    0.13802 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17145 | -0.02782 |    0.13206 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16160 | -0.00600 |    0.11652 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19509 | -0.00111 |    0.14369 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16340 | -0.00497 |    0.12476 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24701 | -0.00344 |    0.16667 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13691 | -0.00198 |    0.10448 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11916 | -0.00907 |    0.09352 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14118 | -0.01541 |    0.11236 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10734 | -0.00284 |    0.08421 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12769 | -0.01376 |    0.10183 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12478 | -0.00129 |    0.09906 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14469 | -0.01082 |    0.11198 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11459 | -0.00753 |    0.09043 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09801 | -0.00623 |    0.07687 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10369 | -0.01252 |    0.08303 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06244 |  0.00362 |    0.04726 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58102 | -0.00001 |    0.45487 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:32:28,245 - Total sparsity: 0.00

2018-11-02 20:32:28,245 - --- validate (epoch=258)-----------
2018-11-02 20:32:28,245 - 10000 samples (128 per mini-batch)
2018-11-02 20:32:28,967 - Epoch: [258][   50/   78]    Loss 0.389920    Top1 90.359375    Top5 99.656250    
2018-11-02 20:32:29,359 - ==> Top1: 90.280    Top5: 99.670    Loss: 0.393

2018-11-02 20:32:29,360 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:32:29,360 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:32:29,367 - 

2018-11-02 20:32:29,367 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:32:30,388 - Epoch: [259][   50/  391]    Overall Loss 0.057920    Objective Loss 0.057920    Top1 98.093750    Top5 100.000000    LR 0.000253    Time 0.020388    
2018-11-02 20:32:31,355 - Epoch: [259][  100/  391]    Overall Loss 0.055263    Objective Loss 0.055263    Top1 98.210938    Top5 99.992188    LR 0.000253    Time 0.019849    
2018-11-02 20:32:32,321 - Epoch: [259][  150/  391]    Overall Loss 0.054979    Objective Loss 0.054979    Top1 98.151042    Top5 99.994792    LR 0.000253    Time 0.019662    
2018-11-02 20:32:33,285 - Epoch: [259][  200/  391]    Overall Loss 0.052747    Objective Loss 0.052747    Top1 98.250000    Top5 99.996094    LR 0.000253    Time 0.019564    
2018-11-02 20:32:34,247 - Epoch: [259][  250/  391]    Overall Loss 0.053173    Objective Loss 0.053173    Top1 98.231250    Top5 99.993750    LR 0.000253    Time 0.019493    
2018-11-02 20:32:35,208 - Epoch: [259][  300/  391]    Overall Loss 0.053143    Objective Loss 0.053143    Top1 98.213542    Top5 99.994792    LR 0.000253    Time 0.019445    
2018-11-02 20:32:36,170 - Epoch: [259][  350/  391]    Overall Loss 0.052406    Objective Loss 0.052406    Top1 98.236607    Top5 99.993304    LR 0.000253    Time 0.019413    
2018-11-02 20:32:37,041 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35869 | -0.00325 |    0.22253 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14153 | -0.00191 |    0.09007 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15098 | -0.00638 |    0.11491 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17181 | -0.03094 |    0.13213 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17554 |  0.00092 |    0.13801 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17143 | -0.02782 |    0.13206 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16158 | -0.00599 |    0.11651 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19507 | -0.00111 |    0.14368 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16339 | -0.00496 |    0.12475 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24699 | -0.00343 |    0.16666 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13689 | -0.00198 |    0.10448 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11915 | -0.00906 |    0.09351 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14117 | -0.01541 |    0.11235 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10733 | -0.00284 |    0.08420 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12767 | -0.01376 |    0.10182 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12477 | -0.00129 |    0.09905 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14468 | -0.01082 |    0.11197 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11458 | -0.00752 |    0.09042 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09800 | -0.00623 |    0.07686 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10368 | -0.01252 |    0.08302 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06243 |  0.00362 |    0.04726 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58103 | -0.00001 |    0.45489 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:32:37,041 - Total sparsity: 0.00

2018-11-02 20:32:37,041 - --- validate (epoch=259)-----------
2018-11-02 20:32:37,041 - 10000 samples (128 per mini-batch)
2018-11-02 20:32:37,765 - Epoch: [259][   50/   78]    Loss 0.390661    Top1 90.359375    Top5 99.656250    
2018-11-02 20:32:38,157 - ==> Top1: 90.260    Top5: 99.670    Loss: 0.395

2018-11-02 20:32:38,158 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:32:38,158 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:32:38,170 - 

2018-11-02 20:32:38,170 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:32:39,187 - Epoch: [260][   50/  391]    Overall Loss 0.052689    Objective Loss 0.052689    Top1 98.281250    Top5 99.984375    LR 0.000240    Time 0.020302    
2018-11-02 20:32:40,149 - Epoch: [260][  100/  391]    Overall Loss 0.056163    Objective Loss 0.056163    Top1 98.210938    Top5 99.984375    LR 0.000240    Time 0.019762    
2018-11-02 20:32:41,111 - Epoch: [260][  150/  391]    Overall Loss 0.055421    Objective Loss 0.055421    Top1 98.218750    Top5 99.989583    LR 0.000240    Time 0.019577    
2018-11-02 20:32:42,072 - Epoch: [260][  200/  391]    Overall Loss 0.055740    Objective Loss 0.055740    Top1 98.179688    Top5 99.992188    LR 0.000240    Time 0.019480    
2018-11-02 20:32:43,032 - Epoch: [260][  250/  391]    Overall Loss 0.054280    Objective Loss 0.054280    Top1 98.225000    Top5 99.993750    LR 0.000240    Time 0.019419    
2018-11-02 20:32:43,989 - Epoch: [260][  300/  391]    Overall Loss 0.053489    Objective Loss 0.053489    Top1 98.247396    Top5 99.994792    LR 0.000240    Time 0.019371    
2018-11-02 20:32:44,949 - Epoch: [260][  350/  391]    Overall Loss 0.053112    Objective Loss 0.053112    Top1 98.272321    Top5 99.993304    LR 0.000240    Time 0.019343    
2018-11-02 20:32:45,820 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35866 | -0.00316 |    0.22250 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14152 | -0.00192 |    0.09006 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15097 | -0.00640 |    0.11490 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17179 | -0.03093 |    0.13212 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17552 |  0.00090 |    0.13799 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17141 | -0.02783 |    0.13204 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16156 | -0.00599 |    0.11650 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19505 | -0.00110 |    0.14366 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16337 | -0.00496 |    0.12474 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24697 | -0.00345 |    0.16663 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13688 | -0.00199 |    0.10447 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11914 | -0.00906 |    0.09350 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14116 | -0.01541 |    0.11234 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10732 | -0.00284 |    0.08419 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12766 | -0.01376 |    0.10181 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12476 | -0.00128 |    0.09904 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14466 | -0.01082 |    0.11196 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11456 | -0.00752 |    0.09042 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09799 | -0.00623 |    0.07685 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10367 | -0.01252 |    0.08302 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06243 |  0.00362 |    0.04725 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58105 | -0.00001 |    0.45490 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:32:45,821 - Total sparsity: 0.00

2018-11-02 20:32:45,821 - --- validate (epoch=260)-----------
2018-11-02 20:32:45,821 - 10000 samples (128 per mini-batch)
2018-11-02 20:32:46,542 - Epoch: [260][   50/   78]    Loss 0.389375    Top1 90.453125    Top5 99.687500    
2018-11-02 20:32:46,931 - ==> Top1: 90.280    Top5: 99.700    Loss: 0.392

2018-11-02 20:32:46,931 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:32:46,931 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:32:46,939 - 

2018-11-02 20:32:46,939 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:32:48,035 - Epoch: [261][   50/  391]    Overall Loss 0.058698    Objective Loss 0.058698    Top1 97.921875    Top5 100.000000    LR 0.000228    Time 0.021882    
2018-11-02 20:32:49,069 - Epoch: [261][  100/  391]    Overall Loss 0.058503    Objective Loss 0.058503    Top1 98.015625    Top5 100.000000    LR 0.000228    Time 0.021277    
2018-11-02 20:32:50,108 - Epoch: [261][  150/  391]    Overall Loss 0.057268    Objective Loss 0.057268    Top1 98.052083    Top5 99.994792    LR 0.000228    Time 0.021104    
2018-11-02 20:32:51,133 - Epoch: [261][  200/  391]    Overall Loss 0.057371    Objective Loss 0.057371    Top1 98.042969    Top5 99.996094    LR 0.000228    Time 0.020947    
2018-11-02 20:32:52,095 - Epoch: [261][  250/  391]    Overall Loss 0.055291    Objective Loss 0.055291    Top1 98.121875    Top5 99.993750    LR 0.000228    Time 0.020598    
2018-11-02 20:32:53,053 - Epoch: [261][  300/  391]    Overall Loss 0.055655    Objective Loss 0.055655    Top1 98.135417    Top5 99.992188    LR 0.000228    Time 0.020355    
2018-11-02 20:32:54,011 - Epoch: [261][  350/  391]    Overall Loss 0.054702    Objective Loss 0.054702    Top1 98.174107    Top5 99.993304    LR 0.000228    Time 0.020182    
2018-11-02 20:32:54,881 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35863 | -0.00316 |    0.22249 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14150 | -0.00192 |    0.09005 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15095 | -0.00640 |    0.11489 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17178 | -0.03094 |    0.13211 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17551 |  0.00092 |    0.13798 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17139 | -0.02783 |    0.13203 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16155 | -0.00601 |    0.11649 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19503 | -0.00111 |    0.14365 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16336 | -0.00496 |    0.12473 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24694 | -0.00344 |    0.16662 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13687 | -0.00198 |    0.10445 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11913 | -0.00906 |    0.09349 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14114 | -0.01541 |    0.11233 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10731 | -0.00284 |    0.08419 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12765 | -0.01376 |    0.10180 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12475 | -0.00128 |    0.09904 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14465 | -0.01082 |    0.11195 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11456 | -0.00752 |    0.09041 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09798 | -0.00623 |    0.07685 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10366 | -0.01252 |    0.08301 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06242 |  0.00362 |    0.04725 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58106 | -0.00001 |    0.45491 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:32:54,881 - Total sparsity: 0.00

2018-11-02 20:32:54,881 - --- validate (epoch=261)-----------
2018-11-02 20:32:54,881 - 10000 samples (128 per mini-batch)
2018-11-02 20:32:55,598 - Epoch: [261][   50/   78]    Loss 0.386808    Top1 90.453125    Top5 99.703125    
2018-11-02 20:32:55,987 - ==> Top1: 90.240    Top5: 99.710    Loss: 0.392

2018-11-02 20:32:55,988 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:32:55,988 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:32:55,998 - 

2018-11-02 20:32:55,999 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:32:57,019 - Epoch: [262][   50/  391]    Overall Loss 0.053778    Objective Loss 0.053778    Top1 98.296875    Top5 100.000000    LR 0.000217    Time 0.020377    
2018-11-02 20:32:57,982 - Epoch: [262][  100/  391]    Overall Loss 0.054367    Objective Loss 0.054367    Top1 98.203125    Top5 100.000000    LR 0.000217    Time 0.019801    
2018-11-02 20:32:58,982 - Epoch: [262][  150/  391]    Overall Loss 0.053983    Objective Loss 0.053983    Top1 98.260417    Top5 100.000000    LR 0.000217    Time 0.019858    
2018-11-02 20:32:59,992 - Epoch: [262][  200/  391]    Overall Loss 0.054399    Objective Loss 0.054399    Top1 98.167969    Top5 100.000000    LR 0.000217    Time 0.019936    
2018-11-02 20:33:00,956 - Epoch: [262][  250/  391]    Overall Loss 0.054036    Objective Loss 0.054036    Top1 98.156250    Top5 99.996875    LR 0.000217    Time 0.019801    
2018-11-02 20:33:01,915 - Epoch: [262][  300/  391]    Overall Loss 0.054399    Objective Loss 0.054399    Top1 98.166667    Top5 99.997396    LR 0.000217    Time 0.019694    
2018-11-02 20:33:02,875 - Epoch: [262][  350/  391]    Overall Loss 0.054409    Objective Loss 0.054409    Top1 98.162946    Top5 99.997768    LR 0.000217    Time 0.019620    
2018-11-02 20:33:03,747 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35860 | -0.00311 |    0.22246 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14149 | -0.00193 |    0.09004 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15094 | -0.00641 |    0.11488 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17176 | -0.03094 |    0.13210 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17549 |  0.00093 |    0.13797 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17138 | -0.02783 |    0.13202 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16154 | -0.00601 |    0.11649 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19502 | -0.00112 |    0.14364 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16334 | -0.00496 |    0.12472 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24692 | -0.00343 |    0.16660 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13686 | -0.00198 |    0.10444 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11912 | -0.00906 |    0.09349 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14113 | -0.01541 |    0.11232 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10730 | -0.00284 |    0.08418 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12764 | -0.01376 |    0.10179 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12474 | -0.00128 |    0.09903 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14464 | -0.01082 |    0.11194 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11455 | -0.00752 |    0.09040 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09797 | -0.00622 |    0.07684 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10365 | -0.01252 |    0.08300 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06242 |  0.00362 |    0.04725 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58107 | -0.00001 |    0.45492 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:33:03,747 - Total sparsity: 0.00

2018-11-02 20:33:03,747 - --- validate (epoch=262)-----------
2018-11-02 20:33:03,748 - 10000 samples (128 per mini-batch)
2018-11-02 20:33:04,468 - Epoch: [262][   50/   78]    Loss 0.392442    Top1 90.359375    Top5 99.671875    
2018-11-02 20:33:04,855 - ==> Top1: 90.240    Top5: 99.680    Loss: 0.396

2018-11-02 20:33:04,855 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:33:04,856 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:33:04,863 - 

2018-11-02 20:33:04,863 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:33:05,882 - Epoch: [263][   50/  391]    Overall Loss 0.057456    Objective Loss 0.057456    Top1 98.000000    Top5 99.984375    LR 0.000206    Time 0.020336    
2018-11-02 20:33:06,842 - Epoch: [263][  100/  391]    Overall Loss 0.054551    Objective Loss 0.054551    Top1 98.062500    Top5 99.992188    LR 0.000206    Time 0.019763    
2018-11-02 20:33:07,805 - Epoch: [263][  150/  391]    Overall Loss 0.054625    Objective Loss 0.054625    Top1 98.098958    Top5 99.994792    LR 0.000206    Time 0.019583    
2018-11-02 20:33:08,766 - Epoch: [263][  200/  391]    Overall Loss 0.054271    Objective Loss 0.054271    Top1 98.148438    Top5 99.996094    LR 0.000206    Time 0.019486    
2018-11-02 20:33:09,728 - Epoch: [263][  250/  391]    Overall Loss 0.055011    Objective Loss 0.055011    Top1 98.128125    Top5 99.993750    LR 0.000206    Time 0.019433    
2018-11-02 20:33:10,693 - Epoch: [263][  300/  391]    Overall Loss 0.055300    Objective Loss 0.055300    Top1 98.138021    Top5 99.989583    LR 0.000206    Time 0.019408    
2018-11-02 20:33:11,656 - Epoch: [263][  350/  391]    Overall Loss 0.054670    Objective Loss 0.054670    Top1 98.169643    Top5 99.991071    LR 0.000206    Time 0.019384    
2018-11-02 20:33:12,524 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35857 | -0.00317 |    0.22243 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14148 | -0.00194 |    0.09003 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15093 | -0.00643 |    0.11487 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17175 | -0.03093 |    0.13209 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17548 |  0.00094 |    0.13796 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17137 | -0.02782 |    0.13201 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16152 | -0.00601 |    0.11647 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19500 | -0.00112 |    0.14363 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16333 | -0.00496 |    0.12471 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24690 | -0.00342 |    0.16659 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13685 | -0.00196 |    0.10444 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11911 | -0.00906 |    0.09348 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14112 | -0.01540 |    0.11231 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10729 | -0.00283 |    0.08418 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12763 | -0.01376 |    0.10178 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12473 | -0.00128 |    0.09902 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14463 | -0.01082 |    0.11193 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11454 | -0.00752 |    0.09039 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09796 | -0.00622 |    0.07684 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10365 | -0.01252 |    0.08300 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06241 |  0.00362 |    0.04724 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58108 | -0.00001 |    0.45492 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:33:12,524 - Total sparsity: 0.00

2018-11-02 20:33:12,524 - --- validate (epoch=263)-----------
2018-11-02 20:33:12,525 - 10000 samples (128 per mini-batch)
2018-11-02 20:33:13,247 - Epoch: [263][   50/   78]    Loss 0.390317    Top1 90.406250    Top5 99.671875    
2018-11-02 20:33:13,637 - ==> Top1: 90.270    Top5: 99.680    Loss: 0.392

2018-11-02 20:33:13,638 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:33:13,638 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:33:13,649 - 

2018-11-02 20:33:13,650 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:33:14,669 - Epoch: [264][   50/  391]    Overall Loss 0.050687    Objective Loss 0.050687    Top1 98.171875    Top5 100.000000    LR 0.000196    Time 0.020356    
2018-11-02 20:33:15,633 - Epoch: [264][  100/  391]    Overall Loss 0.052069    Objective Loss 0.052069    Top1 98.234375    Top5 100.000000    LR 0.000196    Time 0.019805    
2018-11-02 20:33:16,598 - Epoch: [264][  150/  391]    Overall Loss 0.053862    Objective Loss 0.053862    Top1 98.109375    Top5 99.994792    LR 0.000196    Time 0.019627    
2018-11-02 20:33:17,558 - Epoch: [264][  200/  391]    Overall Loss 0.055214    Objective Loss 0.055214    Top1 98.066406    Top5 99.992188    LR 0.000196    Time 0.019516    
2018-11-02 20:33:18,519 - Epoch: [264][  250/  391]    Overall Loss 0.054519    Objective Loss 0.054519    Top1 98.081250    Top5 99.993750    LR 0.000196    Time 0.019451    
2018-11-02 20:33:19,486 - Epoch: [264][  300/  391]    Overall Loss 0.054471    Objective Loss 0.054471    Top1 98.085938    Top5 99.994792    LR 0.000196    Time 0.019428    
2018-11-02 20:33:20,448 - Epoch: [264][  350/  391]    Overall Loss 0.054114    Objective Loss 0.054114    Top1 98.100446    Top5 99.995536    LR 0.000196    Time 0.019398    
2018-11-02 20:33:21,313 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35854 | -0.00320 |    0.22240 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14147 | -0.00193 |    0.09003 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15092 | -0.00643 |    0.11486 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17173 | -0.03093 |    0.13208 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17546 |  0.00093 |    0.13795 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17136 | -0.02780 |    0.13200 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16151 | -0.00601 |    0.11646 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19499 | -0.00113 |    0.14362 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16332 | -0.00496 |    0.12470 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24689 | -0.00341 |    0.16657 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13683 | -0.00196 |    0.10443 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11910 | -0.00906 |    0.09348 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14111 | -0.01540 |    0.11230 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10728 | -0.00283 |    0.08417 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12762 | -0.01376 |    0.10178 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12472 | -0.00129 |    0.09901 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14462 | -0.01082 |    0.11193 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11453 | -0.00752 |    0.09039 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09796 | -0.00622 |    0.07683 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10364 | -0.01252 |    0.08299 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06241 |  0.00362 |    0.04724 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58110 | -0.00001 |    0.45494 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:33:21,314 - Total sparsity: 0.00

2018-11-02 20:33:21,314 - --- validate (epoch=264)-----------
2018-11-02 20:33:21,314 - 10000 samples (128 per mini-batch)
2018-11-02 20:33:22,033 - Epoch: [264][   50/   78]    Loss 0.389651    Top1 90.281250    Top5 99.671875    
2018-11-02 20:33:22,422 - ==> Top1: 90.180    Top5: 99.680    Loss: 0.393

2018-11-02 20:33:22,423 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:33:22,423 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:33:22,434 - 

2018-11-02 20:33:22,434 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:33:23,505 - Epoch: [265][   50/  391]    Overall Loss 0.049059    Objective Loss 0.049059    Top1 98.468750    Top5 99.968750    LR 0.000186    Time 0.021389    
2018-11-02 20:33:24,467 - Epoch: [265][  100/  391]    Overall Loss 0.051740    Objective Loss 0.051740    Top1 98.453125    Top5 99.984375    LR 0.000186    Time 0.020298    
2018-11-02 20:33:25,429 - Epoch: [265][  150/  391]    Overall Loss 0.053007    Objective Loss 0.053007    Top1 98.322917    Top5 99.984375    LR 0.000186    Time 0.019940    
2018-11-02 20:33:26,390 - Epoch: [265][  200/  391]    Overall Loss 0.052529    Objective Loss 0.052529    Top1 98.347656    Top5 99.988281    LR 0.000186    Time 0.019753    
2018-11-02 20:33:27,352 - Epoch: [265][  250/  391]    Overall Loss 0.052618    Objective Loss 0.052618    Top1 98.334375    Top5 99.990625    LR 0.000186    Time 0.019644    
2018-11-02 20:33:28,313 - Epoch: [265][  300/  391]    Overall Loss 0.053366    Objective Loss 0.053366    Top1 98.283854    Top5 99.992188    LR 0.000186    Time 0.019568    
2018-11-02 20:33:29,279 - Epoch: [265][  350/  391]    Overall Loss 0.053510    Objective Loss 0.053510    Top1 98.285714    Top5 99.991071    LR 0.000186    Time 0.019531    
2018-11-02 20:33:30,148 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35851 | -0.00319 |    0.22239 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14146 | -0.00194 |    0.09002 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15091 | -0.00642 |    0.11486 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17172 | -0.03094 |    0.13208 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17545 |  0.00093 |    0.13794 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17134 | -0.02781 |    0.13198 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16150 | -0.00600 |    0.11645 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19497 | -0.00111 |    0.14361 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16330 | -0.00497 |    0.12469 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24687 | -0.00341 |    0.16656 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13682 | -0.00196 |    0.10442 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11909 | -0.00906 |    0.09347 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14110 | -0.01540 |    0.11230 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10727 | -0.00283 |    0.08416 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12761 | -0.01376 |    0.10177 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12471 | -0.00129 |    0.09901 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14461 | -0.01082 |    0.11192 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11452 | -0.00752 |    0.09038 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09795 | -0.00622 |    0.07682 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10363 | -0.01251 |    0.08298 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06240 |  0.00362 |    0.04724 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58111 | -0.00001 |    0.45495 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:33:30,148 - Total sparsity: 0.00

2018-11-02 20:33:30,148 - --- validate (epoch=265)-----------
2018-11-02 20:33:30,148 - 10000 samples (128 per mini-batch)
2018-11-02 20:33:30,873 - Epoch: [265][   50/   78]    Loss 0.387200    Top1 90.406250    Top5 99.671875    
2018-11-02 20:33:31,295 - ==> Top1: 90.270    Top5: 99.680    Loss: 0.391

2018-11-02 20:33:31,296 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:33:31,296 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:33:31,310 - 

2018-11-02 20:33:31,311 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:33:32,330 - Epoch: [266][   50/  391]    Overall Loss 0.056959    Objective Loss 0.056959    Top1 98.015625    Top5 99.968750    LR 0.000177    Time 0.020340    
2018-11-02 20:33:33,290 - Epoch: [266][  100/  391]    Overall Loss 0.056367    Objective Loss 0.056367    Top1 98.070312    Top5 99.968750    LR 0.000177    Time 0.019767    
2018-11-02 20:33:34,253 - Epoch: [266][  150/  391]    Overall Loss 0.055962    Objective Loss 0.055962    Top1 98.078125    Top5 99.979167    LR 0.000177    Time 0.019588    
2018-11-02 20:33:35,213 - Epoch: [266][  200/  391]    Overall Loss 0.054258    Objective Loss 0.054258    Top1 98.183594    Top5 99.984375    LR 0.000177    Time 0.019483    
2018-11-02 20:33:36,176 - Epoch: [266][  250/  391]    Overall Loss 0.055274    Objective Loss 0.055274    Top1 98.150000    Top5 99.987500    LR 0.000177    Time 0.019433    
2018-11-02 20:33:37,139 - Epoch: [266][  300/  391]    Overall Loss 0.054971    Objective Loss 0.054971    Top1 98.158854    Top5 99.989583    LR 0.000177    Time 0.019402    
2018-11-02 20:33:38,101 - Epoch: [266][  350/  391]    Overall Loss 0.054503    Objective Loss 0.054503    Top1 98.180804    Top5 99.991071    LR 0.000177    Time 0.019375    
2018-11-02 20:33:38,966 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35849 | -0.00317 |    0.22237 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14145 | -0.00193 |    0.09001 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15090 | -0.00642 |    0.11485 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17171 | -0.03094 |    0.13207 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17544 |  0.00094 |    0.13794 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17133 | -0.02780 |    0.13197 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16149 | -0.00599 |    0.11644 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19496 | -0.00111 |    0.14361 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16329 | -0.00497 |    0.12468 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24685 | -0.00341 |    0.16656 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13682 | -0.00196 |    0.10442 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11908 | -0.00906 |    0.09346 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14109 | -0.01540 |    0.11229 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10727 | -0.00282 |    0.08416 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12760 | -0.01377 |    0.10176 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12470 | -0.00130 |    0.09900 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14460 | -0.01082 |    0.11191 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11451 | -0.00751 |    0.09037 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09794 | -0.00622 |    0.07682 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10362 | -0.01252 |    0.08298 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06240 |  0.00361 |    0.04723 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58112 | -0.00001 |    0.45496 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:33:38,966 - Total sparsity: 0.00

2018-11-02 20:33:38,966 - --- validate (epoch=266)-----------
2018-11-02 20:33:38,966 - 10000 samples (128 per mini-batch)
2018-11-02 20:33:39,688 - Epoch: [266][   50/   78]    Loss 0.387555    Top1 90.468750    Top5 99.687500    
2018-11-02 20:33:40,081 - ==> Top1: 90.300    Top5: 99.700    Loss: 0.391

2018-11-02 20:33:40,082 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:33:40,082 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:33:40,090 - 

2018-11-02 20:33:40,090 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:33:41,110 - Epoch: [267][   50/  391]    Overall Loss 0.058679    Objective Loss 0.058679    Top1 97.968750    Top5 100.000000    LR 0.000168    Time 0.020366    
2018-11-02 20:33:42,073 - Epoch: [267][  100/  391]    Overall Loss 0.054280    Objective Loss 0.054280    Top1 98.210938    Top5 100.000000    LR 0.000168    Time 0.019803    
2018-11-02 20:33:43,060 - Epoch: [267][  150/  391]    Overall Loss 0.053592    Objective Loss 0.053592    Top1 98.161458    Top5 99.994792    LR 0.000168    Time 0.019777    
2018-11-02 20:33:44,020 - Epoch: [267][  200/  391]    Overall Loss 0.053082    Objective Loss 0.053082    Top1 98.226562    Top5 99.988281    LR 0.000168    Time 0.019624    
2018-11-02 20:33:44,982 - Epoch: [267][  250/  391]    Overall Loss 0.052881    Objective Loss 0.052881    Top1 98.218750    Top5 99.987500    LR 0.000168    Time 0.019543    
2018-11-02 20:33:45,943 - Epoch: [267][  300/  391]    Overall Loss 0.052707    Objective Loss 0.052707    Top1 98.231771    Top5 99.989583    LR 0.000168    Time 0.019485    
2018-11-02 20:33:46,906 - Epoch: [267][  350/  391]    Overall Loss 0.052865    Objective Loss 0.052865    Top1 98.254464    Top5 99.991071    LR 0.000168    Time 0.019450    
2018-11-02 20:33:47,776 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35847 | -0.00321 |    0.22236 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14144 | -0.00194 |    0.09001 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15089 | -0.00641 |    0.11484 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17170 | -0.03094 |    0.13206 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17543 |  0.00091 |    0.13793 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17132 | -0.02779 |    0.13197 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16148 | -0.00600 |    0.11644 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19495 | -0.00111 |    0.14360 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16328 | -0.00497 |    0.12467 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24683 | -0.00340 |    0.16655 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13681 | -0.00195 |    0.10441 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11907 | -0.00906 |    0.09346 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14108 | -0.01541 |    0.11228 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10726 | -0.00282 |    0.08415 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12759 | -0.01377 |    0.10176 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12469 | -0.00130 |    0.09899 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14459 | -0.01082 |    0.11190 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11450 | -0.00751 |    0.09037 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09794 | -0.00622 |    0.07681 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10362 | -0.01252 |    0.08297 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06239 |  0.00362 |    0.04723 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58113 | -0.00001 |    0.45496 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:33:47,776 - Total sparsity: 0.00

2018-11-02 20:33:47,776 - --- validate (epoch=267)-----------
2018-11-02 20:33:47,776 - 10000 samples (128 per mini-batch)
2018-11-02 20:33:48,500 - Epoch: [267][   50/   78]    Loss 0.388904    Top1 90.375000    Top5 99.671875    
2018-11-02 20:33:48,891 - ==> Top1: 90.200    Top5: 99.690    Loss: 0.393

2018-11-02 20:33:48,892 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:33:48,892 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:33:48,899 - 

2018-11-02 20:33:48,900 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:33:49,951 - Epoch: [268][   50/  391]    Overall Loss 0.052560    Objective Loss 0.052560    Top1 98.234375    Top5 100.000000    LR 0.000159    Time 0.020989    
2018-11-02 20:33:50,911 - Epoch: [268][  100/  391]    Overall Loss 0.051339    Objective Loss 0.051339    Top1 98.328125    Top5 100.000000    LR 0.000159    Time 0.020084    
2018-11-02 20:33:51,874 - Epoch: [268][  150/  391]    Overall Loss 0.051045    Objective Loss 0.051045    Top1 98.343750    Top5 100.000000    LR 0.000159    Time 0.019799    
2018-11-02 20:33:52,836 - Epoch: [268][  200/  391]    Overall Loss 0.052087    Objective Loss 0.052087    Top1 98.328125    Top5 100.000000    LR 0.000159    Time 0.019651    
2018-11-02 20:33:53,796 - Epoch: [268][  250/  391]    Overall Loss 0.052266    Objective Loss 0.052266    Top1 98.334375    Top5 100.000000    LR 0.000159    Time 0.019559    
2018-11-02 20:33:54,759 - Epoch: [268][  300/  391]    Overall Loss 0.052922    Objective Loss 0.052922    Top1 98.299479    Top5 99.997396    LR 0.000159    Time 0.019504    
2018-11-02 20:33:55,721 - Epoch: [268][  350/  391]    Overall Loss 0.053881    Objective Loss 0.053881    Top1 98.243304    Top5 99.997768    LR 0.000159    Time 0.019461    
2018-11-02 20:33:56,590 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35844 | -0.00315 |    0.22235 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14143 | -0.00194 |    0.09000 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15088 | -0.00641 |    0.11483 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17168 | -0.03095 |    0.13205 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17542 |  0.00091 |    0.13792 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17131 | -0.02778 |    0.13196 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16147 | -0.00601 |    0.11643 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19494 | -0.00111 |    0.14359 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16327 | -0.00496 |    0.12466 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24682 | -0.00340 |    0.16655 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13680 | -0.00195 |    0.10440 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11907 | -0.00905 |    0.09345 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14107 | -0.01540 |    0.11227 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10725 | -0.00282 |    0.08415 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12759 | -0.01377 |    0.10175 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12468 | -0.00130 |    0.09899 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14458 | -0.01082 |    0.11190 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11450 | -0.00751 |    0.09036 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09793 | -0.00622 |    0.07681 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10361 | -0.01252 |    0.08297 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06239 |  0.00362 |    0.04723 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58114 | -0.00001 |    0.45497 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:33:56,590 - Total sparsity: 0.00

2018-11-02 20:33:56,590 - --- validate (epoch=268)-----------
2018-11-02 20:33:56,590 - 10000 samples (128 per mini-batch)
2018-11-02 20:33:57,308 - Epoch: [268][   50/   78]    Loss 0.390039    Top1 90.281250    Top5 99.640625    
2018-11-02 20:33:57,697 - ==> Top1: 90.220    Top5: 99.660    Loss: 0.394

2018-11-02 20:33:57,698 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:33:57,698 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:33:57,705 - 

2018-11-02 20:33:57,705 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:33:58,724 - Epoch: [269][   50/  391]    Overall Loss 0.052900    Objective Loss 0.052900    Top1 98.109375    Top5 100.000000    LR 0.000151    Time 0.020343    
2018-11-02 20:33:59,684 - Epoch: [269][  100/  391]    Overall Loss 0.050313    Objective Loss 0.050313    Top1 98.390625    Top5 100.000000    LR 0.000151    Time 0.019760    
2018-11-02 20:34:00,669 - Epoch: [269][  150/  391]    Overall Loss 0.052023    Objective Loss 0.052023    Top1 98.328125    Top5 100.000000    LR 0.000151    Time 0.019731    
2018-11-02 20:34:01,631 - Epoch: [269][  200/  391]    Overall Loss 0.052477    Objective Loss 0.052477    Top1 98.296875    Top5 99.996094    LR 0.000151    Time 0.019605    
2018-11-02 20:34:02,595 - Epoch: [269][  250/  391]    Overall Loss 0.052761    Objective Loss 0.052761    Top1 98.265625    Top5 99.996875    LR 0.000151    Time 0.019535    
2018-11-02 20:34:03,560 - Epoch: [269][  300/  391]    Overall Loss 0.052654    Objective Loss 0.052654    Top1 98.273438    Top5 99.997396    LR 0.000151    Time 0.019489    
2018-11-02 20:34:04,521 - Epoch: [269][  350/  391]    Overall Loss 0.053347    Objective Loss 0.053347    Top1 98.256696    Top5 99.995536    LR 0.000151    Time 0.019449    
2018-11-02 20:34:05,387 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35842 | -0.00320 |    0.22233 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14142 | -0.00194 |    0.09000 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15087 | -0.00642 |    0.11482 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17167 | -0.03094 |    0.13205 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17541 |  0.00090 |    0.13791 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17130 | -0.02777 |    0.13196 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16146 | -0.00600 |    0.11643 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19492 | -0.00109 |    0.14358 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16326 | -0.00497 |    0.12466 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24681 | -0.00339 |    0.16654 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13679 | -0.00196 |    0.10440 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11906 | -0.00905 |    0.09344 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14107 | -0.01540 |    0.11226 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10725 | -0.00281 |    0.08415 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12758 | -0.01376 |    0.10174 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12468 | -0.00130 |    0.09898 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14457 | -0.01082 |    0.11189 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11449 | -0.00751 |    0.09036 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09792 | -0.00622 |    0.07681 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10360 | -0.01252 |    0.08296 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06239 |  0.00362 |    0.04722 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58116 | -0.00001 |    0.45498 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:34:05,387 - Total sparsity: 0.00

2018-11-02 20:34:05,388 - --- validate (epoch=269)-----------
2018-11-02 20:34:05,388 - 10000 samples (128 per mini-batch)
2018-11-02 20:34:06,107 - Epoch: [269][   50/   78]    Loss 0.388936    Top1 90.546875    Top5 99.640625    
2018-11-02 20:34:06,497 - ==> Top1: 90.400    Top5: 99.660    Loss: 0.392

2018-11-02 20:34:06,498 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:34:06,498 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:34:06,509 - 

2018-11-02 20:34:06,510 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:34:07,567 - Epoch: [270][   50/  391]    Overall Loss 0.055793    Objective Loss 0.055793    Top1 98.015625    Top5 100.000000    LR 0.000144    Time 0.021117    
2018-11-02 20:34:08,528 - Epoch: [270][  100/  391]    Overall Loss 0.056041    Objective Loss 0.056041    Top1 98.054688    Top5 99.992188    LR 0.000144    Time 0.020156    
2018-11-02 20:34:09,491 - Epoch: [270][  150/  391]    Overall Loss 0.053884    Objective Loss 0.053884    Top1 98.161458    Top5 99.994792    LR 0.000144    Time 0.019847    
2018-11-02 20:34:10,452 - Epoch: [270][  200/  391]    Overall Loss 0.054643    Objective Loss 0.054643    Top1 98.136719    Top5 99.996094    LR 0.000144    Time 0.019684    
2018-11-02 20:34:11,414 - Epoch: [270][  250/  391]    Overall Loss 0.054138    Objective Loss 0.054138    Top1 98.168750    Top5 99.996875    LR 0.000144    Time 0.019590    
2018-11-02 20:34:12,375 - Epoch: [270][  300/  391]    Overall Loss 0.054509    Objective Loss 0.054509    Top1 98.161458    Top5 99.997396    LR 0.000144    Time 0.019526    
2018-11-02 20:34:13,336 - Epoch: [270][  350/  391]    Overall Loss 0.054938    Objective Loss 0.054938    Top1 98.171875    Top5 99.997768    LR 0.000144    Time 0.019475    
2018-11-02 20:34:14,202 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35840 | -0.00313 |    0.22231 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14141 | -0.00193 |    0.08999 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15086 | -0.00642 |    0.11482 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17166 | -0.03095 |    0.13203 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17540 |  0.00088 |    0.13790 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17130 | -0.02776 |    0.13195 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16145 | -0.00601 |    0.11642 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19491 | -0.00108 |    0.14357 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16325 | -0.00496 |    0.12465 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24679 | -0.00339 |    0.16652 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13678 | -0.00195 |    0.10439 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11905 | -0.00905 |    0.09344 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14106 | -0.01540 |    0.11226 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10724 | -0.00281 |    0.08414 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12757 | -0.01376 |    0.10174 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12467 | -0.00129 |    0.09898 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14456 | -0.01082 |    0.11188 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11448 | -0.00751 |    0.09035 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09792 | -0.00622 |    0.07680 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10360 | -0.01252 |    0.08296 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 |  0.00362 |    0.04722 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58116 | -0.00001 |    0.45499 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:34:14,202 - Total sparsity: 0.00

2018-11-02 20:34:14,202 - --- validate (epoch=270)-----------
2018-11-02 20:34:14,202 - 10000 samples (128 per mini-batch)
2018-11-02 20:34:14,920 - Epoch: [270][   50/   78]    Loss 0.390621    Top1 90.250000    Top5 99.656250    
2018-11-02 20:34:15,308 - ==> Top1: 90.140    Top5: 99.680    Loss: 0.394

2018-11-02 20:34:15,309 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:34:15,309 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:34:15,316 - 

2018-11-02 20:34:15,317 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:34:16,335 - Epoch: [271][   50/  391]    Overall Loss 0.056678    Objective Loss 0.056678    Top1 98.140625    Top5 100.000000    LR 0.000137    Time 0.020332    
2018-11-02 20:34:17,294 - Epoch: [271][  100/  391]    Overall Loss 0.055106    Objective Loss 0.055106    Top1 98.132812    Top5 99.992188    LR 0.000137    Time 0.019749    
2018-11-02 20:34:18,257 - Epoch: [271][  150/  391]    Overall Loss 0.056141    Objective Loss 0.056141    Top1 98.083333    Top5 99.994792    LR 0.000137    Time 0.019576    
2018-11-02 20:34:19,217 - Epoch: [271][  200/  391]    Overall Loss 0.055140    Objective Loss 0.055140    Top1 98.132812    Top5 99.996094    LR 0.000137    Time 0.019480    
2018-11-02 20:34:20,176 - Epoch: [271][  250/  391]    Overall Loss 0.054499    Objective Loss 0.054499    Top1 98.171875    Top5 99.996875    LR 0.000137    Time 0.019416    
2018-11-02 20:34:21,138 - Epoch: [271][  300/  391]    Overall Loss 0.054934    Objective Loss 0.054934    Top1 98.161458    Top5 99.997396    LR 0.000137    Time 0.019380    
2018-11-02 20:34:22,099 - Epoch: [271][  350/  391]    Overall Loss 0.054926    Objective Loss 0.054926    Top1 98.171875    Top5 99.997768    LR 0.000137    Time 0.019354    
2018-11-02 20:34:22,968 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35838 | -0.00310 |    0.22231 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14141 | -0.00193 |    0.08999 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15085 | -0.00641 |    0.11481 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17165 | -0.03095 |    0.13203 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17539 |  0.00088 |    0.13789 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17129 | -0.02776 |    0.13194 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16144 | -0.00600 |    0.11641 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19490 | -0.00107 |    0.14356 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16324 | -0.00497 |    0.12464 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24678 | -0.00339 |    0.16652 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13678 | -0.00195 |    0.10439 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11905 | -0.00906 |    0.09343 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14105 | -0.01539 |    0.11225 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10723 | -0.00281 |    0.08413 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12756 | -0.01376 |    0.10173 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12466 | -0.00129 |    0.09897 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14455 | -0.01081 |    0.11187 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11448 | -0.00751 |    0.09035 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09791 | -0.00621 |    0.07680 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10359 | -0.01252 |    0.08295 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 |  0.00362 |    0.04722 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58117 | -0.00001 |    0.45499 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:34:22,969 - Total sparsity: 0.00

2018-11-02 20:34:22,969 - --- validate (epoch=271)-----------
2018-11-02 20:34:22,969 - 10000 samples (128 per mini-batch)
2018-11-02 20:34:23,688 - Epoch: [271][   50/   78]    Loss 0.392058    Top1 90.406250    Top5 99.656250    
2018-11-02 20:34:24,077 - ==> Top1: 90.280    Top5: 99.680    Loss: 0.394

2018-11-02 20:34:24,078 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:34:24,078 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:34:24,085 - 

2018-11-02 20:34:24,085 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:34:25,115 - Epoch: [272][   50/  391]    Overall Loss 0.056363    Objective Loss 0.056363    Top1 98.140625    Top5 100.000000    LR 0.000130    Time 0.020564    
2018-11-02 20:34:26,074 - Epoch: [272][  100/  391]    Overall Loss 0.057630    Objective Loss 0.057630    Top1 98.031250    Top5 100.000000    LR 0.000130    Time 0.019858    
2018-11-02 20:34:27,033 - Epoch: [272][  150/  391]    Overall Loss 0.056563    Objective Loss 0.056563    Top1 98.046875    Top5 100.000000    LR 0.000130    Time 0.019626    
2018-11-02 20:34:27,994 - Epoch: [272][  200/  391]    Overall Loss 0.055311    Objective Loss 0.055311    Top1 98.105469    Top5 99.996094    LR 0.000130    Time 0.019522    
2018-11-02 20:34:28,954 - Epoch: [272][  250/  391]    Overall Loss 0.055792    Objective Loss 0.055792    Top1 98.112500    Top5 99.996875    LR 0.000130    Time 0.019452    
2018-11-02 20:34:29,919 - Epoch: [272][  300/  391]    Overall Loss 0.056249    Objective Loss 0.056249    Top1 98.088542    Top5 99.997396    LR 0.000130    Time 0.019410    
2018-11-02 20:34:30,879 - Epoch: [272][  350/  391]    Overall Loss 0.056095    Objective Loss 0.056095    Top1 98.120536    Top5 99.993304    LR 0.000130    Time 0.019378    
2018-11-02 20:34:31,743 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35837 | -0.00312 |    0.22229 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14140 | -0.00194 |    0.08998 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15084 | -0.00640 |    0.11481 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17164 | -0.03096 |    0.13202 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17538 |  0.00087 |    0.13789 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17128 | -0.02775 |    0.13193 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16143 | -0.00601 |    0.11641 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19489 | -0.00106 |    0.14356 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16324 | -0.00496 |    0.12464 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24677 | -0.00339 |    0.16651 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13677 | -0.00194 |    0.10438 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11904 | -0.00906 |    0.09343 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14104 | -0.01539 |    0.11224 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10723 | -0.00281 |    0.08413 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12756 | -0.01376 |    0.10173 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12466 | -0.00129 |    0.09897 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14455 | -0.01081 |    0.11187 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11447 | -0.00751 |    0.09034 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09791 | -0.00621 |    0.07679 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10359 | -0.01252 |    0.08295 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06238 |  0.00362 |    0.04722 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58118 | -0.00001 |    0.45499 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:34:31,743 - Total sparsity: 0.00

2018-11-02 20:34:31,743 - --- validate (epoch=272)-----------
2018-11-02 20:34:31,744 - 10000 samples (128 per mini-batch)
2018-11-02 20:34:32,457 - Epoch: [272][   50/   78]    Loss 0.389274    Top1 90.359375    Top5 99.640625    
2018-11-02 20:34:32,843 - ==> Top1: 90.300    Top5: 99.670    Loss: 0.392

2018-11-02 20:34:32,844 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:34:32,844 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:34:32,855 - 

2018-11-02 20:34:32,856 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:34:33,874 - Epoch: [273][   50/  391]    Overall Loss 0.056227    Objective Loss 0.056227    Top1 98.140625    Top5 100.000000    LR 0.000123    Time 0.020330    
2018-11-02 20:34:34,836 - Epoch: [273][  100/  391]    Overall Loss 0.053477    Objective Loss 0.053477    Top1 98.289062    Top5 100.000000    LR 0.000123    Time 0.019776    
2018-11-02 20:34:35,798 - Epoch: [273][  150/  391]    Overall Loss 0.053041    Objective Loss 0.053041    Top1 98.270833    Top5 99.994792    LR 0.000123    Time 0.019585    
2018-11-02 20:34:36,758 - Epoch: [273][  200/  391]    Overall Loss 0.053388    Objective Loss 0.053388    Top1 98.226562    Top5 99.996094    LR 0.000123    Time 0.019488    
2018-11-02 20:34:37,719 - Epoch: [273][  250/  391]    Overall Loss 0.053194    Objective Loss 0.053194    Top1 98.225000    Top5 99.996875    LR 0.000123    Time 0.019426    
2018-11-02 20:34:38,680 - Epoch: [273][  300/  391]    Overall Loss 0.052756    Objective Loss 0.052756    Top1 98.257812    Top5 99.997396    LR 0.000123    Time 0.019388    
2018-11-02 20:34:39,642 - Epoch: [273][  350/  391]    Overall Loss 0.053474    Objective Loss 0.053474    Top1 98.207589    Top5 99.997768    LR 0.000123    Time 0.019365    
2018-11-02 20:34:40,508 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35835 | -0.00313 |    0.22228 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14139 | -0.00194 |    0.08998 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15084 | -0.00641 |    0.11480 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17163 | -0.03095 |    0.13201 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17537 |  0.00086 |    0.13788 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17127 | -0.02775 |    0.13192 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16142 | -0.00600 |    0.11640 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19488 | -0.00106 |    0.14355 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16323 | -0.00496 |    0.12463 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24675 | -0.00340 |    0.16651 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13676 | -0.00194 |    0.10438 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11903 | -0.00905 |    0.09343 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14104 | -0.01539 |    0.11224 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10722 | -0.00280 |    0.08413 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12755 | -0.01376 |    0.10172 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12465 | -0.00130 |    0.09896 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14454 | -0.01081 |    0.11186 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11447 | -0.00751 |    0.09034 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09790 | -0.00621 |    0.07679 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10358 | -0.01252 |    0.08295 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 |  0.00362 |    0.04721 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58118 | -0.00001 |    0.45500 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:34:40,508 - Total sparsity: 0.00

2018-11-02 20:34:40,508 - --- validate (epoch=273)-----------
2018-11-02 20:34:40,509 - 10000 samples (128 per mini-batch)
2018-11-02 20:34:41,230 - Epoch: [273][   50/   78]    Loss 0.389048    Top1 90.406250    Top5 99.671875    
2018-11-02 20:34:41,622 - ==> Top1: 90.310    Top5: 99.680    Loss: 0.393

2018-11-02 20:34:41,623 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:34:41,623 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:34:41,630 - 

2018-11-02 20:34:41,630 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:34:42,648 - Epoch: [274][   50/  391]    Overall Loss 0.052037    Objective Loss 0.052037    Top1 98.156250    Top5 100.000000    LR 0.000117    Time 0.020317    
2018-11-02 20:34:43,611 - Epoch: [274][  100/  391]    Overall Loss 0.054553    Objective Loss 0.054553    Top1 98.062500    Top5 99.984375    LR 0.000117    Time 0.019780    
2018-11-02 20:34:44,574 - Epoch: [274][  150/  391]    Overall Loss 0.053887    Objective Loss 0.053887    Top1 98.161458    Top5 99.984375    LR 0.000117    Time 0.019596    
2018-11-02 20:34:45,544 - Epoch: [274][  200/  391]    Overall Loss 0.054090    Objective Loss 0.054090    Top1 98.183594    Top5 99.984375    LR 0.000117    Time 0.019543    
2018-11-02 20:34:46,504 - Epoch: [274][  250/  391]    Overall Loss 0.054407    Objective Loss 0.054407    Top1 98.162500    Top5 99.987500    LR 0.000117    Time 0.019455    
2018-11-02 20:34:47,466 - Epoch: [274][  300/  391]    Overall Loss 0.054177    Objective Loss 0.054177    Top1 98.179688    Top5 99.989583    LR 0.000117    Time 0.019416    
2018-11-02 20:34:48,429 - Epoch: [274][  350/  391]    Overall Loss 0.054144    Objective Loss 0.054144    Top1 98.174107    Top5 99.991071    LR 0.000117    Time 0.019392    
2018-11-02 20:34:49,300 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35833 | -0.00311 |    0.22228 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14139 | -0.00194 |    0.08997 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15083 | -0.00640 |    0.11480 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17163 | -0.03096 |    0.13201 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17536 |  0.00087 |    0.13787 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17126 | -0.02775 |    0.13192 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16142 | -0.00600 |    0.11640 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19487 | -0.00107 |    0.14354 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16322 | -0.00497 |    0.12463 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24674 | -0.00339 |    0.16650 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13676 | -0.00194 |    0.10437 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11903 | -0.00905 |    0.09342 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14103 | -0.01538 |    0.11223 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10722 | -0.00280 |    0.08412 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12755 | -0.01375 |    0.10172 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12464 | -0.00129 |    0.09896 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14453 | -0.01081 |    0.11186 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11446 | -0.00751 |    0.09033 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09790 | -0.00621 |    0.07679 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10358 | -0.01252 |    0.08294 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 |  0.00361 |    0.04721 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58119 | -0.00001 |    0.45501 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:34:49,300 - Total sparsity: 0.00

2018-11-02 20:34:49,300 - --- validate (epoch=274)-----------
2018-11-02 20:34:49,300 - 10000 samples (128 per mini-batch)
2018-11-02 20:34:50,020 - Epoch: [274][   50/   78]    Loss 0.389180    Top1 90.328125    Top5 99.687500    
2018-11-02 20:34:50,411 - ==> Top1: 90.230    Top5: 99.700    Loss: 0.394

2018-11-02 20:34:50,412 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:34:50,412 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:34:50,419 - 

2018-11-02 20:34:50,420 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:34:51,438 - Epoch: [275][   50/  391]    Overall Loss 0.055605    Objective Loss 0.055605    Top1 98.171875    Top5 99.984375    LR 0.000111    Time 0.020333    
2018-11-02 20:34:52,398 - Epoch: [275][  100/  391]    Overall Loss 0.055227    Objective Loss 0.055227    Top1 98.132812    Top5 99.984375    LR 0.000111    Time 0.019755    
2018-11-02 20:34:53,357 - Epoch: [275][  150/  391]    Overall Loss 0.055524    Objective Loss 0.055524    Top1 98.072917    Top5 99.989583    LR 0.000111    Time 0.019558    
2018-11-02 20:34:54,318 - Epoch: [275][  200/  391]    Overall Loss 0.055037    Objective Loss 0.055037    Top1 98.082031    Top5 99.992188    LR 0.000111    Time 0.019468    
2018-11-02 20:34:55,279 - Epoch: [275][  250/  391]    Overall Loss 0.054772    Objective Loss 0.054772    Top1 98.140625    Top5 99.993750    LR 0.000111    Time 0.019415    
2018-11-02 20:34:56,239 - Epoch: [275][  300/  391]    Overall Loss 0.054997    Objective Loss 0.054997    Top1 98.156250    Top5 99.994792    LR 0.000111    Time 0.019375    
2018-11-02 20:34:57,203 - Epoch: [275][  350/  391]    Overall Loss 0.054934    Objective Loss 0.054934    Top1 98.162946    Top5 99.995536    LR 0.000111    Time 0.019356    
2018-11-02 20:34:58,068 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35832 | -0.00312 |    0.22227 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14138 | -0.00194 |    0.08997 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15082 | -0.00640 |    0.11479 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17162 | -0.03096 |    0.13201 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17536 |  0.00088 |    0.13787 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17126 | -0.02774 |    0.13192 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16141 | -0.00600 |    0.11639 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19487 | -0.00107 |    0.14354 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16321 | -0.00497 |    0.12462 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24673 | -0.00339 |    0.16649 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13675 | -0.00194 |    0.10436 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11902 | -0.00906 |    0.09342 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14103 | -0.01538 |    0.11223 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10721 | -0.00280 |    0.08412 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12754 | -0.01375 |    0.10171 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12464 | -0.00130 |    0.09895 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14453 | -0.01081 |    0.11185 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11446 | -0.00750 |    0.09033 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09790 | -0.00621 |    0.07678 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10357 | -0.01252 |    0.08294 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 |  0.00361 |    0.04721 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58120 | -0.00001 |    0.45501 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:34:58,068 - Total sparsity: 0.00

2018-11-02 20:34:58,069 - --- validate (epoch=275)-----------
2018-11-02 20:34:58,069 - 10000 samples (128 per mini-batch)
2018-11-02 20:34:58,793 - Epoch: [275][   50/   78]    Loss 0.391713    Top1 90.421875    Top5 99.718750    
2018-11-02 20:34:59,198 - ==> Top1: 90.270    Top5: 99.720    Loss: 0.396

2018-11-02 20:34:59,198 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:34:59,199 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:34:59,206 - 

2018-11-02 20:34:59,206 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:35:00,303 - Epoch: [276][   50/  391]    Overall Loss 0.056398    Objective Loss 0.056398    Top1 98.109375    Top5 99.953125    LR 0.000106    Time 0.021901    
2018-11-02 20:35:01,270 - Epoch: [276][  100/  391]    Overall Loss 0.052160    Objective Loss 0.052160    Top1 98.312500    Top5 99.976562    LR 0.000106    Time 0.020607    
2018-11-02 20:35:02,229 - Epoch: [276][  150/  391]    Overall Loss 0.052831    Objective Loss 0.052831    Top1 98.250000    Top5 99.984375    LR 0.000106    Time 0.020130    
2018-11-02 20:35:03,190 - Epoch: [276][  200/  391]    Overall Loss 0.053552    Objective Loss 0.053552    Top1 98.218750    Top5 99.988281    LR 0.000106    Time 0.019896    
2018-11-02 20:35:04,150 - Epoch: [276][  250/  391]    Overall Loss 0.053533    Objective Loss 0.053533    Top1 98.225000    Top5 99.987500    LR 0.000106    Time 0.019750    
2018-11-02 20:35:05,111 - Epoch: [276][  300/  391]    Overall Loss 0.053281    Objective Loss 0.053281    Top1 98.229167    Top5 99.986979    LR 0.000106    Time 0.019658    
2018-11-02 20:35:06,073 - Epoch: [276][  350/  391]    Overall Loss 0.053484    Objective Loss 0.053484    Top1 98.232143    Top5 99.988839    LR 0.000106    Time 0.019596    
2018-11-02 20:35:06,939 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35830 | -0.00318 |    0.22227 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14137 | -0.00193 |    0.08996 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15082 | -0.00641 |    0.11478 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17161 | -0.03095 |    0.13200 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17535 |  0.00088 |    0.13787 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17125 | -0.02774 |    0.13191 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16140 | -0.00600 |    0.11639 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19486 | -0.00107 |    0.14353 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16321 | -0.00496 |    0.12461 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24672 | -0.00339 |    0.16649 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13674 | -0.00194 |    0.10436 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11902 | -0.00906 |    0.09341 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14102 | -0.01538 |    0.11222 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10721 | -0.00280 |    0.08411 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12754 | -0.01375 |    0.10171 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12463 | -0.00129 |    0.09895 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14452 | -0.01081 |    0.11185 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11445 | -0.00750 |    0.09033 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09789 | -0.00621 |    0.07678 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10357 | -0.01252 |    0.08293 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06237 |  0.00361 |    0.04721 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58120 | -0.00001 |    0.45502 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:35:06,939 - Total sparsity: 0.00

2018-11-02 20:35:06,939 - --- validate (epoch=276)-----------
2018-11-02 20:35:06,939 - 10000 samples (128 per mini-batch)
2018-11-02 20:35:07,654 - Epoch: [276][   50/   78]    Loss 0.390578    Top1 90.328125    Top5 99.703125    
2018-11-02 20:35:08,047 - ==> Top1: 90.190    Top5: 99.700    Loss: 0.395

2018-11-02 20:35:08,048 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:35:08,048 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:35:08,055 - 

2018-11-02 20:35:08,055 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:35:09,072 - Epoch: [277][   50/  391]    Overall Loss 0.056742    Objective Loss 0.056742    Top1 97.984375    Top5 100.000000    LR 0.000100    Time 0.020312    
2018-11-02 20:35:10,033 - Epoch: [277][  100/  391]    Overall Loss 0.055111    Objective Loss 0.055111    Top1 98.078125    Top5 100.000000    LR 0.000100    Time 0.019754    
2018-11-02 20:35:10,995 - Epoch: [277][  150/  391]    Overall Loss 0.054967    Objective Loss 0.054967    Top1 98.114583    Top5 100.000000    LR 0.000100    Time 0.019572    
2018-11-02 20:35:11,957 - Epoch: [277][  200/  391]    Overall Loss 0.054415    Objective Loss 0.054415    Top1 98.101562    Top5 100.000000    LR 0.000100    Time 0.019485    
2018-11-02 20:35:12,918 - Epoch: [277][  250/  391]    Overall Loss 0.055038    Objective Loss 0.055038    Top1 98.134375    Top5 100.000000    LR 0.000100    Time 0.019425    
2018-11-02 20:35:13,879 - Epoch: [277][  300/  391]    Overall Loss 0.055723    Objective Loss 0.055723    Top1 98.111979    Top5 100.000000    LR 0.000100    Time 0.019388    
2018-11-02 20:35:14,842 - Epoch: [277][  350/  391]    Overall Loss 0.055246    Objective Loss 0.055246    Top1 98.136161    Top5 99.997768    LR 0.000100    Time 0.019355    
2018-11-02 20:35:15,711 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35829 | -0.00313 |    0.22225 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14137 | -0.00193 |    0.08996 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15081 | -0.00641 |    0.11478 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17160 | -0.03095 |    0.13200 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17534 |  0.00088 |    0.13786 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17124 | -0.02775 |    0.13190 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16140 | -0.00601 |    0.11638 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19485 | -0.00107 |    0.14353 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16320 | -0.00496 |    0.12461 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24671 | -0.00339 |    0.16648 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13674 | -0.00194 |    0.10436 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11901 | -0.00906 |    0.09341 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14101 | -0.01537 |    0.11222 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10721 | -0.00280 |    0.08411 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12753 | -0.01375 |    0.10171 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12463 | -0.00129 |    0.09895 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14451 | -0.01081 |    0.11184 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11445 | -0.00750 |    0.09032 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09789 | -0.00621 |    0.07678 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10356 | -0.01252 |    0.08293 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06236 |  0.00361 |    0.04721 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58121 | -0.00001 |    0.45502 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:35:15,711 - Total sparsity: 0.00

2018-11-02 20:35:15,711 - --- validate (epoch=277)-----------
2018-11-02 20:35:15,711 - 10000 samples (128 per mini-batch)
2018-11-02 20:35:16,425 - Epoch: [277][   50/   78]    Loss 0.387840    Top1 90.468750    Top5 99.656250    
2018-11-02 20:35:16,806 - ==> Top1: 90.300    Top5: 99.670    Loss: 0.392

2018-11-02 20:35:16,806 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:35:16,807 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:35:16,813 - 

2018-11-02 20:35:16,814 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:35:17,829 - Epoch: [278][   50/  391]    Overall Loss 0.053538    Objective Loss 0.053538    Top1 98.250000    Top5 99.984375    LR 0.000095    Time 0.020286    
2018-11-02 20:35:18,791 - Epoch: [278][  100/  391]    Overall Loss 0.053074    Objective Loss 0.053074    Top1 98.312500    Top5 99.992188    LR 0.000095    Time 0.019751    
2018-11-02 20:35:19,751 - Epoch: [278][  150/  391]    Overall Loss 0.052845    Objective Loss 0.052845    Top1 98.281250    Top5 99.994792    LR 0.000095    Time 0.019560    
2018-11-02 20:35:20,713 - Epoch: [278][  200/  391]    Overall Loss 0.052241    Objective Loss 0.052241    Top1 98.289062    Top5 99.996094    LR 0.000095    Time 0.019472    
2018-11-02 20:35:21,675 - Epoch: [278][  250/  391]    Overall Loss 0.053466    Objective Loss 0.053466    Top1 98.196875    Top5 99.996875    LR 0.000095    Time 0.019423    
2018-11-02 20:35:22,636 - Epoch: [278][  300/  391]    Overall Loss 0.053458    Objective Loss 0.053458    Top1 98.187500    Top5 99.994792    LR 0.000095    Time 0.019385    
2018-11-02 20:35:23,599 - Epoch: [278][  350/  391]    Overall Loss 0.052690    Objective Loss 0.052690    Top1 98.245536    Top5 99.995536    LR 0.000095    Time 0.019363    
2018-11-02 20:35:24,465 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35827 | -0.00312 |    0.22223 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14136 | -0.00193 |    0.08996 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15081 | -0.00641 |    0.11478 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17160 | -0.03095 |    0.13199 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17533 |  0.00088 |    0.13785 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17124 | -0.02775 |    0.13190 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16139 | -0.00601 |    0.11638 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19484 | -0.00107 |    0.14352 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16319 | -0.00496 |    0.12460 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24670 | -0.00338 |    0.16648 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13673 | -0.00194 |    0.10435 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11901 | -0.00906 |    0.09341 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14101 | -0.01537 |    0.11221 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10720 | -0.00280 |    0.08411 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12753 | -0.01374 |    0.10170 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12462 | -0.00129 |    0.09894 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14451 | -0.01081 |    0.11184 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11444 | -0.00750 |    0.09032 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09788 | -0.00621 |    0.07678 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10356 | -0.01252 |    0.08293 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06236 |  0.00361 |    0.04720 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58122 | -0.00001 |    0.45503 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:35:24,465 - Total sparsity: 0.00

2018-11-02 20:35:24,465 - --- validate (epoch=278)-----------
2018-11-02 20:35:24,465 - 10000 samples (128 per mini-batch)
2018-11-02 20:35:25,185 - Epoch: [278][   50/   78]    Loss 0.388372    Top1 90.437500    Top5 99.687500    
2018-11-02 20:35:25,575 - ==> Top1: 90.270    Top5: 99.690    Loss: 0.391

2018-11-02 20:35:25,575 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:35:25,576 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:35:25,585 - 

2018-11-02 20:35:25,586 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:35:26,608 - Epoch: [279][   50/  391]    Overall Loss 0.059736    Objective Loss 0.059736    Top1 97.921875    Top5 99.984375    LR 0.000091    Time 0.020394    
2018-11-02 20:35:27,569 - Epoch: [279][  100/  391]    Overall Loss 0.057101    Objective Loss 0.057101    Top1 98.039062    Top5 99.992188    LR 0.000091    Time 0.019792    
2018-11-02 20:35:28,530 - Epoch: [279][  150/  391]    Overall Loss 0.057338    Objective Loss 0.057338    Top1 97.989583    Top5 99.994792    LR 0.000091    Time 0.019598    
2018-11-02 20:35:29,489 - Epoch: [279][  200/  391]    Overall Loss 0.056044    Objective Loss 0.056044    Top1 98.101562    Top5 99.992188    LR 0.000091    Time 0.019487    
2018-11-02 20:35:30,452 - Epoch: [279][  250/  391]    Overall Loss 0.055309    Objective Loss 0.055309    Top1 98.112500    Top5 99.993750    LR 0.000091    Time 0.019435    
2018-11-02 20:35:31,413 - Epoch: [279][  300/  391]    Overall Loss 0.055075    Objective Loss 0.055075    Top1 98.122396    Top5 99.992188    LR 0.000091    Time 0.019384    
2018-11-02 20:35:32,374 - Epoch: [279][  350/  391]    Overall Loss 0.054052    Objective Loss 0.054052    Top1 98.154018    Top5 99.993304    LR 0.000091    Time 0.019356    
2018-11-02 20:35:33,243 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35826 | -0.00304 |    0.22223 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14136 | -0.00193 |    0.08996 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15080 | -0.00641 |    0.11477 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17159 | -0.03095 |    0.13199 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17533 |  0.00088 |    0.13785 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17123 | -0.02774 |    0.13189 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16138 | -0.00602 |    0.11637 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19484 | -0.00107 |    0.14352 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16319 | -0.00496 |    0.12460 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24669 | -0.00337 |    0.16647 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13673 | -0.00193 |    0.10435 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11901 | -0.00906 |    0.09340 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14100 | -0.01537 |    0.11221 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10720 | -0.00280 |    0.08411 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12752 | -0.01374 |    0.10170 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12462 | -0.00129 |    0.09894 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14450 | -0.01081 |    0.11183 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11444 | -0.00750 |    0.09031 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09788 | -0.00621 |    0.07677 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10356 | -0.01252 |    0.08293 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06236 |  0.00361 |    0.04720 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58122 | -0.00001 |    0.45503 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:35:33,244 - Total sparsity: 0.00

2018-11-02 20:35:33,244 - --- validate (epoch=279)-----------
2018-11-02 20:35:33,244 - 10000 samples (128 per mini-batch)
2018-11-02 20:35:33,963 - Epoch: [279][   50/   78]    Loss 0.386020    Top1 90.484375    Top5 99.640625    
2018-11-02 20:35:34,355 - ==> Top1: 90.310    Top5: 99.670    Loss: 0.389

2018-11-02 20:35:34,356 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:35:34,356 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:35:34,363 - 

2018-11-02 20:35:34,363 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:35:35,382 - Epoch: [280][   50/  391]    Overall Loss 0.051752    Objective Loss 0.051752    Top1 98.328125    Top5 100.000000    LR 0.000086    Time 0.020348    
2018-11-02 20:35:36,345 - Epoch: [280][  100/  391]    Overall Loss 0.051692    Objective Loss 0.051692    Top1 98.304688    Top5 100.000000    LR 0.000086    Time 0.019789    
2018-11-02 20:35:37,308 - Epoch: [280][  150/  391]    Overall Loss 0.053420    Objective Loss 0.053420    Top1 98.187500    Top5 100.000000    LR 0.000086    Time 0.019602    
2018-11-02 20:35:38,269 - Epoch: [280][  200/  391]    Overall Loss 0.053162    Objective Loss 0.053162    Top1 98.179688    Top5 100.000000    LR 0.000086    Time 0.019502    
2018-11-02 20:35:39,231 - Epoch: [280][  250/  391]    Overall Loss 0.052994    Objective Loss 0.052994    Top1 98.212500    Top5 100.000000    LR 0.000086    Time 0.019444    
2018-11-02 20:35:40,203 - Epoch: [280][  300/  391]    Overall Loss 0.053264    Objective Loss 0.053264    Top1 98.216146    Top5 100.000000    LR 0.000086    Time 0.019442    
2018-11-02 20:35:41,167 - Epoch: [280][  350/  391]    Overall Loss 0.053438    Objective Loss 0.053438    Top1 98.209821    Top5 100.000000    LR 0.000086    Time 0.019414    
2018-11-02 20:35:42,038 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35825 | -0.00304 |    0.22222 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14135 | -0.00193 |    0.08995 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15080 | -0.00641 |    0.11477 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17159 | -0.03094 |    0.13198 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17532 |  0.00088 |    0.13784 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17122 | -0.02775 |    0.13189 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16138 | -0.00601 |    0.11637 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19483 | -0.00107 |    0.14352 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16318 | -0.00496 |    0.12460 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24669 | -0.00338 |    0.16646 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13672 | -0.00193 |    0.10435 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11900 | -0.00906 |    0.09340 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14100 | -0.01537 |    0.11221 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10719 | -0.00280 |    0.08410 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12752 | -0.01374 |    0.10169 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12462 | -0.00129 |    0.09893 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14450 | -0.01081 |    0.11183 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11444 | -0.00750 |    0.09031 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09788 | -0.00621 |    0.07677 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10355 | -0.01252 |    0.08292 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06236 |  0.00361 |    0.04720 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58123 | -0.00001 |    0.45504 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:35:42,038 - Total sparsity: 0.00

2018-11-02 20:35:42,039 - --- validate (epoch=280)-----------
2018-11-02 20:35:42,039 - 10000 samples (128 per mini-batch)
2018-11-02 20:35:42,764 - Epoch: [280][   50/   78]    Loss 0.389710    Top1 90.421875    Top5 99.703125    
2018-11-02 20:35:43,155 - ==> Top1: 90.180    Top5: 99.710    Loss: 0.394

2018-11-02 20:35:43,156 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:35:43,156 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:35:43,163 - 

2018-11-02 20:35:43,163 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:35:44,252 - Epoch: [281][   50/  391]    Overall Loss 0.055945    Objective Loss 0.055945    Top1 97.984375    Top5 100.000000    LR 0.000082    Time 0.021747    
2018-11-02 20:35:45,276 - Epoch: [281][  100/  391]    Overall Loss 0.056087    Objective Loss 0.056087    Top1 98.031250    Top5 100.000000    LR 0.000082    Time 0.021101    
2018-11-02 20:35:46,301 - Epoch: [281][  150/  391]    Overall Loss 0.054468    Objective Loss 0.054468    Top1 98.119792    Top5 100.000000    LR 0.000082    Time 0.020893    
2018-11-02 20:35:47,329 - Epoch: [281][  200/  391]    Overall Loss 0.053551    Objective Loss 0.053551    Top1 98.179688    Top5 99.996094    LR 0.000082    Time 0.020805    
2018-11-02 20:35:48,326 - Epoch: [281][  250/  391]    Overall Loss 0.054209    Objective Loss 0.054209    Top1 98.153125    Top5 99.996875    LR 0.000082    Time 0.020614    
2018-11-02 20:35:49,285 - Epoch: [281][  300/  391]    Overall Loss 0.053611    Objective Loss 0.053611    Top1 98.190104    Top5 99.994792    LR 0.000082    Time 0.020370    
2018-11-02 20:35:50,246 - Epoch: [281][  350/  391]    Overall Loss 0.053864    Objective Loss 0.053864    Top1 98.180804    Top5 99.995536    LR 0.000082    Time 0.020200    
2018-11-02 20:35:51,110 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35824 | -0.00304 |    0.22222 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14135 | -0.00193 |    0.08995 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15079 | -0.00641 |    0.11477 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17158 | -0.03094 |    0.13198 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17532 |  0.00088 |    0.13784 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17122 | -0.02774 |    0.13189 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16137 | -0.00601 |    0.11637 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19482 | -0.00107 |    0.14351 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16318 | -0.00496 |    0.12459 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24668 | -0.00338 |    0.16646 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13672 | -0.00192 |    0.10434 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11900 | -0.00906 |    0.09340 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14100 | -0.01537 |    0.11220 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10719 | -0.00280 |    0.08410 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12751 | -0.01374 |    0.10169 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12461 | -0.00129 |    0.09893 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14449 | -0.01081 |    0.11183 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11443 | -0.00750 |    0.09031 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09787 | -0.00621 |    0.07677 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10355 | -0.01252 |    0.08292 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06236 |  0.00361 |    0.04720 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58123 | -0.00001 |    0.45504 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:35:51,110 - Total sparsity: 0.00

2018-11-02 20:35:51,110 - --- validate (epoch=281)-----------
2018-11-02 20:35:51,110 - 10000 samples (128 per mini-batch)
2018-11-02 20:35:51,832 - Epoch: [281][   50/   78]    Loss 0.389880    Top1 90.265625    Top5 99.640625    
2018-11-02 20:35:52,222 - ==> Top1: 90.200    Top5: 99.680    Loss: 0.394

2018-11-02 20:35:52,223 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:35:52,223 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:35:52,234 - 

2018-11-02 20:35:52,234 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:35:53,344 - Epoch: [282][   50/  391]    Overall Loss 0.051015    Objective Loss 0.051015    Top1 98.328125    Top5 100.000000    LR 0.000078    Time 0.022169    
2018-11-02 20:35:54,372 - Epoch: [282][  100/  391]    Overall Loss 0.053121    Objective Loss 0.053121    Top1 98.226562    Top5 100.000000    LR 0.000078    Time 0.021352    
2018-11-02 20:35:55,335 - Epoch: [282][  150/  391]    Overall Loss 0.053482    Objective Loss 0.053482    Top1 98.197917    Top5 100.000000    LR 0.000078    Time 0.020642    
2018-11-02 20:35:56,295 - Epoch: [282][  200/  391]    Overall Loss 0.054868    Objective Loss 0.054868    Top1 98.179688    Top5 100.000000    LR 0.000078    Time 0.020277    
2018-11-02 20:35:57,256 - Epoch: [282][  250/  391]    Overall Loss 0.054782    Objective Loss 0.054782    Top1 98.196875    Top5 100.000000    LR 0.000078    Time 0.020063    
2018-11-02 20:35:58,217 - Epoch: [282][  300/  391]    Overall Loss 0.054397    Objective Loss 0.054397    Top1 98.184896    Top5 100.000000    LR 0.000078    Time 0.019919    
2018-11-02 20:35:59,179 - Epoch: [282][  350/  391]    Overall Loss 0.054359    Objective Loss 0.054359    Top1 98.171875    Top5 100.000000    LR 0.000078    Time 0.019818    
2018-11-02 20:36:00,047 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35823 | -0.00303 |    0.22221 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14135 | -0.00193 |    0.08995 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15079 | -0.00641 |    0.11476 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17158 | -0.03093 |    0.13197 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17531 |  0.00088 |    0.13783 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17121 | -0.02774 |    0.13188 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16137 | -0.00600 |    0.11636 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19482 | -0.00107 |    0.14350 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16317 | -0.00496 |    0.12459 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24667 | -0.00337 |    0.16646 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13672 | -0.00192 |    0.10434 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11899 | -0.00905 |    0.09339 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14099 | -0.01537 |    0.11220 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10719 | -0.00280 |    0.08410 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12751 | -0.01374 |    0.10169 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12461 | -0.00129 |    0.09893 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14449 | -0.01080 |    0.11182 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11443 | -0.00750 |    0.09031 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09787 | -0.00621 |    0.07677 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10355 | -0.01252 |    0.08292 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06235 |  0.00361 |    0.04720 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58123 | -0.00001 |    0.45504 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:36:00,047 - Total sparsity: 0.00

2018-11-02 20:36:00,048 - --- validate (epoch=282)-----------
2018-11-02 20:36:00,048 - 10000 samples (128 per mini-batch)
2018-11-02 20:36:00,770 - Epoch: [282][   50/   78]    Loss 0.389950    Top1 90.328125    Top5 99.703125    
2018-11-02 20:36:01,157 - ==> Top1: 90.220    Top5: 99.710    Loss: 0.395

2018-11-02 20:36:01,158 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:36:01,158 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:36:01,165 - 

2018-11-02 20:36:01,166 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:36:02,183 - Epoch: [283][   50/  391]    Overall Loss 0.053734    Objective Loss 0.053734    Top1 98.250000    Top5 99.984375    LR 0.000074    Time 0.020320    
2018-11-02 20:36:03,144 - Epoch: [283][  100/  391]    Overall Loss 0.055306    Objective Loss 0.055306    Top1 98.164062    Top5 99.984375    LR 0.000074    Time 0.019756    
2018-11-02 20:36:04,106 - Epoch: [283][  150/  391]    Overall Loss 0.055881    Objective Loss 0.055881    Top1 98.145833    Top5 99.989583    LR 0.000074    Time 0.019574    
2018-11-02 20:36:05,069 - Epoch: [283][  200/  391]    Overall Loss 0.053957    Objective Loss 0.053957    Top1 98.218750    Top5 99.992188    LR 0.000074    Time 0.019491    
2018-11-02 20:36:06,029 - Epoch: [283][  250/  391]    Overall Loss 0.054739    Objective Loss 0.054739    Top1 98.206250    Top5 99.993750    LR 0.000074    Time 0.019429    
2018-11-02 20:36:06,993 - Epoch: [283][  300/  391]    Overall Loss 0.053880    Objective Loss 0.053880    Top1 98.218750    Top5 99.992188    LR 0.000074    Time 0.019398    
2018-11-02 20:36:07,951 - Epoch: [283][  350/  391]    Overall Loss 0.053258    Objective Loss 0.053258    Top1 98.250000    Top5 99.991071    LR 0.000074    Time 0.019362    
2018-11-02 20:36:08,818 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35822 | -0.00303 |    0.22221 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14134 | -0.00193 |    0.08995 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15078 | -0.00642 |    0.11476 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17157 | -0.03093 |    0.13197 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17531 |  0.00087 |    0.13783 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17121 | -0.02774 |    0.13188 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16137 | -0.00601 |    0.11636 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19481 | -0.00108 |    0.14350 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16317 | -0.00496 |    0.12458 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24666 | -0.00337 |    0.16645 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13671 | -0.00192 |    0.10434 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11899 | -0.00905 |    0.09339 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14099 | -0.01537 |    0.11220 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10718 | -0.00280 |    0.08410 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12751 | -0.01374 |    0.10169 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12460 | -0.00129 |    0.09893 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14449 | -0.01081 |    0.11182 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11442 | -0.00750 |    0.09030 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09787 | -0.00621 |    0.07676 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10354 | -0.01252 |    0.08292 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06235 |  0.00361 |    0.04720 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58124 | -0.00001 |    0.45505 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:36:08,818 - Total sparsity: 0.00

2018-11-02 20:36:08,818 - --- validate (epoch=283)-----------
2018-11-02 20:36:08,818 - 10000 samples (128 per mini-batch)
2018-11-02 20:36:09,536 - Epoch: [283][   50/   78]    Loss 0.392513    Top1 90.453125    Top5 99.703125    
2018-11-02 20:36:09,926 - ==> Top1: 90.300    Top5: 99.710    Loss: 0.395

2018-11-02 20:36:09,926 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:36:09,927 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:36:09,936 - 

2018-11-02 20:36:09,937 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:36:10,959 - Epoch: [284][   50/  391]    Overall Loss 0.051708    Objective Loss 0.051708    Top1 98.328125    Top5 100.000000    LR 0.000070    Time 0.020406    
2018-11-02 20:36:11,921 - Epoch: [284][  100/  391]    Overall Loss 0.050993    Objective Loss 0.050993    Top1 98.367188    Top5 100.000000    LR 0.000070    Time 0.019809    
2018-11-02 20:36:12,883 - Epoch: [284][  150/  391]    Overall Loss 0.054033    Objective Loss 0.054033    Top1 98.208333    Top5 99.994792    LR 0.000070    Time 0.019615    
2018-11-02 20:36:13,845 - Epoch: [284][  200/  391]    Overall Loss 0.053789    Objective Loss 0.053789    Top1 98.171875    Top5 99.996094    LR 0.000070    Time 0.019514    
2018-11-02 20:36:14,809 - Epoch: [284][  250/  391]    Overall Loss 0.053363    Objective Loss 0.053363    Top1 98.190625    Top5 99.996875    LR 0.000070    Time 0.019463    
2018-11-02 20:36:15,771 - Epoch: [284][  300/  391]    Overall Loss 0.052645    Objective Loss 0.052645    Top1 98.250000    Top5 99.997396    LR 0.000070    Time 0.019410    
2018-11-02 20:36:16,734 - Epoch: [284][  350/  391]    Overall Loss 0.052178    Objective Loss 0.052178    Top1 98.270089    Top5 99.997768    LR 0.000070    Time 0.019384    
2018-11-02 20:36:17,601 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35821 | -0.00305 |    0.22220 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14134 | -0.00193 |    0.08994 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15078 | -0.00642 |    0.11476 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17157 | -0.03093 |    0.13197 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17530 |  0.00087 |    0.13782 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17120 | -0.02775 |    0.13187 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16136 | -0.00600 |    0.11636 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19481 | -0.00108 |    0.14349 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16316 | -0.00496 |    0.12458 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24666 | -0.00337 |    0.16645 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13671 | -0.00192 |    0.10433 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11899 | -0.00905 |    0.09339 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14098 | -0.01536 |    0.11219 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10718 | -0.00280 |    0.08410 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12750 | -0.01374 |    0.10168 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12460 | -0.00129 |    0.09892 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14448 | -0.01081 |    0.11182 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11442 | -0.00750 |    0.09030 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09787 | -0.00621 |    0.07676 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10354 | -0.01251 |    0.08291 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06235 |  0.00361 |    0.04720 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58124 | -0.00001 |    0.45505 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:36:17,602 - Total sparsity: 0.00

2018-11-02 20:36:17,602 - --- validate (epoch=284)-----------
2018-11-02 20:36:17,602 - 10000 samples (128 per mini-batch)
2018-11-02 20:36:18,323 - Epoch: [284][   50/   78]    Loss 0.388380    Top1 90.515625    Top5 99.671875    
2018-11-02 20:36:18,712 - ==> Top1: 90.360    Top5: 99.690    Loss: 0.392

2018-11-02 20:36:18,713 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:36:18,713 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:36:18,728 - 

2018-11-02 20:36:18,728 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:36:19,747 - Epoch: [285][   50/  391]    Overall Loss 0.052891    Objective Loss 0.052891    Top1 98.218750    Top5 100.000000    LR 0.000067    Time 0.020341    
2018-11-02 20:36:20,709 - Epoch: [285][  100/  391]    Overall Loss 0.056217    Objective Loss 0.056217    Top1 98.132812    Top5 100.000000    LR 0.000067    Time 0.019779    
2018-11-02 20:36:21,669 - Epoch: [285][  150/  391]    Overall Loss 0.054876    Objective Loss 0.054876    Top1 98.197917    Top5 100.000000    LR 0.000067    Time 0.019578    
2018-11-02 20:36:22,630 - Epoch: [285][  200/  391]    Overall Loss 0.054906    Objective Loss 0.054906    Top1 98.203125    Top5 100.000000    LR 0.000067    Time 0.019480    
2018-11-02 20:36:23,589 - Epoch: [285][  250/  391]    Overall Loss 0.054913    Objective Loss 0.054913    Top1 98.234375    Top5 99.996875    LR 0.000067    Time 0.019416    
2018-11-02 20:36:24,557 - Epoch: [285][  300/  391]    Overall Loss 0.054724    Objective Loss 0.054724    Top1 98.231771    Top5 99.994792    LR 0.000067    Time 0.019403    
2018-11-02 20:36:25,522 - Epoch: [285][  350/  391]    Overall Loss 0.054235    Objective Loss 0.054235    Top1 98.256696    Top5 99.995536    LR 0.000067    Time 0.019385    
2018-11-02 20:36:26,392 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35820 | -0.00301 |    0.22219 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14133 | -0.00193 |    0.08994 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15077 | -0.00641 |    0.11475 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17156 | -0.03093 |    0.13197 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17530 |  0.00088 |    0.13782 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17120 | -0.02774 |    0.13187 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16136 | -0.00600 |    0.11635 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19480 | -0.00109 |    0.14349 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16316 | -0.00496 |    0.12458 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24665 | -0.00337 |    0.16644 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13670 | -0.00192 |    0.10433 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11898 | -0.00905 |    0.09339 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14098 | -0.01536 |    0.11219 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10718 | -0.00280 |    0.08409 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12750 | -0.01374 |    0.10168 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12460 | -0.00129 |    0.09892 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14448 | -0.01080 |    0.11182 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11442 | -0.00750 |    0.09030 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09786 | -0.00621 |    0.07676 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10354 | -0.01252 |    0.08291 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06235 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58125 | -0.00001 |    0.45505 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:36:26,392 - Total sparsity: 0.00

2018-11-02 20:36:26,392 - --- validate (epoch=285)-----------
2018-11-02 20:36:26,393 - 10000 samples (128 per mini-batch)
2018-11-02 20:36:27,111 - Epoch: [285][   50/   78]    Loss 0.388879    Top1 90.359375    Top5 99.656250    
2018-11-02 20:36:27,501 - ==> Top1: 90.250    Top5: 99.670    Loss: 0.392

2018-11-02 20:36:27,501 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:36:27,501 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:36:27,509 - 

2018-11-02 20:36:27,509 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:36:28,527 - Epoch: [286][   50/  391]    Overall Loss 0.050167    Objective Loss 0.050167    Top1 98.437500    Top5 100.000000    LR 0.000063    Time 0.020332    
2018-11-02 20:36:29,486 - Epoch: [286][  100/  391]    Overall Loss 0.050433    Objective Loss 0.050433    Top1 98.296875    Top5 100.000000    LR 0.000063    Time 0.019738    
2018-11-02 20:36:30,445 - Epoch: [286][  150/  391]    Overall Loss 0.051335    Objective Loss 0.051335    Top1 98.260417    Top5 99.994792    LR 0.000063    Time 0.019543    
2018-11-02 20:36:31,406 - Epoch: [286][  200/  391]    Overall Loss 0.051942    Objective Loss 0.051942    Top1 98.253906    Top5 99.996094    LR 0.000063    Time 0.019454    
2018-11-02 20:36:32,367 - Epoch: [286][  250/  391]    Overall Loss 0.052462    Objective Loss 0.052462    Top1 98.231250    Top5 99.993750    LR 0.000063    Time 0.019391    
2018-11-02 20:36:33,330 - Epoch: [286][  300/  391]    Overall Loss 0.052790    Objective Loss 0.052790    Top1 98.250000    Top5 99.989583    LR 0.000063    Time 0.019364    
2018-11-02 20:36:34,291 - Epoch: [286][  350/  391]    Overall Loss 0.053094    Objective Loss 0.053094    Top1 98.258929    Top5 99.991071    LR 0.000063    Time 0.019340    
2018-11-02 20:36:35,161 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35819 | -0.00305 |    0.22219 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14133 | -0.00193 |    0.08994 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15077 | -0.00641 |    0.11475 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17156 | -0.03092 |    0.13196 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17529 |  0.00087 |    0.13782 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17120 | -0.02774 |    0.13186 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16135 | -0.00600 |    0.11635 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19480 | -0.00108 |    0.14349 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16316 | -0.00496 |    0.12457 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24664 | -0.00337 |    0.16644 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13670 | -0.00192 |    0.10433 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11898 | -0.00905 |    0.09338 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14098 | -0.01537 |    0.11219 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10718 | -0.00280 |    0.08409 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12750 | -0.01374 |    0.10168 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12459 | -0.00129 |    0.09892 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14447 | -0.01080 |    0.11181 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11442 | -0.00750 |    0.09030 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09786 | -0.00621 |    0.07676 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10354 | -0.01252 |    0.08291 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06235 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58125 | -0.00001 |    0.45506 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:36:35,161 - Total sparsity: 0.00

2018-11-02 20:36:35,161 - --- validate (epoch=286)-----------
2018-11-02 20:36:35,161 - 10000 samples (128 per mini-batch)
2018-11-02 20:36:35,882 - Epoch: [286][   50/   78]    Loss 0.387550    Top1 90.406250    Top5 99.687500    
2018-11-02 20:36:36,267 - ==> Top1: 90.270    Top5: 99.700    Loss: 0.392

2018-11-02 20:36:36,268 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:36:36,268 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:36:36,275 - 

2018-11-02 20:36:36,275 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:36:37,292 - Epoch: [287][   50/  391]    Overall Loss 0.056688    Objective Loss 0.056688    Top1 98.015625    Top5 100.000000    LR 0.000060    Time 0.020298    
2018-11-02 20:36:38,330 - Epoch: [287][  100/  391]    Overall Loss 0.053148    Objective Loss 0.053148    Top1 98.156250    Top5 100.000000    LR 0.000060    Time 0.020518    
2018-11-02 20:36:39,290 - Epoch: [287][  150/  391]    Overall Loss 0.053467    Objective Loss 0.053467    Top1 98.171875    Top5 100.000000    LR 0.000060    Time 0.020073    
2018-11-02 20:36:40,253 - Epoch: [287][  200/  391]    Overall Loss 0.053415    Objective Loss 0.053415    Top1 98.218750    Top5 100.000000    LR 0.000060    Time 0.019866    
2018-11-02 20:36:41,218 - Epoch: [287][  250/  391]    Overall Loss 0.053396    Objective Loss 0.053396    Top1 98.209375    Top5 100.000000    LR 0.000060    Time 0.019746    
2018-11-02 20:36:42,183 - Epoch: [287][  300/  391]    Overall Loss 0.053864    Objective Loss 0.053864    Top1 98.208333    Top5 99.997396    LR 0.000060    Time 0.019668    
2018-11-02 20:36:43,146 - Epoch: [287][  350/  391]    Overall Loss 0.053740    Objective Loss 0.053740    Top1 98.216518    Top5 99.997768    LR 0.000060    Time 0.019607    
2018-11-02 20:36:44,013 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35818 | -0.00307 |    0.22219 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14133 | -0.00193 |    0.08994 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15077 | -0.00641 |    0.11475 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17156 | -0.03092 |    0.13196 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17529 |  0.00086 |    0.13782 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17119 | -0.02774 |    0.13186 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16135 | -0.00599 |    0.11635 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19479 | -0.00108 |    0.14348 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16315 | -0.00496 |    0.12457 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24664 | -0.00337 |    0.16643 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13670 | -0.00192 |    0.10433 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11898 | -0.00905 |    0.09338 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14097 | -0.01536 |    0.11218 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10717 | -0.00280 |    0.08409 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12749 | -0.01374 |    0.10168 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12459 | -0.00129 |    0.09892 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14447 | -0.01080 |    0.11181 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11441 | -0.00750 |    0.09029 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09786 | -0.00621 |    0.07676 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10353 | -0.01252 |    0.08291 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06235 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58125 | -0.00001 |    0.45506 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:36:44,013 - Total sparsity: 0.00

2018-11-02 20:36:44,014 - --- validate (epoch=287)-----------
2018-11-02 20:36:44,014 - 10000 samples (128 per mini-batch)
2018-11-02 20:36:44,745 - Epoch: [287][   50/   78]    Loss 0.388480    Top1 90.468750    Top5 99.671875    
2018-11-02 20:36:45,139 - ==> Top1: 90.310    Top5: 99.670    Loss: 0.393

2018-11-02 20:36:45,140 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:36:45,140 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:36:45,147 - 

2018-11-02 20:36:45,148 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:36:46,168 - Epoch: [288][   50/  391]    Overall Loss 0.050897    Objective Loss 0.050897    Top1 98.218750    Top5 99.984375    LR 0.000057    Time 0.020368    
2018-11-02 20:36:47,132 - Epoch: [288][  100/  391]    Overall Loss 0.051672    Objective Loss 0.051672    Top1 98.320312    Top5 99.984375    LR 0.000057    Time 0.019810    
2018-11-02 20:36:48,095 - Epoch: [288][  150/  391]    Overall Loss 0.052459    Objective Loss 0.052459    Top1 98.307292    Top5 99.989583    LR 0.000057    Time 0.019620    
2018-11-02 20:36:49,060 - Epoch: [288][  200/  391]    Overall Loss 0.052579    Objective Loss 0.052579    Top1 98.261719    Top5 99.992188    LR 0.000057    Time 0.019521    
2018-11-02 20:36:50,018 - Epoch: [288][  250/  391]    Overall Loss 0.052412    Objective Loss 0.052412    Top1 98.284375    Top5 99.993750    LR 0.000057    Time 0.019442    
2018-11-02 20:36:50,982 - Epoch: [288][  300/  391]    Overall Loss 0.053479    Objective Loss 0.053479    Top1 98.210938    Top5 99.992188    LR 0.000057    Time 0.019413    
2018-11-02 20:36:51,948 - Epoch: [288][  350/  391]    Overall Loss 0.053743    Objective Loss 0.053743    Top1 98.209821    Top5 99.993304    LR 0.000057    Time 0.019396    
2018-11-02 20:36:52,819 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35817 | -0.00310 |    0.22219 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14132 | -0.00193 |    0.08993 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15076 | -0.00640 |    0.11475 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17155 | -0.03093 |    0.13196 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17528 |  0.00086 |    0.13781 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17119 | -0.02774 |    0.13186 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16135 | -0.00599 |    0.11634 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19479 | -0.00108 |    0.14348 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16315 | -0.00496 |    0.12457 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24663 | -0.00337 |    0.16643 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13670 | -0.00192 |    0.10432 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11898 | -0.00905 |    0.09338 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14097 | -0.01537 |    0.11218 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10717 | -0.00280 |    0.08409 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12749 | -0.01374 |    0.10167 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12459 | -0.00129 |    0.09891 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14447 | -0.01080 |    0.11181 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11441 | -0.00750 |    0.09029 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09786 | -0.00621 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10353 | -0.01252 |    0.08291 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58126 | -0.00001 |    0.45506 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:36:52,820 - Total sparsity: 0.00

2018-11-02 20:36:52,820 - --- validate (epoch=288)-----------
2018-11-02 20:36:52,820 - 10000 samples (128 per mini-batch)
2018-11-02 20:36:53,534 - Epoch: [288][   50/   78]    Loss 0.394398    Top1 90.359375    Top5 99.640625    
2018-11-02 20:36:53,924 - ==> Top1: 90.230    Top5: 99.660    Loss: 0.398

2018-11-02 20:36:53,925 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:36:53,925 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:36:53,932 - 

2018-11-02 20:36:53,933 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:36:54,952 - Epoch: [289][   50/  391]    Overall Loss 0.061345    Objective Loss 0.061345    Top1 97.906250    Top5 99.984375    LR 0.000054    Time 0.020364    
2018-11-02 20:36:55,912 - Epoch: [289][  100/  391]    Overall Loss 0.058467    Objective Loss 0.058467    Top1 97.992188    Top5 99.992188    LR 0.000054    Time 0.019767    
2018-11-02 20:36:56,875 - Epoch: [289][  150/  391]    Overall Loss 0.055717    Objective Loss 0.055717    Top1 98.083333    Top5 99.994792    LR 0.000054    Time 0.019587    
2018-11-02 20:36:57,835 - Epoch: [289][  200/  391]    Overall Loss 0.055700    Objective Loss 0.055700    Top1 98.050781    Top5 99.992188    LR 0.000054    Time 0.019486    
2018-11-02 20:36:58,793 - Epoch: [289][  250/  391]    Overall Loss 0.054855    Objective Loss 0.054855    Top1 98.106250    Top5 99.990625    LR 0.000054    Time 0.019415    
2018-11-02 20:36:59,754 - Epoch: [289][  300/  391]    Overall Loss 0.054761    Objective Loss 0.054761    Top1 98.125000    Top5 99.992188    LR 0.000054    Time 0.019380    
2018-11-02 20:37:00,718 - Epoch: [289][  350/  391]    Overall Loss 0.054116    Objective Loss 0.054116    Top1 98.169643    Top5 99.993304    LR 0.000054    Time 0.019363    
2018-11-02 20:37:01,585 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35817 | -0.00310 |    0.22218 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14132 | -0.00193 |    0.08993 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15076 | -0.00640 |    0.11474 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17155 | -0.03092 |    0.13195 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17528 |  0.00087 |    0.13781 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17118 | -0.02773 |    0.13185 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16134 | -0.00599 |    0.11634 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19478 | -0.00108 |    0.14348 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16315 | -0.00496 |    0.12457 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24663 | -0.00337 |    0.16642 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13669 | -0.00192 |    0.10432 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11897 | -0.00905 |    0.09338 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14097 | -0.01537 |    0.11218 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10717 | -0.00280 |    0.08408 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12749 | -0.01374 |    0.10167 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12459 | -0.00129 |    0.09891 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14446 | -0.01080 |    0.11180 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11441 | -0.00750 |    0.09029 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09785 | -0.00621 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10353 | -0.01252 |    0.08290 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58126 | -0.00001 |    0.45507 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:37:01,586 - Total sparsity: 0.00

2018-11-02 20:37:01,586 - --- validate (epoch=289)-----------
2018-11-02 20:37:01,586 - 10000 samples (128 per mini-batch)
2018-11-02 20:37:02,300 - Epoch: [289][   50/   78]    Loss 0.392008    Top1 90.421875    Top5 99.671875    
2018-11-02 20:37:02,686 - ==> Top1: 90.220    Top5: 99.680    Loss: 0.396

2018-11-02 20:37:02,686 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:37:02,687 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:37:02,694 - 

2018-11-02 20:37:02,694 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:37:03,744 - Epoch: [290][   50/  391]    Overall Loss 0.053538    Objective Loss 0.053538    Top1 98.281250    Top5 100.000000    LR 0.000052    Time 0.020957    
2018-11-02 20:37:04,878 - Epoch: [290][  100/  391]    Overall Loss 0.055441    Objective Loss 0.055441    Top1 98.125000    Top5 100.000000    LR 0.000052    Time 0.021803    
2018-11-02 20:37:05,861 - Epoch: [290][  150/  391]    Overall Loss 0.055467    Objective Loss 0.055467    Top1 98.135417    Top5 100.000000    LR 0.000052    Time 0.021081    
2018-11-02 20:37:06,852 - Epoch: [290][  200/  391]    Overall Loss 0.055944    Objective Loss 0.055944    Top1 98.121094    Top5 100.000000    LR 0.000052    Time 0.020743    
2018-11-02 20:37:07,813 - Epoch: [290][  250/  391]    Overall Loss 0.056130    Objective Loss 0.056130    Top1 98.096875    Top5 100.000000    LR 0.000052    Time 0.020437    
2018-11-02 20:37:08,773 - Epoch: [290][  300/  391]    Overall Loss 0.056222    Objective Loss 0.056222    Top1 98.083333    Top5 99.997396    LR 0.000052    Time 0.020227    
2018-11-02 20:37:09,733 - Epoch: [290][  350/  391]    Overall Loss 0.054835    Objective Loss 0.054835    Top1 98.140625    Top5 99.997768    LR 0.000052    Time 0.020076    
2018-11-02 20:37:10,603 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35816 | -0.00312 |    0.22218 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14132 | -0.00193 |    0.08993 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15076 | -0.00639 |    0.11474 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17155 | -0.03093 |    0.13195 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17528 |  0.00086 |    0.13781 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17118 | -0.02773 |    0.13185 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16134 | -0.00599 |    0.11634 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19478 | -0.00108 |    0.14347 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16314 | -0.00496 |    0.12456 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24662 | -0.00337 |    0.16642 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13669 | -0.00192 |    0.10432 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11897 | -0.00905 |    0.09338 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14096 | -0.01537 |    0.11218 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10717 | -0.00280 |    0.08408 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12749 | -0.01374 |    0.10167 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12458 | -0.00129 |    0.09891 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14446 | -0.01080 |    0.11180 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11441 | -0.00750 |    0.09029 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09785 | -0.00621 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10353 | -0.01252 |    0.08290 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58126 | -0.00001 |    0.45507 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:37:10,603 - Total sparsity: 0.00

2018-11-02 20:37:10,603 - --- validate (epoch=290)-----------
2018-11-02 20:37:10,603 - 10000 samples (128 per mini-batch)
2018-11-02 20:37:11,324 - Epoch: [290][   50/   78]    Loss 0.390790    Top1 90.453125    Top5 99.687500    
2018-11-02 20:37:11,715 - ==> Top1: 90.210    Top5: 99.700    Loss: 0.395

2018-11-02 20:37:11,715 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:37:11,716 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:37:11,723 - 

2018-11-02 20:37:11,723 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:37:12,765 - Epoch: [291][   50/  391]    Overall Loss 0.053889    Objective Loss 0.053889    Top1 98.218750    Top5 100.000000    LR 0.000049    Time 0.020805    
2018-11-02 20:37:13,772 - Epoch: [291][  100/  391]    Overall Loss 0.054221    Objective Loss 0.054221    Top1 98.195312    Top5 100.000000    LR 0.000049    Time 0.020457    
2018-11-02 20:37:14,734 - Epoch: [291][  150/  391]    Overall Loss 0.054995    Objective Loss 0.054995    Top1 98.187500    Top5 100.000000    LR 0.000049    Time 0.020045    
2018-11-02 20:37:15,692 - Epoch: [291][  200/  391]    Overall Loss 0.054656    Objective Loss 0.054656    Top1 98.214844    Top5 100.000000    LR 0.000049    Time 0.019820    
2018-11-02 20:37:16,653 - Epoch: [291][  250/  391]    Overall Loss 0.055130    Objective Loss 0.055130    Top1 98.209375    Top5 99.996875    LR 0.000049    Time 0.019695    
2018-11-02 20:37:17,612 - Epoch: [291][  300/  391]    Overall Loss 0.054984    Objective Loss 0.054984    Top1 98.197917    Top5 99.997396    LR 0.000049    Time 0.019592    
2018-11-02 20:37:18,574 - Epoch: [291][  350/  391]    Overall Loss 0.054830    Objective Loss 0.054830    Top1 98.183036    Top5 99.997768    LR 0.000049    Time 0.019538    
2018-11-02 20:37:19,448 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35815 | -0.00310 |    0.22218 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14132 | -0.00193 |    0.08993 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15075 | -0.00640 |    0.11474 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17154 | -0.03092 |    0.13195 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17527 |  0.00087 |    0.13780 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17118 | -0.02773 |    0.13185 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16134 | -0.00599 |    0.11634 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19478 | -0.00108 |    0.14347 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16314 | -0.00496 |    0.12456 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24662 | -0.00337 |    0.16642 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13669 | -0.00192 |    0.10432 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11897 | -0.00905 |    0.09338 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14096 | -0.01536 |    0.11217 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10717 | -0.00279 |    0.08408 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12748 | -0.01374 |    0.10167 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12458 | -0.00129 |    0.09891 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14446 | -0.01080 |    0.11180 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11440 | -0.00750 |    0.09029 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09785 | -0.00621 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10352 | -0.01252 |    0.08290 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58127 | -0.00001 |    0.45507 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:37:19,448 - Total sparsity: 0.00

2018-11-02 20:37:19,448 - --- validate (epoch=291)-----------
2018-11-02 20:37:19,448 - 10000 samples (128 per mini-batch)
2018-11-02 20:37:20,162 - Epoch: [291][   50/   78]    Loss 0.390103    Top1 90.390625    Top5 99.656250    
2018-11-02 20:37:20,551 - ==> Top1: 90.230    Top5: 99.680    Loss: 0.395

2018-11-02 20:37:20,551 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:37:20,552 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:37:20,563 - 

2018-11-02 20:37:20,563 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:37:21,583 - Epoch: [292][   50/  391]    Overall Loss 0.051454    Objective Loss 0.051454    Top1 98.281250    Top5 100.000000    LR 0.000047    Time 0.020360    
2018-11-02 20:37:22,545 - Epoch: [292][  100/  391]    Overall Loss 0.049776    Objective Loss 0.049776    Top1 98.390625    Top5 100.000000    LR 0.000047    Time 0.019796    
2018-11-02 20:37:23,510 - Epoch: [292][  150/  391]    Overall Loss 0.053501    Objective Loss 0.053501    Top1 98.302083    Top5 99.994792    LR 0.000047    Time 0.019621    
2018-11-02 20:37:24,475 - Epoch: [292][  200/  391]    Overall Loss 0.054251    Objective Loss 0.054251    Top1 98.257812    Top5 99.988281    LR 0.000047    Time 0.019534    
2018-11-02 20:37:25,439 - Epoch: [292][  250/  391]    Overall Loss 0.053979    Objective Loss 0.053979    Top1 98.256250    Top5 99.990625    LR 0.000047    Time 0.019479    
2018-11-02 20:37:26,401 - Epoch: [292][  300/  391]    Overall Loss 0.054623    Objective Loss 0.054623    Top1 98.197917    Top5 99.992188    LR 0.000047    Time 0.019433    
2018-11-02 20:37:27,362 - Epoch: [292][  350/  391]    Overall Loss 0.054295    Objective Loss 0.054295    Top1 98.203125    Top5 99.993304    LR 0.000047    Time 0.019400    
2018-11-02 20:37:28,256 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35814 | -0.00312 |    0.22217 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14131 | -0.00193 |    0.08993 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15075 | -0.00640 |    0.11474 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17154 | -0.03092 |    0.13195 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17527 |  0.00087 |    0.13780 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17118 | -0.02773 |    0.13185 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16133 | -0.00599 |    0.11634 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19477 | -0.00108 |    0.14347 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16314 | -0.00496 |    0.12456 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24661 | -0.00337 |    0.16641 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13668 | -0.00192 |    0.10432 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11897 | -0.00905 |    0.09337 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14096 | -0.01536 |    0.11217 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10716 | -0.00279 |    0.08408 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12748 | -0.01374 |    0.10166 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12458 | -0.00129 |    0.09891 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14446 | -0.01080 |    0.11180 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11440 | -0.00750 |    0.09029 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09785 | -0.00621 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10352 | -0.01252 |    0.08290 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58127 | -0.00001 |    0.45507 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:37:28,256 - Total sparsity: 0.00

2018-11-02 20:37:28,256 - --- validate (epoch=292)-----------
2018-11-02 20:37:28,256 - 10000 samples (128 per mini-batch)
2018-11-02 20:37:28,976 - Epoch: [292][   50/   78]    Loss 0.388915    Top1 90.343750    Top5 99.640625    
2018-11-02 20:37:29,364 - ==> Top1: 90.180    Top5: 99.680    Loss: 0.394

2018-11-02 20:37:29,365 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:37:29,365 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:37:29,373 - 

2018-11-02 20:37:29,373 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:37:30,392 - Epoch: [293][   50/  391]    Overall Loss 0.052537    Objective Loss 0.052537    Top1 98.234375    Top5 100.000000    LR 0.000044    Time 0.020346    
2018-11-02 20:37:31,351 - Epoch: [293][  100/  391]    Overall Loss 0.052345    Objective Loss 0.052345    Top1 98.273438    Top5 100.000000    LR 0.000044    Time 0.019753    
2018-11-02 20:37:32,313 - Epoch: [293][  150/  391]    Overall Loss 0.052536    Objective Loss 0.052536    Top1 98.229167    Top5 100.000000    LR 0.000044    Time 0.019574    
2018-11-02 20:37:33,273 - Epoch: [293][  200/  391]    Overall Loss 0.052207    Objective Loss 0.052207    Top1 98.257812    Top5 100.000000    LR 0.000044    Time 0.019473    
2018-11-02 20:37:34,235 - Epoch: [293][  250/  391]    Overall Loss 0.052119    Objective Loss 0.052119    Top1 98.237500    Top5 100.000000    LR 0.000044    Time 0.019423    
2018-11-02 20:37:35,197 - Epoch: [293][  300/  391]    Overall Loss 0.052864    Objective Loss 0.052864    Top1 98.226562    Top5 100.000000    LR 0.000044    Time 0.019386    
2018-11-02 20:37:36,159 - Epoch: [293][  350/  391]    Overall Loss 0.052821    Objective Loss 0.052821    Top1 98.245536    Top5 100.000000    LR 0.000044    Time 0.019362    
2018-11-02 20:37:37,031 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35814 | -0.00313 |    0.22217 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14131 | -0.00193 |    0.08993 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15075 | -0.00640 |    0.11474 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17154 | -0.03092 |    0.13195 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17527 |  0.00087 |    0.13780 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17117 | -0.02773 |    0.13185 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16133 | -0.00598 |    0.11633 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19477 | -0.00108 |    0.14347 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16313 | -0.00496 |    0.12456 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24661 | -0.00337 |    0.16641 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13668 | -0.00192 |    0.10432 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11897 | -0.00905 |    0.09337 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14096 | -0.01536 |    0.11217 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10716 | -0.00279 |    0.08408 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12748 | -0.01374 |    0.10166 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12458 | -0.00129 |    0.09890 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14445 | -0.01080 |    0.11180 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11440 | -0.00750 |    0.09028 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09785 | -0.00621 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10352 | -0.01252 |    0.08290 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58127 | -0.00001 |    0.45507 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:37:37,031 - Total sparsity: 0.00

2018-11-02 20:37:37,031 - --- validate (epoch=293)-----------
2018-11-02 20:37:37,031 - 10000 samples (128 per mini-batch)
2018-11-02 20:37:37,751 - Epoch: [293][   50/   78]    Loss 0.385336    Top1 90.578125    Top5 99.671875    
2018-11-02 20:37:38,141 - ==> Top1: 90.400    Top5: 99.680    Loss: 0.389

2018-11-02 20:37:38,142 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:37:38,142 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:37:38,153 - 

2018-11-02 20:37:38,153 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:37:39,171 - Epoch: [294][   50/  391]    Overall Loss 0.051634    Objective Loss 0.051634    Top1 98.265625    Top5 100.000000    LR 0.000042    Time 0.020315    
2018-11-02 20:37:40,130 - Epoch: [294][  100/  391]    Overall Loss 0.054030    Objective Loss 0.054030    Top1 98.093750    Top5 99.992188    LR 0.000042    Time 0.019741    
2018-11-02 20:37:41,092 - Epoch: [294][  150/  391]    Overall Loss 0.053083    Objective Loss 0.053083    Top1 98.135417    Top5 99.994792    LR 0.000042    Time 0.019563    
2018-11-02 20:37:42,051 - Epoch: [294][  200/  391]    Overall Loss 0.053067    Objective Loss 0.053067    Top1 98.128906    Top5 99.996094    LR 0.000042    Time 0.019464    
2018-11-02 20:37:43,011 - Epoch: [294][  250/  391]    Overall Loss 0.053404    Objective Loss 0.053404    Top1 98.150000    Top5 99.993750    LR 0.000042    Time 0.019405    
2018-11-02 20:37:43,974 - Epoch: [294][  300/  391]    Overall Loss 0.054417    Objective Loss 0.054417    Top1 98.101562    Top5 99.994792    LR 0.000042    Time 0.019375    
2018-11-02 20:37:44,940 - Epoch: [294][  350/  391]    Overall Loss 0.054610    Objective Loss 0.054610    Top1 98.116071    Top5 99.995536    LR 0.000042    Time 0.019365    
2018-11-02 20:37:45,807 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35813 | -0.00313 |    0.22217 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14131 | -0.00193 |    0.08993 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15075 | -0.00639 |    0.11473 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17153 | -0.03092 |    0.13194 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17527 |  0.00087 |    0.13780 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17117 | -0.02773 |    0.13184 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16133 | -0.00598 |    0.11633 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19477 | -0.00108 |    0.14346 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16313 | -0.00496 |    0.12455 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24661 | -0.00337 |    0.16641 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13668 | -0.00192 |    0.10431 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00904 |    0.09337 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14095 | -0.01536 |    0.11217 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10716 | -0.00279 |    0.08408 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12748 | -0.01374 |    0.10166 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00129 |    0.09890 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14445 | -0.01080 |    0.11180 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11440 | -0.00750 |    0.09028 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09785 | -0.00621 |    0.07675 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10352 | -0.01251 |    0.08290 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58127 | -0.00001 |    0.45508 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:37:45,807 - Total sparsity: 0.00

2018-11-02 20:37:45,807 - --- validate (epoch=294)-----------
2018-11-02 20:37:45,807 - 10000 samples (128 per mini-batch)
2018-11-02 20:37:46,532 - Epoch: [294][   50/   78]    Loss 0.389959    Top1 90.375000    Top5 99.671875    
2018-11-02 20:37:46,925 - ==> Top1: 90.220    Top5: 99.690    Loss: 0.394

2018-11-02 20:37:46,926 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:37:46,926 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:37:46,933 - 

2018-11-02 20:37:46,934 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:37:48,025 - Epoch: [295][   50/  391]    Overall Loss 0.058135    Objective Loss 0.058135    Top1 98.046875    Top5 99.984375    LR 0.000040    Time 0.021796    
2018-11-02 20:37:49,001 - Epoch: [295][  100/  391]    Overall Loss 0.053596    Objective Loss 0.053596    Top1 98.195312    Top5 99.984375    LR 0.000040    Time 0.020647    
2018-11-02 20:37:49,962 - Epoch: [295][  150/  391]    Overall Loss 0.054115    Objective Loss 0.054115    Top1 98.250000    Top5 99.989583    LR 0.000040    Time 0.020162    
2018-11-02 20:37:50,924 - Epoch: [295][  200/  391]    Overall Loss 0.053744    Objective Loss 0.053744    Top1 98.234375    Top5 99.992188    LR 0.000040    Time 0.019925    
2018-11-02 20:37:51,886 - Epoch: [295][  250/  391]    Overall Loss 0.053664    Objective Loss 0.053664    Top1 98.231250    Top5 99.993750    LR 0.000040    Time 0.019783    
2018-11-02 20:37:52,847 - Epoch: [295][  300/  391]    Overall Loss 0.053079    Objective Loss 0.053079    Top1 98.273438    Top5 99.994792    LR 0.000040    Time 0.019687    
2018-11-02 20:37:53,809 - Epoch: [295][  350/  391]    Overall Loss 0.053715    Objective Loss 0.053715    Top1 98.270089    Top5 99.995536    LR 0.000040    Time 0.019618    
2018-11-02 20:37:54,681 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35813 | -0.00314 |    0.22217 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14131 | -0.00193 |    0.08993 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15074 | -0.00639 |    0.11473 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17153 | -0.03092 |    0.13194 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17526 |  0.00087 |    0.13779 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17117 | -0.02772 |    0.13184 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16133 | -0.00598 |    0.11633 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19476 | -0.00109 |    0.14346 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16313 | -0.00496 |    0.12455 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24660 | -0.00337 |    0.16640 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13668 | -0.00192 |    0.10431 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00904 |    0.09337 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14095 | -0.01536 |    0.11217 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10716 | -0.00279 |    0.08408 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12747 | -0.01374 |    0.10166 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00129 |    0.09890 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14445 | -0.01080 |    0.11179 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11440 | -0.00750 |    0.09028 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09784 | -0.00621 |    0.07674 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10352 | -0.01251 |    0.08289 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06234 |  0.00361 |    0.04719 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58128 | -0.00001 |    0.45508 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:37:54,681 - Total sparsity: 0.00

2018-11-02 20:37:54,681 - --- validate (epoch=295)-----------
2018-11-02 20:37:54,681 - 10000 samples (128 per mini-batch)
2018-11-02 20:37:55,396 - Epoch: [295][   50/   78]    Loss 0.389509    Top1 90.421875    Top5 99.671875    
2018-11-02 20:37:55,783 - ==> Top1: 90.300    Top5: 99.690    Loss: 0.392

2018-11-02 20:37:55,784 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:37:55,784 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:37:55,794 - 

2018-11-02 20:37:55,794 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:37:56,815 - Epoch: [296][   50/  391]    Overall Loss 0.051268    Objective Loss 0.051268    Top1 98.421875    Top5 100.000000    LR 0.000038    Time 0.020387    
2018-11-02 20:37:57,775 - Epoch: [296][  100/  391]    Overall Loss 0.052671    Objective Loss 0.052671    Top1 98.296875    Top5 99.992188    LR 0.000038    Time 0.019777    
2018-11-02 20:37:58,736 - Epoch: [296][  150/  391]    Overall Loss 0.055585    Objective Loss 0.055585    Top1 98.177083    Top5 99.989583    LR 0.000038    Time 0.019582    
2018-11-02 20:37:59,695 - Epoch: [296][  200/  391]    Overall Loss 0.054969    Objective Loss 0.054969    Top1 98.199219    Top5 99.992188    LR 0.000038    Time 0.019480    
2018-11-02 20:38:00,661 - Epoch: [296][  250/  391]    Overall Loss 0.054877    Objective Loss 0.054877    Top1 98.203125    Top5 99.990625    LR 0.000038    Time 0.019442    
2018-11-02 20:38:01,624 - Epoch: [296][  300/  391]    Overall Loss 0.054780    Objective Loss 0.054780    Top1 98.195312    Top5 99.989583    LR 0.000038    Time 0.019407    
2018-11-02 20:38:02,585 - Epoch: [296][  350/  391]    Overall Loss 0.054244    Objective Loss 0.054244    Top1 98.229911    Top5 99.988839    LR 0.000038    Time 0.019376    
2018-11-02 20:38:03,456 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35812 | -0.00316 |    0.22216 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14130 | -0.00192 |    0.08992 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15074 | -0.00639 |    0.11473 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17153 | -0.03092 |    0.13194 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17526 |  0.00087 |    0.13779 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17116 | -0.02772 |    0.13184 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16132 | -0.00598 |    0.11633 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19476 | -0.00109 |    0.14346 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16313 | -0.00496 |    0.12455 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24660 | -0.00337 |    0.16640 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13668 | -0.00192 |    0.10431 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00904 |    0.09337 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14095 | -0.01535 |    0.11217 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10716 | -0.00279 |    0.08408 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12747 | -0.01374 |    0.10166 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00129 |    0.09890 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14445 | -0.01080 |    0.11179 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11439 | -0.00750 |    0.09028 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09784 | -0.00621 |    0.07674 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10352 | -0.01251 |    0.08289 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06233 |  0.00361 |    0.04718 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58128 | -0.00001 |    0.45508 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:38:03,457 - Total sparsity: 0.00

2018-11-02 20:38:03,457 - --- validate (epoch=296)-----------
2018-11-02 20:38:03,457 - 10000 samples (128 per mini-batch)
2018-11-02 20:38:04,178 - Epoch: [296][   50/   78]    Loss 0.388987    Top1 90.437500    Top5 99.656250    
2018-11-02 20:38:04,559 - ==> Top1: 90.280    Top5: 99.680    Loss: 0.393

2018-11-02 20:38:04,560 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:38:04,560 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:38:04,571 - 

2018-11-02 20:38:04,572 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:38:05,591 - Epoch: [297][   50/  391]    Overall Loss 0.056428    Objective Loss 0.056428    Top1 98.109375    Top5 99.984375    LR 0.000036    Time 0.020364    
2018-11-02 20:38:06,554 - Epoch: [297][  100/  391]    Overall Loss 0.054663    Objective Loss 0.054663    Top1 98.164062    Top5 99.992188    LR 0.000036    Time 0.019794    
2018-11-02 20:38:07,517 - Epoch: [297][  150/  391]    Overall Loss 0.054710    Objective Loss 0.054710    Top1 98.250000    Top5 99.994792    LR 0.000036    Time 0.019609    
2018-11-02 20:38:08,478 - Epoch: [297][  200/  391]    Overall Loss 0.054864    Objective Loss 0.054864    Top1 98.238281    Top5 99.996094    LR 0.000036    Time 0.019506    
2018-11-02 20:38:09,438 - Epoch: [297][  250/  391]    Overall Loss 0.054927    Objective Loss 0.054927    Top1 98.240625    Top5 99.996875    LR 0.000036    Time 0.019441    
2018-11-02 20:38:10,401 - Epoch: [297][  300/  391]    Overall Loss 0.055025    Objective Loss 0.055025    Top1 98.229167    Top5 99.994792    LR 0.000036    Time 0.019406    
2018-11-02 20:38:11,364 - Epoch: [297][  350/  391]    Overall Loss 0.054388    Objective Loss 0.054388    Top1 98.245536    Top5 99.995536    LR 0.000036    Time 0.019382    
2018-11-02 20:38:12,231 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35812 | -0.00315 |    0.22215 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14130 | -0.00192 |    0.08992 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15074 | -0.00639 |    0.11473 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17153 | -0.03092 |    0.13194 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17526 |  0.00087 |    0.13779 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17116 | -0.02772 |    0.13184 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16132 | -0.00598 |    0.11633 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19476 | -0.00109 |    0.14346 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16312 | -0.00496 |    0.12455 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24659 | -0.00337 |    0.16640 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.00192 |    0.10431 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00904 |    0.09337 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14095 | -0.01535 |    0.11216 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10716 | -0.00279 |    0.08407 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12747 | -0.01374 |    0.10166 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00129 |    0.09890 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14444 | -0.01080 |    0.11179 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11439 | -0.00750 |    0.09028 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09784 | -0.00621 |    0.07674 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10351 | -0.01251 |    0.08289 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06233 |  0.00361 |    0.04718 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58128 | -0.00001 |    0.45508 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:38:12,231 - Total sparsity: 0.00

2018-11-02 20:38:12,231 - --- validate (epoch=297)-----------
2018-11-02 20:38:12,232 - 10000 samples (128 per mini-batch)
2018-11-02 20:38:12,956 - Epoch: [297][   50/   78]    Loss 0.387469    Top1 90.421875    Top5 99.687500    
2018-11-02 20:38:13,346 - ==> Top1: 90.270    Top5: 99.720    Loss: 0.393

2018-11-02 20:38:13,347 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:38:13,347 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:38:13,356 - 

2018-11-02 20:38:13,357 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:38:14,377 - Epoch: [298][   50/  391]    Overall Loss 0.049977    Objective Loss 0.049977    Top1 98.421875    Top5 99.968750    LR 0.000034    Time 0.020374    
2018-11-02 20:38:15,339 - Epoch: [298][  100/  391]    Overall Loss 0.050470    Objective Loss 0.050470    Top1 98.375000    Top5 99.984375    LR 0.000034    Time 0.019789    
2018-11-02 20:38:16,303 - Epoch: [298][  150/  391]    Overall Loss 0.050190    Objective Loss 0.050190    Top1 98.380208    Top5 99.984375    LR 0.000034    Time 0.019616    
2018-11-02 20:38:17,269 - Epoch: [298][  200/  391]    Overall Loss 0.050956    Objective Loss 0.050956    Top1 98.343750    Top5 99.988281    LR 0.000034    Time 0.019533    
2018-11-02 20:38:18,230 - Epoch: [298][  250/  391]    Overall Loss 0.052829    Objective Loss 0.052829    Top1 98.256250    Top5 99.990625    LR 0.000034    Time 0.019468    
2018-11-02 20:38:19,193 - Epoch: [298][  300/  391]    Overall Loss 0.052806    Objective Loss 0.052806    Top1 98.242188    Top5 99.992188    LR 0.000034    Time 0.019429    
2018-11-02 20:38:20,156 - Epoch: [298][  350/  391]    Overall Loss 0.053273    Objective Loss 0.053273    Top1 98.225446    Top5 99.991071    LR 0.000034    Time 0.019400    
2018-11-02 20:38:21,025 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35811 | -0.00313 |    0.22215 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14130 | -0.00192 |    0.08992 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15074 | -0.00640 |    0.11473 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17152 | -0.03092 |    0.13194 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17525 |  0.00087 |    0.13779 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17116 | -0.02772 |    0.13183 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16132 | -0.00598 |    0.11633 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19476 | -0.00108 |    0.14345 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16312 | -0.00496 |    0.12455 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24659 | -0.00337 |    0.16639 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.00192 |    0.10431 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00904 |    0.09337 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14095 | -0.01535 |    0.11216 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10715 | -0.00279 |    0.08407 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12747 | -0.01374 |    0.10165 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00129 |    0.09890 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14444 | -0.01080 |    0.11179 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11439 | -0.00750 |    0.09028 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09784 | -0.00621 |    0.07674 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10351 | -0.01251 |    0.08289 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06233 |  0.00361 |    0.04718 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58128 | -0.00001 |    0.45508 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:38:21,025 - Total sparsity: 0.00

2018-11-02 20:38:21,025 - --- validate (epoch=298)-----------
2018-11-02 20:38:21,025 - 10000 samples (128 per mini-batch)
2018-11-02 20:38:21,746 - Epoch: [298][   50/   78]    Loss 0.388884    Top1 90.546875    Top5 99.703125    
2018-11-02 20:38:22,139 - ==> Top1: 90.370    Top5: 99.710    Loss: 0.392

2018-11-02 20:38:22,139 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:38:22,140 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:38:22,151 - 

2018-11-02 20:38:22,151 - Training epoch: 50000 samples (128 per mini-batch)
2018-11-02 20:38:23,171 - Epoch: [299][   50/  391]    Overall Loss 0.056288    Objective Loss 0.056288    Top1 98.140625    Top5 100.000000    LR 0.000033    Time 0.020356    
2018-11-02 20:38:24,131 - Epoch: [299][  100/  391]    Overall Loss 0.053160    Objective Loss 0.053160    Top1 98.265625    Top5 99.992188    LR 0.000033    Time 0.019773    
2018-11-02 20:38:25,093 - Epoch: [299][  150/  391]    Overall Loss 0.052957    Objective Loss 0.052957    Top1 98.296875    Top5 99.994792    LR 0.000033    Time 0.019582    
2018-11-02 20:38:26,058 - Epoch: [299][  200/  391]    Overall Loss 0.052240    Objective Loss 0.052240    Top1 98.285156    Top5 99.996094    LR 0.000033    Time 0.019508    
2018-11-02 20:38:27,020 - Epoch: [299][  250/  391]    Overall Loss 0.052396    Objective Loss 0.052396    Top1 98.265625    Top5 99.996875    LR 0.000033    Time 0.019450    
2018-11-02 20:38:27,983 - Epoch: [299][  300/  391]    Overall Loss 0.052645    Objective Loss 0.052645    Top1 98.234375    Top5 99.994792    LR 0.000033    Time 0.019413    
2018-11-02 20:38:28,944 - Epoch: [299][  350/  391]    Overall Loss 0.052724    Objective Loss 0.052724    Top1 98.229911    Top5 99.995536    LR 0.000033    Time 0.019383    
2018-11-02 20:38:29,815 - 
Parameters:
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
|    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
|----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
|  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.35811 | -0.00313 |    0.22215 |
|  1 | module.layer1.0.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14130 | -0.00192 |    0.08992 |
|  2 | module.layer1.0.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15074 | -0.00640 |    0.11473 |
|  3 | module.layer1.1.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17152 | -0.03092 |    0.13194 |
|  4 | module.layer1.1.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17525 |  0.00087 |    0.13779 |
|  5 | module.layer1.2.conv1.weight        | (7, 16, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17116 | -0.02772 |    0.13183 |
|  6 | module.layer1.2.conv2.weight        | (16, 7, 3, 3)  |          1008 |           1008 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16132 | -0.00598 |    0.11632 |
|  7 | module.layer2.0.conv1.weight        | (13, 16, 3, 3) |          1872 |           1872 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19475 | -0.00109 |    0.14345 |
|  8 | module.layer2.0.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16312 | -0.00496 |    0.12454 |
|  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.24659 | -0.00337 |    0.16639 |
| 10 | module.layer2.1.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13667 | -0.00192 |    0.10431 |
| 11 | module.layer2.1.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11896 | -0.00904 |    0.09336 |
| 12 | module.layer2.2.conv1.weight        | (13, 32, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14094 | -0.01535 |    0.11216 |
| 13 | module.layer2.2.conv2.weight        | (32, 13, 3, 3) |          3744 |           3744 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10715 | -0.00279 |    0.08407 |
| 14 | module.layer3.0.conv1.weight        | (26, 32, 3, 3) |          7488 |           7488 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12747 | -0.01374 |    0.10165 |
| 15 | module.layer3.0.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12457 | -0.00129 |    0.09890 |
| 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14444 | -0.01080 |    0.11179 |
| 17 | module.layer3.1.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11439 | -0.00750 |    0.09028 |
| 18 | module.layer3.1.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09784 | -0.00621 |    0.07674 |
| 19 | module.layer3.2.conv1.weight        | (26, 64, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10351 | -0.01251 |    0.08289 |
| 20 | module.layer3.2.conv2.weight        | (64, 26, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06233 |  0.00361 |    0.04718 |
| 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.58128 | -0.00001 |    0.45508 |
| 22 | Total sparsity:                     | -              |        112640 |         112640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
+----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
2018-11-02 20:38:29,816 - Total sparsity: 0.00

2018-11-02 20:38:29,816 - --- validate (epoch=299)-----------
2018-11-02 20:38:29,816 - 10000 samples (128 per mini-batch)
2018-11-02 20:38:30,541 - Epoch: [299][   50/   78]    Loss 0.387326    Top1 90.343750    Top5 99.687500    
2018-11-02 20:38:30,930 - ==> Top1: 90.220    Top5: 99.700    Loss: 0.391

2018-11-02 20:38:30,931 - ==> Best Top1: 90.400   On Epoch: 217

2018-11-02 20:38:30,931 - Saving checkpoint to: logs/2018.11.02-195132/checkpoint.pth.tar
2018-11-02 20:38:30,941 - --- test ---------------------
2018-11-02 20:38:30,942 - 10000 samples (128 per mini-batch)
2018-11-02 20:38:31,691 - Test: [   50/   78]    Loss 0.387326    Top1 90.343750    Top5 99.687500    
2018-11-02 20:38:32,081 - ==> Top1: 90.220    Top5: 99.700    Loss: 0.391

2018-11-02 20:38:32,085 - 
2018-11-02 20:38:32,085 - Log file for this run: /home/ccma/Chilung/1022/distiller/examples/classifier_compression/logs/2018.11.02-195132/2018.11.02-195132.log
